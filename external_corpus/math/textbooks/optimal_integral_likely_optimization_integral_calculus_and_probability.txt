        OPTIMAL, INTEGRAL, LIKELY

          OPTIMIZATION, INTEGRAL CALCULUS, AND PROBABILITY

             FOR STUDENTS OF COMMERCE AND THE SOCIAL SCIENCES
      Prepared by Bruno Belevan, Parham Hamidi, Nisha Malhotra, and Elyse Yeager
   Adapted from CLP Calculus by Joel Feldman, Andrew Rechnitzer, and Elyse Yeager

THIS DOCUMENT WAS TYPESET ON WEDNESDAY 29TH MAY, 2024.
ee e Licenses and Attributions

Copyright © 2020, 2021 Bruno Belevan, Parham Hamidi, Nisha Malhotra, and Elyse Yea-
ger
This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike
4.0 International License. You can view a copy of the license at
http://creativecommons.org/licenses/by-nc-sa/4.0/.

Source files can be found at https://gitlab.math.ubc.ca/ecyeager/OIL
This textbook contains new material as well as material adapted from open sources.

    · Chapters 1 and 2 (and their associated appendix sections) were adapted with mi-
       nor changes from Chapters 1 and 2 of CLP 3 - Multivariable Calculus by Feldman,
       Rechnitzer, and Yeager under a Creative Commons Attribution-NonCommercial-
       ShareAlike 4.0 International license.

    · Chapters 3 and 5 (and their associated appendix sections) and Appendix B were
       adapted with minor changes from Chapters 1 and 3, Section 2.4, and Appendix A
       of CLP 2 - Integral Calculus by Feldman, Rechnitzer, and Yeager under a Creative
       Commons Attribution-NonCommercial-ShareAlike 4.0 International license.

    · Chapter 4 contains content adapted with significant changes from Sections 1.1, 3.1,
       Ch 4 introduction, 4.1, and 4.2 of Introductory Statistics by Ilowsky and Dean under
       a Creative Commons Attribution License v4.0.

 Acknowledgements

UBC Point Grey campus sits on the traditional, ancestral and unceded territory of the
xwm kw y´ m (Musqueam). Musqueam and UBC have an ongoing relationship sharing
insight, knowledge, and labour. Those interested in learning more about this relationship
might start here.

    Matt Coles of the University of British Columbia has been an important member of the
project to develop quality open resources for Math 105. Thanks to Andrew Rechnitzer at
UBC Mathematics for help converting LaTeX to PreTeXt.

    The development of this text was supported by an OER Implementation Grant, pro-
vided through the UBC Open Educational Resources Fund.

 Contact

To report a mistake, or to let us know you're using this book in a course you're teaching,
please email elyse@math.ubc.ca

                                                          2
                       CONTENTS

1 Geometry in Three Dimensions     1

1.1 Points . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1

1.2 Functions of Two Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3

1.3 Sketching Surfaces in 3d . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9

1.3.1 Quadric Surfaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24

2 Partial Derivatives              28

2.1 Partial Derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28

2.2 Higher Order Derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36

2.3 Local Maximum and Minimum Values . . . . . . . . . . . . . . . . . . . . . . 39

2.3.1 Critical Points . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40

2.3.2 Classifying Critical Points . . . . . . . . . . . . . . . . . . . . . . . . . 50

2.4 Absolute Minima and Maxima . . . . . . . . . . . . . . . . . . . . . . . . . . 61

2.5 Lagrange Multipliers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70

2.5.1 Bounded vs Unbounded Constraints . . . . . . . . . . . . . . . . . . . 81

2.6 Utility and Demand Functions . . . . . . . . . . . . . . . . . . . . . . . . . . 83

2.6.1 Constrained Optimization of the Utility Function . . . . . . . . . . . 84

2.6.2 Demand Curves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87

3 Integration                      95

3.1 Definition of the Integral . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95

3.1.1 Summation Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103

3.1.2 The Definition of the Definite Integral . . . . . . . . . . . . . . . . . . 107

3.1.3 Using Known Areas to Evaluate Integrals . . . . . . . . . . . . . . . . 115

3.1.4 Surplus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118

3.2 Basic Properties of the Definite Integral . . . . . . . . . . . . . . . . . . . . . 126

3.2.1 More Properties of Integration: Even and Odd Functions . . . . . . . 134

3.2.2 More Properties of Integration: Inequalities for Integrals . . . . . . . 137

3.3 The Fundamental Theorem of Calculus . . . . . . . . . . . . . . . . . . . . . 139

3.3.1 Indefinite Integration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145

3.3.2 Marginal Cost and Marginal Revenue . . . . . . . . . . . . . . . . . . 155

                                i
CONTENTS                    CONTENTS

3.4 Substitution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
      3.4.1 Substitution and Definite Integrals . . . . . . . . . . . . . . . . . . . . 164
      3.4.2 More Substitution Examples . . . . . . . . . . . . . . . . . . . . . . . 168

3.5 Integration by Parts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172
      3.5.1 Another Technique using Integration by Parts: dv = dx . . . . . . . . 179

3.6 Numerical Integration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
      3.6.1 Simpson's Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184
      3.6.2 Error Behaviour . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188

3.7 Improper Integrals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192
      3.7.1 Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192
      3.7.2 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
      3.7.3 Convergence Tests for Improper Integrals . . . . . . . . . . . . . . . . 205

3.8 Overview of Integration Techniques . . . . . . . . . . . . . . . . . . . . . . . 212
3.9 Differential Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215

      3.9.1 (Optional) Logistic Growth . . . . . . . . . . . . . . . . . . . . . . . . 225
      3.9.2 (Optional) Interest on Investments and Loans . . . . . . . . . . . . . 231

4 Probability               238

4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238
      4.1.1 Foundational Vocabulary and Notation . . . . . . . . . . . . . . . . . 238
      4.1.2 Discrete vs Continuous . . . . . . . . . . . . . . . . . . . . . . . . . . 242
      4.1.3 Combining Events . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244
      4.1.4 Equally Likely Outcomes . . . . . . . . . . . . . . . . . . . . . . . . . 246

4.2 Probability Mass Function (PMF) . . . . . . . . . . . . . . . . . . . . . . . . . 249
      4.2.1 Limitations of Probability Mass Function (PMF) . . . . . . . . . . . . 254

4.3 Cumulative Distribution Function (CDF) . . . . . . . . . . . . . . . . . . . . 256
4.4 Probability Density . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263

      4.4.1 Density Diagrams . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
      4.4.2 Probability Density Function (PDF) . . . . . . . . . . . . . . . . . . . 265
4.5 Expected Value . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272
      4.5.1 Motivation: Long-Term Average . . . . . . . . . . . . . . . . . . . . . 272
      4.5.2 Definition and Examples . . . . . . . . . . . . . . . . . . . . . . . . . . 273
      4.5.3 Checking your Expectation Calculation . . . . . . . . . . . . . . . . . 277
4.6 Variance and Standard Deviation . . . . . . . . . . . . . . . . . . . . . . . . . 283
      4.6.1 Motivation: Average difference from the average . . . . . . . . . . . 283
      4.6.2 Definitions and Computations . . . . . . . . . . . . . . . . . . . . . . 285
      4.6.3 Checking your Standard Deviation Calculation . . . . . . . . . . . . 292

5 Sequences and Series      294

5.1 Sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 295
      5.1.1 Musical Scales . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300

5.2 Series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305
      5.2.1 Geometric Series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308
      5.2.2 Telescoping Series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313
      5.2.3 Arithmetic of Series . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315
      5.2.4 (Optional) Intergenerational Cost-Benefit Analysis . . . . . . . . . . 317

5.3 The Integral and Divergence Tests . . . . . . . . . . . . . . . . . . . . . . . . 319

                        ii
CONTENTS                                                                                  CONTENTS

5.4 Comparison Tests . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 326
5.5 The Ratio Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332

      5.5.1 Convergence Test List . . . . . . . . . . . . . . . . . . . . . . . . . . . 334
5.6 Absolute and Conditional Convergence . . . . . . . . . . . . . . . . . . . . . 335

6 Power Series                                                                                           338

6.1 Radius of Convergence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 339
6.2 Working With Power Series . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347
6.3 Extending Taylor Polynomials . . . . . . . . . . . . . . . . . . . . . . . . . . . 354
6.4 Computing with Taylor Series . . . . . . . . . . . . . . . . . . . . . . . . . . . 362
6.5 Evaluating Limits using Taylor Expansions . . . . . . . . . . . . . . . . . . . 368

A Proofs and Supplements                                                                                 371
A.1 Folding the First Octant of R3 . . . . . . . . . . . . . . . . . . . . . . . . . . . 371
A.2 Vectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 372
A.2.1 Addition of Vectors and Multiplication of a Vector by a Scalar . . . . 375
A.2.2 The Dot Product . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 378
A.3 Conic Sections and Quadric Surfaces . . . . . . . . . . . . . . . . . . . . . . . 381
A.4 Mixed Partial Derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 383
A.4.1 Clairaut: The Pro2of of Theorem22.2.5 . . . . . . . . . . . . . . . . . . . 383
                             ff                     ff
A.4.2 An Example of fxfy (x0, y0) $ fyfx (x0, y0) . . . . . . . . . . . . . . . . 386
A.5 The (multivariable) chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . 387
                                        d                df     dx (t)
A.5.1     Review  of    the  Proof  of  dt  f  x(t)                     .  .  .  .  .  .  .  .  .  .  .  389
                                                     = dx x(t)  dt
A.5.2 Proof of Theorem A.5.1 . . . . . . . . . . . . . . . . . . . . . . . . . . 389
A.6 Lagrange Multipliers: Proof of Theorem 2.5.2 . . . . . . . . . . . . . . . . . . 393
A.7 A More Rigorous Area Computation . . . . . . . . . . . . . . . . . . . . . . . 394
A.8 Careful Definition of the Integral . . . . . . . . . . . . . . . . . . . . . . . . . 396
A.9 Integrating sec x and csc x . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 401
A.10 Further Reading on Numerical Integration . . . . . . . . . . . . . . . . . . . 403
A.10.1 The Midpoint Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 403
A.10.2 The Trapezoidal Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . 406
A.10.3 Error Behaviour . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 409
A.10.4 An Error Bound for the Midpoint Rule . . . . . . . . . . . . . . . . . 410
A.11 Comparison Tests Proof . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 413
A.12 Alternating Series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 414
A.12.1 The Alternating Series Test . . . . . . . . . . . . . . . . . . . . . . . . 414
A.12.2 Alternating Series Test Proof . . . . . . . . . . . . . . . . . . . . . . . 419
A.13 Delicacy of Conditional Convergence . . . . . . . . . . . . . . . . . . . . . . 419

B High school material                                                                                   423

B.1 Similar Triangles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 423
B.2 Pythagoras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 424
B.3 Trigonometry -- Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 424
B.4 Radians, Arcs and Sectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 424
B.5 Trigonometry -- Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 425
B.6 Trigonometry -- Special Triangles . . . . . . . . . . . . . . . . . . . . . . . . 425
B.7 Trigonometry -- Simple Identities . . . . . . . . . . . . . . . . . . . . . . . . 425

                                               iii
CONTENTS      CONTENTS

B.8 Trigonometry -- Add and Subtract Angles . . . . . . . . . . . . . . . . . . . 426
B.9 Inverse Trigonometric Functions . . . . . . . . . . . . . . . . . . . . . . . . . 426
B.10 Areas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 427
B.11 Volumes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 428
B.12 Powers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 428
B.13 Logarithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 429
B.14 Highschool Material You Should be Able to Derive . . . . . . . . . . . . . . . 430
B.15 Cartesian Coordinates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 431
B.16 Roots of Polynomials . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 432

          iv
Chapter 1

  GEOMETRY IN THREE DIMENSIONS

     Before we get started doing calculus in two and three dimensions we need to brush up
     on some basic geometry that we will use a lot. We are already familiar with the Cartesian
     plane1, but we'll start from the beginning.

1.1 Points

     Each point in two dimensions may be labeled by two coordinates2 (x, y) which specify the
     position of the point in some units with respect to some axes as in the figure below.

                                                  y
                                                                        (x, y)
                                                                        y

x  x

The set of all points in two dimensions is denoted3 R2. Observe that

  · the distance from the point (x, y) to the x-axis is |y|

1 Rene´ Descartes (1596-1650) was a French scientist and philosopher, who lived in the Dutch Republic
      for roughly twenty years after serving in the (mercenary) Dutch States Army. He is viewed as the father
      of analytic geometry, which uses numbers to study geometry.

2 This is why the xy-plane is called "two dimensional" -- the name of each point consists of two real
      numbers.

3 Not surprisingly, the 2 in R2 signifies that each point is labelled by two numbers and the R in R2
      signifies that the numbers in question are real numbers. There are more advanced applications (for
      example in signal analysis and in quantum mechanics) where complex numbers are used. The space of
     all pairs (z1, z2), with z1 and z2 complex numbers is denoted C2.

                                                          1
GEOMETRY                                                                                1.1 POINTS

  · the distance from the point (x, y) to the y-axis is |x| 

   · the distance from the point (x, y) to the origin (0, 0) is x2 + y2
    Similarly, each point in three dimensions may be labeled by three coordinates (x, y, z),
as in the two figures below.

                z                                              z
                          (x, y, z)
                                                                         (x, y, z)
                                   z
                                                                         z
                xy                                                                y

                y                                                           x
                                                                 y

             x                           x

The set of all points in three dimensions is denoted R3. The plane that contains, for exam-
ple, the x- and y-axes is called the xy-plane.

   · The xy-plane is the set of all points (x, y, z) that satisfy z = 0.
   · The xz-plane is the set of all points (x, y, z) that satisfy y = 0.
   · The yz-plane is the set of all points (x, y, z) that satisfy x = 0.

More generally,

   · The set of all points (x, y, z) that obey z = c is a plane that is parallel to the xy-plane

    and is a distance |c| from it. If c ¡ 0, the plane z = c is above the xy-plane. If

       c 0, the plane z = c is below the xy-plane. We say that the plane z = c is a signed
       distance c from the xy-plane.
   · The set of all points (x, y, z) that obey y = b is a plane that is parallel to the xz-plane
       and is a signed distance b from it.
   · The set of all points (x, y, z) that obey x = a is a plane that is parallel to the yz-plane
       and is a signed distance a from it.

             z                           z                        z
                   z"c                                   y"b                         y
                                                            y
                                y

          x                           x                        x  x"a

Observe that our 2d distances extend quite easily to 3d.
                                                          2
GEOMETRY                   1.2 FUNCTIONS OF TWO VARIABLES

  · the distance from the point (x, y, z) to the xy-plane is |z|
  · the distance from the point (x, y, z) to the xz-plane is |y|
  · the distance from the point (x, y, z) to the yz-plane is |x| 

   · the distance from the point (x, y, z) to the origin (0, 0, 0) is x2 + y2 + z2
To see that the distance from the point (x, y, z) to the origin (0, 0, 0) is indeed x2 + y2 + z2,

   · apply Pythagoras to the right-angled triangle with vert ices (0, 0, 0), (x, 0, 0) and
       (x, y, 0) to see that the distance from (0, 0, 0) to (x, y, 0) is x2 + y2 and then

   · apply Pythagoras to the right-angled triangle with vertices(0, 0, 0), (x, y, 0) and
       (x, y, z) to see that the distance from (0, 0, 0) to (x, y, z) is x2 + y2 2 + z2 =
       x2 + y2 + z2.

                        z  px, y, zq
                           z
                    x
          px, 0, 0q y               y
                           px, y, 0q
             x

More generally, the distance from the point (x, y, z) to the point (xI, yI, zI) is

                                                                   

                          (x ¡ xI)2 + (y ¡ yI)2 + (z ¡ zI)2

Notice that this gives us the equation for a sphere quite directly. All the points on a sphere
are equidistant from the centre of the sphere. So, for example, the equation of the sphere
centered on (1, 2, 3) with radius 4, that is, the set of all points (x, y, z) whose distance from
(1, 2, 3) is 4, is

                        (x ¡ 1)2 + (y ¡ 2)2 + (z ¡ 3)2 = 16

    If you're having a hard time picturing the three-dimensional axes, Appendix section A.1
will lead you through folding a model out of a piece of paper.

1.2 Functions of Two Variables

     First, a quick review of dependent and independent variables. Independent variables are
     the variables we think of as changing somehow on their own; the dependent variables are
     the variables whose change we think of as being caused by the independent variables.
     For example, if you want to describe the relationship between the age of a cup of cottage
     cheese, and the number of bacteria in that cup, we generally choose age (time) to be the

                                                                3
GEOMETRY  1.2 FUNCTIONS OF TWO VARIABLES

independent variable and population of bacteria to be the dependent variable: we think
of age changing on its own, then that age causing the bacterial population to change.

    We could of course go the other way, and write time as a function of bacteria. This
could be useful if we were trying to figure out how old the cheese was by counting its
bacteria. So the difference between an independent variable and a dependent variable
has to do with how we want to interpret a function.

    In a single-variable function, by convention we write
                                                   y = f (x)

where y is the dependent variable and x is the independent variable. Similarly, in a two-
variable function, we generally write

                                                  z = f (x, y)
We think of the variables x and y as independent, and the variable z as dependent.

    If we're not too concerned with independent vs dependent variables; or if the rela-
tionship between the dependent and independent variables is difficult (or impossible) to
write explicitly in this form; then we can also define multivariable functions implicitly.
For example, in the equation

                            z3x + z2y + xyz ¡ 1 = 0

we can think of z as an implicitly defined function of x and y. You've already seen two
families of implicitly defined functions: planes and spheres.

 Example 1.2.1

Which points (1, y, 1) in R3 satisfy the equation

                            z3x + z2y + xyz ¡ 1 = 0 ?

Solution. If x = z = 1, then the equation becomes

                               1+y+y¡1 = 0

which has solution y = 0. So the only such point is (1, 0, 1).

                                                                Example 1.2.1

    It's common to see a multivariable equation like
                                            f (x, y) = sin(x + y)

or g(x, y) = ex2+y2
and think that the sine and exponential functions are different from the sine and exponen-
tial functions we've seen in two dimensions. They aren't! When x and y are real numbers,
then (x + y) and (x2 + y2) are real numbers as well. We're taking the sine of a real number
in the first equation, and e to a real power in the second equation, just as we always have.

    Functions of two (or more) variables are not so different from functions of one variable
in other ways as well.

                                                          4
GEOMETRY                             1.2 FUNCTIONS OF TWO VARIABLES

 Definition1.2.2 (Domain and Range).
Let f (x, y) be a function that takes pairs of real numbers as inputs, and gives a
real number as its output.
The set of points (x, y) that can be input to f is the domain of that function. The
set of outputs of f over its entire domain is the range of that function.

Example 1.2.3 (Domain and Range)

Find the domain and range of the function

                                                                                                        

                             f (x, y) = ex2+y2 ¡ 2

Solution. There are three operations in our function: exponentiation, subtraction, and
taking of a square root. We can subtract anything from anything; and we can raise e to
any power. So the only thing that could "break" our function is if we tried to take the
square root of a negative number. This tells us that, in order for f (x, y) to be defined, we
need

                                  ex2+y2 ¡ 2 ¥ 0

           ùñ                      ex2+y2 ¥ 2
          ùñ                      x2 + y2 ¥ ln 2

    One way of describing the domain of this function is to call it "all points (x, y) with

x2 + y2 ¥ ln 2." A more standard way is to describe the shapecthis set makes in R2: all
points on or outside the circle centred at the origin with radius ln 2  0.83.

                                  y

          cln 2

                                                                                                          x

    To help you visualize what we mean, take a point in the shaded area above. For exam-
ple, (1, .5). If we plug that into our function, it causes no problems:

                f (1, .5) = e12+.52 ¡ 1 = e1.25 ¡ 2  c1.49  1.22

                                                          5
GEOMETRY                                                   1.2 FUNCTIONS OF TWO VARIABLES

On the other hand, take a point in the white area. For example, (.5, .5). If we try to plug
this into our function, we end up with

             f (.5, .75) = e.52+.52 ¡ 2 = e0.5 ¡ 2  c1.65 ¡ 2  c¡0.35

which is not a real number.
                                                        y

          cln 2                                            (1, .5)

                                                           (.5, .5)
                                                                             x

    Now, let's think about range. By choosing larger and larger values of x and y, we can
make x2 + y2 into larger and larger numbers. So within our restricted domain, the range

of x2 + y2 is [ln2, V); so the range of ex2+y2 is eln 2, V = [2, V); so the range of ex2+y2 ¡ 2
is [0, V); so the range of f (x, y) is [0, V).

    Again, note that the domain of f consists of ordered pairs of real numbers, while its
range consists of real numbers.

                                                                                                Example 1.2.3

 Example 1.2.4
Find the domain and range of the function

                                                                   x

                              f (x, y) = sin c

                                                                    y

Solution. Let's start with domain. We can take the sine of any number we like, so that
part of the function doesn't limit the domain. The things limiting the domain are that we
cannot take the square root of a negative number, and we can't divide by zero.

  · Because we can't take the square root of a negative number, we must have y ¥ 0.
  · Because we can't divide by 0, we must have cy $ 0, i.e. y $ 0.
Combining these restrictions, we can only have values of y in the interval (0, V); x can be

any real number. So, our domain is the upper half of the xy plane, excluding the x-axis:
                                                          6
GEOMETRY                             1.2 FUNCTIONS OF TWO VARIABLES
                        y

                                               x

  In general, the range of sin x is [¡1, 1]. So, we certainly can't get a larger range than

this. We should check that our range is no smaller. When y = 1, our function becomes
f (x, 1) = sin(x/1) = sin x. Since x can be any real number, indeed the range of our

function is [¡1, 1].

                                                                                                Example 1.2.4

Example 1.2.5

Find the domain and range of the function
                                        f (x, y) = ln(arctan(x + y))

Solution. First, let's think about the arctangent and logarithm function in the context of
single-variable functions. The domain of arctangent is all real numbers, and its range is
¡,     .  The domain of the natural logarithm is all positive numbers, and its range is all
   22
real numbers.

                  z                                                   z

               
               2

                     t                                                          t

               z = arctan t                                           z = ln t
                                                7
GEOMETRY                                      1.2 FUNCTIONS OF TWO VARIABLES

    Since only positive numbers may be input into the natural logarithm, we require arctan(x +

y) ¡ 0. That requires (x + y) ¡ 0. So, our domain is the collection of all points (x, y) such
that x + y ¡ 0; put another way, all points above the line y = ¡x.

                                                         y

                                                          x

If our domain is points (x, y) such that x + y ¡ 0, then the range of the function (x +
y) is (0, V); so the numbers being plugged into the arctangent function are (0, V). So,
the numbers coming out of the arctangent function are  0,       .  Then the numbers from
0, 
                                                           2
    2  are being input into the natural logarithm function, leading to a range of the entire
function of  ¡V, ln        .
                     2

                        z                                          z

                     
                     2

                                           t              ln                       t

                                                                2

                                                                             
                                                                             2

       If 0  t, then 0        arctan t        If 0     t        ,  then  ¡V  ln t  ln 
                                        2                    2
                                                                                         2

                                                                                                Example 1.2.5
    We may sometimes restrict the domain of a function more than is mathematically nec-
essary in order for it to make sense in a model. For example, we may have a function
that only makes sense in our model when it gives positive values. In this case, we might

                                                          8
GEOMETRY     1.3 SKETCHING SURFACES IN 3D

restrict the domain to a model domain, the set of inputs for which the function is not only
defined, but sensible in the context of our model.

 Example 1.2.6

A large pharmaceutical company determines its research budget for a new vaccine accord-
ing to the formula

                                              R(x, y) = ln(xy)

where x is the size of the customer base they expect to have and y is the revenue they
expect per dose.

    Then for each variable x, y, and R, negative values don't make sense in the model. So

although we could compute R(¡1, ¡1) = 1, and we could compute R(0.5, 0.5)  ¡1.39,

they wouldn't be sensible in the context of our model.

· Since x and y need to be nonnegative, we will only consider points (x, y) in the first

  quadrant of the Cartesian plane: x ¥ 0 and y ¥ 0.

·  Since R needs to be nonnegative, we will further restrict xy  ¥ 1.  That is, y  ¥  1.

                                                                                      x

The two restrictions above give us the model domain shaded below.

          y

          1

                                    x
                    1

         Depending on the specifics of how the function is being used, the model domain may
     be restricted even further. For example, perhaps the firm has a maximum budget for any
     given project; perhaps the amount they can charge is limited by law; etc.

                                                                                                      Example 1.2.6

1.3 Sketching Surfaces in 3d

     In practice students taking multivariable calculus regularly have great difficulty visual-
     ising surfaces in three dimensions, despite the fact that we all live in three dimensions.
     We'll now develop some technique to help us sketch surfaces in three dimensions4.

      4 Of course you could instead use some fancy graphing software, but part of the point is to build intuition.
            Not to mention that you can't use fancy graphing software on your exam.

                                                                9
GEOMETRY                                                                  1.3 SKETCHING SURFACES IN 3D

    We all have a fair bit of experience drawing curves in two dimensions. Typically the
intersection of a surface (in three dimensions) with a plane is a curve lying in the (two
dimensional) plane. Such an intersection is usually called a cross-section. In the special
case that the plane is one of the coordinate planes, or parallel to one of the coordinate
planes, the intersection is sometimes called a trace.

      Definition1.3.1.
     The trace of a surface is the intersection of that surface with a plane that is parallel
     to one of the coordinate planes.

    So, one trace (the intersection with the xy plane) is found by setting z equal to a con-
stant; another trace (the intersection with the yz plane) is found by setting x equal to a
constant; and the final trace (the intersection with the xz plane) is found by setting y equal
to a constant.

    One can often get a pretty good idea of what a surface looks like by sketching a bunch
of cross-sections. Here are some examples.

 Example 1.3.2 4x2 + y2 ¡ z2 = 1
Sketch the surface that satisfies 4x2 + y2 ¡ z2 = 1.

Solution. We'll start by fixing any number z0 and sketching the part of the surface that
lies in the horizontal plane z = z0.

                                                   z

                                                                z " z0

                                                                       y

                                       x

The intersection of our surface with that horizontal plane is a horizontal cross-section.
Any point (x, y, z) lying on that horizontal cross-section satsifies both

                                       z = z0 and 4x2 + y2 ¡ z2 = 1

                                 ðñ z = z0         and   4x2  +  y2    =  1  +  z2

                                                                                 0

Think  of  z0  as  a  constant.  Then  4x2  +  y2  =  1  +  z2  is  a  curve    in  the  xy-plane.  As  1  +  z2  is  a

                                                             0                                                 0
constant, the curve is an ellipse. To determine its semi-axes5, we observe that when y = 0,

5 The semi-axes of an ellipse are the line segments from the centre of the ellipse to the farthest point on
      the curve and to the nearest point on the curve. For a circle the lengths of both of these line segments
      are just the radius.

                                                      10
GEOMETRY                                                                      1.3 SKETCHING SURFACES IN 3D

                  ¨1          z2                                              ¨              z2.
                     2
we  have  x  =          1  +   0  and   when      x  =    0,  we  have  y  =          1  +    0   So   the  curve  is  just  an

                              1            z2                                 z2.
                              2
ellipse  with  x  semi-axis       1     +   0  and     y  semi-axis     1  +   0      It's   easy  to  sketch.

                                  (0 ,     1   +  z2   )      y

                                                    0

                                                                           x

                                                                  ( 21     1  +  z2   ,  0)

                                                                                   0

Remember that this ellipse is the part of our surface that lies in the plane z = z0. Imagine
that the sketch of the ellipse is on a single sheet of paper. Lift the sheet of paper up, move
it around so that the x- and y-axes point in the directions of the three dimensional x- and
y-axes and place the sheet of paper into the three dimensional sketch at height z0. This
gives a single horizontal ellipse in 3d, as in the figure below.

                                                           z
                                                                     z " z0

                                                                            y
                                                     x
We can build up the full surface by stacking many of these horizontal ellipses -- one for
each possible height z0. So we now draw a few of them as in the figure below. To reduce
the amount of clutter in the sketch, we have only drawn the first octant (i.e. the part of

three dimensions that has x ¥ 0, y ¥ 0 and z ¥ 0).

                                                z
                                                                    z=3

                                                                    z=2
                                                                    z=1

                                                                            y

                                         x

                                                          11
GEOMETRY                                                              1.3 SKETCHING SURFACES IN 3D

  Here is why it is OK, in this case, to just sketch the first octant. Replacing x by ¡x in
the equation 4x2 + y2 ¡ z2 = 1 does not change the equation. That means that a point
(x, y, z) is on the surface if and only if the point (¡x, y, z) is on the surface. So the surface
is invariant under reflection in the yz-plane. Similarly, the equation 4x2 + y2 ¡ z2 = 1 does
not change when y is replaced by ¡y or z is replaced by ¡z. Our surface is also invariant

under reflection in the xz- and xy-planes. Once we have the part in the first octant, the
remaining octants can be gotten simply by reflecting about the coordinate planes.

    We can get a more visually meaningful sketch by adding in some vertical cross-sections.
The x = 0 and y = 0 cross-sections (also called traces -- they are the parts of our surface
that are in the yz- and xz-planes, respectively) are

                 x = 0, y2 ¡ z2 = 1 and y = 0, 4x2 ¡ z2 = 1

These equations describe hyperbolae6. If you don't remember how to sketch them, don't
worry. We'll do it now. We'll first sketch them in 2d. Since

y2 = 1 + z2 ùñ |y| ¥ 1 and y = ¨1 when z = 0 and for large z, y  ¨z

4x2 = 1 + z2     ùñ  |x|  ¥  1  and  x  =              ¨1    when  z  =  0  and  for  large  z,  x    ¨  1  z
                             2                            2                                              2

the sketchs are

                                z z=y                                    z

                 y2 - z2 = 1                                                4x2 - z2 = 1
                                                    y                              x

Now we'll incorporate them into the 3d sketch. Once again imagine that each is a single
sheet of paper. Pick each up and move it into the 3d sketch, carefully matching up the
axes. The red (blue) parts of the hyperbolas above become the red (blue) parts of the 3d
sketch below (assuming of course that you are looking at this on a colour screen).

                                                z
                                                                    z=3

                                                                    z=2
                                                                    z=1

                                                                            y

                                         x

6 It's not just a figure of speech!

                                                          12
GEOMETRY                                                               1.3 SKETCHING SURFACES IN 3D

Now that we have a pretty good idea of what the surface looks like we can clean up and
simplify the sketch. Here are a couple of possibilities.

                          z

                                                         y

                      x

This type of surface is called a hyperboloid of one sheet.
    There are also hyperboloids of two sheets. For example, replacing the +1 on the right

hand side of x2 + y2 ¡ z2 = 1 gives x2 + y2 ¡ z2 = ¡1, which is a hyperboloid of two

sheets. We'll sketch it quickly in the next example.
                                                                                                Example 1.3.2

 Example 1.3.3 4x2 + y2 ¡ z2 = ¡1
Sketch the surface that satisfies 4x2 + y2 ¡ z2 = ¡1.

Solution. As in the last example, we'll start by fixing any number z0 and sketching the
part of the surface that lies in the horizontal plane z = z0. The intersection of our surface
with that horizontal plane is

                                   z = z0    and   4x2  +   y2  =  z2  ¡  1

                                                                    0

Think of z0 as a constant.

· If |z0|    1,  then  z2    ¡  1  0  and  there   are  no  solutions     to  x2  +  y2  =   z2  ¡  1.

                        0                                                                     0

· If |z0| = 1 there is exactly one solution, namely x = y = 0.

       |z0|  ¡            4x2 + y2       z2  ¡                                                   1    z2  ¡
                                                                                                 2
·  If           1  then               =   0     1  is  an   ellipse  with     x   semi-axis            0     1  and  y

                   z2  ¡                                               |z0|                                         |z0|

   semi-axis        0     1.  These   semi-axes    are  small   when          is  close  to  1   and    grow    as

   increases.

The first octant parts of a few of these horizontal cross-sections are drawn in the figure
below.

                                                   13
GEOMETRY                             1.3 SKETCHING SURFACES IN 3D

          z
                              z"3

                                                  z"2

                                               z " 1.02
                                                          y

                                         x

Next we add in the x = 0 and y = 0 cross-sections (i.e. the parts of our surface that are in
the yz- and xz-planes, respectively)

                        x = 0, z2 = 1 + y2 and y = 0, z2 = 1 + 4x2

                                                z
                                                                    z"3

                                                  z"2

                                               z " 1.05
                                                          y

                                         x
Now that we have a pretty good idea of what the surface looks like we clean up and
simplify the sketch.

                              z

                                            y
          x

                                           14
GEOMETRY  1.3 SKETCHING SURFACES IN 3D

This type of surface is called a hyperboloid of two sheets.

                                                             Example 1.3.3

 Example 1.3.4 (yz = 1)
Sketch the surface yz = 1.
Solution. This surface has a special property that makes it relatively easy to sketch. There
are no x's in the equation yz = 1. That means that if some y0 and z0 obey y0z0 = 1, then

the point (x, y0, z0) lies on the surface yz = 1 for all values of x. As x runs from ¡V to V,

the point (x, y0, z0) sweeps out a straight line parallel to the x-axis. So the surface yz = 1
is a union of lines parallel to the x-axis. It is invariant under translations parallel to the
x-axis. To sketch yz = 1, we just need to sketch its intersection with the yz-plane and then
translate the resulting curve parallel to the x-axis to sweep out the surface.

    We'll start with a sketch of the hyperbola yz = 1 in two dimensions.

                                                         z
                                                             yz = 1

                                                                       y

Next we'll move this 2d sketch into the yz-plane, i.e. the plane x = 0, in 3d, except that
we'll only draw in the part in the first octant.

                                                     z

                                                                         y
                                            x
The we'll draw in x = x0 cross-sections for a couple of more values of x0

                                                          15
GEOMETRY                                                             1.3 SKETCHING SURFACES IN 3D
                                                 z

                                                                   y

and clean up the sketch a bit          x
                                              z

                                                                y

                               x
                                                                                   Example 1.3.4

Example 1.3.5 (xyz = 4)

Sketch the surface xyz = 4.

Solution. We'll sketch this surface using much the same procedure as we used in Examples
1.3.2 and 1.3.3. We'll only sketch the part of the surface in the first octant. The remaining

parts (in the octants with x, y 0, z ¥ 0, with x, z 0, y ¥ 0 and with y, z 0, x ¥ 0) are

just reflections of the first octant part.
    As usual, we start by fixing any number z0 and sketching the part of the surface that

lies in the horizontal plane z = z0. The intersection of our surface with that horizontal
plane is the hyperbola

                                       z = z0 and xy = 4z0

Note that x Ñ V as y Ñ 0 and that y Ñ V as x Ñ 0. So the hyperbola has both the x-axis
and the y-axis as asymptotes, when drawn in the xy-plane. The first octant parts of a few
of  these  horizontal  cross-sections  (namely,  z0     4,  z0        2  and  z0     1)  are  drawn  in  the
                                                     =          =                 =
                                                                                     2
figure below.

                                                 16
GEOMETRY                                                            1.3 SKETCHING SURFACES IN 3D

                      z                                         z"4
          x
                                                                z"2
                                                              z " 1{2

                                                                        y

Next we add some vertical cross-sections. We can't use x = 0 or y = 0 because any point
on xyz = 4 must have all of x, y, z nonzero. So we use

                               x = 4, yz = 1 and y = 4, xz = 1
instead. They are again hyperbolae.

                        z                                     y"4
          x"4                                                    y

           x

Finally, we clean up and simplify the sketch.
                                                          17
GEOMETRY                          1.3 SKETCHING SURFACES IN 3D
          z

                                                                                y

                                      x

                                                                                                Example 1.3.5

    Often the reason you are interested in a surface in 3d is that it is the graph z = f (x, y)
of a function of two variables f (x, y). Another good way to visualize the behaviour of a
function f (x, y) is to sketch what are called its level curves.

      Definition1.3.6.
     A level curve of f (x, y) is a curve whose equation is f (x, y) = C, for some con-
     stant C.

    A level curve is the set of points in the xy-plane where f takes the value C. Because
it is a curve in 2d, it is usually easier to sketch than the graph of f . Here are a couple of
examples.

 Example 1.3.7 f (x, y) = x2 + 4y2 ¡ 2x + 2
Sketch the level curves of f (x, y) = x2 + 4y2 ¡ 2x + 2.

Solution. Fix any real number C. Then, for the specified function f , the level curve
f (x, y) = C is the set of points (x, y) that obey

               x2 + 4y2 ¡ 2x + 2 = C ðñ x2 ¡ 2x + 1 + 4y2 + 1 = C
                                   ðñ (x ¡ 1)2 + 4y2 = C ¡ 1

Now (x ¡ 1)2 + 4y2 is the sum of two squares, and so is always at least zero. So if C ¡ 1 0,
i.e. if C 1, there is no curve f (x, y) = C. If C ¡ 1 = 0, i.e. if C = 1, then f (x, y) = C ¡ 1 =
0 if and only if both (x ¡ 1)2 = 0 and 4y2 = 0 and so the level curve consists of the single
point (1, 0). If C ¡ 1, then f (x, y) = C become (x ¡ 1)2 + 4y2 = C ¡ 1 ¡ 0 which describes

an ellipse centred on (1, 0). It intersects the x-axis when y = 0 and

            (x ¡ 1)2 = C ¡ 1 ðñ x ¡ 1 = ¨cC ¡ 1 ðñ x = 1 ¨ cC ¡ 1

                                                          18
GEOMETRY                     1.3 SKETCHING SURFACES IN 3D

and it intersects the line x = 1 (i.e. the vertical line through the centre) when

                          c  1c
                    24y = C ¡ 1 ðñ 2y = ¨ C ¡ 1 ðñ y = ¨2 C ¡ 1

So, when C ¡c1, f (x, y) = C is the ellipse centred on (1, 0) with x semi-axis cC ¡ 1 and
y  semi-axis  1  C ¡ 1. Here is a sketch of some representative level curves of f (x, y) =
x2 + 4y2 ¡ 2x + 2.2

                       y

                       1

                                                                               f "10 f "17
                                     f "1 f "2 f "5

                          1                                                                 x

                                                            x"1

It is often easier to develop an understanding of the behaviour of a function f (x, y) by
looking at a sketch of its level curves, than it is by looking at a sketch of its graph. On
the other hand, you can also use a sketch of the level curves of f (x, y) as the first step in
building a sketch of the graph z = f (x, y). The next step would be to redraw, for each C,
the level curve f (x, y) = C, in the plane z = C, as we did in Example 1.3.2.

                                                                                                Example 1.3.7
    If you've ever used a topographic map, you've seen examples of level curves. Mod-
elling the z-axis as a measure of elevation, with z = 0 as sea level, the contours shown on
topographic maps show the level curves associated with different elevations. The exam-
ple7 below shows the area around Gambier, Anvil, and Keats Islands, north of UBC. The
lines show level curves for z = 0 metres, z = 100 metres, z = 200 metres, etc.

7 generated by Natural Resources Canada's Atlas of Canada - Toporama, included under an open gov-
      ernment license

                                                          19
GEOMETRY                                               1.3 SKETCHING SURFACES IN 3D

Example 1.3.8 (ex+y+z = 1)

The function f (x, y) is given implicitly by the equation ex+y+z = 1. Sketch the level curves

of f .

Solution. This one is not as nasty as it appears. That " f (x, y) is given implicitly by the
equation ex+y+z = 1" means that, for each x, y, the solution z of ex+y+z = 1 is f (x, y). So,
for the specified function f and any fixed real number C, the level curve f (x, y) = C is the
set of points (x, y) that obey

        ex+y+C = 1 ðñ x + y + C = 0      (by taking the ln of both sides)
                  ðñ x + y = ¡C

This is of course a straight line. It intersects the x-axis when y = 0 and x = ¡C and it
intersects the y-axis when x = 0 and y = ¡C. Here is a sketch of some level curves.

                                  y

                                  1                    f =-3
                                              1
                                                       x

                                                       f =-2

                                                       f =-1

                            f =3     f =2        f =1  f =0

                                     20
GEOMETRY                       1.3 SKETCHING SURFACES IN 3D
                                                   Example 1.3.8

    We have just seen that sketching the level curves of a function f (x, y) can help us
understand the behaviour of f . We can generalise this to functions F(x, y, z) of three vari-
ables. A level surface of F(x, y, z) is a surface whose equation is of the form F(x, y, z) = C
for some constant C. It is the set of points (x, y, z) at which F takes the value C.

 Example 1.3.9 F(x, y, z) = x2 + y2 + z2

Let F(xc, y, z) = x2 + y2 + z2. If C ¡ 0, then the level surface F(x, y, z) = C is the sphere of

radius C centred on the origin. Here is a sketch of the parts of the level surfaces F = 1
(radius 1), F = 4 (radius 2) and F = 9 (radius 3) that are in the first octant.

                                          z

                         F "4  F "9
                                     y

                   F "1
          x

                                        Example 1.3.9

 Example 1.3.10 F(x, y, z) = x2 + z2

Let F(x, y, z) = x2 + z2 and C ¡ 0. Consider the level surface x2 + z2 = C. The variable
y does not appear in this equation. So for any fixed y0, tche intersection of the our surface

x2 + z2 = C with the plane y = y0 is the circle of radius C centred on x = z = 0. Here is
a sketch of the first quadrant part of one such circle.

                                                          21
GEOMETRY                                1.3 SKETCHING SURFACES IN 3D
             z y " y0

                     F "C

             y

          x

The full surface is the hcorizontal stack of all of those circles with y0 running over R. It is

the cylinder of radius C centred on the y-axis. Here is a sketch of the parts of the level
surfaces F = 1 (radius 1), F = 4 (radius 2) and F = 9 (radius 3) that are in the first octant.

                                                z
                                                         F "9
                                                         F "4
                                                         F "1
                                                                            y

          x
                                                                 Example 1.3.10

 Example 1.3.11 (F(x, y, z) = ex+y+z)

Let F(x, y, z) = ex+y+z and C ¡ 0. Consider the level surface ex+y+z = C, or equivalently,

x + y + z = ln C. It is the plane that contains the intercepts (ln C, 0, 0), (0, ln C, 0) and
(0, 0, ln C). Here is a sketch of the parts of the level surfaces

   · F = e (intercepts (1, 0, 0), (0, 1, 0), (0, 0, 1)),
   · F = e2 (intercepts (2, 0, 0), (0, 2, 0), (0, 0, 2)) and
   · F = e3 (intercepts (3, 0, 0), (0, 3, 0), (0, 0, 3))
that are in the first octant.

                                                          22
GEOMETRY                                    1.3 SKETCHING SURFACES IN 3D
                                         z

                                                                      F " e3
                                                             F " e2
                                                   F "e

                                                                                       y

                              x
                                                                                                Example 1.3.11

    There some classes of relatively simple, but commonly occurring, surfaces that are
given their own names. One such class is cylindrical surfaces. You are probably used to
thinking of a cylinder as being something that looks like x2 + y2 = 1.

                                                           x2 ` y2 " 1

In Mathematics the word "cylinder" is given a more general meaning.
      Definition1.3.12 (Cylinder).
     A cylinder is a surface that consists of all points that are on all lines that are
          · parallel to a given line and
          · pass through a given fixed plane curve (in a plane not parallel to the given
             line).

 Example 1.3.13
Here are sketches of three cylinders. The familiar cylinder on the left below

                                                          23
GEOMETRY                  1.3 SKETCHING SURFACES IN 3D

          x2 ` y2 " 1     x2 ` py ´ zq2 " 1

is called a right circular cylinder, because the given fixed plane curve (x2 + y2 = 1, z = 0)
is a circle and the given line (the z-axis) is perpendicular (i.e. at right angles) to the fixed
plane curve.

    The cylinder on the left above can be thought of as a vertical stack of circles. The
cylinder on the right above can also be thought of as a stack of circles, but the centre of the
circle at height z has been shifted rightward to (0, z, z). For that cylinder, the given fixed
plane curve is once again the circle x2 + y2 = 1, z = 0, but the given line is y = z, x = 0.

    We have already seen the third cylinder

                       z

                                                                                y

                                                   x yz " 1
                                                        x, y, z  0

       in Example 1.3.4. It is called a hyperbolic cylinder. In this example, the given fixed plane
      curve is the hyperbola yz = 1, x = 0 and the given line is the x-axis.

                                                                                                       Example 1.3.13

1.3.1  Quadric Surfaces

       Another named class of relatively simple, but commonly occurring, surfaces is the quadric
       surfaces.

                                                                 24
GEOMETRY  1.3 SKETCHING SURFACES IN 3D

 Definition1.3.14 (Quadrics).
A quadric surface is surface that consists of all points that obey Q(x, y, z) = 0,
with Q being a polynomial of degree two8.

    For Q(x, y, z) to be a polynomial of degree two, it must be of the form
            Q(x, y, z) = Ax2 + By2 + Cz2 + Dxy + Eyz + Fxz + Gx + Hy + Iz + J

for some constants A, B, ¤ ¤ ¤ , J. Each constant z cross section of a quadric surface has an

equation of the form
                            Ax2 + Dxy + By2 + gx + hy + j = 0, z = z0

If A = B = D = 0 but g and h are not both zero, this is a straight line. If A, B, and D
are not all zero, then by rotating and translating our coordinate system the equation of the
cross section can be brought into one of the forms9

  · x2 + y2 =  with ,  ¡ 0, which, if  ¡ 0, is an ellipse (or a circle),
  · x2 ¡ y2 =  with ,  ¡ 0, which, if  $ 0, is a hyperbola, and if  = 0 is two lines,
  · x2 = y, which, if  $ 0 is a parabola, and if  = 0 is a straight line.

There are similar statements for the constant y cross sections and the constant z cross
sections. Hence quadratic surfaces are built by stacking these three types of curves.

    We have already seen a number of quadric surfaces in the last couple of sections.

  · We saw the quadric surface 4x2 + y2 ¡ z2 = 1 in Example 1.3.2.

       Its constant z cross sections are ellipses and its x = 0 and y = 0 cross sections are
       hyperbolae. It is called a hyperboloid of one sheet.
   · We saw the quadric surface x2 + y2 = 1 in Example 1.3.13.

8 Technically, we should also require that the polynomial can't be factored into the product of two poly-
      nomials of degree one.

9 This statement can be justified using a linear algebra eigenvalue/eigenvector analysis. It is beyond
      what we can cover here, but is not too difficult for a standard linear algebra course.

                                                          25
GEOMETRY         1.3 SKETCHING SURFACES IN 3D

       Its constant z cross sections are circles and its x = 0 and y = 0 cross sections are
       straight lines. It is called a right circular cylinder.

  · the quadric surface x2 + (y ¡ z)2 = 1 in Example 1.3.13, and

   · We saw the quadric surface yz = 1 in Example 1.3.4.
    Appendix A.3 contains other quadric surfaces.
 Example 1.3.15 (Indifference curves)
Suppose a function U(x, y) gives the happiness10 (or utility) a consumer gains when they
purchase x units of Good X and y units of Good Y. The level curves of the surface
z = U(x, y) are called indifference curves, because every point along that curve results
in the same benefit to the consumer.

                     c

    Suppose U(x, y) = x y. The purchasing 2 units of Good X and one unit of Good Y
produces the same benefit as purchasing 1 unit of Good X and 4 units of Good Y, because
both these combinations are on the level curve U(x, y) = 2.

                                         y

                                      4

             1 xcy = 2

                                                      x
                       12

Let's make a small contour map of our surface U(x, y) = xcy, plotting several indif-
          c  c2
ference curves. (Note x y = c is equivalent to y = x2 in our model domain.)

10 An amusing thought experiment is to propose units for measuring happiness. "The one-point increase
      in GDP was associated with an average increase of 3.7 wrinkly puppy faces of happiness nation-wide."

                                                          26
GEOMETRY                                                    1.3 SKETCHING SURFACES IN 3D
                                        y
                                           U=1
                                              U=2
                                                 U=3
                                                    U=4
                                                       U=5

                                                                              x

    Not surprisingly, if we move roughly in the direction of the (1, 1) (that is, increasing
both x and y), our happiness U(x, y) goes up.

    Note that none of the indifference curves touch either of the x or y axes. It is clear
enough from the formula that U(0, y) = U(x, 0) = 0. This is a common feature of utility
functions: that to maximize utility, a consumer will have at least a little of both products,
rather than consuming only one type.

                                                                                                Example 1.3.15

    Chapter 1 (excluding Section 1.2) was adapted from Chapter 1 of CLP-3 Multivariable
Calculus by Feldman, Rechnitzer, and Yeager under a Creative Commons Attribution-
NonCommercial-ShareAlike 4.0 International license.

                                           27
Chapter 2

               PARTIAL DERIVATIVES

In this chapter we are going to generalize the definition of "derivative" to functions of
more than one variable, and then we are going to use those derivatives. We can speed
things up considerably by recycling what we have already learned in the single-variable
case.

2.1 Partial Derivatives

First, recall how we defined the derivative, f I(a), of a function of one variable, f (x). We
imagined that we were walking along the x-axis, in the positive direction, measuring, for
example, the temperature along the way. We denoted by f (x) the temperature at x. The
instantaneous rate of change of temperature that we observed as we passed through x = a
was d f (a) = lim f (a + h) ¡ f (a) = lim f (x) ¡ f (a)
               dx       hÑ0     h           xÑa x ¡ a

    Next suppose that we are walking in the xy-plane and that the temperature at (x, y) is
f (x, y). We can pass through the point (x, y) = (a, b) moving in many different directions,
and we cannot expect the measured rate of change of temperature if we walk parallel to
the x-axis, in the direction of increasing x, to be the same as the measured rate of change
of temperature if we walk parallel to the y-axis in the direction of increasing y. We'll start
by considering just those two directions. other directions (like walking parallel to the line
y = x) later.

    Suppose that we are passing through the point (x, y) = (a, b) and that we are walking
parallel to the x-axis (in the positive direction). Then our y-coordinate will be constant, al-
ways taking the value y = b. So we can think of the measured temperature as the function
of one variable B(x) = f (x, b) and we will observe the rate of change of temperature

           dB (a) = lim B(a + h) ¡ B(a) = lim f (a + h, b) ¡ f (a, b)
           dx      hÑ0       h         hÑ0  h

This is called the "partial derivative f with respect to x at (a, b)" and is denoted  ff
Here                                                                                  fx y(a, b).

                                   28
PARTIAL DERIVATIVES                                                        2.1 PARTIAL DERIVATIVES

    ¥ the symbol f, which is read "partial", indicates that we are dealing with a function

      of more than one variable and

    ¥ the subscript y on y indicates that y is being held fixed, i.e. being treated as a

      constant, and

               ff

    ¥ the x in fx indicates that we are differentiating with respect to x.

      ff

    ¥ fx is read " partial dee f dee x".

Do  not  write  d   when  f   is  appropriate.  (There  exist  situations  when  d   f  and  f   f  are  both
                dx        fx                                                     dx          fx
defined and have different meanings.)

    If, instead, we are passing through the point (x, y) = (a, b) and are walking parallel to
the y-axis (in the positive direction), then our x-coordinate will be constant, always taking
the value x = a. So we can think of the measured temperature as the function of one
variable A(y) = f (a, y) and we will observe the rate of change of temperature

                    dA (b) = lim A(b + h) ¡ A(b) = lim f (a, b + h) ¡ f (a, b)
                    dy        hÑ0       h               hÑ0                h

                                                                                        ff
This is called the "partial derivative f with respect to y at (a, b)" and is denoted fy (a, b).

                                                                                                                                                   x
                                                                                          df

    Just as was the case for the ordinary derivative dx (x), it is common to treat the partial
derivatives of f (x, y) as functions of (x, y) simply by evaluating the partial derivtives at
(x, y) rather than at (a, b).

    Definition2.1.1 (Partial Derivatives).

    The x- and y-partial derivatives of the function f (x, y) are

                                  f f (x, y) = lim f (x + h, y) ¡ f (x, y)
                                  fx y          hÑ0            h

                                  f f (x, y) = lim f (x, y + h) ¡ f (x, y)
                                  fy x          hÑ0            h

    respectively. The partial derivatives of functions of more than two variables are
    defined analogously.

    Partial derivatives are used a lot. And there many notations for them.
                                                         29
PARTIAL DERIVATIVES                           2.1 PARTIAL DERIVATIVES

Notation2.1.2.

                          ff
The partial derivative fx of a function f (x, y) is also denoted

                                                y

                       f f fx Dx f D1 f
                       fx

The subscript 1 on D1 f indicates that f is being differentiated with respect to its

                                          ff
first variable. The partial derivative fx (a, b) is also denoted

                                                                         y

                               f f §§
                                     §

                               fx§

                                    (a,b)

                                             ff
with the subscript (a, b) indicating that fx is being evaluated at (x, y) = (a, b).
The abbreviated notation fx for fx is extremely commonly used. But it isffff

                                   y
dangerous to do so, when it is not clear from the context, that it is the variable y
that is being held fixed.

Remark 2.1.3 (The Geometric Interpretation of Partial Derivatives).  We'll now develop
a geometric interpretation of the partial derivative

                        f f (a, b) = lim f (a + h, b) ¡ f (a, b)
                        fx y   hÑ0         h

in terms of the shape of the graph z = f (x, y) of the function f (x, y). That graph appears
in the figure below. It looks like the part of a deformed sphere that is in the first octant.

                     ffy
The definition of fx (a, b) concerns only points on the graph that have y = b. In

other words, the curve of intersection of the surface z = f (x, y) with the plane y = b. That
is the red curve in the figure. The two blue vertical line segments in the figure have heights
                                                                          f (a+h,b)¡ f (a,b)
f (a, b) and f (a + h, b), which are the two numbers in the numerator of  h                   .

                                   30
PARTIAL DERIVATIVES                                              2.1 PARTIAL DERIVATIVES
                                                       z

               z " f px, yq                                   y"b
f pa ` h, bq ´ f pa, bq
                                                                              f pa, bq
                                                                             f pa ` h, bq

                                                                                   y

                                                                            pa, b, 0q
                                                                         h
                                                                      pa ` h, b, 0q

                                 x
A side view of the curve (looking from the left side of the y-axis) is sketched in the figure
below. Again, the two blue vertical line segments in the figure have heights f (a, b)

                      z

                                                              f pa ` h, bq ´ f pa, bq

                                                                   z " f px, bq, y " b

                                                              f pa, bq
                                                              f pa ` h, bq

pa, b, 0q                                             x
                                pa ` h, b, 0q

and f (a + h, b), which are the two numbers in the numerator of  f (a+h,b)¡ f (a,b)         . So the
                                                                                        h
numerator f (a + h, b) ¡ f (a, b) and denominator h are the rise and run, respectively, of
                                                             ff
the curve z = f (x, b) from x = a to x = a + h. Thus fx (a, b) is exactly the slope of (they

tangent to) the curve of intersection of the surface z = f (x, y) and the plane y = b at the point
                                   ff
a, b, f (a, b) . In the same way fy (a, b) is exactly the slope of (the tangent to) the curve ofx

intersection of the surface z = f (x, y) and the plane x = a at the point a, b, f (a, b) .

                                                          31
PARTIAL DERIVATIVES                                                         2.1 PARTIAL DERIVATIVES

 Evaluation of Partial Derivatives

From   the  above  discussion,        we  see  that  we  can  readily  compute  partial  derivatives  f   by
                                                                        d.                            fx
using  what   we  already       know  about      ordinary  derivatives      More  precisely,
                                                                        dx

               ff
· to evaluate fx (x, y), treat the y in f (x, y) as a constant and differentiate the resulting

   function of x with respect to x.

                ff
· To evaluate fy (x, y), treat the x in f (x, y) as a constant and differentiate the resulting

   function of y with respect to y.

                ff
· To evaluate fx (a, b), treat the y in f (x, y) as a constant and differentiate the resulting

   function of x with respect to x. Then evaluate the result at x = a, y = b.

                ff
· To evaluate fy (a, b), treat the x in f (x, y) as a constant and differentiate the resulting

   function of y with respect to y. Then evaluate the result at x = a, y = b.

Now for some examples.

Example 2.1.4

Let
                                          f (x, y) = x3 + y2 + 4xy2

Then,  since  f   treats    y  as  a  constant,
              fx

                               ff =   f f = f (x3) + f (y2) + f (4xy2)
                               fx     fx y fx                 fx        fx

                                               = 3x2 + 0 + 4y2 f (x)
                                                                  fx
                                               = 3x2 + 4y2

and,  since  f   treats  x  as  a  constant,
             fy

                               ff =   f f = f (x3) + f (y2) + f (4xy2)
                               fy     fy x fy                 fy        fy
                                               = 0 + 2y + 4x f (y2)
                                                              fy

                                               = 2y + 8xy

In particular, at (x, y) = (1, 0) these partial derivatives take the values

                          f f (1, 0) = 3(1)2 + 4(0)2 = 3
                          fx
                          f f (1, 0) = 2(0) + 8(1)(0) = 0
                          fy

                                                                                         Example 2.1.4

                                                         32
PARTIAL DERIVATIVES                                                      2.1 PARTIAL DERIVATIVES

Example 2.1.5

Let
                                          f (x, y) = y cos x + xexy

Then,  since  f   treats  y  as  a  constant,  f eyx  =  yeyx  and
              fx                               fx

                                    f f (x, y) = ¡y sin x + exy + xyexy
                                    fx
                                    f f (x, y) = cos x + x2exy
                                    fy

                                                                                                Example 2.1.5
Let's move up to a function of four variables. Things generalize in a quite straight forward
way.

 Example 2.1.6

Let                            f (x, y, z, t) = x sin(y + 2z) + t2e3y ln z
Then
                             f f (x, y, z, t) = sin(y + 2z)
                             fx
                             f f (x, y, z, t) = x cos(y + 2z) + 3t2e3y ln z
                             fy
                             f f (x, y, z, t) = 2x cos(y + 2z) + t2e3y/z
                             fz
                             f f (x, y, z, t) = 2te3y ln z
                             ft

                                                                                                Example 2.1.6
Now here is a more complicated example -- our function takes a special value at (0, 0).
To compute derivatives there we have to revert to the definition.

 Example 2.1.7

Set 5 cos x¡cos y

                                      x¡y if x $ y
                                    f (x, y) = 0               if x = y

                                                                             cos x¡cos y
If b $ a, then for all (x, y) sufficiently close to (a, b), f (x, y) = x¡y and we can
compute the partial derivatives of f at (a, b) using the familiar rules of differentiation.
However that is not the case for (a, b) = (0, 0). To evaluate fx(0, 0), we need to set y = 0
and find the derivative of
                                               5 cos x¡1 if x $ 0
                                    f (x, 0) = 0 x if x = 0

                                                      33
PARTIAL DERIVATIVES                                                                                   2.1 PARTIAL DERIVATIVES

with respect to x at x = 0. To do so, we basically have to apply the definition

fx(0, 0) = lim f (h, 0) ¡ f (0, 0)          h
                       hÑ0
                      cos h¡1 ¡ 0
                                                                           (Recall that h $ 0 in the limit.)
                 = lim h
                       hÑ0 h                                                           (By l'Ho^ pital's rule.)
                 = lim 2 cos h ¡ 1                                                      (By l'Ho^ pital again.)
                       hÑ0 h
                 = lim ¡ sin h
                       hÑ0 2h
                 = lim ¡ cos h
                       hÑ0 2
                 = ¡12

                                                                                                         Example 2.1.7

Example 2.1.8

Again set                                             5 cos x¡cos y             if x $ y
                                            f (x, y) = x 0 ¡y
                                                                                if x = y

We'll now compute fy(x, y) for all (x, y).

The case y $ x: When y $ x,

fy(x, y) = f cos x ¡ cos y
              fy x ¡ y
                             f                                                        f
           =  (  x  ¡  y  )  fy  (  cos  x  ¡  cos  y  )  ¡  (  cos  x  ¡  cos  y  )  fy  (  x  ¡  y  )  by the quotient rule

                                                  (x ¡ y)2
              (x ¡ y) sin y + cos x ¡ cos y
           =                     (x ¡ y)2

The case y = x: When y = x,

fy(x, y) = lim f (x, y + h) ¡ f (x, y) = lim f (x, x + h) ¡ f (x, x)h                        h
                    hÑ0                                              hÑ0
                             cos x¡cos(x+h)
                 = lim                                                          (Recall that h $ 0 in the limit.)
                               x¡(x+h) ¡ 0

                    hÑ0                     h
                 = lim 2 cos(x + h) ¡ cos x
                    hÑ0                     h

Now we apply L'Ho^ pital's rule, remembering that, in this limit, x is a constant and h is
the variable -- so we differentiate with respect to h.

                                               fy(x, y) = lim ¡ sin(x + h)
                                                                hÑ0        2h

                                                                34
PARTIAL DERIVATIVES                                                                    2.1 PARTIAL DERIVATIVES

Note that if x is not an integer multiple of , then the numerator ¡ sin(x + h) does not

tend to zero as h tends to zero, and the limit giving fy(x, y) does not exist. On the other
hand, if x is an integer multiple of , both the numerator and denominator tend to zero
as h tends to zero, and we can apply L'Ho^ pital's rule a second time. Then

                                           fy(x, y) = lim ¡ cos(x + h)2
                                                        hÑ0
                                                      = ¡cos x 2

The conclusion:

                      9 6 (x¡y) sin y+cos x¡cos y     if x $ y
                      9          (x¡y)2
                      8                               if x = y with x an integer multiple of 
                                                      if x = y with x not an integer multiple of 
          fy(x, y) = ¡ cos x
                      92

                      9
                      7DNE

                                                                                               Example 2.1.8

Our next example uses implicit differentiation.
 Example 2.1.9

The equation                                 z5 + y2ez + e2x = 0

implicitly determines z as a function of x and y. For example, when x = y = 0, the
equation reduces to
                                                      z5 = ¡1
                                                                                  fz (0,
which     forces1  z(0,   0)  =  ¡1.  Let's  find  the  partial   derivative      fx      0).

     We are not going to be able to explicitly solve the equation for z(x, y). All we know is
that
                                         z(x, y)5 + y2ez(x,y) + e2x = 0

for  all  x  and  y.  We  can  turn   this  into  an  equation    for  fz (0,  0)  by  differentiating2  the  whole
equation with respect to x, giving                                     fx

                              5z(x, y)4 fz (x, y) + y2ez(x,y) fz (x, y) + 2e2x = 0
                                      fx                          fx

and then setting x = y = 0, giving

                            5z(0, 0)4 fz (0, 0) + 2 = 0
                                    fx

As we already know that z(0, 0) = ¡1,

                                         fxfz (0, 0) = ¡ 4 2 = ¡2              5
                                                        5z(0, 0)

1 The only real number z which obeys z5 = ¡1 is z = ¡1. However there are four other complex numbers
   which also obey z5 = ¡1.

2 You should have already seen this technique, called implicit differentiation, in your first Calculus
      course.

                                                        35
PARTIAL DERIVATIVES                                                     2.2 HIGHER ORDER DERIVATIVES

                                                                                          Example 2.1.9

Next we have a partial derivative disguised as a limit.
 Example 2.1.10

In this example we are going to evaluate the limit

                                         lim (x + y + z)3 ¡ (x + y)3
                                         zÑ0           (x + y)z

The critical observation is that, in taking the limit z Ñ 0, x and y are fixed. They do not

change as z is getting smaller and smaller. Furthermore this limit is exactly of the form
of the limits in the Definition 2.1.1 of partial derivative, disguised by some obfuscating
changes of notation.

    Set f (x, y, z) = (x + y + z)3
                                                            (x + y)

Then

lim (x + y + z) = 3 ¡ (x + y)3 lim f (x, y, z) ¡ f (x, y, 0) = lim f (x, y, 0 + h) ¡ f (x, y, 0)
zÑ0        (x + y)z                      zÑ0               z                   hÑ0        h
                                      = f f (x, y, 0)
                                         fz
                                      = f (x + y + z)3
                                             fz x + y z=0

Recalling  that  f   treats  x  and   y  as  constants,    we  are  evaluating    the     derivative  of  a  function
                 fz
           (const+z)3
of the form const . So

                       lim      (x + y + z)3 ¡ (x + y)3             (x  +   y  +  z)2  §
                                                                                       §
                                                               = 3 §§
                       zÑ0               (x + y)z                       x + y z=0

                                                               = 3(x + y)

                                                                                          Example 2.1.10

2.2 Higher Order Derivatives

You have already observed, in your first Calculus course, that if f (x) is a function of x,
                                    df

then its derivative, dx (x), is also a function of x, and can be differentiated to give the
                                d2 f
second order derivative dx2 (x), which can in turn be differentiated yet again to give the
third order derivative, f (3)(x), and so on.
We can do the same for functions of more than one variable. If f (x, y) is a function of x
                                                       ff               ff
and y, then both of its partial derivatives, fx (x, y) and fy (x, y) are also functions of x and

                                                         36
PARTIAL DERIVATIVES                                               2.2 HIGHER ORDER DERIVATIVES

y. They can both be differentiated with respect to x and they can both be differentiated
with respect to y. So there are four possible second order derivatives. Here they are,
together with various alternate notations.

                           f f f (x, y) = f 2 ( 2 f x, y) = fxx(x, y)
                           fx fx                  fx
                           f f f (x, y) = f ( 2 f x, y)= fxy(x, y)
                           fy fx                  fyfx
                           f f f (x, y) = f ( 2 f x, y)= fyx(x, y)
                           fx fy                  fxfy
                           f f f (x, y) = f 2 ( 2 f x, y) = fyy(x, y)
                           fy fy                  fy

    Warning2.2.1.

    f2 f        f2                                                        f
    In fy fx = fy fx f , the derivative closest to f , in this case fx , is applied first. So we
    work through the variables in the bottom right-to-left.
    In fxy, the derivative with respect to the variable closest to f , in this case x, is
    applied first. So we work through the subscript variables left-to-right.

    The difference in "direction" highlighted in the warning seems confusing at first, but
it stems from the way the first partial derivative is written. In the fractional notation, if f
                                                              ff      f                          f
is  being  differentiated  with  respect  to  x,  we   write  fx  or  fx  f.  So  the  operator  fx  is  added
                                                                            ff
to the left of the function. Now suppose we want to differentiate fx with respect to y.
                                 f ff             f2f
By analogy, we would write fy fx , or fyfx . This leads to the order of variables being
right-to-left.
    With the subscript notation, if f is being differentiated with respect to x, we write fx,
with the variable on the right of the function. So now if we take the second derivative with
respect to y, it makes sense by analogy to add that new variable to the right: ( fx)y, or fxy,
in left-to-right order.

Example 2.2.2

Let f (x, y) = emy cos(nx). Then                               fy = memy cos(nx)

              fx = ¡nemy sin(nx)                              fyx = ¡mnemy sin(nx)
             fxx = ¡n2emy cos(nx)
             fxy = ¡mnemy sin(nx)                             fyy = m2emy cos(nx)

                                                                                       Example 2.2.2

                                                  37
PARTIAL DERIVATIVES                                                               2.2 HIGHER ORDER DERIVATIVES

Example 2.2.3

Let f (x, y) = ex+y. Then

                            fx = ex+y                                             fy = ex+y
                           fxx = 2ex+y                                           fyx = ex+y
                           fxy = ex+y                                            fyy = 2ex+y

More generally, for any integers m, n ¥ 0,

                                                f =  m+n f m nex+y
                                                fxm fyn

                                                                                                Example 2.2.3

Example 2.2.4

If  f (x1, x2, x3, x4)  =  x4   x3   x2   x4,  then

                             1    2    3

                                          f4 f                   f3                 432
                                                        =                         x1 x2 x3
                                     fx1 fx2 fx3 fx4 fx1 fx2 fx3
                                                        = f2
                                                           fx1 fx2         2  x4   x3   x3

                                                                                1    2

                                                        =f          6  x4   x2    x3
                                                           fx1
                                                                         1    2

                                                        =  24  x3   x2   x3

                                                                 1    2

and

                                          f4 f                 f3                  332
                                                     =                        4x1 x2 x3 x4
                                fx4 fx3 fx2 fx1 fx4 fx3 fx2
                                                     = f2
                                                        fx4 fx3        12    x3   x2   x2   x4

                                                                               1    2    3

                                                     =f          24   x3   x2   x3  x4
                                                        fx4
                                                                        1    2

                                                     =  24  x3   x2   x3

                                                              1    2

                                                                                                Example 2.2.4

Notice that in Example 2.2.2,                  fxy = fyx = ¡mnemy sin(nx)
and in Example 2.2.3
                                                   fxy = fyx = ex+y

                                                            38
PARTIAL DERIVATIVES                     2.3 LOCAL MAXIMUM AND MINIMUM VALUES

and in Example 2.2.4

                      f4 f              f4 f                   32
                                  =                    = 24 x1 x2 x3
                      fx1 fx2 fx3 fx4 fx4 fx3 fx2 fx1

In all of these examples, it didn't matter what order we took the derivatives in. The fol-
lowing theorem3 shows that this was no accident.

Theorem2.2.5 (Clairaut's Theorem4 or Schwarz's Theorem5).

                      f2 f        f2 f
If the partial derivatives fxfy and fyfx exist and are continuous at (x0, y0), then

                            f ( 2 f x0, y0) = f ( 2 f x0, y0)
                            fxfy        fyfx

The Proof of Theorem 2.2.5 can be found in Appendix A.4.1. An example of a function
              f2 f    f2 f
f (x, y) where fxfy (x0, y0) $ fyfx (x0, y0) can be found in Appendix A.4.2.
We won't use this theorem a whole lot in Math 105. It can occasionally be useful to
note that as long as a function is continuous and differentiable, you can differentiate it in
any "order."

Example 2.2.6

Let f (x, y) = x5ex + y. Find fxxxy.
Solution. Since f (x, y) is continuous and differentiable everywhere, then the order of
differentiation doesn't matter. Rather than starting with respect to x (which is harder), we
start with respect to y (which is easier).

                                             fy = 1

                              fyx = 0 ùñ fxy = 0
                             fxyx = 0 ùñ fxxy = 0
                            fxxyx = 0 ùñ fxxxy = 0

                                                                      Example 2.2.6

2.3 Local Maximum and Minimum Values

     One of the core topics in single variable calculus courses is finding the maxima and min-
     ima of functions of one variable. We'll now extend that discussion to functions of more
     than one variable6. To keep things simple, we'll focus on functions with two variables.

      3 The history of this important theorem is pretty convoluted. See "A note on the history of mixed partial
            derivatives" by Thomas James Higgins which was published in Scripta Mathematica 7 (1940), 59-62.

      4 Alexis Clairaut (1713-1765) was a French mathematician, astronomer, and geophysicist.
      5 Hermann Schwarz (1843-1921) was a German mathematician.
      6 Life is not (always) one-dimensional and sometimes we have to embrace it.

                                                               39
PARTIAL DERIVATIVES  2.3 LOCAL MAXIMUM AND MINIMUM VALUES

It's worth noting, though, that many of the techniques we use will generalize to func-
tions with even more. To start, we have the following natural extensions to some familiar
definitions.

 Definition2.3.1.

Let the function f (x, y) be defined for all (x, y) in some subset R of R2. Let (a, b)
be a point in R.

  · (a, b) is a local maximum of f (x, y) if f (x, y) ¤ f (a, b) for all (x, y) close to
    (a, b). More precisely, (a, b) is a local maximum of f (x, y) if there is an r ¡ 0
    such that f (x, y) ¤ f (a, b) for all points (x, y) within a distance r of (a, b).

  · (a, b) is a local minimum of f (x, y) if f (x, y) ¥ f (a, b) for all (x, y) close to

       (a, b).
    · Local maximum and minimum values are also called extremal values.

  · (a, b) is an absolute maximum or global maximum of f (x, y) if f (x, y) ¤ f (a, b)

       for all (x, y) in R.

  · (a, b) is an absolute minimum or global minimum of f (x, y) if f (x, y) ¥ f (a, b)

       for all (x, y) in R.

2.3.1  Critical Points

       One of the first things you did when you were developing the techniques used to find the
      maximum and minimum values of f (x) was to ask yourself7

            Suppose that the largest value of f (x) is f (a). What does that tell us about a?
       After a little thought you answered

           If the largest value of f (x) is f (a) and f is differentiable at a, then f I(a) = 0.

                                                         y

                                                                                 x
                                                                               y " f pxq

        7 Or perhaps your instructor asked you.

                                                                 40
PARTIAL DERIVATIVES  2.3 LOCAL MAXIMUM AND MINIMUM VALUES

Let's recall why that's true. Suppose that the largest value of f (x) is f (a). Then for all

h ¡ 0,
     f (a + h) ¤ f (a) ùñ f (a + h) ¡ f (a) ¤ 0 ùñ f (a + h) ¡ f (a) h ¤ 0 if h ¡ 0

Taking the limit h Ñ 0 tells us that f I(a) ¤ 0. Similarly, for all h 0,
     f (a + h) ¤ f (a) ùñ f (a + h) ¡ f (a) ¤ 0 ùñ f (a + h) ¡ f (a) h ¥ 0 if h 0

Taking the limit h Ñ 0 now tells us that f I(a) ¥ 0. So we have both f I(a) ¥ 0 and f I(a) ¤ 0

which forces f I(a) = 0.

  You also observed at the time that for this argument to work, you only need f (x) ¤

f (a) for all x's close to a, not necessarily for all x's in the whole world. (In the above
inequalities, we only used f (a + h) with h small.) Since we care only about f (x) for x near
a, we can refine the above statement.

     If f (a) is a local maximum for f (x) and f is differentiable at a, then f I(a) = 0.

Precisely the same reasoning applies to minima.

     If f (a) is a local minimum for f (x) and f is differentiable at a, then f I(a) = 0.

    Let's use the ideas of the above discourse to extend the study of local maxima and
local minima to functions of more than one variable. Suppose that the function f (x, y)
is defined for all (x, y) in some subset R of R2, that (a, b) is point of R that is not on the
boundary of R, and that f has a local maximum at (a, b). See the figure below.

                     z

                                     pa,b , f pa,bqq

                                                           z " f px, yq

                                                                         y
                                              pa,bq R
                     x

Then the function f (x, y) must decrease in value as (x, y) moves away from (a, b) in any

direction. If we change the x-coordinate a little, f (x, y) must not increase. So for all h ¡ 0:

f (a + h, b) ¤ f (a, b) ùñ f (a + h, b) ¡ f (a, b) ¤ 0 ùñ  f (a + h, b) ¡ f (a, b) h ¤ 0  if h ¡ 0
Taking the limit h Ñ 0 tells us that fx(a, b) ¤ 0.

                     41
PARTIAL DERIVATIVES  2.3 LOCAL MAXIMUM AND MINIMUM VALUES

    Similarly, for all h 0,

f (a + h, b) ¤ f (a, b) ùñ f (a + h, b) ¡ f (a, b) ¤ 0 ùñ f (a + h, b) ¡ f (a, b) h ¥ 0 if h 0
Taking the limit h Ñ 0 now tells us that fx(a, b) ¥ 0. So we have both fx(a, b) ¥ 0 and
fx(a, b) ¤ 0 which forces fx(a, b) = 0. The same reasoning tells us fy(a, b) = 0 as well, and

that these partial derivatives are zero for minima as well as maxima.
    This is an important and useful result, so let's theoremise it.

 Theorem2.3.2.

Let the function f (x, y) be defined for all (x, y) in some subset R of R2. Assume
that

  ¥ (a, b) is a point of R that is not on the boundary of R and
  ¥ (a, b) is a local maximum or local minimum of f and that
  ¥ the partial derivatives of f exist at (a, b).

Then

                                               fx(a, b) = 0
                                         and fy(a, b) = 0

 Definition2.3.3.
Let f (x, y) be a function and let (a, b) be a point in its domain. Then we call (a, b)
a critical point (or a stationary point) of the function if

   · fx(a, b) does not exist, or
   · fy(a, b) does not exist, or
   · fx(a, b) = fy(a, b) = 0.

 Warning2.3.4.
Note that some people (and texts) do not include the cases where one or both
partial derivatives do not exist in the definition of a critical point. These points
would (usually) be referred as a singular point of the function. We do not use
this terminology.

                                                    42
PARTIAL DERIVATIVES  2.3 LOCAL MAXIMUM AND MINIMUM VALUES

 Warning2.3.5.
Theorem 2.3.2 tells us that every local maximum or minimum (in the interior of
the domain of a differentiable function) is a critical point. Beware that it does not8
tell us that every critical point is either a local maximum or a local minimum.

    In fact, as we shall see in Example 2.3.12, critical points that are neither local maxima
nor a local minima. None-the-less, Theorem 2.3.2 is very useful because often functions
have only a small number of critical points. To find local maxima and minima of such
functions, we only need to consider its critical points. We'll return later to the question of
how to tell if a critical point is a local maximum, local minimum or neither. For now, we'll
just practice finding critical points.

 Example 2.3.6 f (x, y) = x2 ¡ 2xy + 2y2 + 2x ¡ 6y + 12

Find all critical points of f (x, y) = x2 ¡ 2xy + 2y2 + 2x ¡ 6y + 12.

Solution. To find the critical points, we need to find the first order partial derivatives. So,
as a preliminary calculation, we find the two first order partial derivatives of f (x, y).

                     fx(x, y) = 2x ¡ 2y + 2
                     fy(x, y) = ¡2x + 4y ¡ 6

These functions are defined everywhere. So the critical points are the solutions of the pair
of equations

                      2x ¡ 2y + 2 = 0 ¡ 2x + 4y ¡ 6 = 0

or equivalently (dividing by two and moving the constants to the right hand side)

                     x ¡ y = ¡1                                                         (E1)

                     ¡x + 2y = 3                                                        (E2)

This is a system of two equations in two unknowns (x and y). One strategy for solving
system like this is to

· First use one of the equations to solve for one of the unkowns in terms of the other
   unknown. For example, (E1) tells us that y = x + 1. This expresses y in terms of x.
   We say that we have solved for y in terms of x.

· Then substitute the result, y = x + 1 in our case, into the other equation, (E2). In our
   case, this gives

                  ¡x + 2(x + 1) = 3 ðñ x + 2 = 3 ðñ x = 1

· We have now found that x = 1, y = x + 1 = 2 is the only solution. So the only critical
   point is (1, 2). Of course it only takes a moment to verify that fx(1, 2) = fy(1, 2) = 0.
   It is a good idea to do this as a simple check of our work.

8 A very common error of logic that people make is "Affirming the consequent". "If P then Q" is true,
      does not imply that "If Q then P" is true . The statement "If he is Shakespeare then he is dead" is true.
      But concluding from "That sheep is dead" that "He must be Shakespeare" is just silly.

                                                          43
PARTIAL DERIVATIVES  2.3 LOCAL MAXIMUM AND MINIMUM VALUES

An alternative strategy for solving a system of two equations in two unknowns, like (E1)
and (E2), is to

    · add equations (E1) and (E2) together. This gives

                (E1) + (E2) : (1 ¡ 1)x + (¡1 + 2)y = ¡1 + 3 ðñ y = 2

       The point here is that adding equations (E1) and (E2) together eliminates the un-
       known x, leaving us with one equation in the unknown y, which is easily solved.
       For other systems of equations you might have to multiply the equations by some
       numbers before adding them together.
   · We now know that y = 2. Substituting it into (E1) gives us

                               x ¡ 2 = ¡1 ùñ x = 1

   · Once again (thankfully) we have found that the only critical point is (1, 2).

                                                                                                Example 2.3.6
This was pretty easy because we only had to solve linear equations, which in turn was a
consequence of the fact that f (x, y) was a polynomial of degree two. Here is an example
with some slightly more challenging algebra.

 Example 2.3.7 f (x, y) = 2x3 ¡ 6xy + y2 + 4y
Find all critical points of f (x, y) = 2x3 ¡ 6xy + y2 + 4y.

Solution. As in the last example, we need to find where the partial derivatives do not exist
or are zero.

                       fx = 6x2 ¡ 6y fy = ¡6x + 2y + 4

These functions are defined everywhere. So the critical points are the solutions of

                       6x2 ¡ 6y = 0 ¡ 6x + 2y + 4 = 0

We can rewrite the first equation as y = x2, which expresses y as a function of x. We can
then substitute y = x2 into the second equation, giving

¡6x + 2y + 4 = 0 ðñ ¡6x + 2x2 + 4 = 0 ðñ x2 ¡ 3x + 2 = 0 ðñ (x ¡ 1)(x ¡ 2) = 0
                ðñ x = 1 or 2

When x = 1, y = 12 = 1 and when x = 2, y = 22 = 4. So, there are two critical points:
(1, 1), (2, 4).

  Alternatively, we could have also used the second equation to write y = 3x ¡ 2, and

then substituted that into the first equation to get

                    6x2 ¡ 6(3x ¡ 2) = 0 ðñ x2 ¡ 3x + 2 = 0

just as above.

                                                          44
PARTIAL DERIVATIVES               2.3 LOCAL MAXIMUM AND MINIMUM VALUES

                                                                               Example 2.3.7

    And here is an example for which the algebra requires a bit more thought.

 Example 2.3.8 ( f (x, y) = xy(5x + y ¡ 15))

Find all critical points of f (x, y) = xy(5x + y ¡ 15).
Solution. The first order partial derivatives of f (x, y) = xy(5x + y ¡ 15) are

    fx(x, y) = y(5x + y ¡ 15) + xy(5) = y(5x + y ¡ 15) + y(5x) = y(10x + y ¡ 15)
    fy(x, y) = x(5x + y ¡ 15) + xy(1) = x(5x + y ¡ 15) + x(y) = x(5x + 2y ¡ 15)

Therefore the partial derivatives of the function exist everywhere in the domain of the
function. The critical points are the solutions of fx(x, y) = fy(x, y) = 0. That is, we need
to find all x, y that satisfy the pair of equations

                                  y(10x + y ¡ 15) = 0                                                 (E1)

                                  x(5x + 2y ¡ 15) = 0                                                 (E2)

The first equation, y(10x + y ¡ 15) = 0, is satisfied if at least one of the two factors y,
(10x + y ¡ 15) is zero. So the first equation is satisfied if at least one of the two equations

                                          y=0                                                      (E1a)
                                  10x + y = 15                                                     (E1b)

is satisfied. The second equation, x(5x + 2y ¡ 15) = 0, is satisfied if at least one of the two
factors x, (5x + 2y ¡ 15) is zero. So the second equation is satisfied if at least one of the

two equations

                                          x=0                                                      (E2a)
                                  5x + 2y = 15                                                     (E2b)

is satisfied.
    So both critical point equations (E1) and (E2) are satisfied if and only if at least one

of (E1a), (E1b) is satisfied and in addition at least one of (E2a), (E2b) is satisfied. So both
critical point equations (E1) and (E2) are satisfied if and only if at least one of the following
four possibilities hold.

· (E1a) and (E2a) are satisfied if and only if x = y = 0

· (E1a) and (E2b) are satisfied if and only if y = 0, 5x + 2y = 15 ðñ y = 0, 5x = 15

· (E1b) and (E2a) are satisfied if and only if 10x + y = 15, x = 0 ðñ y = 15, x = 0

· (E1b) and (E2b) are satisfied if and only if 10x + y = 15, 5x + 2y = 15. We can use, for
example,  the  second  of  these  equations  to  solve  for  x  in  terms  of  y:  x     1     15  ¡  2  y     .
                                                                                      =  5  (               )
When we substitute this into the first equation we get 2(15 ¡ 2y) + y = 15, which we
can solve for y. This gives ¡3y = 15 ¡ 30 or y = 5 and then x = 15 (15 ¡ 2 ¢ 5) = 1.

                                  45
PARTIAL DERIVATIVES                              2.3 LOCAL MAXIMUM AND MINIMUM VALUES

In conclusion, the critical points are (0, 0), (3, 0), (0, 15) and (1, 5).
    A more compact way to write what we have just done is

                              fx(x, y) = 0                and                        fy(x, y) = 0

ðñ                      y(10x + y ¡ 15) = 0               and             x(5x + 2y ¡ 15) = 0

ðñ 2y = 0 or 10x + y = 15@ and 2x = 0 or 5x + 2y = 15@
ðñ 2y = 0, x = 0@ or 2y = 0, 5x + 2y = 15@ or 210x + y = 15, x = 0@ or
                                     210x + y = 15, 5x + 2y = 15@

ðñ 2x = y = 0@ or 2y = 0, x = 3@ or 2x = 0, y = 15@ or 2x = 1, y = 5@

                                                                                     Example 2.3.8

    Let's try a more practical example -- something from the real world. Well, a mathe-
matician's "real world". The interested reader should search-engine their way to a dis-
cussion of "idealisation", "game theory" "Cournot models" and "Bertrand models". But
don't spend too long there. A discussion of breweries is about to take place.

 Example 2.3.9

In a certain community, there are two breweries in competition9, so that sales of each neg-
atively affect the profits of the other. If brewery A produces x litres of beer per month and
brewery B produces y litres per month, then the profits of the two breweries are given by

                    P = 2x ¡ 106 2x2 + y2 Q = 2y ¡ 2 ¢ 106 4y2 + x2

respectively. Find the sum of the two profits if each brewery independently sets its own
production level to maximize its own profit and assumes that its competitor does likewise.
Then, assuming cartel behaviour, find the sum of the two profits if the two breweries
cooperate so as to maximize that sum10.

Solution. If A adjusts x to maximize P (for y held fixed) and B adjusts y to maximize Q
(for x held fixed) then we want to find the (x, y) using

                                          Px  =  2¡    104x

                                                            6

                                          Qy = 2 ¡ 2¢106  8y

Note that Px and Qy exists everywhere. Then x and y are determined by the equations

                                              Px = 0                                                    (E1)

                                              Qy = 0                                                    (E2)

Equation  (E1)  yields  x  =  1 106  and  equation  (E2)       yields  y  =  1 106.  Knowing  x    and  y  we

                              2                                              2
can determine P, Q and the total profit

                              P + Q = 2(x + y) ¡       10 1    5 x2 + 3y2

                                                            6  2

                                     = 106    1  +  1  ¡  5    ¡  3  = 5 106
                                                          8       4
                                                                         8

9 We have both types of music here -- country and western.
10 This sort of thing is generally illegal.

                                                 46
PARTIAL DERIVATIVES                                    2.3 LOCAL MAXIMUM AND MINIMUM VALUES

On  the  other  hand  if  (A,   B)  adjust  (x,  y)  to  maximize              P  +  Q    =    2(x  +    y)  ¡   1   5 x2 + 3y2 ,
                                                                                                                106
then x and y are determined by                                                                                       2

                                       (P + Q)x          =  2¡        5x    =     0                                      (E1)
                                                                      106
                                                                      6y
                                       (P + Q)y = 2 ¡ 106 = 0                                                            (E2)

Equation  (E1)  yields    x  =  2 106  and  equation     (E2)      yields         y  =    1 106.  Again      knowing  x  and  y

                                5                                                         3
we can determine the total profit

                                P + Q = 2(x + y) ¡             101       5 x2 + 3y2

                                                                   6     2

                                       = 106 4 + 2 ¡ 2 ¡ 1 = 11 106
                                                     5 353                           15

So cooperating really does help their profits. Unfortunately, like a very small tea-pot,
consumers will be a little poorer11.

                                                                                                Example 2.3.9

Moving swiftly away from the last pun, let's do something a little more geometric.

Example 2.3.10

Equal angle bends are made at equal distances from the two ends of a 100 metre long fence
so the resulting three segment fence can be placed along an existing wall to make an en-
closure of trapezoidal shape. What is the largest possible area for such an enclosure?

                                                       wall

                                                                      

Solution. This is a very geometric problem (fenced off from pun opportunities), and as
such we should start by drawing a sketch and introducing some variable names.

                          x                 x x sin 

                                             

                             100 ´ 2x

The area enclosed by the fence is the area inside the blue rectangle (in the figure on the
right above) plus the area inside the two blue triangles.

                        A(x,    )   =  (100  ¡   2x)x  sin     +      2  ¤  1  ¤  x  sin    ¤  x  cos  
                                                                            2
                                    = (100x ¡ 2x2) sin  + x2 sin  cos 

11 The authors extend their deepest apologies.

                                                         47
PARTIAL DERIVATIVES                        2.3 LOCAL MAXIMUM AND MINIMUM VALUES

To maximize the area, we need to solve

                     0 = fA = (100 ¡ 4x) sin  + 2x sin  cos 
                          fx
                          fA
                                           2 22 2 2 @
                     0 = f = (100x ¡ 2x ) cos  + x cos  ¡ sin 

Note  that  fA  and  fA  are  defined  everywhere  in  their  domain  (so  here  the  critical  points
            fx       f
are the points where both partial derivatives are zero). Both terms in the first equation
contain the factor sin  and all terms in the second equation contain the factor x. If either
sin  or x are zero the area A(x, ) will also be zero, and so will certainly not be maximal.
So we may divide the first equation by sin  and the second equation by x, giving

                                        (100 ¡ 4x) + 2x cos  = 0                                (E1)

                          (100 ¡ 2x) cos  + x2 cos2  ¡ sin2 @ = 0 (E2)

These equations might look a little scary. But there is no need to panic. They are not as
bad as they look because  enters only through cos  and sin2 , which we can easily write
in terms of cos . Furthermore we can eliminate cos  by observing that the first equation
                ¡ 100¡4x                                              (100¡4x)2
forces cos   =        2x  and hence sin2   =  1 ¡ cos2        =   1¡             Substituting these
                                                                           2.
into the second equation gives                                        4x

                          ¡(100 ¡ 2x)  100 ¡ 4x        (100 ¡ 4x)2
                                                 +x               2 ¡1 =0
                                       2x                     2x

                ùñ ¡(100 ¡ 2x)(100 ¡ 4x) + (100 ¡ 4x)2 ¡ 2x2 = 0

                ùñ                                               6x2 ¡ 200x = 0

                ùñ x = 1003 cos  = ¡¡100/3 200/3 = 12  = 60¥

and the maximum area enclosed is              c3 1 1002 c3 2500
                                                   +                  =c
                 A = 100100 3 ¡ 2 32 1002        2 23 2       2            3

                                                                                 Example 2.3.10

    Now here is a very useful (even practical!) statistical example -- finding the line that
best fits a given collection of points.

 Example 2.3.11 (Linear regression)

An experiment yields n data points (xi, yi), i = 1, 2, ¤ ¤ ¤ , n. We wish to find the straight

line y = mx + b which "best" fits the data. The definition of "best" is "minimizes the

                                                          48
PARTIAL DERIVATIVES         2.3 LOCAL MAXIMUM AND MINIMUM VALUES
                     y

                                                                    pxn ,yn q

                     px1 ,y1 q           px3 ,y3 q

                                    px2 ,y2 q

                     y " mx ` b
                                                                       x

root mean square error", i.e. minimizes

                                                                         ¸ n

                          E(m, b) = (mxi + b ¡ yi)2

                                                                      i=1

Note that
   · term number i in E(m, b) is the square of the difference between yi, which is the ith
       measured value of y, and mx + b x=xi, which is the approximation to yi given by
       the line y = mx + b.

· All terms in the sum are positive, regardless of whether the points (xi, yi) are above
   or below the line.

Our problem is to find the m and b that minimizes E(m, b). This technique for drawing a
line through a bunch of data points is called "linear regression". It is used a lot12 13. Even
in the real world -- and not just the real world that you find in mathematics problems.
The actual real world that involves jobs.

Solution. We wish to choose m and b so as to minimize E(m, b). So we need to determine
where the partial derivatives of E do not exist, or exist and are equal to zero.

fE ¸ n                              ° n 2 ° n ° n
= 2(mxi + b ¡ yi)xi= m 2xi + b 2xi ¡ 2xiyi
fm i=1                              i=1               i=1                 i=1

fE = ¸ 2(mxi + b n ¡ yi) = m ° n 2xi + b ° n 2 ¡ ° n 2yi
fb i=1                                   i=1               i=1            i=1

There are a lot of symbols here. But remember that all of the xi's and yi's are given con-
stants. They come from, for example, experimental data. The only unknowns are m and
b. To emphasize this, and to save some writing, define the constants

          ° n                  ° n             ° n 2                  ° n

Sx = xi              Sy = yi        Sx2 = xi               Sxy = xiyi

         i=1                  i=1             i=1                    i=1

12 Proof by search engine.
13 And has been used for a long time. It was introduced by the French mathematician Adrein-Marie

      Legendre, 1752-1833, in 1805, and by the German mathematician and physicist Carl Friedrich Gauss,
      1777-1855, in 1809.

                                    49
PARTIAL DERIVATIVES                   2.3 LOCAL MAXIMUM AND MINIMUM VALUES

The partial derivatives of E exists everywhere so we only need to find where they are
equal to zero. The equations which determine the critical points are (after dividing by
two)

       0 = Sx2 m + Sx b ¡ Sxy ùñ Sx2 m + Sx b = Sxy                               (E1)

       0 = Sx m + n b ¡ Sy ùñ Sx m + n b = Sy                                     (E2)

These are two linear equations on the unknowns m and b. They may be solved in any of
the usual ways. One is to use (E2) to solve for b in terms of m

                               b = 1n Sy ¡ Sxm (E3)

and then substitute this into (E1) to get the equation

       Sx2 m + 1n Sx Sy ¡ Sxm = Sxy ùñ             nSx2  ¡  S2   m = nSxy ¡ SxSy

                                                              x

for m. We can then solve this equation for m and substitute back into (E3) to get b. This
gives
                         nSxy ¡ SxSy               SxSxy ¡ SySx2
                     m=  nSx2 ¡ Sx         b=¡        nSx2 ¡ Sx
                                  2                              2

Another way to solve the system of equations is

          n(E1) ¡ Sx(E2) :           nSx2  ¡  S2   m = nSxy ¡ SxSy
       ¡Sx(E1) + Sx2(E2) :
                                                x

                                     nSx2  ¡  S2   b  = ¡SxSxy + SySx2

                                                x

which gives the same solution.
    So given a bunch of data points, it only takes a quick bit of arithmetic -- no calculus

required -- to apply the above formulae and so to find the best fitting line. Of course while
you don't need any calculus to apply the formulae, you do need calculus to understand
where they came from. The same technique can be extended to other types of curve fitting
problems. For example, polynomial regression.

                                                                                                Example 2.3.11

2.3.2  Classifying Critical Points

       Now let's start thinking about how to tell if a critical point is a local minimum, local maxi-
       mum, or neither. We'll start with an intuitive approach, then introduce the (multivariable)
       Second Derivative Test.

           You have already encountered single variable functions that have a critical point which
       is neither a local max nor a local min. This can also happen for functions of two variables.
       We'll start with the simplest possible such example.

     Example 2.3.12 f (x, y) = x2 ¡ y2
    The first partial derivatives of f (x, y) = x2 ¡ y2 are fx(x, y) = 2x and fy(x, y) = ¡2y. So

                                                                 50
PARTIAL DERIVATIVES  2.3 LOCAL MAXIMUM AND MINIMUM VALUES

the only critical point of this function is (0, 0). Is this a local minimum or maximum? Well
let's start with (x, y) at (0, 0) and then move (x, y) away from (0, 0) and see if f (x, y) gets
bigger or smaller. At the origin f (0, 0) = 0. Of course we can move (x, y) away from (0, 0)
in many different directions.

   · First consider moving (x, y) along the x-axis. Then (x, y) = (x, 0) and f (x, y) =
       f (x, 0) = x2. So when we start with x = 0 and then increase x, the value of the
       function f increases -- which means that (0, 0) cannot be a local maximum for f .

   · Next let's move (x, y) away from (0, 0) along the y-axis. Then (x, y) = (0, y) and

     f (x, y) = f (0, y) = ¡y2. So when we start with y = 0 and then increase y, the value

       of the function f decreases -- which means that (0, 0) cannot be a local minimum
       for f .
So moving away from (0, 0) in one direction causes the value of f to increase, while mov-
ing away from (0, 0) in a second direction causes the value of f to decrease. Consequently
(0, 0) is neither a local minimum or maximum for f . It is called a saddle point, because the
graph of f looks like a saddle. (The full definition of "saddle point" is given immediately
after this example.) Here are some figures showing the graph of f .

The figure below show some level curves of f . Observe from the level curves that
   · f increases as you leave (0, 0) walking along the x axis
   · f decreases as you leave (0, 0) walking along the y axis

                                                            y

                                                                                              f =-9
                                                                                              f =-4
                                                                                              f =-1
                                                       f =9 f =4 f =1 f =0 f =1 f =4 f =9

                                                                                        x

                                                                                              f =-1
                                                                                              f =-4
                                                                                              f =-9

                                                          51
PARTIAL DERIVATIVES  2.3 LOCAL MAXIMUM AND MINIMUM VALUES

                                                                                                Example 2.3.12

    Approximately speaking, if a critical point (a, b) is neither a local minimum nor a local
maximum, then it is a saddle point. For (a, b) to not be a local minimum, f has to take
values smaller than f (a, b) at some points nearby (a, b). For (a, b) to not be a local max-
imum, f has to take values bigger than f (a, b) at some points nearby (a, b). Writing this
more mathematically we get the following definition.

      Definition2.3.13.
     The critical point (a, b) is called a saddle point for the function f (x, y) if, for each

   r ¡ 0,

         · there is at least one point (x, y), within a distance r of (a, b), for which

         f (x, y) ¡ f (a, b) and

         · there is at least one point (x, y), within a distance r of (a, b), for which
             f (x, y) f (a, b).

    Understanding what the graph of a function looks like is a powerful tool for classifying
critical points, but it can be very time-consuming. The Second Derivative Test (below) is
a more algebraic approach to classification. This test is often faster than graphing, but the
drawback is that it is sometimes inconclusive.

      Theorem2.3.14 (Second Derivative Test).

   Let r ¡ 0 and assume that all second order derivatives of the function f (x, y) are

     continuous at all points (x, y) that are within a distance r of (a, b). Assume that
      fx(a, b) = fy(a, b) = 0. Define

                      D(x, y) = fxx(x, y) fyy(x, y) ¡ fxy(x, y)2

     It is called the discriminant of f . Then

      · if D(a, b) ¡ 0 and fxx(a, b) ¡ 0, then f (x, y) has a local minimum at (a, b),
      · if D(a, b) ¡ 0 and fxx(a, b) 0, then f (x, y) has a local maximum at (a, b),

         · if D(a, b) 0, then f (x, y) has a saddle point at (a, b), but
         · if D(a, b) = 0, then we cannot draw any conclusions without more work.

    The proof of Theorem 2.3.14 is beyond the scope of Math 105, but there is some intu-
ition supporting it that is more accessible. Extremely informally, we can think of saddle
points as places with inconsistent concavity: in some directions the surface looks concave

                                                          52
PARTIAL DERIVATIVES                                  2.3 LOCAL MAXIMUM AND MINIMUM VALUES

up, in other directions it looks concave down. On the other hand, at a local extremum, the
concavity is the same in all directions.

    Let's do thought experiments on a few simple cases to expand those ideas.
 Example 2.3.15 (Second Derivative Test Intuition)
Let (a, b) be a critical point of the function f (x, y) with fx(a, b) = fy(a, b) = 0, and assume
all second-order derivatives fo f (x, y) are continuous.

   1. Suppose at (a, b), the surface looks like a minimum if y is held constant, but it looks
       like a maximum if x is held constant. (In particular, this means (a, b) is the location
       of a saddle point.)

                                                   (a, b, f (a, b))

Holding y = b constant, we can think of z = f (x, b) as a one-variable function, in

which case fxx(a, b) ¥ 0 by the single-variable second derivative test. Holding x = a

constant, we can think of z = f (a, y) as a one-variable function (whose variable is

y). In that case, fyy(a, b) ¤ 0 by the single-variable second derivative test.

                                   f (x, b)

                                                                          f (a, y)

Since fxx(a, b) and fyy(a, b) have different signs (or at least one of them is zero):

                              fxx(a, b) fyy(a, b) ¤ 0

                     fxx(a, b) fyy(a, b) ¡ fx2y(a, b) ¤ ¡ fx2y)(a, b) ¤ 0
                                      D(a, b) ¤ 0

So in this simple saddle-point example, we expect D(a, b) ¤ 0. This accords with the

third bullet point in Theorem 2.3.14.

2. Suppose D(a, b) ¡ 0.

                                               0     fxx(a, b) fyy(a, b) ¡ fx2y(a, b)

                               f  2   (  a  ,  b  )  fxx(a, b) fyy(a, b)
                                  xy

Since fxy is raised to an even power, it's nonnegative.

                         0  ¤  f  2   (  a  ,  b  )  fxx(a, b) fyy(a, b)
                                  xy                 fxx(a, b) fyy(a, b)

                                               0

                                                     53
PARTIAL DERIVATIVES                2.3 LOCAL MAXIMUM AND MINIMUM VALUES

   This tells us that fxx(a, b) and fyy(a, b) have the same sign - either they're both pos-
   itive or they're both negative. So, the function's concavity is the same whether we
   hold the x-value or the y-value constant. The function might have the same concav-
   ity in all directions - unlike the saddle point example we saw above. So, it seems
   plausible that critical points with positive discriminants are local extrema, rather
   than saddle points.

3. Suppose the surface has a local maximum at (a, b).
   Holding y = b constant, we can think of z = f (x, b) as a one-variable function, in

  which case fxx(a, b) ¤ 0 by the single-variable second derivative test.

                     z = f (x, y)  z = f (x, b)

  a by                               a by
x                                  x

  This doesn't go so far as to show us that D(a, b) ¥ 0, but it does accord with the test

   of fxx(a, b) in the second bullet point of Theorem 2.3.14.

4. Similarly, suppose the surface has a local minimum at (a, b).
   Holding y = b constant, we can think of z = f (x, b) as a one-variable function, in

  which case fxx(a, b) ¥ 0 by the single-variable second derivative test.

                     z = f (x, y)  z = f (x, b)

  a by                               a by
x                                  x

Again, although this doesn't go so far as to show us that D(a, b) ¥ 0, it does accord

with the test of fxx(a, b) in the first bullet point of Theorem 2.3.14.
                                                                                         Example 2.3.15

    You might wonder why, in the local maximum/local minimum cases of Theorem
2.3.14, fxx(a, b) appears rather than fyy(a, b). The answer is only that x is before y in the

                                                          54
PARTIAL DERIVATIVES                          2.3 LOCAL MAXIMUM AND MINIMUM VALUES

alphabet14. You can use fyy(a, b) just as well as fxx(a, b). The reason is that if D(a, b) ¡ 0
(as in the first two bullets of the theorem), then because D(a, b) = fxx(a, b) fyy(a, b) ¡
fxy(a, b)2 ¡ 0, we necessarily have fxx(a, b) fyy(a, b) ¡ 0 so that fxx(a, b) and fyy(a, b)

must have the same sign -- either both are positive or both are negative.
    You might also wonder why we cannot draw any conclusions when D(a, b) = 0 and

what happens then. The second derivative test for functions of two variables was derived
in precisely the same way as the second derivative test for functions of one variable is

derived -- you approximate the function by a polynomial that is of degree two in (x ¡ a),
(y ¡ b) and then you analyze the behaviour of the quadratic polynomial near (a, b). For
this to work, the contributions to f (x, y) from terms that are of degree two in (x ¡ a),
(y ¡ b) had better be bigger than the contributions to f (x, y) from terms that are of degree
three and higher in (x ¡ a), (y ¡ b) when (x ¡ a), (y ¡ b) are really small. If this is not
the case, for example when the terms in f (x, y) that are of degree two in (x ¡ a), (y ¡ b)

all have coefficients that are exactly zero, the analysis will certainly break down. That's
exactly what happens when D(a, b) = 0. Here are some examples. The functions

f1(x, y) = x4 + y4 f2(x, y) = ¡x4 ¡ y4 f3(x, y) = x3 + y3 f4(x, y) = x4 ¡ y4

all have (0, 0) as the only critical point and all have D(0, 0) = 0. The first, f1 has its
minimum there. The second, f2, has its maximum there. The third and fourth have a
saddle point there.

    Here are sketchs of some level curves for each of these four functions (with all renamed
to simply f ).

                     y f"9                   y f"´9

                             f "4                    f "´4
                             f "1                    f "´1

                          f "0.1                  f "´0.1

                      f "0                    f "0

                                          x                       x

             level curves of f px, yq " x4 ` y4 level curves of f px, yq " ´x4 ´ y4

14 The shackles of convention are not limited to mathematics. Election ballots often have the candidates
      listed in alphabetic order.

                                                          55
PARTIAL DERIVATIVES                              2.3 LOCAL MAXIMUM AND MINIMUM VALUES

                     y                                                 y

                             f "4                                           f "´4
                             f "1                                           f "´1

                              f "0                          f "4 f "1       f "0
                                                                                   f "1 f "4

                                           x                                    f "0         x

                                          f "´1                                             f "´1
                                          f "´4                                             f "´4

       level curves of f px, yq " x3 ` y3                   level curves of f px, yq " x4 ´ y4

 Example 2.3.16 f (x, y) = 2x3 ¡ 6xy + y2 + 4y
Find and classify all critical points of f (x, y) = 2x3 ¡ 6xy + y2 + 4y.

Solution. Thinking a little way ahead, to find the critical points we will need the first
order partial derivatives. To apply the second derivative test of Theorem 2.3.14 we will
need all second order partial derivatives. So we need all partial derivatives of order up to
two. Here they are.

                    f = 2x3 ¡ 6xy + y2 + 4y

                    fx = 6x2 ¡ 6y                     fxx = 12x        fxy = ¡6
                    fy = ¡6x + 2y + 4                 fyy = 2          fyx = ¡6

(Of course, fxy and fyx have to be the same. It is still useful to compute both, as a way to
catch some mechanical errors.)

    We have already found, in Example 2.3.7, that the critical points are (1, 1), (2, 4). The
classification is

                    critical        fxx fyy ¡ fxy 2         fxx        type
                    point
                    (1, 1) 12 ¢ 2 ¡ (¡6)2 0
                                                                 saddle point

                    (2, 4) 24 ¢ 2 ¡ (¡6)2 ¡ 0 24 local min

We were able to leave the fxx entry in the top row blank, because

·  we knew that  fxx(1, 1) fyy(1, 1) ¡  f  2   (  1,  1  )  0, and
                                           xy
                                                  fxx(1, 1) fyy(1, 1) ¡     2
·  we  knew,  from  Theorem   2.3.14,  that                              f  xy  (  1,  1  )  0, by itself, was

   enough to ensure that (1, 1) was a saddle point.

Here is a sketch of some level curves of our f (x, y). They are not needed to answer this

                                                     56
PARTIAL DERIVATIVES                             2.3 LOCAL MAXIMUM AND MINIMUM VALUES
                               y
                                  f p2,4q"0, p2,4q

                                    f "2                                              f "0.25
                                    f "3                                              f "0.5
                                                                                      f "1
                                         f "0.5                                       f "2
                                  f "0                         f "3
                                                               p1,1q, f p1,1q"1

                                                         f "1                                  x

question, but can give you some idea as to what the graph of f looks like.
                                                                                                Example 2.3.16

Example 2.3.17 ( f (x, y) = xy(5x + y ¡ 15))

Find and classify all critical points of f (x, y) = xy(5x + y ¡ 15).

Solution. We have already computed the first order partial derivatives

fx(x, y) = y(10x + y ¡ 15)                                     fy(x, y) = x(5x + 2y ¡ 15)

of f (x, y) in Example 2.3.8. Again, to classify the critical points we need the second order
partial derivatives. They are

fxx(x, y) = 10y
fyy(x, y) = 2x

fxy(x, y) = (1)(10x + y ¡ 15) + y(1)= 10x + 2y ¡ 15
fyx(x, y) = (1)(5x + 2y ¡ 15) + x(5)= 10x + 2y ¡ 15

(Once again, we have computed both fxy and fyx to guard against mechanical errors.) We
have already found, in Example 2.3.8, that the critical points are (0, 0), (0, 15), (3, 0) and
(1, 5). The classification is

critical                          fxx            fyy  ¡  f2    fxx  type
point
                                                          xy
(0, 0)
                                  0 ¢ 0 ¡ (¡15)2 0                  saddle point

(0, 15) 150 ¢ 0 ¡ 152 0                                             saddle point

(3, 0) 0 ¢ 6 ¡ 152 0                                                saddle point

(1, 5) 50 ¢ 2 ¡ 52 ¡ 0 50 local min

                                                         57
PARTIAL DERIVATIVES                              2.3 LOCAL MAXIMUM AND MINIMUM VALUES

    Here is a sketch of some level curves of our f (x, y). f is negative in the shaded re-
gions and f is positive in the unshaded regions. Again this is not needed to answer this

                                              y

                                                 p0,15q, f p0,15q"0

                f p1,5q"´25, p1,5q

                                       f "20                        f "20  p3,0q, f p3,0q"0
                f p0,0q"0, p0,0q
                                                 f "´20                              x
                              f "´20                 f "´10
                                                                  f "0         f "´20

                                                        f "20

question, but can give you some idea as to what the graph of f looks like.
                                                                                                Example 2.3.17

Example 2.3.18

Find and classify all of the critical points of f (x, y) = x3 + xy2 ¡ 3x2 ¡ 4y2 + 4.

Solution. We know the drill now. We start by computing all of the partial derivatives of f
up to order 2.

f = x3 + xy2 ¡ 3x2 ¡ 4y2 + 4                     fxx = 6x ¡ 6              fxy = 2y
fx = 3x2 + y2 ¡ 6x                               fyy = 2x ¡ 8              fyx = 2y
fy = 2xy ¡ 8y

fx and fy are defined everywhere. So the critical points are then the solutions of fx = 0,
fy = 0. That is

                                    fx = 3x2 + y2 ¡ 6x = 0                                   (E1)

                                    fy = 2y(x ¡ 4) = 0                                       (E2)

The second equation, 2y(x ¡ 4) = 0, is satisfied if and only if at least one of the two

equations y = 0 and x = 4 is satisfied.

· When y = 0, equation (E1) forces x to obey

                                    0 = 3x2 + 02 ¡ 6x = 3x(x ¡ 2)

so that x = 0 or x = 2.

                                                 58
PARTIAL DERIVATIVES                                 2.3 LOCAL MAXIMUM AND MINIMUM VALUES

   · When x = 4, equation (E1) forces y to obey

                           0 = 3 ¢ 42 + y2 ¡ 6 ¢ 4 = 24 + y2

       which is impossible.
So, there are two critical points: (0, 0), (2, 0). Here is a table that classifies the critical
points.

                critical          fxx  fyy  ¡  f2             fxx           type
                point                                                   local max
                                                xy         ¡6 0        saddle point
                (0, 0)
                              (¡6) ¢ (¡8) ¡ 02 ¡ 0
                (2, 0)
                                  6 ¢ (¡4) ¡ 02 0

                                                                                           Example 2.3.18

 Example 2.3.19

A manufacturer wishes to make an open rectangular box of given volume V using the least
possible material. Find the design specifications.
Solution. Denote by x, y and z, the length, width and height, respectively, of the box.

                                                                 z

                                                             x
                                                y

The box has two sides of area xz, two sides of area yz and a bottom of area xy. So the total
surface area of material used is

                                       S = 2xz + 2yz + xy

However the three dimensions x, y and z are not independent. The requirement that the
box have volume V imposes the constraint

                                                xyz = V

We can use this constraint to eliminate one variable. Since z is at the end of the alphabet
(poor  z),  we  eliminate  z  by  substituting  z      V.  Note  that  if  x  (or  y)  is  equal  to  zero  then
                                                    =
                                                       xy
the volume of the box would equal zero. What is the point of a box with zero volume?!
So if we assume the box has non-zero volume then x = 0 and y = 0. So we have find the
values of x and y that minimize the function

                                  S(x, y) = 2Vy + 2Vx + xy

                                                    59
PARTIAL DERIVATIVES                       2.3 LOCAL MAXIMUM AND MINIMUM VALUES

Let's start by finding the critical points of S. Since

                                          Sx(x, y) = ¡ x2 2V + y
                                          Sy(x, y) = ¡ y2 2V + x

Note that the partial derivatives are not defined for (x, y) = (0, 0) but we have already
eliminated the case where x or y is equal to zero. So (x, y) is a critical point if and only if

                                          x2y = 2V                                   (E1)

                                          xy2 = 2V                                   (E2)

Solving  (E1)  for  y  gives  y  =  2V    Substituting  this  into  (E2)  gives

                                    x2 .

         x x4 4V = 2 2V ùñ x3 = 2V ùñ x = c3 2V and y = (2V)2/3 2V = c3 2V

As there is only one critical point, we would expect it to give the minimum15. But let's use
the second derivative test to verify that at least the critical point is a local minimum. The
various second partial derivatives are

                       Sxx(x, y) = x3 4V                      Sxx c3 2V , c3 2V = 2
                       Sxy(x, y) = 1                          Sxy c3 2V , c3 2V = 1
                                                              Syy c3 2V , c3 2V = 2
                       Syy(x, y) = y3 4V

So

Sxx c3 2V , c3 2V Syy c3 2V , c3 2V ¡ Sxy c3 2V , c3 2V 2 = 3 ¡ 0 Sxx c3 2V , c3 2V = 2 ¡ 0

and, by Theorem 2.3.14.b,           c3 2V , c3 2V is a local minimum and the desired dimensions
are
                                    x = y = c3 2V                  V
                                                              z= 3 4

Note that our solution has x = y. That's a good thing -- the function S(x, y) is symmetric
in x and y. Because the box has no top, the symmetry does not extend to z.

                                                                                                Example 2.3.19

15 Indeed one can use the facts that 0 x V, that 0 y V, and that S Ñ V as x Ñ 0 and as y Ñ 0
   and as x Ñ V and as y Ñ V to prove that the single critical point gives the global minimum.

                                                          60
PARTIAL DERIVATIVES         2.4 ABSOLUTE MINIMA AND MAXIMA

2.4 Absolute Minima and Maxima

     Of course a local maximum or minimum of a function need not be the absolute maximum
     or minimum. We'll now consider how to find the absolute maximum and minimum. Let's
     start by reviewing how one finds the absolute maximum and minimum of a function of
     one variable on an interval.

         For concreteness, let's suppose that we want to find the extremal16 values of a function

   f (x) on the interval 0 ¤ x ¤ 1. If an extremal value is attained at some x = a which is in

     the interior of the interval, i.e. if 0 a 1, then a is also a local maximum or minimum
     and so has to be a critical point of f . But if an extremal value is attained at a boundary
     point a of the interval, i.e. if a = 0 or a = 1, then a need not be a critical point of f . This

   happens, for example, when f (x) = x. The largest value of f (x) on the interval 0 ¤ x ¤ 1

    is 1 and is attained at x = 1, but f I(x) = 1 is never zero, so that f has no critical points.

                     y      y = f (x) = x

                     1

                        1x

So to find the maximum and minimum of the function f (x) on the interval [0, 1], you:

  1. build up a list of all candidate points 0 ¤ a ¤ 1 at which the maximum or miminum

       could be attained, by finding all a's for which either

       (a) 0 a 1 and f I(a) does not exist or
       (b) 0 a 1 and f I(a) = 0 or

        (c) a is a boundary point, i.e. a = 0 or a = 1;

2. and then you evaluate f (a) at each a on the list of candidates. The biggest of these
   candidate values of f (a) is the absolute maximum and the smallest of these candi-
   date values is the absolute minimum.

    The procedure for finding the maximum and minimum of a function of two variables

f (x, y) in a set like, for example, the unit disk x2 + y2 ¤ 1, is similar. You again:

1. build up a list of all candidate points (a, b) in the set at which the maximum or
   minimum could be attained, by finding all (a, b)'s for which either17

(a) (a, b) is in the interior of the set and fx(a, b) or fy(a, b) does not exist or

(b) (a, b) is in the interior of the set (for our example, a2 + b2              1) and fx(a, b) =
     fy(a, b) = 0 or

16 Recall that "extremal value" means "either maximum value or minimum value".
17 This is probably a good time to review the statement of Theorem 2.3.2.

                                                          61
PARTIAL DERIVATIVES          2.4 ABSOLUTE MINIMA AND MAXIMA

(c) (a, b) is a boundary18 point, (for our example, a2 + b2 = 1), and could give the
    maximum or minimum on the boundary -- more about this shortly --

   2. and then you evaluate f (a, b) at each (a, b) on the list of candidates. The biggest of
       these candidate values of f (a, b) is the absolute maximum and the smallest of these
       candidate values is the absolute minimum.

The boundary of a set in R2 (like x2 + y2 ¤ 1) is a curve (like x2 + y2 = 1). This curve is a

one dimensional set, meaning that it is like a deformed x-axis. We can find the maximum
and minimum of f (x, y) on this curve by converting f (x, y) into a function of one variable
(on the curve) and using the standard function of one variable techniques. This is best
explained by some examples.

 Example 2.4.1

Find the maximum and minimum values of f (x, y) = x3 + xy2 ¡ 3x2 ¡ 4y2 + 4 on the disk
x2 + y2 ¤ 1.

Solution. Again, we first find all critical points, and then we analyze the boundary.
Interior: If f takes its maximum or minimum value at a point in the interior, x2 + y2 1,
then that point must be a critical point of f . To find the critical points19 we compute the
first order derivatives.

                      fx = 3x2 + y2 ¡ 6x fy = 2xy ¡ 8y

These are polynomials (in two variables) and they are defined everywhere. So the critical
points are the solutions of

                         fx = 3x2 + y2 ¡ 6x = 0            (E1)

                         fy = 2y(x ¡ 4) = 0                (E2)

The second equation, 2y(x ¡ 4) = 0, is satisfied if and only if at least one of the two

equations y = 0 and x = 4 is satisfied.

· When y = 0, equation (E1) forces x to obey

                         0 = 3x2 + 02 ¡ 6x = 3x(x ¡ 2)

so that x = 0 or x = 2.

· When x = 4, equation (E1) forces y to obey

                        0 = 3 ¢ 42 + y2 ¡ 6 ¢ 4 = 24 + y2

which is impossible.

18 It should intuitively obvious from a sketch that the boundary of the disk x2 + y2 ¤ 1 is the circle

     x2 + y2 = 1. But if you really need a formal definition, here it is. A point (a, b) is on the boundary of a
     set S if there is a sequence of points in S that converges to (a, b) and there is also a sequence of points
     in the complement of S that converges to (a, b).
19 We actually found the critical points in Example 2.3.18. But, for the convenience of the reader, we'll
      repeat that here.

                         62
PARTIAL DERIVATIVES                                      2.4 ABSOLUTE MINIMA AND MAXIMA

So, there are only two critical points: (0, 0), (2, 0).
Boundary: Our boundary is x2 + y2 = 1 We know that (x, y) satisfies x2 + y2 = 1, and

hence y2 = 1 ¡ x2. Examining the formula for f (x, y), we see that it contains only even20
powers of y, so we can eliminate y by substituting y2 = 1 ¡ x2 into the formula.

             f = x3 + x(1 ¡ x2) ¡ 3x2 ¡ 4(1 ¡ x2) + 4 = x + x2

The max and min of x + x2 for ¡1 ¤ x ¤ 1 must occur either

· when x = ¡1 (ñ y = f = 0) or

· when x = +1 (ñ y = 0, f = 2) or

             d (x + x2)                      ¡  1        =¨     3,        ¡ 14 ).
                                                2
·  when 0 =  dx          = 1 + 2x ( so x  =        ,  y         4   f  =

Here is a sketch showing all of the points that we have identified.

                         (- 1 , 3 ) y

                              22

                         (-1, 0)         (0, 0) (1, 0) (2, 0) x

                                      

                         (- 12 , - 32 )

Note that the point (2, 0) is outside the allowed region21. So all together, we have the
following candidates for max and min, with the max and min indicated.

                point    (0, 0)          (¡1, 0)      (1, 0)           c
             value of f    4                            0
                                            2                   ¡ 1,¨ 3
                         max                                        22
                                                                  ¡1
                                                                        4
                                                                  min

                                                                                   Example 2.4.1

 Example 2.4.2

Find the maximum and minimum values of f (x, y) = xy ¡ x3y2 when (x, y) runs over the
square 0 ¤ x ¤ 1, 0 ¤ y ¤ 1.

20 If it ccontained odd powers too, we could cconsider the cases y ¥ 0 and y ¤ 0 separately and substitute
   y = 1 ¡ x2 in the former case and y = ¡ 1 ¡ x2 in the latter case.

21 We found (2, 0) as a solution to the critical point equations (E1), (E2). That's because, in the course of

   solving those equations, we ignored the constraint that x2 + y2 ¤ 1.

                                                          63
PARTIAL DERIVATIVES                                               2.4 ABSOLUTE MINIMA AND MAXIMA

Solution. As usual, let's examine the critical points and boundary in turn.
Interior: If f takes its maximum or minimum value at a point in the interior, 0 x 1,
0 y 1, then that point must be a critical point of f . To find the critical points we
compute the first order derivatives.

                            fx(x, y) = y ¡ 3x2y2 fy(x, y) = x ¡ 2x3y

Again, these functions are polynomials in two variables and they are smooth everywhere
in their domain, so the first order partial derivatives exist everywhere in the interior. This
means that the critical points are the solutions of

            fx = 0          ðñ y(1 ¡ 3x2y) = 0 ðñ y = 0 or 3x2y = 1
            fy = 0          ðñ x(1 ¡ 2x2y) = 0 ðñ x = 0 or 2x2y = 1

· If y = 0, we cannot have 2x2y = 1, so we must have x = 0.
· If 3x2y = 1, we cannot have x = 0, so we must have 2x2y = 1. Dividing gives

            3x2y 3

   1 = 2x2y = 2 which is impossible.

So the only critical point in the square is (0, 0). There f = 0. Boundary: The region is a
square, so its boundary consists of its four sides.

· First, we look at the part of the boundary with x = 0. On that entire side f = 0.

· Next, we look at the part of the boundary with y = 0. On that entire side f = 0.

· Next, we look at the part of the boundary with y = 1. There f = f (x, 1) = x ¡ x3. To

   find the maximum and minimum of f (x, y) on the part of the boundary with y = 1,

  we must find the maximum and minimum of x ¡ x3 when 0 ¤ x ¤ 1.

Recall that, in general, the maximum and minimum of a function h(x) on the interval
a ¤ x ¤ b, must occur either at x = a or at x = b or at an x for which either hI(x) = 0
or hI(x) does not exist.                In this case,  d   (x  ¡  x3)     1 ¡ 3x2, so the max and min of
x ¡ x3 for 0 ¤ x ¤ 1 must occur                        dx              =

- either at x = 0, where f = 0,
- or at x = c1 , where f = c2 ,
                         3                 33
- or at x = 1, where f = 0.

· Finally, we look at the part of the boundary with x = 1. There f = f (1, y) = y ¡ y2.
As  d   (y  ¡  y2           1 ¡ 2y,  the   only  critical  point  of   y ¡ y2  is  at  y     1.  So  the  max  and
    dy             )  =                                                                   =
                                                                                             2
min of y ¡ y2 for 0 ¤ y ¤ 1 must occur

- either at y = 0, where f = 0,
                      1                    1,
-   or at y    =      2  ,  where    f  =
                                           4
- or at y = 1, where f = 0.

All together, we have the following candidates for max and min, with the max and min
indicated.

                                                       64
PARTIAL DERIVATIVES                                2.4 ABSOLUTE MINIMA AND MAXIMA

   point    (0, 0)   (0,0¤y¤1)  (0¤x¤1,0)  (1, 0)  (1,     1  )  (1, 1)  (0, 1)    ( c1 , 1)
value of f    0                              0             2       0       0
                         0          0                                                    3
            min        min        min      min          1        min     min
                                                        4                        3c2 3  0.385

                                                                                     max

                                      y    ( 31 , 1) (1, 1)
                                (0, 1)

                                                   (1,  1  )
                                                        2

                                (0, 0)            x
                                           (1, 0)

                                                                                 Example 2.4.2

 Warning2.4.3 (Checking Entire Boundaries).

A common misconception when students are first learning about "checking
boundaries" is that the absolute extrema will occur on the "corners" of the
boundaries. In the example we just finished, Example 2.4.2, the four corners
of our square boundary were indeed points we needed to check. But if we had
only checked the corners, we wouldn't have found the absolute maximum.
In your homework, if you notice that the extrema often occur at "corners" of
boundaries, or at point with x or y equal to 0, you should not take this to be a
general rule.

    To really see why corners don't need to be important, consider the image22 below of an
area northeast of UBC. The central body of water in the image is Indian Arm. Indian Arm
extends into the ocean, so its elevation is pretty close to sea level. If we're thinking of the
z axis as height above sea level, the surface of Indian Arm is probably the global minimum
height in the rectangular region shown. So, the global minimum along the boundary is not
at a corner. It's somewhere in the middle of the left vertical boundary segment.

22 image generated by Natural Resources Canada's Atlas of Canada - Toporama and shared under the
      open government license

                                                          65
PARTIAL DERIVATIVES      2.4 ABSOLUTE MINIMA AND MAXIMA

Similarly, looking at the mountains in the image, there's no reason to imagine the absolute
highest point along the boundary must specifically happen at a corner.

 Example 2.4.4

Find the high and low points of the surface z = x2 + y2 with (x, y) varying over the

square |x| ¤ 1, |y| ¤ 1 .

Solution. The function f (x, y) = x2 + y2 has a particularly simple geometric interpre-
tation -- it is the distance from the point (x, y) to the origin. So

· the minimum of f (x, y) is achieved at the point in the square that is nearest the
   origin -- namely the origin itself. So (0, 0, 0) is the lowest point on the surface and
   is at height 0.

· The maximum of f (x, y) is achieved at the points in the square that are farthest from
the origin -- namely the four corners of the square  ¨ 1c, ¨1 . At those four points

   c
z = 2. So the highest points on the surface are (¨1, ¨1, 2).

Even though we have already answered this question, it will be instructive to see what
we wouldhave found if we had followed our usual protocol. The partial derivatives of

f (x, y) = x2 + y2 are defined for (x, y) $ (0, 0) and are

                            fx(x, y) =  x x2 + y2 fy(x, y) =  y x2 + y2

· As we mentioned above, at the point (x, y) = (0, 0) the partial derivatives are not
   defined. But (0, 0) is inside the interior of the domain of our function. Therefore,
   (0, 0) is a critical point.

· There are no other critical points because
      - fx = 0 only for x = 0, and
      - fy = 0 only for y = 0.
      - So (0, 0) is the only critical point because fx and fy are not defined there.

                     66
PARTIAL DERIVATIVES      2.4 ABSOLUTE MINIMA AND MAXIMA

· The boundary of the square consists of its four sides. One side is

                          2 (x, y) §§ x = 1, ¡1 ¤ y ¤ 1 @
  On this side f = 1 + y2. As 1 + y2 increases with |cy|, the smallest value of f on
  that side is 1 (when y = 0) and the largest value of f is 2 (when y = ¨1). The same

   thing happens on the other three sides. The maximum value of f is achieved at the
   four corners. Note that fx and fy are both nonzero at all four corners.

                                                                                            Example 2.4.4

 Example 2.4.5 (Disconnecting a Complete Graph)
In graph theory, a complete graph is a collection of n vertices (visualized as dots), every pair
of which is connected by an edge (visualized as lines). The complete graphs on 10 vertices
and on 30 vertices are shown below.

    Suppose you start with the complete graph on 30 vertices. You delete edges (but not
vertices) one-by-one until the graph is broken into three parts. Every part has at least one
vertex (otherwise it wouldn't be a part, it would be a nothing) and there are no edges
between vertices of different parts. Some possibilities are shown below to demonstrate.

                     67
PARTIAL DERIVATIVES                            2.4 ABSOLUTE MINIMA AND MAXIMA

    What is the minimum number of edges you could have deleted, in order to break the
graph into three pieces?
Solution. Let's name the pieces X, Y, and W, and say the numbers of vertices they contain

are x, y, and w, respectively. Then x ¥ 1, y ¥ 1, w ¥ 1, and x + y + w = 30.

    For every vertex in one piece of the broken graph, you must have deleted the edges
connecting it to every vertex in every other piece. So, to delete all the edges from X to
Y, you deleted at least xy edges; to delete all the edges from X to W, you deleted at least
xw edges; and to delete all the edges from Y to W, you deleted at least yw edges. So all
together, you deleted at least this many edges:

                                                xy + xw + yw

Since x + y + w = 30, we can eliminate one of these from our expression, and say the
minimum number of edges deleted was:

                    f (x, y) = xy + x(30 ¡ x ¡ y) + y(30 ¡ x ¡ y)
                          = 30x + 30y ¡ x2 ¡ xy ¡ y2

The domain of this function is all integer pairs in the region bounded by x ¥ 1, y ¥ 1, and
x + y ¤ 29.

                                   y

y = 28

y=1

                     x=1                   x = 28  x
                                                   x + y = 29

To find the minimum value of f (x, y) in this region, we should check for critical points,
and check all three boundary lines.

· First, let's check for critical points.

f (x, y) = 30x + 30y ¡ x2 ¡ xy ¡ y2                fy = 30 ¡ 2y ¡ x
   fx = 30 ¡ 2x ¡ y

Solving fx = 0 for y, we find y = 30 ¡ 2x. Plugging into the equation fy = 0, we get:

0 = fy = 30 ¡ 2(30 ¡ 2x) ¡ x
      = 3x ¡ 30

x = 10

y = 30 ¡ 2x = 10

                                           68
PARTIAL DERIVATIVES  2.4 ABSOLUTE MINIMA AND MAXIMA

So, our only critical point is (10, 10), and this is inside our region.

                f (10, 10) = 300 + 300 ¡ 100 ¡ 100 ¡ 100 = 300

· Second, let's check the boundary line y = 1, 1 ¤ x ¤ 28. On this portion of the

   boundary:

                        f (x, y) = 30x + 30y ¡ x2 ¡ xy ¡ y2
                              = 30x + 30 ¡ x ¡ x ¡ 1

                                            = 28x + 29

   This is an increasing function, so its minimum will be at the smallest value of x in
   our interval: x = 1.

                                                 f (1, 1) = 57

· Third, we check the boundary line x = 1, 1 ¤ y ¤ 28. On this portion of the

   boundary:

                        f (x, y) = 30x + 30y ¡ x2 ¡ xy ¡ y2
                              = 30 + 30y ¡ 1 ¡ y ¡ y

                                            = 28y + 29

   This is an increasing function, so its minimum will be at the smallest value of y in
   our interval: y = 1.

                                                 f (1, 1) = 57

· Fourth, we check the final boundary line, y = 29 ¡ x, 1 ¤ x ¤ 28. On this portion of

   the boundary:

               f (x, y) = 30x + 30y ¡ x2 ¡ xy ¡ y2
                     = 30x + 30(29 ¡ x) ¡ x2 ¡ x(29 ¡ x) ¡ (29 ¡ x)2
                     = ¡x2 + 29x + 29

  The one-variable function g(x) = ¡x2 + 29x + 29 is a parabola pointing down, so its

   minimum will occur at and endpoint of our interval: x = 1 or x = 28.

                                     f (1, 28) = 57 f (28, 1) = 57

Comparing the values from the four bullet points, we find the minimum number of edges
we could have deleted in order to break the complete graph into 3 pieces is 57. We achieve
that minimum by having two pieces of one vertex each, and the remaining piece with all
other vertices.

                                                          69
PARTIAL DERIVATIVES                                               2.5 LAGRANGE MULTIPLIERS

    Remark 1: making use of sketching and symmetry can reduce the amount of work
involved in solving this problem. If we recognize that f (x, y) is a paraboloid opening
down, then we know its critical point will actually be an absolute max - not the minimum
we're looking for.

    We can see the x and y are symmetric in f (x, y) and in our region, so we also could
have checked only the boundary x = 1, and not the boundary y = 1, understanding that
their minimum values would be the same.

Remark 2: Our model domain for this problem actually restricts x and y to whole-
number values, as opposed to real numbers. We showed that 57 was the minimum value
of f (x, y) over all real numbers in the sketched region. Since whole numbers are them-
selves reals, and the minimum occurred at integer value of x and y (i.e. the minimum is
in our model domain), we can be sure that 57 is the minimum over all whole numbers in
our  domain.  If  the  minimum  had  occurred  at,  say  x     1  and  y     1,  then  it  wouldn't  have
                                                            =  2          =
                                                                             2
been in our model domain - and this would be a problem for a different course!

                                                                                       Example 2.4.5

2.5 Lagrange Multipliers

     In the last section we had to solve a number of problems of the form "What is the maxi-
     mum value of the function f on the curve C?" In those examples, the curve C was simple
     enough that we could reduce the problem to finding the maximum of a function of one
     variable. For more complicated problems this reduction might not be possible. In this sec-
     tion, we introduce another method for solving such problems. First some nomenclature.

                                                               70
PARTIAL DERIVATIVES  2.5 LAGRANGE MULTIPLIERS

 Definition2.5.1.
A problem of the form
 "Find the maximum and minimum values of the function f (x, y) for (x, y) on

       the curve g(x, y) = 0."
is one type of constrained optimization problem. The function being maximized or
minimized, f (x, y), is called the objective function. The function, g(x, y), whose
zero set is the curve of interest, is called the constraint function.

    Such problems are quite common. As we said above, we have already encountered
them in the last section on absolute maxima and minima, when we were looking for the
extreme values of a function on the boundary of a region. In economics "utility functions"
are used to model the relative "usefulness" or "desirability" or "preference" of various
economic choices. For example, a utility function U(w, ) might specify the relative level
of satisfaction a consumer would get from purchasing a quantity w of wine and  of coffee.
If the consumer wants to spend $100 and wine costs $20 per unit and coffee costs $5 per
unit, then the consumer would like to mazimize U(w, ) subject to the constraint that
20w + 5 = 100.

    To this point we have always solved such constrained optimization problemsby solv-
ing g(x, y) = 0 for y as a function of x (or for x as a function of y). However, quite often
the function g(x, y) is so complicated that one cannot explicitly solve g(x, y) = 0 for y
as a function of x or for x as a function of y and one also cannot explicitly parametrize
g(x, y) = 0. Or sometimes you can, for example, solve g(x, y) = 0 for y as a function
of x, but the resulting solution is so complicated that it is really hard, or even virtually
impossible, to work with. Direct attacks become even harder in higher dimensions when,
for example, we wish to optimize a function f (x, y, z) subject to a constraint g(x, y, z) = 0.

    There is another procedure called the method of "Lagrange23 multipliers" that comes
to our rescue in these scenarios. Here is the two-dimensional version of the method. There
are obvious analogues is other dimensions.

23 Joseph-Louis Lagrange was actually born Giuseppe Lodovico Lagrangia in Turin, Italy in 1736. He
      moved to Berlin in 1766 and then to Paris in 1786. He eventually acquired French citizenship and then
      the French claimed he was a French mathematician, while the Italians continued to claim that he was
      an Italian mathematician.

                                                          71
PARTIAL DERIVATIVES  2.5 LAGRANGE MULTIPLIERS

 Theorem2.5.2 (Lagrange Multipliers).

Let f (x, y) and g(x, y) have continuous first partial derivatives in a region of R2
that contains the surface S given by the equation g(x, y) = 0. Further assume
that g(x, y) has no critical points on S.
If f , restricted to the surface S, has a local extreme value at the point (a, b) on S,
then there is a real number  such that

                                       fx(a, b) =  gx(a, b)
                                       fy(a, b) =  gy(a, b)

The number  is called a Lagrange multiplier.

    A proof of this theorem can be found in Appendix A.6.
    So to find the maximum and minimum values of f (x, y) on a surface g(x, y) = 0,
assuming that both the objective function f (x, y) and constraint function g(x, y) have con-
tinuous first partial derivatives, and that g(x, y)hasnocritical points, you

   1. build up a list of candidate points (x, y, z) by finding all solutions to the equations
                                                fx(x, y) =  gx(x, y)
                                                fy(x, y) =  gy(x, y)
                                                 g(x, y) = 0

       Note that there are three equations and three unknowns, namely x, y, and .

   2. Then you evaluate f (x, y) at each (x, y) on the list of candidates. The biggest of these
       candidate values is the absolute maximum, if an absolute maximum exists. The
       smallest of these candidate values is the absolute minimum, if an absolute minimum
       exists..

    Theorem 2.5.2 can be extended to functions of more variables in a natural way. Using
higher-dimensional Lagrange isn't in our learning goals, but for interest, we want you to
see how easily the method generalizes. The calculus is the same - it's only the algebra that
gets longer.

                                                          72
PARTIAL DERIVATIVES                          2.5 LAGRANGE MULTIPLIERS

 Theorem2.5.3 ((Optional) Lagrange Multipliers for Functions of Three Variables).

Let f (x, y, z) and g(x, y, z) have continuous first partial derivatives in a region
of R3 that contains the surface S given by the equation g(x, y, z) = 0. Further
assume that g(x, y, z) has no critical points on S.
If f , restricted to the surface S, has a local extreme value at the point (a, b, c) on
S, then there is a real number  such that

                                    fx(a, b, c) =  gx(a, b, c)
                                    fy(a, b, c) =  gy(a, b, c)
                                     fz(a, b, c) =  gz(a, b, c)

The number  is called a Lagrange multiplier.

  Now for a bunch of examples.
Example 2.5.4

Find the maximum and minimum of the function x2 ¡ 10x ¡ y2 on the ellipse whose equa-

tion is x2 + 4y2 = 16.
Solution. For this first example, we'll do out the algebra in truly gory detail. Once you
get the hang of it, it'll go much faster.

    Our objective function (the one we want to maximize and/or minimize) is f (x, y) =

x2 ¡ 10x ¡ y2 and the constraint function is g(x, y) = x2 + 4y2 ¡ 16. To apply the method of

Lagrange multipliers we start by computing the first-order derivatives of these functions.

   fx = 2x ¡ 10 fy = ¡2y gx = 2x gy = 8y

So, according to the method of Lagrange multipliers, we need to find all solutions to the
following system of equations.

   fx = gx                                   2x ¡ 10 = (2x)     (E1)

   fy = gy                           ùñ      ¡2y = (8y)         (E2)

   g(x, y) = 0                               x2 + 4y2 ¡ 16 = 0  (E3)

(E1) In equation (E1), if 2x is nonzero, then we can divide both sides of the equation by it,
                                x¡5
   2x¡10                             . If 2x = 0, then the equation becomes ¡10 = 0,
to find  = 2x , i.e.  =         x

which is not true for any .

(E2) In equation (E2), if 8y is nonzero, then we can divide both sides of the equation by it,

   ¡2y                       1
to find  = 8y , i.e.  = ¡ . If 8y = 0, then we also get a solution y = 0 for any
                             4
.

(E1)+(E2) We need all three equations to be true at the same time (that is, for the same
       values of x, y, and . We've found two ways for both (E1) and (E2) to be true.

                                         73
PARTIAL DERIVATIVES                                               2.5 LAGRANGE MULTIPLIERS

·  First way:        =  x¡5  and     =  ¡  1
                                           4
                         x x¡5

·  Second way:          =   x   and y   =0

(E3) Now we'll see which points make (E1) and (E2) true while also making (E3) true.

·  First way:        =  x¡5  and     =  ¡  1
                                           4
                         x

                                      = x ¡ 5 x and  = ¡14
                                ùñ x ¡ 5 = ¡1
                                                      x       4
                                ùñ            ¡4x + 20 = x
                                ùñ
                                                         x=4

   In order to satisfy (E3):

                                                         0 = 42 + 4y2 ¡ 16

                                                         0=y

   So, the point (x, y) = (4, 0) satisfies all three equations.

·  Second way:          =  x¡5  and y   = 0.  If y  = 0, then from E3, we see

                            x

                                        0 = x2 + 4 ¤ 02 ¡ 16

                                        16 = x2

                                        x = ¨4

   So the points to consider are (x, y) = (¨4, 0) .

  Now we've found the only possible solutions to all three equations: (¨4, 0). ( has

to exist, but we don't actually care what it is.) So the method of Lagrange multipliers,
Theorem 2.5.2, gives that the only possible locations of the maximum and minimum of

the function f are (4, 0) and (¡4, 0). To complete the problem, we only have to compute f

at those points.

                                point         (4, 0)     (¡4, 0)
                             value of f
                                              ¡24           56
                                                          max
                                              min

Hence the maximum value of x2 ¡ 10x ¡ y2 on the ellipse is 56 and the minimum value is
¡24.

                                               y
                           x2 ` 4y2 " 16

                             p´4,0q                      p4,0q x

                                              74
PARTIAL DERIVATIVES                                  2.5 LAGRANGE MULTIPLIERS

                                                     Example 2.5.4

    In the previous example, we had to make a lot of decisions about how to solve for the
solutions to the system of three equations. Actually, we can start our Lagrange system-
solving the same way every time. The first observation we make is that the partial deriva-
tives of g can be 0, or nonzero. If they're zero, this may or may not lead to a solution; if
they're nonzero, this tells us something about .

    In the textbook and problem book, we will consistently use the same method to solve
the system of equations. It's certainly not the only way, and you are free to use other
methods. Once you get used to the computations, you'll probably start finding ways to
make them faster based on the specifics of individual problems.

 Example 2.5.5 (Solving Lagrange in General)

Suppose you want to find all points (x, y) for which a solution exists to the system below.

                                  fx = gx                (E1)

                                  fy = gy                (E2)

                                  g(x, y) = 0            (E3)

where  is some real constant. Our method below will hinge on the observation from the
last example that we get different solutions for zero vs. nonzero partial derivatives of the
constraint.

· If gx $ 0 and gy $ 0, then from (E1) we see  = gx , and from (E2) we see  = gy . So,fxfy

choosing a pair (x, y) such that  fx gx = fy gy

means that for some , that pair makes (E1) and (E2) true. Simplify the equation
above to find the necessary relationship between x and y, then find which pairs with
that relationship make (E3) true.

· If gx = 0, then from (E1) we see also fx = 0. Then (E1) is true for any  that we like.
   We can check that there exists some  that makes (E2) true as well. Then, we find
   the points (x, y) that make (E3) true as well as gx = fx = 0.

· If gy = 0, then from (E2) we see also fy = 0. Then (E2) is true for any  that we like.
   We can check that there exists some  that makes (E1) true as well. Then, we find
   the points (x, y) that make (E3) true as well as gx = fx = 0.

    Sometimes, one or more of these cases won't lead to any solutions. In Example 2.5.4,
we were immediately able to discard the possibility gx = 0, because it didn't lead to
a solution. Once you're practiced with these types of problems, you'll often see quite
quickly which cases you get to discard.

                                                                                                Example 2.5.5

                                  75
PARTIAL DERIVATIVES                                       2.5 LAGRANGE MULTIPLIERS

  We'll apply our three-case breakdown in subsequent examples.
Example 2.5.6

Find the minimum and maximum values of the objective function

       f (x, y) = ln x2 ¡ 2x + 5 + ln y2 ¡ 4y + 13

subject to the constraint  x2 ¡ 2x + y2 ¡ 4y = 20

Solution. Our constraint function is

                       g(x, y) = x2 ¡ 2x + y2 ¡ 4y ¡ 20 = 0

We start by setting up the first two equations from the method of Lagrange multipliers.

             fx = gx                         2 2x ¡ 2 = (2x ¡ 2) (E1)
             fy = gy                        x ¡ 2x + 5
       g(x, y) = 0
                                              2y ¡ 4
                                            y2 ¡ 4y + 13 = (2y ¡ 4) (E2)

                                            x2 ¡ 2x + y2 ¡ 4y = 20                    (E3)

Now we consider our three cases.

·  gx  $ 0 and gy $ 0. From (E1), this means  =   21 .    From  (E2),    =      1.

                                                 x ¡2x+5                    y2¡4y+13

                     1            1
       x2 ¡ 2x + 5 = y2 ¡ 4y + 13

       x2 ¡ 2x + 5 = y2 ¡ 4y + 13

                     x2 ¡ 2x = y2 ¡ 4y + 8

   This gives us the relationship between x and y that must hold for (E1) and (E2) to be

   true under the assumption gx $ 0 and gy $ 0. Now, in order for (E3) to be true as

   well:

                           0 = (x2 ¡ 2x) + y2 ¡ 4y ¡ 20

                           = (y2 ¡ 4y + 8) + y2 ¡ 4y ¡ 20

                           = 2y2 ¡ 8y ¡ 12

                           0 = y2 ¡ 4y ¡ 6                c
                           y = 4 ¨ 16 ¡ 4(1)(¡6) = 4 ¨ 40 = 2 ¨ c10

                                     2                    2
                        So, 0 = (x2 ¡ 2x) + y2 ¡ 4y ¡ 20
                           = x2 ¡ 2x + 2 ¨ c10 2 ¡ 4(2 ¨ c10) ¡ 20
                           = x2 ¡ 2x + 4 ¨ 4c10 + 10 ¡ 8 © 4c10 ¡ 20

                                     76
PARTIAL DERIVATIVES                                         2.5 LAGRANGE MULTIPLIERS

    Note ¨4c2 © 4c2 = 0

                         = x2 ¡ 2x + 4 + 10 ¡ 8 ¡ 20

                         = x2 ¡ 2x ¡ 14                     c
                         x = 2 ¨ 4 ¡ 4(¡14) = 2 ¨ 2 15 = 1 ¨ c15

                                  2                 2

This gcives us focur points tco considecr:          cc                  cc
1 + 15, 2 + 10 , 1 ¡ 15, 2 + 10 , 1 + 15, 2 ¡ 10 , and 1 ¡ 15, 2 ¡ 10 .

· If gx = 0, then x = 1, and (E1) is true for any . Then we can choose whatever  is
   necessary to make (E2) true. By (E3):

                                0 = x2 ¡ 2x + y2 ¡ 4y ¡ 20
                                 = 1 ¡ 2 + y2 ¡ 4y ¡ 20
                                 = y2 ¡ 4y ¡ 21
                                 = (y ¡ 7)(y + 3)

                                y = 7, y = ¡3

This gives us two points to consider: (1, 7) and (1, ¡3).

· If gy = 0, then y = 2, and (E2) is true for any . Then we can choose whatever  is
   necessary to make (E1) true. By (E3):

                                0 = x2 ¡ 2x + y2 ¡ 4y ¡ 20
                                 = x2 ¡ 2x + 4 ¡ 8 ¡ 20
                                 = x2 ¡ 2x ¡ 24
                                 = (x ¡ 6)(x + 4)

                                x = 6, x = ¡4

This gives us two points to consider: (¡4, 2) and (6, 2).

    So, all together we have eight points that satisfy our three Lagrange equations. It's left
only to decide which of those points lead to maxima and to minima.

   point    (1 + c15, 2 + c10)  (1 ¡ c15, 2 + c10)  (1 + c15, 2 ¡ c10)  (1 ¡ c15, 2 ¡ c10)
value of f
                    ln 361              ln 361              ln 361              ln 361
                     max                 max                 max                 max

               point            (¡4, 2)     (6, 2)  (1, 7)  (1, ¡3)
            value of f                      ln 261  ln 136
                                ln 261               min    ln 136
                                                             min

                                            77
PARTIAL DERIVATIVES                                                  2.5 LAGRANGE MULTIPLIERS

Our maximum value is ln 361, and our minimum value is ln 136.

                                                                               Example 2.5.6

 Example 2.5.7

Find the ends of the major and minor axes of the ellipse 3x2 ¡ 2xy + 3y2 = 4. They are the

points on the ellipse that are farthest from and nearest to the origin.

Solution. Let (x, y) be a point on 3x2 ¡ 2xy + 3y2 = 4. This point is at the end of a major

axis when it maximizes its distance from the centre of the ellipse, (0, 0). It is at the end
of a minor axis when i t minimizes its distance from (0, 0). So we wish to maximize and
minimize the distance x2 + y2 subject to the constraint

                        g(x, y) = 3x2 ¡ 2xy + 3y2 ¡ 4 = 0

Now maximizing/minimizing x2 + y2 is equivalent24 to maximizing/minimizing its
square x2 + y2 2 = x2 + y2. So we are free to choose the objective function

                                        f (x, y) = x2 + y2

which we will do, because it makes the derivatives cleaner. Again, we use Lagrange
multipliers to solve this problem, so we start by finding the partial derivatives.

   fx(x, y) = 2x fy(x, y) = 2y gx(x, y) = 6x ¡ 2y gy(x, y) = ¡2x + 6y

We need to find all solutions to

                                                  2x = (6x ¡ 2y)                          (E1)

                                                  2y = (¡2x + 6y)                         (E2)

                                3x2 ¡ 2xy + 3y2 ¡ 4 = 0                                   (E3)

·  If  gx  $  0 and  gy  $  0,  then    =    2x   =    x   by (E1),  and    =      2y  =      y  by

   (E2).                                   6x¡2y     3x¡y                      ¡2x+6y     ¡x+3y

                                                x= y

                                           3x ¡ y ¡x + 3y
                                        ¡x2 + 3xy = 3xy ¡ y2

                                                  x2 = y2

                                               x = ¨y

   So if x = ¨y, then the appropriate  will make both (E1) and (E2) true. Now let's see

24 The function S(z) = z2 is a strictly increasing function for z ¥ 0. So, for a, b ¥ 0, the statement "a b"

     is equivalent to the statement "S(a) S(b)".

                                                          78
PARTIAL DERIVATIVES                                  2.5 LAGRANGE MULTIPLIERS

what makes (E3) true.                   ùñ           x = ¨c when x = ¡y1

      4 = 3x2 ¡ 2xy + 3y2                                  2
      4 = 3(¨y)2 ¡ 2(¨y)y + 3y2         ùñ           x = ¨1 when x = y

       = 3y2 © 2y2 + 3y2
       = (6 © 2)y2

        4 = (6 + 2)x2

      4 = (6 ¡ 2)x2

This gives us four points to check: the two points ¨ c1 , ¡c1 and the two points22
¨(1, 1)

· If gx = 0, then 6x ¡ 2y = 0, i.e. y = 3x. By (E1), x = 0, so y = 0. Then (E3) doesn't

   hold, so this leads to no solutions.

· If gy = 0, then ¡2x + 6y = 0, i.e. x = 3y. By (E2), y = 0, so x = 0. Then (E3) doesn't
hold, so this leads to no solutions.
The distance from (0, 0) to ¨(1, 1), namely c2, is larger than the distance from (0, 0)
to ¨ c1 , ¡c1 , namely 1. So the ends of the minor axes are ¨ c1 , ¡c1 and the ends of
the major axes are ¨(1, 1). Those ends are sketched in the figure on the left below. Once2222

we have the ends, it is an easy matter25 to sketch the ellipse as in the figure on the right
below.

                        y                            y

                     ?     p1,1q                  ?           p1,1q
           p´1,1q{ 2                    p´1,1q{ 2

                                     x                                     x

                                     ?                                  ?
                           p1,´1q{ 2                          p1,´1q{ 2

           p´1,´1q                      p´1,´1q

                                            3x2 ´ 2xy ` 3y2 " 4

                                                                                                Example 2.5.7

    In the previous examples, the objective function and the constraint were specified ex-
plicitly. That will not always be the case. In the next example, we have to do a little
geometry to extract them.

25 if you tilt your head so that the line through (1, 1) and (¡1, ¡1) appears horizontal

                                                          79
PARTIAL DERIVATIVES                                                  2.5 LAGRANGE MULTIPLIERS

 Example 2.5.8
Find the rectangle of largest area (with sides parallel to the coordinates axes) that can be
inscribed in the ellipse x2 + 2y2 = 1.
Solution. Since this question is so geometric, it is best to start by drawing a picture.

                                           y        px, yq
                        x2 ` 2y2 " 1                       x

                      p´x, ´yq                      px, ´yq

    Call the coordinates of the upper right corner of the rectangle (x, y), as in the figure

above. Note that x ¥ 0 and y ¥ 0; and if x = 0 or y = 0, then the area of the rectangle is

0, which is certainly not a maximum. So the global maximum must occur at some point
where x and y are both positive. This will also be a local maximum, so we should be able
to find it using the method of Lagrange multipliers.

  The four corners of the rectangle are (¨x, ¨y) so the rectangle has width 2x and height

2y and the objective function is f (x, y) = 4xy. The constraint function for this problem is

g(x, y) = x2 + 2y2 ¡ 1. Again, to use Lagrange mutlipliers we need the first order partial

derivatives.
                             fx = 4y fy = 4x gx = 2x gy = 4y

So, according to the method of Lagrange multipliers, we need to find all solutions to

                                                4y = (2x)                                          (E1)

                                                4x = (4y)                                          (E2)

                                  x2 + 2y2 ¡ 1 = 0                                                 (E3)

·  If gx  $ 0 and gy  $ 0, then   =  4y  =  2y  from (E1) and        =  4x  =  x  from (E2).  So,
                                     2x     x                           4y     y

                                                2yx = xy

                                                2y2 = x2 x = (¨c2)y

                                                80
PARTIAL DERIVATIVES                                       2.5 LAGRANGE MULTIPLIERS

From (E3),

                     (¨c2)y  2 + 2y2 ¡ 1 = 0

                             2y2 + 2y2 = 1

                                       4y2 = 1

                                             y = ¨12   c    1

                                             x = (¨ 2)y = ¨c  2

So there are four points to consider:  ¨ c12  ,  ¨1    .
                                                    2

· If gx = 0, i.e. 2x = 0, then x = 0; by (E1) also y = 0; but then (E3) fails. So this
   doesn't give us any more points to consider.

· If gy = 0, i.e. 4y = 0, then y = 0; by (E2) also x = 0; but then (E3) fails. So this
   doesn't give us any more points to consider either.

  We now have four possible values of (x, y), namely 1/c2 , 1/2 , ¡ 1/c2 , ¡1/2 , 1/c2 , ¡1/2
and ¡ 1/c2 , 1/2 . They are the four corners of a single rectangle. We said that we wanted

(x, y) to be the upper right corner, i.e. the corner in the first quadrant. It is 1/c2 , 1/2 .

    How do we interpret the other three points we found? The global min of the function
4xy subject to the constraint x2 + 2y2 = 1 will occur at one of these points, but those
points aren't in our model domain. When x and y have different signs, 4xy no longer
gives the area of a rectangle, since it's negative. Over our model domain, we kind of
have "endpoints:" x = 0 and y = 0. Our maximum occurred somewhere between our
endpoints; our model minimum occurs at the endpoints.

                                                                                                Example 2.5.8

2.5.1  Bounded vs Unbounded Constraints

       In the last example, we had to think a little extra about whether the solution to the La-
       grange equations gave a maximum or minimum. Take a closer look at Theorem 2.5.2: all
       local extrema will occur at a solution point. So when do the solution points definitely also
       include all absolute extrema?

          1. If our constraint function is a closed curve (circle, ellipse, square, etc.) and our ob-
              jective function is continuous over it, then there will certainly be an absolute max
              and absolute min over the constraint; and these will certainly also be local extrema.
              So when our constraint is a closed curve, and our objective function is continuous
              over it, we are guaranteed that the absolute max and min exist, and are at points that
              satisfy the Lagrange equations.
                                                                 81
PARTIAL DERIVATIVES  2.5 LAGRANGE MULTIPLIERS

       In Section 2.4 we considered domains that were bounded by a closed curve, so we
       only considered boundaries of this type.
   2. If our constraint function is not a closed curve (e.g. a line, a line segment, a function
       like xy = 1, etc.) then the system is more complicated. Assume that the objective
       function is continuous over the constraint curve. Since our constraint curve is one-
       dimensional (like a line, but a line that has some orientation in space), we're in a
       similar position as we were in single-variable calculus: extrema can occur at end-
       points, or at "critical points." In our case, "critical points" translate to solutions to
       the Lagrange equations; "endpoints" mean pretty much the same thing they always
       have.
        (a) If the constraint function is bounded, we must consider its endpoints as well

             as solutions to the Lagrange system. There will be an absolute maximum and
             minimum, and these will definitely occur at solutions to the Lagrange system
             or at the endpoints of the constraint.

        (b) If the constraint function is unbounded, there may or may not exist absolute ex-
             trema. This is where you'll most heavily rely on your understanding of function
             shape and behaviour. Limits can be useful here.

 Example 2.5.9

Find the values of w ¥ 0 and  ¥ 0 that maximize the utility function

               U(w, ) = 6w2/31/3 subject to the constraint 4w + 2 = 12
                                                          82
PARTIAL DERIVATIVES  2.6 UTILITY AND DEMAND FUNCTIONS

Solution. The constraint 4w + 2 = 12 is simple enough that we can easily use it to

express  in terms of w, then substitute  = 6 ¡ 2w into U(w, ), and then maximize
U(w, 6 ¡ 2w) = 6w2/3(6 ¡ 2w)1/3 using the techniques of last semester.

    However, for practice purposes, we'll use Lagrange multipliers with the objective func-

tion U(w, ) = 6w2/31/3 and the constraint function g(w, ) = 4w + 2 ¡ 12. The first order

derivatives of these functions are

                 Uw = 4w¡1/31/3 U = 2w2/3¡2/3 gw = 4 g = 2

The boundary values ("endpoints") w = 0 and  = 0 give utility 0, which is obviously not
going to be the maximum utility. So it suffices to consider only local maxima. According
to the method of Lagrange multipliers, we need to find all solutions to

                     4w¡1/31/3 = 4                                             (E1)

                     2w2/3¡2/3 = 2                                             (E2)

                     4w + 2 ¡ 12 = 0                                           (E3)

Then we see gx $ 0 and gw $ 0, so we only have one of our usual three cases.

   · equation (E1) gives  = w¡1/31/3.
   · Substituting this into (E2) gives w2/3¡2/3 =  = w¡1/31/3 and hence w = .

· Then substituting w =  into (E3) gives 6 = 12.

So w =  = 2 and the maximum utility is U(2, 2) = 12.

    Note in this example we had a bounded (but not closed) curve. It has endpoints (0, 6)
and (3, 0). Since the maximum didn't occur at the endpoints, then the global maximum
was also a local maximum, and so it showed up as a solution to the system of Lagrange
equations.

                                                                                                Example 2.5.9

    Chapter 2 was adapted from Chapter 2 of CLP 3 - Multivariable Calculus by Feld-
man, Rechnitzer, and Yeager under a Creative Commons Attribution-NonCommercial-
ShareAlike 4.0 International license.

2.6 Utility and Demand Functions

     Economists use the concept of utility to define the welfare of an entity or an individual.
     The utility function measures the level of satisfaction or happiness that a consumer gains
     from various actions, like consumption, leisure, etc. One such form of utility function,
     discussed below, represents a constrained optimization problem: where consumers, given
     their preferences for two goods, maximize welfare or level of happiness from consuming
     particular combinations of goods or services, given finite resources or income.

         The amount consumed should be a non-negative number, so we'll restrict our domains
     accordingly.

                                                               83
PARTIAL DERIVATIVES                                                        2.6 UTILITY AND DEMAND FUNCTIONS

     Let x be a variable representing a quantity of good X, and let u(x) be the utility func-
                                                                              du  ¡
tion    for  that  good.      If  "more    is   better,"  then  we    expect  dx      0  for  all  nonnegative         x  (i.e.  for

all  x  in   the  model       domain).     We   can  think  of    du   as  marginal      utility:  the   gain    in  happiness
of getting just a little more of something.                       dx

     Suppose good X is subject to "diminishing returns." That is, as we get more of the
good (i.e. as x increases) each additional unit brings us less happiness than the last. Then
                                                                       d2 u
our   marginal         utility    du  is  decreasing,     meaning      dx2       0. Since most goods are subject to
                                  dx
diminishing returns, we often choose utility functions that are concave down.
     Utility functions can encompass more than one good. A multivariable utility func-
tion u(x, y) might give the happiness associated with consuming quantity x of good X
alongside quantity y of good Y. Just like with single-variable utility functions, if "more is
better"      than  fu     ¡   0   and  fu  ¡    0  everywhere.        If  there  are  diminishing        returns,    then  also
                   fx                  fy
f2u                f2u
fx  2 0 and 2 0 everywhere.fy

2.6.1  Constrained Optimization of the Utility Function

Example 2.6.1

Suppose a consumer's preferences lead to the utility function

                                                     u(x, y) = x2 + 2y

for consuming a combination of x units of good X and y units of good Y.

  For these goods, "more is better" (because ux ¡ 0 and uy ¡ 0 for all non-negative x

and y) without diminishing returns.26
    Good X costs 2 dollars per unit, good Y costs 3 dollars per unit, and the consumer has

10 dollars to spend on these two goods.
    Find the combined consumption of goods X and Y that maximizes the utility function,

subject to the constraint that the consumer spends at most 10 dollars. What is that maxi-
mum utility?

Solution. This is a constrained optimization problem. Our objective function (what we

want to maximize) is                                 u(x, y) = x2 + 2y

Our constraint function comes from our budget and the prices of the two goods:

                                                g(x, y) = 2x + 3y ¡ 10 = 0

(Since "more is better," there's no incentive to spend less than our budget of ten dollars.)
     We     can   solve   this    by   substitution.      From    our     constraint,  we  see     y     10¡2x .     That  turns
                                                                                                      =
                                                                                                            3
our utility function into the following:

                              u(x, y) = x2 + 2y = x2 + 23 (10 ¡ 2x) = x2 ¡ 43 x + 203

26   Indeed,      f2u  ¡  0,  meaning     each  subsequent  unit  of  the  good  associated   with    x  brings  more  happiness
                  fx2
     than the last - a hallmark that this equation is fabricated for practice purposes, and probably isn't a
     realistic utility function of actual goods. The idea of increasing (rather than diminishing) returns can
     make for an interesting thought experiment, though.

                                                                84
PARTIAL DERIVATIVES                              2.6 UTILITY AND DEMAND FUNCTIONS

This is a parabola pointing up, so its maximum will be at an endpoint of our interval.

Since x and y are quantities, we require x ¥ 0 and y ¥ 0.

                          0 ¤ y = 10 ¡ 2x 3 ùñ x ¤ 5

Our model domain is 0 ¤ x ¤ 5. The endpoint x = 5 corresponds to all $10 going to the
first good (and y = 0). The endpoint x = 0 corresponds to all $10 going to the second
good  (with  y     10 ).
                =
                   3

                       u(5, 0) = 52 + 2(0) = 25
                   u 0, 103 = 02 + 2 103 = 203

    Our utility is maximized when we spend all $10 on the first good, purchasing x = 5
and y = 0. That maximum utility is 25.

                                                      Example 2.6.1

 Example 2.6.2

Alejandro has recently found a true passion for baking. He likes making two types of
bread: ciabatta (c) and pita (p). Ciabatta costs 20 dollars per unit to make and pita 10
dollars per unit. Alejandro wants to spend 60 dollars on bread, and his utility function27
is as follows:

                                         u(c, p) = ln(c) + 2 ln(p)
Find the optimal consumption for Alejandro and the corresponding maximum utility.
Solution. The utility function will be the objective function and the constraint will be the
budget constraint. The budget constraint is 20c + 10p = 60. We can find the maximum
utility using substitution or the method of Lagrange multipliers.

    Solution 1: substitution

Since 20c + 10p = 60, we see p = 6 ¡ 2c. Then our utility function is:
                  u(c, p) = ln(c) + 2 ln(p) = ln(c) + 2 ln (6 ¡ 2c)

Using log rules,

                  u(c, p) = ln(c) + ln (6 ¡ 2c)2
                        = ln c(7 ¡ 2c)2

27 We're not averse to having negative utility values. Again, utility doesn't have absolute units, but rather
      is useful as a relative scale. Higher utility is better, whether the numbers are positive or not.
     For this particular utility function, c = 0 or p = 0 will minimize utility. This is actually a common
      property of utility functions. It avoids having an optimal solution where one good is not consumed at
      all.

                                                          85
PARTIAL DERIVATIVES                              2.6 UTILITY AND DEMAND FUNCTIONS

Much like the square root function, natural logarithm is an increasing function. So, the

maximum of ln c(6 ¡ 2c)2 will occur at the same place as the maximum of
c(6 ¡ 2c)2, provided that maximum is positive (and thus in the domain of the logarith-

mic function).

                    f (c) = c(6 ¡ 2c)2

Using the product rule,

                    f I(c) = c ¤ 2(6 ¡ 2c)(¡2) + (6 ¡ 2c)2
                        = (6 ¡ 2c) [¡4c + (6 ¡ 2c)]
                        = 12(3 ¡ c)(1 ¡ c)

The critical points of f (c) are c = 1 and c = 3.

                             f (1) = 16                                       We've  already
                             f (3) = 0

We also need to check the endpoints of our interval. Since p ¥ 0, then:
                       0 ¤ p = 6 ¡ 2c ùñ c ¤ 3

The endpoints of our interval are c = 0 (all pita) and c = 3 (all ciabatta).
found f (3) = 0.

                              f (0) = 0

The function c(6 ¡ 2c)2 has a maximum of 16 when c = 1, so the function ln c(6 ¡ 2c)2

has a maximum of ln 16 when c = 1. Since c = 1 means p = 4, utility is maximized when
Alejandro spends $20 on ciabatta, and $40 on pita.

Solution 2: Lagrange

6                     = gc             6  1      =  ¤ 20
                                                 =  ¤ 10
9 8uc                 = gp ùñ          9  c
  up                                   8  2      =0
                                          p
9 7g(c, p)            = 0 9 720c + 10p ¡ 60

From the first two equations, we see

                                = 120c = 2 10p

                               p = 4c

From the constraint equation,

                               0 = 20c + 10p ¡ 60 = 10c + 10(4c) ¡ 60

                               c=1 p=4

    So, the point c = 1 is a point to check. We should also check the endpoints of our
interval, c = 0 and c = 3. Note both these cause the utility to go to negative infinity - so
they are minima. That tells us c = 1, p = 4 gives us our constrained maxima. The utility
of spending $20 on ciabatta and $40 on pita is ln 1 + 2 ln 4 = ln(16).

                                                                       Example 2.6.2

                                             86
PARTIAL DERIVATIVES  2.6 UTILITY AND DEMAND FUNCTIONS

2.6.2  Demand Curves

       A demand curve gives the relationship between the quantity of a good a consumer would
       buy and the price of that good. We assume the consumer would buy the quantity that
       maximizes their utility function, given their budget constraints. In Examples 2.6.1 and
       2.6.2 we found "optimal consumption" when the price and budget were fixed numbers.
       So secretly, we were finding a point on a demand curve.

           Instead of keeping price and budget fixed, we can assign them variables. We can still
       find the amount a consumer would buy to maximize their utility, but now that amount
       will be a function of price and budget, rather than a fixed number. The consumer's opti-
       mal consumption (as a function of price and budget) gives the general demand function.
       This is sometimes formally referred to as Marshallian demand. That is, Marshallian demand
       describes the relationship between the price of a good, the budget for that good, and the
       quantity of that good demanded.

 Definition2.6.3 (Marshallian demand).

Let x be a quantity of good X, let y be a quantity of good Y, and let u(x, y) be the
utility function of these two goods.
Let px be the unit price for good X, and py be the unit price for good Y. Let I be
the amount of a consumer's income they budget for buying X and Y. Then the
function

                                           xm(px, py, I)
giving the optimal consumption of x to maximize u(x, y) subject to the budget
constraint pxx + pyy = I is called the Marshallian demand function.

    Note: the superscript m in the function name xm isn't a power. Rather than denoting a
variable, m simply stands for "Marshallian."

 Example 2.6.4

Let's go back to Alejandro and his passion for baking. This weekend he would like to
make ciabatta (c) and focaccia (f). Ciabatta costs pc dollars to make and focaccia p f dollars.
For this weekend, Alejandro wants to spend I dollars on bread, and his utility function is
as follows:

                                         u(c, f ) = ln(c) + 2 ln( f )

Find the optimal consumption for Alejandro of each bread type.
Solution. The utility function is the objective function, because that's the function we want

to maximize. The constraint is pcc + p f f = I ñ b(c, f ) = cpc + f p f ¡ I.

    As in Example 2.6.2, the endpoints of our interval (c = 0, f = 0) minimize utility, so
the maximum will be at some interior point. We can find it using the method of Lagrange
multipliers.

                                                          87
PARTIAL DERIVATIVES                             2.6 UTILITY AND DEMAND FUNCTIONS

6                            =  ¤ bc      61                   =  ¤ pc
                             = ¤bf                             = ¤ pf
9 8uc                                     9
9 7u f b(c, f )              =0           8c                   =0
                                      ùñ     2
                                          9  f
                                          7cpc + f p f ¡ I

From the first two equations, we see

                                      = 1 = 2

                                          c ¤ pc f ¤ pf

                                      f = 2c pc p f

From the budget constraint,

                                      0 = cpc + f pf ¡ I   pf ¡ I

                                        = cpc + 2c pc p f

                                       = cpc + 2cpc ¡ I

                                      I = 3cpc
                                      c = I3pc

Using the relationship between f and c,

                                      f = 2c pc p f = 2I 3p f

  The point c = 3pI c , f = 32pIf is the only point to consider for a max. Since c ¥ 0 and
f ¥ 0, the point is within our model domain. So, it gives the optimal consumption of

ciabatta and focaccia.
    Let's think of the optimal consumption of each bread type (as functions of prices and

income allocated to bread), and name these functions cm and f m (m for "Marshallian").
Then

                             cm(I, pc, p f ) = I3pc f m(I, pc, p f ) = 2I 3p f
give the Marshallian demand curves for ciabatta and focaccia, respectively.

                                                                                                Example 2.6.4
We use the Marshallian demand to define certain types of goods. A normal good is defined
as a product for which quantity demanded increases as income increases. An inferior good
is defined as a product for which quantity demanded decreases as income increases.

                                                          88
PARTIAL DERIVATIVES                                        2.6 UTILITY AND DEMAND FUNCTIONS

 Definition2.6.5 (Normal and Inferior Goods).

Let xm(px, py, I) be the Marshallian demand function of a good when the price of
that good is px, the price of another good is py, and the amount of a consumer's
income budgeted for these goods is I. If

                           fxm(px, py, I) ¡ 0
                                fI

everywhere then the good is a normal good. If

                           fxm(px, py, I) 0
                                fI

everywhere then the good is an inferior good.

    In the case of Alejandro's example 2.6.4, you can verify that both goods are normal
goods.

      Theorem2.6.6 (Normal and Inferior Goods).
     Let X and Y be two goods with positive unit prices px and py, respectively, subject
     to the budget constraint pxx + pyy = I. If X is an inferior good, then Y is a normal
     good.

Proof. Let xm and ym be the Marshallian demand functions of X and Y, respectively.
    For any quantities x and y, we must satisfy the budget constraint pxx + pyy = I. So:

                                       y = I ¡ pxx py

When x = xm, then y = ym, so:

                                   ym = I ¡ pxxm py
                  ùñ fy = = m f I ¡ pxxm f
                                   fI fI py                     fI  1py I ¡ px py xm
                                          = 1 ¡ px ¤ fxm
                                          py py fI

Since  X  is  an  inferior  good,  by  Definition  2.6.5,  fxm  0. Since also px and py are positive,
then the term ¡ ppx fy fxIm is positive:                   fI

                  ùñ fym ¥ 1 ¡ 0
                           fI py

So, Y is a normal good by Definition 2.6.5.

                                                       89
PARTIAL DERIVATIVES                2.6 UTILITY AND DEMAND FUNCTIONS

    Using the first partial derivative, we can also analyse how changes in prices affect the
Marshallian Demand.

      Definition2.6.7 (Price Effect).
     Let xm(px, py, I) be a Marshallian demand function for a good X whose quantity
     is given by x and unit price is given by px, in relation to another good Y whose
     quantity is given by y and whose unit price s given by py.

                                 fxm(px, py, I)
                                     fpx

     is the rate of change of xm (the optimal consumption of X) relative to the price of
      X. We call this the price effect of X on xm. Similarly,

                                 fxm(px, py, I)
                                     f py

     the rate of change of xm (the optimal consumption of X) relative to the price of Y.
     This is the price effect of Y on xm.

Example 2.6.8 (Price effects)

In this example, we revisit Example 2.6.4.
(a) Are the ciabatta and focaccia from Example 2.6.4 normal goods, or inferior goods?
(b) If the price of making foccacia increases, how will this effect the amount of ciabatta

     Alejandro makes? (Assume everything else stays the same - the utility function stays
     the same, the price of ciabatta stays the same, the portion of income I allotted to bread
     stays the same, and the assumption remains that Alejandro will maximize utility sub-
     ject to his budget constraint.)

Solution.
    To decide whether ciabatta and focaccia are normal or inferior goods, we should take

their partial derivatives with respect to I.

cm(I, pc, p f ) = I3pc             f m(I, pc, p f ) = 2I 3p f

      fc = m 1 ¡ 0                       f f = m 2 ¡ 0
       fI 3pc                             fI 3pf

Since both derivatives are positive everywhere, ciabatta and focaccia are both normal
goods.

    Surprisingly, the price of focaccia doesn't affect the consumption of ciabatta at all! The
Marshallian demand of ciabatta is

                                             cm(I, pc, p f ) = I3pc

                               90
PARTIAL DERIVATIVES                                  2.6 UTILITY AND DEMAND FUNCTIONS

Since p f doesn't even show up, the derivative is easy to take:

                                   fc = m 0
                                   fpf

That means the price effect of focaccia on Alejandro's ciabatta baking is zero. (If the price
of focaccia goes up, the impact on his baking habits are that he will make less focaccia.)

                                                                                                Example 2.6.8

Example 2.6.9

Kenechukwu is doing groceries for the week, and as usual he has I dollars to spend on
fruits and berries. If he consumes a kg of apples and s kg of strawberries, then his utility
function is:

                                              u(a, s) = a1/2s1/4
Apples cost pa dollars per kg, and strawberries cost ps dollars per kg.

    Find Kenechukwu's Marshallian demand function for apples. What is the price effect
of ps on apples? Are apples normal or inferior goods?
Solution. The utility function will be the objective function, because utility is what we
want to maximize. As in Example 2.6.2, the endpoints a = 0 and s = 0 are minima of the
utility function. (We see this because setting either a = 0 or s = 0 leads to u = 0; and since
u involves even roots, it never returns a negative value.) So, the maximum will happen at
some internal point, which we can find using Lagrange multipliers.

  The budget constraint is paa + pss = I ñ b(a, s) = paa + pss ¡ I.

               6              =  ¤ ba   9 6 1 a¡1/2s1/42     =  ¤ pa
                                                             =  ¤ ps
               9 8ua                    8
               9 7ub b(a, s)  =  ¤ bb ùñ 1 a1/2s¡3/4         =0
                                        94    paa + pss ¡ I
                              =0
                                        7

From the first two equations, we see

                            = 12pa a¡1/2s1/4 = 14ps a1/2s¡3/4
               2psa¡1/2s1/4 = paa1/2s¡3/4

                2pss1/4+3/4 = paa1/2+1/2
                         2pss = paa
                         2ps pa s = a

Now, to satisfy the budget constraint,

               pa 2ps pa s + pss = I                 a = 2ps pa s = 2ps pa ¤ I3ps = 2I 3pa

                              3pss = I
                                  s = I3ps ,

                                                 91
PARTIAL DERIVATIVES                           2.6 UTILITY AND DEMAND FUNCTIONS

So, our Marshilian demand function are

                     am(pa, ps, I) = 2I 3pa sm(pa, ps, I) = I3ps

The price effect of ps on apples is nothing, since

                                    fa = m 0
                                    f ps

The goods are both normal, because

                     fa = m 2 ¡ 0       fs = m 1 ¡ 0
                     fI 3pa             fI 3ps

    The optimal consumption is 1 kg of strawberries and 4 kg of apples. This leads to the
maximum utility, u(4, 1) = 2.

                                                                                                Example 2.6.9

    So far, our paradigm has been to optimize happiness, given a fixed budget. We could
instead fix the desired amount of utility, and try to minimize the cost required to achieve
it. In this paradigm, our utility function is our constraint, while our cost function is the
objective function we want to minimize. This gives rise to the Hicksian demand.

      Definition2.6.10 (Hicksian demand).
     Let goods X and Y have utility function u(x, y), where x is the quantity of X and
     y is the quantity of Y. Let px be the unit price of good X, and py be the unit price
     of good Y. Let U be the minimum level of utility required by the consumer - that

   is, the consumer requires u(x, y) ¥ U.

     The Hicksian demand function of good X, denoted
                                                xh(px, py, U),

     gives the value of x that minimizes the cost function f (x, y) = pxx + pyy subject

   to the constraint u(x, y) ¥ U. That is, the Hicksian demand function gives the

     quantity of good X that minimizes the amount of money spent on the two goods
     while still achieving some fixed level of utility.

    Note: the superscript h in the function name xh isn't a power. Rather than denoting a
variable, h simply stands for "Hicksian."

    The definition requires that the utility be at least some fixed constant. In practice, we
can usually assume that the utility is equal to that fixed constant. That's because if we have
a higher utility than necessary, we can usually save some money by bringing our utility
down to its minimum allowable level. This could fail only if, at some point, our utility
function had a negative partial derivative. A negative partial derivative indicates that we
might increase utility as we decrease consumption.

                                                          92
PARTIAL DERIVATIVES                                    2.6 UTILITY AND DEMAND FUNCTIONS

Example 2.6.11

Lets go back to Alejandro and his passion for baking. This weekend he would like to make
ciabatta (c) and baguettes (B). Ciabatta costs pc dollars to make and baguettes pb dollars.
His utility function is as follows:
                                                    c
                                         u(c, b) = cb

Fixing Alejandro's utility as the constant u(c, b) = U, find his Hicksian demand for both
types of bread.

Solution. In Hicksian demand, we minimizeccost, so cost is our objective function. That is,

f (c, b) = pcc + pbb. Our constraint is U = cb. We can find the constrained minimum of
f (c, b) using substitution.

                         U = ccb

                                   U2 = cb
                                      c = U2 b

Plugging this into our objective function,

                               f (c, b) = pcc + pbb = pc Ub + 2 pbb =  U2 pc  b¡1 + pbb
This is a function of one variable. Let's find the critical points.

                     0 = ¡ U2 pc b¡2 + pb

                U2 pc b¡2 = pb

                     Upb = 2 pc b2
                                   pc

                          b = U pb

At that point, c = U2  = U pb        b
                                                pc

To verify that this critical point gives a global minimum, consider the second derivative
of our one-variable function.

ddb ¡ U2 pc b¡2 + pb = 2 U2 pc b¡3

Our model domain only allows for non-negative values of b, so the second derivative is
non-negative everywhere. That means its globa l minimum is at its sole critical point. In
particular, the quantities c = U ppbc and b = U ppcb minimize the cost function f (c, b) =
pcc + pbb subject to the constraint u(c, b) = U. So, our Hicksian demand functions are:

ch  (pc, pb, U) = U pb and bh  (pc, pb, U) = U pc
                                     pc                                pb

                                                93
PARTIAL DERIVATIVES      2.6 UTILITY AND DEMAND FUNCTIONS

                                                                                                Example 2.6.11

  In Example 2.6.11, note ffpchb $ 0. This is in contrast to examples 2.6.8 and 2.6.9, where

the price effects of one good's price on the other good's consumption were both 0. Hick-
sian demand is sometimes used to study the substitution effect, where a change in price in
one good causes a change in consumption of another good. This discussion is, however,
beyond the scope of the current text.

 Example 2.6.12 (Contrasting Marshallian and Hicksian Demand)
In Marshallian demand, the consumer has a fixed budget, and tries to be as happy as pos-
sible. In Hicksian demand, the consumer has a fixed utility need, and tries to be as thrifty
as possible. These different models fit different types of transactions.

    You have $1000 to invest in stocks. You choose the combination of stocks that you
think will have the best mix of risk and reward, spending your entire budget. You're
operating under a generally Marshallian mindset, because you want the most utility for a
fixed budget.

    After you purchase your stocks, you're so excited that you accidentally spill ramen on
your laptop, and need a new one right away. Your laptop needs to be of a sufficient quality
for your needs - some combination of available soon, reliable, fast enough, and so on. You
go to your local gadget store and identify all the models that will meet your needs. You
buy the cheapest of those options. For the laptop, your demand is more Hicksian - you
want to find the cheapest option that still meets your needs.

                                                                                                Example 2.6.12

                     94
Chapter 3

           INTEGRATION

Calculus is built on two operations -- differentiation and integration.
    · Differentiation -- as we saw last term, differentiation allows us to compute and
       study the instantaneous rate of change of quantities. At its most basic it allows
       us to compute tangent lines and velocities, but it also led us to quite sophisticated
       applications including approximation of functions through Taylor polynomials and
       optimisation of quantities by studying critical points.
    · Integration -- at its most basic, allows us to analyse the area under a curve. Of
       course, its application and importance extend far beyond areas and it plays a central
       role in solving differential equations.

     It is not immediately obvious that these two topics are related to each other. However, as
     we shall see, they are indeed intimately linked.

3.1 Definition of the Integral

     Arguably the easiest way to introduce integration is by considering the area between the
     graph of a given function and the x-axis, between two specific vertical lines -- such as is
     shown in the figure above. We'll follow this route by starting with a motivating example.

                                                               95
INTEGRATION                                                   3.1 DEFINITION OF THE INTEGRAL

 A Motivating Example

Let  us  find 2the  area§  under  the  curve  y  =  ex  (and  above  the  x-axis)  for  0  ¤  x  ¤  1.  That  is,

                                                    @
the area of (x, y) § 0 ¤ y ¤ ex, 0 ¤ x ¤ 1 .

This area is equal to the "definite integral"

                                                                               »1

                                               Area = exdx

                                                                                 0

Do not worry about this notation or terminology just yet. We discuss it at length below.
In different applications this quantity will have different interpretations -- not just area.
For example, if x is time and ex is your velocity at time x, then we'll see later (in Exam-
ple 3.1.12) that the specified area is the net distance travelled between time 0 and time 1.
After we finish with the example, we'll mimic it to give a general definition of the integral

³b

 a f (x)dx.
 Example 3.1.1

We wish to compute the area of 2 (x, y) §§ 0 ¤ y ¤ ex, 0 ¤ x ¤ 1 @. We know, from our

experience with ex in differential calculus, that the curve y = ex is not easily written in
terms of other simpler functions, so it is very unlikely that we would be able to write the
area as a combination of simpler geometric objects such as triangles, rectangles or circles.

    So rather than trying to write down the area exactly, our strategy is to approximate the
area and then make our approximation more and more precise1. We choose2 to approx-
imate the area as a union of a large number of tall thin (vertical) rectangles. As we take
more and more rectangles we get better and better approximations. Taking the limit as
the number of rectangles goes to infinity gives the exact area3.

    As a warm up exercise, we'll now just use four rectangles. In Example 3.1.2, below,
we'll consider an arbitrary number of rectangles and then take the limit as the number of
rectangles goes to infinity. So

1 This should remind the reader of the approach taken to compute the slope of a tangent line way way
      back at the start of differential calculus.

2 Approximating the area in this way leads to a definition of integration that is called Riemann integra-
      tion. This is the most commonly used approach to integration. However we could also approximate the
      area by using long thin horizontal strips. This leads to a definition of integration that is called Lebesgue
      integration. We will not be covering Lebesgue integration in these notes.

3 If we want to be more careful here, we should construct two approximations, one that is always a little
      smaller than the desired area and one that is a little larger. We can then take a limit using the Squeeze
      Theorem and arrive at the exact area. More on this later.

                                                          96
INTEGRATION                                  3.1 DEFINITION OF THE INTEGRAL

  · subdivide the interval 0 ¤ x ¤ 1 into 4 equal subintervals each of width 1/4, and

    · subdivide the area of interest into four corresponding vertical strips, as in the figure
       below.

The area we want is exactly the sum of the areas of all four strips.

             y y = ex

                         4 2 4 1 1 3 1 x

Each of these strips is almost, but not quite, a rectangle. While the bottom and sides are
fine (the sides are at right-angles to the base), the top of the strip is not horizontal. This
is where we must start to approximate. We can replace each strip by a rectangle by just
levelling off the top. But now we have to make a choice -- at what height do we level off
the top?

    Consider, for example, the leftmost strip. On this strip, x runs from 0 to 1/4. As x
runs from 0 to 1/4, the height y runs from e0 to e1/4. It would be reasonable to choose the
height of the approximating rectangle to be somewhere between e0 and e1/4. Which height

                      y                   y = ex

             e1/4 e0

                         1                x

                         4

should we choose? Well, actually it doesn't matter. When we eventually take the limit of
infinitely many approximating rectangles all of those different choices give exactly the
same final answer. We'll say more about this later.

    In this example we'll do two sample computations.
    · For the first computation we approximate each slice by a rectangle whose height is

       the height of the left hand side of the slice.
          - On the first slice, x runs from 0 to 1/4, and the height y runs from e0, on the left
             hand side, to e1/4, on the right hand side.

                                                          97
INTEGRATION                                         3.1 DEFINITION OF THE INTEGRAL

- So we approximate the first slice by the rectangle of height e0 and width 1/4,
and          hence   of  area  1  e0     1.
                               4      =
                                         4

- On the second slice, x runs from 1/4 to 1/2, and the height y runs from e1/4 and
   e1/2.

- So we approximate the second slice by the rectangle of height e1/4 and width
1/4,         and  hence  of  area     1  e1/4.
                                      4

- And so on.

- All together, we approximate the area of interest by the sum of the areas of the
  four approximating rectangles, which is

                                         1 + e1/4 + e1/2 + e3/4 14 = 1.5124

- This particular approximation represents the shaded area in the figure on the
  left below. Note that, because ex increases as x increases, this approximation is
  definitely smaller than the true area.

y                                                                               y = ex
                   y = ex

                                                y

                  1      2        3      4x         1  2  3                  4x

                  4      4        4      4          4  4  4                  4

· For the second computation we approximate each slice by a rectangle whose height
   is the height of the right hand side of the slice.

- On the first slice, x runs from 0 to 1/4, and the height y runs from e0, on the left
  hand side, to e1/4, on the right hand side.

- So we approximate the first slice by the rectangle of height e1/4 and width 1/4,
and          hence   of  area  1  e1/4.
                               4

- On the second slice, x runs from 1/4 to 1/2, and the height y runs from e1/4 and
   e1/2.

- So we approximate the second slice by the rectangle of height e1/2 and width
1/4,         and  hence  of  area     1  e1/2.
                                      4

- And so on.

                                                98
INTEGRATION  3.1 DEFINITION OF THE INTEGRAL

- All together, we approximate the area of interest by the sum of the areas of the
  four approximating rectangles, which is
                                 e1/4 + e1/2 + e3/4 + e1 14 = 1.9420

- This particular approximation represents the shaded area in the figure on the
  right above. Note that, because ex increases as x increases, this approximation is
  definitely larger than the true area.

                                                                                     Example 3.1.1

    Now for the full computation that gives the exact area.
 Example 3.1.2

Recall that we wish to compute the area of 2 (x, y) §§ 0 ¤ y ¤ ex, 0 ¤ x ¤ 1 @ and that our

strategy is to approximate this area by the area of a union of a large number of very thin
rectangles, and then take the limit as the number of rectangles goes to infinity. In Exam-
ple 3.1.1, we used just four rectangles. Now we'll consider a general number of rectangles,

that we'll call n. Then we'll take the limit n Ñ V. So

    · pick a natural number n and

  · subdivide the interval 0 ¤ x ¤ 1 into n equal subintervals each of width 1/n, and

    · subdivide the area of interest into corresponding thin strips, as in the figure below.
The area we want is exactly the sum of the areas of all of the thin strips.

             y y = ex

                                                 n n 1 2 · · · nn x
Each of these strips is almost, but not quite, a rectangle. As in Example 3.1.1, the only
problem is that the top is not horizontal. So we approximate each strip by a rectangle, just
by levelling off the top. Again, we have to make a choice -- at what height do we level off
the top?

    Consider, for example, the leftmost strip. On this strip, x runs from 0 to 1/n. As x runs
from 0 to 1/n, the height y runs from e0 to e1/n. It would be reasonable to choose the height
of the approximating rectangle to be somewhere between e0 and e1/n. Which height should
we choose?

                                                          99
INTEGRATION                                                         3.1 DEFINITION OF THE INTEGRAL

    Well, as we said in Example 3.1.1, it doesn't matter. We shall shortly take the limit

n Ñ V and, in that limit, all of those different choices give exactly the same final answer.

We won't justify that statement in this example, but Appendix section A.10.4 provides the
justification. For this example we just, arbitrarily, choose the height of each rectangle to be
the height of the graph y = ex at the smallest value of x in the corresponding strip4. The
figure on the left below shows the approximating rectangles when n = 4 and the figure
on the right shows the approximating rectangles when n = 8.

           y                      y = ex                     y                     y = ex

                     1       2    3       4x                        12345678 x

                     4       4    4       4                         88888888

Now we compute the approximating area when there are n strips.

· We approximate the leftmost strip by a rectangle of height e0. All of the rectangles
   have    width   1/n.  So  the  leftmost  rectangle      has   area  1 e0.

                                                                       n

·  On strip number 2,        x runs from     1  to    2.  So the smallest value of x on strip number 2
       1,                                    n                                             e1/n
           and   we                  strip            n   2  by  a  rectangle                    and  hence  of
   is  n             approximate            number                             of  height
   area 1 e1/n.
           n

· And so on.

·  On the last strip, x runs from    n¡1     to    n  = 1.   So the smallest value of x on the last strip
       n¡1 ,                                       n                                       e(n¡1)/n
   is         and  we   approximate   n      last   strip    by  a  rectangle  of  height            and  hence
        n                            the
   of area 1 e(n¡1)/n.
              n

The total area of all of the approximating rectangles is

       Total approximating area = 1n e0 + 1n e1/n + 1n e2/n + 1n e3/n + ¤ ¤ ¤ + 1n e(n¡1)/n
                              = 1 1 + e1/n + e2/n + e3/n + ¤ ¤ ¤ + e(n¡1)/n

                                                 n
Now the sum in the brackets might look a little intimidating because of all the exponen-
tials, but it actually has a pretty simple structure that can be easily seen if we rename
e1/n = r. Then

4 Notice that since ex is an increasing function, this choice of heights means that each of our rectangles is
      smaller than the strip it came from.

                                                      100
INTEGRATION                                            3.1 DEFINITION OF THE INTEGRAL

    · the first term is 1 = r0 and
   · the second term is e1/n = r1 and
   · the third term is e2/n = r2 and
   · the fourth term is e3/n = r3 and

    · and so on and

   · the last term is e(n¡1)/n = rn¡1.

So

              Total approximating area = 1n 1 + r + r2 + ¤ ¤ ¤ + rn¡1

The sum in brackets is known as a geometric sum and satisfies a nice simple formula:

                                                       Equation 3.1.3(Geometric sum).

                   1 + r + r2 + ¤ ¤ ¤ + rn¡1 = rn ¡ 1  provided r $ 1
                                         r¡1

The derivation of the above formula is not too difficult. So let's derive it in a little aside.

 Geometric Sum

Denote the sum as

                   S = 1 + r + r2 + ¤ ¤ ¤ + rn¡1

Notice that if we multiply the whole sum by r we get back almost the same thing:

                   rS = r 1 + r + r2 + ¤ ¤ ¤ + rn¡1
                     = r + r2 + r3 + ¤ ¤ ¤ + rn

This right hand side differs from the original sum S only in that

· the right hand side is missing the "1+ " that S starts with and

· the right hand side has an extra "+rn " at the end that does not appear in S.

That is

                                   rS = S ¡ 1 + rn

Moving this around a little gives

                             (r ¡ 1)S = (rn ¡ 1)
                                   S = rn ¡ 1
                                        r¡1

as required. Notice that the last step in the manipulations only works providing r $ 1

(otherwise we are dividing by zero).

                                   101
INTEGRATION                                      3.1 DEFINITION OF THE INTEGRAL

 Back to Approximating Areas

Now we can go back to our area approximation armed with the above result about geo-
metric sums.

Total approximating area = 1n 1 + r + r2 + ¤ ¤ ¤ + rn¡1  remember that r = e1/n
                      = 1 rn ¡ 1
                         n r¡1
                         1 en/n ¡ 1
                      = n e1/n ¡ 1
                         1 e¡1
                      = n e1/n ¡ 1

    To get the exact area5 all we need to do is make the approximation better and better

by taking the limit n Ñ V. The limit will look more familiar if we rename 1/n to X. As n

tends to infinity, X tends to 0, so

             Area  =  lim  1 e¡1
                              e1/n ¡ 1
                      nÑV  n

                   = (e ¡ 1) nlÑimV 1/n 1/n
                              e ¡1
                   = (e ¡ 1) lim XX
                              XÑ0 e ¡ 1                  (with X = 1/n)

Examining this limit we see that both numerator and denominator tend to zero as X Ñ

0, and so we cannot evaluate this limit by computing the limits of the numerator and
denominator separately and then dividing the results. Despite this, the limit is not too
hard to evaluate; here we give two ways:

· Perhaps the easiest way to compute the limit is by using l'Ho^ pital's rule6. Since both
   numerator and denominator go to zero, this is a 0/0 indeterminate form. Thus

                      lim XX  = lim          dX  = lim X1 = 1

                                             dX
                      XÑ0 e ¡ 1 XÑ0 dX (e ¡ 1) XÑ0 e
                                             dX

· Another way7 to evaluate the same limit is to observe that it can be massaged into
   the form of the limit definition of the derivative. First notice that

                          lim XX = lim eX ¡ 1 ¡1
                         XÑ0 e ¡ 1 XÑ0 X

5 We haven't proved that this will give us the exact area, but it should be clear that taking this limit will
      give us a lower bound on the area. To complete things rigorously we also need an upper bound and
      the Squeeze Theorem. We do this in the next optional subsection.

6 If you do not recall L'Ho^ pital's rule and indeterminate forms then we recommend you skim over your
      differential calculus notes on the topic.

7 Say if you don't recall l'Ho^ pital's rule and have not had time to revise it.

                                                         102
INTEGRATION                   3.1 DEFINITION OF THE INTEGRAL

provided this second limit exists and is nonzero. This second limit should look a
little familiar:

             lim e = X ¡ 1 lim eX ¡ e0
             XÑ0 X            XÑ0 X ¡ 0

which is just the definition of the derivative of ex at x = 0. Hence we have

             lim XX =         lim eX ¡ e0 ¡1
                              XÑ0 X ¡ 0
             XÑ0 e ¡ 1
                              d eX§§ ¡1 §
                           =
                           =  dX X=0

                              eX§§ ¡1 X=0

                    =1

So, after this short aside into limits, we may now conclude that

                           Area = (e ¡ 1) lim XX
                                        XÑ0 e ¡ 1

                                = e¡1

                                                                  Example 3.1.2

A more rigorous area computation can be found in Appendix A.7

3.1.1  Summation Notation

       As you can see from the above example (and the more careful rigorous computation), our
       discussion of integration will involve a fair bit of work with sums of quantities. To this
       end, we make a quick aside into summation notation. While one can work through the
       material below without this notation, proper summation notation is well worth learning,
       so we advise the reader to persevere.

           Writing out the summands explicitly can become quite impractical -- for example, say
       we need the sum of the first 11 squares:

                              1 + 22 + 32 + 42 + 52 + 62 + 72 + 82 + 92 + 102 + 112
       This becomes tedious. Where the pattern is clear, we will often skip the middle few terms
       and instead write

                                    1 + 22 + ¤ ¤ ¤ + 112.

       A far more precise way to write this is using  (capital-sigma) notation. For example, we
       can write the above sum as

                                                               ¸ 11 k2

                                                                                k=1

       This is read as

                                                                103
INTEGRATION                                                       3.1 DEFINITION OF THE INTEGRAL

       The sum from k equals 1 to 11 of k2.
More generally

   Notation3.1.4.

   Let m ¤ n be integers and let f (x) be a function defined on the integers. Then we

   write

                                                                    ¸ n

                                                      f (k)

                                                                k=m

   to mean the sum of f (k) for k from m to n:

                  f (m) + f (m + 1) + f (m + 2) + ¤ ¤ ¤ + f (n ¡ 1) + f (n).

   Similarly we write

                                                     ¸ n

                                                         ai

                                                     i=m

   to mean

                      am + am+1 + am+2 + ¤ ¤ ¤ + an¡1 + an
   for some set of coefficients tam, . . . , anu.

   Consider the example

                                      ¸ 7 1 1 1 1 1 1
                                            = 2+ 2+ 2+ 2+ 2

                                     k=3 k2 3 4 5 6 7
It is important to note that the right hand side of this expression evaluates to a number8; it
does not contain "k". The summation index k is just a "dummy" variable and it does not
have to be called k. For example

                                   ¸ 7 1 ¸ 7 1 ¸ 7 1 ¸ 7 1
                                           = 2= 2=
                                   k=3 k2 i=3 i j=3 j =3          2

Also the summation index has no meaning outside the sum. For example

                                                     k  ¸ 7 1

                                                        k=3 k  2

has no mathematical meaning; it is gibberish.

8  Some  careful  addition  shows  it  is  46181

                                           176400 .

                                                        104
INTEGRATION                                               3.1 DEFINITION OF THE INTEGRAL

    A sum can be represented using summation notation in many different ways. If you
are unsure as to whether or not two summation notations represent the same sum, just
write out the first few terms and the last couple of terms. For example,

                      ¤ ¤ ¤ hkmki =3kkj hkmki =4kkj hkmki =5kkj     hmkki =1kk4j hmkki =1kk5j

             ¸ 15 1 = 1 + 1 + 1 +                                + 142 1 + 152 1
             m=3 m2 32 42 52

                     hkmki =4kkj hkmki =5kkj hkmki =6kkj         hmkki =1kk5j hmkki =1kk6j
     = + + + ¸ 16 1 1 1 1 ¤ ¤ ¤ + 1 + 1
     m=4 (m ¡ 1)2 32 42 52                                       142      152

are equal.
    Here is a theorem that gives a few rules for manipulating summation notation.

Theorem3.1.5 (Arithmetic of Summation Notation).

Let n ¥ m be integers. Then for all real numbers c and ai, bi, m ¤ i ¤ n.

       ° n    ° n

(a) cai = c      ai

      i=m    i=m

        ° n           ° n          ° n

(b) (ai + bi) =          ai +         bi

      i=m            i=m          i=m

(c) ° n (ai ¡ bi) =  ° n ai ¡      ° n

      i=m            i=m              bi

                                  i=m

Proof. We can prove this theorem by just writing out both sides of each equation, and
observing that they are equal, by the usual laws of arithmetic9. For example, for the first
equation, the left and right hand sides are

¸ n  cai = cam + cam+1 + ¤ ¤ ¤ + can and c     ¸ n        ai = c(am + am+1 + ¤ ¤ ¤ + an)

i=m                                            i=m

They are equal by the usual distributive law. The "distributive law" is the fancy name for
c(a + b) = ca + cb.

    Not many sums can be computed exactly10. Here are some that can. The first few are
used a lot.

9 Since all the sums are finite, this isn't too hard. More care must be taken when the sums involve an
      infinite number of terms. We will examine this in Chapter 5.

10 Of course, any finite sum can be computed exactly -- just sum together the terms. What we mean by
      "computed exactly" in this context, is that we can rewrite the sum as a simple, and easily evaluated,
      formula involving the terminals of the sum. For example

             ¸ r n k = rn+1 ¡ rm                          provided r $ 1
                       r¡1

             k=m

                                          105
INTEGRATION                                   3.1 DEFINITION OF THE INTEGRAL

Theorem3.1.6.

° n i        1¡rn+1
(a) ar = a 1¡r , for all real numbers a and r $ 1 and all integers n ¥ 0.
i=0

(b) ° n 1 = n, for all integers n ¥ 1.

      i=1

       ° n 1

(c) i = 2 n(n + 1), for all integers n ¥ 1.

      i=1

       ° n 2 1

(d) i = 6 n(n + 1)(2n + 1), for all integers n ¥ 1.

      i=1

       ° n 3 1 2

(e) i = 2 n(n + 1) , for all integers n ¥ 1.

      i=1

 Proof of Theorem 3.1.6
Proof. (a) The first sum is

                                                    ¸ n

                            ari = ar0 + ar1 + ar2 + ¤ ¤ ¤ + arn

                                                 i=0

    which is just the left hand side of equation (3.1.3), with n replaced by n + 1 and then
     multiplied by a.

(b) The second sum is just n copies of 1 added together, so of course the sum is n.

(c) The sum ° n i = 1 + 2 + 3 + ¤ ¤ ¤ + n can be visualized as the area of the red stairsteps

                      i=1

     below: the first column has area 1, the second column has area 2, and so on.

No matter what finite integers we choose for m and n, we can quickly compute the sum in just a few
arithmetic operations. On the other hand, the sums,

                     ¸ n 1                           ¸ n 1
                     k=m k                           k=m k2

cannot be expressed in such clean formulas (though you can rewrite them quite cleanly using integrals).
To explain more clearly we would need to go into a more detailed and careful discussion that is beyond
the scope of this course.

                                        106
INTEGRATION       3.1 DEFINITION OF THE INTEGRAL

             123  n

If we duplicate those stairsteps and spin them around, we make a rectangle with base
n + 1 and height n.

            Since the red stairsteps are exactly half the total area of that rectangle,
                                                      ¸ n i = 1 (n)(n + 1)
                                                        i=1 2

       (d) The last two identities are proved in Question 29 of Section 5.2 of the practice book.

3.1.2  The Definition of the Definite Integral

                                                                                                                »b

      In this section we give a definition of the definite integral f (x)dx generalising the ma-

                                                                                                                   a

       chinery we used in Example 3.1.1. But first some terminology and a couple of remarks to
       better motivate the definition.

                                                                107
INTEGRATION                                            3.1 DEFINITION OF THE INTEGRAL

 Notation3.1.7.

                      »b

The symbol f (x)dx is read "the definite integral of the function f (x) from

                         a ³b

a to b". The function f (x) is called the integrand of a f (x)dx and a and b are

called11 the limits of integration. The interval a ¤ x ¤ b is called the interval of

integration and is also called the domain of integration.

    Before we explain more precisely what the definite integral actually is, a few remarks
(actually -- a few interpretations) are in order.

                                                                                                            »b

  · If f (x) ¥ 0 and a ¤ b, one interpretation of the symbol f (x)dx is "the area of the
    region 2 (x, y) §§ a ¤ x ¤ b, 0 ¤ y ¤ f (x) @". a

             y                                                       y = f (x)

                a                                      bx

                                                                                                                                          ³1 x

   In this way we can rewrite the area in Example 3.1.1 as the definite integral 0 e dx.

· This interpretation breaks down when either a ¡ b or f (x) is not always positive,

   but it can be repaired by considering "signed areas".

                                                                                                               ³b

· If a ¤ b, but f (x) is not always positive, one interpretation of a f (x)dx is "the signed
  area between y = f (x) and the x-axis for a ¤ x ¤ b". For "signed area" (which

   is also called the "net area"), areas above the x-axis count as positive while areas
   below the x-axis count as negative. In the example below, we have the graph of the
   function

                                    6                  if 1 ¤ x ¤ 2
                                                       if 2 x ¤ 4
                         9 8¡1
                                                       otherwise
                   f (x) = 2
                            9 70

The 2 ¢ 2 shaded square above the x-axis has signed area +2 ¢ 2 = +4. The 1 ¢ 1
shaded square below the x-axis has signed area ¡1 ¢ 1 = ¡1. So, for this f (x),

                   »5

                     f (x)dx = +4 ¡ 1 = 3

                     0

11 a and b are also called the bounds of integration.

                   108
INTEGRATION                                                   3.1 DEFINITION OF THE INTEGRAL

                           y
                          2

                                                      +            signed area= +4

                                    1          2              4x
                                       - signed area= -1

                          -1

    · We'll come back to the case b a later.

                                                  ³b

We're now ready to define a f (x)dx. The definition is a little involved, but essentially
mimics what we did in Example 3.1.1 (which is why we did the example before the defini-
tion). The main differences are that we replace the function ex by a generic function f (x)
and we replace the interval from 0 to 1 by the generic interval12 from a to b.

· We start by selecting any natural number n and subdividing the interval from a to b
                                                                     b¡a .
   into  n   equal  subintervals.   Each  subinterval    has  width
                                                                      n

· Just as was the case in Example 3.1.1 we will eventually take the limit as n Ñ V,

   which squeezes the width of each subinterval down to zero.

·  For each integer 0     ¤   i  ¤  n, define  xi  =  a+i¤  b¡a .  Note that this means that  x0  =  a

                                                             n
   and xn = b. It is worth keeping in mind that these numbers xi do depend on n even
   though our choice of notation hides this dependence.

· Subinterval number i is xi¡1 ¤ x ¤ xi. In particular, on the first subinterval, x
   runs from x0           a to x1      a + b¡a .   On the second subinterval, x runs from x1 to
                2 b¡a .=            =
                                                n
   x2     a         n
       =     +

                    y
                                                                       y = f (x)

                          a = x0 x1 x2 x3 · · ·                                         x
                                                                     xn-1 xn = b

12 We'll eventually allow a and b to be any two real numbers, not even requiring a  b. But it is easier to
      start off assuming a b, and that's what we'll do.

                                                   109
INTEGRATION                                                     3.1 DEFINITION OF THE INTEGRAL

·  On  each   subinterval      we   now  pick   x¦     between xi¡1 and xi.        ¦      We then approximate

          on  the  ith                   the      i,n     function                 i,        .  We              in  the
   f (x)                subinterval  by         constant            y     f     x                   include  n
                                                                       =     (         n  )

   subscript to remind ourselves that these numbers depend on n.

   Geometrically, we're approximating the region

              2            §                                                                             @
                   (x, y) § x is between xi¡1 and xi, and y is between 0 and f (x)

   by the rectangle

              2         §                                                                            ¦@
                 (x, y) § x is between xi¡1 and xi, and y is between 0 and f (xi,n)

   In  Example     3.1.1   we  chose  x¦     =  xi¡1   and  so  we  approximated                the  function   ex  on

                                        i,n
   each subinterval by the value it took at the leftmost point in that subinterval.

· So, when there are n subintervals our approximation to the signed area between the
   curve y = f (x) and the x-axis, with x running from a to b, is

                                              ¸ n ¦ b ¡ a
                                                 f (xi,n) ¤

                                              i=1 n

   We  interpret   this    as  the  signed   area  since  the   summands        f (xi¦,n) ¤         b¡a  need  not  be
   positive.
                                                                                                     n

· Finally we define the definite integral by taking the limit of this sum as n Ñ V.

Oof! This is quite an involved process, but we can now write down the definition we

                                                                                                                                     »b

need. (A more mathematically rigorous definition of the definite integral f (x)dx can
be found in Appendix A.8.) a

                                                         110
INTEGRATION                                               3.1 DEFINITION OF THE INTEGRAL

Definition3.1.8.

Let a and b be two real numbers and let f (x) be a function that is defined for all
x between a and b. Then we define

                      f (x)dx = lim f (xi » b ¸ n ¦,n) ¤ b ¡ a
                      a                nÑV  i=1               n

when the limit exists and takes the same value for all choices of the xi¦,n's. In this

case, we say that f is integrable on the interval from a to b.

    Of course, it is not immediately obvious when this limit should exist. Thankfully it is
easier for a function to be "integrable" than it is for it to be "differentiable".

      Theorem3.1.9.
     Let f (x) be a function on the interval [a, b]. If

         · f (x) is continuous on [a, b], or
         · f (x) has a finite number of jump discontinuities on [a, b] (and is otherwise

             continuous)
     then f (x) is integrable on [a, b].

    We will not justify this theorem. But a slightly weaker statement is proved in (the
optional) Section A.8. Of course this does not tell us how to actually evaluate any definite
integrals -- but we will get to that in time.

    Some comments:

· Note that, in Definition 3.1.8, we allow a and b to be any two real numbers. We do

                                                                                                              ³b

  not require that a b. That is, even when a ¡ b, the symbol a f (x)dx is still defined
                                                                                                                            ³b

   by the formula of Definition 3.1.8. We'll get an interpretation for a f (x)dx, when

  a ¡ b, later.

                                                 ³b
· It is important to note that the definite integral a f (x)dx represents a number, not a
function of x. The inte° gration variable x is another "dummy" variable, just like the
summation index i in     n       (see  Section   3.1.1).  The    integration  variable  does  not

                         i=m ai
have to be called x. For example

                         »b            »b                 »b
                             f (x)dx = f (t)dt = f (u)du
                         a             a                  a

Just as with summation variables, the integration variable x has no meaning outside
of f (x)dx. For example

                             » x 1 » exdx and x exdx
                             0                            0

are both gibberish.

                                       111
INTEGRATION                                                     3.1 DEFINITION OF THE INTEGRAL

    The sum inside definition 3.1.8 is named after Bernhard Riemann13 who made the first
rigorous definition of the definite integral and so placed integral calculus on rigorous
footings.

Definition3.1.10.

The sum inside definition 3.1.8

                            ¸ n ¦ b ¡ a

                                              f (xi,n)
                                           i=1 n

is called a Riemann sum. It is also often written as

                                               ¸ f (xi n ¦) x

                                               i=1

where   x    =  b¡a .                   i b¡a

                 n                         n
If  we  choose  x¦         xi     a            we  obtain  the  approximation
                       =       =     +
                  i,n

                                        ¸ n f a + i b ¡ a       b¡a

                                        i=1 n                     n

                                                                             ³b
which is called the "right Riemann sum approximation to a f (x)dx with n subin-
tervals". The word "right" signifies that, on each subinterval [xi¡1, xi] we approx-
imate   f  by  its  value  at  the   right-hand    end-point,   xi     a     i b¡a ,  of  the  subinterval.
                                                                    =     +
                                                                                n

    In order to compute a definite integral using Riemann sums we need to be able to
compute the limit of the sum as the number of summands goes to infinity. This approach is
not always feasible and we will soon arrive at other means of computing definite integrals
based on antiderivatives. However, Riemann sums also provide us with a good means of
approximating definite integrals -- if we take n to be a large, but finite, integer, then the
corresponding Riemann sum can be a good approximation of the definite integral. Under
certain circumstances this can be strengthened to give rigorous bounds on the integral.
Let us revisit Example 3.1.1.

 Example 3.1.11

                                                                                   ³1 x

Let's say we are again interested in the integral 0 e dx. We can follow the same procedure
as we used previously to construct Riemann sum approximations. However since the in-
tegrand f (x) = ex is an increasing function, we can make our approximations into upper
and lower bounds without much extra work.

  More precisely, we approximate f (x) on each subinterval xi¡1 ¤ x ¤ xi

13 Bernhard Riemann was a 19th century German mathematician who made extremely important con-
      tributions to many different areas of mathematics -- far too many to list here. Arguably two of the
      most important (after Riemann sums) are now called Riemann surfaces and the Riemann hypothesis
      (he didn't name them after himself).

                                                         112
INTEGRATION                                              3.1 DEFINITION OF THE INTEGRAL

   · by its smallest value on the subinterval, namely f (xi¡i), when we compute the Rie-
      mann sum approximation using the left endpoint of each interval for xi¦,n, and

   · by its largest value on the subinterval, namely f (xi), when we compute the right
       Riemann sum approximation.

This is illustrated in the two figures below. The shaded region in the left hand figure is
the Riemann sum approximation using the left endpoint of each interval, and the shaded
region in the right hand figure is the right Riemann sum approximation.

                   y                   y = ex       y                       y = ex

                           n n 1 2 · · · nn x            n n 1 2 · · · nn x

We can see that exactly because f (x) is increasing, the first Riemann sum (using the left

endpoints of each interval for xi¦,n) describes an area smaller than the definite integral,

while the right Riemann sum gives an area larger14 than the integral.

                                                                    ³1 x

    When we approximate the integral 0 e dx using n subintervals, then, on interval num-
ber i,

·  x runs from        i¡1  to  i  and
                               n
                       n
· y = ex runs from e(i¡1)/n, when x is at the left hand end point of the interval, to ei/n,
   when x is at the right hand end point of the interval.

                                                         ³1 x
Consequently, the Riemann sum approximation to 0 e dx using the left endpoint of each
   °n (i¡1)/n 1                                                              °n i/n 1
interval is i=1 e          n and the right Riemann sum approximation is i=1 e ¤ n . So

                                  ¸ n e(i¡1)/n 1 ¤ exdx ¤ ei/n » 1 ¸ n ¤ 1
                                  i=1 n 0                i=1 n

   °n (i¡1)/n 1            n , which for any n can be evaluated by computer, is a lower bound
Thus Ln = i=1 e
                      ³1 x                     °n i/n 1
on the exact value of 0 e dx and Rn = i=1 e n , which for any n can also be evaluated by
                                                         ³1 x
computer, is an upper bound on the exact value of 0 e dx. For example, when n = 1000,

14 When a function is decreasing the situation is reversed -- the Riemann sum using left endpoints is
      always larger than the integral while the right Riemann sum is smaller than the integral. For more
      general functions that both increase and decrease it is perhaps easiest to study each increasing (or
      decreasing) interval separately.

                                               113
INTEGRATION                                                              3.1 DEFINITION OF THE INTEGRAL

Ln = 1.7174 and Rn = 1.7191 (both to four decimal places) so that, again to four decimal
places,

                           » 1.7174 ¤ 1 exdx ¤ 1.7191
                                                                          0

Recall that the exact value is e ¡ 1 = 1.718281828 . . . .

                                                                                             Example 3.1.11

    So far, we have only a single interpretation15 for definite integrals -- namely areas
under graphs. In the following example, we develop a second interpretation.

 Example 3.1.12 (Another Interpretation for Definite Integrals)

Suppose that a particle is moving along the x-axis and suppose that at time t its velocity is
v(t) (with v(t) ¡ 0 indicating rightward motion and v(t) 0 indicating leftward motion).
What is the change in its x-coordinate between time a and time b ¡ a?
We'll work this out using a procedure similar to our definition of the integral. First
pick a natural number n and divide the time interval from a to b into n equal subintervals,
                 b¡a .
each  of  width           We    are  working    our  way      towards    a  Riemann    sum   (as  we         have  done
                  n
several times above) and so we will eventually take the limit n Ñ V.

·     The first time interval runs from a to a +              b¡a .  If we think of n as some large number,
                                           b¡a
      the  width      of  this  interval,                      n      over             time  interval,       the
                                            n   is  very  small  and            this                              velocity
      does not change very much. Hence we can approximate the velocity over the first
      subinterval as being essentially constant at its value at the end of the time interval --

      v   a + a+b     . Over the subinterval the x-coordinate changes by velocity times time,

                   n

      namely v a + a+b ¤ b¡a .n      n

·     Similarly, the second interval runs from time                  a + b¡a     to time     a + 2 b¡a .     Again, we

                                                                              n                         n
      can assume that the velocity does not change very much and so we can approximate
      the velocity as being essentially constant at its value at the end of the subinterval --
                      a + 2 b¡a
      namely v                      . So during the second subinterval the particle's x-coordinate
                                 n

      changes by approximately v                a + 2 b¡a     b¡a .

                                                           n   n

·     In  general,    time  subinterval    number    i    runs  from  a  +  (i  ¡  1)  b¡a  to a + i b¡a     and during

                                                                                        n                 n
      this subinterval the particle's x-coordinate changes, essentially, by

                                                v a + i b ¡ a b ¡ a n n .

15 If this were the only interpretation then integrals would be a nice mathematical curiosity and unlikely
      to be the core topic of a large first year mathematics course.

                                                         114
INTEGRATION                                          3.1 DEFINITION OF THE INTEGRAL

So the net change in x-coordinate from time a to time b is approximately

v a + b ¡ a b ¡ a n n + v a + 2 b ¡ a n  b ¡ a n + ¤ ¤ ¤ + v a + i b ¡ a b ¡ a n n + ¤ ¤ ¤
                                                     +v a+nb¡a b¡a
                                                                    n     n
¸ n = v a + i b ¡ a  b¡a

   i=1 n               n

This exactly the right Riemann sum approximation to the integral of v from a to b with

                                                                                                                          ³b

n subintervals. The limit as n Ñ V is exactly the definite integral a v(t)dt. Following

tradition, we have called the (dummy) integration variable t rather than x to remind us
that it is time that is running from a to b.

    The conclusion of the above discussion is that if a particle is moving along the x-axis
and its x-coordinate and velocity at time t are x(t) and v(t), respectively, then, for all

b ¡ a,

                                              »b

                     x(b) ¡ x(a) = v(t)dt.
                                                a

                                                                       Example 3.1.12

3.1.3  Using Known Areas to Evaluate Integrals

       One of the main aims of this course is to build up general machinery for computing def-
       inite integrals (as well as interpreting and applying them). We shall start on this soon,
       but not quite yet. We have already seen one concrete, if laborious, method for computing
       definite integrals -- taking limits of Riemann sums as we did in Example 3.1.1. A second
       method, which will work for some special integrands, works by interpreting the definite
       integral as "signed area". This approach will work nicely when the area under the curve
       decomposes into simple geometric shapes like triangles, rectangles and circles. Here are
       some examples of this second method.

         Example 3.1.13

³b                                            ³b
The integral a 1dx (which is also written as just a dx) is the area of the shaded rectangle
(of width b ¡ a and height 1) in the figure on the right below. So

                                                  y

»b  dx = (b ¡ a) ¢ (1) = b ¡ a                1

a

                                                     a                 bx

                                                                       Example 3.1.13

                                         115
INTEGRATION                                    3.1 DEFINITION OF THE INTEGRAL

Example 3.1.14

                                         ³b

Let b ¡ 0. The integral 0 xdx is the area of the shaded triangle (of base b and of height b)

in the figure on the right below. So

                                           y                        y=x

                » b xdx = 1 b ¢ b = b2 b22
                0

                                                                                bx

                      ³0

The integral ¡b xdx is the signed area of the shaded triangle (again of base b and of height

b) in the figure on the right below. So

                                           -b       y

                   » 0 xdx = ¡ b2                                x

                   ¡b     2

                                                           -b
                                           y=x

                                                                                                Example 3.1.14

                                                                                                                 ³b

Notice that it is very easy to extend this example to the integral 0 cxdx for any real num-

bers b, c ¡ 0 and find

                          » b cxdx = c b2.2
                          0

Example 3.1.15

                                                             ³1

In this example, we shall evaluate ¡1 (1 ¡ |x|) dx. Recall that
                                   5¡x if x ¤ 0

                              |x| = x if x ¥ 0

so that

                                                5

                                   1 + x if x ¤ 0
                          1 ¡ |x| = 1 ¡ x if x ¥ 0

To picture the geometric figure whose area the integral represents observe that

  · at the left hand end of the domain of integration x = ¡1 and the integrand 1 ¡ |x| =
    1 ¡ | ¡ 1| = 1 ¡ 1 = 0 and

  · as x increases from ¡1 towards 0, the integrand 1 ¡ |x| = 1 + x increases linearly,

       until

                                   116
INTEGRATION                           3.1 DEFINITION OF THE INTEGRAL

  · when x hits 0 the integrand hits 1 ¡ |x| = 1 ¡ |0| = 1 and then
  · as x increases from 0, the integrand 1 ¡ |x| = 1 ¡ x decreases linearly, until

   · when x hits +1, the right hand end of the domain of integration, the integrand hits

    1 ¡ |x| = 1 ¡ |1| = 0.

                          ³1

So the integral ¡1 (1 ¡ |x|) dx is the area of the shaded triangle (of base 2 and of height 1)

in the figure on the right below and

                                                           y

» 1 (1 ¡ |x|) dx = 1 1 ¢ 2 ¢ 1 = 12
¡1

                                      -1                          1x

                                                                  Example 3.1.15

Example 3.1.16

³1 c 2                                c2
The cintegral 0 1 ¡ x dx has integrand f (x) = 1 ¡ x . So it represents the area under
y = 1 ¡ x2 with x running from 0 to 1. But we may rewrite

                
             y = 1 ¡ x2        as         x2 + y2 = 1, y ¥ 0

But this is the (implicit) equation for a circle -- the extra condition that y ¥ 0 makes it

the equation for the semi-circle centred at the origin with radius 1 lying on and above the
x-axis. Thus the integral represents the area of the quarter circle of radius 1, as shown in
the figure on the right below. So

                                          y

                1 ¡ x2 » 1  dx = 1 (1)2 =  144
                0

                                                              1x

                                                                  Example 3.1.16

    This next one is a little trickier and relies on us knowing the symmetries of the sine
function.

 Example 3.1.17

                      ³

The integral ¡ sin xdx is the signed area of the shaded region in the figure on the right

below. It naturally splits into two regions, one on either side of the y-axis. We don't know
the formula for the area of either of these regions (yet), however the two regions are very

                                                         117
INTEGRATION  3.1 DEFINITION OF THE INTEGRAL

nearly the same. In fact, the part of the shaded region below the x-axis is exactly the re-
flection, in the x-axis, of the part of the shaded region above the x-axis. So the signed area
of part of the shaded region below the x-axis is the negative of the signed area of part of
the shaded region above the x-axis and

                                                                   y
                                                                  1

             »

              ¡ sin xdx = 0 -  x

                                                                -1

             Example 3.1.17

3.1.4  Surplus

       In Section 2.6, we saw demand curves that depended on a consumer's income, their pref-
       erences (utility function), and the prices of goods. Now let's use a simplified demand
      curve: D(q) is the per-unit price at which consumers will purchase a quantity q of a
       good16.

           Similarly, we can make a supply curve S(q) giving the per-unit price at which suppliers
       are willing to sell q units.

           In simple examples, D(q) has a negative slope (since, to motivate consumers to buy a
      higher quantity, prices should be lower) and S(q) has a positive slope (since, to motivate
       suppliers to sell a higher quantity, prices should be higher). The quantity and price where
       the two curves meet are called the equilibrium quantity and equilibrium price, respectively,
       and are denoted qe resp. pe. In theory, suppliers would aim to sell qe products at a unit
       price of pe. (If they make more goods, to sell them all they'd have to charge less than they
       are willing to accept. If they make fewer goods, they will not meet consumer demand.)

        16 The more natural way of thinking about this is reversed: given the price, how much quantity will
              consumers purchase? But formulating the relationship where price is a function of quantity (rather
              than the other way around) is standard practice in economics texts, so we follow it here.

                                                                118
INTEGRATION                        3.1 DEFINITION OF THE INTEGRAL
             Price p                                     S(q)

pe

                                                                          D(q)
                                      qe Quantity q

 Example 3.1.18 (Supply and demand curves over a small market)
To get a feel for what these curves represent, let's take a very simplified model market.
Our market consists of 10 consumers and 10 suppliers. All widgets are sold at the same
price, which we call the market price.
Demand Curve Each consumer wants at most one widget. Their tastes and needs differ,

       so some value the widgets more than others. The table below shows the maximum
       amount each consumer17 is willing to pay for one widget. If the price is higher, they
       won't buy any widget; if the price is lower, they will still only buy one, because they
       only need one.

                       consumer    price

                          Cabot     $5
                       Cameron      $4
                                    $3
                         Carter     $3
                       Charlotte    $3
                      Christopher   $2
                         Chioke     $2
                                    $2
                          Chloe     $1
                          Claire    $1
                           Cole
                         Cooper

To further simplify things, let's only deal with prices in whole dollars. We'll graph
out D(q) point-by-point.

17 Popular Canadian baby names for consumers and suppliers taken from here and here.

                                                         119
INTEGRATION  3.1 DEFINITION OF THE INTEGRAL

p = 5 When the market price of a widget is $5, only Cabot wants one, so the demand
      over all consumers is 1. That puts the point (q, p) = (1, 5) on the demand curve.

p = 4 When the market price of a widget is $4, both Cabot and Cameron want one,
      so the demand over all consumers is 2. That puts the point (q, p) = (2, 4) on
      the demand curve.

p = 3 When the market price of a widget is $3, then Cabot, Cameron, Carter, Char-
      lotte, and Christopher all want one, so the demand over all consumers is 5. That
      puts the point (q, p) = (5, 3) on the demand curve.

p = 2 When the market price of a widget is $2, then all consumers except Cole and
      Cooper want one, so the demand over all consumers is 8. That puts the point
      (q, p) = (8, 2) on the demand curve.

p = 1 When the market price of a widget is $1, then all consumers want one, so the
      demand over all consumers is 10. That puts the point (q, p) = (10, 1) on the
      demand curve.

Here are the points we found of our demand curve, graphed:

Price p
      5
      4
      3
      2
      1

             1 2 3 4 5 6 7 8 9 10 Quantity q

Supply Curve Each supplier can produce at most one widget. Their costs of production
       differ, so some will be willing to sell more cheaply than others. The table below
       shows the lowest price at which each producer is willing to sell their widget. They
       will sell no widgets for cheaper than their listed price; if the market price is higher,
       they will offer only one widget for sale, as that is all they can produce.
                                                         120
INTEGRATION              3.1 DEFINITION OF THE INTEGRAL

              supplier   price

               Scarlett   $1
               Searlus    $2
              Seignour    $2
               Sennet     $2
              Shawnita    $3
               Sontee     $4
               Sophia     $5
               Suthley    $5
              Swindel     $5
             Symington    $6

We'll graph out S(q) point-by-point, again considering only whole dollar amounts.

p = 1 When the market price of a widget is $1, then only Scarlett is willing to sell,
      so the supply over the entire market is 1. That puts the point (q, p) = (1, 1) on
      the supply curve.

p = 2 When the market price of a widget is $2, then Scarlett, Searlus, Seignour, and
      Sennet are all willing to sell, so the supply over the entire market is 4. That puts
      the point (q, p) = (4, 2) on the supply curve.

p = 3 When the market price of a widget is $3, then Scarlett, Searlus, Seignour, Sen-
      net, and Shawnita are all willing to sell, so the supply over the entire market is
      5. That puts the point (q, p) = (5, 3) on the supply curve.

p = 4 When the market price of a widget is $4, then Scarlett, Searlus, Seignour, Sen-
      net, Shawnita, and Sontee are all willing to sell, so the supply over the entire
      market is 6. That puts the point (q, p) = (6, 4) on the supply curve.

p = 5 When the market price of a widget is $5, then all suppliers except Symington
      are willing to sell, so so the supply over the entire market is 9. That puts the
      point (q, p) = (9, 5) on the supply curve.

p = 6 When the market price of a widget is $6, then all suppliers are willing to sell,
      so so the supply over the entire market is 10. That puts the point (q, p) = (10, 6)
      on the supply curve.

Here are the points we found of our demand curve, graphed:
                                                 121
INTEGRATION                  3.1 DEFINITION OF THE INTEGRAL

            Price p
                  6
                  5
                  4
                  3
                  2
                  1

                     1 2 3 4 5 6 7 8 9 10 Quantity q

Equilibrium Both supply and demand share the points (5, 3). So, with the market at
       equilibrium, we expect each widget to sell for $3, and for 5 of them to be sold.
       (In the graph below, we've connected all the points to one another by straight lines,
       to make the difference between the two collections clearer.)

             Price p

                             S(q)

pe = 3

                             D(q)

                     qe = 5  Quantity q

To be even more detailed: we expect Scarlett, Searlus, Seignour, Sennet, and Shawnita
to sell one widget apiece to Cabot, Cameron, Carter, Charlotte, and Christopher.

                                                                                         Example 3.1.18

                     122
INTEGRATION  3.1 DEFINITION OF THE INTEGRAL

    Now that we have the model set up, let's dive deeper. In our setup, all units of our
good are sold at the same price, the market price. However, not all consumers and pro-
ducers assign the same value to the good. Some consumers who value the good highly
were able to buy it at the market price, which feels cheap to them. These consumers expe-
rienced a surplus: they bought something worth a lot to them for a little money. Similarly,
some suppliers were willing to sell very cheaply, but actually sold at the higher market
rate. These suppliers also experienced a surplus: they sold something worth very little to
them for a lot of money.

 Example 3.1.19 (Surplus over a small market)

Let's return to our model market from Example 3.1.18. Recall Scarlett, Searlus, Seignour,
Sennet, and Shawnita sold one widget apiece to Cabot, Cameron, Carter, Charlotte, and
Christopher. Each of the five widgets sold for $3. Let's consider their individual experi-
ences.

Consumer Surplus Cabot and Cameron were willing to pay higher than the market rate,
       so they accrued some personal gain when they bought their widgets.
       Cabot valued their widget the highest. They were willing to pay $5 for it, so we
             think of the widget as being worth $5 to Cabot. Since they only paid $3 for it,
             in their personal estimation, they accrued a surplus of $2.
       Cameron valued their widget the next highest. They were willing to pay $4 for
             it. Since they only paid $3 for it, in their personal estimation, they accrued a
             surplus of $1.
       Carter, Charlotte, and Christopher were willing to pay $3, and they paid $3. They
             consider their transactions to be even trades.
       No other consumers bought a widget. Their personal wealth was unchanged.
       All together, the consumer surplus over the entire market is $3: Cabot accrued a
       surplus of $2, and Cameron accrued a surplus of $1.

Producer Surplus Similarly, most suppliers who sold a widget came out ahead.
       Scarlett would have been willing to sell their widget for $1, but they sold at the
             market price of $3. So, they each were able to accrue a surplus of $2.
       Searlus, Seignour, and Sennet would have been willing to sell their widget fot $2,
             but they sold at the market price of $3. So, each accrued a surplus of $1.
       Shawnita made what they consider a fair trade.
       No other suppliers sold a widget, so their personal wealth is unchanged.
       All together, the producers surplus over the entire market is $5: $2 of surplus for
       Charlotte, and $1 each for Searlus, Seignour, and Sennet.

                                                                                                Example 3.1.19
Let's use the ideas of Example 3.1.19 to find a way of computing the surplus over a general
market. Let D(q) and S(q) be the demand resp. supply curves of a good in a market.

                                                         123
INTEGRATION               3.1 DEFINITION OF THE INTEGRAL

    Consumers would have been happy to buy the first unit of the good at the price D(1).
We can say then that the first good has a value of D(1) for consumers. If they paid a lower

price pe, then the number D(1) ¡ pe is a surplus to the consumer: they gained D(1) units

of value by paying only pe units of value. This surplus to the consumer of selling the first
unit of the good can be visualized as the shaded area below.

             Price p
                                                                                            S(q)

D(1)

             pe

                 1   qe       D(q)
                          Quantity q

    Similarly, consumers would have been happy to buy the second unit of the good at the
unit price D(2). If they paid a smaller price pe, then their surplus from that second good is

D(2) ¡ pe: its value to them, minus what they actually paid. The consumer surplus after

buying the first two units of the good can be visualized as the shaded rectangles below.

Price p
                                                                               S(q)

D(1)
D(2)

             pe

                 12  qe       D(q)
                          Quantity q

                     124
INTEGRATION  3.1 DEFINITION OF THE INTEGRAL

    All together, we expect the consumer to buy qe units. Their total surplus is represented
by the shaded rectangles below.

Price p
                                                                               S(q)

              pe
                                                                                        D(q)

                                                     qe Quantity q

This motivates the definition of consumer surplus. Producer surplus behaves similarly.

  Definition3.1.20.
 Consider a supply curve S(q) and a demand curve D(q) with intersection point
 (qe, pe), graphed on the (q, p)-plane. The consumer surplus is the area from q = 0
 to q = qe under D(q) and above the line p = pe. The producer surplus is the area
 from q = 0 to q = qe over S(q) and under the line p = pe. The total surplus is the
 sum of consumer surplus and producer surplus.

                                                    125
INTEGRATION                3.2 BASIC PROPERTIES OF THE DEFINITE INTEGRAL
             Price p                                                   S(q)

                      C

           pe                                                      D(q)
                        P                                      Quantity q

                                                 qe

    Given a sale of qe items at unit price pe, we think of the consumer surplus as the net
benefit to the consumer, and the producer surplus as the net benefit to the producer. To
c³alculate these, we need a little geometric intuition. The consumer surplus is the area

 qe

 0 D(q) dq minus the area of the rectangle with width qe and height pe. So, the consumer
surplus is

                                                                   » qe

                             C = D(q)dq ¡ peqe
                                                                     0

    Similarly, the co³nsumer surplus is the area of the rectangle with width qe and height

                                  qe

pe, minus the area 0 S(q) dq. So, the producer surplus is

                                              » qe

                           P = peqe ¡ S(q)dq
                                                0

Finally, the total surplus is the value gained by everybody, producers and consumers
combined:
                                » qe                 » qe
                      T = C + P = D(q)dq ¡ S(q)dq
                                0                    0

3.2 Basic Properties of the Definite Integral

When we studied limits and derivatives, we developed methods for taking limits or
derivatives of "complicated functions" like f (x) = x2 + sin(x) by understanding how
limits and derivatives interact with basic arithmetic operations like addition and subtrac-
tion. This allowed us to reduce the problem into one of computing derivatives of simpler
functions like x2 and sin(x). Along the way we established simple rules such as

lim( f (x) + g(x)) = lim f (x) + lim g(x) and d ( f (x) + g(x)) = d f + dg
xÑa                   xÑa  xÑa                             dx  dx dx

                                      126
INTEGRATION                  3.2 BASIC PROPERTIES OF THE DEFINITE INTEGRAL

Some of these rules have very natural analogues for integrals and we discuss them below.
Unfortunately the analogous rules for integrals of products of functions or integrals of
compositions of functions are more complicated than those for limits or derivatives. We
discuss those rules at length in subsequent sections. For now let us consider some of the
simpler rules of the arithmetic of integrals.

Theorem3.2.1 (Arithmetic of Integration).

Let a, b and A, B, C be real numbers. Let the functions f (x) and g(x) be integrable
on an interval that contains a and b. Then

                 »b                        »b         »b
(a)                  ( f (x) + g(x)) dx = f (x)dx + g(x)dx
                 a                         a          a
                 »b                        »b         »b
(b)                  ( f (x) ¡ g(x)) dx = f (x)dx ¡ g(x)dx
                 a                         a          a
                         »b                    »b
(c)                          C f (x)dx = C ¤ f (x)dx
                         a                        a

Combining these three rules we have

(d)          »b                               »b          »b
                 (A f (x) + Bg(x)) dx = A f (x)dx + B g(x)dx
             a                                 a          a

That is, integrals depend linearly on the integrand.

                     »b      »b
(e)                      dx = 1 ¤ dx = b ¡ a
                     a       a

    It is not too hard to prove this result from the definition of the definite integral. Addi-
tionally we only really need to prove (d) and (e) since

   · (a) follows from (d) by setting A = B = 1,

  · (b) follows from (d) by setting A = 1, B = ¡1, and

   · (c) follows from (d) by setting A = C, B = 0.
Proof. As noted above, it suffices for us to prove (d) and (e). Since (e) is easier, we will
start with that. It is also a good warm-up for (d).

                                                         127
INTEGRATION                            3.2 BASIC PROPERTIES OF THE DEFINITE INTEGRAL

                                                    ³b

· The definite integral in (e), a 1dx, can be interpreted geometrically as the area of the

  rectangle with height 1 running from x = a to x = b; this area is clearly b ¡ a. We

   can also prove this formula from the definition of the integral (Definition 3.1.8):

             dx = lim f (xi » b ¸ n ¦,n) b ¡ a                       by definition
              a          nÑV  i=1             n                    since f (x) = 1
                                                         since a, b are constants
                      ¸ n = lim 1 b ¡ a
                         nÑV i=1 n
                      = lim (b ¡ a) ¸ n 1
                         nÑV           i=1 n

                      = lim (b ¡ a)
                         nÑV
                      = b¡a

as required.

· To prove (d) let us start by defining h(x) = A f (x) + Bg(x) and then we need to
   express the integral of h(x) in terms of those of f (x) and g(x). We use Definition 3.1.8
   and some algebraic manipulations18 to arrive at the result.

h(x)dx = h(xi » b ¸ n ¦,n) ¤ b ¡ a                              by Definition 3.1.8
a i=1 n
                 ¸ n ¦                                        by Theorem 3.1.5(b)
                                           ¦ b¡a              by Theorem 3.1.5(a)
             = A f (xi,n) + Bg(xi,n) ¤
                 i=1 n                                          by Definition 3.1.8
                 ¸ n
                              ¦ b¡a              ¦ b¡a
             =           A f (xi,n) ¤      + Bg(xi,n) ¤
                 i=1 n n

                 ¸ n          ¦ b¡a              ¸ n ¦ b ¡ a
                         A f (xi,n) ¤         + Bg(xi,n) ¤
             =   i=1 n i=1 n

                         ¸ n ¦ b ¡ a             ¸ n ¦ b ¡ a
             =A          f (xi,n) ¤           + B g(xi,n) ¤
                      i=1 n i=1 n

                 »b                    »b
             = A f (x)dx + B g(x)dx
                      a                a

as required.

Using this Theorem we can integrate sums, differences and constant multiples of functions
we know how to integrate. For example:

18 Now is a good time to look back at Theorem 3.1.5.

                                                         128
INTEGRATION                           3.2 BASIC PROPERTIES OF THE DEFINITE INTEGRAL

Example 3.2.2

                                                    ³1 x

In Example 3.1.1 we saw that 0 e dx = e ¡ 1. So

»1             »1         »1
    ex + 7 dx = exdx + 7 1dx
0              0          0
                          by Theorem 3.2.1(d) with A = 1, f (x) = ex, B = 7, g(x) = 1

             = (e ¡ 1) + 7 ¢ (1 ¡ 0)

                          by Example 3.1.1 and Theorem 3.2.1(e)

             = e+6

                                                                      Example 3.2.2

                                             ³b
    When we gave the formal definition of a f (x)dx in Definition 3.1.8 we explained that
the integral could be interpreted as the signed area between the curve y = f (x) and the
x-axis on the interval [a, b]. In order for this interpretation to make sense we required that
a b, and though we remarked that the integral makes sense when a ¡ b we did not
                                                                                                                                         ³b

explain any further. Thankfully there is an easy way to express the integral a f (x)dx in
    ³a
terms of b f (x)dx -- making it always possible to write an integral so the lower limit of
integration is less than the upper limit of integration. Theorem 3.2.3, below, tell us that, for
    ³3 x            ³7 x
example, 7 e dx = ¡ 3 e dx. The same theorem also provides us with two other simple
manipulations of the limits of integration.

    Theorem3.2.3 (Arithmetic for the Domain of Integration).

    Let a, b, c be real numbers. Let the function f (x) be integrable on an interval that
    contains a, b and c. Then

               (a)              »a    f (x)dx = 0

                                a                            »b
                                »a
               (b)                    f (x)dx = ¡ f (x)dx
                                b                              a
                                »b                 »c             »b
               (c)                    f (x)dx = f (x)dx + f (x)dx
                                a                         a       c

    The proof of this statement is not too difficult.

Proof. Let us prove the statements in order.

    · Consider the definition of the definite integral

                          f (x)dx = lim f (xi » b ¸ n ¦,n) ¤ b ¡ a
                             a                nÑV         i=1     n

                                             129
INTEGRATION                3.2 BASIC PROPERTIES OF THE DEFINITE INTEGRAL

If we now substitute b = a in this expression we have

                 f (x)dx = lim f (xi » a ¸ n ¦,n) ¤ a ¡ a

                  a nÑV i=1 loom n oon

                                                                     =0

                                     ¸ n ¦

                          = lim f (xi,n) ¤ 0

                               nÑV loooomoooon

                                               i=1 =0

                              = lim 0

                               nÑV

                              =0

   as required.

                                                                   ³B

· Consider now the definite integral A f (x)dx. Shortly we will substitute A = b and
   B = a, but first let's write down the definition of this integral using Definition 3.1.8.

f (x)dx = lim f (xi » B ¸ n ¦,n) ¤ B ¡ A
A                nÑV  i=1            n

Now substitute A = b and B = a into this expression:

f (x)dx = lim f (xi » a ¸ n ¦,n) ¤ a ¡ b
b                nÑV  i=1            n

                      ¸ n ¦               b¡a
                 = lim f (xi,n) ¤ (¡1) ¤
                 nÑV i=1 n
                            ¸ n ¦ b ¡ a
                 = lim (¡1) ¤ f (xi,n) ¤                  by Theorem 3.1.5(a)
                 nÑV i=1 n                             by arithmetic of limits
                           ¸ n ¦ b ¡ a
                 = (¡1) lim f (xi,n) ¤                      by Definition 3.1.8
                      nÑV i=1 n

                                »b

                 = (¡1) ¤ f (x)dx
                                  a

as required.
(Remark: in the last step, we are glossing over a little fine print about the exact

meaning of xi¦,n.)

· Finally consider (c) -- we will not give a formal proof of this, but instead will inter-
   pret it geometrically. Indeed one can also interpret (a) geometrically. In both cases
   these become statements about areas:

             »a                      »b        »c                        »b
                 f (x)dx = 0 and          f (x)dx = f (x)dx + f (x)dx
             a                       a         a                         c

                                     130
INTEGRATION                         3.2 BASIC PROPERTIES OF THE DEFINITE INTEGRAL

    are

                     Area2 (x, y) §§ a ¤ x ¤ a, 0 ¤ y ¤ f (x) @ = 0

    and

    Area2 (x, y) §§ a ¤ x ¤ b, 0 ¤ y ¤ f (x) @ = Area2 (x, y) §§ a ¤ x ¤ c, 0 ¤ y ¤ f (x) @
                                            + Area2 (x, y) §§ c ¤ x ¤ b, 0 ¤ y ¤ f (x) @

    respectively. Both of these geometric statements are intuitively obvious. See the
    figures below.

             y                          y
                  y = f (x)                  y = f (x)

                      a          x               a        c                            x
                                                                               b

    Note that we have assumed that a ¤ c ¤ b and that f (x) ¥ 0. One can remove these

    restrictions and also make the proof more formal, but it becomes quite tedious and
    less intuitive.

  Example 3.2.4

Back in Example 3.1.14 we saw that when b ¡ 0 0 xdx = 2 . We'll now verify that³bb2

³b0 xdx = 2 is still true when b = 0 and also when b 0.b2

                                        ³b            b2
    · First consider b = 0. Then the statement 0 xdx = 2 becomes

                                    »0

                                       xdx = 0

                                      0

    This is an immediate consequence of Theorem 3.2.3(a).

    · Now consider b  0. Let us write B = ¡b, so that B ¡ 0. In Example 3.1.14 we saw
       that

                                    » 0 xdx = ¡ B2 .2
                                    ¡B

    So we have
                 » b » xdx = ¡B » xdx 0 = ¡ xdx
                 0       0          ¡B                    by Theorem 3.2.3(b)
                      = ¡ ¡ B22                             by Example 3.1.14

                      = B2 = b2
                          22

                                        131
INTEGRATION                      3.2 BASIC PROPERTIES OF THE DEFINITE INTEGRAL

We have now shown that                          for all real numbers b
                                                                               Example 3.2.4
               » b xdx = b22
               0

Example 3.2.5

Applying Theorem 3.2.3 yet again, we have, for all real numbers a and b,

»b                »0         »b
    xdx = xdx + xdx              by Theorem 3.2.3(c) with c = 0
a                 a          0                 by Theorem 3.2.3(b)
                  »b         »a
               = xdx ¡ xdx                by Example 3.2.4, twice
                  0          0
               = b2 ¡ a2
                      2

We can also understand this result geometrically.

· (left) When 0 a b, the integral represents the area in green which is the difference
   of two right-angle triangles -- the larger with area b2/2 and the smaller with area
   a2/2.

· (centre) When a 0 b, the integral represents the signed area of the two displayed

  triangles. The one above the axis has area b2/2 while the one below has area ¡a2/2

   (since it is below the axis).
· (right) When a b 0, the integral represents the signed area in purple of the

  difference between the two triangles -- the larger with area ¡a2/2 and the smaller
  with area ¡b2/2.

                                                                                            Example 3.2.5

                                                     132
INTEGRATION                         3.2 BASIC PROPERTIES OF THE DEFINITE INTEGRAL

    Theorem 3.2.3(c) shows us how we can split an integral over a larger interval into one
over two (or more) smaller intervals. This is particularly useful for dealing with piece-

wise functions, like |x|.

 Example 3.2.6

Using Theorem 3.2.3, we can readily evaluate integrals involving |x|. First, recall that
                                   5x if x ¥ 0

                              |x| = ¡x if x 0

                                                    ³3

Now consider (for example) ¡2 |x|dx. Since the integrand changes at x = 0, it makes

sense to split the interval of integration at that point:

    »3          »0      »3
        |x|dx = |x|dx + |x|dx                                  by Theorem 3.2.3
    ¡2          ¡2      0
                »0         »3                                by definition of |x|
                    ¡x)dx + xdx
                = ¡2( 0                                     by Theorem 3.2.1(c)
                »0      »3
                ¡ xdx + xdx
                = ¡2 0
                = ¡(¡22/2) + (32/2) = (4 + 9)/2

                = 13/2

We can go further still -- given a function f (x) we can rewrite the integral of f (|x|) in
terms of the integral of f (x) and f (¡x).

                    »1              »0           »1
                        f |x| dx = f |x| dx + f |x| dx
                    ¡1              ¡1           0

                                    »0           »1
                                        f (¡x)dx + f (x)dx
                                    = ¡1 0

                                                                   Example 3.2.6

  Here is a more concrete example.
Example 3.2.7

                            ³1

Let us compute ¡1 1 ¡ |x| dx again. In Example 3.1.15 we evaluated this integral by in-

terpreting it as the area of a triangle. This time we are going to use only the properties
given in Theorems 3.2.1 and 3.2.3 and the facts that

        » b » dx b = b ¡ a and xdx = b2 ¡ a2                2
             a                                           a

³b                                                   ³b     b2¡a2
That a dx = b ¡ a is part (e) of Theorem 3.2.1. We saw that a xdx = 2 in Example 3.2.5.

                                        133
INTEGRATION              3.2 BASIC PROPERTIES OF THE DEFINITE INTEGRAL

    First we are going to get rid of the absolute value signs by splitting the interval over

which we integrate. Recalling that |x| = x whenever x ¥ 0 and |x| = ¡x whenever x ¤ 0,

we split the interval by Theorem 3.2.3(c),

                 »1      »0      »1
                     1 ¡ |x| dx = 1 ¡ |x| dx + 1 ¡ |x| dx
                 ¡1      ¡1          0

                         »0             »1
                             1 ¡ (¡x) dx + 1 ¡ x dx
                     = ¡1 0
                         »0      »1
                             1 + x dx + 1 ¡ x dx
                     = ¡1 0

Now we apply parts (a) and (b) of Theorem 3.2.1, and then

             »1      »0      »0  »1                        »1
                 1 ¡ |x| dx = 1dx + xdx + 1dx ¡ xdx
             ¡1      ¡1      ¡1  0                         0

                     = [0 ¡ (¡1)] + 0 2 + [ 2 ¡ (¡1)2 1 ¡ 0] ¡ 12 ¡ 02 2

                     =1

                                                               Example 3.2.7

3.2.1  More Properties of Integration: Even and Odd Functions

       Recall19 the following definition
              Definition3.2.8.
            Let f (x) be a function. Then,

           · we say that f (x) is even when f (x) = f (¡x) for all x, and
           · we say that f (x) is odd when f (x) = ¡ f (¡x) for all x.

           Of course most functions are neither even nor odd, but many of the standard functions
       you know are.

        Example 3.2.9 (Even functions)

       · Three examples of even functions are f (x) = |x|, f (x) = cos x and f (x) = x2. In

              fact, if f (x) is any even power of x, then f (x) is an even function.

        19 We haven't done this in this course, but you should have seen it in your differential calculus course or
              perhaps even earlier.

                                                                134
INTEGRATION                     3.2 BASIC PROPERTIES OF THE DEFINITE INTEGRAL

· The part of the graph y = f (x) with x ¤ 0, may be constructed by drawing the part
  of the graph with x ¥ 0 (as in the figure on the left below) and then reflecting it in

   the y-axis (as in the figure on the right below).

                y                                       y

                1                                       1

             -                      x    -                                  x

                -1                                      -1

· In particular, if f (x) is an even function and a ¡ 0, then the two sets
                2 (x, y) §§ 0 ¤ x ¤ a and y is between 0 and f (x) @
                2 (x, y) §§ ¡a ¤ x ¤ 0 and y is between 0 and f (x) @

are reflections of each other in the y-axis and so have the same signed area. That is

                                »a       »0
                                0 f (x)dx = ¡a f (x)dx

                                                            Example 3.2.9

Example 3.2.10 (Odd functions)

· Three examples of odd functions are f (x) = sin x, f (x) = tan x and f (x) = x3. In
   fact, if f (x) is any odd power of x, then f (x) is an odd function.

· The part of the graph y = f (x) with x ¤ 0, may be constructed by drawing the part
  of the graph with x ¥ 0 (like the solid line in the figure on the left below) and then

   reflecting it in the y-axis (like the dashed line in the figure on the left below) and
   then reflecting the result in the x-axis (i.e. flipping it upside down, like in the figure
   on the right, below).

                y                                       y

                1                                       1

             -                      x    -                                  x

                -1                                      -1

                                    135
INTEGRATION                          3.2 BASIC PROPERTIES OF THE DEFINITE INTEGRAL

· In particular, if f (x) is an odd function and a ¡ 0, then the signed areas of the two

   sets

                2 (x, y) §§ 0 ¤ x ¤ a and y is between 0 and f (x) @
                2 (x, y) §§ ¡a ¤ x ¤ 0 and y is between 0 and f (x) @

are negatives of each other -- to get from the first set to the second set, you flip it
upside down, in addition to reflecting it in the x-axis. That is

                                 »a           »0
                                     f (x)dx = ¡ f (x)dx
                                 0            ¡a

                                                                   Example 3.2.10

We can exploit the symmetries noted in the examples above, namely

             »a          »0                                      for f even
             0 f (x)dx = ¡a f (x)dx                               for f odd
             »a              »0
                 f (x)dx = ¡ f (x)dx
             0               ¡a

together with Theorem 3.2.3

»a                       »0             »a
             ¡a f (x)dx = ¡a f (x)dx + 0 f (x)dx

in order to simplify the integration of even and odd functions over intervals of the form

[¡a, a].

Theorem3.2.11 (Even and Odd).

Let a ¡ 0.

(a) If f (x) is an even function, then

                                 »a           »a
                                 ¡a f (x)dx = 2 0 f (x)dx

(b) If f (x) is an odd function, then

                                                             »a

                                       ¡a f (x)dx = 0

Proof. For any function

                         »a          »a           »0
                         ¡a f (x)dx = 0 f (x)dx + ¡a f (x)dx

When f is even, the two terms on the right hand side are equal. When f is odd, the two
terms on the right hand side are negatives of each other.

                                         136
INTEGRATION                         3.2 BASIC PROPERTIES OF THE DEFINITE INTEGRAL

3.2.2  More Properties of Integration: Inequalities for Integrals

       We are still unable to integrate many functions, however with a little work we can infer
       bounds on integrals from bounds on their integrands.

 Theorem3.2.12 (Inequalities for Integrals).

Let a ¤ b be real numbers and let the functions f (x) and g(x) be integrable on
the interval a ¤ x ¤ b.
(a) If f (x) ¥ 0 for all a ¤ x ¤ b, then

                                                              »b

                                 f (x)dx ¥ 0

                                                                a

(b) If there are constants m and M such that m ¤ f (x) ¤ M for all a ¤ x ¤ b,

     then

                                                                 »b

                      m(b ¡ a) ¤ f (x)dx ¤ M(b ¡ a)
                                                                   a

(c) If f (x) ¤ g(x) for all a ¤ x ¤ b, then

                               »b                        »b
                                    f (x)dx ¤ g(x)dx
                               a                         a

(d) We have

                            §§ » b             §§ » b
                                    f (x)dx§§ ¤               | f (x)|dx
                            §  a                         a
                            §

Proof. (a) By interpreting the integral as the signed area, this statement simply2says th§at if
the curve y = f (x) lies above the x-axis and a ¤ b, then the signed area of (x, y) § a ¤
x ¤ b, 0 ¤ y ¤ f (x) @ is at least zero. This is quite clear. Alternatively, we could argue
                                                                                                ³b
more algebraically from Definition 3.1.8. We observe that when we define a f (x)dx
via  Riemann  sums,  every  summand,  f     x  ¦         b¡a  ¥  0.  Thus  the  whole  sum  is  nonnega-
                                         (         n  )
                                               i,         n
tive and consequently, so is the limit, and thus so is the integral.

(b) We can argue this from (a) with a little massaging. Let g(x) = M ¡ f (x), then since
   f (x) ¤ M, we have g(x) = M ¡ f (x) ¥ 0 so that

                     »b                            »b
                            M ¡ f (x) dx = g(x)dx ¥ 0.
                     a                                a

                                         137
INTEGRATION                              3.2 BASIC PROPERTIES OF THE DEFINITE INTEGRAL

but we also have

                       »b                        »b            »b
                             M ¡ f (x) dx = Mdx ¡ f (x)dx
                          a                       a            a
                                                               »b
                                             = M(b ¡ a) ¡ f (x)dx
                                                                  a

Thus

                                  »b                                    rearrange

              M(b ¡ a) ¡ f (x)dx ¥ 0
                                    a
                                                         »b
                         M(b ¡ a) ¥ f (x)dx
                                                            a

                                                                ³b

as required. The argument showing a f (x)dx ¥ m(b ¡ a) is similar.

(c) Now let h(x) = g(x) ¡ f (x). Since f (x) ¤ g(x), we have h(x) = g(x) ¡ f (x) ¥ 0 so

    that

                  »b                              »b
                             g(x) ¡ f (x) dx = h(x)dx ¥ 0
                  a                               a

But we also have that

                  »b                              »b               »b
                             g(x) ¡ f (x) dx = g(x)dx ¡ f (x)dx
                  a                               a                  a

Thus

              »b             »b
                  g(x)dx ¡ f (x)dx ¥ 0                                  rearrange
              a                 a
                             »b              »b
                                   g(x)dx ¥ f (x)dx
                                a            a

as required.

(d) For any x, | f (x)| is either f (x) or ¡ f (x) (depending on whether f (x) is positive or

     negative), so we certainly have

              f (x) ¤ | f (x)|               and                     ¡ f (x) ¤ | f (x)|

Applying part (c) to each of those inequalities gives

      »b          »b                                           »b       »b
             f (x)dx ¤ | f (x)|dx            and               ¡ f (x)dx ¤ | f (x)|dx
          a            a                                       a        a

Now | a f (x)dx| is either equal to a f (x)dx or ¡ a f (x)dx (depending on whether the³b³b³b

integral is positive or negative). In either case we can apply the above two inequalities
to get the same result, namely

                                   §         §

                                   §» b      § »b
                                   §§ f (x)dx§§ ¤ | f (x)|dx.
                                   §a        §        a

                                             138
INTEGRATION                            3.3 THE FUNDAMENTAL THEOREM OF CALCULUS

Example 3.2.13 0 ³/3 ccos xdx

Consider the integral

                                       » /3 ccos xdx
                                         0

This is not so easy to compute exactly20, but we can bound it quite quickly.           1.
For  x  between 0 and  ,    the function cos x     takes values21     between 1 and        Thus the
function ccos x takes values between 1 and c1 . That is                                2
                       3

                                                   2

                   1c                                           for 0 ¤ x ¤ 3 .
                   c ¤ cos x ¤ 1

                     2

Consequently,  by  Theorem  3.2.12(b)  with  a  =  0,  b  =  ,  m  =  c12  and M = 1,

                                                             3

                                » /3 c                          
                               c¤               cos xdx ¤
                            32 0                                3

Plugging these expressions into a calculator gives us

                       »  0.7404804898 ¤ /3 ccos xdx ¤ 1.047197551
                                                     0

                                                                                 Example 3.2.13

3.3 The Fundamental Theorem of Calculus

     We have spent quite a few pages (and lectures) talking about definite integrals, what
     they are (Definition 3.1.8), when they exist (Theorem 3.1.9), how to compute some spe-
     cial cases (Section 3.1.3), some ways to manipulate them (Theorem 3.2.1 and 3.2.3) and
     how to bound them (Theorem 3.2.12). Conspicuously missing from all of this has been a
     discussion of how to compute them in general. It is high time we rectified that.

         The single most important tool used to evaluate integrals is called "the Fundamental
     Theorem of Calculus". Its grand name is justified -- it links the two branches of calculus
     by connecting derivatives to integrals. In so doing it also tells us how to compute integrals.
     Very roughly speaking the derivative of an integral is the original function. This fact
     allows us to compute integrals using antiderivatives22. Of course "very rough" is not
     enough -- let's be precise.

      20 It is not too hard to use Riemann sums and a computer to evaluate it numerically: 0.948025319 . . . .
      21 You know the graphs of sine and cosine, so you should be able to work this out without too much

            difficulty.
      22 You learned these near the end of your differential calculus course. Now is a good time to revise -- but

            we'll go over them here since they are so important in what follows.

                                                              139
INTEGRATION                          3.3 THE FUNDAMENTAL THEOREM OF CALCULUS

    Theorem3.3.1 (Fundamental Theorem of Calculus).

   Let a b and let f (x) be a function which is defined and continuous on [a, b].

                                      »x

   Part 1: Let F(x) = f (t)dt for any x in the interval [a, b]. Then the function

                                        a

            F(x) is differentiable and further

                                            FI(x) = f (x)

   Part 2: Let G(x) be any function which is defined and continuous on [a, b]. Fur-

           ther let G(x) be differentiable with GI(x) = f (x) for all a x b. Then

   f (x)dx = G(b) ¡ G(a) or equivalently G » b » b I(x)dx = G(b) ¡ G(a)
   a                                                          a

    Before we prove this theorem and look at a bunch of examples of its application, it
is important that we recall one definition from differential calculus -- antiderivatives. If

FI(x) = f (x) on some interval, then F(x) is called an antiderivative of f (x) on that inter-

val. So Part 2 of the Fundamental Theorem of Calculus tells us how to evaluate the definite
integral of f (x) in terms of any of its antiderivatives -- if G(x) is any antiderivative of f (x)
then

                                                        »b

                              f (x)dx = G(b) ¡ G(a)

                                                          a

           ³b I

The form a G (x) dx = G(b) ¡ G(a) of the Fundamental Theorem relates the rate of
change of G(x) over the interval a ¤ x ¤ b to the net change of G between x = a and

x = b. For that reason, it is sometimes called the "net change theorem".
    We'll start with a simple example. Then we'll see why the Fundamental Theorem is

true and then we'll do many more, and more involved, examples.

Example 3.3.2 (A first example)

                                      ³b

Consider the integral a xdx which we have explored previously in Example 3.2.5.
   · The integrand is f (x) = x.

·  We can readily verify that  G(x)  =  x2  satisfies  GI(x)  =  f (x) and so is an antideriva-
                                        2
   tive of the integrand.

· Part 2 of Theorem 3.3.1 then tells us that

                                 »b  f (x)dx = G(b) ¡ G(a)

                                 a   » b xdx = b2 ¡ a2

                                     a           22

   which is precisely the result we obtained (with more work) in Example 3.2.5.

                                            140
INTEGRATION  3.3 THE FUNDAMENTAL THEOREM OF CALCULUS

                                          Example 3.3.2

    We do not give completely rigorous proofs of the two parts of the theorem -- that is
not really needed for this course. We just give the main ideas of the proofs so that you can
understand why the theorem is true.

Part 1. We wish to show that if

               F(x) = f (t)dt then F » x I(x) = f (x)

                                        a

   · Assume that F is the above integral and then consider FI(x). By definition

             FI(x) = lim F(x + h) ¡ F(x)h
             hÑ0

· To understand this limit, we interpret the terms F(x), F(x + h) as signed areas. To
   simplify this further, let's only consider the case that f is always nonnegative and

  that h ¡ 0. These restrictions are not hard to remove, but the proof ideas are a bit

   cleaner if we keep them in place. Then we have

       F(x + h) = the area of the region 2 (t, y) §§ a ¤ t ¤ x + h, 0 ¤ y ¤ f (t) @
           F(x) = the area of the region 2 (t, y) §§ a ¤ t ¤ x, 0 ¤ y ¤ f (t) @

· Then the numerator

    F(x + h) ¡ F(x) = the area of the region 2 (t, y) §§ x ¤ t ¤ x + h, 0 ¤ y ¤ f (t) @

   This is just the more darkly shaded region in the figure

                                          y = f (t)

                                               a x x+h t

  · We will be taking the limit h Ñ 0. So suppose that h is very small. Then, as t runs

       from x to x = h, f (t) runs only over a very narrow range of values23, all close to
       f (x).
   · So the darkly shaded region is almost a rectangle of width h and height f (x) and so

                                                          F(x+h)¡F(x)

       has an area which is very close to f (x)h. Thus h is very close to f (x).

23 Notice that if f were discontinuous, then this might be false.

                                                         141
INTEGRATION                                  3.3 THE FUNDAMENTAL THEOREM OF CALCULUS

· In the limit h Ñ 0,  F(x+h)¡F(x)           becomes exactly f (x), which is precisely what we
                       h
want.

We can make the above more rigorous using the Mean Value Theorem24.

                                                     ³b

Part 2. We want to show that a f (t)dt = G(b) ¡ G(a). To do this we exploit the fact that

the derivative of a constant is zero.

· Let

                                     »x

                       H(x) = f (t)dt ¡ G(x) + G(a)
                                       a

Then the result we wish to prove is that H(b) = 0. We will do this by showing that
H(x) = 0 for all x between a and b.

· We first show that H(x) is constant by computing its derivative:

              HI(x) = d » x f (t)dt ¡ d (G(x)) + d (G(a))
                          dx a                    dx     dx

Since G(a) is a constant, its derivative is 0 and by assumption the derivative of G(x)
is just f (x), so

                       = d » x f (t)dt ¡ f (x)

                          dx a

Now Part 1 of the theorem tells us that this derivative is just f (x), so

                       = f (x) ¡ f (x) = 0

Hence H is constant.

· To determine which constant we just compute H(a):

                           »a                            by Theorem 3.2.3(a)

             H(a) = f (t)dt ¡ G(a) + G(a)
                           »a
                              a
                    = f (t)dt
                             a
                    =0

as required.

24 The MVT tells us that there is a number c between x and x + h so that

                       FI(c) = F(x + h) ¡ F(x) = F(x + h) ¡ F(x)
                          (x + h) ¡ x                 h

But since FI(x) = f (x), this tells us that

                                F(x + h) ¡ F(x) h = f (c)
where c is trapped between x + h and x. Now when we take the limit as h Ñ 0 we have that this number

c is squeezed to x and the result follows.

                                             142
INTEGRATION                                       3.3 THE FUNDAMENTAL THEOREM OF CALCULUS

    The simple example we did above (Example 3.3.2), demonstrates the application of
part 2 of the Fundamental Theorem of Calculus. Before we do more examples (and there
will be many more over the coming sections) we should do some examples illustrating
the use of part 1 of the fundamental theorem of calculus. Then we'll move on to part 2.

                               d ³x

 Example 3.3.3 dx 0 tdt

                                      ³x

Consider the integral 0 t dt. We know how to evaluate this -- it is just Example 3.3.2 with
a = 0, b = x. So we have two ways to compute the derivative. We can evaluate the in-
tegral and then take the derivative, or we can apply Part 1 of the Fundamental Theorem.
We'll do both, and check that the two answers are the same.

    First, Example 3.3.2 gives

                                           » F x (x) = t dt = x22
                                                  0

So of course FI(x) = x. Second, Part 1 of the Fundamental Theorem of calculus tells us that

the derivative of F(x) is just the integrand. That is, Part 1 of the Fundamental Theorem of

Calculus also gives FI(x) = x.

                                                                                                Example 3.3.3

    In the previous example we were able to evaluate the integral explicitly, so we did not
need the Fundamental Theorem to determine its derivative. Here is an example that really
does require the use of the Fundamental Theorem.

                  d ³x ¡t2

Example 3.3.4 dx 0 e dt

                    d ³x ¡t2
We would like to find dx 0 e dt. In the previous example, we were able to compute the
corresponding derivative in two ways -- we could explicitly compute the integral and
then differentiate the result, or we could apply part 1 of the Fundamental Theorem of cal-
culus. In this example we do not know the integral explicitly. Indeed it is not possible
                              ³x  e¡t2 dt
to  express25  the  integral   0           as  a  finite  combination  of  standard       functions  such  as
polynomials, exponentials, trigonometric functions and so on.

    Despite this, we can find its derivative by just applying the first part of the Fundamen-

                 ³x ¡t2

25 The integral 0 e dt is closely related to the "error function" which is an extremely important function
      in mathematics. While we cannot express this integral (or the error function) as a finite combination of
      polynomials, exponentials etc, we can express it as an infinite series

               » x e¡t2dt = x ¡ x3 + x5 ¡ x7 + x9 + ¤ ¤ ¤ + (¡1)k x2k+1 + ¤ ¤ ¤
               0                  3 ¤ 1 5 ¤ 2 7 ¤ 3! 9 ¤ 4!                (2k + 1) ¤ k!

    But more on this in Chapter 5.

                                                  143
INTEGRATION                  3.3 THE FUNDAMENTAL THEOREM OF CALCULUS

tal Theorem of Calculus with f (t) = e¡t2 and a = 0. That gives

                   d » x e¡t2dt = d » x f (t)dt
                   dx 0               dx 0
                                      = f (x) = e¡x2

                                                                 Example 3.3.4

    Let us ratchet up the complexity of the previous example -- we can make the limits
of the integral more complicated functions. So consider the previous example with the
upper limit x replaced by x2:

                   d ³x2 ¡t2

 Example 3.3.5 dx 0 e dt

                        ³x2 ¡t2

Consider the integral 0 e dt. We would like to compute its derivative with respect to x
using part 1 of the fundamental theorem of calculus.

    Th³e Fundamental Theorem tells us how to compute the derivative of functions of the

           x

form a f (t)dt but the integral at hand is not of the specified form because the upper limit
we have is x2, rather than x, -- so more care is required. Thankfully we can deal with this
obstacle with only a little extra work. The trick is to define an auxiliary function by simply
changing the upper limit to x. That is, define

                                        » E x (x) = e¡t2dt

                                                                                0

Then the integral we want to work with is

                                       E(x2 » x2 ) = e¡t2dt

                                                                                0

The derivative EI(x) can be found via part 1 of the Fundamental Theorem of calculus (as
we did in Example 3.3.4) and is EI(x) = e¡x2. We can then use this fact with the chain rule

to compute the derivative we need:

             d » x2 e¡t2dt = d E(x2)        use the chain rule
             dx 0  dx
                   = 2xEI(x2)

                   = 2xe¡x4

                                                                                                Example 3.3.5
    What if both limits of integration are functions of x? We can still make this work, but
we have to split the integral using Theorem 3.2.3.

                                                         144
INTEGRATION                     3.3 THE FUNDAMENTAL THEOREM OF CALCULUS

                  d ³x2 ¡t2

Example 3.3.6 dx x e dt

Consider the integral

                                          » x2 e¡t2dt

                                            x

As was the case in the previous example, we have to do a little pre-processing before we
can apply the Fundamental Theorem.

    This time (by design), not only is the upper limit of integration x2 rather than x³, but the

                                                                                                                                                 x

lower limit of integration also depends on x -- this is different from the integral a f (t)dt
in the Fundamental Theorem where the lower limit of integration is a constant.

    Fortunately we can use the basic properties of integrals (Theorem 3.2.3(b) and (c)) to

     ³x2 ¡t2

split x e dt into pieces whose derivatives we already know.

» x2 e¡t2 » dt 0 = e¡t2 » dt x2 + e¡t2dt               by Theorem 3.2.3(c)
x                      x     0                         by Theorem 3.2.3(b)
                       » x = ¡ e¡t2 » dt x2 + e¡t2dt
                          0     0

With this pre-processing, both integrals are of the right form. Using what we have learned
in the previous two examples,

                       d » x2 e¡t2dt = d  » ¡ x e¡t2 » dt x2 + e¡t2dt
             dx x               dx              0      0

                             = ¡ d » x e¡t2dt + d » x2 e¡t2dt
                                          dx 0         dx 0

                             = ¡e¡x2 + 2xe¡x4

                                                                       Example 3.3.6

3.3.1  Indefinite Integration

       Before we start to work with part 2 of the Fundamental Theorem, we need a little termi-
       nology and notation. First some terminology -- you may have seen this definition in your
       differential calculus course.

              Definition3.3.7 (Antiderivatives).

           Let f (x) and F(x) be functions. If FI(x) = f (x) on an interval, then we say that

            F(x) is an antiderivative of f (x) on that interval.

                                                                145
INTEGRATION  3.3 THE FUNDAMENTAL THEOREM OF CALCULUS

    As we saw above, an antiderivative of f (x) = x is F(x) = x2/2 -- we can easily verify
this by differentiation. Notice that x2/2 + 3 is also an antiderivative of x, as is x2/2 + C
for any constant C. This observation gives us the following simple lemma.

 Lemma3.3.8.
Let f (x) be a function and let F(x) be an antiderivative of f (x). Then F(x) + C
is also an antiderivative for any constant C. Further, every antiderivative of f (x)
must be of this form.

Proof. There are two parts to the lemma and we prove each in turn.
   · Let F(x) be an antiderivative of f (x) and let C be some constant. Then
                                     ddx (F(x) + C) = ddx (F(x)) + ddx (C)
                                                        = f (x) + 0
       since the derivative of a constant is zero, and by definition the derivative of F(x) is
       just f (x). Thus F(x) + C is also an antiderivative of f (x).
   · Now let F(x) and G(x) both be antiderivatives of f (x) -- we will show that G(x) =

    F(x) + C for some constant C. To do this let H(x) = G(x) ¡ F(x). Then
           ddx H(x) = ddx (G(x) ¡ F(x)) = ddx G(x) ¡ ddx F(x) = f (x) ¡ f (x) = 0

       Since the derivative of H(x) is zero, H(x) must be a constant function26. Thus

    H(x) = G(x) ¡ F(x) = C for some constant C and the result follows.

    Based on the above lemma we have the following definition.

26 This follows from the Mean Value Theorem. Say H(x) were not constant, then there would be two

   numbers a b so that H(a) $ H(b). Then the MVT tells us that there is a number c between a and b so

      that

                                    HI(c) = H(b) ¡ H(a) .
                                               b¡a

      Since both numerator and denominator are non-zero, we know the derivative at c is nonzero. But
      this would contradict the assumption that derivative of H is zero. Hence we cannot have a b with

   H(a) $ H(b) and so H(x) must be constant.

                                                         146
INTEGRATION                                    3.3 THE FUNDAMENTAL THEOREM OF CALCULUS

 Definition3.3.9.
The "indefinite integral of f (x)" is denoted by ³ f (x)dx and should be regarded
as the general antiderivative of f (x). In particular, if F(x) is an antiderivative of
f (x) then

                                                                      »

                                        f (x)dx = F(x) + C

where the C is an arbitrary constant. In this context, the constant C is also often
called a "constant of integration".

Now we just need a tiny bit more notation.

Notation3.3.10.

The symbol

                                               » §§b
                                               f  (  x  )  d  x
                                                                 §
                                                                 §  a

denotes the change in an antiderivative of f (x) from x = a to x = b. More
precisely, let F(x) be any antiderivative of f (x). Then

                 » §§b
                                                   b
                       f  (  x  )  d  x  §     = F(x)|a = F(b) ¡ F(a)
                                         §
                                            a

Notice that this notation allows us to write part 2 of the Fundamental Theorem as

                 » b » §§b
                          f (x)dx =               f  (  x  )  d  x
                    a                                                  §
                                                                       §  a

                                               = F(x)|a = F(b) ¡ F(a)b

Some texts also use an equivalent notation using square brackets:

                 » b f (x)dx = F(x) b = F(b) ¡ F(a).       a
                 a

You should be familiar with both notations.
    We'll soon develop some strategies for computing more complicated integrals. But for

now, we'll try a few integrals that are simple enough that we can just guess the answer.
Of course, any antiderivative that we can guess we can also check -- simply differentiate
the guess and verify you get back to the original function:

                                   d » f (x)dx = f (x).
                                   dx

                                                  147
INTEGRATION                                              3.3 THE FUNDAMENTAL THEOREM OF CALCULUS

We do these examples in some detail to help us become comfortable finding indefinite
integrals.

Example 3.3.11

                                                     ³2

Compute the definite integral 1 xdx.

                                                              ³2  22¡12 3
Solution. We have already seen, in Example 3.2.5, that 1 xdx = 2 = 2 . We shall now
rederive that result using the Fundamental Theorem of Calculus.

· The main difficulty in this approach is finding the indefinite integral (an antideriva-
   tive) of x. That is, we need to find a function F(x) whose derivative is x. So think
   back to all the derivatives you computed last term27 and try to remember a function
   whose derivative was something like x.

· This shouldn't be too hard -- we recall that the derivatives of polynomials are poly-
   nomials. More precisely, we know that

                                      ddx xn = nxn¡1

So if we want to end up with just x = x1, we need to take n = 2. However this gives
us

                                              ddx x2 = 2x

· This is pretty close to what we want except for the factor of 2. Since this is a constant
   we can just divide both sides by 2 to obtain:

                12 ¤ ddx x2 = 12 ¤ 2x                         which becomes
                 ¤ d x = 2 x

                   dx 2

which is exactly what we need. It tells us that x2/2 is an antiderivative of x.

· Once one has an antiderivative, it is easy to compute the indefinite integral
                                             » xdx = 1 x2 + C
                                                            2

   as well as the definite integral:

» 2 1 2§§2                                               since x2/2 is the antiderivative of x
   xdx = x §§
             1  21
                = 1222 ¡ 1212 = 32

27 Of course, this assumes that you did your differential calculus course last term. If you did that course at
      a different time then please think back to that point in time. If it is long enough ago that you don't quite
      remember when it was, then you should probably do some revision of derivatives of simple functions
      before proceeding further.

                                                         148
INTEGRATION                          3.3 THE FUNDAMENTAL THEOREM OF CALCULUS

                                                                                                Example 3.3.11
While the previous example could be computed using signed areas, the following example
would be very difficult to compute without using the Fundamental Theorem of Calculus.

Example 3.3.12

Compute 0 ³/2 sin xdx.
Solution.

    · Once again, the crux of the solution is guessing the antiderivative of sin x -- that is
       finding a function whose derivative is sin x.

· The standard derivative that comes closest to sin x is

                               ddx cos x = ¡ sin x
  which is the derivative we want, multiplied by a factor of ¡1.

· Just as we did in the previous example, we multiply this equation by a constant to
   remove this unwanted factor:

               (¡1) ¤ ddx cos x = (¡1) ¤ (¡ sin x)                        giving us
                 d ¡ cos x = sin x

                        dx

   This tells us that ¡ cos x is an antiderivative of sin x.

· Now it is straightforward to compute the integral:

   » /2 /2                                     since ¡ cos x is the antiderivative of sin x

       sin xdx = ¡ cos x|0

     0

             = ¡ cos 2 + cos 0

                  = 0+1 = 1

                                                                          Example 3.3.12

Example 3.3.13

         ³2 1

Find 1 x dx.
Solution.

·  Once  again,  the  crux  of  the  solution  is  guessing  a  function  whose  derivative  is  1.
   Our standard way to differentiate powers of x, namely
                                                                                                 x

                                     ddx xn = nxn¡1,

                                               149
INTEGRATION                         3.3 THE FUNDAMENTAL THEOREM OF CALCULUS

doesn't work in this case -- since it would require us to pick n = 0 and this would
give

                                    ddx x0 = ddx 1 = 0.

· Fortunately, we also know28 that

                                              ddx ln x = 1x
which is exactly the derivative we want.

· We're now ready to compute the prescribed integral.

             »2 1 2                 since ln x is an antiderivative of 1/x
                                                                since ln 1 = 0
                 dx = ln x|1

              1x

                    = ln 2 ¡ ln 1

                       = ln 2

                                                             Example 3.3.13

 Example 3.3.14

     ³¡1 1
Find ¡2 x dx.

Solution.
    · As we saw in the last example,
                                                     ddx ln x = 1x
       and if we naively use this here, then we will obtain

                             » ¡1 1 dx = ln(¡1) ¡ ln(¡2)

                                      ¡2 x

       which makes no sense since the logarithm is only defined for positive numbers29.

  · We can work around this problem using a slight variation of the logarithm -- ln |x|.

28 To align with what you probably saw in high school, we'll use ln x to denote the natural logarithm.
      This is unambiguous - ln x is always the same as loge x.
      On the other hand, the precise meaning of log x is not universal. The implied base may be 10 (com-
      mon in chemistry and physics), e (common in math and computer languages like Java, C, Python, and
      MATLAB), or 2 (common in computer science).

29 This is not entirely true -- one can extend the definition of the logarithm to negative numbers, but to
      do so one needs to understand complex numbers which is a topic beyond the scope of this course.

                                                         150
INTEGRATION                           3.3 THE FUNDAMENTAL THEOREM OF CALCULUS

- When x ¡ 0, we know that |x| = x and so we have

               ln |x| = ln x                        differentiating gives us
             ddx ln |x| = ddx ln x = 1x .

- When x 0 we have that |x| = ¡x and so

             ln |x| = ln(¡x)               differentiating with the chain rule gives

             ddx ln |x| = ddx ln(¡x)
             = 1 ¤ (¡1) = 1
             (¡x)                     x

- Indeed, more generally we should write the indefinite integral of 1/x as

                            » 1 dx = ln |x| + C

                                              x

which is valid for all positive and negative x. It is, however, undefined at x = 0.

· We're now ready to compute the prescribed integral.

» ¡1 1 dx = ln |x|§§§§¡1                            since ln |x| is an antiderivative of 1/x
¡2 x         ¡2
             = ln | ¡ 1| ¡ ln | ¡ 2| = ln 1 ¡ ln 2
             = ¡ ln 2 = ln 1/2.

                                                       Example 3.3.14

    This next example raises a nasty issue that requires a little care. We know that the
function 1/x is not defined at x = 0 -- so can we integrate over an interval that contains
x = 0 and still obtain an answer that makes sense? More generally can we integrate a
function over an interval on which that function has discontinuities?

 Example 3.3.15

         ³1 1

Find ¡1 x2 dx.

Solution. Beware that this is a particularly nasty example, which illustrates a booby trap
hidden in the Fundamental Theorem of Calculus. The booby trap explodes when the
theorem is applied sloppily.

    · The sloppy solution starts, as our previous examples have, by finding an antideriva-
       tive of the integrand. In this case we know that

                                    d 1 dx x = ¡ x21
    which means that ¡x¡1 is an antiderivative of x¡2.

                                                         151
INTEGRATION                            3.3 THE FUNDAMENTAL THEOREM OF CALCULUS

· This suggests (if we proceed naively) that

   ¡1 x » 1 ¡2dx = ¡ 1x §§§1§¡1        since ¡1/x is an antiderivative of 1/x2
            = ¡1 ¡
                                 ¡1
                       1           ¡1

            = ¡2

   Unfortunately,

· At this point we should really start to be concerned. This answer cannot be correct.
   Our integrand, being a square, is positive everywhere. So our integral represents the
   area of a region above the x-axis and must be positive.

· So what has gone wrong? The flaw in the computation is that the Fundamental
   Theorem of calculus, which says that

                   if FI(x) = f (x) then f (x)dx = F(b) ¡ F(a), » b
                                                                           a

   is only applicable when FI(x) exists and equals f (x) for all x between a and b.

·  In this case FI(x)  =  1   does not exist for x  = 0.  So we cannot apply the Fundamental
                          x2
   Theorem of Calculus as we tried to above.

                               ³1 1

An integral, like ¡1 x2 dx, whose integrand is undefined somewhere in the domain of

integration is called improper. We'll give a more thorough treatment of improper integrals
later in the text. For now, we'll just say that the correct way to define (and evaluate)
improper integrals is as a limit of well-defined approximating integrals. We shall later see

                            ³1 1

that, not only is ¡1 x2 dx not negative, it is infinite.

                                                                                                Example 3.3.15

    The above examples have illustrated how we can use the fundamental theorem of
calculus to convert knowledge of derivatives into knowledge of integrals. We are now in
a position to easily build a table of integrals. Here is a short table of the most important
derivatives that we know.

   F(x)      1 xn sin x cos x tan x ex ln |x| arcsin x arctan x

   f (x) = FI(x) 0 nxn¡1 cos x ¡ sin x sec2 x ex          1  c1    1
                                                          x
                                                                      2
                                                             1¡x2  1+x

Of course we know other derivatives, such as those of sec x and cot x, however the ones
listed above are arguably the most important ones. From this table (with a very little
massaging) we can write down a short table of indefinite integrals.

                                                         152
INTEGRATION                   3.3 THE FUNDAMENTAL THEOREM OF CALCULUS

Theorem3.3.16 (Important indefinite integrals).

             f (x) F(x) = ³ f (x)dx

             1                            x+C

             xn            1  xn+1  +  C  provided   that  n  $  ¡1
                         n+1

             1x ln |x| + C

             ex                           ex + C

             sin x                     ¡ cos x + C

             cos x                        sin x + C

              sec2 x                    tan x + C
                                       arcsin x + C
             c 1 1 ¡ x2                arctan x + C

                 1
              1 + x2

 Example 3.3.17
Find the following integrals

         ³7 x

  (i) 2 e dx

         ³2 1

 (ii) ¡2 1+x2 dx

         ³3 3

(iii) 0(2x + 7x ¡ 2)dx

Solution. We can proceed with each of these as before -- find the antiderivative and then
apply the Fundamental Theorem. The third integral is a little more complicated, but we
can split it up into monomials using Theorem 3.2.1 and do each separately.

                                                         153
INTEGRATION                              3.3 THE FUNDAMENTAL THEOREM OF CALCULUS

(i) An antiderivative of ex is just ex, so

                                  » 7 §§7
                                     exdx = ex§§
                                  2               2

                                            = e7 ¡ e2 = e2(e5 ¡ 1).

(ii)  An antiderivative of    1   is arctan(x), so
                            1+x2

                            » 2 1 §§2

                                                                                         §

                                       2 dx = arctan(x)§
                               ¡2 1 + x                                                   ¡2
                                            = arctan(2) ¡ arctan(¡2)

      We can simplify this a little further by noting that arctan(x) is an odd function, so

      arctan(¡2) = ¡ arctan(2) and thus our integral is

                                            = 2 arctan(2)

(iii) We can proceed by splitting the integral using Theorem 3.2.1(d)

             »3                                »3                                           »3         »3
                 (2x3 + 7x ¡ 2)dx = 2x3dx + 7xdx ¡ 2dx
             0                                 0                                              0              0
                                               »3                                              »3               »3
                                            = 2 x3dx + 7 xdx ¡ 2 dx
                                                    0                                            0              0

      and because we know that x4/4, x2/2, x are antiderivatives of x3, x, 1 respectively,
      this becomes

                                               x4 3 7x2 3 3
                                            =          +                                            ¡ [2x]0
                                                  20                                        20
                                            = 812 + 7 ¤ 9 2 ¡ 6
                                            = 81 + 63 ¡ 12 = 132 = 66.
                                                       2                                            2

      We can also just find the antiderivative of the whole polynomial by finding the an-
      tiderivatives of each term of the polynomial and then recombining them. This is
      equivalent to what we have done above, but perhaps a little neater:

                            » 3(2x3 + 7x ¡ 2)dx = x4 + 7x2 ¡ 3 2x
                            0                             22                                           0
                                                     = 812 + 7 ¤ 9 2 ¡ 6 = 66.

                                                                                                                    Example 3.3.17

                                               154
INTEGRATION                  3.3 THE FUNDAMENTAL THEOREM OF CALCULUS

3.3.2  Marginal Cost and Marginal Revenue

 Definition3.3.18.
The total cost function, TC(q), is the cost of producing q of units of a good.

   · We call TC(0) (the cost incurred for producing q = 0 units) the fixed cost,
       FC.

  · The quantity TC(q) ¡ TC(0) is the variable cost, which we call VC(q).

Total cost is, therefore, the sum of fixed and variable costs:
                                     TC(q) = FC + VC(q)

    Fixed cost encompasses all expenses that do not change with quantity (such as rent on
a factory space, which is the same whether you make 1 or 1000 units). Fixed cost is a
constant, and generally nonzero. We can think of these expenses as the cost of setting up a
business, incurred before the first unit is ever produced, hence the definition of fixed costs
as TC(0).

    Variable cost consists of expenses that depend on the quantity produced. A typical
example of such an expense is raw materials: producing more units means using more
raw materials. Note that the variable cost varies with the quantity q produced, while the
fixed cost is independent of q.

Consider the cost of making "one more unit" of output, after having already made q
units: TC(q + 1) ¡ TC(q). Using the definition of the derivative, we can approximate this
quantity  by  dTC :

               dq

                     dTC = lim TC(q + h) ¡ TC(q)  TC(q + 1) ¡ TC(q)1
                     dq hÑ0  h

This motivates the definition of a marginal cost.

 Definition3.3.19.
Let TC(q) be the total cost of producing q units of output of a particular good.
The marginal cost of producing the good is defined as

                                     MC(q) = ddq TC(q) .

The marginal cost is generally interpreted as the change in cost due to producing one
                                                    155
INTEGRATION           3.3 THE FUNDAMENTAL THEOREM OF CALCULUS

additional unit. This interpretation follows from the definition of the derivative:

                   MC(q) = ddq TC(q)
                      = lim TC(q + h) ¡ TC(q)
                      hÑ0                          h
                       TC(q + 1) ¡ TC(q)

where we set h = 1 for our approximation.
    Suppose we know the marginal cost function, MC(q), and we want to find the total

cost function, TC(q). By the Fundamental Theorem of Calculus,

                                                                                                  »

                                        TC(q) = MC(q) dq + C

for some constant C. In order to find C, we use the initial value
                                                 TC(0) = FC.

Example 3.3.20 (From marginal cost to total cost)

Suppose a product has fixed cost of $100, and its marginal cost function is MC(q) =

e¡q + 3. What is its total cost function?

Solution. Using the Fundamental Theorem of Calculus Part 1, given the definition MC(q) =
d
dq  TC  , we see:

                   »                               »
                   TC(q) = MC dq + C = e¡q + 3 dq + C

Antidifferentiating by inspection,

                           = ¡e¡q + 3q + C

Using FC=T(0):

                   100 = T(0) = ¡e¡0 + 3 ¤ 0 + C = ¡1 + C

                            101 = C

All together,

                   TC(q) = ¡e¡q + 3q + 101

                                                                                                Example 3.3.20
    In addition to considering total and marginal costs, we can consider total and marginal
revenue.

                                                         156
INTEGRATION                      3.3 THE FUNDAMENTAL THEOREM OF CALCULUS

Definition3.3.21.

Suppose the total revenue collected from q units of output is given by the func-
tion TR(q), with TR(0) = 0 (since selling no products leads to no revenue). We
define the marginal revenue to be

                                 MR(q) = ddq TR(q) .

We define the unit price to be

                                 P(q) = TR(q) q

for q ¡ 0.

    We think of marginal revenue as the extra revenue gained by producing one extra unit
of output. As with the interpretation of marginal cost, this follows from the definition of
the derivative, approximated with h = 1.

    For unit price, we assume that each unit is sold for the same amount, but that amount is
determined by the number of units of output q. So if 100 units are sold, each unit is priced
at P(100); but a larger production of 1000 units would lead to each unit being priced at
P(1000).

 Example 3.3.22

Suppose the marginal revenue function for a product is MR(q) = 10 ¡ 1+3q2 . Let P be the

price at which each unit is sold, and suppose 10 units are sold. Find P.

Solution. First, we use the Fundamental Theorem of Calculus Part 1 to find the total
revenue function.

                              »          »    10 ¡ 1 + q2 3

                   TR = MRdq + C =                           dq + C

Referring to Theorem 3.3.16,

                   = 10q ¡ 3 arctan q + C

Now we use the initial value TR(0) = 0.

               0 = TR(0) = 10(0) ¡ 3 arctan 0 + C

                          0=C

All together,

               TR(q) = 10q ¡ 3 arctan q

If 10 units are sold, the unit price is

        P(10) = TR(10) 10 = 10(10) ¡ 3 arctan(10) 10 = 10 ¡ 0.3 arctan(10)  10.44

                                         157
INTEGRATION                                            3.4 SUBSTITUTION
                                                        Example 3.3.22

3.4 Substitution

In the previous section we explored the Fundamental Theorem of Calculus and the link it
provides between definite integrals and antiderivatives. Indeed, integrals with simple in-
tegrands are usually evaluated via this link. In this section we start to explore methods for
integrating more complicated integrals. We have already seen -- via Theorem 3.2.1 -- that
integrals interact very nicely with addition, subtraction and multiplication by constants:

             »b            »b                  »b
                 (A f (x) + Bg(x)) dx = A f (x)dx + B g(x)dx
             a                 a               a

for A, B constants. By combining this with the list of indefinite integrals in Theorem 3.3.16,
we can compute integrals of linear combinations of simple functions. For example

»4                »4  »4                       »4
    ex ¡ 2 sin x + 3x2 dx = exdx ¡ 2 sin xdx + 3 x2dx
1                 1            1               1
                                               x3 §§4
                  = ex + (¡2) ¤ (¡ cos x) + 3      §          and so on
                                               31  §

Of course there are a great many functions that can be approached in this way, however
there are some very simple examples that cannot.

    »                 »           » x dx

      sin(x)dx          xexdx       x2 ¡ 5x + 6

In each case the integrands are not linear combinations of simpler functions; in order to
compute them we need to understand how integrals (and antiderivatives) interact with
compositions, products and quotients. We reached a very similar point in our differential
calculus course where we understood the linearity of the derivative,

                                  ddx (A f (x) + Bg(x)) = A d f dx + B dg dx ,
but had not yet seen the chain, product and quotient rules30. While we will develop tools
to find the second and third integrals in later sections, we should really start with how to
integrate compositions of functions.

    It is important to state up front, that in general one cannot write down the integral of
the composition of two functions -- even if those functions are simple. This is not because
the integral does not exist. Rather it is because the integral cannot be written down as
a finite combination of the standard functions we know. A very good example of this,

30 If your memory of these rules is a little hazy then you really should go back and revise them before
      proceeding. You will definitely need a good grasp of the chain rule for what follows in this section.

                      158
INTEGRATION                                                              3.4 SUBSTITUTION

which we encountered in Example 3.3.4, is the composition of ex and ¡x2. Even though

we know

» » 1 x3 + C
exdx = ex + C                              and              ¡x2dx = ¡3

there is no simple function that is equal to the indefinite integral

                                           »

                                             e¡x2 dx.

even though the indefinite integral exists. In this way integration is very different from
differentiation.

    With that caveat out of the way, we can introduce the substitution rule. The substitu-
tion rule is obtained by antidifferentiating the chain rule. In some sense it is the chain rule
in reverse. For completeness, let us restate the chain rule:

      Theorem3.4.1 (The chain rule).

Let F(u) and u(x) be differentiable functions and form their composition
F(u(x)). Then

                      ddx F u(x) = FI u(x) ¤ uI(x)

Equivalently, if y(x) = F(u(x)), then

                            dy dx = dF du ¤ du dx .

Consider a function f (u), which has antiderivative F(u). Then we know that

                »                          »
                   f (u)du = FI(u)du = F(u) + C

Now take the above equation and substitute into it u = u(x) -- i.e. replace the variable u
with any (differentiable) function of x to get

                   »                    §

                      f  (  u  )  d  u  §          = F(u(x)) + C

                                        §  u=u(x)
                                        §

But now the right-hand side is a function of x, so we can differentiate it with respect to x
to get

                          ddx F(u(x)) = FI(u(x)) ¤ uI(x)
This tells us that F(u(x)) is an antiderivative of the function FI(u(x)) ¤ uI(x) = f (u(x))uI(x).

Thus we know

             »                                           »            §
                f u(x) ¤ uI(x) dx = F u(x) + C = f (u) du§§§
                                                                         u=u(x)

This is the substitution rule for indefinite integrals.

                                              159
INTEGRATION                                                     3.4 SUBSTITUTION

Theorem3.4.2 (The substitution rule -- indefinite integral version).

For any differentiable function u(x):

                       »                    »   §
                          f (u(x))uI(x)dx = f (u)du§§§
                                                        u=u(x)

    In order to apply the substitution rule successfully we will have to write the integrand

in the form f (u(x)) ¤ uI(x). To do this we need to make a good choice of the function u(x);

after that it is not hard to then find f (u) and uI(x). Unfortunately there is no one strategy

for choosing u(x). This can make applying the substitution rule more art than science31.
Here we suggest two possible strategies for picking u(x):

(1) Factor the integrand and choose one of the factors to be uI(x). For this to work, you

     must be able to easily find the antiderivative of the chosen factor. The antiderivative
    will be u(x).
(2) Look for a factor in the integrand that is a function with an argument that is more
    complicated than just "x". That factor will play the role of f u(x) Choose u(x) to be
     the complicated argument.
Here are two examples which illustrate each of those strategies in turn.
 Example 3.4.3

Consider the integral

                          »

                            9 sin8(x) cos(x)dx

We want to massage this into the form of the integrand in the substitution rule -- namely

f (u(x)) ¤ uI(x). Our integrand can be written as the product of the two factors

                              l9osoionmo 8(oxon) ¤ clooom s(oxon)

                                                              first factor second factor

and we start by determining (or guessing) which factor plays the role of uI(x). We can
choose uI(x) = 9 sin8(x) or uI(x) = cos(x).

   · If we choose uI(x) = 9 sin8(x), then antidifferentiating this to find u(x) is really not

       very easy. So it is perhaps better to investigate the other choice before proceeding
       further with this one.

   · If we choose uI(x) = cos(x), then we know (Theorem 3.3.16) that u(x) = sin(x). This

       also works nicely because it makes the other factor simplify quite a bit 9 sin8(x) =
       9u8. This looks like the right way to go.

31 Thankfully this does become easier with experience and we recommend that the reader read some
      examples and then practice a LOT.

                                       160
INTEGRATION                                                              3.4 SUBSTITUTION

So we go with the second choice. Set uI(x) = cos(x), u(x) = sin(x), then

»                            »
   9 sin8(x) cos(x)dx = 9u(x)8 ¤ uI(x)dx

                             »            §

                             = 9u8du§§    §u=sin(x)                      by the substitution rule

We are now left with the problem of antidifferentiating a monomial; this we can do with
Theorem 3.3.16.

                                                                                                   §

                                     = u9 + C §§

                                                                      §u=sin(x)

                                     = sin9(x) + C

Note that 9 sin8(x) cos(x) is a function of x. So our answer, which is the indefinite integral
of 9 sin8(x) cos(x), must also be a function of x. This is why we have substituted u =
sin(x) in the last step of our solution -- it makes our solution a function of x.

                                                                                                Example 3.4.3

 Example 3.4.4
Evaluate the integral

                                      »

                                        3x2 cos(x3)dx

Solution. Again we are going to use the substitution rule and helpfully our integrand is a
product of two factors

                                      ¤ 2          lcoo osm ( xo on 3 )

                                   loo3m x oon

                                   first factor second factor

The second factor, cos x3 is a function, namely cos, with a complicated argument, namely

x3. So we try u(x) = x3. Then uI(x) = 3x2, which is the other factor in the integrand. So

the integral becomes

»                         »
   3x2 cos(x3)dx = uI(x) cos u(x) dx
                                                                         just swap order of factors
                             »                                             by the substitution rule

                       = cos u(x) uI(x)dx                                    using Theorem 3.3.16)

                          »           §

                                      §
                       = cos(u)du§§
                                         u=x3
                                          §

                       =  (sin(u)  +  C)  §

                                          §  u=x3
                                          §

                       = sin(x3) + C

                                             161
INTEGRATION                                                           3.4 SUBSTITUTION

                                                                      Example 3.4.4

Now let's look at a definite integral.

             ³1 x  x
Example 3.4.5 0 e sin(e )dx

Compute

                                                » 1 ex sin ex dx.

                                                                   0

Solution. Again we use the substitution rule.

· The integrand is again the product of two factors and we can choose uI(x) = ex or
  uI(x) = sin(ex).

· If we choose uI(x) = ex then u(x) = ex and the other factor becomes sin(u) --

   this looks promising. Notice that if we applied the other strategy of looking for a
   complicated argument then we would arrive at the same choice.

· So we try uI(x) = ex and u(x) = ex. This gives (if we ignore the limits of integration

   for a moment)

         »            »
            ex sin ex dx = sin u(x) uI(x)dx
                                                                      apply the substitution rule

                      »                 §

                                        §
                   = sin(u)du§§
                                           u=ex§

                   = (¡ cos(u) + C) §§§

                                                  u=ex

                   = ¡ cos ex + C

· But what happened to the limits of integration? We can incorporate them now. We

  have just shown that the indefinite integral is ¡ cos(ex), so by the fundamental the-

   orem of calculus

                    ex sin ex dx = ¡ cos ex » 1 10
                                            0
                                  = ¡ cos(e1) ¡ (¡ cos(e0))
                                  = ¡ cos(e) + cos(1)

                                                                      Example 3.4.5

The example below introduces a special case where the "inside" function is linear.
                                                    162
INTEGRATION                                                      3.4 SUBSTITUTION

 Example 3.4.6                                                   »

Compute the indefinite integrals                                   e3x¡2dx

             » c2x + 1dx and

Solution.

· Starting with the first integral, we see that it is not too hard cto spot the complicated

   argument. If we set u(x) = 2x + 1 then the integrand is just u.

·  Hence we substitute 2x + 1 Ñ u and dx  Ñ   I1 du   =  21 du:

                                             u (x)

                            » c » 2x + 1dx = cu 1du2

                                       = u1/2 » 1 du2

                                          2 3/2 1           §

                                       = 3 u ¤ 2 u=2x+1 + C §§
                                                            §

                                       = 1 (2x + 1)3/2 + C3

· We can evaluate the second integral in much the same way. Set u(x) = 3x ¡ 2 and
   replace  dx  by   I1 du     31 du:
                            =
                    u (x)

                               e3x » ¡2dx = eu » 1 du

                                                      3
                                                  1 u §§§

                                          = 3 u=3x e + C § ¡2
                                          = 1 e3x¡2 + C

                                                3

                                                                                                Example 3.4.6
This last example illustrates that substitution can be used to easily deal with arguments of
the form ax + b, i.e. that are linear functions of x, and suggests the following theorem.

    Theorem3.4.7.
   Let F(u) be an antiderivative of f (u) and let a, b be constants. Then

                                 » f (ax + b)dx = 1 F(ax + b) + C
                                                          a

                                       163
INTEGRATION                                                                                              3.4 SUBSTITUTION

Proof. We can show this using the substitution rule. Let u(x) = ax + b so uI(x) = a, then

       » » f (ax + b)dx = f (u) ¤ I1 du
                                             u (x)
                        » = 1 f (u)du
                                a
                        = 1 » f (u)du
                             a                                                              since a is a constant
                             1 §§                                   since F(u) is an antiderivative of f (u)
                        = F(u)§§                    +C
                             a
                                            u=ax+b
                        = 1a F(ax + b) + C.

3.4.1  Substitution and Definite Integrals

Theorem 3.4.2, the substitution rule for indefinite integrals, tells us that if F(u) is any

antiderivative for f (u), then F u(x) is an antiderivative for f u(x) uI(x). So the Funda-

mental Theorem of Calculus gives us

    f u(x) u » b I(x) dx = F u(x) §§§§x=b
    a                                             x=a
                             = F u(b) ¡ F u(a)

                                » u(b)       f (u) du                   since F(u) is an antiderivative for f (u)

                             =      u(a)

and we have just found

       Theorem3.4.8 (The substitution rule -- definite integral version).

    For any differentiable function u(x):

                                    f (u(x))u » b I(x)dx = f (u)du » u(b)
                                        a                               u(a)

    Notice that to get from the integral on the left hand side to the integral on the right
hand side you

  · substitute32 u(x) Ñ u and uI(x)dx Ñ du,

   · set the lower limit for the u integral to the value of u (namely u(a)) that corresponds
       to the lower limit of the x integral (namely x = a), and

32  A  good  way  to    remember    this    last  step  is  that    we  replace  du dx    by   just  du  --  which  looks   like  we

                                                                                 dx
    cancelled out the dx terms: dudx = du. While using "cancel the dx" is a good mnemonic (memory
                                        dx
    aid),  you  should  not  think  of  the  derivative     du  as  a  fraction  --  you  are  not   dividing  du  by  dx.
                                                            dx

                                                                164
INTEGRATION                                                         3.4 SUBSTITUTION

· set the upper limit for the u integral to the value of u (namely u(b)) that corresponds
   to the upper limit of the x integral (namely x = b).

                                                                    ³b                   I
Also note that we now have two ways to evaluate definite integrals of the form a f u(x) u (x) dx.

· We can find the indefinite integral ³ f u(x) uI(x) dx, using Theorem 3.4.2, and then

   evaluate the result between x = a and x = b. This is what was done in Example 3.4.5.

· Or we can apply Theorem 3.4.2. This entails finding the indefinite integral ³ f (u) du
   and evaluating the result between u = u(a) and u = u(b). This is what we will do
   in the following example.

                ³1 2   3
 Example 3.4.9  0 x sin(x + 1)dx
Compute

                          »1

                             x2 sin x3 + 1 dx

                            0

Solution.

· In this example the integrand is already neatly factored into two pieces. While we
   could deploy either of our two strategies, it is perhaps easier in this case to choose
   u(x) by looking for a complicated argument.

· The second factor of the integrand is sin x3 + 1 , which is the function sin evaluated

  at x3 + 1. So set u(x) = x3 + 1, giving uI(x) = 3x2 and f (u) = sin(u)
· The first factor of the integrand is x2 which is not quite uI(x), however we can easily

   massage the integrand into the required form by multiplying and dividing by 3:

                      x2 sin x3 + 1 = 13 ¤ 3x2 ¤ sin x3 + 1 .

· We want this in the form of the substitution rule, so we do a little massaging:

           » 1 x2 sin  x3 + 1 dx = » 1 1 0 3 ¤ 3x2 ¤ sin x3 + 1 dx

             0                          1 3 2 » 1

                                = 3 0 sin x + 1 ¤ 3x dx             by Theorem 3.2.1(c)

                                  165
INTEGRATION                                                          3.4 SUBSTITUTION

· Now we are ready for the substitution rule:

1 » 1 sin             2 1 3 2 » 1
30           x3 + 1   ¤ 3x dx =  sin x + 1 ¤ loo3m x oon dx
                                 3 0 loooooomoooooon =uI(x)
                                          = f (u(x))

                         = 1 » 1 f (u(x))uI(x)dx                     with u(x) = x3 + 1 and f (u) = sin(u)
                                                                                        by the substitution rule
                            30
                         = 1 » u(1) f (u)du                                      since u(0) = 1 and u(1) = 2

                            3 u(0)

                         = 1 » 2 sin(u)du
                            31

                         = 13 ¡ cos(u) 12
                         = 1 ¡ cos(2) ¡ (¡ cos(1))

                            3

                         = cos(1) ¡ cos(2) 3 .

                                                                     Example 3.4.9

    There is another, and perhaps easier, way to view the manipulations in the previous
example. Once you have chosen u(x) you

  · make the substitution u(x) Ñ u,
  · replace dx Ñ uI1(x) du.

In so doing, we take the integral

a f (u(x)) ¤ u » b I(x)dx = u f (u) (a) ¤ u » u(b) I(x) ¤ uI1(x) du

                         » u(b)  f (u)du                             exactly the substitution rule

                      =  u(a)

but we do not have to manipulate the integrand so as to make uI(x) explicit. Let us redo

the previous example by this approach.

Example 3.4.10 (Example 3.4.9 revisited)

Compute the integral

                                 »1

                                    x2 sin x3 + 1 dx

                                   0

Solution.

                                          166
INTEGRATION                                                                   3.4 SUBSTITUTION

· We have already observed that one factor of the integrand is sin x3 + 1 , which is
   sin evaluated at x3 + 1. Thus we try setting u(x) = x3 + 1.

·  This  makes  uI(x)  =  3x2,    and  we  replace  u(x)   =  x3 + 1   Ñ  u  and   dx  Ñ   I1 du   =

    12 du:                                                                                u (x)

   3x

                      » 1 x2 sin  x3 + 1   dx =    » u(1)  x2 sin x3 + 1     1 du

                        0                           u(0) loooooomoooooon 3x2

                                                              =sin(u)

                                                 » 2 x2
                                              = sin(u) 2 du
                                                    1         3x

                                              » 2 = 1 sin(u)du
                                                    13
                                              = 1 » 2 sin(u)du
                                                   31

   which is precisely the integral we found in Example 3.4.9.

                                                                                   Example 3.4.10

    We can do the following example using the substitution rule or Theorem 3.4.7:

 Example 3.4.11 0 ³/2 cos(3x)dx
Compute 0 ³/2 cos(3x)dx.

·  In  this  example  we  should  set  u   =  3x,  and    substitute  dx  Ñ   I1 du  =  31 du.  When

                                                                             u (x)
   we do this we also have to convert the limits of the integral: u(0) = 0 and u(/2) =
   3/2. This gives

                          » /2 » 3 cos /2 (3x)dx = cos(u) 1 du    3
                          0                            0
                                              = 1 3/2 sin(u)
                                                       3      0

                                              = sin(3/2) ¡ sin(0)
                                                    ¡1 ¡ 0 3 1
                                              = 3 = ¡3.

· We can also do this example more directly using the above theorem. Since sin(x) is

                                                                                                  sin(3x)

   an antiderivative of cos(x), Theorem 3.4.7 tells us that 3 is an antiderivative of
                                                     167
INTEGRATION                                                                3.4 SUBSTITUTION
       cos(3x). Hence

                        » /2 cos(3x)dx = sin(3x) /2
                        0                              30
                                               = sin(3/2) ¡ sin(0)
                                                        3
                                               = ¡13.

                                                                           Example 3.4.11

3.4.2  More Substitution Examples

       The rest of this section is just more examples of the substitution rule. We recommend
       that you after reading these that you practice many examples by yourself under exam
       conditions. Practice is integral to the learning process - there is no substitution for it.

       ³1 2
Example 3.4.12 0 x sin(1 ¡ x )dx    3

This integral looks a lot like that of Example 3.4.9. It makes sense to try u(x) = 1 ¡ x3 since
it is the argument of sin(1 ¡ x3). We

    · substitute u = 1 ¡ x3 and

    ·  replace dx with   I1 du =      1 2 du,

                        u (x)       ¡3x

    · when x = 0, we have u = 1 ¡ 03 = 1 and

    · when x = 1, we have u = 1 ¡ 13 = 0.

So

                        » 1 x2 sin  1 ¡ x3  ¤ dx = x2 » 0 sin(u) ¤ 1 2 du
                                                    1      ¡3x
                          0                    » 0 = ¡ 1 sin(u)du.

                                                    13

Note that the lower limit of the u-integral, namely 1, is larger than the upper limit, which
is 0. There is absolutely nothing wrong with that. We can simply evaluate the u-integral

in the normal way. Since ¡ cos(u) is an antiderivative of sin(u):

                                               = cos(u) 0
                                                       31

                                               = cos(0) ¡ cos(1)

                                                            3

                                               = 1 ¡ cos(1) 3 .

                                               168
INTEGRATION                                                                          3.4 SUBSTITUTION

                                                                                     Example 3.4.12

                                ³1 1

 Example 3.4.13 0 (2x+1)3 dx

                 ³1 1

Compute 0 (2x+1)3 dx.
    We could do this one using Theorem 3.4.7, but its not too hard to do without. We can

think of the integrand as the function "one over a cube" with the argument 2x + 1. So it
makes sense to substitute u = 2x + 1. That is

    · set u = 2x + 1 and

    ·  replace dx  Ñ    I1 du   =   21 du.

                       u (x)

    · When x = 0, we have u = 2 ¢ 0 + 1 = 1 and

    · when x = 1, we have u = 2 ¢ 1 + 1 = 3.

So

                            »1 1                      »3 1 1
                                            dx = 3 ¤ du
                            0 (2x + 1)3               1u 2
                                                   = 1 » 3 u¡3du
                                                      21
                                                   = 1 u¡2 3
                                                      2 ¡2 1
                                                   =1 1 ¤1¡ 1 ¤1
                                                      2 ¡2 9 ¡2 1

                                                   = 1 1 2 2 ¡ 118 = 12 ¤ 818

                                                   = 29

                                                                                     Example 3.4.13

                              ³1 x

Example 3.4.14 0 1+x2 dx

                ³1 x

Evaluate 0 1+x2 dx.
Solution.

    ·  The  integrand  can  be  rewritten   as  x  ¤    1   .  This  second  factor  suggests  that  we  should
                                                      1+x2
       try setting u = 1 + x2 -- and so we interpret the second factor as the function "one
       over" evaluated at argument 1 + x2.

    · With this choice we

                                                      169
INTEGRATION                                                                     3.4 SUBSTITUTION

   - set u = 1 + x2,

   -       substitute dx  Ñ  1   du,  and
                             2x

   - translate the limits of integration: when x = 0, we have u = 1 + 02 = 1 and
     when x = 1, we have u = 1 + 12 = 2.

· The integral then becomes

                                 » 1 x » dx 2 = x 1 du
                                    0 1 + x2       1 u 2x
                                              » 2 = 1 du
                                                   1 2u
                                              = 12 ln |u| 12
                                              = ln 2 ¡ ln 1 = ln 2.
                                                      2           2

                                                                                Example 3.4.14

Example 3.4.15 ³ x3 cos x4 + 2 dx

Compute the integral ³ x3 cos x4 + 2 dx.

Solution.

· The integrand is the product of cos evaluated at the argument x4 + 2 times x3, which
   aside from a factor of 4, is the derivative of the argument x4 + 2.

·  Hence we set u  =      x4 + 2 and then substitute dx    Ñ   I1 du    =   13 du.

                                                              u (x)        4x

· Before proceeding further, we should note that this is an indefinite integral so we
   don't have to worry about the limits of integration. However we do need to make
   sure our answer is a function of x -- we cannot leave it as a function of u.

· With this choice of u, the integral then becomes

                          »            » 4 3 1 §§§
                                      x + 2 dx = x cos(u) 3 du§
                            x3 cos                            4x        u=x4+2

                                                 » 1 §§4          u=x4+2
                                              = cos(u)du§§

                                                   1 §§
                                              =       sin(u) + C     §
                                                   4                 §
                                                                        u=x4+2
                                              = 14 sin(x4 + 2) + C.

                                                                                                Example 3.4.15
The next two examples are more involved and require more careful thinking.

                                              170
INTEGRATION                                                                         3.4 SUBSTITUTION

 Example 3.4.16 ³ c1 + x2 x3dx
Compute ³ c1 + x2 x3dx.

· An obvious choice of u is the argument inside the square root. So substitute u =
1     x2  and  dx  Ñ  1 du.
   +
                      2x

· When we do this we obtain

                       »  » 1 + x2 ¤ x3dx = cu ¤ x3 ¤ 1 du

                                                                            2x

                                      » = 1cu ¤ x2du

                                                                2

Unlike all our previous examples, we have not cancelled out all of the x's from the
integrand. However before we do the integral with respect to u, the integrand must
be expressed solely in terms of u -- no x's are allowed. (Look that integrand on the
right hand side of Theorem 3.4.2.)

· But all is not lost. We can rewrite the factor x2 in terms of the variable u. We know

  that u = 1 + x2, so this means x2 = u ¡ 1. Substituting this into our integral gives

                   »  » 1 + x2 ¤ x3dx = 1 cu ¤ x2du2

                                » = 1cu ¤ (u ¡ 1)du2

                                =2 1 u3/2 ¡ u1/2 » du

                                   1 2 5/2   2 3/2         §

                                = 2 5u ¡ 3u                §                    +C
                                                           §

                                                           §  u=x2+1

                                      1 5/2  1 3/2      §

                                = 5u ¡ 3u               §                       +C
                                                        §

                                                        §  u=x2+1

                                = 1 (x2 + 1)5/2 ¡ 1 (x2 + 1)3/2 + C.53

Oof!

· Don't forget that you can always check the answer by differentiating:

d 1 dx 5 (x2 + 1)5/2 ¡ 13 (x2 + 1)3/2 + C = d 1 dx 5 (x2 + 1)5/2 ¡ d 1 dx 3 (x2 + 1)3/2
                                  = 15 ¤ 2x ¤ 52 ¤ (x2 + 1)3/2 ¡ 13 ¤ 2x ¤ 32 ¤ (x2 + 1)1/2
                                  = x(x2 + 1)3/2 ¡ x(x2 + 1)1/2

                                                                                                                                            

                                  = x (x2 + 1) ¡ 1 ¤ x2 + 1
                                                                                                         

                                                  = x3 x2 + 1.

which is the original integrand .

                                      171
INTEGRATION                                                                   3.5 INTEGRATION BY PARTS

                                                                                              Example 3.4.16

Example 3.4.17 (³ tan xdx)

Evaluate the indefinite integral ³ tan(x)dx.
Solution.

· At first glance there is nothing to manipulate here and ³so very little to go on. How-
   ever  we  can  rewrite  tan x  as    sin x    making     the  integral          sin x dx.  This  gives  us  more
   to work with.
                                        cos x ,                                    cos x

·  Now think of the integrand as being the product                   1  x  ¤  sin  x.  This suggests that we set
                                                                   cos
   u = cos x and that we interpret the first factor as the function "one over" evaluated
   at u = cos x.

·  Substitute u   = cos x and dx     Ñ  ¡  1     x  du  to  give:
                                           sin

         » sin x    dx =  » sin x 1 §§
                                           du§§
             cos x            u ¡ sin x u=cos x

                       » 1 §§

                    = ¡ du§§
                              u u=cos x
                    = ¡ ln | cos x| + C
                    = ln §§§ 1 §§§ + C                             and if we want to go further

                           §  cos x  §

                    = ln | sec x| + C.

                                                                                              Example 3.4.17

3.5 Integration by Parts

     The Fundamental Theorem of Calculus tells us that it is very easy to integrate a derivative.
     In particular, we know that

                                            » d (F(x)) dx = F(x) + C
                                                 dx

     We can exploit this in order to develop another rule for integration -- in particular a rule
     to help us integrate products of simpler function such as

                                                                                                           »

                                                              xexdx

     In so doing we will arrive at a method called "integration by parts".

                                                              172
INTEGRATION                                             3.5 INTEGRATION BY PARTS

    To do this we start with the product rule and integrate. Recall that the product rule
says

                            ddx u(x)v(x) = uI(x) v(x) + u(x) vI(x)

Integrating this gives

             »

         uI(x) v(x) + u(x) vI(x) dx = a function whose derivative is uIv + uvI + C

                                 = u(x)v(x) + C

Now this, by itself, is not terribly useful. In order to apply it we need to have a function

whose integrand is a sum of products that is in exactly this form uI(x)v(x) + u(x)vI(x).

This is far too specialised.
    However if we tease this apart a little:

           »                             »              »
              uI(x) v(x) + u(x) vI(x) dx = uI(x) v(x) dx + u(x) vI(x) dx

Bring one of the integrals to the left-hand side

                              »          »
              u(x)v(x) ¡ uI(x) v(x)dx = u(x) vI(x)dx

Swap left and right sides

                              »                      »
                                 u(x) vI(x)dx = u(x)v(x) ¡ uI(x) v(x)dx

In this form we take the integral of one product and express it in terms of the integral of
a different product. If we express it like that, it doesn't seem too useful. However, if the
second integral is easier, then this process helps us.

    Let us do a simple example before explaining this more generally.

 Example 3.5.1 (³ xexdx)

                                                    »

Compute the integral xexdx.

Solution.

· We start by taking the equation above

                           »                      »
                              u(x) vI(x)dx = u(x)v(x) ¡ uI(x) v(x)dx

· Now set u(x) = x and vI(x) = ex. How did we know how to make this choice? We

   will explain some strategies later. For now, let us just accept this choice and keep
   going.

· In order to use the formula we need to know uI(x) and v(x). In this case it is quite
  straightforward: uI(x) = 1 and v(x) = ex.

                                 173
INTEGRATION                                                     3.5 INTEGRATION BY PARTS

· Plug everything into the formula:

                        »                      »

                           xexdx = xex ¡ exdx

So our original more difficult integral has been turned into a question of computing
an easy one.

                                 = xex ¡ ex + C

· We can check our answer by differentiating:

             d   (xe ¡ e + C) = ¤ lxoeoooo+m1ooooeon ¡e + 0x
                 xx                     xx
             dx
                           by product rule

                     = xex                                      as required.

                                                                                                Example 3.5.1
The process we have used in the above example is called "integration by parts". When

our integrand is a product we try to write it as u(x)vI(x) -- we need to choose one factor
to be u(x) and the other to be vI(x). We then compute uI(x) and v(x) and then apply the

following theorem:

Theorem3.5.2 (Integration by parts).

Let u(x) and v(x) be continuously differentiable. Then

                 »                             »
                    u(x) vI(x)dx = u(x) v(x) ¡ v(x) uI(x)dx

If we write dv for vI(x)dx and du for uI(x)dx (as the substitution rule suggests),

then the formula becomes

                     »                      »

                        udv = u v ¡ vdu

The application of this formula is known as integration by parts.
The corresponding statement for definite integrals is

             u(x) v » b I(x)dx = u(b) v(b) ¡ u(a) v(a) ¡ v(x) u » b I(x)dx
             a                                               a

    Integration by parts is not as easy to apply as the product rule for derivatives. This is
because it relies on us

(1) judiciously choosing u(x) and vI(x), then
(2) computing uI(x) and v(x) -- which requires us to antidifferentiate vI(x), and finally

                                                         174
INTEGRATION                                                 3.5 INTEGRATION BY PARTS

(3) that the integral ³ uI(x)v(x)dx is easier than the integral we started with.
   Notice that any antiderivative of vI(x) will do. All antiderivatives of vI(x) are of the

form v(x) + A with A a constant. Putting this into the integration by parts formula gives

»                                               »
   u(x)vI(x)dx = u(x) (v(x) + A) ¡ uI(x) (v(x) + A) dx

                                                   »         »
                = u(x)v(x) + Au(x) ¡ uI(x)v(x)dx ¡ A uI(x)dx

                                                             loooooomoooooon

                                                 »           =Au(x)+C

                = u(x)v(x) ¡ uI(x)v(x)dx + C

So that constant A will always cancel out.
    In most applications (but not all) our integrand will be a product of two factors so we

have two choices for u(x) and vI(x). Typically one of these choices will be "good" (in that

it results in a simpler integral) while the other will be "bad" (we cannot antidifferentiate

our choice of vI(x) or the resulting integral is harder). Let us illustrate what we mean by

returning to our previous example.
 Example 3.5.3 (³ xexdx -- again)

Our integrand is the product of two factors

             x                      and                                ex

This gives us two obvious choices of u and vI:           vI(x) = ex
                                                         vI(x) = x
                u(x) = x

                   or
                u(x) = ex

We should explore both choices:

1. If take u(x) = x and vI(x) = ex. We then quickly compute

             uI(x) = 1                       and             v(x) = ex

which means we will need to integrate (in the right-hand side of the integration by
parts formula)

                                 »                    »
                                    uI(x)v(x)dx = 1 ¤ exdx

   which looks straightforward. This is a good indication that this is the right choice of

   u(x) and vI(x).

2. But before we do that, we should also explore the other choice, namely u(x) = ex

   and vI(x) = x. This implies that
                   uI(x) = ex and v(x) = 12 x2

                                    175
INTEGRATION                                                    3.5 INTEGRATION BY PARTS

   which means we need to integrate

                              »             »
                                       I(x)v(x)dx = 1 x2 ¤ exdx.
                                       u2

   This is at least as hard as the integral we started with. Hence we should try the first
   choice.

With our choice made, we integrate by parts to get

                              »             »

                                       xexdx = xex ¡ exdx

                                       = xex ¡ ex + C.

The above reasoning is a very typical workflow when using integration by parts.
                                                                                                Example 3.5.3

Integration by parts is often used

·  to eliminate factors of x from an integrand like xex    by using that  dx  = 1 and

                                                                          dx

·  to eliminate a ln x from an integrand by using that     d ln x  =  1  and
                                                                      x
                                                           dx

· to eliminate inverse trig functions, like arctan x, from an integrand by using that, for
             d                1+1x2 .
   example,  dx  arctan x  =

 Example 3.5.4 (³ x sin xdx)
Solution.

· Again we have a product of two factors giving us two possible choices.

   (1) If we choose u(x) = x and vI(x) = sin x, then we get

                 uI(x) = 1             and                     v(x) = ¡ cos x

        which is looking promising.

   (2) On the other hand if we choose u(x) = sin x and vI(x) = x, then we have

                 uI(x) = cos x and v(x) = 12 x2

                                                                                                     ³1 2

         which is looking worse -- we'd need to integrate 2 x cos xdx.

· So we stick with the first choice. Plugging u(x) = x, v(x) = ¡ cos x into integration

   by parts gives us

                           »                        »

                              x sin xdx = ¡x cos x ¡ 1 ¤ (¡ cos x)dx

                                       = ¡x cos x + sin x + C

                                       176
INTEGRATION                                              3.5 INTEGRATION BY PARTS

· Again we can check our answer by differentiating:

              ddx (¡x cos x + sin x + C) = ¡ cos x + x sin x + cos x + 0

                                                      = x sin x

    Once we have practised this a bit we do not really need to write as much. Let us solve
it again, but showing only what we need to.
Solution.

· We use integration by parts to solve the integral.

· Set u(x) = x and vI(x) = sin x. Then uI(x) = 1 and v(x) = ¡ cos x, and

                »                                     »

                   x sin xdx = ¡x cos x + cos xdx

                      = ¡x cos x + sin x + C.

                                                         Example 3.5.4

It is pretty standard practice to reduce the notation even further in these problems. As
noted above, many people write the integration by parts formula as

                   »             »

                      udv = uv ¡ vdu

where du, dv are shorthand for uI(x)dx, vI(x)dx. Let us write up the previous example

using this notation.
 Example 3.5.5 (³ x sin xdx yet again)

Solution. Using integration by parts, we set u = x and dv = sin xdx. This makes du = 1dx

and v = ¡ cos x. Consequently

             »        »

                x sin xdx = udv

                                        »

                      = uv ¡ vdu

                                                      »

                      = ¡x cos x + cos xdx

                      = ¡x cos x + sin x + C

You can see that this is a very neat way to write up these problems and we will continue
using this shorthand in the examples that follow below.

                                                                                                Example 3.5.5

    We can also use integration by parts to eliminate higher powers of x. We just need to
apply the method more than once.

                                                         177
INTEGRATION                                                      3.5 INTEGRATION BY PARTS

Example 3.5.6 ³ x2exdx

Solution.

· Let u = x2 and dv = exdx. This then gives du = 2xdx and v = ex, and

                        »                                     »

                           x2exdx = x2ex ¡ 2xexdx

· So we have reduced the problem of computing the original integral to one of inte-
   grating 2xex. We know how to do this -- just integrate by parts again:

           »            »

              x2exdx = x2ex ¡ 2xexdx                              set u = 2x, dv = exdx
                                                                 since du = 2dx, v = ex
                                                         »

              = x2ex ¡ 2xex ¡ 2exdx

              = x2ex ¡ 2xex + 2ex + C

    · We can, if needed, check our answer by differentiating:

           ddx x2ex ¡ 2xex + 2ex + C = x2ex + 2xex ¡ (2xex + 2ex) + 2ex + 0

                                                    = x2ex

A similar iterated application of integration by parts will work for integrals

                                                          »

                                 P(x) (Aeax + B sin(bx) + C cos(cx)) dx

where P(x) is a polynomial and A, B, C, a, b, c are constants.

                                                                 Example 3.5.6

    Now let us look at integrands containing logarithms. We don't know the antiderivative
of ln x, but we can eliminate ln x from an integrand by using integration by parts with
u = ln x.

 Example 3.5.7 (³ x ln xdx)

Solution.

    · We have two choices for u and dv.
        (1) Set u = x and dv = ln xdx. This gives du = dx but v is hard to compute -- we
             haven't done it yet33. Before we go further along this path, we should look to
             see what happens with the other choice.

33 We will soon.

                                                         178
INTEGRATION                                                    3.5 INTEGRATION BY PARTS

(2)  Set u   =  ln x and dv  =  xdx.  This gives du  =  1  dx  and  v  =  1  x2,  and  we  have  to
                                                        x                 2
     integrate

                                      » » v du = 1 ¤ 1 x2dx

                                                     x2

     which is easy.

· So we proceed with the second choice.

                             » x ln xdx = 1 x2 » ln x ¡ 1 xdx22

                                      = 12 x2 ln x ¡ 14 x2 + C

· We can check our answer quickly:

              d x2 dx 2 ln x ¡ x4 + 2 C = x ln x + x2 1 2 x ¡ x2 + 0 = x ln x

                                                                             Example 3.5.7

3.5.1  Another Technique using Integration by Parts: dv = dx

       It's tempting to think of integration by parts as a product rule for integration. It can be
       used that way, but it also shows up in more surprising contexts. Integration by parts lets
       us find the antderivatives of the natural logarithm and inverse trigonometric functions,
       despite these not being the product of two functions in any obvious way.

        Example 3.5.8 (³ ln xdx)
       It is not immediately obvious that one should use integration by parts to compute the in-
       tegral

                                                                                                              »

                                                                ln xdx

       since the integrand is not a product. But we should persevere -- indeed this is a situation
       where our shorter notation helps to clarify how to proceed.
       Solution.

           · In the previous example we saw that we could remove the factor ln x by setting
              u = ln x and using integration by parts. Let us try repeating this. When we make

            this choice, we are then forced to take dv = dx -- that is we choose vI(x) = 1. Once

              we have made this sneaky move everything follows quite directly.

                                                                179
INTEGRATION                                          3.5 INTEGRATION BY PARTS

·  We then have du  =  1  dx  and  v  =  x, and the integration by parts formula gives us
                       x

                              » » ln xdx = x ln x ¡ 1 ¤ xdx

                                                          x

                                                                            »

                                     = x ln x ¡ 1dx

                                     = x ln x ¡ x + C

· As always, it is a good idea to check our result by verifying that the derivative of the
   answer really is the integrand.

                  ddx x ln x ¡ x + C = ln x + x 1x ¡ 1 + 0 = ln x

                                                                               Example 3.5.8

    The same method works almost exactly to compute the antiderivatives of arcsin(x)
and arctan(x):

 Example 3.5.9 (³ arctan(x)dx and ³ arcsin(x)dx)
Compute the antiderivatives of the inverse sine and inverse tangent functions.
Solution.

· Again neither of these integrands are products, but that is no impediment. In both

  cases we set dv = dx (ie vI(x) = 1) and choose v(x) = x.

· For inverse tan we choose u = arctan(x), so du = 1+1x2 dx:

   »                                  »      2 1 dx

      arctan(x)dx = x arctan(x) ¡ x ¤       1+x             now use substitution rule

             » = x arctan(x) ¡ wI(x) ¤ 1 dx          with w(x) = 1 + x2, wI(x) = 2x
                                            2w
             = x arctan(x) ¡ 1 » 1 dw                            but 1 + x2 ¡ 0, so
                                         2w
             = x arctan(x) ¡ 12 ln |w| + C
             = x arctan(x) ¡ 1 ln |1 + x2| + C
                                         2
             = x arctan(x) ¡ 12 ln(1 + x2) + C

                                            180
INTEGRATION                                                                    3.6 NUMERICAL INTEGRATION

    · Similarly for inverse sine we choose u = arcsin(x) so du = c 1 2 dx:

                                                                           1¡x

    » » arcsin(x)dx = x arcsin(x) ¡ c x dx                                              now use substitution rule
                                  1 ¡ x2
                                                                               with w(x) = 1 ¡ x2, wI(x) = ¡2x
                                     »I

                = x arcsin(x) ¡ ¡w (x) ¤ w¡1/2dx

                                                   2

                                      1 » w¡1/2dw

                      = x arcsin(x) + 2

                = x arcsin(x) + 1 ¤ 2w1/2 + C

                                             2

                                                                             

                = x arcsin(x) + 1 ¡ x2 + C

    · Both can be checked quite quickly by differentiating -- but we leave that as an exer-
       cise for the reader.
                                                                                                Example 3.5.9

3.6 Numerical Integration

By now the reader will have come to appreciate that integration is generally quite a bit
more difficult than differentiation. There are a great many simple-looking integrals, such

as ³ e¡x2dx, that are either very difficult or even impossible to express in terms of stan-

dard functions34. Such integrals are not merely mathematical curiosities, but arise very
naturally in many contexts. For example, the error function

                                            2 » x ¡t2

                                 erf(x) = c e dt

                                               0

is extremely important in many areas of mathematics, and also in many practical applica-
tions of statistics.

    In such applications we need to be able to evaluate this integral (and many others) at a
given numerical value of x. In this section we turn to the problem of how to find (approx-
imate) numerical values for integrals, without having to evaluate them algebraically.

    We have already seem that a definite integral can be approximated by a Riemann sum.
Returning to Definition 3.1.8, we defined

                            f (x)dx = lim f (xi » b ¸ n ¦,n) ¤ b ¡ a
                            a                         nÑV      i=1             n

                                                                                                                                              ³b

(subject to some fine print). That means we can approximate the actual value of a f (x)dx
by  evaluating  a  Riemann  sum  °n      f     x  ¦         ¤  b¡a  for  a  large-enough  value  of  n.
                                    i=1     (         n  )
                                                  i,            n

34 We apologise for being a little sloppy here -- but we just want to say that it can be very hard or even
      impossible to write some integrals as some finite sized expression involving polynomials, exponen-
      tials, logarithms and trigonometric functions. We don't want to get into a discussion of computability,
      though that is a very interesting topic.

                                                            181
INTEGRATION                                       3.6 NUMERICAL INTEGRATION

    In practice, the phrase "large enough" in the above paragraph is quite important. If a
sufficiently accurate estimation requires a huge value of n, it might take a lot of computing
power to evaluate. So, we will introduce a method that uses the same basic ideas as
Riemann sums, but that is often more efficient.

    Let's take a moment to remember where Riemann sums come from, and think about
how we might have made different choices to end up at different methods of approximat-
ing signed areas.

· We first select an integer n ¡ 0, called the "number of steps".

· We then divide the interval of integration, a ¤ x ¤ b, into n equal subintervals, each
of length x        b¡a .  The first subinterval runs from x0           a to x1        a + x.  The
                =                                                   =           =
                    n
second runs from x1 to x2 = a + 2x, and so on. The last runs from xn¡1 = b ¡ x
to xn = b.

                   y
                                                         y = f (x)

                   a = x0 x1 x2 x3 · · ·                       x
                                                  xn-1 xn = b

This splits the original integral into n pieces:

             » b » f x (x) dx = 1 » f x (x) dx + 2 » f x (x) dx + ¤ ¤ ¤ + n f (x) dx
             a            x0  x1                              xn¡1

                               ³xj

Each subintegral xj¡1 f (x) dx is approximated by the area of a simple geometric figure.
For a Riemann sum, we used a rectangle, but we could have used different shapes. Three
algorithms commonly considered approximate the area by rectangles, trapezoids and
parabolas, respectively.

                              182
INTEGRATION                                           3.6 NUMERICAL INTEGRATION

We will focus our attention on Simpson's rule, but brief overviews of the three methods
are below. (For more detailed information on the Midpoint and Trapezoid Rules, see
Appendix A.10.)

(1) The midpoint rule approximates each subintegral by the area of a rectangle of height
     given by the value of the function at the midpoint of the subinterval

                   » xj f (x)dx  f xj¡1 + xj x     2
                   xj¡1

This is illustrated in the leftmost figure above.

(2) The trapezoidal rule approximates each subintegral by the area of a trapezoid with

    vertices at (xj¡1, 0), (xj¡1, f (xj¡1)), (xj, f (xj)), (xj, 0):

                   » xj f (x)dx  1 f (xj¡1) + f (xj x2
                   xj¡1

The trapezoid is illustrated in the middle figure above.

(3) Simpson's rule approximates two adjacent subintegrals by the area under a parabola

    that passes through the points (xj¡1, f (xj¡1)), (xj, f (xj)) and (xj+1, f (xj+1)):

             » xj+1 f (x)dx  13  f (xj¡1) + 4 f (xj) + f (xj+1 x
             xj¡1

The parabola is illustrated in the right hand figure above. We shall derive the formula
for the area shortly.

    One thing that makes these rules useful is that we have methods of bounding the errors
involved. So, let's define exactly what we mean by "error."

                                 183
INTEGRATION                                                   3.6 NUMERICAL INTEGRATION

Definition3.6.1.

Suppose that  is an approximation to A. This approximation has

· absolute error |A ¡ | and

·  relative error      |A¡|  and

                          A

·  percentage     error  100  |A¡|

                                 A

We will discuss errors further in Section 3.6.2.

3.6.1  Simpson's Rule

Simpson's35 rule approximates the integral over two neighbouring subintervals by the
area between a parabola and the x-axis. In order to describe this parabola we need 3
distinct points (which is why we approximate two subintegrals at a time). That is, we
approximate

                       » x1         » x2          » x2
                             f (x) dx + f (x) dx = f (x) dx
                       x0           x1            x0

by the area bounded by the parabola that passes through the three points x0, f (x0) ,
 x1, f (x1) and x2, f (x2) , the x-axis, and the vertical lines x = x0 and x = x2. We repeat

                                   x1, f (x1)     x2, f (x2)
                              x0, f (x0)

                                                    x0 x1 x2

                                                                                                ³x4

this on the next pair of subintervals and approximate x2 f (x) dx by the area between the

x-axis and the part of a parabola with x2 ¤ x ¤ x4. This parabola passes through the three

points x2, f (x2) , x3, f (x3) and x4, f (x4) . And so on. Because Simpson's rule does
the approximation two slices at a time, n must be even.

    To derive Simpson's rule formula, we first find the equation of the parabola that passes
through the three points x0, f (x0) , x1, f (x1) and x2, f (x2) . Then we find the area

between the x-axis and the part of that parabola with x0 ¤ x ¤ x2. To simplify this
computation consider a parabola passing through the points (¡h, y¡1), (0, y0) and (h, y1).

35 Simpson's rule is named after the 18th century English mathematician Thomas Simpson, despite its
      use a century earlier by the German mathematician and astronomer Johannes Kepler. In many German
      texts the rule is often called Kepler's rule.

                                                         184
INTEGRATION                                             3.6 NUMERICAL INTEGRATION

Write the equation of the parabola as

                                             y = Ax2 + Bx + C

Then the area between it and the x-axis with x running from ¡h to h is

Ax2 » h + Bx + C dx = A x3 + B x2 h + Cx32
¡h                                              ¡h
                       = 2A3 h3 + 2Ch
                                                        it is helpful to write it as

                       = h 2Ah2 + 6C3

Now, the three points (¡h, y¡1), (0, y0) and (h, y1) lie on this parabola if and only if

                 Ah2 ¡ Bh + C = y¡1                     at (¡h, y¡1)

                                C = y0                      at (0, y0)

                 Ah2 + Bh + C = y1                         at (h, y1)

Adding the first and third equations together gives us

                       2Ah2 + (B ¡ B)h + 2C = y¡1 + y1

To this we add four times the middle equation

                       2Ah2 + 6C = y¡1 + 4y0 + y1.

This means that  area = Ax2 » h + Bx + C dx = h     3   2Ah2 + 6C
Note that here         ¡h
                 = h3 (y¡1 + 4y0 + y1)

· h is one half of the length of the x-interval under consideration

· y¡1 is the height of the parabola at the left hand end of the interval under consider-

   ation

· y0 is the height of the parabola at the middle point of the interval under considera-
   tion

· y1 is the height of the parabola at the right hand end of the interval under consider-
   ation

So Simpson's rule approximates

                 » x2  f (x)  dx      1 x  f (x0) + 4 f (x1) + f (x2)

                 x0                   3

                                           185
INTEGRATION                                                         3.6 NUMERICAL INTEGRATION

and » x4                    f (x)  dx        1 x       f (x2) + 4 f (x3) + f (x4)

                        x2                   3

and so on. Summing these all together gives:

» b » f x (x) dx = 2 » f x (x) dx + 4 » f x (x) dx + 6 » f x (x) dx + ¤ ¤ ¤ + n f (x) dx
a              x0              x2                      x4                  xn¡2

      x        f (x0) + 4 f (x1) + f (x2)  + x      f (x2) + 4 f (x3) + f (x4)
       3
                                                 3
      + x                                     ¤¤¤          x
               f (x4) + 4 f (x5) + f (x6)  +           +    3  f (xn¡2) + 4 f (xn¡1) + f (xn)
            3

   =  f (x0)+ 4 f (x1)+ 2 f (x2)+ 4 f (x3)+ 2 f (x4)+ ¤ ¤ ¤ + 2 f (xn¡2)+ 4 f (xn¡1)+ f (xn)                   x
                                                                                                                3

   In summary:

                                                                    Equation 3.6.2(Simpson's rule).

The Simpson's rule approximation is

      »b                f (x0)+ 4 f (x1)+ 2 f (x2)+ 4 f (x3)+ 2 f (x4)+ ¤ ¤ ¤

        f (x) dx 

        a

                                                    ¤ ¤ ¤ + 2 f (xn¡2)+ 4 f (xn¡1)+ f (xn)     x
                                                                                                3

where n is even and

x = b¡a ,      x0 = a,  x1 = a + x,                 x2 = a + 2x,    ¤¤¤ ,  xn¡1 = b ¡ x,              xn = b

            n

    Notice that Simpson's rule requires only slightly more work than a right Riemann sum.
In both cases we must evaluate f (x) at x = x1, . . . , xn, but we add those terms multiplied
by different constants36, and for Simpson's rule, we must also find f (x0).

                                                        ³1 4

Example 3.6.3 Approximating 0 1+x2 dx using Simpson's rule

We approximate the above integral using Simpson's rule with n = 8 steps.
Solution.

   ·  First we set up all the x-values that we will need.           Note that a    = 0, b  = 1, x     =     1  and
                                                                                                            8

               x0 = 0   x1  =  1             x2     =  2       ¤¤¤  x7     =    7          x8  =   8  =  1
                               8                       8                        8                  8

36 There is an easy generalisation of Simpson's rule that uses cubics instead of parabolas. It leads to the
      formula

» b f (x)dx = [ f (x0) + 3 f (x1) + 3 f (x2) + 2 f (x3) + 2 f (x4) + 3 f (x5) + 3 f (x6) + 2 f (x7) + ¤ ¤ ¤ + f (xn)] 3x8
a

   where n is a multiple of 3. This result is known as Simpson's second rule and Simpson's 3/8 rule. While
   one can push this approach further (using quartics, quintics etc), it can sometimes lead to larger errors
   -- the interested reader should look up Runge's phenomenon.

                                                       186
INTEGRATION                                                            3.6 NUMERICAL INTEGRATION

· Applying Equation 3.6.2 gives

» 1 4 dx                2 4 + 4 1 4 + 2 22 4 + 4 32 4
                    1+0             1 + 82 1 + 2 1 + 2  8           8
 0 1 + x2
                =   + 2 2 4 + 4 2 4 + 2 2 4 + 4 2 4 + 2 4                                    1
                        1  +    4   1      +   5        1  +  6     1  +  7      1  +  8
                               8              8               8           8            8   8¢3
                                 2              2              2           2            2

                    4 + 4 ¢ 3.938461538 + 2 ¢ 3.764705882 + 4 ¢ 3.506849315

                   + 2 ¢ 3.2 + 4 ¢ 2.876404494 + 2 ¢ 2.56 + 4 ¢ 2.265486726 + 2                          1

                 = 3.14159250                                                                          8¢3

(correct to eight decimal places).

· In this case we can compute the integral exactly (which is one of the reasons it was
   chosen as a first example):

                                    » 1 4 §§1
                                     0 1 + x2 dx = 4 arctan x§0 = 

· Our approximation agrees with  (the exact value of the integral) to six decimal
places. So the error in the approximation generated by eight steps of Simpson's rule
    |3.14159250  ¡  |           ¢   10¡7,                                                  |3.14159250¡|
is                     =  1.5              which   is   a  percent  error  of  only  100                  %  =
5 ¢ 10¡6 %.                                                                                         

                                                                                           Example 3.6.3

    When a computer algebra system approximates , or any other number, is has to ap-
proximate it by using other numbers that it either already knows or can compute. Note
that the calculation above consisted of multiplying, dividing, adding, and subtracting in-
tegers. These are all operations that we can do by hand, and can also easily program a
computer to do.

                              ³

 Example 3.6.4 0 sin x dx -- Simpson's rule
Apply Simpson's rule with n = 8 steps to the above integral.
Solution.

· We again start by setting up all the x-values that we will need. So a = 0, b = ,
x         and
    =  8

       x0 = 0       x1  =           x2 = 2                 ¤¤¤      x7 = 7             x8  =  8   =  
                           8                                                                   8
                                              8                               8

                                                   187
INTEGRATION                                                                 3.6 NUMERICAL INTEGRATION

· Applying Equation 3.6.2 gives

   »  sin x dx        sin(x0) + 4 sin(x1) + 2 sin(x2) + ¤ ¤ ¤ + 4 sin(x7) + sin(x8)                              x
     0                                                                                                            3
                 =
                      sin(0)     +  4  sin(     )  +  2  sin(  2   )  +  4  sin(  3   )  +  2  sin(  4   )
                                             8                  8                  8                  8

                                 +  4  sin(  5   )  +  2  sin(  6   )  +  4  sin(  7   )  +  sin(  8   )     
                                              8                  8                  8               8
                                                                                                            8¢3

                      = 0 + 4 ¢ 0.382683 + 2 ¢ 0.707107 + 4 ¢ 0.923880 + 2 ¢ 1.0

                      + 4 ¢ 0.923880 + 2 ¢ 0.707107 + 4 ¢ 0.382683 + 0                                    

                                                                                                         8¢3

                      = 15.280932 ¢ 0.130900

                      = 2.00027

· Again, we have chosen this example so that we can compare it against the exact
   value:

                                    » 

                     sin xdx = ¡ cos x 0 = ¡ cos  + cos 0 = 2.

                                      0

·  With  only  eight  steps  of  Simpson's   rule,     we  achieved          100  2.00027¡2    = 0.014% error.

                                                                                        2

                                                                                               Example 3.6.4

Although it is possible to exactly find numbers like sin                          using geometry, we used a
                                                                             8
calculator to find the values in the above example. Once again, it's worth thinking about
how a calculator "finds" values like this. One reason why we cover numerical integration
is to give you a sense of where calculator answers might be coming from. (Many computer
algebra systems are not transparent about how they do their computations, leaving users
to guess--and hope that the programmers haven't left any bugs.)

    So far, we have only found errors in approximations by comparing them to known
values. But in general, if we know an exact value, we have no need of an approximation.
One reason why Simpson's rule is useful is that we can say something about our error
without knowing the exact value we're approximating. The next section explains how.

3.6.2  Error Behaviour

       Now we are armed with a (relatively simple) method for numerical integration we should
       give thought to how practical it might be in the real world37. Two obvious considerations
       when deciding whether or not a given algorithm is of any practical value are
       (a) the amount of computational effort required to execute the algorithm and
       (b) the accuracy that this computational effort yields.

        37 Indeed, even beyond the "real world" of many applications in first year calculus texts, some of the
              methods we have described are used by actual people (such as ship builders, engineers and surveyors)
              to estimate areas and volumes of actual objects!

                                                                188
INTEGRATION                           3.6 NUMERICAL INTEGRATION

For algorithms like Simpson's rule, the bulk of the computational effort usually goes into
evaluating the function f (x). The number of evaluations of f (x) required for n steps of
Simpson's rules is n + 1. So the amount of effort required is essentially one evaluation
of f (x) per step. So if we double the value of n, we can expect to roughly double the
computation time needed for an evaluation.

Let's revisit Example 3.6.4 to inve³stigate38 how the error changes as we increase n. In
the table below, we approximated 39  
this integral is 2.
                                     0 sin xdx using n intervals. Recall the exact value of

                     n approximation  error # evals
                                      1.1 ¢ 10¡4 11
                     10  2.00011
                     100 2.000000011 1.1 ¢ 10¡8 101
                     1000 2.0000000000011 1.1 ¢ 10¡12 1001

40

    It seems that when we increase n by a factor of 10, we decrease the error by a factor of
104. That is, it seems like the error

                     en = |exact value ¡ approximate value|

with n steps is (roughly) of the form
                                                   en = K n41

for some constant K  1.1.

    This intuition does indeed accord with the general behaviour of Simpson's rule when
f (x) is reasonably smooth. A proof of the following theorem is beyond the scope of this
course, but Appendix A.10.4 can give you in idea of what is involved.

38 For more detail, see Appendix A.10.3.
39 Even in this simple case, we notice the opacity of computer algebra systems. The author evaluated

     the n = 10 approximation three ways: using Python, Open Office Calc, and WolframAlpha. Python re-
      turned 2.000109517315004. Open Office returned 2.0001095173, using fewer decimal places but agreeing
      in all of them. However, WolframAlpha gave 2.000006784441801 (accessed August 20, 2021). It seems
      that WolframAlpha interprets the number of intervals in a different way. It tracks the number of ap-
      proximating parabolas, as opposed to the number of x-values where we evaluate our function. So,
      to get the same approximation as the other programs, we have to ask WolframAlpha for 5 intervals
      instead of 10. Then WolframAlpha gives 2.000109517315004, exactly agreeing with Python.
40 If you need a high degree of accuracy, it's good to know how many decimals your computer algebra

   system keeps track of. When the author asked Python to evaluate sin(), it returned about 1.2 ¢ 10¡16

    (instead of the actual value, 0). That's a good indicator that values close to or smaller than 10¡16 will

      not be accurately calculated (without telling the program to use more decimal places).

                                                         189
INTEGRATION                                                         3.6 NUMERICAL INTEGRATION

    Theorem3.6.5 (Numerical integration errors).

   Assume that | f (4)(x)| ¤ L for all a ¤ x ¤ b. Then the total error introduced by
                                                                     »b

   Simpson's rule when approximating f (x)dx is bounded by

                                                                       a

                                  L (b ¡ a)5

                                                180 n4

    Here are some examples which illustrate the error bound i³s used. First, let us check

                                                                                                                 

that the above result is consistent with our observations about 0 sin xdx.

                                                                                              ³

 Example 3.6.6 Simpson's rule error approximating 0 sin x dx

                           ³

· The integral 0 sin x dx has b ¡ a = .

· To find L, we should first find the fourth derivative of f (x) = sin x:

                                          f I(x) = cos x

                                f P(x) = ¡ sin x
                               f (3)(x) = ¡ cos x

                                              f (4)(x) = sin x

   So the fourth derivative of the integrand satisfies
                                           §§ d4 §§

                            § 4 sin x§§ = | sin x| ¤ 1

                                           § dx

   for all values of x. Therefore, we take L = 1.

· So the error, en, introduced when n steps are used is bounded by

                              |en| ¤ 180 n4 L (b ¡ a)5

                                                         1 5
                                                  = 180 n4

                                   1.7 n41

·  Our  guess  for  the  error  was  around  1.1  1   ,  which  is  indeed  less  than  1.7  1   .  Remember
                                                  n4                                         n4
   the bounds given in the theorem are worst-case scenarios. They represent the biggest
   the error could possibly be, but are not exactly the same as the actual error. So our
   experiments do accords with the theorem.

                                             190
INTEGRATION                                         3.6 NUMERICAL INTEGRATION

                                                                        Example 3.6.6

    In a typical application we would be asked to evaluate a given integral to some spec-
ified accuracy. For example, if you are manufacturer and your machinery can only cut

                                                 1 th

materials to an accuracy of 10 of a millimeter, there is no point in making design specifi-

                                                 1 th

cations more accurate than 10 of a millimeter.
 Example 3.6.7

Suppose, for example, that we wish to use Simpson's rule to evaluate41

                                            » 1 e¡x2dx

                                                                        0

to within an accuracy of 10¡6.

Solution. In order to use Simpson's rule, we need to decide how many intervals to use.
To find the number of intervals, we'll take the worst-case error from Theorem 3.6.5, set it

to be less than 10¡6, and solve for n. First, we'll need to find a, b, and L.

· The integral has a = 0 and b = 1.

· The first four derivatives of the integrand are:

  ddx e¡x2 = ¡2xe¡x2
  2 d2 e¡x2 = d ¡ 2xe¡x2 = ¡2e¡x2 + 4x2e¡x2 = 2(2x2 ¡ 1)e¡x2
dx           dx
dx3 d3 e¡x2 = ddx 2(2x2 ¡ 1)e¡x2 = 2 (2x2 ¡ 1)(¡2x)e¡x2 + 4xe¡x2 = 4(¡2x3 + 3x)e¡x2
  4 d4 e¡x2 = d 4(¡2x3 + 3x)e¡x2 = 4 (¡2x3 + 3x)(¡2x)e¡x2 + (¡6x2 + 3)e¡x2
dx           dx
             = 4(4x4 ¡ 12x2 + 3)e¡x2

· As x runs from 0 to 1, 2x2 ¡ 1 increases from ¡1 to 1, so that
           0 ¤ x ¤ 1 ùñ |2x2 ¡ 1| ¤ 1, e¡x2 ¤ 1 ùñ §§2(2x2 ¡ 1)e¡x2§§ ¤ 2

· Now, for any x, e¡x2 ¤ 1. Also, for 0 ¤ x ¤ 1,

               0 ¤ x2, x4 ¤ 1                                                         so
               3 ¤ 4x4 + 3 ¤ 7                                                     and
             ¡12 ¤ ¡12x2 ¤ 0                        adding these together gives
             ¡9 ¤ 4x4 ¡ 12x2 + 3 ¤ 7

41 This is our favourite running example of an integral that cannot be evaluated algebraically -- we need
      to use numerical methods.

                                                         191
INTEGRATION                                            3.7 IMPROPER INTEGRALS

Consequently, |4x4 ¡ 12x2 + 3| is bounded by 9 and so

                 §§ d4                     §

                 §                  ¡x2 §§
                 § dx  4 e § ¤ 4 ¢ 9 = 36

So take L = 36.

· The error introduced by the n step Simpson's rule is at most

                 en ¤ 180 n4 L (b ¡ a)5
                      36 (1 ¡ 0)5 1

                   ¤ 180 n4 = 5n4

· In order for this error to be no more than 10¡6 we require n to satisfy

                  en ¤ 15n4 ¤ 10¡6                          and so
                 5n4 ¥ 106                      take fourth root
                  n4 ¥ 200000

                  n ¥ 21.15

So 22 steps of Simpson's rule will do the job.

· n = 22 steps actually results in an error of 3.5 ¢ 10¡8. The reason that we get an
error so much smaller than we need is that we have overestimated the number of
s§ teps req§uired. This, in turn, occurred because we made quite a rough bound of
§ d4
§ dx4 f (x)§ ¤ 36. If we are more careful then we will get a slightly smaller n. It§

actually turns out42 that you only need n = 10 to approximate within 10¡6.

                                                                Example 3.6.7

 3.7 Improper Integrals

3.7.1  Definitions

                                                                                                                               ³b

      To this point we have only considered nicely behaved integrals a f (x)dx. Though the
       algebra involved in some of our examples was quite difficult, all the integrals had

           · finite limits of integration a and b, and
          · a bounded integrand f (x) (and in fact continuous except possibly for finitely many

              jump discontinuities).
       Not all integrals we need to study are quite so nice.

        42 The authors tested this empirically.

                                                                192
INTEGRATION                                                                          3.7 IMPROPER INTEGRALS

       Definition3.7.1.
      An integral having either an infinite limit of integration or an unbounded inte-
      grand is called an improper integral.

    Two examples are

                      » V dx                     » and 1 dx

                      0 1 + x2                                                                      0x

The first has an infinite domain of integration and the integrand of the second tends to V

as x approaches the left end of the domain of integration. We'll start with an example that
illustrates the traps that you can fall into if you treat such integrals sloppily. Then we'll
see how to treat them carefully.

                            ³1 1

Example 3.7.2 ¡1 x2 dx

Consider the integral

                                                     » 1 1 dx

                                             ¡1 x2

If we "do" this integral completely naively then we get

                                          » 1 1 dx = x¡1 §§1§
                                                                                  §
                                          ¡1 x2            ¡1 ¡1
                                                 = 1 ¡ ¡1
                                                           ¡1 ¡1
                                                 = ¡2

which is wrong43.     In fact,    the answer is ridiculous.                          The integrand  1   ¡  0,  so the integral
has to be positive.                                                                                 x2

    The flaw in the argument is that the Fundamental Theorem of Calculus, which says
that

      if F (x) = f (x) then a f (x) dx = F(b) ¡ F(a)I³b

is applicable only when FI(x) exists and equals f (x) for all a ¤ x ¤ b. In this case FI(x) =
1   does  not  exist  for  x     0.  The  given  integral  is  improper.             We'll  see         later  that  the  correct
x2                            =
answer is +V.
                                                                                                           Example 3.7.2

                                                                                  ³V dx

Let us put this example to one side for a moment and turn to the integral a 1+x2 . In this

43 Very wrong. But it is not an example of "not even wrong" -- which is a phrase attributed to the physicist
      Wolfgang Pauli who was known for his harsh critiques of sloppy arguments. The phrase is typically
      used to describe arguments that are so incoherent that not only can one not prove they are true, but
      they lack enough coherence to be able to show they are false. The interested reader should do a little
      searchengineing and look at the concept of falisfyability.

                                                 193
INTEGRATION                                                    3.7 IMPROPER INTEGRALS

case, the integrand is bounded but the domain of integration extends to +V. We can eval-

uate this integral by sneaking up on it. We compute it on a bounded domain of integration,

       ³R dx

like a 1+x2 , and then take the limit R Ñ V. Let us put this into practice:

                                                               y = f (x)

                a                                              Rx

 Example 3.7.3  ³V dx
Solution.
                 a 1+x2

· Since the domain extends to +V we first integrate on a finite domain

                         » R dx §§R
                                        =  arctan  x  §
                         a 1+x       2                §
                                                         a
                                        = arctan R ¡ arctan a

· We then take the limit as R Ñ +V:

                         » V dx  = lim       » R dx

                         a 1 + x2 RÑV a 1 + x               2

                                 = lim arctan R ¡ arctan a
                                        RÑV
                                 = 2 ¡ arctan a.

                                                                                                Example 3.7.3
    To be more precise, we actually formally define an integral with an infinite domain
as the limit of the integral with a finite domain as we take one or more of the limits of
integration to infinity.

                                                         194
INTEGRATION                                                3.7 IMPROPER INTEGRALS

Definition3.7.4 (Improper integral with infinite domain of integration).

                               ³R

(a) If the integral a f (x) dx exists for all R ¡ a, then

                     »V                       »R
                         f (x) dx = lim f (x) dx
                     a                  RÑV a

when the limit exists (and is finite).

                                ³b

(b) If the integral r f (x) dx exists for all r b, then

                     »b                       »b
                         f (x) dx = lim f (x) dx
                     ¡V                 rÑ¡V r

when the limit exists (and is finite).

                               ³R

(c) If the integral r f (x) dx exists for all r R, then

             »V          »c                                »R
                 f (x) dx = lim f (x) dx + lim f (x) dx
             ¡V          rÑ¡V r                     RÑV c

when both limits exist (and are finite). Any c can be used.

When the limit(s) exist, the integral is said to be convergent. Otherwise it is said
to be divergent.

                                                                                   ³1 dx

    We must also be able to treat an integral like 0 x that has a finite domain of integration
but whose integrand is unbounded near one limit of integration44 Our approach is similar
-- we sneak up on the problem. We compute the integral on a smaller domain, such as

³1 dx

t x , with t ¡ 0, and then take the limit t Ñ 0+.

                              ³1 1

 Example 3.7.5 0 x dx

Solution.

· Since the integrand is unbounded near x = 0, we integrate on the smaller domain

  t ¤ x ¤ 1 with t ¡ 0:
                           » 1 1 t x dx = ln |x|§§ = t ¡ ln |t| §§1

· We then take the limit as t Ñ 0+ to obtain

                 » 1 1 » dx 1 = lim 1 dx = lim ¡ ln |t| = +V
                 0x      tÑ0+ t x             tÑ0+

44 This will, in turn, allow us to deal with integrals whose integrand is unbounded somewhere inside the
      domain of integration.

                         195
INTEGRATION                                                         3.7 IMPROPER INTEGRALS
                                                                                Example 3.7.5
    Thus this integral diverges to +V.

                                y
                                    y = 1x

                 t                                          1x

Indeed, we define integrals with unbounded integrands via this process:

Definition3.7.6 (Improper integral with unbounded integrand).

                               ³b

(a) If the integral t f (x) dx exists for all a t b, then

                    »b                           »b
                        f (x) dx = lim f (x) dx
                    a                           tÑa+ t

when the limit exists (and is finite).

                                ³T

(b) If the integral a f (x) dx exists for all a T b, then

                    »b                           »T
                        f (x) dx = lim f (x) dx
                    a                           TÑb¡ a

when the limit exists (and is finite).

                        ³T                              ³b
(c) Let a c b. If the integrals a f (x) dx and t f (x) dx exist for all a T c
and c t b, then

»b                                          »T              »b
    f (x) dx = lim f (x) dx + lim f (x) dx
a                       TÑc¡ a                              tÑc+ t

when both limit exist (and are finite).

When the limit(s) exist, the integral is said to be convergent. Otherwise it is said
to be divergent.

                                            196
INTEGRATION                                                     3.7 IMPROPER INTEGRALS

    Notice that (c) is used when the integrand is unbounded at some point in the middle
of the domain of integration, such as was the case in our original example

                                                     » 1 1 dx

                                             ¡1 x2

A quick computation shows that this integral diverges to +V

             »1 1   dx = lim         »a 12 dx + lim       »1 1 2 dx

             ¡1 x2   aÑ0 ¡1 x¡               bÑ0 b x   +

                    = lim 1 ¡ 1 + lim 1 ¡ 1
                     aÑ0¡                a bÑ0+ b
                    = +V

    More generally, if an integral has more than one "source of impropriety" (for exam-
ple an infinite domain of integration and an integrand with an unbounded integrand or
multiple infinite discontinuities) then you split it up into a sum of integrals with a single
"source of impropriety" in each. For the integral, as a whole, to converge every term in
that sum has to converge.

    For example

                   ³V dx
 Example 3.7.7 ¡V (x¡2)x2

Consider the integral

                                         » V dx

                                 ¡V (x ¡ 2)x2
  · The domain of integration that extends to both +V and ¡V.

   · The integrand is singular (i.e. becomes infinite) at x = 2 and at x = 0.

· So we would write the integral as

» V dx       » a dx                  » 0 dx               » b dx
¡V (x ¡ 2)x2 = ¡V (x ¡ 2)x2 + a (x ¡ 2)x2 + 0 (x ¡ 2)x2
                                     » 2 dx               » c dx     » V dx
                     + b (x ¡ 2)x2 + 2 (x ¡ 2)x2 + c (x ¡ 2)x2

where

      - a is any number strictly less than 0,
      - b is any number strictly between 0 and 2, and
      - c is any number strictly bigger than 2.

  So, for example, take a = ¡1, b = 1, c = 3.

· When we examine the right-hand side we see that

                                     197
INTEGRATION                                                 3.7 IMPROPER INTEGRALS

    - the first integral has domain of integration extending to ¡V
    - the second integral has an integrand that becomes unbounded as x Ñ 0¡,
    - the third integral has an integrand that becomes unbounded as x Ñ 0+,
    - the fourth integral has an integrand that becomes unbounded as x Ñ 2¡,
    - the fifth integral has an integrand that becomes unbounded as x Ñ 2+, and
    - the last integral has domain of integration extending to +V.

· Each of these integrals can then be expressed as a limit of an integral on a small
   domain.
                                                                                            Example 3.7.7

3.7.2  Examples

       With the more formal definitions out of the way, we are now ready for some (important)
       examples.

                 ³V dx

Example 3.7.8 1 xp with p ¡ 0

Solution.

· Fix any p ¡ 0.

                  ³V dx
· The domain of the integral 1 xp extends to +V and the integrand xp is continuous1

and bounded on the whole domain.

· So we write this integral as the limit

                               » V dx     = lim  » R dx

                                 1 xp RÑV 1 x            p

· The antiderivative of 1/xp changes when p = 1, so we will split the problem into

  three cases, p ¡ 1, p = 1 and p 1.

· When p ¡ 1,

                               » R dx          1 1¡p§§§R
                                     p=
                                                   x§
                                 1 x 1¡p 1
                                          = R1¡p ¡ 1
                                               1¡p

Taking the limit as R Ñ V gives

                               » V dx     = lim  » R dx

                               1 xp RÑV 1 x           p

                                          = lim R1¡p ¡ 1
                                          RÑV 1 ¡ p
                                          = ¡1 = 1
                                          1¡p p¡1

                                          198
INTEGRATION                                                      3.7 IMPROPER INTEGRALS

since 1 ¡ p 0.

· Similarly when p 1 we have

             » V dx     = lim      » R dx                      = lim R1¡p ¡ 1
                                                                 RÑV 1 ¡ p
                1 xp RÑV 1 x       p

                        = +V

because 1 ¡ p ¡ 0 and the term R1¡p diverges to +V.

· Finally when p = 1

                        » R dx = ln |R| ¡ ln 0 = ln R

                                      1x

Then taking the limit as R Ñ V gives us
                        » V dx = lim ln |R| = +V.

                                1 xp RÑV

· So summarising, we have

                           » V dx 5divergent           if p ¤ 1
                                   xp = 1              if p ¡ 1
                                1          p¡1

                                                                 Example 3.7.8

                            ³1 dx

Example 3.7.9 0 xp with p ¡ 0

Solution.

· Again fix any p ¡ 0.

                                                ³1 dx                          1
· The domain of integration of the integral 0 xp is finite, but the integrand xp becomes
unbounded as x approaches the left end, 0, of the domain of integration.

· So we write this integral as

                                   » 1 dx  = lim       » 1 dx

                                   0 xp tÑ0+ t x       p

· Again, the antiderivative changes at p = 1, so we split the problem into three cases.

· When p ¡ 1 we have

                                   » 1 dx       1 1¡p§§§1
                                         p=
                                                    x§
                                   t x 1¡p t
                                           = 1 ¡ t1¡p
                                                1¡p

                                           199
INTEGRATION                                                                   3.7 IMPROPER INTEGRALS

Since 1 ¡ p       0 when we take the limit as t Ñ 0 the term t1¡p diverges to +V and

we obtain

                                 » 1 dxp = lim            1 ¡ t1¡p  = +V

                                                       +
                                 0 x tÑ0 1 ¡ p

· When p = 1 we similarly obtain
                                         » 1 dx » 1 = lim dx

                                     0 x tÑ0+ t x

                                  = lim ¡ ln |t|

                                              tÑ0+

                                  = +V

· Finally, when p   1 we have

  since 1 ¡ p ¡ 0.               » 1 dx  = lim  » 1 dx

· In summary                     0 xp tÑ0 t x+            p

                                         = lim 1 ¡ t = 1¡p 1
                                          tÑ0+ 1 ¡ p 1 ¡ p

                                 » 1 dx   51                        if p 1

                                            1¡p                     if p ¥ 1
                                 0 xp = divergent

                                                                                        Example 3.7.9

 Example 3.7.10   ³V dx
Solution.
                  0 xp with p ¡ 0

· Yet again fix p ¡ 0.

                                                                       ³V dx
· This time the domain of integration of the integral 0 xp extends to +V, and in
addition     the  integrand  1   becomes  unbounded          as     x  approaches  the  left  end,  0,  of  the
domain of integration.       xp

· So we split the domain in two -- given our last two examples, the obvious place to
cut is at x = 1:
                                 » V dx » 1 dx » V dx
                                   0 xp = 0 xp + 1 xp

· We saw, in Example 3.7.9, that the first integral diverged whenever p ¥ 1, and we
  also saw, in Example 3.7.8, that the second integral diverged whenever p ¤ 1.

                                          200
INTEGRATION                                                     3.7 IMPROPER INTEGRALS
                                                                            Example 3.7.10
                      ³V dx

    · So the integral 0 xp diverges for all values of p.

                                ³1 dx

 Example 3.7.11 ¡1 x

This is a pretty subtle example. Look at the sketch below: This suggests that the signed

              y
                 y = 1x

-1                                                           x

                                                          1

area to the left of the y-axis should exactly cancel the area to the right of the y-axis making

                                           ³1 dx

the value of the integral ¡1 x exactly zero.

    But both of the integrals

» 1 dx » 1 = lim dx = lim  ln x 1                         = lim ln 1 = +V
0 x tÑ0+ t x  tÑ0+
                                   t                        tÑ0+ t

» 0 dx » T = lim dx = lim  ln |x| T = lim ln |T| = ¡V
¡1 x TÑ0¡ ¡1 x TÑ0¡
                                 ¡1 TÑ0¡

                   ³1 dx

diverge so ¡1 x diverges. Don't make the mistake of thinking that V ¡ V = 0. It is undefined.

And it is undefined for good reason.
    For example, we have just seen that the area to the right of the y-axis is

                               » lim 1 dx = +V

                                       tÑ0+ t x

and that the area to the left of the y-axis is (substitute ¡7t for T above)
                              » lim ¡7t dx = ¡V

                                      tÑ0+ ¡1 x

                                                         201
INTEGRATION                                                                       3.7 IMPROPER INTEGRALS

If V ¡ V = 0, the following limit should be 0.

     lim     » 1 dx » + ¡7t dx  = lim                         ln 1t + ln | ¡ 7t|
              t x ¡1 x
     tÑ0+                         tÑ0+                        ln 1t + ln(7t)

                                = lim

                                  tÑ0+

                                = lim                         ¡ ln t + ln 7 + ln t  = lim ln 7

                                  tÑ0+                                                tÑ0+

                                = ln 7

This appears to give V ¡ V = ln 7. Of course the number 7 was picked arbitrarily. You
can make V ¡ V be any number at all, by making a suitable replacement for 7.

                                                                                                Example 3.7.11

Example 3.7.12 (Example 3.7.2 revisited)

The careful computation of the integral of Example 3.7.2 is

             »1 1          dx = lim   »T 1        2 dx + lim  »1 1                2 dx

                    ¡1 x2       TÑ0¡ ¡1 x                     tÑ0+ t x

                                = lim ¡ 1 T + lim ¡ 1 1

                                  TÑ0¡ x ¡1 tÑ0+ x t

                            =V+V
Hence the integral diverges to +V.

                                                                                        Example 3.7.12

Warning3.7.13 (Sneaky Divergence).

If you don't realize that an integral diverges, you can generate answers that look
plausible but are secretly nonsense. For example, attempting to use the Fun-
                                                                                                     ³1 1

damental Theorem of Calculus on Example 3.7.2 gives ¡1 x2 dx as ¡2: a poor
approximation for positive infinity.
This mistake can be especially dangerous using computer algebra systems, where
you spend less time thinking about the integral and so have fewer chances to no-
tice that something is awry. As of this writing,45 WolframAlpha gives no warn-
                                          ³1 1
ings when you ask it to approximate ¡1 x2 dx using Simpson's Rule: it tells you
the  approximation  with   one  interval  is  2.

                                              3

                    ³V dx
 Example 3.7.14 ¡V 1+x2

45 25 August 2021

                                                         202
INTEGRATION                                                                   3.7 IMPROPER INTEGRALS

Since

                     » R dx R                        = lim arctan R = 
                lim         2 = lim arctan x
             RÑV 0 1 + x RÑV                      0   RÑV                     2

                     »0  2 dx = lim        arctan x 0= lim ¡ arctan r = 
                                                     r rÑ¡V
             lim
             rÑ¡V r 1 + x rÑ¡V                                                2

              ³V dx
The integral ¡V 1+x2 converges and takes the value .

                                                                              Example 3.7.14

Example 3.7.15

                             ³V dx

For what values of p does e x(ln x)p converge?
Solution.

· For x ¥ e, the denominator x(ln x)p is never zero. So the integrand is bounded on the

   entire domain of integration and this integral is improper only because the domain

  of integration extends to +V and we proceed as usual.

· We have

       » V dx        = lim  » R dx                                                     use substitution
                                                                              with u = ln x, du = dxx
       e x(ln x)p RÑV e x(ln x)         p

                     = lim  » ln R du

                         RÑV 1 u     p

                                      6              if p $ 1

                              1 (ln R)1¡p ¡ 1        if p = 1

                     8 = lim 1¡p
                       RÑV 7ln(ln R)

                           5            if p ¤ 1
                                        if p ¡ 1
                          divergent
                     =1

                          p¡1

       In this last step we have used similar logic that that used in Example 3.7.8, but with
       R replaced by ln R.

                                                                              Example 3.7.15

 Example 3.7.16 (the gamma function)
The gamma function (x) is defined by the improper integral

                                     (t) = xt » V ¡1e¡x dx

                                                                           0

We shall now compute (n) for all natural numbers n.

                                                         203
INTEGRATION                                                 3.7 IMPROPER INTEGRALS

· To get started, we'll compute

             (1) = e » V ¡x dx = lim e » R ¡x dx = lim ¡ e¡x R = 1
                     0              RÑV 0              RÑV  0

· Then compute

(2) = xe » V ¡x dx                                     use integration by parts with

               0                                                  u = x, dv = e¡xdx,

     = lim xe » R ¡x dx                                        v = ¡e¡x, du = dx
        RÑV 0

             = lim   ¡ xe¡x§§ + e §R » R ¡x dx
                        0        0
               RÑV
                     ¡ xe¡x ¡ e¡x R
             = lim                           0

               RÑV

             =1

For the last equality, we used that lim xe¡x = 0.
                                      xÑV

· Now we move on to general n, using the same type of computation as we just used
   to evaluate (2). For any natural number n,

(n + 1) = xne » V ¡x dx                                again integrate by parts with

                      0                                          u = xn, dv = e¡xdx,

          = lim xne » R ¡x dx                              v = ¡e¡x, du = nxn¡1dx
             RÑV 0

             = lim   ¡ xne¡x§§ + nx §R n » R ¡1e¡x dx
                           0        0
               RÑV

             = lim n xn » R ¡1e¡x dx
               RÑV 0

             = n(n)

To get to the third row, we used that lim xne¡x = 0.
                                         xÑV

· Now that we know (2) = 1 and (n + 1) = n(n), for all n  N, we can compute

                                                     204
INTEGRATION                                                        3.7 IMPROPER INTEGRALS

all of the (n)'s.

                              (2) = 1

                    (3) = (2 + 1)= 2(2) = 2 ¤ 1
                    (4) = (3 + 1)= 3(3) = 3 ¤ 2 ¤ 1
                    (5) = (4 + 1)= 4(4) = 4 ¤ 3 ¤ 2 ¤ 1

                                     ...

                    (n) = (n ¡ 1) ¤ (n ¡ 2) ¤ ¤ ¤ 4 ¤ 3 ¤ 2 ¤ 1 = (n ¡ 1)!

That is, the factorial is just46 the Gamma function shifted by one.

                                                                                         Example 3.7.16

3.7.3  Convergence Tests for Improper Integrals

It is very common to encounter integrals that are too complicated to evaluate explicitly.
Numerical approximation schemes, evaluated by computer, are often used instead (see
Section 3.6). You want to be sure that at least the integral converges before feeding it into
a computer47. Fortunately it is usually possible to determine whether or not an improper
integral converges even when you cannot evaluate it explicitly.

Remark 3.7.17. For pedagogical purpos³es, we are going to concentrate on the problem of

                                             V

determining whether or not an integral a f (x) dx converges, when f (x) has no singular-

ities for x ¥ a. Recall that the first step in analyzing any improper integral is to write it

as a sum of integrals each of has only a single "source of impropriety" -- either a domain

of integration that extends to +V, or a domain of integration that extends to ¡V, or an

integrand which is singular at one end of the domain of integration. So we are now going
to consider only the first of these three possibilities. But the techniques that we are about
to see have obvious analogues for the other two possibilities.

                                                                   ³V
Now let's start. Imagine that we have an improper integral a f (x) dx, that f (x) has
no singularities for x ¥ a and that f (x) is complicated enough th³at we cannot evaluate the
integral explicitly48. The idea is find another improper integral  V

                                                                   a g(x) dx
                                                                     ³V

· with g(x) simple enough that we can evaluate the integral a g(x) dx explicitly, or
                                 ³V
at least determine easily whether or not a g(x) dx converges, and

46 The Gamma function is far more important than just a generalisation of the factorial. It appears all over
      mathematics, physics, statistics and beyond. It has all sorts of interesting properties and its definition

   can be extended from natural numbers n to all numbers excluding 0, ¡1, ¡2, ¡3, . . . . For example, one

      can show that

                                    (1 ¡ z)(z) =  sin z .

47 Applying numerical integration methods to a divergent integral may result in perfectly reasonably
looking but very wrong answers.
                                                 ³V ¡t2
48 You could, for example, think of something like our running example a e dt.

                                 205
INTEGRATION                                                                            3.7 IMPROPER INTEGRALS

                                                                                 ³V

   · with g(x) behaving enough like f (x) for large x that the integral a f (x) dx con-

                             ³V

       verges if and only if a g(x) dx converges.
So far, this is a pretty vague strategy. Here is a theorem which starts to make it more
precise.

    Theorem3.7.18 (Comparison).

    Let a be a real number. Let f and g be functions that are defined and continuous

    for all x ¥ a and assume that g(x) ¥ 0 for all x ¥ a.

                                                         ³V                                     ³V
    (a) If | f (x)| ¤ g(x) for all x ¥ a and if a g(x) dx converges then a f (x) dx also
        converges.

                                                         ³V                               ³V
    (b) If f (x) ¥ g(x) for all x ¥ a and if a g(x) dx diverges then a f (x) diverges.

    We will not prove this theorem, but, hopefully, the following supporting arguments
should at least appear reasonable to you. Consider the figure below:

         ³V

    · If a g(x) dx converges, then the area of

                         2 (x, y) §§ x ¥ a, 0 ¤ y ¤ g(x) @ is finite.
      When | f (x)| ¤ g(x), the region
       2 (x, y) §§ x ¥ a, 0 ¤ y ¤ | f (x)| @ is contained inside 2 (x, y) §§ x ¥ a, 0 ¤ y ¤ g(x)@

       and so must also have finite area. Consequently the areas of both the regions

              2 (x, y) §§ x ¥ a, 0 ¤ y ¤ f (x) @ and 2 (x, y) §§ x ¥ a, f (x) ¤ y ¤ 0@

    are finite too49.

49  We  have  separated  the  regions  in  which  f (x)  is  positive  and  negative,  because  the  integral   ³V  f (x) dx
                                                                                                                a
                                                  2               §                    @        2            §
    represents the signed area of the union of (x, y) § x ¥ a, 0 ¤ y ¤ f (x) and (x, y) § x ¥ a, f (x) ¤
    y ¤ 0 @.

                                                         206
INTEGRATION                                                          3.7 IMPROPER INTEGRALS

     ³V

· If a g(x) dx diverges, then the area of

                     2 (x, y) §§ x ¥ a, 0 ¤ y ¤ g(x) @ is infinite.
  When f (x) ¥ g(x), the region
   2 (x, y) §§ x ¥ a, 0 ¤ y ¤ f (x) @ contains the region 2 (x, y) §§ x ¥ a, 0 ¤ y ¤ g(x) @

   and so also has infinite area.

                  ³V ¡x2

Example 3.7.19 1 e dx

We  cannot  evaluate  the  integral  ³V  e¡x2  dx  explicitly50,  however  we   would  still  like  to  un-

                                      1
derstand if it is finite or not -- does it converge or diverge?

Solution. We will use Theorem 3.7.18 to answer the question.

· So we want to find another integral that we can compute and that we can compare to
    ³V ¡x2                                                                 ¡x2
    1 e dx. To do so we pick an integrand that looks like e , but whose indefinite
    integral we know -- such as e¡x.

· When x ¥ 1, we have x2 ¥ x and hence e¡x2 ¤ e¡x. Thus we can use Theorem 3.7.18

   to compare

                                     e » V ¡x2dx with e » V ¡xdx
                                         1                    1

· The integral

                           e » V ¡x dx = lim e » R ¡x dx
                            1                      RÑV 1
                                               = lim ¡ e¡x R
                                                   RÑV            1

                                               = lim e¡1 ¡ e¡R       = e¡1

                                                 RÑV

    converges.

· So, by Theorem 3.7.18, with a = 1, f (x) = e¡x2 and g(x) = e¡x, the integral
  ³V ¡x2

    1 e dx converges too (it is approximately equal to 0.1394).

                                                                                Example 3.7.19

 Example 3.7.20  ³V ¡x2
Solution.
                  1/2 e dx

50 It has been the subject of many remarks and footnotes.

                                                         207
INTEGRATION                                          3.7 IMPROPER INTEGRALS

             ³V ¡x2                                  ³V ¡x2
· The integral 1/2 e dx is quite similar to the integral 1 e dx of Example 3.7.19.
But we cannot just repeat the argument of Example 3.7.19 because it is not true that
e¡x2 ¤ e¡x when 0 x 1.

· In fact, for 0 x 1, x2 x so that e¡x2 ¡ e¡x.

· However the difference between the current example and Example 3.7.19 is

                     » V e¡x2 » dx ¡ V e¡x2 » dx 1 = e¡x2 dx
                     1/2         1              1/2

which is clearly a well defined finite number (its actually about 0.286). It is important
to note that we are being a little sloppy by taking the difference of two integrals like
this -- we are assuming that both integrals converge. More on this below.

                               ³V ¡x2

· So we would expect that 1/2 e dx should be the sum of the proper integral inte-
³1 ¡x2                                  ³V ¡x2
gral 1/2 e dx and the convergent integral 1 e dx and so should be a conver-
gent integral. This is indeed the case. The Theorem below provides the justification.

                                                              Example 3.7.20

 Theorem3.7.21.
Let a and c be real numbers with a c an³ d let the function f (x) be continuous

                                               V

for all x ¥ a. Then the improper integral a f (x) dx converges if and only if the

                    ³V

improper integral c f (x) dx converges.

                                               ³V

Proof. By definition the improper integral a f (x) dx converges if and only if the limit

             »R                     »c          »R
             lim f (x) dx = lim         f (x) dx + f (x) dx
             RÑV a        RÑV a                 c

                          »c                    »R
                          = f (x) dx + lim f (x) dx
                          a             RÑV c

                                                                                                           ³c

exists and is finite. (Remember that, in computing the limit, a f (x) dx is a finite constant
independent of R and so can be pulled out of the limit.) But that is the case if and only if

                              ³R

the limit limRÑV c f (x) dx exists and is finite, which in turn is the case if and only if the
                    ³
          V

integral c f (x) dx converges.

 Example 3.7.22

                   ³V cx

Does the integral 1 x2+x dx converge or diverge?
Solution.

    · Our first task is to identify the potential sources of impropriety for this integral.

                                 208
INTEGRATION                                                                     3.7 IMPROPER INTEGRALS

· The domain of integration extends to +V, but we must also check to see if the in-
  tegrand contains any singularities. On the domain of integration x ¥ 1 so the de-

   nominator is never zero and the integrand is continuous. So the only problem is at

  +V.

· Our second task is to develop some intuition51. As the only problem is that the
   domain of integration extends to infinity, whether or not the integral converges will
   be determined by the behavior of the integrand for very large x.

· When x is very large, x2 is much much larger than x (which we can write as x2 4 x)
  so that the denominator x2 + x  x2 and the integrand
                               cx cx 1
                             x2 + x  x2 = x3/2

·  By Example 3.7.8, with   p     =                     ³V   dx    converges.         So we would expect
   ³V cx                                                     x3/2
                                       3/2, the integral 1

   that 1 x2+x dx converges too.

· Our final task is to verify that our intuiticon is correct. To do so, we want to apply
   part (a) of Theorem 3.7.18 with         f (x)  =       x  and   g(x) being          1    ,  or  possibly  some
                                                      x2+x                            x3/2
   constant  times   1      That  is,  we  need   to  show   that  for  all  x  ¥  1  (i.e.    on  the  domain  of
   integration)
                    x3/2 .

                                            cx A
                                           x2 + x ¤ x3/2

   for some constant A. Let's try this.

· Since x ¥ 1 we know that

                                           x2 + x ¡ x2

   Now take the reciprocal of both sides:

                                           1           1

                                           x2 + x x2

   Multiply both sides by cx (which is always positive, so the sign of the inequality

   does not change)

                                            cx         cx 1

                                           x2 + x      x2 = x3/2

· So Theorcem 3.7.18(a) and Example 3.7.8, with p = 3/2 do indeed show that the inte-
       ³V x

   gral 1 x2+x dx converges.

51 This takes practice, practice and more practice. At the risk of alliteration -- please perform plenty of
      practice problems.

                                                  209
INTEGRATION                                                   3.7 IMPROPER INTEGRALS
                                                                          Example 3.7.22

    Notice that in this last example we managed to show that the integral exists by finding
an integrand that behaved the same way for large x. Our intuition then had to be bolstered
with some careful inequalities to apply the comparison Theorem 3.7.18. It would be nice to
avoid this last step and be able jump from the intuition to the conclusion without messing
around with inequalities. Thankfully there is a variant of Theorem 3.7.18 that is often
easier to apply and that also fits well with the sort of intuition that we developed to solve
Example 3.7.22.

    A key phrase in the previous paragraph is "behaves the same way for large x". A good
way to formalise this expression -- " f (x) behaves like g(x) for large x" -- is to require
that the limit

             lim f (x) exists and is a finite nonzero number.

             xÑV g(x)

Suppose that this is the case and call the limit L $ 0. Then

                    f (x)

· the ratio g(x) must approach L as x tends to +V.

· So when x is very large -- say x ¡ B, for some big number B -- we must have that

             12 L ¤ f (x) g(x) ¤ 2L                           for all x ¡ B

Equivalently, f (x) lies between L2 g(x) and 2Lg(x), for all x ¥ B.

· Consequently, the integral of f (x) converges if and only if the integral of g(x) con-
   verges, by Theorems 3.7.18 and 3.7.21.

These considerations lead to the following variant of Theorem 3.7.18.
                                                         210
INTEGRATION                                            3.7 IMPROPER INTEGRALS

 Theorem3.7.23 ( Limiting comparison).

Let ¡V a V. Let f and g be functions that are defined and continuous for all
x ¥ a and assume that g(x) ¥ 0 for all x ¥ a.

      ³V

(a) If a g(x) dx converges and the limit

                                                lim f (x)

                                         xÑV g(x)
                 ³V

    exists, then a f (x) dx converges.

      ³V

(b) If a g(x) dx diverges and the limit

                                                lim f (x)

                                         xÑV g(x)
                                  ³V

    exists and is nonzero, then a f (x) diverges.
Note that in (b) the limit must exist and be nonzero, while in (a) we only require
that the limit exists (it can be zero).

Here is an example of how Theorem 3.7.23 is used.

                    ³V x+sin x

 Example 3.7.24 1 ¡x 2 dx

                                    e +x

                   » V x + sin x
Does the integral ¡x 2 dx converge or diverge?

                        1 e +x
Solution.

· Our first task is to identify the potential sources of impropriety for this integral.

· The domain of integration extends to +V. On the domain of integration the de-

   nominator is never zero so the integrand is continuous. Thus the only problem is at

  +V.

· Our second task is to develop some intuition about the behavior of the integrand
   for very large x. A good way to start is to think about the size of each term when x
   becomes big.

· When x is very large:

- e¡x 3 x2, so that the denominator e¡x + x2  x2, and

- | sin x| ¤ 1 3 x, so that the numerator x + sin x  x, and

-  the  integrand  x+sin x    x   =  1.

                   ¡x 2        2     x
                   e +x x

Notice that we are using A 3 B to mean that "A is much much smaller than B".
Similarly A 4 B means "A is much much bigger than B". We don't really need to be

too precise about its meaning beyond this in the present context.

                                         211
INTEGRATION                              3.8 OVERVIEW OF INTEGRATION TECHNIQUES

             ³V dx                                  ³V x+sin x
· Now, since 1 x diverges, we would expect 1 e¡x+x2 dx to diverge too.

· Our final task is to verify that our intuition is correct. To do so, we set

                             x + sin x                           g(x) = 1x

                    f (x) = ¡x 2

                             e +x

and compute

                        lim    f (x)  =  lim   x + sin x 1 £
                                               e¡x
                        xÑV    g(x)      xÑV        +  x2     x

                                      =  lim   (1 + sin x/x)x       ¢  x
                                               (e¡x/x2
                                         xÑV               +  1)x2

                                      =  lim   1 + sin x/x
                                               e¡x/x2
                                         xÑV           +   1

                                      =1

³V                      ³V dx
· Since 1 g(x) dx = 1 x diverges, by Example 3.7.8 with p = 1, Theorem 3.7.23(b)
                    ³V         ³V x+sin x
now tells us that 1 f (x) dx = 1 e¡x+x2 dx diverges too.

                                                                            Example 3.7.24

3.8 Overview of Integration Techniques

     We have now learned many fancy methods of integration. Below we give a short review
     of the methods we've learned and a general idea of when you might want to choose each
     one. This section has no new mathematical content.

         Up till now, you could often guess the method to use on integrals in the practice book
     by noticing which section they were in. Section 3.8 in the practice book has lots of integrals
     to work on, without that contextual hint.

 Known Areas (Section 3.1.3)

A definite integral gives the area underneath a curve. If that area makes a simple shape,
you might be able to use a formula from geometry. This is particularly convenient for
rectangles.

                                                    y

»b  1 dx = (b ¡ a) ¢ (1) = b ¡ a                    1

a

                                                              a             bx

    A special case where this method is useful is with half and quarter circles. If we wanted
to use the Fundamental Theorem of Calculus to evaluate the integral below, we'd need a

                                          212
INTEGRATION            3.8 OVERVIEW OF INTEGRATION TECHNIQUES

trigonometric substitution. It's much easier to recognize that the area in question is one
quarter of the unit circle.

             1 ¡ x2 » 1  dx = 1 (1)2 = 44  y
             0                            1

                                                        1x

                                                                                                                                 ³

   You can also take advantage of a function's symmetry. For example, ¡ sin x dx = 0

because the positive area on the right exactly cancels out the negative (net) area on the
left.

                                          y
                                          1

             »

              ¡ sin xdx = 0 -  x

                                                                -1

 Substitution (Section 3.4)

Substitution is doing the chain rule in reverse. If you see some "inside" function whose
derivative shows up multiplied to the rest of the integrand, you might want to try substi-
tution. An obvious example would be something like this:

                                                                           »

                                          (4x + 3) cos(2x2 + 3x)dx

    The "inside function" 2x2 + 3x has derivative (4x + 3), and we see precisely that
derivative multiplied to the rest of the integrand. So this is a great candidate for the
substitution u = 2x2 + 3x.

    Substitution is sometimes a first step to get a function in a better form for a second tech-

                                                                ex +e3x

nique. For example, the function ex(1¡ex)(2¡ex) is a rational function (and a candidate for

the method of partial fractions to antidifferentiate) if you consider ex to be your variable.
So a first step in antidifferentiation would be to use u = ex, du = exdx:

» ex + e3x » dx = 1 + e2x x x x ¤ ex » dx = 1 + u2 du
ex(1 ¡ ex)(2 ¡ ex)  e (1 ¡ e )(2 ¡ e )       u(1 ¡ u)(2 ¡ u)

                       213
INTEGRATION                             3.8 OVERVIEW OF INTEGRATION TECHNIQUES

 Integration by Parts (Section 3.5)

If you see the product of two functions, and you would like to swap one with its derivative
and the other with its antiderivative, then integration by parts is the method for you. One
standard example is the integral
                                     »

                                        xex dx.

We let u = x and dv = exdx. Then du = dx and v = ex. The function v = ex isn't much
of an improvement over dv = exdx, but the function du = dx is an improvement over
u = x. We get to replace our integrand with a simpler product of functions:

                                  »              »

                                     xex dx = xex ¡ ex dx

(Contrast this with the substitution rule: both often operate on integrands that are the
product of functions.)
There is one special case you should recognize where integration by parts is useful al-
though the integrand doesn't obviously consist of the product of funtions: the antideriva-
tives of logarithms and inverse trig functions. (See Examples 3.5.8 and 3.5.9 for details.)
For example, to antidifferentiate the natural logarithm, we use integration by parts with
u = ln x and dv = dx.
                         » » ln x dx = x ln x ¡ x ¤ 1 dx
                                                    x

 Numerical Integration (Section 3.6)

Some integrals, such as  »                   »

                            ex2dx and sin x2 dx

cannot be evaluated using the techniques we've learned so far. Their definite integrals,
however, can be approximated using Simpson's Rule. This rule comes with error bounds,
so we can make sure our error is within a given tolerance.

    One special application of numerical integration is finding a decimal approximation
for an irrational number. In Question 23 of Section 3.6 in the practice book, we find a
decimal approximation of ln 2 by applying Simpson's Rule to the integral

                                     » 2 1 dx.
                                      1x

 Improper Integrals (Section 3.7)

Improper integrals have infinite discontinuities in their integrands or infinite intervals of
integration. The two integrals

                            » V e¡x » dx and 2 1 dx
                            1                       ¡1 x

are both improper. The second one is a dangerous type: it's easy to try to apply the
Fundamental Theorem of Calculus to evaluate it, without realizing that your computation

                                        214
INTEGRATION                                         3.9 DIFFERENTIAL EQUATIONS

is nonsense. Both types of improper integrals are evaluated with limits. If at least one
of these limits don't exist (including limits going to infinity), then we say the integral
diverges. That means, roughly, that we don't have a sensible way of assigning a number
to that definite integral.

3.9 Differential Equations

     A differential equation is an equation for an unknown function that involves the derivative
     of the unknown function. Differential equations play a central role in modelling a huge
     number of different phenomena. Here is a table giving a bunch of named differential
     equations and what they are used for. It is far from complete.

      Newton's Law of Motion                       describes motion of particles
         Maxwell's equations                   describes electromagnetic radiation

      Navier-Stokes equations                          describes fluid motion
             Heat equation                               describes heat flow
            Wave equation
                                                       describes wave motion
        Schro¨ dinger equation              describes atoms, molecules and crystals
       Stress-strain equations
        Black-Scholes models                         describes elastic materials
      Predator-prey equations                   used for pricing financial options
                                                describes ecosystem populations
         Einstein's equations                     connects gravity and geometry
Ludwig-Jones-Holling's equation        models spruce budworm/Balsam fir ecosystem
                                            models heart beats and nerve impulses
           Zeeman's model                  for electrical activity in Pancreatic -cells
  Sherman-Rinzel-Keizer model
                                                  models nerve action potentials
    Hodgkin-Huxley equations

    We are just going to scratch the surface of the study of differential equations. Most uni-
versities offer half a dozen different undergraduate courses on various aspects of differen-
tial equations. We'll focus here on one important type of differential equation: separable
differential equations.

    We've already seen one type of differential equation: finding an antiderivative.

 Example 3.9.1

Suppose y(x) is a function satisfying

                                       dy dx = ex.

What is y?

                                       215
INTEGRATION                                                                  3.9 DIFFERENTIAL EQUATIONS

Solution. We know the derivative of our function y, as a function of x, so we just antidif-
ferentiate.

                                                y(x) = ex + C

for some constant C.
    Note the answer to the question is a function.

                                                                                               Example 3.9.1

    Before we talk about solving more complicated differential equations, let's get more
practice working with them. The biggest paradigm shift between solving a differential
equation, and the type of equation-solving you're used to, is that we're solving for a func-
tion instead of a variable.

 Example 3.9.2

Choose the function(s) listed below that solve this differential equation:

                                dy dx + x2 ¡ 1 = y

A. y = x2 + 2x + 1
B. y = x2 + 1

                                                                                                                                   dy

Solution. We want to check whether y is a solution, so we replace y and dx in the differ-
ential equation, and check whether the equation is true.
                                                dy
In     the  case  y   =  x2  + 2x  + 1,   then  dx  =   2x   + 2.  We  plug  these  into  our  differential   equa-

tion:

                                             dy dx + x2 ¡ 1 = y
                                          2x + 2 + x2 ¡ 1 = x2 + 2x + 1

Simplifying the left-hand side,

                                          x2 + 2x + 1 = x2 + 2x + 1

This is true - the function on the left and the function on the right are the same. So the
                                                                                     dy
equation    y  =  x2  +  2x  +  1  is  a  solution  to  the  differential  equation  dx   +  x2  ¡  1  =  y.

Now let's think about the other function we were asked to consider, y = x2 + 1. For
               dy
this fuction, dx = 2x. We plug these into our differential equation:

                                          dy dx + x2 ¡ 1 = y
                                          2x + x2 ¡ 1 = x2 + 2x + 1

                                                        216
INTEGRATION                                                        3.9 DIFFERENTIAL EQUATIONS

Rearranging the left-hand side,

                            x2 + 2x ¡ 1 = x2 + 2x + 1

This is not true - the function on the left and the function on the right are not the same.
                                                                                           dy
So  the  equation  y  =  x2  +  2x  is  not  a  solution  to  the  differential  equation  dx  +  x2  ¡  1  =  y.
    You don't have enough tools yet to come up with solutions like y = x2 + 2x + 1 - those
will come shortly. For this example, we only want you to understand what it means for a
function to be a solution to a differential equation.

                                                                                           Example 3.9.2

    Definition3.9.3.

    A separable differential equation is an equation for a function y(x) that can be writ-
    ten in the form
                                        g y(x) dy (x) = f (x)
                                                   dx

    It may take some rearranging to get a differential equation in this form. The "separa-

ble" refers to the mechanics of getting all terms containing y and yI on side of the equation,

and all terms containing x on the other side.
    We'll start by developing a recipe for solving separable differential equations. Then

we'll look at many examples. Usually one suppresses the argument of y(x) and writes the
equation as below:

                                                  g(y) dy dx = f (x)
If the left and right functions side of the equation are the same (and they should be - oth-
erwise that equals sign has no business being there) then their antiderivatives with respect
to x should be the same as well, up to the usual additive constant.

                                        » g(y) dy » dx = f (x)dx
                                                   dx

The left-hand side of the equation above is in a perfect form for a substitution.

                                                »             »

                                                   g(y)dy = f (x)dx                                            (*)

    In this way, we've turned the problem of finding solutions to our separable differential
equation into the problem of finding two antiderivatives.

    Note the work above didn't really depend on what, exactly, f (x) and g(y) were. So, to
skip to the end, we use the following mnemonic algorithm. It looks strange, but you can
simply think of it as shorthand for the work we just did above.

                                                   217
INTEGRATION                                              3.9 DIFFERENTIAL EQUATIONS

               g(y) ¤ dy dx = f (x)
                        g(y) dy = f (x) dx                          (1)
               »                  »

                        g(y) dy = f (x) dx                          (2)

                                                                                                  dy

    In Step (1), we separate all x's and y's, including in dx , by "multiplying" both sides of
the equation by dx. In Step (2), we add an integral side to both sides of the equation.

                                                                                dy

    This looks illegal, and indeed is illegal -- dx is not a fraction. Again, this procedure is
simply a mnemonic device to help you remember the result (*).

 Example 3.9.4

The differential equation            dy dx = xe¡y

is separable, and we now find all of its solutions by using our mnemonic device. We start
by cross-multiplying so as to move all y's to the left hand side and all x's (including dx)
to the right hand side.

                                                 ey dy = x dx

Then we integrate both sides.

                            eydy = xdx ðñ ey » » = x2 + C

                                                                 2

T³ he C on the right hand side contains both the arbitrary cons³tant for the indefinite integral
 eydy and the arbitrary constant for the indefinite integral xdx. Finally, we solve for y,

which is really a function of x.

                                     y(x) = ln x2 + 2 C

    Note that C is an arbitrary constant. It can take any value. It cannot be determined
by the differential equation itself. In applications C is usually determined by a require-
ment that y take some prescribed value (determined by the application) when x is some
prescribed value. (We call these types of problems "initial value" problems. The given
constants are "initial conditions.") For example, suppose that we wish to find a function
y(x) that obeys both

                               dy dx = xe¡y and y(0) = 1

We know that,  to have  dy  =  xe¡y  satisfied,  we must have y(x)  =  ln  x2
                        dx
constant C. To also have the initial condition y(0) = 1, we must have      2 + C , for some

                     x2 §§     2     x=0    = ln C ðñ ln C = 1 ðñ C = e
1 = y(0) = ln + C §§

                                            218
INTEGRATION                                                      3.9 DIFFERENTIAL EQUATIONS
                                                                                   Example 3.9.4
                                                             x2

So our final solution is y(x) = ln 2 + e .

 Example 3.9.5
Solve dy = y2

           dx

Solution. When y $ 0, we can use our mnemonic.

                                                 dy dx = y2
                                                 dy = dx
                                                    y2
                                              » dy » = dx
                                                    y2

                                          y¡ = 1 x + C

                                 ¡1
                                   y = ¡ 1 x + C

                                                                                               dy

When y = 0, this computation breaks down because y2 contains a division by 0. We can
check if the function y(x) = 0 satisfies the differential equation by just subbing it in:

               y(x) = 0 ùñ yI(x) = 0, y(x)2 = 0 ùñ yI(x) = y(x)2

So y(x) = 0 is a solution and the full solution is:

                  y(x) = 0 or y(x) = ¡ 1 x + C , for any constant C

                                                                                                Example 3.9.5

 Example 3.9.6 (War Moods)
In the article War Moods: 152, researcher Lewis Richardson models the proportion of a
population eager for war using a model previously applied to the spread of infectious
diseases. (We note here an important quote from the paper: "To describe a phenomenon
is not to praise it." Understanding the social psychology of public support for war may
lead to strategies for preventing conflicts.)

    A simplified version of Richardson's model for the lead-up to hostilities is as follows.
Let y be the proportion of a population that supports going to war, with the rest of the
population against going to war. Then the rate of change of y over time is proportional
to the product of the proportion of people who are pro-war and the proportion of people

52 War Moods: 1 by Richardson, PSYCHOMETRIKA-Vol. 13, no. 3 September, 1948. You can access the
      full text with your UBC CWL at this link.

                                                         219
INTEGRATION                                                            3.9 DIFFERENTIAL EQUATIONS

who are anti-war. The reasoning is roughly53 that y changes as pro-war people encounter
anti-war people.

    That corresponds to the differential equation

                                dy dt = Cy(1 ¡ y)
where 1 ¡ y is the proportion of people who are anti-war.

    Let's solve this differential equation.

                               dy dt = Cy(1 ¡ y)

                             1 dy = Cdt

                        y(1 ¡ y)

                      » 1 » dy = Cdt

                        y(1 ¡ y)

Here,  we'll  use  a  slightly  unfair  trick.  Note  that      1   =  1  +   1.  (Finding  such  conve-
                                                                       y
                                                            y(1¡y)           1¡y
nient equalities in order to integrate is called the method of partial fractions; you can read
about it in many integral calculus textbooks. You will not be expected to come up with
this equality on your own for Math 105.)

                      » 1+ 1                         »
                      y 1¡y
                                        dy = Cdt

                      ln y ¡ ln(1 ¡ y) = Ct + D

                                ln y = Ct + D

                                   1¡y

                                          y = eCt+D

                                     1¡y

                                        y = (1 ¡ y)eCt+D = eCt+D ¡ yeCt+D

                      y(1 + eCt+D) = eCt+D

                                        y = 1 + eCt+D eCt+D

where D is some constant.
    The graph of this function has the shape below.

                                                y

                                                                                                      t

53 The actual paper has more subtlety, including considering populations of rival nations, and the pro-
      gression of public sentiment as a war drags on.

                                                         220
INTEGRATION                                        3.9 DIFFERENTIAL EQUATIONS

  In this model, there is a quick change from low support for war (y  0) to high support
for war (y  1). The paper notes, regarding the first world war: "There is evidence ... that

the majority of Britishers changed their opinions about war with Germany during a week
in 1914 between July 24 and August 4."

                                                                                                Example 3.9.6

 Example 3.9.7 (Fish growth)

Professor Daniel Pauly of the UBC Institute for the Oceans and Fisheries considered the
following model of fish growth in the paper A pre´cis of Gill-Oxygen Limitation Theory
(GOLT), with some Emphasis on the Eastern Mediterranean 54.

    Let w(t) be the weight of an individual fish over time. The rate at which is it able to
synthesize proteins (and other necessary substances) is proportional to wd, while the rate
at which its proteins need to be replaced is proportional to w. So,

                              dw dt = Hwd ¡ kw

    where Hwd is the rate at which new proteins are built, and kw is the rate at which they
need to be replaced. Because the rate of production is limited to the rate of oxygen intake
(which itself is proportional to gill size), the exponent d is less than one.

    The paper notes that researchers often neglect oxygen impacts on fish growth-- a de-
cision not supported by this model.

    Suppose d = 0.5 for a particular small species of fish. What is w(t)? How large would
the fish grow, if it grew indefinitely?

Solution. The differential equation is separable.

             dw dt = Hcw ¡ kw
c 1 dw = dt
H w ¡ kw
» c1                       »
H w ¡ kw
             dw = 1dt

» c 1 » c dw = 1dt
w(H ¡ k w)

54 PAULY, D. (2019). A pre´cis of Gill-Oxygen Limitation Theory (GOLT), with some Emphasis on the
      Eastern Mediterranean. Mediterranean Marine Science, 20(4), 660-668. doi:http://dx.doi.org/
      10.12681/mms.19285

                                                         221
INTEGRATION                                                           3.9 DIFFERENTIAL EQUATIONS

For  the  left-hand  side,  we  use    the  substitution  u  =  H  ¡  kcw,  ¡2k du  =  c1 dw

                                                                                         w

          ¡ 2 » 1 » du = 1dt
             ku
             ¡2k ln |u| = t + C
                     ln |u| = ¡ k t + C
                                2                            (remember C is an arbitrary constant)

                     |u| = e¡ 2k t+C
                     kcw|
          |H  ¡             =   e¡  k  t+C
                                    2

If we're studying young fish growing to aduclthood, then              dw       ¡  0, because the fish are
                                                                      dt
getting bigger. Under this assumption, H ¡ k w ¡ 0, so we can drop the absolute value
signs.

             H ¡ kcw = e¡ 2k t+C
                kcw = H ¡ e¡ 2k t+C
                 cw = 1k H ¡ e¡ 2k t+C
                   w = 21 H ¡ e¡ 2k t+C 2

                             k

The shape of this function is shown below.

                                y

                                                                            t

The graph shape suggests the existence of a horizontal asymptote. Indeed:

                                lim 21 H ¡ e¡ 2k t+C 2 =              H2
                                                                      k
                                tÑV k

                                                                                                                               H2

So, aging fish who grow according to our model approach the weight k .
                                                                                                Example 3.9.7

                                            222
INTEGRATION                                                         3.9 DIFFERENTIAL EQUATIONS

     Definition3.9.8.
    A differential equation of the form

                                 dy dx = a(y ¡ b)

    where a and b are constants is called a first-order linear differential equation.

    "First-order" means the equation has a first derivative, but no higher-order derivatives
(e.g. no second derivatives). The right hand side is a linear expression in the variable y.

 Example 3.9.9

Let a and b be any two constants. We'll now solve the family of differential equations

                                           dy dx = a(y ¡ b)

using our mnemonic device.

                     »              »
    dy = a dx ùñ dy = a dx ùñ ln |y ¡ b| = ax + c ùñ |y ¡ b| = eax+c = eceax
y¡b                        y¡b
                 ùñ y ¡ b = Ceax

where C is either +ec or ¡ec. Note that as c runs over all real numbers, +ec runs over
all strictly positive real numbers and ¡ec runs over all strictly negative real numbers. So,
so far, C can be any real number except 0. But we were a bit sloppy here. We implicitly
assumed that y ¡ b was nonzero, so that we could divide it across. None-the-less, the
constant function y = b, which corresponds to C = 0, is a perfectly good solution -- when
y is the constant function y = b, both dx and a(y ¡ b) are zero. So the general solution tody

dy  =  a(y ¡ b)  is  y(x)  =  Ceax  +  b,  where  the  constant  C  can  be  any  real  number.  Note  that
dx
when y(x) = Ceax + b we have y(0) = C + b. So C = y(0) ¡ b and the general solution is

                                       y(x) = (y(0) ¡ b)eax + b

                                                                                        Example 3.9.9

    This is worth stating as a theorem.

       Theorem3.9.10.

    Let a and b be constants. The differentiable function y(x) obeys the differential
    equation

                                 dy dx = a(y ¡ b)

    if and only if                     y(x) = (y(0) ¡ b)eax + b

                                                  223
INTEGRATION                                                        3.9 DIFFERENTIAL EQUATIONS

One solution to the differential equation

                                             dy dt = a(y ¡ b)

is the constant equation

                                               y = b.

We call this the "steady state" solution. Steady, because y is never changing - it's always
b.

Definition3.9.11.

A constant function y = b that satisfies a differential equation of the form

                                               dy dt = g(y)

is a s§teady state solution. The constant b is a steady state of the differential equation
    dy §
           y=b  = g(b) = 0
if dt §

Example 3.9.12

A glucose solution is administered intravenously into the bloodstream at a constant rate
r. As the glucose is added, it is converted into other substances at a rate that is propor-
tional to the concentration at that time. The concentration, C(t), of the glucose in the
bloodstream at time t obeys the differential equation

                                 dC dt = r ¡ kC

where k is a positive constant of proportionality.
(a) Express C(t) in terms of k and C(0).
(b) Find lim C(t).

          tÑV

(c) Find the steady-state solution to the differential equation.

Solution.  (a) Since r ¡ kC  = ¡k     C¡  r    the given equation is
                                          k

                                          dC dt = ¡k C ¡ rk

which  is  of  the  form  solved  in  Theorem  3.9.10  with  a  =  ¡k  and  b  =  r.  So  the  solution  is

                                                                                  k

                                      C(t) = rk + C(0) ¡ rk e¡kt

                                               224
INTEGRATION                                                                     3.9 DIFFERENTIAL EQUATIONS

(b)  For  any    k  ¡  0,  lim  e¡kt     =   0.  Consequently,    for  any  C(0)  and  any           k    ¡   0,  lim  C(t)  =  r  .
                           tÑV                                                                                    tÑV           k

We could have predicted this limit without solving for C(t). If we assume that C(t) ap-
proaches some equilibrium value Ce as t approaches infinity, then taking the limits of both
sides    of  dC     r  ¡  kC  as  t  Ñ   V   gives
             dt  =

                                                 0 = r ¡ kCe ùñ Ce = rk

(c)  dC  =   0   when     C  =  r,   so  C   =   r  is  the  steady-state  solution.  That           is,  if  we  have  a  blood
     dt                                  r,      k
concentration                   k    of
                    of  glucose          k   the    concentration  is  staying  the   same           even     as  the  glucose  is
injected and metabolized.

                                                                                                              Example 3.9.12

3.9.1  (Optional) Logistic Growth

Suppose that we wish to predict the size P(t) of a population as a function of the time
t. In the most naive model of population growth, each couple produces  offspring (for

                                                                                                                             P(t)

some constant ) and then dies. Thus over the course of one generation  2 children are
produced and P(t) parents die so that the size of the population grows from P(t) to

                                P(t + tg) = P(t) +  P(t) looooooomooooo2oon ¡ lPoom (to)on = 2 P(t)
                                                     parents+offspring parents die

where tg denotes the lifespan of one generation. The rate of change of the size of the
population per unit time is

                   P(t + tg) ¡ P(t) tg = 1  tg 2 P(t) ¡ P(t) = bP(t)

             ¡2

where b = 2tg is the net birthrate per member of the population per unit time. If we
approximate

                            P(t + tg) ¡ P(t) tg  dP dt (t)

we get the differential equation

                                                        dP dt = bP(t)                                                      (3.9.1)

By Theorem 3.9.10,

                                                        P(t) = P(0) ¤ ebt                                                  (3.9.2)

This is called the Malthusian55 growth model. It is, of course, very simplistic. One of its

main characteristics is that, since P(t + T) = P(0) ¤ eb(t+T) = P(t) ¤ ebT, every time you add

55 This is named after Rev. Thomas Robert Malthus. He described this model in a 1798 paper called "An
      essay on the principle of population".

                                                             225
INTEGRATION                                         3.9 DIFFERENTIAL EQUATIONS

T to the time, the population size is multiplied by ebT. In particular, the population size
                ln 2
doubles  every   b    units  of  time.

Example 3.9.13

In 1927 the population of the world was about 2 billion. In 1974 it was about 4 billion. Esti-
mate when it reached 6 billion. What will the population of the world be in 2100, assuming
the Malthusian growth model?
Solution.

   · Let P(t) be the world's population, in billions, t years after 1927. Note that 1974

    corresponds to t = 1974 ¡ 1927 = 47.

   · We are assuming that P(t) obeys equation (3.9.1). So, by (3.9.2)

                                  P(t) = P(0) ¤ ebt

       Notice that there are 2 unknowns here -- b and P(0) -- so we need two pieces of
       information to find them.
   · We are told P(0) = 2, so

                                    P(t) = 2 ¤ ebt

· We are also told P(47) = 4, which gives

                        4 = 2 ¤ e47b                                      clean up
                                                    take the log and clean up
                      e47b = 2
                         b = ln 2 47 = 0.0147               to 3 decimal places

· We now know P(t) completely, so we can easily determine the predicted popula-

  tion56 in 2100, i.e. at t = 2100 ¡ 1927 = 173.

                         P(173) = 2e173b = 2e173¢0.0147 = 12.7 billion

· Finally, our crude model predicts that the population is 6 billion at the time t that
   obeys

             P(t) = 2ebt = 6                                              clean up
               ebt = 3                              take the log and clean up
                 t = ln 3 b = 47ln 3 ln 2 = 74.5

which corresponds57 to the middle of 2001.

56 The 2015 Revision of World Population, a publication of the United Nations, predicts that the world's
      population in 2100 will be about 11 billion. But "about" covers a pretty large range. They give an 80%
      confidence interval running from 10 billion to 12.5 billion.

57 The world population really reached 6 billion in about 1999.

                                               226
INTEGRATION                                                    3.9 DIFFERENTIAL EQUATIONS

                                                                           Example 3.9.13

The Malthusian growth model can be a reasonably good model only when the popu-
lation size is very small compared to its environment58. A more sophisticated model of
population growth takes into account the "carrying capacity of the environment."
Logistic growth adds one more wrinkle to the simple population model. It assumes
that the population only has access to limited resources. As the size of the population
grows the amount of food available to each member decreases. This in turn causes the net
birth rate b to decrease. In the logistic growth model b = b0  1  ¡  P  , where K is called the
carrying capacity of the environment, so that                        K

                                   PI(t) = b0 1 ¡ P(t) K P(t)

Figure3.9.1.

Below is a graph of PI(t) = b0                 P(t)   P(t). Pay attention to the axis labels: the inde-

                                         1¡ K
pendent (horizontal) axis is population, P. It is not time. The dependent (vertical) axis is
                                   dP .
rate  of  change  of  population,
                                   dt

                            dP
                            dt

                                                                        P
                                                               K

· When P = 0, there are no individuals in the population, so its growth rate is zero.
   (Extinct animals do not usually reproduce.)

· When 0 P K, the population is less than the carrying capacity of its environ-
                                                ( dP  ¡
      ment,  so   the  population        grows           0).
                                                  dt

· When P ¡ K, the population has outgrown the capacity of the environment to sup-
      port it.    Then  dP  0, as the population experiences a higher death rate than birth
      rate.             dt

    This is a separable differential equation and we can solve it explicitly. We shall do so
shortly (in Example 3.9.14, below). But, before doing that, we'll see what we can learn

58 That is, the population has plenty of food and space to grow.

                                                         227
INTEGRATION                                                      3.9 DIFFERENTIAL EQUATIONS

about the behaviour of solutions to differential equations like this without finding formu-

lae for the solutions. It turns out that we can learn a lot just by watching the sign of PI(t).

For concreteness, we'll look at solutions of the differential equation

                          dP dt (t) = 6000 ¡ 3P(t) P(t)

We'll sketch the graphs of four functions P(t) that obey this equation.

   · For the first function, P(0) = 0.
   · For the second function, P(0) = 1000.
   · For the third function, P(0) = 2000.
   · For the fourth function, P(0) = 3000.

The sketches will be based on the observation that (6000 ¡ 3P) P = 3(2000 ¡ P) P

   · is zero for P = 0, 2000,
    · is strictly positive for 0 P 2000 and

  · is strictly negative for P ¡ 2000.

Consequently

                              dP dt (t)   6       if P(t) = 0

                                          9 9= 0  if 0 P(t) 2000

                                          9 8¡ 0  if P(t) = 2000

                                          9 9= 0  if P(t) ¡ 2000
                                          9 7 0

Thus  if  P(t)  is  some  function  that  obeys  dP (t)       =  6000 ¡ 3P(t) P(t), then as the graph of

P(t) passes through the point t, P(t)            dt

                                             6    i.e. is horizontal, if P(t) = 0
                                                  i.e. is increasing, if 0 P(t) 2000
                             9 9slope zero,       i.e. is horizontal, if P(t) = 2000
          9 8 the graph has positive slope,       i.e. is decreasing, if 0 P(t) 2000

                             9 9slope zero,
                             9 7negative slope,

as illustrated in the figure

                               P (t)
                              3000
                              2000
                              1000

                                                                           t

As a result,
                                                         228
INTEGRATION                                                      3.9 DIFFERENTIAL EQUATIONS

· if P(0) = 0, the graph starts out horizontally. In other words, as t starts to increase,
P(t) remains at zero, so the slope of the graph remains at zero. The population size
remains zero for all time. As a check, observe that the function P(t) = 0 obeys
dP (t) =           6000 ¡ 3P(t) P(t) for all t.

dt

· Similarly, if P(0) = 2000, the graph again starts out horizontally. So P(t) remains at
2000 and the slope remains at zero. The population size remains 2000 for all time.
                                                      dP (t)     6000 ¡ 3P(t) P(t) for all t.
Again,        the  function  P(t)  =   2000  obeys            =
                                                      dt

· If P(0) = 1000, the graph starts out with positive slope. So P(t) increases with t. As

  P(t) increases towards 2000, the slope (6000 ¡ 3P(t) P(t), while remaining positive,

   gets closer and closer to zero. As the graph approaches height 2000, it becomes more
   and more horizontal. The graph cannot actually cross from below 2000 to above
   2000, because to do so it would have to have strictly positive slope for some value of
   P above 2000, which is not allowed.

   · If P(0) = 3000, the graph starts out with negative slope. So P(t) decreases with

    t. As P(t) decreases towards 2000, the slope (6000 ¡ 3P(t) P(t), while remaining

       negative, gets closer and closer to zero. As the graph approaches height 2000, it
       becomes more and more horizontal. The graph cannot actually cross from above
       2000 to below 2000, because to do so it would have to have negative slope for some
       value of P below 2000, which is not allowed.
These curves are sketched in the figure below. We conclude that for any initial population

size P(0), except P(0) = 0, the population size approaches 2000 as t Ñ V.

                              P (t)
                             3000
                             2000
                             1000

                                                                 t

Now we'll do an example in which we explicitly solve the logistic growth equation.
 Example 3.9.14

In 1986, the population of the world was 5 billion and was increasing at a rate of 2% per
year. Using the logistic growth model with an assumed maximum population of 100 bil-
lion, predict the population of the world in the years 2000, 2100 and 2500.

Solution. Let y(t) be the population of the world, in billions of people, at time 1986 + t.
The logistic growth model assumes

                                yI = ay(K ¡ y)

where  K  is  the  carrying  capacity  and  a  =  b0

                                                  K.
First we'll determine the values of the constants a and K from the given data.

                                                  229
INTEGRATION                                                             3.9 DIFFERENTIAL EQUATIONS

· We know that, if at time zero the population is below K, then as time increases the
   population increases, approaching the limit K as t tends to infinity. So in this prob-
   lem K is the maximum population. That is, K = 100.
                                                                                                             yI
· We are also told that, at time zero, the percentage rate of change of population, 100 y ,
                                     yI                                                  yI
   is 2, so that, at time zero, y = 0.02. But, from the differential equation, y = a(K ¡ y).
                                                ¡                        2.
   Hence      at  time  zero,  0.02  =   a(100     5),  so  that  a  =
                                                                        9500

We now know a and K and can solve the (separable) differential equation

          dy = ay(K ¡ y) ùñ dy » = a dt ùñ 1 1 ¡ 1 » dy = a dt
          dt                         y(K ¡ y)                           K y y¡K

                               ùñ 1K [ln |y| ¡ ln |y ¡ K|] = at + C
                               ùñ ln |y| = aKt + CK ùñ § § = De §§ y §§ aKt
                                         |y ¡ K|                            y¡K

                                                                                   §  §       y
              CK                                                                   §y§
with D = e . We know that y remains between 0 and K, so that § y¡K § = K¡y and our
solution obeys
                                                y = DeaKt
                                         K¡y

At this stage, we know the values of the constants a and K, but not the value of the constant
D. We are given that at t = 0, y = 5. Subbing in this, and the values of K and a,

                                         5 = De0 ùñ D = 5
                                     100 ¡ 5                            95

So the solution obeys the algebraic equation

                                            y = 5 e2t/95

                                         100 ¡ y 95

which we can solve to get y as a function of t.

          y = (100 ¡ y) 595 e2t/95 ùñ 95y = (500 ¡ 5y)e2t/95
                             ùñ 95 + 5e2t/95 y = 500e2t/95

                                                   500e2t/95            100e2t/95        100
                                     ùñ y = 95 + 5e2t/95 = 19 + e2t/95 = 1 + 19e¡2t/95

Finally,

·  In the year 2000, t = 14 and y =                   100     6.6 billion.

                                                1+19e¡28/95     36.7 billion.
·  In the year 2100, t = 114 and y =                  100

                                                1+19e¡228/95       100 billion.
·  In the year 2200, t = 514 and y =                   100

                                                1+19e¡1028/95

                                                                                      Example 3.9.14

                                                   230
INTEGRATION                                                                        3.9 DIFFERENTIAL EQUATIONS

3.9.2  (Optional) Interest on Investments and Loans

      Suppose that you deposit $P in a bank account at time t = 0. The account pays r% interest
       per year compounded n times per year.

    ·    The first interest payment is made at time t                =     1.  Because the balance in the account

                                                        1                  n                                  1 th

         during the time interval 0 t n is $P and interest is being paid for n of a year,
         that  first  interest   payment     is   1  ¢   r   ¢  P.  After  the  first  interest  payment,        the   balance
                                                  n     100
         in  the  account    is  P     1  ¢   r   ¢  P       1+ r          P.
                                    +  n     100        =
                                                                    100n
    · The second interest payment is made at time t                                2.   Because the balance in the
                                                        1            2 is       =
                                                        n                          n
         account      during  the   time     interval           t    n     1+ r         P and interest is being paid

                  th                                                              100n
               1      of a year, the second interest payment is n ¢ 100 ¢
         for   n                                                                   1r            1+ r            P. After the

                                                                                                        100n  1  ¢   r    ¢
         second interest payment, the balance in the account is                         1+ r         P        n     100      1+
                                                                                                          +
                                                                                               100n
         r P = 1 + r 2P.
         100n                100n
    · And so on.

In  general,   at   time  t  =   m  (just  after  the   mth  interest     payment),     the  balance      in  the   account  is
                                 n

                                    B(t) = 1 + r m 100n P = 1 + r nt 100n P                                               (3.9.3)

Three common values of n are 1 (interest is paid once a year), 12 (i.e. interest is paid

once a month) and 365 (i.e. interest is paid daily). The limit n Ñ V is called continuous

compounding59. Under continuous compounding, the balance at time t is

                                             B(t) = lim 1 + r ntP
                                                        nÑV          100n

You may have already seen the limit

                                                     lim(1 + x)a/x = ea                                                   (3.9.4)

                                                     xÑ0

If  so,  you   can  evaluate     B(t)  by    applying      (3.9.4)  with   x   =    r   and  a  =     rt  (so    that  a  =  nt).
As n Ñ V, x Ñ 0 so that                                                           100n               100               x

                    B(t) = lim 1 + r ntP = lim(1 + x)a/xP = eaP = ert/100P                                                (3.9.5)
                             nÑV             100n               xÑ0

If you haven't seen (3.9.4) before, that's OK. In the following example, we rederive (3.9.5)
using a differential equation instead of (3.9.4).

Example 3.9.15

Suppose, again, that you deposit $P in a bank account at time t = 0, and that the account
pays r% interest per year compounded n times per year, and denote by B(t) the balance
at time t. Suppose that you have just received an interest payment at time t. Then the next

59 There are banks that advertise continuous compounding. You can find some by googling "interest is
      compounded continuously and paid"

                                                             231
INTEGRATION                                                                3.9 DIFFERENTIAL EQUATIONS

interest  payment   will  be   made       at  time  t  +   1  and will be  1   ¢   r   ¢  B(t)  =  10r0n B(t).  So,
          1                                                n               n      100
calling   n     h,
             =

                B(t + h) = B(t) + r100 B(t)h or B(t + h) ¡ B(t) h = r100 B(t)
To get continuous compounding we take the limit n Ñ V or, equivalently, h Ñ 0. This
gives
                    lim B(t + h) ¡ B(t) = r B(t) or dB (t) = r B(t)
                    hÑ0           h            100                         dt          100
                                      r
By  Theorem     3.9.10,  with  a  =  100  and  b  =    0,

                                     B(t) = ert/100B(0) = ert/100P

once again.

                                                                                                Example 3.9.15

Example 3.9.16

(a) A bank advertises that it compounds interest continuously and that it will double your
     money in ten years. What is the annual interest rate?

(b) A bank advertises that it compounds monthly and that it will double your money in
     ten years. What is the annual interest rate?

Solution. (a) Let the interest rate be r% per year. If you start with $P, then after t years,
you have Pert/100, under continuous compounding. This was (3.9.5). After 10 years you
have Per/10. This is supposed to be 2P, so

       Per/10 = 2P ùñ er/10 = 2 ùñ r10 = ln 2 ùñ r = 10 ln 2 = 6.93%

(b) Let the interest rate be r% per year. If you start with $P, then after t years, you have
             r 12t
P 1 + 100¢12 , under monthly compounding. This was (3.9.3). After 10 years you have
             r 120
P 1 + 100¢12 . This is supposed to be 2P, so
    P 1 + r 120 = 2P ùñ 1 + r 120 = 2 ùñ 1 + r = 21/120
             100 ¢ 12                                         1200                          1200
    ùñ r 1200 = 21/120 ¡ 1 ùñ r = 1200 21/120 ¡ 1 = 6.95%

                                                                                                Example 3.9.16

 Example 3.9.17
A 25 year old graduate of UBC is given $50,000 which is invested at 5% per year com-
pounded continuously. The graduate also intends to deposit money continuously at the
rate of $2000 per year.

                                                         232
INTEGRATION                                                            3.9 DIFFERENTIAL EQUATIONS

(a) Find a differential equation that A(t) obeys, assuming that the interest rate remains
     5%.

(b) Determine the amount of money in the account when the graduate is 65.
(c) At age 65, the graduate will start withdrawing money continuously at the rate of W

     dollars per year. If the money must last until the person is 85, what is the largest
     possible value of W?

Solution. (a) Let's consider what happens to A over a very short time interval from time
t to time t + t. At time t the account balance is A(t). During the (really short) specified
time  interval  the  balance  remains  very  close  to  A(t)  and  so  earns  interest  of   5   ¢  t  ¢  A(t).
                                                                                            100
During the same time interval, the graduate also deposits an additional $2000t. So

  A(t + t)  A(t) + 0.05A(t)t + 2000t ùñ A(t + t) ¡ A(t) t  0.05A(t) + 2000
In the limit t Ñ 0, the approximation becomes exact and we get

                                            dA dt = 0.05A + 2000
(b) The amount of money at time t obeys

                           dA dt = 0.05A(t) + 2,000 = 0.05 A(t) + 40,000

So by Theorem 3.9.10 (with a = 0.05 and b = ¡40,000),

                              A(t) = A(0) + 40,000 e0.05t ¡ 40,000

At time 0 (when the graduate is 25), A(0) = 50,000, so the amount of money at time t is

                              A(t) = 90,000 e0.05t ¡ 40, 000

In particular, when the graduate is 65 years old, t = 40 and

                     A(40) = 90,000 e0.05¢40 ¡ 40, 000 = $625,015.05

(c) When the graduate stops depositing money and instead starts withdrawing money at
a rate W, the equation for A becomes

                       dA dt = 0.05A ¡ W = 0.05(A ¡ 20W)

assuming that the interest rate remains 5%. This time, Theorem 3.9.10 (with a = 0.05 and
b = 20W) gives

                        A(t) = A(0) ¡ 20W e0.05t + 20W

If we now reset our clock so that t = 0 when the graduate is 65, A(0) = 625, 015.05. So the
amount of money at time t is

                              A(t) = 20W + e0.05t(625, 015.05 ¡ 20W)

                                             233
INTEGRATION                                                3.9 DIFFERENTIAL EQUATIONS

We want the account to be depleted when the graduate is 85. So, we want A(20) = 0. This
is the case if

     20W + e0.05¢20(625, 015.05 ¡ 20W) = 0 ùñ 20W + e(625, 015.05 ¡ 20W) = 0
                                        ùñ 20(e ¡ 1)W = 625, 015.05e
                                        ùñ W = 625, 015.05e = $49, 437.96
                                                  20(e ¡ 1)

                                                                              Example 3.9.17

Example 3.9.18 (Loan Repayment)

Suppose you borrow $750,000 from the bank under the following conditions:
   1. You make payments to the bank once a month.
   2. Every month, you pay 0.25% of the remaining portion of the loan as interest.
   3. Your last payment will be after 300 months (25 years)
    Let's consider different ways to structure your payments.

Option 1:  In the most naive option, let's assume you pay off   1   of the loan each month.
                                                               300
Then your payments towards the loan itself are always $2500. However, the interest
you pay changes month by month.

Suppose P(t) is the amount of the loan still owed to the bank after t monthly pay-
ments. Then P(t) = 750, 000 ¡ 2500t, since after t months you've repaid $2500t.
The interest you pay in month    t  is then  .25 P(t ¡ 1)      1  (750,  000  ¡  2500(t  ¡              1))
25         ¡                                               =   4                                             =
4                                            100
    (301      t).

             $4381.25

              $1881.25

                                                                                                     t
           The dotted line shows monthly interest payments; the solid line shows
           monthly payments ($2500+interest).

                                                    234
INTEGRATION                                                         3.9 DIFFERENTIAL EQUATIONS

In this option, your actual monthly payments to the bank vary quite a bit over the 25
years of the loan. If you expect your salary to grow over time, you pay the highest
payments early on, when you make the least amount of money. So, this option is not
ideal.

Option 2: Let's figure out how to pay off the loan in such a way that your monthly pay-
ments are the same each month, for all 300 months. Again, let P(t) be the amount of
the loan left to repay the bank after you've made t monthly payments. Each month,
you  pay     back  some  portion     of  the  loan,  plus  an  interest  payment  of   .25 P(t).

                                                                                       100

The amount of the loan you've paid back in month t is P(t ¡ 1) ¡ P(t). In particular,

     P(t ¡ 1) ¡ P(t) = ¡ P(t) ¡ P(t ¡ 1)  ¡ lim P(t) ¡ P(t ¡ h) = ¡PI(t)1   h
                                                               hÑ0

Thinking of our monthly payments on the loan as how fast P(t) changes, it makes
sense to approximate them by the rate of change of P. The important detail is that

P(t) is decreasing as you pay positive amounts, which is why we use ¡PI(t) as the

approximation of the amount you paid.
All together, the amount you pay each month is about:

                         loan payment + interest = ¡PI(t) + .25 100 P(t)

In Option 2, we want this amount to be constant. Let's call that constant monthly
payment      C.  This  gives  us  a  linear   differential  equation,    C     ¡PI(t)     .25  P(t),  or
                                                                            =          +  100

                                     PI(t) = 1 400 P(t) ¡ 400C

By Theorem 3.9.10,

                         P(t) = P(0) ¡ 400C et/400 + 400C
                             = 750, 000 ¡ 400C et/400 + 400C

To find C, recall P(300) = 0.

                              0 = 750, 000 ¡ 400C e300/400 + 400C

                 400C(e3/4 ¡ 1) = 750, 000e3/4

                              C = 750, 000e 3/4 = 3/4 1875 e3/4 3/4  3553.60
                                     400 e ¡ 1                      e ¡1

So, a monthly payment of roughly $3553.60 would be sufficient to pay off the loan
in 25 years. The amount of that monthly payment that goes to the loan itself is about

PI(t) = (1875 ¡ C)et/400 = e13/847¡51 et/400, while the rest is interest.

                                                 235
INTEGRATION                                                               3.9 DIFFERENTIAL EQUATIONS

             $3553.60
             $1875.00

                                                                                                    t
          The dotted line shows monthly interest payments; the solid line shows
          total monthly payments (principal+interest).

     Initial payments consist of roughly equal parts interest and principal. Over time,
     payments consist of more and more principal, with less and less interest.
     We note here that the Government of Canada mortgage calculator gives a monthly payment of

     $3,549.34 for a mortgage of $750,000 with annual rate of 3% (0.25% ¢ 12) and amortization

     period 25 years. It also mentions that the total interest paid will be $314,802.37.

     Aside from monthly payments, we can also look at the total amount of interest paid in
the  two  scenarios.  In  Option     1,  the  amount  of  interest  paid  in  month      t  was  25 (301  ¡  t).  So,
over 300 months, the total interest paid was:
                                                                                                 4

          4 (301 3¸ 01 25 ¡ t) = 254     3 301 ¤ 300 ¡ ¸ 01 t       = 25 ¤ 301 ¤ (300 ¡ 151)

          t=1                                              t=1                      4

                             = 254       301 ¤ 300 ¡ 301 ¤ 302 2

                                 = 280, 306.25

     For  Option  2,  in  month  t,  interest  paid  was  approximately        1   P(t)  =  1875  e3/4 ¡ et/400 .
                                                                              400
                                                                                            3/4
Total interest is then approximately:                                                       e ¡1

          3¸ 00 1875      e3/4 ¡ et/400             1875   3 300 ¤ e3/4 ¡ ¸ 00 et/400

          t=1 e3/4 ¡ 1                         = e3/4 ¡ 1                     t=1

                                                      236
INTEGRATION                                     3.9 DIFFERENTIAL EQUATIONS

For lack of a nice formula, we'll interpret the sum as a Riemann sum. It corresponds to the
right-hand Riemann sum for the area under the curve f (t) = et/400 from t = 0 to t = 300,
using 300 intervals.

                  1875                          » 300 ¤ e3/4 ¡ 300 et/400dt

              e3/4 ¡ 1                                               t=0

             = 3/4 1875 300 ¤ e3/4 ¡ 400et/400 300
             e ¡1                               t=0

             = 3/4 1875 300 ¤ e3/4 ¡ 400 e3/4 ¡ 1
             e ¡1
              316081.01

Option 2 is more expensive than Option 1.

                                                Example 3.9.18

    Chapter 3 of this work was adapted from Chapter 1 and Section 2.4 of CLP 2 - Inte-
gral Calculus by Feldman, Rechnitzer, and Yeager under a Create Commons Attribution-
NonCommercial-ShareAlike 4.0 International license.

                                           237
     Chapter 4

                                  PROBABILITY

 4.1 Introduction

       Before we start, a note. Most terms in this introductory section (probability, event, value)
       accord pretty well with their usage in everyday life. However, later on in the chapter we
       will introduce new vocabulary and notation (PDF, CDF, E) whose interpretations are far
       less obvious. Keeping track of definitions will be key to understanding what's going on.
       Make flashcards if you have a hard time remembering different terms. If you read a term
       whose meaning you've forgotten, look it up! If we don't have the same vocabulary, then
       we aren't speaking the same language - so it will be difficult to explain things.

4.1.1  Foundational Vocabulary and Notation

              Definition4.1.1.
             A probability is a number between 0 and 1. We interpret it as a likelihood.

If an outcome of an event has probability 1, it will certainly happen. If an outcome
has  probability  0,  it  will  certainly  not  happen.  If  an  outcome  has    probability  1,  it  has  an

                                                                                              2
equal chance of happening and not happening. If we have an event with an outcome with
probability  1  and   the  event  happens  a    large  number    of  times,  we  expect  the  outcome      to
             2
occur in roughly half of those trials.

    A random variable is a lot like the ordinary variables you're used to using in functions,
in that it is a kind of placeholder that can take on different values. The "random" part of
the name explains that the values taken on are the result of an event - some experiment
or random process.

                                                238
PROBABILITY  4.1 INTRODUCTION

 Definition4.1.2.

A random variable (or just variable) is a characteristic or measurement that can
be determined for each outcome of some event.
Random variables are usually denoted with capital letters, like X or Y. When
they correspond to a clear event, we may also give them names like "Flip" (for a
coin flip) or "Roll" (for a dice roll).

    Events result in values. The event of rolling a dice might result in the value 1; the
event of flipping a coin might result in the value heads; and the event of choosing a person
might result in the value Parham. We usually use lower-case letters as variables specifying
values.

    We'll mostly use events that result in numerical values, although coin flips are a handy
experiment as well. Unless otherwise specified, you can assume values will be numbers.
(Otherwise our formulas become quite abstract - we won't ask you to average people or
integrate colours.)

 Example 4.1.3

Let Roll be the random variable corresponding to the event of rolling a standard 6-sided
dice1. Roll can result in any of the values 1, 2, 3, 4, 5, or 6.

    Suppose we are playing a game and our points are determined by doubling the num-
ber rolled. We might write the following:

       If Roll = x, the number of points earned is 2x.
                                                                                                Example 4.1.3

 Notation4.1.4.

We'll use the shorthand Pr(A) to mean "the probability that A happens." For
example:

                                            Pr(E = x)
denotes "the probability that the event E results in the value x."

    The equation E = x can take some getting used to. Remember that E corresponds to
the event (like rolling a dice), while x corresponds to the outcome of that event (e.g. 5).

 Example 4.1.5

To express "the probability of a dice roll being 5 is 1/6," we write:
                                              Pr(Roll = 5) = 16

1 In the interest of clarity, we'll use "dice" as its own singular (as is common in colloquial English), rather
      than "die" (which is more standard in academic English).

                                                         239
PROBABILITY                                                                      4.1 INTRODUCTION

where  Roll  is  the  event  (dice  roll),  5  is  the  value,  and  1  is  the  probability.
                                                                     6

                                                                                               Example 4.1.5

 Example 4.1.6
If R is the roll of a fair dice, then

                                         Pr(R = 1 or R = 2) = 13

                                                                                                Example 4.1.6

 Example 4.1.7
Let F be the event of flipping a fair coin (that is, a coin that is equally likely to come up
heads or tails), and let x be one of the values "heads" or "tails." Then:

                                               Pr(F = x) = 12

                                                                                               Example 4.1.7

 Definition4.1.8.
The sample space of an event is the set of all possible outcomes. We will use S
to denote the sample space.

 Example 4.1.9                                                                                 Example 4.1.9

If you roll a standard dice, S = t1, 2, 3, 4, 5, 6u.

                                                         240
PROBABILITY                                                                    4.1 INTRODUCTION

 Warning4.1.10.
This seemingly straightforward definition can cause some confusion, especially
when measured data is involved.
For example: suppose our random variable X is the mileage of a car picked at
random out of a parking lot. If there are, say, 100 cars in that lot, then there are
(at most) 100 values possible for X to take on. Unfortunately, we do not know
those values.
When we use the context of a supposedly measured variable, we'll pretend that
it could be anything theoretically sensible. In the case of the cars, we do know
that all of those values will be nonnegative numbers. So, In this case, we could

use the sample space [0, V). Alternately we could say that each of those values is

less than some arbitrarily huge number like 1012 km2 and use the sample space
 0, 1012 .

Example 4.1.11 (A Probabilistic Model in Linguistics)

    These introductory concepts are enough to start understanding probabilistic models in
a wide array of fields. Here we'll consider a paragraph from a short paper about people's
decisions to change the language they use over time.

    The following quote is taken from the article: Abrams, D., Strogatz, S. Modelling the
dynamics of language death. Nature 424, 900 (2003). DOI: https://doi.org/10.
1038/424900a

Consider a system of two competing languages, X and Y, in which the at-
tractiveness of a language increases with both its number of speakers and its
perceived status (a parameter that reflects the social or economic opportunities
afforded to its speakers). Suppose an individual converts from Y to X with a
probability, per unit of time, of Pyx(x, s), where x is the fraction of the popula-

tion speaking X, and 0 ¤ s ¤ 1 is a measure of X's relative status. A minimal

model for language change is therefore

                      dx dt = yPyx(x, s) ¡ xPxy(x, s)
where y = 1 ¡ x is the complementary fraction of the population speaking Y

at time t.

Let's parse this quote in terms of vocabulary that is familiar to us.

· x is the fraction of a population speaking language X at a given time. So if everyone
is  speaking  X,  then  x     1;  if  half  the  population  is  speaking  x,  then  x     1.
                           =                                                            =
                                                                                           2

2 that's farther than driving at 100 kph around the clock for one million years, so it's safe to say no car
      has more mileage than this

                                                         241
PROBABILITY                                                                        4.1 INTRODUCTION

· y is the fraction of the population speaking language Y at a given time. Under the
   simplified assumptions of the model in the paper, everyone speaks either X or Y,

  but not both, at a particular time. So, y = 1 ¡ x.

·  dx  is  the  rate  of  change   of  speakers  of  language  X  over  time.  So  if  dx  is  positive,  then
   dt                                                                                  dt
   dx  is  increasing     and  so  people  are  changing  from    language  Y  to  language    X;  if     dx  is
   dt                                                                                                     dt
   negative, then people are changing from language X to language Y.

· The random event in question is a person changing their language. The three values
   in its sample space are: person does not change; person changes from X to Y; and
   person changes from Y to X.

· The paper uses notation that is different from this textbook. They write Pyx for "the
   probability that a person changes from Y to X, and they write Pxy for "the probability
   that a person changes from X to Y.

· The probabilities come with arguments: Pyx(x, s) and Pxy(x, s). The variables inside
   the parentheses are function variables. How likely someone is to switch languages is
   not a fixed constant, but rather a function depending on how many people speak the
   language, and how much status that language is perceived to have. So, Pyx and Pxy
   are functions of multiple variables, like the functions we worked with in Chapter 2.

    Now that we understand all the notation, we can figure out where the equation in the
quote came from.

· x increases as people switch from speaking Y to speaking X. Pyx is the proportion of
   speakers of Y that we expect to change to X. The number of speakers of Y is y. So,
   we expect yPyx people to change from Y to X.

· x decreases as people switch from speaking X to speaking Y. Pxy is the proportion
   of speakers of X that we expect to change to Y. The number of speakers of X is x.
   So, we expect xPxy people to change from X to Y.

· All together, the change in x is (number of people coming to X from Y) minus (num-
   ber of people going to Y from X), or

                                dx dt = yPyx ¡ xPxy

   which is exactly the equation from the article.

                                                                                       Example 4.1.11

4.1.2  Discrete vs Continuous

       The distinction between discrete and continuous variables plays an important role in the
       way we calculate properties of variables. The formal definition of a continuous variable
       will have to wait until Definition 4.3.6. For now, we'll think of continuous simply as the
       alternative to discrete.

                                                                242
PROBABILITY     4.1 INTRODUCTION

 Definition4.1.12.

If the sample space of a random variable can be written as a list (as opposed to
existing on a continuum), then the sample space and the random variable are
discrete.

    "Written as a list" is an informal description of the mathematical term "countable,"
whose definition3 is beyond the scope of this class. We'll explain what we mean with
examples.

 Example 4.1.13
Let X be the random variable corresponding to choosing a whole number in [1, 10].

                          1 2 3 4 5 6 7 8 9 10
    The values in the sample space can be listed: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10. So, X is discrete.

                                                                                                Example 4.1.13

 Example 4.1.14
Let Y be the random variable corresponding to choosing any real number number in [1, 10]

             1  10

    S = [1, 10]. There are infinitely many possible values, along a continuum, that could
result. Y is not discrete, it is continuous.

                                                                                                Example 4.1.14

 Example 4.1.15
For each of the following events, describe the sample space as discrete or continuous,
where we are still using "continuous" informally as the opposite of "discrete."

   1. Roll three standard dice, add the values.
   2. Number of pets you have.4
   3. Your exact age at noon today.5
   4. Volume of a box.

3 a set is countable if there exists an injective (one-to-one) function from that set to the natural numbers.
4 We aren't monsters-there's no such thing as half a pet.
5 Imagine you have have perfect precision.

                                                         243
PROBABILITY  4.1 INTRODUCTION

Solution.

  1. The sample space is discrete, S = t3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18u.

   2. This is also discrete. The number of pets you have is a whole number: 0, 1, 2, 3, etc.
   3. You can be any age from 0 to, say, 500 years. If we have exact precision, your age is

       a real number: you might be 19.015 years old, or 19.016 years old, or somewhere in
       between. So with exact precision, we're taking numbers along a continuum. This is
       a continuous sample space.
   4. Similar to the above, if we have exact precision, our answer can be any non-negative
       real number, so this is a continuous sample space.

                                                                                                Example 4.1.15

    When our variables are describing physical processes, the line between discrete and
continuous can be somewhat blurry. For example, suppose we're measuring the amount
of water in a container. Volumes in general exist on continuums (or continua), like the
volume of a box in Example 4.1.15, so we could think of this as a continuous sample
space. Alternately, we could think of the amount of water as a discrete quantity, because
the number of molecules is in integer.

    Remembering back to our definition of the definite integral (Definition 3.1.8), we ap-
proximated a curvy area with lots of small rectangles. In a similar way, continuous sample
spaces can be approximated with discrete sample spaces. The reason we need the distinc-
tion is less important for actual measurements, and more important for deciding how to
perform calculations. You'll see as we progress through the chapter that some calculations
only make sense in one type of variable, and not the other.

4.1.3  Combining Events

              Definition4.1.16.
             Two outcomes of an event are disjoint if no value in the sample space can be
             described by both outcomes.

    For example, consider the event of rolling a dice, corresponding as usual to the discrete
random variable X. The outcomes X = 1 and X = 2 are disjoint, because no dice roll will

result in both of them being true. On the other hand, the outcomes X ¡ 2 and "X is even"

are not disjoint, because a roll of 4 or 6 makes both of them true.
 Example 4.1.17

Let X be a continuous random variable with sample space [0, 10]. For each collection of
outcomes below, decide whether the outcomes are disjoint or not.

  1. X 5; X ¥ 5

                                                         244
PROBABILITY              4.1 INTRODUCTION

2. X ¥ 9; X ¥ 8

3. 1 X 2; X even; X odd

Solution.
   1. These are disjoint; no number is both less than five, and also greater than or equal to
       five.
   2. These are not disjoint: X = 9, for example, makes both true. (So does X = 9.5,
       X = 10, etc.)
   3. These are disjoint. If X is an integer, then it is even or odd but not both, and it is not
       in the interval (1, 2). If X is in the interval (1, 2), then it is not an integer, so it is not
       even and not odd.
                                                                                                Example 4.1.17

 Theorem4.1.18.
Suppose A and B represent disjoint outcomes of the same event. Then

        Pr(A happens OR B happens) = Pr(A happens) + Pr(B happens)

      Warning4.1.19.
     In a mathematical context, "or" has a slightly different meaning from its collo-
     quial use. When we say "A or B," we mean "A, B, or both."
     An old joke is that a mathematician is told they may have a peanut butter cookie
     or a chocolate cookie, and takes one of each.

Proof. This comes from the interpretation of a probability as the proportion of trials where
an outcome occurs. If A and B never occur at the same trial, then the proportion where
one or the other occurs is simply the sum of the proportions where one occurs.

 Example 4.1.20

If X is the random variable corresponding to a dice throw, then Pr(X ¤ 3) = Pr(X =

1 OR X = 2 OR X = 3). Since the events X = 1, X = 2, and X = 3 are disjoint, this
probability is equal to:

                     Pr(X = 1) + Pr(X = 2) + Pr(X = 3) = 16 + 16 + 16 = 12.

                                                         245
PROBABILITY                                                                                    4.1 INTRODUCTION

                                                                                                  Example 4.1.20

Example 4.1.21

Suppose there is a lottery where you pick five numbers, and you win a prize if at least
three of your five picks accord with the winning five numbers. Suppose you know that
the  probability       of  matching       exactly  three  numbers      is   1;  the  probability      of  matching    ex-
                                  1;                                                                                  1
                                            the                 of         100                                 if
actly   four  numbers        is  1000  and       probability        matching    exactly   five    numbers          10000 .
     Then the probability of winning something is the probability of matching 3, 4, or 5
numbers:       1         1          1
              100  +   1000  +
                                 10000 .

                                                                                                  Example 4.1.21

Example 4.1.22

Suppose for the province of British Columbia, the probability that a randomly chosen
adult    resident  will    apply   for    employment       insurance   (EI)     benefits  in  2021    is   3,  while  the

                                                                                                          100
probability that a randomly chosen adult resident will be laid off from their job in 2021 is
7.
100 True or false: the probability that a randomly chosen adult resident will apply for EI
or  be  laid  off  is  1.

                       10

Solution. Not necessarily true (and almost certainly false). These are not disjoint events,
so Theorem 4.1.18 does not apply.

                                                                                                  Example 4.1.22

4.1.4  Equally Likely Outcomes

       Equally likely means that each outcome of a discrete-valued experiment occurs with
      equal probability. For example, if you roll a fair, six-sided dice, each face (1, 2, 3, 4, 5, or 6)
      is as likely to occur as any other face. If you toss a fair coin, a Head (H) and a Tail (T) are
       equally likely to occur.

         Example 4.1.23

Suppose you roll one fair six-sided die, with the numbers t1, 2, 3, 4, 5, 6u on its faces, and
you need to roll at least 5 to win a game.
     There    are  two     values  that   win    you  the  game,    5  and  6.  Each  is  expected        to  occur   1  of
the time. So,                                                                                                         6

                                            Pr(X ¥ 5) = 16 + 16 = 13

     If you were to roll the die only a few times, you would not be surprised if your ob-
served results did not match the probability. If you were to roll the die a very large num-
ber  of  times,    you     would   expect   that,  overall,  roughly       (if  not  exactly)  1  of  the  rolls   would
result in an outcome of "at least five".                                                       3

                                                           246
PROBABILITY  4.1 INTRODUCTION

                                                                                                Example 4.1.23
It is important to realize that in many situations, the outcomes are not equally likely. Look
at the dice in a game you have at home; the spots on each face are usually small holes
carved out and then painted to make the spots visible. Your dice may or may not be
biased; it is possible that the outcomes may be affected by the slight weight differences
due to the different numbers of holes in the faces. Casino dice have flat faces; the holes
are completely filled with paint having the same density as the material that the dice are
made out of so that each face is equally likely to occur.

    The continuous analog of "equally likely" is uniformly distributed.

      Definition4.1.24.
     Intuitively, a continuous random variable is uniformly distributed on an interval
     if the variable doesn't favour one region of the interval over any other region.
     More formally:
     Let X be a continuous random variable. X is uniformly distributed on the inter-
     val [a, b] if there exists some constant c such that for any interval [a1, b1] in [a, b],

   Pr(a1 ¤ X ¤ b1) = c(b1 ¡ a1). That is, the probability that X is in a particular

     interval within [a, b] depends only on the length of that interval.

 Example 4.1.25

Suppose X is a continuous random variable that is uniformly distributed on the interval
[0, 10].

  The intervals [2, 5] and [3, 6] have the same length, so Pr(2 ¤ X ¤ 5) = Pr(3 ¤ X ¤ 6).
  The intervals [2, 3], [3, 4], and [7, 8] have equal length, so Pr(2 ¤ X ¤ 3) = Pr(3 ¤ X ¤
4) = Pr(7 ¤ X ¤ 8). So, X is twice as likely to be in the interval [2, 4] as it is to be in the

interval [7, 8].
                                                                                                Example 4.1.25

 Corollary4.1.26.
Suppose X is a continuous random variable that is uniformly distributed on its

sample space, the interval [a, b]. Then for any interval [a1, b1] with a ¤ a1 ¤ b1 ¤
b, Pr(a1 ¤ X ¤ b1) = b1 ¡ a1

                                         b¡a

That is, the probability that X is in the interval [a1, b1] is the ratio of the length of
that interval to the sample space interval.

                                                   247
PROBABILITY                                                                        4.1 INTRODUCTION

Proof. Since the sample space of X is [a, b],

                                         Pr(a ¤ X ¤ b) = 1

Since X is uniformly distributed on [a, b], there exists a constant c such that Pr(a1 ¤ X ¤
b1) = c(b1 ¡ a1) for any interval [a1, b1] inside the interval [a, b]. So,

                     1 = Pr(a ¤ X ¤ b) = c(b ¡ a) ùñ c = 1
                                                        b¡a

Then:                Pr(a1 ¤ X ¤ b1) = c(b1 ¡ a1) = b1 ¡ a1
                                                  b¡a

 Example 4.1.27

Let X be a continuous random variable that is uniformly distributed on its sample space,

the interval [0, 10]. What is Pr(7 ¤ X ¤ 9)?

Solution.
    The interval [7, 9] has length 2; the sample space interval [0, 10] has length 10. So,

                            Pr(7 ¤ X ¤ 9) = 210 = 15

                                                                                                Example 4.1.27

Example 4.1.28

Let X be a continuous random variable that is uniformly distributed across its sample

space [¡8, 17]. Calculate the probabilities below.
  1. Pr(1 ¤ X ¤ 2)
  2. Pr(¡5 ¤ X)
  3. Pr(¡10 ¤ X ¤ 10)

Solution.

1.  By Corollary 4.1.26, Pr(1 ¤  X       ¤ 2)  =    2¡1    =   1
                                                  17¡(¡8)      25

2. Since X only takes on values in its sample space [¡8, 17]: Pr(¡5 ¤ X) = Pr(¡5 ¤
       ¤                                 Pr(¡5  ¤      ¤           17¡(¡5)     22
    X      17).  By  Corollary  4.1.26,            X      17)  =   17¡(¡8)  =  25

3. Since X only takes on values in its sample space [¡8, 27]: Pr(¡10 ¤ X ¤ 10) =
  Pr(¡8 ¤ X ¤ 10). Now the interval [¡8, 10] is inside our sample space, unlike the
  interval [¡10, 10], so we can apply Corollary 4.1.26.
  Pr(¡8 ¤ X ¤ 10) = 10¡(¡8) = 18

                          17¡(¡8) 25

                                                  248
PROBABILITY                   4.2 PROBABILITY MASS FUNCTION (PMF)
                                                                Example 4.1.28

 Example 4.1.29
Suppose the continouous variable X is the age of a randomly chosen living person, mea-
sured in years with exact precision. Then X is more likely to be near 50 than it is to be near
110. So, X is not uniformly distributed.

                                                                                                Example 4.1.29

4.2 Probability Mass Function (PMF)

     For a discrete random variable, the description of the probabilities of all events in its sam-
     ple space is its probability mass function.

            Definition4.2.1.
           A probability mass function (PMF) for a discrete random variable X is the func-
          tion f (x) from R to [0, 1], where

                                                   f (x) = Pr(X = x)

Often f (x) formally takes the form of a piecewise function, e.g.

                          51  x = 1, 2, 3, 4, 5, or 6
                              else
             f (x) = 6
                         0

for a dice roll. In particular, f (x) = 0 for every value x not in the sample space of the
random variable.

                                                         249
PROBABILITY                 4.2 PROBABILITY MASS FUNCTION (PMF)

Notation4.2.2.

Rather than writing a piecewise function every time, we will represent the prob-
ability mass function (PMF) of a random variable X using a table, set up like
this:

                                       x Pr(X = x)

                1  Pr(X  =  1)  =  1
                                   6

                2  Pr(X  =  2)  =  1
                                   6

                3  Pr(X  =  3)  =  1
                                   6

                4  Pr(X  =  4)  =  1
                                   6

                5  Pr(X  =  5)  =  1
                                   6

                6  Pr(X  =  6)  =  1
                                   6

where events not in the sample space do not show up in the table.

      Theorem4.2.3.
     For any probability mass function (PMF) f (x):

         · f (x) is a number in [0, 1] for every real number x, and
          · the sum of the probabilities of all values in the sample space is one.

Proof. · f (x) = Pr(X = x), and probabilities are defined (4.1.1) to be in [0, 1].

   · X is guaranteed to be a value in the sample space, so using Theorem 4.1.18, 1 =
       Pr(X is in S ), which is the sum of Pr(X = x) for every x in S.
                                                         250
PROBABILITY                                           4.2 PROBABILITY MASS FUNCTION (PMF)

Warning4.2.4.

If Pr(X = x) = 0, then often f (x) is omitted from the probability mass
function (PMF). For example, in Notation 4.2.2, we don't bother writing that
Pr(X = 17) = 0, or Pr(X = 18) = 0, or Pr(X = 107.4) = 0.
You might also see this omission in a probability mass function (PMF) written as
a piecewise function. Instead of writing this:

                                       51   x = 1, 2, 3, 4, 5, or 6
                                            else
                          f (x) = 6
                                      0

you could write this:

                          f (x)  =  1  for  all  x  in  t1, 2, 3, 4, 5, 6u.
                                    6

Notation4.2.5.

The notation                                ¸

                                                f (x)

                                             x

means we take the sum of f (x) for every value x in some set. In this context, that
set is understood to be the sample space of a random variable.

We may also omit the bound, writing simply

                                            ¸

                                                f (x)

    The sample space may or may not be a range of integers, which is why this notation is
slightly different from the sigma notation we use in the other chapters of this book.

 Example 4.2.6

A child psychologist is interested in the number of times per night a newborn baby's cry-
ing wakes its parent. The record this number for 100 different parents.

                       x number of parents woken x times

                       0                            5
                       1                            5
                       2                            40
                       3                            23
                       4                            13
                       5                            10
                       6                            0
                       7                            3
                       8                            1

                                                 251
PROBABILITY                                    4.2 PROBABILITY MASS FUNCTION (PMF)

    Suppose we pick one parent uniformly at random. Let X be the number of times per
night that parent is woken up. X takes on the values 0, 1, 2, 3, 4, 5, 6, 7, 8.

             x P(X = x)

             0  P(X  =                         0)  =   5
                                                      100

             1  P(X  =                         1)  =   5
                                                      100

             2  P(X  =                         2)  =  40
                                                      100

             3  P(X  =                         3)  =  23
                                                      100

             4  P(X  =                         4)  =  13
                                                      100

             5  P(X  =                         5)  =  10
                                                      100

             6  P(X  =                         6)  =   0
                                                      100

             7  P(X  =                         7)  =   3
                                                      100

             8  P(X  =                         8)  =   1
                                                      100

This is a probability mass function (PMF) because:

· Each probability is in the interval [0, 1].

· The sum of the probabilities is one, that is,

¸ Pr(X = x) = 5 + 5 + 40 + 23 + 13 + 10 + 0 + 3 + 1 = 1
             100 100 100 100 100 100 100 100 100
x

                                                                                                Example 4.2.6

 Example 4.2.7
A hospital researcher is interested in the number of times an average post-op patient will
ring the nurse during a 12-hour shift. For a random sample of 50 patients, the following
information was obtained.

    Let X be the number of times a patient rings the nurse during a 12-hour shift.
                                                         252
PROBABILITY                4.2 PROBABILITY MASS FUNCTION (PMF)

                x P(X = x)

                0  P(x  =  0)  =                4
                                                50

                1  P(x  =  1)  =                8
                                                50

                2  P(x  =  2)  =                16
                                                50

                3  P(x  =  3)  =                14
                                                50

                4  P(x  =  4)  =                6
                                                50

                5  P(x  =  5)  =                2
                                                50

Why is this a probability mass function (PMF)?

Solution. Yes, each probability is a number from the interval [0, 1], and their sum is 1:

             ¸ Pr(X = x) = 4 + 8 + 16 + 14 + 6 + 2 = 1
                50 50 50 50 50 50
             x

                                                        Example 4.2.7

 Example 4.2.8

Suppose Nancy has classes three days a week. She attends classes three days a week 80%
of the time, two days 15% of the time, one day 4% of the time, and no days 1% of the time.
Suppose one week is randomly selected.
a. What is the random variable in this case? Call it X.
b. What values does X take on?
c. Construct a probability mass table (called a PM table) like the one in Example 4.2.6.

   The table should have two columns, labelled x and P(X = x).
d. What does the P(x) column sum to?

Solution.
a. X is the number of days Nancy went to class on the randomly selected week.

b. From the description, X has sample space t0, 1, 2, 3u.

                                              x P(X = x)
                                              0 P(x = 0) = 0.01
                                         c. 1 P(x = 1) = 0.04
                                              2 P(x = 2) = 0.15
                                              3 P(x = 3) = 0.8

                                                         253
PROBABILITY                        4.2 PROBABILITY MASS FUNCTION (PMF)

     °3

d. x=0 Pr(X = x) = 0.01 + 0.04 + 0.15 + 0.8 = 1, which accords with Definition 4.2.1.
                                                                                                Example 4.2.8

 Example 4.2.9

Suppose a person is chosen at random from a group. Let X be the discrete random variable
describing the number of siblings that person has, and suppose the following probabilities
hold for X:

                                            x P(X = x)
                                            0 P(X = 0) = 0.25
                                            1 P(X = 1) = 0.3
                                            2 P(X = 2) = 0.25
                                            3 P(X = 3) = 0.1
                                            4 P(X = 4) = 0.05
    If we sum up the right column, we get

                                ¸ 4

                           Pr(X = x) = 0.25 + 0.3 + 0.25 + 0.0.05 = 0.95 1

                              x=0

    That tells us this is not a probability mass function (PMF). Since all probabilities are
numbers in the interval [0, 1], it must be the case that we haven't summed over all values
in the sample space. That is, in our sample of people, there must be some people who
haven't been described here, e.g. people with more than four siblings. (Indeed, these
folks would make up 5% of the group.)

                                                                                                Example 4.2.9

4.2.1  Limitations of Probability Mass Function (PMF)

Let's imagine we're choosing numbers from 1 to 3 uniformly at random. The number
chosen is called X. In the examples below, we'll investigate the difference between discrete
choices and a continuous choice.

· If we choose an integer from 1 to 3 uniformly at random, then our probability mass
   function (PMF) is:

                                                  51  x is 1, 2, or 3
                                                      otherwise
             f (x) = Pr(X = x) = 3
                                           0

Graphed, it looks like this:

                              254
PROBABILITY                                                          4.2 PROBABILITY MASS FUNCTION (PMF)

                       y

                           1
                           3

                                                                                                                x

                                                   1                      2                   3

Furthermore,                  Pr(X   ¤   2)  =  2.

                                                3

· If we choose a number from 1 to 3 uniformly at random, choosing numbers of the
form  n   where               n  is  an  integer    (e.g.    we  can   choose    1  and  1.5  but  not  1.15),  then  there
      2
are five numbers to choose from. Our probability mass function (PMF) is:

             y

          1
          5

                                                                                                                x

                                                   1         1.5          2         2.5       3

For  example,                 Pr(X   =   2)  =  1  and  Pr(X      =   7)  =  0.  Furthermore,      Pr(X  ¤  2)     =  3.
                                                5
                                                                                                                      5

· If we choose a number from 1 to 3 uniformly at random, choosing numbers of the
form  n   where               n  is  an  integer      (e.g.  we   can  choose    1  and  1.1  but  not  1.15),  then  there
      10
are 21 numbers to choose from. Our probability mass function (PMF) is:

          y

          1

          21 x

                                                   1                      2                   3

Furthermore,                  Pr(X   ¤   2)  =  11 .

                                                21

· So far, all the examples have been discrete systems. What if we want X to be a
   continuous variable? We want to be able to choose any real number from 1 to 3. In
   this case, there are infinitely many numbers to choose from. So, the probability of
   choosing any of them is... zero!

                                                             255
PROBABILITY                            4.3 CUMULATIVE DISTRIBUTION FUNCTION (CDF)
                      y

                                                                         x

                         1                    2                   3

This is a problem! We know we're choosing numbers between 1 and 3, but we have
Pr(X = 1) = 0 and Pr(X = 4) = 0. So the probability mass function (PMF) is not
useful for describing continuous random variables. We need a different tool.

On the other hand, it's easy to imagine that Pr(X          ¤  2)  =  1.  So somehow this

                                                                     2
calculation didn't break when we moved from a discrete system to a continuous
system.

4.3 Cumulative Distribution Function (CDF)

     In the final example above, Pr(X = x) = 0 for every number x. Looking at individual
     numbers isn't very enlightening. Instead of looking at individual numbers, then, we can
     look at ranges of numbers. These behave more nicely. With that in mind, we make the
     following definition.

            Definition4.3.1.
           Given a random variable X, the cumulative distribution function (CDF) of X,
          usually denoted by F(x), is

                                      Pr(X ¤ x)

    This might seem like a weirdly specific definition. Secretly, our main purpose in cre-
ating this function is to use it as a tool to define two other things: a continuous random
variable, and the probability density function. Our motivation for defining the cumulative
distribution function (CDF) may lie with continuous random variables, but the definition
applies to discrete random variables as well.

 Example 4.3.2

Suppose a random variable X has cumulative distribution function (CDF) F(x), given by

                                           6  x 0

                                   9 80       0 ¤ x ¤ 100
                         F(x) = x 42          x ¡ 100

                                      9 10

                                   71

Evaluate the following probabilities:

  1. Pr(X ¤ 50)
  2. Pr(X ¡ 10)

                                       256
PROBABILITY  4.3 CUMULATIVE DISTRIBUTION FUNCTION (CDF)

  3. Pr(X ¤ 0)
  4. Pr(X ¥ 200)
  5. Pr(10 X ¤ 20)

Solution.

  1. By Definition 4.3.1: Pr(X ¤ 50) = F(50); using the formula given for F(x), this is

       502 = 1

          104 4

  2. Pr(X ¡ 10) is the probability that X is not less than or equal to 10, so
          Pr(X ¡ 10) = 1 ¡ Pr(X ¤ 10) = 1 ¡ F(10) = 1 ¡ 104 10 = 2 1 ¡ 1100 = 99 100

  3. Pr(X ¤ 0) = F(0) = 0. Note this tells us that X never takes negative values.
  4. Note Pr(X ¤ 100) = F(100) = 1. That tells us that X always takes values less than

       or equal to 100. Combined with our last note, that means the only values X ever

    takes are in the interval [0, 100]. So, Pr(X ¥ 200) = 0.

   5. We can think of the interval (10, 20] as "numbers that are less than equal to 20 except

    numbers less than or equal to 10." We rewrite Pr(10 X ¤ 20) in a manner similar

       to Problem 2:

          Pr(10 X ¤ 20) =Pr(X ¤ 20 and X § 10) = Pr(X ¤ 20) ¡ Pr(X ¤ 10)
                           = F(20) ¡ F(10) = 104 202 ¡ 104 10 = 2 3100

                                                                                                Example 4.3.2

The ideas in the calculations of 2 and 5 above give us the following corollary.

  Corollary4.3.3.

 Let X be a random variable with cumulative distribution function (CDF) F(x).
 Then

   1. Pr(X ¡ a) = 1 ¡ F(a), and
   2. Pr(a X ¤ b) = F(b) ¡ F(a)

Proof. The probability Pr(X ¡ a) is the probability that X is not less than or equal to a, so
                      Pr(X ¡ a) = 1 ¡ Pr(X ¤ a) = 1 ¡ F(a)

  The probability Pr(a X ¤ b) is the probability that X is less than or equal to b and X

is not less than or equal to a.

              Pr(a X ¤ b) = Pr(X ¤ b) ¡ Pr(X ¤ a) = F(b) ¡ F(a)

             257
PROBABILITY                                4.3 CUMULATIVE DISTRIBUTION FUNCTION (CDF)

Example 4.3.4

Let X be a discrete random variable with probability mass function (PMF) below.

                                           x Pr(X = x)

                                           10            1
                                                       16

                                           20            3
                                                       16

                                           30            5
                                                       16

                                           40            7
                                                       16

Note that the only values taken on by X are the numbers 10, 20, 30, and 40.
Let F(X) be the cumulative distribution function (CDF) of X.

· By Definition 4.3.1, F(10) = Pr(X ¤ 10). Looking at the probability mass function
(PMF),    X    ¤  10  only  when     X     10,  which     happens     1   of  the  time.  So,  in  this  case:
                                        =                             16

                            F(10) = Pr(X ¤ 10) = Pr(X = 10) = 116

· By Definition 4.3.1, F(20) = Pr(X ¤ 20). Looking at the probability mass function
(PMF),    X    ¤  20  only  when     X     10   or  X     20,  which  happens      1      3    of  the  time.   So,
                                        =              =                           16  +  16

in this case:

                F(20) = Pr(X ¤ 20) = Pr(X = 10 or X = 20) = 116 + 316 = 14

· Similarly,

  F(30) = Pr(X ¤ 30) = Pr(X = 10 or X = 20 or X = 30) = 116 + 316 + 516 = 916

and

       F(40) = Pr(X ¤ 40) = Pr(X = 10 or X = 20 or X = 30 or X = 40)

                   = 116 + 316 + 516 + 717 = 1

The cumulative distribution function (CDF) has all real numbers as its domain, so
we aren't quite finished determining the function F(x). However, after doing a few
examples, the rest of the function is easy to figure out.

· F(9) = Pr(X ¤ 9) = 0; indeed, F(x) = 0 for all x 10.

· F(11) = Pr(X ¤ 11) = Pr(X = 10), since 10 is the only number ever taken by X that
is  less  than  or  equal   to  11.  So,  F(11)        F(10)      1.  Indeed,      F(x)      F(10)  for  all  x  in
                                                    =          =                          =
                                                                  16
the interval [10, 20)

                                                    258
PROBABILITY                                          4.3 CUMULATIVE DISTRIBUTION FUNCTION (CDF)

   · Following this line of reasoning:

                                                          6
                                                          9 90 x 10
                                                          9 9 9 1
                                                          9 8 16 10 ¤ x 20
                                         F(x) =              1         20 ¤ x  30
                                                             4
                                                          9 9 9 9
                                                          9 9 16 30 ¤ x 40
                                                          9 71 40 ¤ x

             y
          1

   9/16

    1/4                                                                                                        x
   1/16

                                  10             20                30          40                   50

                                                                                                        Example 4.3.4

 Example 4.3.5

Let U be a random variable that is chosen uniformly at random from all real numbers in
the interval [0, 1]. Understanding the cumulative distribution function (CDF) F(x) of U
can help us understand what "uniformly" means in this case.

    As we saw in section 4.2.1, it's not useful to note that Pr(U = x) is the same for every
number in [0, 1], because that probability is 0. We can get at the meaning of "uniformly"
in a more useful way by examining ranges of numbers.

    If we were to divide our interval6 in half, then the uniformity of distribution tells us
that half the time, U is in one half, and half the time, U is in the other half. In particular,

                    Pr 0 ¤ U ¤ 12 = Pr 12 ¤ U ¤ 1 = 12

So, for the cumulative distribution function (CDF),
                                                 F 12 = 12

6  Since  Pr(U  =  1)  =  0,  it  won't  matter  whether  we    use    the  interval  [0, 1/2]  or  [0, 1/2).

                   2

                                                          259
PROBABILITY        4.3 CUMULATIVE DISTRIBUTION FUNCTION (CDF)

    If we were to divide our interval into equal tenths, then the uniformity of distribution
tells us that U should fall in each interval one-tenth of the time. For example,

Pr 0 ¤ U ¤ 110 = Pr 110 ¤ U ¤ 210 = Pr 210 ¤ U ¤ 310 = 110

So,
                                                F 110 = 110

    In general, if x is a number in the interval [0, 1], then x describes the proportion of [0, 1]
taken up by the interval [0, x], so F(x) = x.

                                     6  x 0

                             9 80       0¤x¤1
                   F(x) = x
                                        1 x
                             9 71

                y
             1

                                                                                                  x
                                                            1

                                                                                                Example 4.3.5

    The cumulative distribution function (CDF) will give us our actual definition of a con-
tinuous random variable. Thinking of "continuous" as the opposite of "discrete" is not
sufficiently accurate.

      Definition4.3.6.
     A random variable X is continuous if its cumulative distribution function (CDF)
     is continuous.

 Example 4.3.7
The random variables from Examples 4.3.2 and 4.3.5 are continuous random variables.

    The random variable from Examples 4.3.4 is not a continuous random variable.
                                                                                                Example 4.3.7

                                                         260
PROBABILITY                           4.3 CUMULATIVE DISTRIBUTION FUNCTION (CDF)

 Corollary4.3.8.
Let X be a continuous random variable. For any real number a,

                                          Pr(X = a) = 0
Furthermore,

        Pr(X a) = Pr(X ¤ a) and Pr(X ¡ a) = Pr(X ¥ a)

Proof. Let F(x) be the cumulative distribution function (CDF) of X.

             lim F(x) = lim Pr(X ¤ x)                = Pr(X a)
             xÑa¡  xÑa¡

By the definition of a continuous function,

                     lim F(x) = F(a)

                 xÑa¡

So,

                                   Pr(X      a) = Pr(X ¤ a)

                   Pr(X ¤ a) ¡ Pr(X          a) = 0

                                      Pr(X = a) = 0

The "furthermore" statements follow.

             Pr(X ¤ a) = Pr(X a) + Pr(X = a) = Pr(X a)
             Pr(X ¥ a) = Pr(X ¡ a) + Pr(X = a) = Pr(X ¡ a)

 Example 4.3.9

V is a number chosen at random from all real numbers in the intervals [¡3, ¡1] or [1, 3] as

follows:
    · First, a fair 6-sided dice is rolled. If the outcome of the roll is 1 or 2, then V is chosen

    to be in the interval [¡3, ¡1]. If the outcome of the roll is 3, 4, 5, or 6, then V is chosen

       to be in the interval [1, 3].
    · Within the selected interval, V is chosen uniformly at random.
    Determine the cumulative distribution function (CDF) of V and decide whether or not
V is continuous.

Solution. From the first step, we see that V is in the interval [¡3, ¡1] one-third of the time,

and in the interval [1, 3] two-thirds of the time.

                  Pr(¡3 ¤ V ¤ ¡1) = 13, Pr(1 ¤ V ¤ 3) = 23

                                                         261
PROBABILITY                                         4.3 CUMULATIVE DISTRIBUTION FUNCTION (CDF)

    Within these intervals, V has a uniform distribution. As in Example 4.3.5, we consider

intervals. For example, V is equally likely to be in the interval [¡3, ¡2] and the interval
[¡2, ¡1]. So,

                     Pr (¡3 ¤ V ¤ ¡2) = Pr (¡2 ¤ V ¤ ¡1)

Also,

          Pr (¡3 ¤ V ¤ ¡2) + Pr (¡2 ¤ V ¤ ¡1) = Pr(¡3 ¤ V ¤ ¡1) = 13

So,

                   Pr (¡3 ¤ V ¤ ¡2) = Pr (¡2 ¤ V ¤ ¡1) = 16

Following the reasoning in Example 4.3.5, we see on the interval [¡3, ¡1], the function
F(x)  is  a  straight  line  from   F(¡3)        0  to  F(¡1)       1.
                                              =                 =
                                                                    3
When ¡1 x 1, then F(x) = Pr(X ¤ x) = Pr(X ¤ ¡1) = F(¡1), since no values of
V are ever less than 1 without also being less than or equal to ¡1. Then, by Corollary 4.3.8,
also F(1) = Pr(X ¤ 1) = Pr(X 1) = Pr(X ¤ ¡1) = F(¡1).

On the interval [1, 3], V is uniformly distributed. Following the familiar line of reason-
ing,  the  function    F(x)  is  a  straight  line  from      F(1)      1  to  F(3)     1.  All  together:
                                                                    =   3            =

                                                           y
                                                        1

                                                        1
                                                        3

             ¡3                     ¡1                                     1                                 x
                                                                                                    3
Using the graph, we can find F(x) in equation form:
                                                                                                 Example 4.3.9
                                                 6              x ¡3
                                                 9 90           ¡3 ¤ x ¡1
                                                 9         1    ¡1 ¤ x 1
                                                 9              1¤x 3
                                                 9x     +       x¥3

                                                 9
                                                 86 2
                                    F(x) = 1
                                                 93
                                                 9 9 1  x
                                                 9  3
                                                 9
                                                 9 71

Since F(x) is continuous, V is a continuous random variable.

                                                           262
PROBABILITY                                                 4.4 PROBABILITY DENSITY

 Corollary4.3.10 (Properties of the cumulative distribution functions (CDF)).

If F(x) is the cumulative distribution function (CDF) of a continuous random
variable X, then:

  1. 0 ¤ F(x) ¤ 1 for all real x

   2. F(x) is nondecreasing
   3. lim F(x) = 1

      xÑV

   4. lim F(x) = 0

      xÑ¡V

Proof. 1. F(x) is a probability, and all probabilities are numbers between 0 and 1.
   2. Suppose a b.

           F(a) = Pr(X ¤ a) ¤ Pr(X ¤ a) + Pr(a X ¤ b) = Pr(X ¤ b) = F(b)
    That is, if a b, then F(a) ¤ F(b).

   3. Rather than a rigorous proof, we offer the following hand-wavey intuition: if infinity

    were a number, we'd expect F(V) = Pr(X ¤ V) = 1.

   4. Rather than a rigorous proof, we offer the following hand-wavey intuition: if nega-

    tive infinity were a number, we'd expect F(¡V) = Pr(X ¤ ¡V) = 0.

 4.4 Probability Density

4.4.1  Density Diagrams

       We're going to introduce a tool for visualizing random processes that will hopefully help
       topics in continuous random variables be more intuitive. We'll call that tool a density
       diagram.

           Let X be some continuous random variable. If X is a process (like choosing the height,
       in feet, of a random student), we can imagine performing that process again and again
       and again. Suppose we do just that. Every time we get a new value of X, we put a mark
       on a number line. For example:

          1. The first randomly-chosen student has height 5.5 feet:

             1  2  3  4                                     5  6

2. The second randomly-chosen student has height 6.1 feet:
                                                     263
PROBABILITY                                                   4.4 PROBABILITY DENSITY

             1      2       3                              4  5     6

3. The third randomly-chosen student has height 5.2 feet:

             1      2       3                              4  5     6

4. The third randomly-chosen student has height 5.4 feet:

             1      2       3                              4  5     6

5. After 20 choices, our results might look like this:

             1      2       3                              4  5     6

6. After 100 choices, our marks would start being so close together, they would be
   indistinguishable, so we might choose to make the marks slightly transparent. Then
   darker regions represent ranges where more heights have been chosen.

             1      2       3                              4  5     6

 Example 4.4.1
The continuous random variable V from Example 4.3.9 is chosen as follows:

    · First, a fair 6-sided dice is rolled. If the outcome of the roll is 1 or 2, then V is chosen

    to be in the interval [¡3, ¡1]. If the outcome of the roll is 3, 4, 5, or 6, then V is chosen

       to be in the interval [1, 3].
    · Within the selected interval, V is chosen uniformly at random.
    If we were to perform this trial 100 times, and record the number each time, our results
might look like this:

-3              -1                                      1        3

                       264
PROBABILITY                                                              4.4 PROBABILITY DENSITY

    The marks (trial outcomes) are twice as dense on the right interval. Inside the right
interval, and inside the left interval, the marks are fairly evenly distributed.

                                                                                                Example 4.4.1

Example 4.4.2

Match the density diagrams to the variable descriptions so that every description corre-
sponds to exactly one density diagram.

A. Pr(X ¤ 0) = Pr(X ¥ 0).                                  1.

                                                                                     0

B. X is uniformly distributed. 2.

                                                                                                        0

                                                           3.

C. Pr(X ¤ 0) Pr(X ¥ 0).                                                              0

                                                           4.

D. Pr(X ¤ 0) ¡ Pr(X ¥ 0).                                                            0

Solution. In both 1 and 2, it seems like (roughly) the same number of trials resulted in
positive and negative values of X. So in both cases, A holds. However, in 2, the distribu-
tion is not uniform: trials are more likely to have large absolute values than to be near 0.
So, we match B to 1 and A to 2.

  In 3, more trials gave X ¤ 0 than X ¥ 0, so we match that to D.
  In 4, more trials gave X ¥ 0 than X ¤ 0, so we match that to C.

                                                                                                Example 4.4.2

4.4.2  Probability Density Function (PDF)

As we saw in Corollary 4.3.8, if X is a continuous random variable, then Pr(X = a) = 0
for any real number a. However, that doesn't mean that all number ranges are equally
likely. In Example 4.3.5, we saw a continuous random variable U that only existed in the
range  [0,  1];  so  getting  a  value  near  1  is  more  likely  than  getting  a  value                 near  2.
                                              2
When looking at density diagrams, areas with more "hits" show up as having a higher
density of marks. This idea will be central to this section: measuring the density of a con-
tinuous random variable.
A usual definition of density is something like

                                              how much stuff
                                              how much space

                                                     265
PROBABILITY                               4.4 PROBABILITY DENSITY

    Population density might be measured in people per square kilometre, liquid density
might be measured in grams per mL, etc. Probability density follows a similar pattern:
we'll measure how likely a variable is to be in a given interval and divide it by the size (length)
of that interval.

                     a a+h

                     h

    Suppose the density diagram above represents some continuous random variable X,
and we want to measure the probability density near the indicated point a. We start by
defining a small interval around a. As is tradition, we take the interval between a and
a + h, where h is some small7 real number.

    It doesn't make sense to count the marks is this interval, since the actual number will
change as we do different trials, so instead we measure the likeliness our random variable

is to be in this interval: Pr(a ¤ X ¤ a + h). The length of the interval is h. So, our

probability density around a is:

             Pr(a ¤ X ¤ a + h)

                        h

If F(x) is our cumulative distribution function (CDF), then we can re-write this using
Corollaries 4.3.3 and 4.3.8.

                                        = F(a + h) ¡ F(a)

                                                                          h

Since we only consider small values of h, we recognize the definition of a derivative.

             lim F(a + h) ¡ F(a) = FI(a)h
             hÑ0

    This motivates our definition of the probability density function (PDF) of a continuous
random variable. Probability mass functions (PMFs) and probability density functions
(PDFs) serve similar purposes: describing which values a variable tends to take on.

 Definition4.4.3.
The probability density function (PDF) of a continuous random variable, usu-
ally written f (x), is the derivative of the cumulative distribution function (CDF),
where it exists.

    The observant reader will note that the conventional use of F(x) as an antiderivative
of f (x) squares nicely with our use of F(x) for a cumulative distribution function (CDF)
and f (x) for a probability density function (PDF).

7 By "small," we mean |h|  0. In the discussion that follows, we're considering the case h ¡ 0; the case

      h 0 proceeds in the same way.

                                                         266
PROBABILITY                                        4.4 PROBABILITY DENSITY

 Warning4.4.4.
Some textbooks use the term "probability distribution function" instead of
"probability mass function," and then use the abbreviation PDF in both a con-
tinuous and a discrete context. This reflects the similar roles probability density
functions (PDFs) and probability mass functions (PMFs) play.

Example 4.4.5

In Example 4.3.2, we considered a continuous random variable with cumulative distribu-
tion function (CDF) given by

                                   6  x 0

                           9 80       0 ¤ x ¤ 100
                 F(x) = x 42          x ¡ 100

                              9 10

                           71

The probability density function (PDF) of this variable is FI(x), namely

                                  6   x 0

                          9 80        0 ¤ x 100
                 f (x) = x            x ¡ 100

                              9 5000

                          70

    Translating f (x) into a density diagram, to help build intuition about the behaviour of
this variable, we expect to see

· no marks except in the interval [0, 100], and

· an increasing density of marks from left to right on the interval [0, 100].

             1
             50

                                                            100

                                                        Example 4.4.5
                 267
PROBABILITY                                       4.4 PROBABILITY DENSITY

Notation4.4.6.

As with probability mass functions (PMFs), it is common to suppress the regions
where a probability density function (PDF) is zero or doesn't exist. Instead of
writing
                         6
                         9 80           x 0

                f (x) =       x         0¤x  100
                            5000
                         9 70 x ¡ 100

as in Example 4.4.5, we may also write

                         3    x         0¤x
                            5000
                f (x) =                      100

and it is understood that f (x) is zero or doesn't exist when x not in the interval
[0, 100).

Another time-saving measure is to use the words "else" or "otherwise" in a
piecewise-defined function. In the context of this function:

                         5     x        0¤x  100
                               00
                f (x) = 50
                            0 else

"else" means "for all values of x other than the ones that have already been de-
fined," i.e. for all values of x outside the interval [0, 100).

 Example 4.4.7
In Example 4.3.5, we considered a continuous random variable with cumulative distribu-
tion function (CDF) given by

                                                                                                  6

                                                      9 80 x 0
                                          F(x) = x 0 x 1

                                                      9 71 1 x

   The probability density function (PDF) of this variable is FI(x), namely

                                                                                                  6

                                                      9 80 x 0
                                           f (x) = 1 0 x 1

                                                      9 70 1 x

    Notice that the density is constant on the interval (0, 1). This is a hallmark of uniformly
distributed variables: in the interval in question, no one region is denser than any other
region.

                                                         268
PROBABILITY                                                    4.4 PROBABILITY DENSITY

                        1

                                                                               1

    Note f (x) is not defined at x = 0 and x = 1 because F(x) is not differentiable at these
points8.

                                                                                                Example 4.4.7

Example 4.4.8

In Example 4.3.9, we considered a continuous random variable with cumulative distribu-
tion function (CDF) given by the function

                               6                    x ¡3
                               9 90                 ¡3 ¤ x ¡1
                               9                 1  ¡1 ¤ x 1
                               9                    1¤x 3
                               9x     +             x¥3

                               9
                               86 2
                           F(x) = 1
                               93
                               9 9 1  x
                               9  3
                               9
                               9 71

The probability density function (PDF) of this variable is FI(x), namely

                                            6       x ¡3
                                                    ¡3 x ¡1
                                    9 90            ¡1 x 1

                                            9       1 x 3
                                            9
                                                    x¡3
                                        91

                                            9

                                        86

                           f (x) = 0

                                        9 9 9 1
                                        9 9 9 3

                                            7

                                       0

    The places where the probability density function (PDF) is 0 are telling: these are the
regions where our variable never reaches (impossible to occur).

                                         1
                                         3

                                         1
                                         6

-3                         -1                       1                     3

8 You can see this by comparing the right and left limits of the limit definition of the derivative of F(x) at
      these points.

                                                         269
PROBABILITY                              4.4 PROBABILITY DENSITY

    Our intuition about f (x) is that higher f (x) means more "hits" near x. In the density

diagram above, f (2) ¡ f (¡2), and indeed the marks are denser in the area 2 than near -2.

                                                                                                Example 4.4.8

 Warning4.4.9.
Let f (x) be the probability density function (PDF) of a continuous random vari-

able. If f (x) ¡ f (y), it is not correct to say that x is more likely than y, because it

is still the case that Pr(X = x) = Pr(X = y) = 0.

 Corollary4.4.10.

From Definition 4.4.3, given a continuous random variable X with probability
density function (PDF) f (x):

                                         ³b

  1. Pr(a ¤ X ¤ b) = a f (x)dx
  2. f (x) ¥ 0 for all real x in the domain of f .

      ³V
   3. ¡V f (x) = 1

Proof. 1. By Corollaries 4.3.3 and 4.3.8, Pr(a ¤ X ¤ b) = F(b) ¡ F(a). By the Funda-I
mental Theorem of Calculus Part 2, a f (x)dx = F(b) ¡ F(a), since F (x) = f (x).³b

For this property, we are glossing over some details in assuming f (x) exists on (a, b).
If it does not, then we partition (a, b) into intervals where it does exist, and apply
the Fundamental Theorem of Calculus to those intervals separately.

2. By Part 2 of Corollary 4.3.10, F(x) is nondecreasing, so its derivative is nonnegative.

                                ³V

3. From the property above, ¡V f (x) = Pr(¡V ¤ X ¤ V) = 1

    The first property of Corollary 4.4.10 is a key piece of intuition for working with prob-
ability density functions (PDFs) : the probability density function (PDF) of a continuous
random variable X is a function f (x) with the property that the area under the curve of
f (x) from a to b is equal to the probability that X lies between a and b.

                                   y

                        f (x)            x

             a       b

             shaded area: Pr(a ¤ X ¤ b)

                270
PROBABILITY                                                       4.4 PROBABILITY DENSITY

Example 4.4.11

A continuous random variable X has probability density function (PDF)
                                                f (x) = x2 a+ 1

for some constant a.

   1. Find a.

  2. Find Pr(0 ¤ X ¤ 10).

   3. Find the cumulative distribution function (CDF) of X.

Solution.

1. By Corollary 4.4.10,

                     »V a             »V 1
                 1=         2 dx = a  2 dx
                     ¡V x + 1         ¡V x + 1

                     = a lim   »0 1                »c 1
                                    2 dx + lim 2 dx
                         bÑ¡V b x + 1 cÑV 0 x + 1

                     = a lim (arctan 0 ¡ arctan b) + lim (arctan c ¡ arctan 0)
                         bÑ¡V                            cÑV
                     = a 0 ¡ ¡2 + 2 + 0 = a ¤ 

So,        a  =  1.

                 

2. By Corollary 4.4.10,

                            » 10 » 10 1/ 1                                            arctan(10)   0.47
Pr(0 ¤ X ¤ 10) = f (x)dx =            2 dx = [arctan 10 ¡ arctan 0] =
                            0         0 x +1                                              

Note:         because    f (x) has even symmetry,  we know  Pr(X   ¤  0)  =  Pr(X  ¥  0)  =  1.

                                                                                             2
Also, Pr(0 ¤ X ¤ 10) ¤ Pr(0 ¤ X), so it stands to reason that our answer would be
less than one-half.

3. Let F(x) be the cumulative distribution function (CDF) of X.

           F(x) = Pr(X ¤ x)                                           (definition of CDF)

                 = Pr(¡V X ¤ x)
                    » x » x 1/
                 = f (t)dt = lim 2 dt
                     ¡V        bÑ¡V b t + 1
                 = 1 lim [arctan x ¡ arctan b] = 1
                      bÑ¡V                           arctan x + 2

                 = 1 arctan x + 12

Note: it's nice to do a quick sanity check by comparing F(x) to the properties of a
cumulative distribution function (CDF) in Corollary 4.3.10. This is a great way to
root out calculation errors, sign errors, and so on.

                                      271
PROBABILITY                              4.5 EXPECTED VALUE
                                               Example 4.4.11

We can formalize the last part of the previous exercise as a corollary to Corollary 4.4.10.

 Corollary4.4.12.
Let X be a continuous random variable with probability density function (PDF)
f (x). Then the cumulative distribution function (CDF) of X is

                                                                    »x

                                  F(x) = ¡V f (t)dt

Proof. The CDF is defined as F(x) = Pr(X ¤ x), i.e. Pr(¡V X ¤ x). By Corollary 4.4.10,

             Pr(¡V                   »x

                    X ¤ x) = f (t)dt

                                ¡V

 4.5 Expected Value

4.5.1  Motivation: Long-Term Average

       Suppose I throw a 4-sided dice a large number of times, and record the number that comes
       up each time. What will the average (mean) of those numbers be?

           To calculate the mean, I'll add up the results of my rolls and divide by the number of
       rolls I took.

    mean = (result of first roll) + (result of second roll) + ¤ ¤ ¤ + (result of last roll) total number of rolls

                                                                272
PROBABILITY                                                   4.5 EXPECTED VALUE

The numerator will consist of the numbers 1 through 4, since these are the numbers re-
sulting from a 4-sided dice roll. Let's regroup the numerator so we add up all the 1s first,
then all the 2s second, etc.

     = (1 + 1 + ¤ ¤ ¤ ) + (2 + 2 + ¤ ¤ ¤ ) + (3 + 3 + ¤ ¤ ¤ ) + (4 + 4 + ¤ ¤ ¤ )

                                     total number of rolls

= (1 + 1 + ¤ ¤ ¤ ) + (2 + 2 + ¤ ¤ ¤ ) + (3 + 3 + ¤ ¤ ¤ ) + (4 + 4 + ¤ ¤ ¤ )
total rolls       total rolls     total rolls    total rolls

= 1 ¤ (number of times 1 was rolled) + 2 ¤ (number of times 2 was rolled)
                  total rolls                    total rolls

+ 3 ¤ (number of times 3 was rolled) + 4 ¤ (number of times 4 was rolled)
             total rolls                         total rolls

     = 1 ¤ (proportion of rolls resulting in 1) + 2 ¤ (proportion of rolls resulting in 2)
     + 3 ¤ (proportion of rolls resulting in 3) + 4 ¤ (proportion of rolls resulting in 4)

If we've rolled the dice a large number of times, we expect the proportion of rolls resulting
in 1 to closely approximate Pr(X = 1), and so on.

                                                                                                                                 ¸ 4

      1 ¤ Pr(X = 1) + 2 ¤ Pr(X = 2) + 3 ¤ Pr(X = 3) + 4 ¤ Pr(X = 4) = x ¤ Pr(X = x)

                                                                                                                           x=1

    This calculation, what we expect to have as our average if we perform the dice roll a
large number of times, motivates Definition 4.5.1 below.

4.5.2  Definition and Examples

       The expected value or expectation of a random variables is often referred to as the "long-
       term" average. This means that over the long term of doing an experiment over and over,
       you would expect this average.

Definition4.5.1.

Given a discrete random variable X, the expected value of X, denoted E(X), is
given by
                               ¸  x ¤ Pr(X = x)

where the sum is taken over every possible value of X.

Given a continuous random variable X with probability density function (PDF)
f (x), the expected value of X is given by

                               » V x ¤ f (x)dx

                                ¡V

                                  273
PROBABILITY                                             4.5 EXPECTED VALUE

    Note the similarities between the continuous and discrete cases. A sum in the discrete
cases turns into an integral in the continuous case; Pr(X = x) turns into the probabil-
ity density function (PDF) f (x); and "every possible value of X" turns into the range

(¡V, V).

 Example 4.5.2

In Example 4.2.6, we saw the following probability mass function (PMF) for the random
variable X:

             x P(X = x)

             0  P(x  =  0)  =                      5
                                                  100

             1  P(x  =  1)  =                      5
                                                  100

             2  P(x  =  2)  =                     40
                                                  100

             3  P(x  =  3)  =                     23
                                                  100

             4  P(x  =  4)  =                     13
                                                  100

             5  P(x  =  5)  =                     10
                                                  100

             6  P(x  =  6)  =                      0
                                                  100

             7  P(x  =  7)  =                      3
                                                  100

             8  P(x  =  8)  =                      1
                                                  100

The expected value of this discrete random variable is

               ¸ 8

E(X) = x ¤ Pr(X = x)

              x=0

     = 0 ¤ Pr(X = 0) + 1 ¤ Pr(X = 1) + 2 ¤ Pr(X = 2) + 3 ¤ Pr(X = 3) + 4 ¤ Pr(X = 4)
     + 5 ¤ Pr(X = 5) + 6 ¤ Pr(X = 6) + 7 ¤ Pr(X = 7) + 8 ¤ Pr(X = 8)
     = 0 ¤ 5100 + 1 ¤ 5100 + 2 ¤ 40 100 + 3 ¤ 23 100 + 4 ¤ 13 100 + 5 ¤ 10 100 + 6 ¤ 0100 + 7 ¤ 3100 + 8 ¤ 1100

       = 285 = 2.85
           100

    The most literal interpretation of expected value in this context is this:

Suppose we choose a parent from a list at random many times, and each time
record the number of awakenings, X. After a large number of trials, we expect
the average of these X values to approach 2.85.

We can also interpret the calculation like this:

The average number of times a parent was woken up in our trial was 2.85.

                     274
PROBABILITY                                                                                     4.5 EXPECTED VALUE

    Of course, no parent was woken up exactly 2.85 times in the night. Expected values
refer to averages, and do not necessarily accord well with individual trials.

                                                                                                Example 4.5.2

    Probability does not describe the short-term results of an experiment. It gives informa-
tion about what can be expected in the long term. The Law of Large Numbers states that, as
the number of trials in a probability experiment increases, the difference between the the-
oretical probability of an event and the relative frequency approaches zero (the theoretical
probability and the relative frequency get closer and closer together).

 Example 4.5.3

Suppose we flip a fair coin a large number of times. We want to record the average number
of times the flip resulted in heads.

    Let X be the random variable corresponding to a coin flip, with X = 1 when the flip is
heads and X = 0 when the flip is tails. Using these assignments, if we add up the values
of X from each experiment, that sum tells us how many flips were heads. The expected
value of X is

                   E(X) = ¸ x 2 ¤ Pr(X = x) = 0 ¤ 12 + 1 ¤ 12 = 12

                                                    x=1

Consider interpreting the expected value as a long-term average, using the law of large
numbers. If we were to flip a fair coin a large number of times, we would expect the
average     value  of  X  to  be  1.  That    is,  we  would        expect   roughly     1  of  the  tosses  to  result  in
heads.                                                                                   2
                                  2

In 2009, intrepid undergraduate students at Berkeley tossed coins 40,000 times9. The
tosses resulted in 20,217 heads. The fraction of coin tosses resulting in heads, therefore,
was 20, 217 = 0.505425
                                                   40, 000

which   is  indeed  fairly    close   to  1.

                                          2

                                                                                                     Example 4.5.3

 Example 4.5.4

Let X be a continuous random variable with probability density function (PDF)

                         f (x) = ax2(10 ¡ x), 0 ¤ x ¤ 10

where a is a constant.
    Find a and E(X).

9 A writeup is here: https://www.stat.berkeley.edu/~aldous/Real-World/coin_tosses.
html. They were actually trying to determine whether the starting orientation of a coin had an impact
on the result of a toss. There's actually a bit of a cart-before-the-horse problem in using this example
here: if we tossed a coin a large number of times and it didn't result in very close to half heads and half
                                                                                                        1.
tails,   the  conclusion  would   be  that    the  probability  of  tossing  heads  was  not  actually
                                                                                                        2

                                                            275
PROBABILITY                                                               4.5 EXPECTED VALUE

Solution.
    From Corollary 4.4.10 part 3:

             » 1 = V » f 10 » 10 (x) = 0 + ax2(10 ¡ x)dx = a (10x2 ¡ x3)dx
                  ¡V                       0                       0

               = a 103 x3 ¡ 14 x4 = 0 a 10 104 3 ¡ 104 = 4 a 104 12
             a = 4 12
                  10

From Definition 4.5.1,

              » (X) = V x ¤ f (x)dx

                    E

                           ¡V

Note where f (x) = 0, we have a x ¤ f (x)dx = a 0dx = 0.³b³b

                                     » 10                  » 10
                           = 0 + ax3(10 ¡ x)dx = a (10x3 ¡ x4)dx
                                      0                    0
                           = a 104 x4 ¡ 15 x5 = 0 a 10 105 4 ¡ 105 = 5 a 105 20
                           = 4 12 ¤ 10 = 5 6
                               10 20

                                                                                 Example 4.5.4

Example 4.5.5

Suppose Y is a continuous random variable with probability density function (PDF)

                               f (x) = ex, x ¤ 0

Find E(Y).

Solution.
    From Definition 4.5.1,

» (Y) = V » x ¤ f 0 » 0 (x)dx = 0 + x ¤ exdx = lim x ¤ exdx
E                                          ¡V           aÑ¡V a

          ¡V

We use integration by parts with u = x, dv = exdx; du = dx, v = ex

             lim      xex   0  ¡  »0  exdx = lim     ¡aea  ¡  [ex   0     lim    [¡aea ¡ 1 + ea]

= aÑ¡V            [        ]a     a            aÑ¡V                ]a  =  aÑ¡V

                                               276
PROBABILITY                                                              4.5 EXPECTED VALUE

Note lim ea = 0, so lim ¡aea has the indeterminate form 0 ¤ V. We use l'Ho^ pital's rule.
        aÑ¡V       aÑ¡V

                   ¡a                           1
              = lim ¡a ¡ 1 + 0 = lim ¡a ¡ 1 = lim [e ] ¡ 1 = ¡1       a
              aÑ¡V looemoon        aÑ¡V e                    aÑ¡V

                   numÑV
                   denÑV

So, E(Y) = ¡1.

                                                                               Example 4.5.5

Example 4.5.6

Let  Z  be a  continuous random  variable with  probability  density function  (PDF)  f (x)  =  1
x ¥ 1. Find E(Z).
                                                                                                x2 ,

Solution.
    From Definition 4.5.1,

                E(Z) = x ¤ f (x)dx = 0 + x ¤ x » V » V ¡2dx = x » V ¡1dx
                            ¡V                  1                  1

                   = lim x » b ¡1dx = lim [ln b] = V
                            bÑV 1               bÑV

    It is sometimes the case that the expectation of a continuous random variable is infinite.
How should we interpret that?

    A random variable Z with the given probability density function (PDF) has sample

space is [1, V). It takes on finite values, but there is no limit to how large those values can

be. (It is true that smaller values are more likely, since f (x) = x¡2 is a decreasing function.

However, Z also takes on extremely large values from time to time.) E(Z) = V tells us

that if we run our experiment Z a lot of times, over time the average will increase without
bound.

                                                                                                Example 4.5.6

4.5.3  Checking your Expectation Calculation

       The expectation of a random variable has several intuitive properties that can be used to
       quickly check that your answer is reasonable.

              Theorem4.5.7.

        Let a, b be real numbers or ¨V with a b. Suppose a (discrete or continuous)

            random variable X takes values from the interval [a, b]. Then E(X) will be some
            number in the interval [a, b].

                                                                277
PROBABILITY                                                4.5 EXPECTED VALUE

Proof. First, suppose X is continuous, with probability density function (PDF) f (x).

                       »b            »b             »b
E(X) = x f (x)dx ¤ b ¤ f (x)dx = b f (x)dx = b
                       a               a            a
                       »b            »b             »b
E(X) = x f (x)dx ¥ a ¤ f (x)dx = a f (x)dx = a
                       a               a            a

Next, suppose X is discrete

                       ¸                    ¸           ¸
E(X) = x ¤ Pr(X = x) ¤ b ¤ Pr(X = x) = b Pr(X = x) = b

                       x                    x           x
                       ¸                    ¸           ¸
E(X) = x ¤ Pr(X = x) ¥ a ¤ Pr(X = x) = a Pr(X = x) = a

                       x                    x           x

Theorem4.5.8.

Let a and b be real numbers with a b. Suppose a continuous (resp. discrete)
random variable X takes values from the interval [a, b], and its probability den-
sity function (PDF) (resp. probability mass function (PMF)) is increasing on the
                                  ¡  a+b .
interval  [a, b].     Then  E(X)
                                      2

Similarly, suppose a continuous (resp. discrete) random variable X takes values
from the interval [a, b], with a b, and its probability density function (PDF)
(resp. probability mass function (PMF)) is decreasing on the interval [a, b]. Then
E(X) a+b .

                 2

Proof. Intuitively, an increasing f (x) means we have more high values than low values,
so when we average them together, the average will be high. Similarly, decreasing f (x)
means we have more low values than high values, so when we average them together, the
average will be low.

We will prove the corollary more rigorously for continuo³us variables. Let F(x) be the
                                                                                                             x

cumulative distribution function (CDF) of f (x), i.e. F(x) = ¡V f (t) dt. Note the sample
                                                                           ³x

space of X is [a, b], so for x  [a, b], F(x) = a f (t) dt. Also, F(a) = 0 and F(b) = 1.
                   ³b             b¡a                      ³b  b¡a
We claim that a F(x) dx 2 when f (x) is increasing, and a F(x) dx ¡ 2 when
f (x) is decreasing.

Proof of claim. If f (x) is increasing on [a, b], then f I(x) is positive over [a, b], i.e. FP(x) is

positive over [a, b], i.e. F(x) is concave up over [a, b]. Similarly, if f (x) is a decreasing
function on [a, b], then F(x) is concave down over [a, b].

    Concave-up functions lie below their secant lines, and concave-down functions lie
above their secant lines. Note F(a) = 0 and F(b) = 1, as desired.

· If f (x) is increasing on [a, b], then F(x) lies below the straight line from (a, 0) to (b, 1),
   so the area underneath F(x) is less than the area underneath the secant line. That is,

                                               278
PROBABILITY                                                                               4.5 EXPECTED VALUE

³b              1  (  b  ¡  a  ).
                2
 a F(x)
    y

1
                     secant li F(x) ne

             a                                                    x

                                                          b

· If f (x) is decreasing on [a, b], then F(x) lies above the straight line from (a, 0) to
(b, 1), so the area underneath F(x) is greater than the area underneath the secant
line. That is, a F(x) ¡ 2 (b ¡ a), as desired.³b
                                   1

          y

1                              F(x)
          a                      secant line

                                                                   x
                                                          b

    With this claim in hand, we now consider the expected value of X. We'll use integra-
tion by parts with u = x, dv = f (x) dx; du = dx, v = F(x).

                                      » b » b b
                            E(X) = x f (x) dx = [xF(x)]a ¡ F(x) dx
                                      a                                        a
                                                                        »b

                                      b lFoom (boo)n ¡a lFoom (aoo)n ¡ F(x) dx
                                   =

                                                                            a
                                              1              0

                                              »b

                                   = b ¡ F(x) dx
                                                a

Using the claim,

                                   5  E(X)       ¡  b  ¡  b¡a     if f (x) is increasing
                                                                  if f (x) is decreasing
                                                           2
                                      E(X)          b ¡ b¡a
                                                            2

That is,

                                   5                         if f (x) is increasing
                                                             if f (x) is decreasing
                                      X) ¡ b+a
                                      E(               2

                                      E(X) b+a         2

                                                             279
PROBABILITY                                                          4.5 EXPECTED VALUE

Example 4.5.9

Suppose X is a continuous random variable with probability density function (PDF)

                                          5ex¡a        if 1 ¤ x ¤ 5

                                  f (x) = 0            else

for some appropriate constant a. Using the two theorems in this section, give a range for
E(X).

Solution. X only takes values from [1, 5], so by Theorem 4.5.7, 1 ¤ E(X) ¤ 5.
The probability density function (PDF) f (x) = ex¡a is an increasing function, so by
Theorem  4.5.8,  E(X)  ¡  5+1     3.
                            2  =

So, E(X) is in the interval (3, 5].

    Note: There is a unique value of a for which f (x) is a probability density function
(PDF). It is the value of a that satisfies the following equality:

                                      1 = ex » 5 ¡adx

                                               1

i.e. a = ln e5 ¡ e .

                                                                     Example 4.5.9

Example 4.5.10

You calculate expected values for the various random variables described below. Which
of the values can you immediately, with very little computation, say are wrong? Which
seem reasonable?

1. W is a random variable that takes values from [4, 5], and you calculate E(W) = 4.75.

2. X is a random variable that takes values from [¡1, 0], and you calculate E(X) = 0.5.

3. Y is a continuous random variable with probability density function (PDF)

                                                   51  1¤x¤e

                                      f (x) = x        else
                                                  0

and you calculate E(Y) = 1.9.

4. Z is a continuous random variable with probability density function (PDF)

                                                   51  1¤x

                                      f (x) = x2       x 1
                                                  0

and you calculate E(Z) = ¡1.

                                      280
PROBABILITY                                                            4.5 EXPECTED VALUE

5. A is a continuous random variable with probability density function (PDF)

                                           51    c1 ¤ x
                                                   2
                              f (x) = x3 0
                                                 x c1
and you calculate E(A) = c2.
                                                           2

Solution. From Theorem 4.5.7, E(X) and E(Z) are incorrect.
The PDF of Y is decreasing on [1, e], so E(Y)    e+1          3.72     1.85  by  Theorem  4.5.8.
                                                  2                 =

Therefore the result E(Y) = 1.9 is incorrect.
For E(W), we don't have enough information to apply Theorem 4.5.8. However, it
passes the test of Theorem 4.5.7. So E(W) is reasonable, though we have no way of know-
ing whether it its correct.
For E(A), Theorem 4.5.8 doesn't apply, since the values of A do not lie in a finite
interval. However, it passes the test of Theorem 4.5.7. So E(W) is reasonable. (Indeed, if
you go through the calculation, it is correct.)

                                                                             Example 4.5.10

Example 4.5.11 (Conspiracy Theories)

The paper On the Viability of Conspiratorial Beliefs10 investigates a probabilistic model11 for
the length of time a conspiracy theory can remain secret. In particular, the author uses the
formula
                             L(t) = 1 ¡ e¡t(1¡(1¡p)N(t))

where L(t) is the probability that, after t years, a leak has occurred that would cause the
conspiracy to be exposed; N(t) is the number of people involved in the conspiracy at time
t; and p is the probability that a person involved will cause a leak in any particular year.
(It is implied that L(t) = 0 for negative values of t.)

    For this example, we'll only use a very basic version of the full model. Suppose there
are 100 (immortal) people involved in a conspiracy, no new people are ever brought into
the conspiracy, and each person has a 1% chance of causing a leak in one year.

(a) Using the model above, what is the expected amount of time it will take for a leak to
     occur?

(b) Using the model above, what is the probability that the conspiracy can survive with-
     out a leak for at least 5 years?

10 Grimes DR (2016) On the Viability of Conspiratorial Beliefs. PLoS ONE 11(1): e0147905. https://
      doi.org/10.1371/journal.pone.0147905

11 The assumptions made that lead to this model are that every member of the conspiracy is equally likely
      to cause a leak (whether by negligence or on purpose); that leak events are independent of one another;
      and that the probability of a conspirator causing a leak in any given year is constant. The full derivation
      is beyond the scope of the text, but the interested reader may look up "Poisson distribution."
      The paper goes on to approximate p using conspiracy theories that have been exposed. They also use
     demographic data to approximate N(t). They apply the model to famous conspiracy theories (e.g. the
      moon landing being faked) to discuss whether such a plot could realistically remain secret until present
      day.

                                                         281
PROBABILITY                                                                     4.5 EXPECTED VALUE
Solution.

(a) L(t) is the probability that, at time t, at least one leak has occurred. Let T be the

   time that the first leak occurs. Then L(t) = Pr(T ¤ t). So, the function L(t) is the

    cumulative distribution function of T. In order to find E(T), we'll need the probability

    density function of T, which will be LI(t) (by Definition 4.4.3).

Let's  start  by  filling  in  our  constants:  N(t)    =  100  and  p  =   1.

                                                                           100

              L(t) = 1 ¡ e¡t(1¡(1¡p)N(t)) = 1 ¡ e¡t(1¡0.99100) = 1 ¡ et(0.99100¡1)

Note that 0.99100 ¡ 1 is a constant. In order to make the work below clearer, we'll

replace it with c.

              L(t) = 1 ¡ ect where c = 0.99100 ¡ 1

We find the PDF of T by differentiating L(t).

         LI(t) = ¡cect

Now we use the definition of expected value, Definition 4.5.1

              E(T) = t ¤ L » V I(t)dt = t ¤ ¡cetc dt = lim t ¤ ¡cect dt » V » b
                           ¡V                   0                       bÑV 0

We use integration by parts with u = t, dv = ¡cectdt; du = dt, v = ¡ect

                  = lim        ¡tect b0 ¡ ¡ectdt » b
                                                 0
                    bÑV
                               ¡bebc +  1 ect b
                  = lim                 c0

                    bÑV        ¡bebc + 1c ebc ¡ 1c
                                1c ¡ b ebc ¡ 1c
                  = lim

                    bÑV

                  = lim

                    bÑV

                                                   282
PROBABILITY                                       4.6 VARIANCE AND STANDARD DEVIATION

Since c      0, lim ebc = 0 (*). So,  1  ¡  b  ebc has the indeterminate form ¡V ¤ 0. We will
             bÑV                      c

re-write this in order to use l'Ho^ pital's rule.

                  = lim ¡bc ¡1¡b         1
                         c
                  bÑV e                  c

                         d [1 ¡ b]             1

                         db c
                  = lim  d [e¡bc] ¡ c
                         db
                    bÑV     ¡1 1
                         ¡ce¡bc ¡ c
                  = lim

                    bÑV

                  = lim 1 ebc ¡ 1
                  bÑV c               c

                  = 0 ¡ 1c using (*)
                  = ¡ 1001 = 100 1  1.58

                     .99 ¡ 1 1 ¡ .99

     So, the expected value of the time it would take for this conspiracy theory to be leaked
     is about 19 months.

(b) The probability that no leak has occurred at time t = 5 is 1 ¡ L(5):
                            1 ¡ L(5) = e5(.99100¡1)  0.04

     So, there's about a 4% chance that the conspiracy would survive at least 5 years with-
     out any leaks.

                                                   Example 4.5.11

 4.6 Variance and Standard Deviation

4.6.1  Motivation: Average difference from the average

       In Example 4.5.2, we found that if we chose one of our 100 parents at random, the expected
       number of nightly awakenings was 2.85. If we choose a parent at random in this way, how
       can we determine whether that parent had a "usual" or "unusual" experience? Let's
       get our head around this problem with some preliminary observations.

           · The expected value is not an integer. So no matter who we choose, we are guaran-
              teed to not choose a parent with the expected number of awakenings. So, a "usual"
              experience is not the same as actually achieving the expected value.

           · If we choose a parent with 3 awakenings, that's as close as we can get to the expec-

         tation. It seems reasonable that when X  E(X), that's a fairly "usual" trial.

                                                                283
PROBABILITY                             4.6 VARIANCE AND STANDARD DEVIATION

· Parents with two awakenings are the most numerous. So although these parents are
   farther from average, we are more likely to choose one of them than we are to choose
   any other. So it is not enough to look for value of X that are closest to E(X).

· Suppose we choose a parent with 4 awakenings. Is this so far above average that is
   is very unusual (and so possibly a cause for concern) or is it still within a reasonably
   common range? This question will bring us to the heart of the matter: how far from
   E(X) is still "usual"?

    To quantify the last bullet point, let's compare each parent's experience to the expected
value. If your baby woke you up twice during the night, then your experience differs from
the average by 0.85. If your baby woke you up three times during the night, then your
experience differs from the average by 0.15. Let's give that difference its own variable
name, Y. Larger values of Y mean a larger difference between the individual experience
and the expectation. So parents with a high Y value are "less usual" than parents with a
low Y-value.

             x proportion of parents woken up x times Y = |x ¡ 2.85|

             0                       5                        2.85
                            100

             1                       5                        1.85
                            100

             2              40                                0.85
                            100

             3              23                                0.15
                            100

             4              13                                1.15
                            100

             5              10                                2.15
                            100

             6                       0                        3.15
                            100

             7                       3                        4.15
                            100

             8                       1                        5.15
                            100

The expectation of Y is about 2.38:

                ¸ 8
E(Y) = |lxoo¡oom2o.o8oo5n| ¤Pr(Y = y)
                x=0 Y
                = 2.85 ¤ 5100 + 1.85 ¤ 5100 + 0.85 ¤ 40 100 + 0.15 ¤ 23 100 + 1.15 ¤ 13 100
                + 2.15 ¤ 10 + 3.15 ¤ 0 + 4.15 ¤ 3 + 5.15 ¤ 1
                       100  100              100  100
                 1.15

    That is, when we choose parents at random, on average their number of awakenings
differs from the expected number of awakenings by 1.15.

                                        284
PROBABILITY  4.6 VARIANCE AND STANDARD DEVIATION

  With that in mind, we might say a parent who wakes up between 1.15 ¡ 2.38 = ¡1.23

and 1.15 + 2.38 = 3.53 times wakes up a "usual" number of times, which the other parents
have experiences that are "unusual". A parent whose baby wakes then up four times dur-
ing the night is "unusual," in that their experience is quite different from the expectation,
but a parent whose baby never wakes them up is still in the range of "usual".

    To generalize what we just computed:

· X is a random variable

· Y = |X ¡ E(X)| tells us how different X is from its expectation

· So, E(Y) = E §X §§ ¡ E(X)§§ is the expected difference from the expectation. We

   used this as a measure of how far off from E(X) our variable X could be and still be
   considered "usual".

4.6.2  Definitions and Computations

              Definition4.6.1.
            The variance of a random variable X, denoted Var(X), is:

                                   E X ¡ E(X) 2 .

            The standard deviation of X, written (X), is the square root of the variance:

                                                                                                                      

                                                    (X) = Var(X)

Remark: Let X be a continuous random variable, with PDF f (x). Then X2 is a different
continuous random variable, and it has its own PDF, say g(x), which is probably different
from f (x). Then, if we're strictly following definitions, we³ need to know what g(x) is be-
fore we can compute E(X2). Luckily, however, E(X2) =  V   x2  f  (x).  (A  similar  equation
                                                      ¡V
holds for the discrete case.) Thanks to Ben Williams for pointing out that this is a special
case of the law of the unconscious statistician.

    Recall from Definition 4.5.1 that the definition of E(X) depends on whether X is con-
tinuous or discrete.

                                                         285
PROBABILITY         4.6 VARIANCE AND STANDARD DEVIATION

 Corollary4.6.2.

If X is a discrete random variable, then

                                                                            ¸

                  Var(X) = (x ¡ E(X))2 ¤ Pr(X = x)

                                                          x

where the sum is taken over every possible value of X.
If X is a continuous random variable, then

                                    »V

                   Var(X) = (x ¡ E(X))2 ¤ f (x)dx

                                     ¡V

where f (x) is the probability density function (PDF) of X.

    Note the similarities between Var(X) and E(Y) from the end of the last subsection,
4.6.1. Their interpretations are similar: Var(X) measures the expected squared difference
between X and E(X)12.

  One reason we replace |X ¡ E(X)| with (X ¡ E(X))2 is that f (X) = |x ¡ E(X)| is
not differentiable, while f (x) = (x ¡ E(X))2 is differentiable. We want to be able to use

calculus tools, so differentiability is desirable.
 Example 4.6.3

Consider the random variable X with probability mass function (PMF) given below.

                x Pr(X = x)

                0        1
                         2

                10       1
                         2

    X takes on values from [0, 10], with E(X) = 5. Every value of X differs from E(X) by
5. However,

Var(X) = ( ¸ x ¡ 5)2 ¤ Pr(X = x) = (0 ¡ 5)2 ¤ 1 + (10 ¡ 5)2 ¤ 1 = 252          2

             x

  A drawback to replacing |X ¡ E(X)| with (X ¡ E(X))2 is that the variance may no

longer be in a meaningful range. In this case, 25 is not in the range of numbers we're
considering, so it's hard to interpret this as a "usual difference" between X and E(X).
That's why we define the standard deviation:

                               (G) = c25 = 5

    We take the square root of Var(X) to somehow atone for our previous transgression

of squaring |X ¡ E(X)|. Informally, we think of the standard deviation as the "usual"

difference between X and E(X).

12 To explore why we need absolute values or squares, see Question 14 in Section 4.6 of the practice book.

                    286
PROBABILITY                                   4.6 VARIANCE AND STANDARD DEVIATION

                                                               Example 4.6.3

 Example 4.6.4
One thousand students take a midterm, and we choose one student uniformly at random.
X is the mark the student got on the midterm, out of 100. For this particular group of 1000
students, E(X) = 65 and (X) = 15.

    · Suppose we select Student A, who earned 60 points. Although this is below the class
       average, it is within one standard deviation of the expectation. That is,

                            |X ¡ E(X)| = 5 15 = (X).

       So this student is not below average in a really significant way.
    · If we select Student B who scored 90, not only are they above the class average, they

       are well above the class average. The difference between X and E(X) is greater than
       usual.
    · If we select Student C who scored 45, not only are they below the class average, they
       are well below the class average. The difference between X and E(X) is worse than
       usual.
    · In general, we think of students with grades from 50 to 80 as having a "usual" score.

    Those numbers come from E(X) ¡ (X) = 50 and E(X) + (X) = 80.

                                                                                                Example 4.6.4

    The variance of a random variable is often calculated in the manner below:
      Corollary4.6.5.

                          Var(X) = E(X2) ¡ E(X) 2

Proof. In the continuous case, from Corollary 4.6.2:

» Var(X) = V x ¡ E(X) 2 f (x)dx
                »¡V
                V
             =       x2 ¡ 2x ¤ E(X) + [E(X)]2 f (x)dx
                »¡V
                 V                            »V           »V
             = ¡V x2 f (x)dx ¡ 2 ¤ E(X) ¡V x f (x)dx + [E(X)]2 ¡V f (x)dx

By the definition of E(X), Definition 4.5.1:

                                                      »V

             = E(X2) ¡ 2 ¤ E(X) ¤ E(X) + [E(X)]2 f (x)dx

                                                       ¡V

                                              287
PROBABILITY                                     4.6 VARIANCE AND STANDARD DEVIATION

By property 3 of Corollary 4.4.10,

               = E(X2) ¡ 2 ¤ [E(X)]2 + [E(X)]2 ¤ 1
               = E(X2) ¡ [E(X)]2

The discrete case progresses similarly. From Corollary 4.6.2:

                        ¸

Var(X) = (x ¡ E(x))2 ¤ Pr(X = x)

     x

      ¸

= x2 ¡ 2 ¤ E(x) + [E(X)]2 ¤ Pr(X = x)

               x
               ¸                                ¸                                                  ¸
= x2 ¤ Pr(X = x) ¡ 2 ¤ E(X) ¤ xPr(X = x) + [E(X)]2 Pr(X = x)

               x                                x                                                  x

By the definition of E(X), Definition 4.5.1:

                                                                                          ¸

= E(X2) ¡ 2 ¤ E(X) ¤ E(X) + [E(X)]2 Pr(X = x)

                                                                    x

By the definition of a PDF, Definition 4.2.1,

= E(X2) ¡ 2 ¤ E(X) ¤ E(X) + [E(X)]2 ¤ 1
= E(X2) ¡ [E(X)]2

Example 4.6.6

Suppose X is a continuous random variable with probability density function (PDF)

                                       5x       if 0 ¤ x ¤ 10

                          f (x) = 50            else
                                      0

We will calculate Var(X) two ways.

· To calculate Var(X), we first need to know E(X).

                          » V » 10 E(X) = x ¤ f (x)dx = x ¤ x dx
                                        ¡V                                    0 50

                                       » 10 x2       x3 §§10 103 20
                                    =           dx = §§ =                     =
                                        0 50         150 0 150 3

· Using Corollary 4.6.2,

» Var(X) = V » 10 (x ¡ E(x))2 ¤ f (x)dx = x ¡ 20 2 ¤ x dx
                  ¡V                                 0                        3 50

                  = x2 » 10 ¡ 40 x + 400 ¤ x dx = 1 x3 » 10 ¡ 40 x2 + 400 x dx                  3     9
                  0       3             9 50             50 0

                  =1      x4 40x3 200x2 §§10 1                                104 ¡ 40 ¤ 10 + 3 200 ¤ 102

                                                                           §
                          ¡+                         §=
                  50 4 9                    9 0 50 4                                         9        9

                  = 104   14 ¡ 49 + 29  = 509
                      50

                                                288
PROBABILITY                                 4.6 VARIANCE AND STANDARD DEVIATION

· Using Corollary 4.6.5,

               Var(X) = E(X2) ¡ [E(X)]2

                        = x2 » V ¤ f (x)dx ¡ 20 2 = x2 » 10 ¤ x dx ¡ 400
                          ¡V                3           0       50         9

                             x § 4 §§10 400 104 400 50

                        = §¡ = ¡ =
                          50 ¤ 4 0 9 200 9 9

                                                                        Example 4.6.6

Example 4.6.7

Calculate the variance (two ways) and standard deviation of a dice roll.
Solution. (Since we'll be evaluating sums, Theorem 3.1.6 comes in handy.)

    Let X be the random variable that takes on the number rolled. By Definition 4.5.1,

               E(X) = ¸ x 6 ¤ Pr(X = x) = 1 ¸ 6 x = 6 2 = 6 1 6 ¤ 7 72
                        x=1                 x=1

Using Corollary 4.6.2,

Var(X) = ( ¸ x ¡ E(X))2 ¤ Pr(X = x) = ¸ x 6 ¡ 7 2 ¤ 1
                                                  x=1 2 6
               x

               ¸ 6 = 1       x2 ¡ 7x + 494  = 1 ¸ 6 x 6 2 ¡ 7 ¸ 6 x + 6 1 ¸ 6 49 6 4
                       6                      x=1          x=1        x=1
               x=1
               = 1 6 ¤ 7 ¤ 13 6 6 ¡ 7 7 ¤ 6 6 2 + 494

               = 3512

Using Corollary 4.6.5 to calculate a second way,

               Var(X) = E(X2) ¡ E(X) 2 = ¸ x 6 2 ¤ Pr(X = x) ¡ 7 2 2

                                                                   x=1

               = ¸ 6 x 6 1 2 ¡ 494 = 16     6 ¤ 7 ¤ 13  ¡ 494 = 3512

                   x=1                          6

(Computing the variance two different ways is not usually necessary, but it can be a
good way to double-check your work.)
                                            
                               35
Using Definition 4.6.1, (X) = Var(X) = 12  1.7

                                                                        Example 4.6.7

                                      289
PROBABILITY                                   4.6 VARIANCE AND STANDARD DEVIATION

Example 4.6.8

A continuous random variable W has cumulative distribution function (CDF)

                                         6    x 0

                                 9 80         0 ¤ x ¤ ln 2
                                              x ¡ ln 2
                       F(x) = ex ¡ 1

                                 9 71

Calculate the variance and standard deviation of W. For practice, use both methods dis-
cussed in this section for computing variance.
Solution.

    We use the variance to calculate the standard deviation; we use expected value to
calculate variance; we use probability density function (PDF) to calculate expected value;
and we use cumulative distribution function (CDF) to define probability density function
(PDF). Working backwards, this gives us a plan for performing the necessary calculations.

               Step 1     Step 2              Step 3         Step 4
F(x) ÝÝÝÝÝÑ f (x) ÝÝÝÝÝÑ E(W) ÝÝÝÝÝÑ Var(W) ÝÝÝÝÝÑ (W)

Step 1 Definition 4.4.3 tells us the probability density function (PDF) is the derivative of
       the cumulative distribution function (CDF).

                                            6  x 0

                                    9 80       0 ¤ x ¤ ln 2
                                               x ¡ ln 2
                          F(x) = ex ¡ 1

                                    9 71

                                           6  x 0

                                   9 80       0 x ln 2
                          f (x) = ex
                                              x ¡ ln 2
                                   9 70

                                     5ex 0 x ln 2
                                  = 0 else

Step 2 Using Definition 4.5.1

              » (W) = V x ¤ f (x)dx

                   E

                           ¡V

                                          » ln 2

                  = x ¤ exdx
                                            0

       We use integration by parts with u = x, dv = exdx; du = dx, v = ex

               = xex ln 2 » ¡ ln 2 exdx = 2 ln 2 ¡ [2 ¡ 1] = 2 ln 2 ¡ 1  0.39
                       0       0

We can do a quick reliability check using Theorems 4.5.7 and 4.5.8. Our variable W
spends its entire life between 0 and ln 2  0.69, so we expect E(W) to be in that same
interval, which is true. Since f (x) is increasing on the relevant interval, W spends
                                                                     ¡  ln 2  
more time near the larger numbers, so we also expect E(W)                2      0.35.  This
accords with our calculation.

                                  290
PROBABILITY                        4.6 VARIANCE AND STANDARD DEVIATION

Step 3 We'll be using the constant E(W) = 2 ln 2 ¡ 1 a lot in the calculations below, so

       we'll use logarithm rules to write it more compactly:

                2 ln 2 ¡ 1 = ln(22) ¡ ln e = ln 4 ¡ ln e = ln(4/e)

The benefit of this equivalent expression is that when we square it, there are no
binomials to expand. (It is of course perfectly possible to do the computations with

2 ln 2 ¡ 1.)

Using Corollary 4.6.2,

                »V                              » ln 2
             Var(W) = (x ¡ E(W))2 ¤ f (x)dx = (x ¡ ln(4/e))2 ¤ exdx
                ¡V                              0

                » ln 2       x2 ¡ 2x ln(4/e) + ln2(4/e) exdx

             =  0

                » ln 2                  » ln 2                      » ln 2
             = x2exdx ¡ 2 ln(4/e) x ¤ exdx + ln2(4/e) exdx
                0                       0                           0
                » ln 2
             = x2exdx ¡ 2 ln(4/e)E(W) + ln2(4/e)(2 ¡ 1)
                0

We'll use integration by parts on the remaining integral: u = x2, dv = exdx; du =
2xdx, v = ex

             = x2ex ln 2 » ¡ ln 2 2x ¤ exdx ¡ 2 ln2(4/e) + ln2(4/e)
                             0  0

             = 2 ln2 2 ¡ 2E(W) ¡ ln2(4/e)

             = 2 ln2 2 ¡ 2 ln(4/e) ¡ ln2(4/e)

To simplify, we'll revert the arguments of our logarithms to 2 ln 2 ¡ 1, rather than

ln(4/e).

             = 2 ln2 2 ¡ 2 2 ln 2 ¡ 1 ¡ 2 ln 2 ¡ 1 2
             = 2 ln2 2 ¡ 4 ln 2 + 2 ¡ 4 ln2 2 ¡ 4 ln 2 + 1

             = 1 ¡ 2 ln2 2  0.039

Using Corollary 4.6.5,

           Var(W) = E(W2) ¡ E(W) 2 = x2exdx ¡ (2 ln 2 ¡ 1)2 » ln 2
                                                                                  0

The integral was already computed in the work above.

                  = (2 ln2 2 ¡ 4 ln 2 + 2) ¡ (2 ln 2 ¡ 1)2
                  = 1 ¡ 2 ln2 2  0.039

Step 4 By Definition 4.6.1,

                                        

                   (W) = Var(W) = 1 ¡ 2 ln2 2  0.198

                                   291
PROBABILITY                                   4.6 VARIANCE AND STANDARD DEVIATION
                                                                                 Example 4.6.8

4.6.3  Checking your Standard Deviation Calculation

Corollary4.6.9.

Let a, b be real numbers with a   b and suppose a random variable X takes values
from the interval [a, b]. Then
                                 0 ¤ (X) ¤ b ¡ a 2

Proof.  First, consider what happens when we replace E(X) with   b+a        (the midpoint of the
sample space) in the definition of variance (Definition 4.6.1).   2

E X ¡ b + a 2 » b = x ¡ b + a 2 ¤ f (x)dx22
                   a

                       »b   x2 ¡ (b + a)x +   b+a 2              ¤ f (x)dx
                                                2
                   =

                         a

                   »b                         »b                 b+a        2» b
                   = x2 f (x)dx ¡ (b + a) x f (x)dx +              2
                   a                          a                                  f (x)dx
                   = E(X2) ¡ (b + a)E(X) + b + a 2 2
                                                                                a

                   = E(X2) ¡ [E(X)]2 + [E(X)]2 ¡ (b + a)E(X) + b + a 2 2

                   = E(X2) ¡ [E(X)]2 + E(X) ¡ b + a 2 2

                   ¥ E(X2) ¡ [E(X)]2 = Var(X)                                             (*)

Since X takes values in the interval [a, b]:

                                    a ¤X ¤ b

             ùñ a ¡ b + a 2 ¤X ¡ b + a 2 ¤ b ¡ b + a 2
             ùñ ¡b ¡ a ¤X ¡ b + a ¤ b ¡ a
                                 2            2      2
             ùñ 0 ¤ X ¡ b + a 2 2 ¤ b ¡ a 2 2

By Theorem 4.5.7,

                                 0 ¤ E X ¡ b + a 2 2 ¤ b ¡ a 2 2

                                    292
PROBABILITY  4.6 VARIANCE AND STANDARD DEVIATION

So, with our previous result (*),

                            Var(X) ¤ E X ¡ b + a 2 2 ¤ b ¡ a 2 2
           So, (X) ¤ b ¡ a 2

 Example 4.6.10

If the ran dom variable X takes on values from the interval [1, 5], then 0 ¤ (X) ¤ 2. Since
(X) = Var(X), then 0 ¤ Var(X) ¤ 4.

                                                                                                Example 4.6.10

    Chapter 4 contains content adapted by Bruno Belevan, Parham Hamidi, and Elyse
Yeager from Sections 1.1, 3.1, Ch 4 introduction, 4.1, and 4.2 of Introductory Statistics by
Ilowsky and Dean under a Creative Commons Attribution License v4.0.

             293
Chapter 5

           SEQUENCES AND SERIES

You have probably learned about Taylor polynomials1 and, in particular, that

           ex = 1 + x + x2! + 3! + 2 x3 ¤ ¤ ¤ + xn! + n En(x)

where En(x) is the error introduced when you approximate ex by its Taylor polynomial of
degree n. You may have even seen a formula for En(x). We are now going to ask what
happens as n goes to infinity? Does the error go zero, giving an exact formula for ex? We
shall later see that it does and that

           ex = 1 + x + x + + 2 x3 ¤ ¤ ¤ = ¸ V xn
           2! 3!  n=0 n!

At this point we haven't defined, or developed any understanding of, this infinite sum.
How do we compute the sum of an infinite number of terms? Indeed, when does a sum
of an infinite number of terms even make sense? Clearly we need to build up foundations
to deal with these ideas. Along the way we shall also see other functions for which the
corresponding error obeys lim En(x) = 0 for some values of x and not for other values of

                              nÑV

x.
    To motivate the next section, consider using the above formula with x = 1 to compute

the number e:

           e = 1 + 1 + 1 + 1 + ¤ ¤ ¤ = ¸ V 1
           2! 3!  n=0 n!

As we stated above, we don't yet understand what to make of this infinite number of
terms, but we might try to sneak up on it by thinking about what happens as we take

1 Now would be an excellent time to quickly read over your notes on the topic.

                                                         294
SEQUENCES AND SERIES                                                          5.1 SEQUENCES

more and more terms.                                      1=1
                  1 term                             1+1 = 2
                  2 terms                       1 + 1 + 12 = 2.5
                  3 terms                 1 + 1 + 1 + 1 = 2.666666 . . .
                  4 terms                            26
                  5 terms          1 + 1 + 12 + 16 + 124 = 2.708333 . . .
                  6 terms  1 + 1 + 1 + 1 + 1 + 1 = 2.716666 . . .
                                     2 6 24 120

By looking at the infinite sum in this way, we naturally obtain a sequence of numbers

             t 1 , 2 , 2.5 , 2.666666 , . . . , 2.708333 , . . . , 2.716666 , . . . , ¤ ¤ ¤ u.

The key to understanding the original infinite sum is to understand the behaviour of this
sequence of numbers -- in particularly, what do the numbers do as we go further and
further? Does it settle down 2 to a given limit?

5.1 Sequences

     In the discussion above we used the term "sequence" without giving it a precise mathe-
     matical meaning. Let us rectify this now.

Definition5.1.1.

A sequence is a list of infinitely3 many numbers with a specified order. It is
denoted
         2                    @           2@   2 @V
            a1, a2, a3, ¤ ¤ ¤ , an, ¤ ¤ ¤ or an or an n=1

We will often specify a sequence by writing it more explicitly, like

                           3              AV

                              an = f (n)  n=1

where f (n) is some function from the natural numbers to the real numbers.

2 You will notice a great deal of similarity between the results of the next section and "limits at infinity"
      which was covered last term.

3 For the more pedantic reader, here we mean a list of countably infinitely many numbers. The interested
      (pedantic or otherwise) reader should look up countable and uncountable sets.

                                                         295
SEQUENCES AND SERIES                                                   5.1 SEQUENCES

Example 5.1.2

Here are three sequences.

1, 2, 3, 3 1 1 ¤ ¤ ¤ , 1n , ¤ ¤ ¤ A                 3 or an = 1 AV

                                                                           n n=1

3  1, 2, 3, ¤ ¤ ¤ , n, ¤ ¤ ¤  A                         3          AV

                                                    or     an = n  n=1

1, 3 ¡1, 1, ¡1, ¤ ¤ ¤ , (¡1)n¡1, ¤ ¤ ¤ or an = ( A 3 ¡1)n¡1AV

                                                                                                                      n=1

It is not necessary that there be a simple explicit formula for the nth term of a sequence.
For example the decimal digits of  is a perfectly good sequence

23, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9, 3, 2, 3, 8, 4, 6, 2, 6, 4, 3, 3, 8, ¤ ¤ ¤ @

but there is no simple formula4 for the nth digit.

                                                                   Example 5.1.2

Our primary concern with sequences will be the behaviour of an as n tends to infinity and,
in particular, whether or not an "settles down" to some value as n tends to infinity.

 Definition5.1.3.

             2 @V

A sequence an n=1 is said to converge to the limit A if an approaches A as n
tends to infinity. If so, we write

                 lim an = A or an Ñ A as n Ñ V

                      nÑV

A sequence is said to converge if it converges to some limit. Otherwise it is said
to diverge.

The reader should immediately recognise the similarity with limits at infinity

                 lim f (x) = L if f (x) Ñ L as x Ñ V

                     xÑV

Example 5.1.4

Three of the four sequences in Example 5.1.2 diverge:

               2              @V
· The sequence an = n n=1 diverges because an grows without bound, rather than
approaching some finite value, as n tends to infinity.

4 There is, however, a remarkable result due to Bailey, Borwein and Plouffe that can be used to compute
      the nth binary digit of  (i.e. writing  in base 2 rather than base 10) without having to work out the
      preceding digits.

                                                         296
SEQUENCES AND SERIES                                                                                5.1 SEQUENCES

                             2        n¡1@V
    · The sequence an = (¡1) n=1 diverges because an oscillates between +1 and ¡1
       rather than approaching a singe value as n tends to infinity.

    · The sequence of the decimal digits of  also diverges, though the proof that this is
       the case is a bit beyond us right now5.

The  other      sequence     in  Example  5.1.2  has   an  =  1.  As    n  tends  to  infinity,  1  tends  to   zero.  So
                                                                                                 n
                                                              n

                                                    lim 1 = 0

                                                    nÑV n

                                                                                                    Example 5.1.4

Example 5.1.5            lim n

                                2n+1
                         nÑV

Here   is  a  little  less   trivial  example.  To  study   the   behaviour       of    n   as  n   Ñ  V,  it  is  a  good
idea to write it as                                                                   2n+1

                                                    n             1
                                                 2n + 1 = 2 + 1
                                                                     n

As  n  Ñ   V,   the   1  in  the  denominator    tends  to  zero,    so    that  the  denominator      2  +  1  tends  to
           1          n      1.                                                                              n
2 and           tends to         So
             1               2
       2+ n

                                      lim n = lim 1 1 = 1

                                      nÑV 2n + 1 nÑV 2 + n 2

                                                                                                Example 5.1.5
Notice that in this last example, we are really using techniques that we used before to
study infinite limits like lim f (x). This experience can be easily transferred to dealing

                            xÑV

with lim an limits by using the following result.

     nÑV

      Theorem5.1.6.

     If
                                                lim f (x) = L

                                          xÑV

     and if an = f (n) for all positive integers n, then

                                                 lim an = L

                                           nÑV

5 If the digits of  were to converge, then  would have to be a rational number. The irrationality of 
      (that it cannot be written as a fraction) was first proved by Lambert in 1761. Niven's 1947 proof is more
      accessible and we invite the interested reader to use their favourite search engine to find step-by-step
      guides to that proof.

                                                         297
SEQUENCES AND SERIES                                                                5.1 SEQUENCES

 Example 5.1.7 lim e¡n                   we know that                     lim e¡n = 0
                   nÑV                                                    nÑV

Set f (x) = e¡x. Then e¡n = f (n) and

            since lim e¡x = 0
                  xÑV

                                                                          Example 5.1.7

The bulk of the rules for the arithmetic of limits of functions that you already know also
apply to the limits of sequences. That is, the rules you learned to work with limits such as
lim f (x) also apply to limits like lim an.
xÑV                   nÑV

     Theorem5.1.8 (Arithmetic of limits).

                                                             2 @V         2 @V
     Let A, B and C be real numbers and let the two sequences an n=1 and bn n=1
     converge to A and B respectively. That is, assume that

                             lim an = A      lim bn = B

                          nÑV                nÑV

     Then the following limits hold.

     (a) lim an + bn = A + B

         nÑV

          (The limit of the sum is the sum of the limits.)

     (b) lim an ¡ bn = A ¡ B

         nÑV

          (The limit of the difference is the difference of the limits.)

     (c) lim Can = CA.

         nÑV

     (d) lim an bn = A B

         nÑV

          (The limit of the product is the product of the limits.)

     (e) If B $ 0 then lim an = A

                        nÑV bn B

          (The limit of the quotient is the quotient of the limits provided the limit of the
          denominator is not zero.)

    We use these rules to evaluate limits of more complicated sequences in terms of the
limits of simpler sequences -- just as we did for limits of functions.

 Example 5.1.9

                                                         298
SEQUENCES AND SERIES                                                                         5.1 SEQUENCES

Combining Examples 5.1.5 and 5.1.7,                                               by Theorem 5.1.8.a
                                                                                  by Theorem 5.1.8.c
    lim n + 7e¡n = lim n + lim 7e¡n                                    by Examples 5.1.5 and 5.1.7
    nÑV 2n + 1             nÑV 2n + 1 nÑV
                           = lim n + 7 lim e¡n                                             Example 5.1.9
                           nÑV 2n + 1 nÑV
                           = 12 + 7 ¤ 0
                           =1
                             2

    There is also a Squeeze Theorem for sequences.

      Theorem5.1.10 (Squeeze Theorem).

    If an ¤ cn ¤ bn for all natural numbers n, and if

                                           lim an = lim bn = L

                                      nÑV nÑV

     then
                                                  lim cn = L

                                           nÑV

Example 5.1.11

In this example we use the Squeeze Theorem to evaluate

                                            lim 1 + n
                                            nÑV          n

where n is the nth decimal digit of . That is,

                  1 = 3 2 = 1 3 = 4 4 = 1 5 = 5 6 = 9 ¤ ¤ ¤

We do not have a simple formula for n. But we do know that

                  0 ¤ n ¤ 9 ùñ 0 ¤ n n ¤ 9n ùñ 1 ¤ 1 + n n ¤ 1 + 9n

and we also know that

                           lim 1 = 1               lim 1 + 9 = 1

                           nÑV                     nÑV n

So  the  Squeeze  Theorem  with  an  =  1,  bn  =  1  +  n ,  and  cn  =  1  +  9  gives
                                                                                n
                                                         n

                                        lim 1 + n = 1
                                        nÑV           n

                                                   299
SEQUENCES AND SERIES                                                                      5.1 SEQUENCES

                                                                                                Example 5.1.11

    Finally, recall that we can compute the limit of the composition of two functions using
continuity. In the same way, we have the following result:

      Theorem5.1.12 (Continuous functions of limits).
     If lim an = L and if the function g(x) is continuous at L, then

       nÑV

                                              lim g(an) = g(L)

                                       nÑV

Example 5.1.13          lim sin n

                                     2n+1
                        nÑV

Write  sin   n    =  g    n   with g(x) = sin(x). We saw, in Example 5.1.5 that
            2n+1        2n+1

                                           lim n = 1

                                           nÑV 2n + 1 2

Since  g(x)  =  sin(x)  is    continuous   at  x  =  1,  which  is  the  limit  of    n,  we  have

                                                     2                              2n+1

                     lim sin n = lim g n = g 1 = sin  = 1
                     nÑV 2n + 1 nÑV 2n + 1                          2               2

                                                                                          Example 5.1.13

5.1.1  Geometric and harmonic sequences in musical scales

       Lists of numbers don't always get added together6, so sequences (that are not worked into
       series) can be interesting in their own right. We present here an application of sequences
       to music theory.

           First, some musical preliminaries. Sound is caused by waves, and the frequency of a
       sound wave determines its pitch - how high or low it sounds. Higher frequencies lead to
       higher pitches, so the sound wave made by the chirp of a sparrow has a higher frequency
       than the sound wave made by the growl of a dog. We measure frequency in Hz (Hertz),
       which corresponds to periods per second. We often leave out the units, so you might see a
       frequency referred to as "100" instead of "100 Hz." We'll picture the waves like the graph
       of a sine function, although this is not how they would actually appear.

           We'll use the word "note" to mean a specified pitch. For example, the note named A4
       usually corresponds to a frequency of 440 Hz. An interval is the "distance" between two
       notes, quantified as the ratio of their frequencies. The way we perceive the "distance"

        6 or they do but they shouldn't be, e.g. this amusing sign

                                                                300
SEQUENCES AND SERIES                                          5.1 SEQUENCES

between two notes relies on the ratio of their two frequencies, which is why we use a ratio
and not a difference when measuring intervals.

 Example 5.1.14
Consider the three pairs of notes below. Which pairs will sound roughly the same distance
from each other, and which will sound different?

   1. 110 Hz and 193.25 Hz
   2. 440 Hz and 523.25 Hz
   3. 587.33 Hz and 698.46 Hz

Solution. To quantify how far apart two notes sound, we take the ratio of their frequencies.

1  110 Hz and 193.25 Hz have a ratio of  193.25   1.75682
                                          110

2  440 Hz and 523.25 Hz have a ratio of  523.25   1.18920
                                          440

3  587.33 Hz and 698.46 Hz have a ratio of  698.46   1.18921
                                            587.33

The last two pairs of notes sound about the same distance away from one another, because
their ratios are nearly identical. The first pair of notes will sound farther apart from one
another than the other pairs.

    Incidentally, the interval spanned in 2 and 3 has a name: a minor third. For listeners in
the Western tradition, the sound of two notes of such an interval being played together is
often evocative of a melancholy or enigmatic mood.

                                                                                                Example 5.1.14

    A scale is a collection of notes. There are many different scales that are used, and
many more that are theoretically possible. Scales in context usually refer to the collection
of notes that make up most of a single piece of music. So, one song might mainly consist of
notes from a scale named "B Minor," and another song might mainly consist of notes from
a scale named "G major pentatonic." Generally speaking7, standardized scales consist of
notes that people have decided they like hearing played together.

 Example 5.1.15
The interval between some frequency a and the frequency 2a is called an octave. Some
popular musical scales divide the octave into twelve intervals. (In the partial piano schematic
below, the key labelled 13 would produce a note with twice the frequency of the key la-
belled 1.)

7 Precision in describing the things that people do is much harder to attain than precision in mathematics.

                                                         301
SEQUENCES AND SERIES                                                                                      5.1 SEQUENCES

                    2                     57                                                       10 12
                 13                    468                                                       9 11 13

    We call a scale "even-tempered" if consecutive notes always sound like they're the
same distance apart from one another. Since the sound of notes in relation to each other
is determined by the ratio of their frequencies, this means means that the ratio of the
frequencies of two consecutive notes is the same, no matter which two consecutive notes
we're considering.

    Suppose the key labelled 1 makes the note 440Hz, and the key labelled 13 makes the
note 880 Hz (one octave above 440). If the piano is tuned to an even-tempered scale, what
are the frequencies associated with the keys labelled 2 through 12?
Solution.

    Let the notes on the piano form the first part8 of a sequence, with key 1 making note
a1, key 2 making note a2, and so on. We know three pieces of information:

   1. a1 = 440

2. a13 = 880

3. a2 = a3 = a4 = ¤ ¤ ¤ = a13
       a1 a2 a3                  a12

(3 comes from the description of even-tempering.) Let's give the number aa21 the name r
(because it's a ratio). This gives us a recurrence relation to describe our partial sequence:
since  an+1     r, then an+1     ran.  We can now write out each element of the partial sequence
        an   =                =

in terms of r.

                                        a1 = 440
                                        a2 = 440r
                                        a3 = (440r)r = 440r2
                                        a4 = (440r2)r = 440r3

                                          ..
                                          .

                                       a12 = 440r11
                                       a13 = 440r12

Since we're given a13 = 880, we can solve for r.
                                          880 = 440r12

                                                                                              1

                                             r = 2 12

8 we defined sequences to be infinite, but pianos have only finitely many keys

                                       302
SEQUENCES AND SERIES                                                                             5.1 SEQUENCES

Now, we can write down each note frequency.

1. 440                        5. 440 ¤ 24/12  554.365         9. 440 ¤ 28/12  698.456
                              6. 440 ¤ 25/12  587.330         10. 440 ¤ 22/12  739.989
2. 440 ¤ 21/12  466.163       7.440 ¤ 26/12  622.254          11. 440 ¤ 210/12  783.991
3.440 ¤ 22/12  493.883        8.440 ¤ 27/12  659.255          12. 440 ¤ 211/12  830.609
4. 440 ¤ 21/12  523.251

                                                                                                 Example 5.1.15

    When we say "the interval between consecutive notes is the same," we mean "the ratio
between consecutive notes is the same." Having a common ratio between consecutive
terms is the defining characteristic of a geometric sequence.

Definition5.1.16.

A geometric sequence is a sequence of the form

                  a, ar, ar 3 2, ¤ ¤ ¤ , arn, ¤ ¤ ¤ or an = ar A 3 nAV

                                                                                            n=1

where a and r are any two fixed real numbers with a $ 0.

Note  an+1  =  r  for  every  whole  number  n.  We  call  r  the  common  ratio.
       an

    (If we were to "add up" the terms of a geometric sequences, we'd get a geometric series
- see Example 5.2.4.)

    When a tone is made by a vibrating physical9 object, although we may primarily pick
up on one frequency (the "fundamental"), usually waves of many different frequencies
are being generated. If we make a tone by causing a string to vibrate, as on a violin or
guitar, the waves that make noise have frequencies that are whole-number multiples of
the fundamental frequency. To explain this behaviour, note that the ends of the string are
fixed, so they can't move up and down. So, the only waves that can occur on the string
are waves that keep these points fixed. The fundamental is the longest wave. The other
waves that are generated are called harmonics. The nth harmonic has frequency n times
the fundamental.

fundamental                          second harmonic                                             third harmonic

9 For the following "physical" discussion, we're relying on a very simplified model. However, the results
      are indeed relevant to how actual musical instruments sound.

                                                         303
SEQUENCES AND SERIES                                                                        5.1 SEQUENCES

    In the figure above, a string10 is fixed between two dots. We imagine it vibrating up
and down in a wave pattern, moving between the positions shown by the dashed and
dotted lines. The wavelength of these waves is inversely proportional to the frequency
they generate - so dividing a wavelength by (say) three causes the frequency to triple.

 Example 5.1.17

A string, when played, has a fundamental tone of 100 Hz, with a wavelength of 1 m. Let

t fnu be the sequence of frequencies of the harmonics of the string, organized by increasing
pitch (with f1 = 100). Let tnu be the sequence of corresponding wavelengths (so 1 = 1).
What are tnu and t fnu?

Solution. The frequencies of harmonic tones are integer multiples of the fundamental, so

                    f1 = 100, f2 = 200, f3 = 300, . . . , fn = 100n

The wavelengths are inversely proportional to the frequencies. So, if frequency fn is f1 ¤ n,
                            1 .
then  wavelength    n   is
                            n

                            1 = 1, 2 = 12 , 3 = 13 , . . . , n = 1n

                                                                                         Example 5.1.17

The       sequence  t 1 uV       is called the harmonic sequence.       (We'll consider the harmonic

                      n n=1
series in Example 5.3.4.) In music textbooks, you might see the sequence of harmonic
notes referred to as the "harmonic series." This isn't because the notes are added together,
it's simply a different use of the word "series."

Example 5.1.18

Consider an even-tempered musical scale with twelve intervals in each octave, the lowest
note of which is 250 Hz.

    Suppose we have a string whose fundamental tone is 250 Hz. Which harmonics of the
string are also notes of the even-tempered scale?

Solution.
The even-tempered musical scale is given by the geometric sequence ten = a ¤ rnuVn=0
                                 1                                                  thn     250nuVn=1.
where  a   =  250  and  r  =          The  harmonic  sequence  of  the  string  is       =
                              2 12 .
All frequencies in the harmonic sequence are integer multiples of 250, and so are whole
numbers. The only whole numbers in the geometric sequence en occur when 2 is raised
to a whole-number powers, i.e. when n is a multiple of 12. So our only candidates for
frequencies that appear in both sequences have the form 250 ¤ 2k. It's quick to see that
these occur in both: 250 ¤ 2k = gn when n = 12k, and 250 ¤ 2k = hn when n = 2k.
So, the only intervals from the even-tempered scale that perfectly line up with the nat-
ural harmonics of the string are octaves: the fundamental, twice the fundamental, twice
that frequency, etc.

10 Similar wave behaviour occurs in tubes of air, like you might find in a brass instrument or woodwind.
      Brass players can emphasize different harmonic notes by changing they way they blow into their in-
      strument.

                                                     304
SEQUENCES AND SERIES                                                    5.2 SERIES

                                                                        Example 5.1.18

    Harmonics are produced naturally, so it's nice if they're "in tune" with the scale notes.
The dearth of overlap between harmonic and geometric sequences is one reason that even-
tempered scales are sometimes unpopular. However, many harmonic notes are approxi-

                                                                                                                                    19

mated by the even-tempered scale above. For example, 2 12  2.9966  3, so g19 is a fair

approximation to e3.
 Example 5.1.19

Suppose we were to make a scale that consisted only of harmonics. The frequencies would

make up the sequence thn = anuVn=1, where a is the fundamental.

    How would such a scale sound if we played the notes one after the other? Remember,
the way two notes sound depends on the ratio of their frequencies. A bigger ratio sounds

like a bigger "step" from one note to the next. So, let's define a sequencetrnuVn=2 to be the

ratio of the nth harmonic to the note before it. A value of rn that is close to 1 means the
two notes sound the same. A value of rn that is far from 1 means the two notes sound
different.

                        frequency: a 2a 3a 4a 5a 6a 7a ¤ ¤ ¤ na
                        ratio:  2 3 4 5 6 7 ¤¤¤ n
                                23476                              n¡1

The sequences hn and rn have different limits, each with a musical interpretation.

· lim hn = V tells us that the notes of this sequence have no upper bound. We can

  nÑV

   find notes as high as we please in this scale.

   · lim rn = 1 tells us that notes of the scale sound more and more alike as we go higher.

      nÑV

    The picture painted by these two limits is that the scale climbs higher and higher,
but does so in tiny increments, so that many different high-pitched notes are virtually
indistinguishable from one another. (On the other hand, the first step is huge: an entire
octave!)

                                                                                                Example 5.1.19

    With this introduction to sequences and some tools to determine their limits, we can
now return to the problem of understanding infinite sums.

    The content of Section 5.1.1 is original, but the authors would like to acknowledge
the open textbook used for fact-checking: Catherine Schmidt-Jones, Sound, Physics and
Music. OpenStax CNX. Mar. 27, 2013
http://cnx.org/contents/18e41aa3-0133-4bd1-84ae-2975f4d0ddaf.

5.2 Series

     A series is a sum

                                a1 + a2 + a3 + ¤ ¤ ¤ + an + ¤ ¤ ¤

                                               305
SEQUENCES AND SERIES                                                                   5.2 SERIES

of infinitely many terms. In summation notation, it is written

                                               ¸ V

                                                   an

                                               n=1

You already have a lot of experience with series, though you might not realise it. When
you write a number using its decimal expansion you are really expressing it as a series.
Perhaps  the  simplest  example  of  this  is  the  decimal   expansion    of  1:

                                                                               3

                                           13 = 0.3333 ¤ ¤ ¤

Recall that the expansion written in this way actually means

              0.333333 ¤ ¤ ¤ = 310 + 3 100 + 3 1000 + 3 10000 + ¤ ¤ ¤ = n=1 10n ¸ V 3

The summation index n is of course a dummy index. You can use any symbol you like
(within reason) for the summation index.

                        ¸ V 3 ¸ V 3 ¸ V 3 ¸ V 3

                        n=1 10n = i=1 10i = j=1 10j = =1 10

A series can be expressed using summation notation in many different ways. For example
the following expressions all represent the same series:

                                          hkkni =1kkj hkkni =2kkj hkkni =3kkj

                        10n = 10 + 100 + 1000 + ¸ V 3 3 3 3 ¤ ¤ ¤

                        n=1

                                             j=2           j=3      j=4

                                           hkkikkj       hkkikkj  hkkikkj
                        10j¡1 = 10 + 100 + 1000 + ¸ V 3 3 3 3 ¤ ¤ ¤
                        j=2

                                                   hkki =0kkj hkki =1kkj hkki =3kkj

                           10+1 = 10 + 100 + 1000 + ¸ V 3 3 3 3 ¤ ¤ ¤

                             =0
                                                            hkkni =2kkj hkkni =3kkj

                        310 + 10n = 10 + 100 + 1000 + ¸ V 3 3 3 3 ¤ ¤ ¤

                                 n=2

We can get from the first line to the second line by substituting n = j ¡ 1 -- don't forget to
also change the limits of summation (so that n = 1 becomes j ¡ 1 = 1 which is rewritten

as j = 2). To get from the first line to the third line, substitute n =  + 1 everywhere,
including in the limits of summation (so that n = 1 becomes  + 1 = 1 which is rewritten
as  = 0).

    Whenever you are in doubt as to what series a summation notation expression repre-
sents, it is a good habit to write out the first few terms, just as we did above.

                                                    306
SEQUENCES AND SERIES                                                                                           5.2 SERIES

    Of course, at this point, it is not clear whether the sum of infinitely many terms adds up
to a finite number or not. In order to make sense of this we will recast the problem in terms
of the convergence of sequences (hence the discussion of the previous section). Before we
proceed more formally let us illustrate the basic idea with a few simple examples.

Example 5.2.1              ¸ V 3

                           n=1 10n

                                          °V 3

As we have just seen above the series n=1 10n is

                                                        hkkni =1kkj hkkni =2kkj hkkni =3kkj

                                      10n = 10 + 100 + 1000 + ¸ V 3 3 3 3 ¤ ¤ ¤

                                      n=1

Notice that the nth term in that sum is

                                                   nh¡k1ki zekrkojes

                             3 ¢ 10¡n = 0. 00 ¤ ¤ ¤ 0 3

So the sum of the first 5, 10, 15 and 20 terms in that series are

            ¸ 5 3 = 0.33333                                    ¸ 10 3 = 0.3333333333
            n=1 10n                                            n=1 10n
            ¸ 15 3 = 0.333333333333333                         ¸ 20 3 = 0.33333333333333333333
            n=1 10n                                            n=1 10n

It  sure    looks  like    that,  as  we  add  more    and  more   terms,  we  get  closer       and   closer  to  0.3  =  1.
                                                  °V       3           1.
So  it  is  very   reasonable11       to  define          10n  to  be                                                      3
                                                     n=1               3

                                                                                                       Example 5.2.1

                           ¸ V            ¸ V
Example 5.2.2                   1 and (¡1)n

                           n=1            n=1

                                      °V
Every term in the series n=1 1 is exactly 1. So the sum of the first N terms is exactly N.
As  we      add  more      and    more    terms  this  grows   unboundedly.    So   it       is  very  reasonable  to   say
                         V    1   diverges.
                        °
that the series          n=1
    The series

                   V                      hkkni =1kkj hkkni =2kkj hkkni =3kkj hkkni =4kkj hkkni =5kkj
                   ¸
                           (¡1)n = (¡1) + 1 + (¡1) + 1 + (¡1) + ¤ ¤ ¤

                   n=1

So the sum of the first N terms is 0 if N is even and ¡1 if N is odd. As we add more and
more terms from the series, the sum alternates between 0 and ¡1 for ever and ever. So the

11 Of course we are free to define the series to be whatever we want. The hard part is defining it to be
      something that makes sense and doesn't lead to contradictions. We'll get to a more systematic definition
      shortly.

                                                            307
SEQUENCES AND SERIES                                                                                            5.2 SERIES

sum of all infin° itely many terms does not make any sense and it is again reasonable to say

that the series Vn=1(¡1)n diverges.

                                                                                                Example 5.2.2

In the above examples we have tried to understand the series by examining the sum
of the first few terms and then extrapolating as we add in more and more terms. That is,
we tried to sneak up on the infinite sum by looking at the limit of (partial) sums of the
first few terms. This approach can be made into a mor° e formal rigorous definition. More
precisely, to define what is meant by the infinite sum              V    an,  we                      approximate  it  by  the

                                                                    n=1
sum of its first N terms and then take the limit as N tends to infinity.

Definition5.2.3.

The  Nth  partial  sum   of  the  series  °V      an  is  the  sum  of  its  first                    N  terms

                                             n=1

                                                                       ¸ N

                                           SN = an.

                                                                    n=1

                                        2 @V

The partial sums form a sequence SN N=1. If this sequence of partial sums

                                                               °V

converges SN Ñ S as N Ñ V then we say that the series n=1 an converges to S

¸ and we write V

                                                 an = S

                                                           n=1

If the sequence of partial sums diverges, we say that the series diverges.

5.2.1  Geometric Series

Example 5.2.4 (Geometric Series)

Let a and r be any two fixed real numbers with a $ 0. The series

                                                               ¸ V

                      a + ar + ar2 + ¤ ¤ ¤ + arn + ¤ ¤ ¤ = arn

                                                                                                 n=0

is called the geometric series with first term a and ratio r.
Notice that we have chosen to start the summation index at n = 0. That's fine. The
first12 term is the n = 0 term, which is ar0 = a. The second term i° s the n = 1 term,
which is ar1 = ar. And so on. We could have als§o written the series                                     V arn¡1.      That's

                                                                                                         n=1
exactly the same series -- the first term is arn¡1§n=1 = ar1¡1 = a, the second term is

12 It is actually quite common in computer science to think of 0 as the first integer. In that context, the set
      of natural numbers is defined to contain 0:

                                      N = t0, 1, 2, . . . u

                                                  308
SEQUENCES AND SERIES                                                            5.2 SERIES

arn¡1§n=2 § = ar2¡1 = ar, and so on13. Regardless of how we write the geometric series, a is

the first term and r is the ratio between successive terms.
    Geometric series have the extremely useful property that there is a very simple formula

for their partial sums. Denote the partial sum by

                                                        ¸ N

                      SN = arn = a + ar + ar2 + ¤ ¤ ¤ + arN.

                                                     n=0

The secret to evaluating this sum is to see what happens when we multiply it r:

                rSN = r a + ar + ar2 + ¤ ¤ ¤ + arN
                   = ar + ar2 + ar3 + ¤ ¤ ¤ + arN+1

Notice that this is almost the same14 as SN. The only differences are that the first term, a,
is missing and one additional term, arN+1, has been tacked on the end. So

                      SN = a + ar + ar2 + ¤ ¤ ¤ + arN
                      rSN = ar + ar2 + ¤ ¤ ¤ + arN + arN+1

Hence taking the difference of these expressions cancels almost all the terms:

                (1 ¡ r)SN = a ¡ arN+1 = a(1 ¡ rN+1)

Provided r $ 1 we can divide both side by 1 ¡ r to isolate SN:

                         SN = a ¤ 1 ¡ rN+1 .
                                  1¡r

On the other hand, if r = 1, then

                      SN = ¤ ¤ ¤ lao+ooooaooo+mooooo+ooona = a(N + 1)

                                     N+1 terms

So in summary:              8 6 1¡rN+1
                              a 1¡r
                                              if r $ 1                           (5.2.1)
                      SN =
                             7a(N + 1)        if r = 1

      while the notation

                                      Z+ = t1, 2, 3, . . . u

      is used to denote the (strictly) positive integers. Remember that in this text, as is more standard in
      mathematics, we define the set of natural numbers to be the set of (strictly) positive integers.
13 This reminds the authors of the paradox of Hilbert's hotel. The hotel with an infinite number of rooms
      is completely full, but can always accommodate one more guest. The interested reader should use their
      favourite search engine to find more information on this.
14 One can find similar properties of other special series, that allow us, with some work, to cancel many
      terms in the partial sums. We will shortly see a good example of this. The interested reader should look
      up "creative telescoping" to see how this idea might be used more generally, though it is somewhat
      beyond this course.

                                                         309
SEQUENCES AND SERIES                                                                             5.2 SERIES

Now that we have this expression we can determine whether or not the series con-
verges. If |r|  1,  then  rN+1  tends  to  zero  as  N  Ñ  V,  so  that  SN  converges  to   a   as  N  Ñ  V

                                                                                            1¡r
¸ and V arn = a provided |r| 1. (5.2.2)
                                n=0 1 ¡ r

On the other hand if |r| ¥ 1, SN diverges. To understand this divergence, consider the

following 4 cases:

· If r ¡ 1, then rN grows to V as N Ñ V.

· If r ¡1, then the magnitude of rN grows to V, and the sign of rN oscillates between
  + and ¡, as N Ñ V.

· If r = +1, then N + 1 grows to V as N Ñ V.

· If r = ¡1, then rN just oscillates between +1 and ¡1 as N Ñ V.

In each case the sequence of partial sums does not converge and so the series does not
converge.

                                                                                                Example 5.2.4

Equations 5.2.1 and 5.2.2 are worth stating as a theorem.

Theorem5.2.5 (Geometric Series and Partial Sums).

Let a and r be fixed real numbers, and let N be a positive integer. Then

                                ¸ N n        8 6 1¡rN+1        if r $ 1
                                       ar =
                                              a ¤ 1¡r          if r = 1

                                n=0          7a(N + 1)

¸ and V arn = a provided |r| 1.
                     n=0 1 ¡ r

                                      °V n

If |r| ¥ 1 and a $ 0, then the series n=0 ar diverges.

 Example 5.2.6 (Bitcoin Supply)
Bitcoin is a virtual currency that mimics traditional currencies in a number of ways. One
of those ways is controlled supply15. That is, new bitcoins enter circulation over time in a
controlled manner.

15 Source for the specifics in this example: Controlled Supply, Bitcoin Wiki, url https://en.bitcoin.
      it/wiki/Controlled_supply accessed 16 Aug 2020

                                                         310
SEQUENCES AND SERIES                                                                        5.2 SERIES

    New blocks16 are searched for by computers. When a block is found, it is converted
into a set number of new bitcoins (owned by the finder). This is the reward for finding a
block.

    This process is analogous to mining precious metals which then are added to the cur-
rency supply, so the process of finding new blocks is often called mining. Importantly,
the bitcoins given in the reward are new bitcoins that did not exist before the block was
found. So, finding blocks is how bitcoins are created.

    The reward for finding a block started at 50 bitcoins, but it halves every 210,000 blocks.
The miners who found block 0, block 1, and block 209,999 each got a reward of 50 bitcoins.
Then, the miners who found block 210,000 through block 419,999 each got a reward of 25
bitcoins, and so on.

    For the purposes of this example, we will assume that miners will always be able to
find blocks. (That is, blocks never run out.) We will also assume that rewards for finding
blocks are the only ways bitcoins are ever created, and that bitcoins are never destroyed.
(a) Suppose bitcoins are infinitely divisible. (That is, you can have an arbitrarily small

     portion of a bitcoin, such as one-trillionth of a bitcoin, without a limit on how small
     that portion can be.) If miners continue finding blocks for an infinite period of time,
     what will happen to the total supply of bitcoins?
(b) One Satoshi (or one sat) is equal to 1/100, 000, 000 bitcoin. Suppose when the reward
     for a block is scheduled to be less than one satoshi, the block finder actually gets a
     reward of 0 bitcoins. That is, there are no more bitcoins created when the reward for
     finding a new block dips below one satoshi. If miners continue finding blocks for an
     infinite period of time, what will happen to the total supply of bitcoins?

Solution.

(a) Let's model the number of bitcoins by grouping together collections of 210,000 blocks.

· For the first collection of 210,000 blocks, the number of bitcoins created is 50 each,

  for a total of 210, 000 ¤ 50 bitcoins created.

·          For the second collection of 210,000 blocks, the number of bitcoins created is   50  =
                                                     ¤  50                                  2
           25  each,  for  a  total  of   210,  000     2   bitcoins  created.

·          For the third collection of 210,000 blocks, the number of bitcoins created is    50  =
           25                                                 ¤  50                         4
           2      12.5  each,  for   a  total   of  210, 000     4   bitcoins   created.
               =

· In general, for the nth collection of 210,000 blocks, the total number of bitcoins
           created  by  those  blocks     is    210, 000 ¤   50      bitcoins.

                                                            2n¡1

· All together, the number of bitcoins created by an infinite collection of blocks is

                                     ¸ V                50                      ¸ V  1 n¡1
                                          210, 000 ¤ n¡1 = 210, 000 ¤ 50
                               n=1 2                                            n=1 2

16 For the purposes of this question, the technical details are not important. What you need to know about
      blocks is that you find them and they get turned into currency.

                                                            311
SEQUENCES AND SERIES                                                              5.2 SERIES

This series almost, but not exactly, looks like the series from Theorem 5.2.5. We'll
expand the series17 in order to see how we might have indexed the terms differently.

     210, 000 ¤ 50 ¸ V 12 = n¡ 210, 000 1 ¤ 50 12 + 2 + 2 + 0 1 1 1 2 ¤ ¤ ¤

                         n=1

                          = 210, 000 ¤ 50 ¸ V 1 n

                                                         n=0 2

Now  we   can  apply  Theorem  5.2.5  with   r  =  1.

                                                   2

                               = 210, 000 ¤ 50 ¤ 1 1 = 210, 000 ¤ 50 ¤ 2 = 21, 000, 000
                                            1¡ 2

As blocks are mined, the total number of bitcoins will approach 21 million. It will
never exceed 21 million.

(b) For this part we assume that after a certain number of blocks, no more bitcoin are
     created. So, we will look at a finite sum, rather than an infinite series. Let's start by
     figuring out when the reward for a block drops below 1 satoshi.

The  nth  batch  of  210,000  blocks  earns   50   bitcoins,  as  long  as  that  number  is  greater

                                             2n¡1
than or equal to one satoshi. That is, we create bitcoins as long as:

                                      50               1                1
                                      2n¡1 ¥ 100, 000, 000 = 108

Solving for n:

                              5 ¤ 109 ¥ 2n¡1
                         log2(5 ¤ 109) ¥ n ¡ 1
                      1 + log2(5 ¤ 109) ¥ n

Note n only makes sense as an integer. Using a calculator, 1 + log2(5 ¤ 109)  33.2. So
when n = 33, blocks earn rewards, but when n ¥ 34, they do not.

The means the total supply of bitcoins that could ever be created under this system is:

     ¸ 33 50                                    1 0+      1 1+    12 + 2 ¤ ¤ ¤ +  1 32
                                                2         2                       2
        210, 000 ¤ n¡1 = 210, 000 ¤ 50

     n=1 2

                      = 210, 000 ¤ 50 2n ¸ 32 1

                                              n=0

17 indexing from 0 (starting with the 0th collection, then the 1st collection in the bullet list) would have
      eliminated this upcoming step. We described the creation of the series using the indexing that we
      thought would be most intuitive to our readers, rather than the indexing that would lead to the least
      amount of algebra.

                                                         312
SEQUENCES AND SERIES                                                                   5.2 SERIES

Now  we  can    apply  Theorem  5.2.5  with  r  =  1  and  N  =  32.
                                                   2

                                             1 ¡ 1 33                       1 ¡ 233 1
                                                      2
                       = 210, 000 ¤ 50 ¤              1 = 210, 000 ¤ 100 ¤
                                                1¡ 2

Using a calculator,

                        20, 999, 999.997555278

So the total supply of bitcoins approaches 20,999,999 bitcoins and 99,755,528 satoshi,
but never exceeds this amount.

                                                                            Example 5.2.6

5.2.2  Telescoping Series

       Typically, it is quite difficult to write down a neat closed form expression for the partial
       sums of a series. Geometric series are very notable exceptions to this. Another family
       of series for which we can write down partial sums is called "telescoping series". These
       series have the desirable property that many of the terms in the sum cancel each other out
       rendering the partial sums quite simple.

Example 5.2.7 (Telescoping Series)

                                                      °V      1
In this example, we are going to study the series n=1 n(n+1) . This is a rather artificial se-
ries18 that has been rigged to illustrate a phenomenon call "telescoping". Notice that the
nth term can be rewritten as

         1 n(n + 1) = 1n ¡ 1 n + 1

and so we have

                                an = bn ¡ bn+1                   where bn = 1n .

Because of this we get big cancellations when we add terms together. This allows us to
get a simple formula for the partial sums of this series.

         SN = 1 + 1 + 1 + ¤ ¤ ¤ + 1
                1¤2 2¤3 3¤4                        N ¤ (N + 1)
                = 11 ¡ 12 + 12 ¡ 13 + 13 ¡ 14 + ¤ ¤ ¤ +               1N ¡ 1 N + 1

18 Well. . . this sort of series does show up when you start to look at the Maclaurin polynomial of functions

   like (1 ¡ x) ln(1 ¡ x). So it is not totally artificial. At any rate, it illustrates the basic idea of telescoping

      very nicely, and the idea of "creative telescoping" turns out to be extremely useful in the study of series
      -- though it is well beyond the scope of this course.

                                             313
SEQUENCES AND SERIES                                       5.2 SERIES

The second term of each bracket exactly cancels the first term of the following bracket. So
the sum "telescopes" leaving just

                                    SN = 1 ¡ 1 N + 1

and we can now easily compute

                   = ¸ V 1 lim SN = lim 1 ¡ 1 = 1
                        n(n + 1) NÑV          NÑV     N+1
                   n=1

                                                           Example 5.2.7

More generally, if we can write

                            an = bn ¡ bn+1

for some other known sequence bn, then the series telescopes and we can compute partial
sums using

                               ¸ N    ¸ N
                                    an = (bn ¡ bn+1)

                             n=1      n=1

                                      ¸ N       ¸ N
                                    = bn ¡ bn+1

                                      n=1       n=1
                                    = b1 ¡ bN+1.

and hence

                             ¸ V

                                an = b1 ¡ lim bN+1

                             n=1 NÑV

                                                                  ° V

provided this limit exists. Often lim bN+1 = 0 and then an = b1. But this does not
                               NÑV                    n=1
always happen. Here is an example.

Example 5.2.8 (A Divergent Telescoping Series)

                                                     ° V 1

In this example, we are going to study the series log 1 + n . (We don't specify the base

                                                                                 n=1

-- any base greater than one will behave the same way.) Let's start by just writing out the
first few terms.

¸ V        1 + 1n      hkkkkkkni =1kkkkkkj hkkkkkkni =2kkkkkkj hkkkkkkni =3kkkkkkj hkkkkkkni =4kkkkkkj

    log            = log 1 + 11 + log 1 + 12 + log 1 + 13 + log 1 + 14 + ¤ ¤ ¤

n=1                                 + log 32    + log 43   + log 54 + ¤ ¤ ¤

                   = log(2)

                                      314
SEQUENCES AND SERIES                                                                                5.2 SERIES
This is pretty suggestive since

       log(2) + log 32 + log 43 + log 54 = log 2 ¢ 32 ¢ 43 ¢ 54 = log(5)

So let's try using this idea to compute the partial sum SN:

           ¸ N  1 + 1n

SN = log                                                              hkkkkkknkk=ki N¡kk1kkkkkkkj hkkkkknki =Nkkkkkkj

          n=1

        hkkkkkkni =1kkkkkkj hkkkkkkni =2kkkkkkj  hkkkkkkni =3kkkkkkj

= log 1 + 11 + log 1 + 12 + log 1 + 13                                + ¤ ¤ ¤ + log  1+ 1    + log  1 + 1N
                + log 3                          + log 4              + ¤ ¤ ¤ + log          + log  N+1
= log(2)                2                               3                               N¡1
                                                                                                       N
= log 2 ¢ 3 ¢ 4 ¢ ¤ ¤ ¤ ¢ N ¢ N + 1                                                    N

                                                                                     N¡1

                23         N¡1 N

= log(N + 1)

Uh oh!

                           lim SN = lim log(N + 1) = +V
                        NÑV                      NÑV

This telescoping series diverges! There is an important lesson here. Telescoping series can
diverge. They do not always converge to b1.

                                                                                                Example 5.2.8

5.2.3  Arithmetic of Series

       As was the case for limits, differentiation and antidifferentiation, we can compute more
       complicated series in terms of simpler ones by understanding how series interact with
       the usual operations of arithmetic. It is, perhaps, not so surprising that there are simple
       rules for addition and subtraction of series and for multiplication of a series by a constant.
       Unfortunately there are no simple general rules for computing products or ratios of series.

                                                                315
SEQUENCES AND SERIES                                                                                5.2 SERIES

Theorem5.2.9 (Arithmetic of series).

                                                                      °V             °V
Let A, B and C be real numbers and let the two series n=1 an and n=1 bn con-
verge to S and T respectively. That is, assume that

                       ¸ V                                     ¸ V

                           an = S                                  bn = T

                       n=1                                     n=1

Then the following hold.

(a)      ¸ V     an + bn = S + T and             ¸ V

         n=1                                         an ¡ bn = S ¡ T

                                                 n=1

    ¸ V

(b) Can = CS.

      n=1

Example 5.2.10

As a simple example of how we use the arithmetic of series Theorem 5.2.9, consider

                                          ¸ V 1           2
                                          n=1 7n + n(n + 1)

We recognize that we know how to compute parts of this sum. We know that

                                          ¸ V 1      1/7       1
                                          n=1 7n = 1 ¡ 1/7 = 6

because  it  is  a  geometric  series  (Example  5.2.4)  with  first  term  a  =  1  and  ratio  r  =  1.  And
                                                                                  7
we know that                                                                                           7

                                              ¸ V 1
                                          n=1 n(n + 1) = 1

by Example 5.2.7. We can now use Theorem 5.2.9 to build the specified "complicated"
series out of these two "simple" pieces.

         ¸ V 1      2                  ¸ V 1 ¸ V 2                          by Theorem 5.2.9.a
     n=1 7n + n(n + 1) = n=1 7n + n=1 n(n + 1)                              by Theorem 5.2.9.b
                               = n + ¸ V 1 2 ¸ V 1
                                       n=1 7     n=1 n(n + 1)
                               = 1 + 2 ¤ 1 = 13
                                       6         6

                                                                                          Example 5.2.10

                                                 316
SEQUENCES AND SERIES                                                                     5.2 SERIES

5.2.4  (Optional) Intergenerational Cost-Benefit Analysis

This subsection presents ideas from the article19 Intergenerational cost-benefit analysis and
marine ecosystem restoration by UBC Institute for the Oceans and Fisheries Professor Ussif
Rashid Sumaila.

    Generally we value the promise of money in the future less than we value the posses-
sion of money in the present. The discounting rate describes the loss of value that occurs
with time, and is calculated like interest. For example, suppose we have a discounting
rate of 10%. That means D dollars in our possession today has the same value to us as

D(1 + 0.1) = 1.1 ¤ D dollars promised to us in one year. These both have the same value
to us as (1.1)(1.1 ¤ D) = 1.12 ¤ D dollars in two years, or 1.1t ¤ D dollars in t years:

                          D present-day dollars = (1.1t ¤ D) future dollars

Dividing both sides of the equation by 1.1t, we see that the promise of D dollars in t years
is  worth  the  same  to  us  as  the  possession  of   D    dollars  in  the  present:
                                                       1.1t

                              D future dollars = 1.1t D present-day dollars
    In a conventional cost-benefit analysis (CBA), returns that will happen in the future
are subject to precisely this form of discounting. To quantify the value of a project, units
of Present Value (PV) are used. Given a discounting rate20 of , possession of D dollars
today has the same value as a gain of (1 + )tD dollars t years from now. Rearranged, the
present value of D dollars that will be gained t years in the future is given by

                                       PV(D, t) = (1 + )t D

    Future discounting is human nature, but it doesn't always make for good policy. In
particular, "high discount rates favour myopic fisheries policies resulting in global over-
fishing" (p. 334) since the model makes the health of an ecosystem one hundred years
from now worth almost nothing today.

    Sumaila proposes an intergenerational model, where discounting still happens within
a generation of people, but different generations are considered together. Quoting the
article:

    "The benefits to the current generation from the use of ecosystem resources to-
    day would never have appeared in the conventional CBA[Cost-Benefit Analy-
    sis] of the generations that were here a hundred years ago. Similarly, the gen-
    eration that will be here in a hundred years time, would receive benefits from
    restored marine ecosystems that would mean much to them but would not ap-
    pear in the current generation's conventional CBA. Therefore, to capture the
    benefits to all generations from ecosystem restoration projects, it is necessary
    to use [an intergenerational] CBA approach" (p. 336).

19 Sumaila UR. Intergenerational cost-benefit analysis and marine ecosystem restoration. Fish and
      fisheries (Oxford, England). 2004;5(4):329-43. You can access the full text online with your UBC
      CWL (campus-wide login) here: https://libkey.io/libraries/498/articles/30981866/
      full-text-file?utm_source=api_542.

20 To better understand the rate, note that if  = 0, then $1 today is worth the same to us as $1 one year
      from now, 100 years from now, or at any other time in the future.

                                                   317
SEQUENCES AND SERIES                                                                                   5.2 SERIES

    The approach proposed by Sumaila is as follows. We divide up the future into distinct
generations, each of which reigns over a (non-overlapping) interval of time. Each gener-
ation has its own Present Value calculation, measured from the start of its reign. So the
Present Value of the promise of D dollars in year t, to a generation that started its reign in
year t0, is

                                     PV(D, t) = (1 + )t D ¡t0

The difference between this calculation and the conventional PV calculation is that "present"
is relative for each generation.
Now that we have these components, we can create an expression for a cost-benefit
analysis (CBA) of a long-term project.
Suppose in year t, the costs incurred by the project are given by Ct, and the benefits
are given by Vt. The net value gained in that year is Vt ¡ Ct, before future discounting
is applied. If the generation started its reign in year t = t0, then the present value of of
(Vt ¡ Ct) to that generation is   Vt¡Ct
                                            .  If  the      generation  reigns  from  t  =  t0  to  t  =  t1,  then
                                      t¡t0
                                  (1+)
we combine the net present value of each of those years to find the net present value to
the generation of the entire project.
To include a collection of generations, we add up each generation's Net Present Value.
To express this in sigma notation, let NPVk be the Net Present Value for the kth generation.
We'll index years as follows. The first generation reigns from t = t0 + 1 to t = t1; the
second generation reigns from t = t1 + 1 to t = t2; and (in general) the kth generation
reigns from t = tk¡1 + 1 to t = tk. (Considering the first year to be t = t0 + 1 looks weird,
but makes the indices more consistent with one another.)

t0                    t1                           t2                   t3                      t4

    generation 1 generation 2 generation 3 generation 4

Then generation k has its personal Net Present Value given by

                                                      ¸ tk  Vt ¡ Ct

                                  NPVk =                         t¡tn
                                               t=tk¡1+1 (1 + )

    All together, the intergenerational Net Present Value of a project, from generation 1 to
generation L, is

                                    ¸ L

                      NPV = NPVk

                                        k=1  
                                        ¸ L        ¸ tk     Vt ¡ Ct 
                                  =
                                        k=1 t=tk¡1+1 (1 + )t¡tn

    If the NPV is positive, then the project is a good investment: adjusting for discount-
ing, but considering future generations, the benefits will exceed the costs. If the NPV is
negative, then the project is a bad investment.

                                                   318
SEQUENCES AND SERIES                  5.3 THE INTEGRAL AND DIVERGENCE TESTS

5.3 The Integral and Divergence Tests

It is very common to encounter series for which it is difficult, or even virtually impossi-
ble, to determine the sum exactly. Often you try to evaluate the sum approximately by
truncating it, i.e. having the index run only up to some finite N, rather than infinity. But
there is no point in doing so if the series diverges. So you like to at least know if the
series converges or diverges. Furthermore you would also like to know what error is in-
                                 °V                   °N
troduced when you approximate n=1 an by the "truncated series" n=1 an. That's called
the truncation error. There are a number of "convergence tests" to help you with this.
     Our first test is very easy to apply, but it is also rarely useful. It just allows us to quickly
reject some "trivially divergent" series. It is based on the observation that

                             °V                                                    °N
· by definition, a series n=1 an converges to S when the partial sums SN = n=1 an
     converge to S.

· Then, as N Ñ V, we have SN Ñ S and, because N ¡ 1 Ñ V too, we also have
  SN¡1 Ñ S.

  · So aN = SN ¡ SN¡1 Ñ S ¡ S = 0.

This tells us that, if we already know that a given series ° an is convergent, then the nth
term of the series, an, must converge to 0 as n tends to infinity. In this form, the test is not
so useful. However the contrapositive21 of the statement is a useful test for divergence.

     Theorem5.3.1 (Divergence Test).

                       2 @V                                                    °V
     If the sequence an n=1 fails to converge to zero as n Ñ V, then the series n=1 an
     diverges.

Example 5.3.2

Let  an  =   n.  Then

            n+1

                    lim an = lim n = lim 1 1 = 1 $ 0

                         nÑV nÑV n + 1 nÑV 1 + /n
              °V n

So the series n=1 n+1 diverges.

                                                          Example 5.3.2

21 Given a statement of the form "If A is true, then B is true" the contrapositive is "If B is not true, then A
      is not true". The two statements in quotation marks are logically equivalent -- if one is true, then so is
      the other. In the present context we have
        If (° an converges) then (an converges to 0).
      The contrapositive of this statement is then
        If (an does not converge to 0) then (° an does not converge).

                                                         319
SEQUENCES AND SERIES                                      5.3 THE INTEGRAL AND DIVERGENCE TESTS

     Warning5.3.3.

     The  divergence     test  is  a  "one  way   test".   It  tells  us  that  if  limnÑV an  is   nonzero,
     or fails to exist, then the series        V      an  diverges.    But  it  tells  us  absolutely° nothing
                                              °
                                               n=1
     when limnÑV an = 0. In particular, it is perfectly possible for a series                           V

                                                                                                        n=1 an
                                                                    °V 1
     to diverge even though limnÑV an = 0. An example is n=1 n . We'll show in
     Example 5.3.7, below, that it diverges.

                                                              °V 1

    Now while convergence or divergence of series like n=1 n can be determined using
some clever tricks, it would be much better to have methods that are more systematic and
rely less on being sneaky. Over the next subsections we will discuss several methods for
testing series for convergence.

    Note that while these tests will tell us whether or not a series converges, they do not
(except in rare cases) tell us what the series adds up to. For example, the test we will see
in the next subsection tells us quite immediately that the series

                                                      ¸ V 1

                                                      n=1 n3

converges. However it does not tell us its value22.

                                                 °V

    In the integral test, we think of a series n=1 an, that we cannot evaluate explicitly,
as the area of a union of rectangles, with an representing the area of a rectangle of width
one and height an. Then we compare that area with the area represented by an integral,
that we can evaluate explicitly, much as we did in Theorem 3.7.18, the comparison test for
improper integrals. We'll start with a simple example, to illustrate the idea. Then we'll
move on to a formulation of the test in general.

Example 5.3.4

                                                      °V 1
Visualise the terms of the harmonic series n=1 n as a bar graph -- each term is a rectan-
gle  of  height  1  and  width  1.    The  limit  of  the  series  is  then  the    limiting  area  of  this  union
                 n
of rectangles. Consider the sketch on the left below.

22 This series converges to Ape´ry's constant 1.2020569031 . . . . The constant is named for Roger Ape´ry
      (1916-1994) who proved that this number must be irrational. This number appears in many contexts
      including the following cute fact -- the reciprocal of Ape´ry's constant gives the probability that three
      positive integers, chosen at random, do not share a common prime factor.

                                                         320
SEQUENCES AND SERIES                                 5.3 THE INTEGRAL AND DIVERGENCE TESTS

                                                     °4 1
It shows that the area of the shaded columns, n=1 n , is bigger than the area under the
curve  y  =  1  with  1  ¤  x  ¤  5.  That  is
             x

                                                ¸ 4 1 » ¥ 5 1 dx

                                                n=1 n 1 x

If we were to continue drawing the columns all the way out to infinity, then we would
have

                                ¸ V 1 » ¥ V 1 dx

                                                n=1 n 1 x

We are able to compute this improper integral exactly:

                                      » V 1 dx = lim ln |x| R = +V
                                      1x        RÑV     1

That is the area under the curve diverges to +V and so the area represented by the
columns must also diverge to +V.

    It should be clear that the above argument can be quite easily generalised. For example
the same argument holds mutatis mutandis23 for the series

                                                ¸ V 1

                                                n=1 n2

Indeed we see from the sketch on the right above that

and hence                                       ¸ N 1 » N 1

                                                      ¤ 2 dx

                                                n=2 n2 1 x

                                                ¸ V 1 » V 1

                                                      ¤ 2 dx

                                                n=2 n2 1 x

23 Latin for "Once the necessary changes are made". This phrase still gets used a little, but these days
      mathematicians tend to write something equivalent in English. Indeed, English is pretty much the
      lingua franca for mathematical publishing. Quidquid erit.

                                                321
SEQUENCES AND SERIES                             5.3 THE INTEGRAL AND DIVERGENCE TESTS

This last improper integral is easy to evaluate:

                           » V 1 dx = lim ¡ 1 R
                                 1 x2         RÑV x 1

                                              = lim 1 ¡ 1 = 1
                                              RÑV 1 R

Thus we know that

                                      n2 = ¸ V 1 1 + n2 ¸ V 1 ¤ 2
                                  n=1               n=2

and so the series must converge.

                                                                             Example 5.3.4

The above arguments are formalised in the following theorem.

Theorem5.3.5 (The Integral Test).

Let N0 be any natural number. If f (x) is a function which is defined and contin-

uous for all x ¥ N0 and which obeys
 (i) f (x) ¥ 0 for all x ¥ N0, and

 (ii) f (x) decreases or stays the same as x increases, and

(iii) f (n) = an for all n ¥ N0.

                           y     y = f (x)

                                       a1

                                                 a2 a3 a4

                                       1         2        3        4x

Then                  ¸ V                           »V

                           an converges ðñ f (x) dx converges
                                                      N0
                      n=1

Furthermore, when the series converges, the truncation error

                   §V      an ¡  ¸ N §§ » V
                                      an§§ ¤     f (x) dx    for all N ¥ N0
                   §¸

                   §  n=1        n=1          N
                   §

Proof. Let I be any fixed integer with I ¡ N0. Then

°V                                        °V
· n=1 an converges if and only if n=I an converges -- removing a fixed finite num-
ber of terms from a series cannot impact whether or not it converges.

                                                 322
SEQUENCES AND SERIES                                 5.3 THE INTEGRAL AND DIVERGENCE TESTS

                                                                                                                          °

· Since an ¥ 0 for all n ¥ I ¡ N0, the sequence of partial sums s = n=I an obeys
  s+1 = s + an+1 ¥ s. That is, s increases as  increases.

· So      2@           either  converge    to  some          number       or  increase  to  infinity.  That  is,
          s      must                                finite
             
               °
either          V    an  converges  to  a  finite  number    or  it  is  +V.

                n=I

                                  y = f (x)

                                    I+2 aI aI+1 a aI+3
                                      I I+1 I+2 I+3 x

                                                                °V

Look at the figure above. The shaded area in the figure is n=I an because

· the first shaded rectangle has height aI and width 1, and hence area aI and
· the second shaded rectangle has height aI+1 and width 1, and hence area aI+1, and

   so on

This shaded area is smaller than the area under the curve y = f (x) for I ¡ 1 ¤ x V. So

                                        ¸ V        »V
                                               an ¤ f (x) dx
                                                     I¡1
                                        n=I

                                        °V

and, if the integral is finite, the sum n=I an is finite too. Furthermore, the desired bound
on the truncation error is just the special case of this inequality with I = N + 1:

                             ¸ V        ¸ N          ¸ V          »V
                                  an ¡ an =               an ¤ f (x) dx
                                                                     N
                          n=1       n=1            n=N+1

                                  y = f (x)

                                    I+2 aI aI+1 a aI+3
                                      I I+1 I+2 I+3 x

For     the  "divergence  case"   look  at   the  figure  above.     The  (new)  shaded     area  in  the  figure
is again   V    an  because
          °
           n=I

· the first shaded rectangle has height aI and width 1, and hence area aI and
· the second shaded rectangle has height aI+1 and width 1, and hence area aI+1, and

   so on

                                                   323
SEQUENCES AND SERIES                                5.3 THE INTEGRAL AND DIVERGENCE TESTS

This time the shaded area is larger than the area under the curve y = f (x) for I ¤ x V.
So
                                             V      »V
                                           ¸    an ¥ f (x) dx

                                           n=I      I

                                                °V
and, if the integral is infinite, the sum n=I an is infinite too.

    Now that we have the integral test, it is straightforward to determine for which values
of p the series24

                                              ¸ V 1

                                                       n=1 np
converges.

Remark 5.3.6. Theorem 5.3.5 requires f (x) to be non-increasing. If f (x) is increasing (or

                                                                                     V

constant) while x increases, and f (x) ¡ 0 for all sufficiently large x, then ° an (where

                                                                                                                                 n=1

an = f (n)) is divergent by the divergence test. So if you feel the desire to use the integral
test for an increasing function, remember that an easier option is available.

    In some texts, the integral test is defined to allow increasing functions. The test as
stated would indeed work with increasing functions, but as noted above, there is always25
an easier way.

Example 5.3.7                    ° V 1

                    The p test: np

                                      n=1

                                                                                          °V 1

Let p ¡ 0. We'll now use the integral test to determine whether or not the series n=1 np

(which is sometimes called the p-series) converges.

    ·  To  do  so,  we  need  a  function    f (x)  that  obeys  f (n)  =    an  =     1   for  all  n  bigger   than
                                         1                    1                 ¥      np
       some    N0.  Certainly  f (x)  =  xp  obeys  f (n)  =  np  for   all  n     1.  So  let's  pick  this  f  and

       try N0 = 1. (We can always increase N0 later if we need to.)

    · This function also obeys the other two conditions of Theorem 5.3.5:

24 This series, viewed as a function of p, is called the Riemann zeta function, (p), or the Euler-Riemann
      zeta function. It is extremely important because of its connections to prime numbers (among many
      other things). Indeed Euler proved that

                                 (p) = np = ¸ V 1 ¹ 1 ¡ P¡p ¡1
                                             n=1    P prime

      Riemann showed the connections between the zeros of this function (over complex numbers p) and
      the distribution of prime numbers. Arguably the most famous unsolved problem in mathematics, the
      Riemann hypothesis, concerns the locations of zeros of this function.
25 OK, OK, "always" is a strong term to a mathematician. If you know a function is positive and nonde-
      creasing, you automatically know the associated series is divergent. But perhaps a scenario could be
      invented where you knew a function was either increasing or decreasing, but you didn't know which
      one (the general term is "monotone"), and somehow you could also integrate that function. We suppose
      in that case you might want the extended version of the integral test.

                                                    324
SEQUENCES AND SERIES                                          5.3 THE INTEGRAL AND DIVERGENCE TESTS

        (i) f (x) ¡ 0 for all x ¥ N0 = 1 and                                             0 for all x ¥ N0 = 1.
        (ii) f (x) decreases as x increases because f I(x) = ¡p xp1+1

                                                  °V 1

   · So the integral test tells us that the series n=1 np converges if and only if the integral

     ³V dx

       1 xp converges.

                                                                    ³V dx

   · We have already seen, in Example 3.7.8, that the integral 1 xp converges if and only
        if p ¡ 1.
                                °V 1
So we conclude that n=1 np converges if and only if p ¡ 1. This is sometimes called the
p-test.
                                          °V 1
   · In particular, the series n=1 n , which is called the harmonic series, has p = 1 and so
        diverges. As we add more and more terms of this series together, the terms we add,
        namely     1,  get  smaller   and   smaller     and   tend  to    zero,  but  they  tend  to  zero  so  slowly

                   n
        that the full sum is still infinite.

                                                °V
   · On the other hand, the series n=1 n1.000001 has p = 1.000001 ¡ 1 and so converges.1

        This time as we add more and more terms of this series together, the terms we add,
        namely         1        tend  to  zero  (just)  fast  enough    that  the  full  sum  is  finite.  Mind  you,

                   n1.000001 ,
        for this example, the convergence takes place very slowly -- you have to take a huge
        number of terms to get a decent approximation to the full sum. If we approximate
        °V         1                                    °N          1
          n=1 n1.000001 by the truncated series n=1 n1.000001 , we make an error of at most
        » V dx
                                    » R dx                          1              1              1              106
         N x1.000001 = RlÑimV N x1.000001 = RlÑimV ¡ 0.000001 R0.000001 ¡ N0.000001 = N0.000001
        This does tend to zero as N Ñ V, but really slowly.

                                                                                                  Example 5.3.7

                                                                                                            °V 1
   We now know that the dividing line between convergence and divergence of n=1 np
occurs at p = 1. We can dig a little deeper and ask ourselves how much more quickly than
1  the  nth  term  needs        to  shrink  in  order   for  the  series  to  converge.  We   know    that  for  large
x, the function log x (of any base) is smaller than xa for any positive a -- you can convincen

yourself of this with a quick application of L'Ho^ pital's rule. So it is not unreasonable to
ask whether the series
                                                        ¸ V 1

                                                        n=2 n ln n

converges. Notice that we sum from n = 2 because when n = 1, n ln n = 0. And we don't
need to stop there26. We can analyse the convergence of this sum with any power of ln n.

   Example 5.3.8       ° V 1

                            n(ln n)p
                       n=2
                                                                                        ° V 1

Let p ¡ 0. We'll now use the integral test to determine whether or not the series n(ln n)p
converges. n=2

26 We could go even further and see what happens if we include powers of ln(ln(n)) and other more
      exotic slow-growing functions.

                                                         325
SEQUENCES AND SERIES                                                    5.4 COMPARISON TESTS

· As in the last example, we start by choosing a function that obeys f (n) = an =
       1     for  all  n  bigger than  some  N0.  Certainly  f (x)          1     obeys  f (n)         1
   n(ln n)p                                                          =  x(ln x)p                =  n(ln n)p

   for all n ¥ 2. So let's use that f and try N0 = 2.

· Now let's check the other two conditions of Theorem 5.3.5:

   (i) Both x and ln x are positive for all x ¡ 1, so f (x) ¡ 0 for all x ¥ N0 = 2.

   (ii) As x increases both x and ln x increase and so x(ln x)p increases and f (x) de-
        creases.

                                                    ° V 1

· So the integral test tells us that the series n(ln n)p converges if and only if the
                                                       n=2
   integral  ³  V      dx p converges.

                2  x(ln x)

·  To test the convergence of the integral, we make the substitution u            = ln x, du       =  dx .

                                                                                                      x

                                        » R dx         =  » ln R du

                                        2 x(ln x)p ln 2 u    p

                                             ³V du                                ³R dx
   We already know that the integral 1 up , and hence the integral 2 x(ln x)p , converges
   if and only if p ¡ 1.

                       ° V 1

So we conclude that n(ln n)p converges if and only if p ¡ 1.

                                   n=2

                                                                                  Example 5.3.8

5.4 Comparison Tests

Our next convergence test is the comparison test. It is much like the comparison test for
improper integrals (see Theorem 3.7.18) and is true for much the same reasons. The rough
idea is quite simple. A sum of larger terms must be bigger than a sum of smaller terms. So
if we know the big sum converges, then the small sum must converge too. On the other
hand, if we know the small sum diverges, then the big sum must also diverge. Formalising
this idea gives the following theorem.

   Theorem5.4.1 (The Comparison Test).

   Let N0 be a natural number and let K ¡ 0.

   (a) If |an| ¤ Kcn for all n ¥ N0 and ° V cn converges, then ° V an converges.
                                             n=0                        n=0

   (b) If an ¥ Kdn ¥ 0 for all n ¥ N0 and ° V dn diverges, then ° V an diverges.
                                                  n=0                   n=0

                                                  326
SEQUENCES AND SERIES                                                                   5.4 COMPARISON TESTS

"Proof". We will not prove this theorem here. We'll just observe that it is very reason-
able. That's why there are quotation marks around "Proof". For an actual proof see the
appendix section A.11.

(a) If ° V cn converges to a finite number and if the terms in ° V an are smaller than the
° n=0 V                                                        ° V n=0
terms in cn, then it is no surprise that an converges too.
     n=0                                                    n=0

(b) If ° V dn diverges (i.e. adds up to V) and if the terms in ° V an are larger than the terms
n=0                                                                          n=0
V                                ° V
in ° dn, then of course an adds up to V, and so diverges, too.
n=0                              n=0

    The comparison test for series is also used in much the same way as is the comparison
test for imprope° r integrals. Of course, one needs a good series to compare against, and

often the series n¡p (from Example 5.3.7), for some p ¡ 0, turns out to be just what is

needed.

              °V              1
Example 5.4.2 n=1 n2+2n+3

Whether or not any series converges is determined by the behaviour of the summand27
for very large n. So the first step in tackling such a problem is to develop some intuition
about the behaviour of an when n is very large.

· Step 1: Develop intuition.          In   this     case,   when     n   is  very  large28   n2  4  2n   4   3  so  that

                                                                                          °
     1        1     We  already       know,         from    Example      5.3.7,  that  V     1     converges    if  and
n2+2n+3                                                                                      np
              n2 .                                                                     n=1
                    °V 1

only if p ¡ 1. So n=1 n2 , which has p = 2, converges, and we would expect that
°Vn=1 n2+2n+3 converges too.1

· Step 2: Verify intuition. We can use the comparison test to confirm that this is indeed
the case.  For any n          ¥  1,   n2 + 2n + 3           ¡  n2,  so that       1    ¤     1     So the compari-
                                                                             n2+2n+3                °V
                                                            1                      1         n2 .                   1
son test, Theorem 5.4.1, with an = n2+2n+3 and cn = n2 , tells us that n=1 n2+2n+3
converges.

                                            °V

27 To understand this consider any series n=1 an. We can always cut such a series into two parts -- pick
      some huge number like 106. Then

                                      ¸ V              106          ¸ V

                                                       ¸
                                           an = an +                     an

                                      n=1              n=1     n=106 +1

                                                                                            °V
The first sum, though it cou°ld be humongous, is finite. So the left hand side, n=1 an, is a well-defined
finite number if and only if     V         an,  is  a  well-defined  finite  number.   The  convergence  or  divergence

                                 n=106 +1
of the series is determined by the second sum, which only contains an for "large" n.
28 The symbol "4" means "much larger than". Similarly, the symbol "3" means "much less than". Good
shorthand symbols can be quite expressive.

                                                       327
SEQUENCES AND SERIES                                                                             5.4 COMPARISON TESTS

                                                                                                               Example 5.4.2

Of course the previous example was "rigged" to give an easy application of the com-
parison test. It is o° ften relatively easy, using arguments like those in Example 5.4.2, to find
a "simple" series    V         with        bn    almost the same as                 an  when  n  is large.        However it is

                     n=1 bn
pretty rare that an ¤ bn for all n. It is much more common that an ¤ Kbn for some constant
K. This is enough to allow application of the comparison test. Here is an example.

                 °V n+cos n
Example 5.4.3 n=1 n3¡1/3

As in the previous example, the first step is to develop some intuition about the behaviour
of an when n is very large.

· Step 1: Develop intuition. When n is very large,

¥ n 4 | cos n| so that the numerator n + cos n  n and
¥ n3 4 1/3 so that the denominator n3 ¡ 1/3  n3.

So when n is very large                                 n + cos n n 1

                                                 an = n3 ¡ 1/3  n3 = n2
                                                                °V 1

We already know from Example 5.3.7, with p = 2, that n=1 n2 converges, so we
would  expect        that     °V        n+cos n    converges            too.

                                 n=1       31
                                         n ¡ /3

· Step 2: Verify intuition. We can use the comparison test to confirm that this is indeed
                                                                                              |an|       |n+cos n|
the  case.  To     do     so  we    need    to   find    a  constant        K     such  that        =       3         =  n+cos n  is

                                                                                                                           3
                                                                                                         n ¡1/3 n ¡1/3
smaller   than     K      for  all  n.   A  good      way29         to  do  that    is  to  factor  the  dominant        term  (in
                   n2
this case n) out of the numerator and also factor the dominant term (in this case n3)
out of the denominator.

                                         n + cos n n 1 + cos n 1 1 + cos n                          n
                               an =      n3 ¡ 1/3           =                  n=
                                                                n3   1¡        1        n2   1¡     1
                                                                            3n                   3n
                                                                                 3                    3

                                                                              1+(cos n)/n

So now we need to find a constant K such that 1¡1/3n3 is smaller than K for all n ¥ 1.

¥    First  consider           the  numerator            1  +   (cos    n)  1  .  For all n  ¥1
                                                                            n
               ¤
       *    1      1   and
            n
       * | cos n| ¤ 1
                                                         1                                             (1) 11
     So  the   numerator            1   +  (  cos  n  )  n  is  always      smaller     than  1  +             =  2.

¥ Next consider the denominator 1 ¡ 1/3n3.

       *    When n ¥ 1,              1   lies between           1   and 0 so that
                                    3n3                         3
            1¡       1                        2
       *           3n     is between          3  and 1 and consequently
                       3

29 This is very similar to how we computed limits at infinity way way back near the beginning of first-
      semester calculus.

                                                                328
SEQUENCES AND SERIES                                                                             5.4 COMPARISON TESTS

            *       1    is  between        3  and  1.
                                            2
                1¡1/3n3

   ¥        As  the  numerator        1  +  (cos  n)  1  is  always       smaller  than          2   and                1    is  always
                                                      n
            smaller  than    3,  the  fraction                                                                      1¡1/3n3

                             2

                                                    1 + cos n             3
                                                             n ¤2 =3
                                                    1¡       1            2
                                                         3n
                                                               3

   We now know that                                      1 1 + 2/n 3

                                               |an| = 2 1 3 ¤ 2
                                                         n 1 ¡ /3n n
                                 °V                                                                                       °V
   and,     since  we  know              n¡2   converges,        the  comparison   test          tells  us          that          n+cos  n
                                    n=1                                                                                      n=1
                                                                                                                                    3
   converges.                                                                                                                     n ¡1/3

                                                                                                                    Example 5.4.3

    The last example was actually a relatively simple application of the Comparison The-
orem -- finding a suitable constant K can be really tedious. Fortunately, there is a variant
of the comparison test that completely eliminates the need to explicitly find K.

    The idea behind this isn't too complicated. We have already seen that the convergence
or divergence of a series depends not on its first few terms, but just on what happens
when n is really large. Consequently, if we can work out how the series terms behave for
really big n then we can work out if the series converges. So instead of comparing the
terms of our series for all n, just compare them when n is big.

   Theorem5.4.4 (Limit Comparison Theorem).

   °V                    °V
   Let n=1 an and n=1 bn be two series with bn ¡ 0 for all n. Assume that

                                                    lim an = L

                                                    nÑV bn

   exists.

            °V                                 °V
   (a) If n=1 bn converges, then n=1 an converges too.

                         °V                                  °V
   (b) If L $ 0 and n=1 bn diverges, then n=1 an diverges too.

                                         °V                                                      °V
   In particular, if L $ 0, then n=1 an converges if and only if n=1 bn converges.

Proof. (a)  Because    we  are   told    that  limnÑV        an   =  L,  we  know  that,
                                                             bn

                                                                                                                §§

· when n is large, bann is very close to L, so that §§ ban § n § is very close to |L|.

                                                                                   §§            ¤  |L| + 1, for all n            ¥
                                                                                       § an §
·  In particular, there is some natural number                        N0                                                             N0,
                                                                          so that § b §
   and hence
                                                                                              n

                                                         329
SEQUENCES AND SERIES                                                                           5.4 COMPARISON TESTS

     · |an| ¤ Kbn with K = |L| + 1, for all n ¥ N0.

                                                              °V

     · The Comparison Theorem 5.4.1 now implies that n=1 an converges.

(b) Let's suppose that L ¡ 0. (If L               0, just replace an with ¡an.) Because we are told that
limnÑV       an     L,  we  know       that,
             bn  =

     · when n is large, bann is very close to L.

     ·  In particular, there is some natural number                  N so that     an   ¥   L  ,  and    hence
                                                                                   bn       2

     ·   an  ¥ Kbn with K       =    L  ¡ 0, for all n ¥    N.
                                     2

                                                              °V

     · The Comparison Theorem 5.4.1 now implies that n=1 an diverges.

    The next two examples illustrate how much of an improvement the above theorem is
over the straight comparison test (though of course, we needed the comparison test to
develop the limit comparison test).

                 °V cn+1
Example 5.4.5 n=1 n2¡2n+3
                 c
Set  an  =       n+1        We  first  try  to  develop  some      intuition  about    the  behaviour         of  an  for  large

             n2¡2n+3 .
n and then we confirm that our intuition was correct.

     · Step 1: Develop intuition. When n 4 1, cthe numerator cn + 1  cn, and the denom-
        inator n2 ¡ 2n + 3  n2 so that an                      n     =    1   and  it  looks      like   our  series  should
                                                              n2        n3/2
        converge       by   Example     5.3.7   with  p     3.
                                                         =
                                                            2

     · Step 2: Verify intuition.            To  confirm  our       intuition  we   set  bn  =       1    and  compute         the
                                                                                                  n3/2
        limit                                               cn+1
                                                                                   3/2c
                                              an         n2¡2n+3              n n+1
                                       lim = lim                        = lim 2
                                                                1
                                       nÑV bn nÑV           n   3/2       nÑV n ¡ 2n + 3

        Again it is a good idea to factor the dominant term out of the numerator and the
        dominant term out of the denominator.
                                                  n2c1 + 1/n                           c1 + 1/n
                                an
                            lim = lim 2 2                               =     lim  1 ¡ 2/n + 3/n2        =    1

                            nÑV bn nÑV n 1 ¡ 2/n + 3/n                        nÑV

                                                      °V                °V 1
        We already know that the series n=1 bn = n=1 n3/2 converges by Example 5.3.7
        with     p  =   3.  So  our  series   converges  by     the  limit    comparison          test,  Theorem      5.4.4.

                        2

                                                                                                         Example 5.4.5

                                                            330
SEQUENCES AND SERIES                                                          5.4 COMPARISON TESTS

                 °V cn+1
Example 5.4.6 n=1 n2¡2n+3 , again

We can also try to deal with the series of Example 5.4.5, using the comparison test directly.
But that requires us to find K so that

                                cn + 1 K
                              n2 ¡ 2n + 3 ¤ n3/2

We might do this by examining the numerator and denominator separately:

· The numerator isn't too bad since for all n ¥ 1:

                                         n + 1 ¤ 2n             and so
                                        cc

                                         n + 1 ¤ 2n

· The denominator is quite a bit more tricky, since we need a lower bound, rather than
an upper bound, and we cannot just write |n2 ¡ 2n + 3| ¥ n2, which is false. Instead
we have to make a more careful argument. In particular, we'd like to find N0 and KI
so that n2 ¡ 2n + 3 ¥        KIn2, i.e.           1    ¤    1   for all n  ¥  N0.  For n  ¥ 4, we have

             ¤      ¤                        n2¡2n+3      KIn2
2n     1 4n     1n     n     1 n2.  So  for  n  ¥  4,
    =                     =
       2        2            2

                               n2 ¡ 2n + 3 ¥ n2 ¡ 12 n2 + 3 ¥ 12 n2

Putting the numerator and denominator back together we have
                                      c2n c 1
                       cn + 1       ¤ 2 = 2 2 3/2               for all n ¥ 4
                    n2 ¡ 2n + 3 n /2
                                                       n

and the comparison test then tells us that our series converges. It is pretty clear that the
approach of Example 5.4.5 was much more straightforward.

                                                                                                Example 5.4.6

 Example 5.4.7 (Alternating Harmonic Series)

                                                                ° V 1

We've seen by the integral test that the harmonic series, n , diverges. Now we'll con-
sider the alternating harmonic series, n=1

                                   ¸ V (¡1)n

                                                    n=1 n
    Since we have negative30 terms, we can't immediately use a comparison test.

30 There's a really convenient test for convergence of series that alternate signs every term, the aptly-
      named Alternating Series Test. You can find more information in Appendix A.12.1. The Alternating
      Series Test, however, is not on our syllabus.

                                                         331
SEQUENCES AND SERIES                                                  5.5 THE RATIO TEST

    We'd like to re-write our series. The fine print is that there are only certain circum-
stances where re-writing a series of this type preserves its convergence. (See Section 5.6
and Appendix A.13.) You can take our word for it that the rearrangement below does not
impact the convergence of this particular series.

= ¸ V (¡1)n ¡1 + 1 ¡ 1 + 1 ¡ 1 + 1 ¡ ¤ ¤ ¤
n=1 n                 23 45 6

       = ¡1 + 12 + ¡13 + 14 + ¡15 + 16 + ¤ ¤ ¤

We'll get a common denominator for each bracketed pair.

       = ¡ 2 + 1 + ¡ 4 + 3 + ¡ 6 + 5 +¤¤¤
                      1¤2 1¤2          3¤4 3¤4           5¤6 5¤6

       = ¡ 1 + ¡ 1 + ¡ 1 ¡¤¤¤
                      1¤2      3¤4             5¤6
       ¸ V = ¡1
       n=1 2n(2n ¡ 1)

       ° ¡1                    °1
We can compare 2n(2n¡1) with n2 using the Limit Comparison Test:

                           an = ¡1             bn = 21
                               2n(2n ¡ 1)           n
                           L = lim an
                           nÑV bn
                                       ¡1
                                     2n(2n¡1)
                           = lim 1
                                       n
                             nÑV 2

                           = lim ¡n2
                           nÑV 2n(2n ¡ 1)
                           = ¡14

°V                                             °V
Since n=1 bn converges, and L = ¡ 4 exists, n=1 an converges as well.1       That is, the
                                                                            trust in your
alternating harmonic series converges by the limit comparison test (and by
authors that the rearrangement we started with is, indeed, allowed).

                                                                      Example 5.4.7

5.5 The Ratio Test

The idea behind the ratio test comes from a reexamination of the geometric series. Recall
that the geometric series

                               ¸ V        ¸ V
                                     an = arn

                               n=0        n=0

                                       332
SEQUENCES AND SERIES                                                                        5.5 THE RATIO TEST

converges when |r| 1 and diverges otherwise. So the convergence of this series is com-
pletely determined by the number r. This number is just the ratio of successive terms --
that is r = an+1/an.
In  general  the  ratio  of  successive  terms  of              a  series,  an+1   is  not  constant,  but  depends  on
                                                                                            °
                                                                             an ,
n. However, as we have noted above, the convergence of a series an is determined by
the behaviour of its terms when n is large. In this way, the behaviour of this ratio when
n is small tells us nothing about the convergence of the series, but the limit of the ratio as
n Ñ V does. This is the basis of the ratio test.

Theorem5.5.1 (Ratio Test).

Let N be any positive integer and assume that an $ 0 for all n ¥ N.

             §        §         1, then ° V an converges.
                  § an+1 §
                                            n=1
(a) If lim § a § = L
    nÑV n

             §        §                  §      §                              V
             § an+1 §                    § an+1 §                              °
(b) If lim § a § = L ¡ 1, or lim § a § = +V, then an diverges.
    nÑV           n                nÑV      n                               n=1

 Warning5.5.2.
Beware that the ratio test provides absolutely no conclusion about the conver-

gence or divergence of the series ° V an if lim §§§ ana+1 § n § = 1. §
                                    n=1 nÑV

                                                                                                 §     §
Proof. (a) Pick any number R obeying L R 1. We are assuming that §§ an § a+1 § n § approaches §
L as n Ñ V. In particular there must be some natural number M so that §§ ana+1 § n § ¤ R for all
n ¥ M. So |an+1| ¤ R|an| for all n ¥ M. In particular

                                |aM+1| ¤ R |aM|

                                |aM+2| ¤ R |aM+1| ¤ R2 |aM|

                                |aM+3| ¤ R |aM+2| ¤ R3 |aM|

                                        ...

                                |aM+| ¤ R |aM|

                         °V 
for all  ¥ 0. The series =0 R |aM| is a geometric series with ratio R smaller than one in
magnitude and so converges. Consequently, by the comparison test with an replaced by
                                                                            V               ° V
A = an+ and cn replaced by C = R |aM|, the series ° aM+ =                                           an converges. So
    ° V =1 n=M+1
the series an converges too.
    n=1
                             §  §
(b) We are assuming that §§ ana+1 § n § approaches L ¡ 1 as n Ñ V. In particular there must be § §
                             ¡                    § an+1 §      ¥                  ¥        So |an+1|  ¥    |an| for all
some natural number      M                                         1 for all n         M.
                                N so that § a §

                                                             n

                                                   333
SEQUENCES AND SERIES                                                                                   5.5 THE RATIO TEST

n ¥ M. That is, |an| increases as n increases as long as n ¥ M. So |an| ¥ |aM| for all n ¥ M
and an cannot converge to zero as n Ñ V. So the series diverges by the divergence test.

Example 5.5.3             °V   n=0 anx    n¡1

Fix any two nonzero real numbers a and x. We have al° ready seen in Example 5.2.4 -- we
have just renamed r to x -- that the geometric series                                V     axn  converges     when          |x|  1

                                                                                     n=0
and diverges when |x| ¥ 1. We are now going to°consider a new series, constructed by
differentiating31 each term in the geometric series                           V      axn.  This  new        series  is

                                                                              n=0

                                               ¸ V            with an = a n xn¡1

                                                   an

                                               n=0

Let's apply the ratio test.

               §§ an+1 § § § § a (n + 1) xn §§ n + 1 1
               §       §=§                n¡1 § =               |x| = 1 + |x| Ñ L = |x| as n Ñ V
                  an               anx                     n                  n

The  ratio     test  now       tells  us  that  the  series     °V      a  n  xn¡1  converges    if    |x|    1 and diverges if

                                                                   n=0
|x| ¡ 1. It says nothing about the cases x = ¨1. But in both of those cases an = a n (¨1)n
does not converge to zero as n Ñ V and the series diverges by the divergence test.

                                                                                                              Example 5.5.3

    Notice that in the above example, we had to apply another convergence test in addition
to the ratio test. This will be commonplace when we reach power series and Taylor series
-- the ratio test will tell us something like

    The series converges for |x| R and diverges for |x| ¡ R.
We generally won't bother with the cases x = +R, ¡R.

5.5.1  Convergence Test List

       We now have a handful of convergence tests:

           · Divergence Test
                  - works well when the nth term in the series fails to converge to zero as n tends to
                     infinity

           · Integral Test

31  We  s° hallV  see  later,  in  Theorem  6.2.1,   that  the  function   °V      anxn¡1  is  indeed  the  derivative  of  the  func-
                    axn.  Of   course,    such  a                                    where            series
               n=0                                                            n=0
    tion                                           statement    only  makes   sense            these          converge  --  how  can
    you differentiate a divergent series? (This is not an allusion to a popular series of dystopian novels.)
    Actually, there is quite a bit of interesting and useful mathematics involving divergent series, but it is
    well beyond the scope of this course.

                                                                334
SEQUENCES AND SERIES               5.6 ABSOLUTE AND CONDITIONAL CONVERGENCE

- works well when, if you substitute x for n in the nth term you get a function,
   f (x), that you can integrate

- don't forget to check that f (x) ¥ 0 and that f (x) decreases as x increases

· Ratio Test

-  works well when          an+1  simplifies enough that you can easily compute    lim  §§ an+1 §§ =
                             a
                                                                                           a
   L                         n                                                     nÑV n

- this often happens when an contains powers, like 7n, or factorials, like n!

- don't forget that L = 1 tells you nothing about the convergence/divergence of
  the series

· Comparison Test and Limit Comparison Test

- works well when, for very large n, the nth term an is approximately the same as
   ° a simpler term bn (see Example 5.4.3) and it is easy to determine whether or not
      V       bn  converges

      n=1
- don't forget to check that bn ¥ 0

- A particular comparison series may work with one comparison test but not
   the other. The Direct Com°parison Test is usually only easier when series have
   fairly simple terms, like          1     For   series  with  more  complicated  terms,  like

   °  2n2+sin n                    2n2+5 .

         32       ,  Limit  Comparison  Test  is  often  the  easier  choice.
      4n +n ¡n

5.6 Absolute and Conditional Convergence

We have now seen examples of series that converge and of series that diverge. But we
haven't really discussed how robust the convergence of series is -- that is, can we tweak
the coefficients in some way while leaving the convergence unchanged. A good example
of this is the series

                                            ¸ V 1 n

                                   n=1 3

This is a simple geometric series and we know it converges. We have also seen, as Example
5.5.3 showed us, that we can multiply or divide the nth term by n and it will still converge.

We can even multiply the nth term by (¡1)n, and it will still converge. Pretty robust.

    On the other hand, we have explored the Harmonic series and its relatives quite a lot
and we know it is much more delicate. While

                                               ¸ V 1

                                        n=1 n

diverges, we also know32 the following two series converge:

                  ¸ V 1                                   ( ¸ V ¡1)n 1n .

                  n=1 n1.00000001                         n=1

32 The first is a p-series with p ¡ 1; the second is the alternating harmonic series, which we found to

      converge in Example 5.4.7.

                                        335
SEQUENCES AND SERIES                          5.6 ABSOLUTE AND CONDITIONAL CONVERGENCE

This suggests that the divergence of the Harmonic series is much more delicate. In this
section, we discuss one way to characterize this sort of delicate convergence -- especially
in the presence of changes of sign.

     Definition5.6.1 (Absolute and conditional convergence).

     (a) A series ° V an is said to converge absolutely if the series ° V |an| converges.
                     n=1                                                     n=1

     (b) If ° V an converges but ° V |an| diverges we say that ° V an is conditionally
             n=1                         n=1                                 n=1
     convergent.

     If you consider these definitions for a moment, it should be clear that absolut° e con-
vergence is a stronger condition than just simple convergenc° e. All the terms in n |an|
are  forced  to  be  positive  (by  the  absolute  value  signs),  so  that  n |an| must be bigger than

°                                    °
   n an-- making it easier for n |an| to diverge. This is formalised by the following the-
orem, which is an immediate consequence of the comparison test, Theorem 5.4.1.a, with
cn = |an|.

     Theorem5.6.2 (Absolute convergence implies convergence).

     If the series ° V |an| converges then the series ° V an also converges. That is, abso-
                     n=1                                  n=1
     lute convergence implies convergence.

    Recall that some of our convergence tests (for example, the integral test) may only be
applied to series with positive terms. Theorem 5.6.2 opens up the possibility of applying
"positive only" convergence tests to series whose terms are not all positive, by checking
for "absolute convergence" rather than for plain "convergence".

Example 5.6.3        °V (¡1)n¡1 1
                       n=1          n    2

                       °V §§        n¡1 1 §§ ° V 1
Because the series n=1 (¡1) n2 = n2 of Example 5.3.7 converges (by the integral
                                              n=1
                 ° V n¡1 1

test), the series (¡1) n2 converges absolutely, and hence converges.
                  n=1

                                                                                  Example 5.6.3

 Example 5.6.4 (random signs)
Imagine flipping a coin infinitely many times. Set n = +1 if the nth flip comes up heads

                                                         336
SEQUENCES AND SERIES       5.6 ABSOLUTE AND CONDITIONAL CONVERGENCE

                                              °V §§                          n 1 §§
and n  =  ¡1 if the nth flip comes up tails.  We know that the series n=1 (¡1) 2n    =
° V 1
          °V
     n2 converges. So n=1(¡1) n2 converges absolutely, and hence converges.n 1

n=1

                                              Example 5.6.4

    With series that converge conditionally, arithmetic can get a little tricky. For some
interesting examples of this trickiness, see Appendix A.13.

                           337
Chapter 6

                              POWER SERIES

Let's return to the simple geometric series

                                            ¸ V

                                                xn

                                            n=0

where x is some real number. As we have seen (back in Example 5.2.4), for |x| 1 this
series converges to a limit, that varies with x, while for |x| ¥ 1 the series diverges. Conse-

quently we can consider this series to be a function of x

                     ¸ V                            on the domain |x| 1.

             f (x) = xn

                         n=0

Furthermore (also from Example 5.2.4) we know what the function is.

                                  f (x) = ¸ V xn = 1 .

                                                1¡x

                                              n=0

                                  °V n                                                               1
Hence we can consider the series n=0 x as a new way of representing the function 1¡x
when |x| 1. This series is an example of a power series.
Of  course,  representing  a  function  as  simple  as    1  by  a  series  doesn't  seem  like  it  is

                                                        1¡x
going to make life easier. However the idea of representing a function by a series turns
out to be extremely helpful. Power series turn out to be very robust mathematical ob-
jects and interact very nicely with not only standard arithmetic operations, but also with
differentiation and integration (see Theorem 6.2.1). This means, for example, that

    d 4 1 B = d ¸ V xn                                         provided |x| 1

    dx 1 ¡ x dx n=0                                 just differentiate term by term

                 = ¸ V d xn

                        n=0 dx

                     ¸ V
                 = nxn¡1

                             n=0

                                             338
POWER SERIES                                        6.1 RADIUS OF CONVERGENCE

and in a very similar way

» 1 dx = xn » ¸ V dx                                         provided |x| 1
1 ¡ x n=0
                     ¸ V »                          just integrate term by term
                            xndx
                  =

                     n=0
                          ¸ V
                               1 xn+1
                  =C+
                           n=0 n + 1

We are hiding some mathematics under the word "just" in the above, but you can see that
once we have a power series representation of a function, differentiation and integration
become very straightforward.

    So we should set as our goal for this chapter, the development of machinery to define
and understand power series. This will allow us to answer questions1 like

                                  Is ex = ¸ V xn ?

                                            n=0 n!

6.1 Radius of Convergence

     Our starting point (now that we have equipped ourselves with basic ideas about series),
     is the definition of power series.

            Definition6.1.1.

           A series of the form

                                                                          ¸ V

              A0 + A1(x ¡ c) + A2(x ¡ c)2 + A3(x ¡ c)3 + ¤ ¤ ¤ = An(x ¡ c)n

                                                                                                                 n=0

       is called a power series in (x ¡ c) or a power series centered on c. The numbers An

           are called the coefficients of the power series.
          One often considers power series centered on c = 0 and then the series reduces

         ¸ to V

                        A0 + A1x + A2x2 + A3x3 + ¤ ¤ ¤ = Anxn

                                                                                                        n=0

                  °V xn                                                                  1
For example n=0 n! is the power series with c = 0 and An = n! . Typically, as in
that case, the coefficients An are given fixed numbers, but the "x" is to be thought of as a
variable. Thus each power series is really a whole family of series -- a different series for
each value of x.

1 Recall that n! = 1 ¢ 2 ¢ 3 ¢ ¤ ¤ ¤ ¢ n is called "n factorial". By convention 0! = 1.

                                       339
POWER SERIES                                                                 6.1 RADIUS OF CONVERGENCE

One possible value of x is x = c and then the series reduces2 to

              ¸ V An(x ¡ c)n§§§        ¸ V

                                    = An(c ¡ c)n
              n=0 x=c n=0
                                    = looAm0oon + loom 0 oon + loom 0 oon + loom 0 oon + ¤ ¤ ¤

                                       n=0        n=1               n=2            n=3

and so simply converges to A0.
We now know that a power series converges when x = c. We can now use our
convergence tests to determine for what other values of x the series ° converges. Per-
haps most straightforward is the ratio test. The nth term in the series                         V    An(x  ¡  c)n
is an = An(x ¡ c)n. To apply the ratio test we need to compute the limit
                                                                                                n=0

              lim §§§ an+1 § § § § § = lim § An+1(x ¡ c)n+1 §§§
              nÑV an nÑV An(x ¡ c)§ §          §                             n§

                                               §  A           §

                                       =  lim  §     n  +  1  § ¤ |x ¡ c|§
                                                              §
                                          nÑV An§
                                               §

                                                                 §  A           §

                                       = |x ¡ c| ¤ lim §§ § § .        n  +  1  §
                                                                                §
                                                     nÑV An

When we do so there are several possible outcomes.

· If the limit of ratios exists and is non-zero

                                    lim §§ A § n+1 §§§ = A $ 0,

                                    nÑV An

                                            °V
then the ratio test says that the series n=0 An(x ¡ c)                       n

- converges when A ¤ |x ¡ c| 1, i.e. when |x ¡ c| 1/A, and
- diverges when A ¤ |x ¡ c| ¡ 1, i.e. when |x ¡ c| ¡ 1/A.

Because of this, when the limit exists, the quantity

                                                                                        Equation 6.1.2.

                                    R = 1A =      lim §§ A § n+1 §§ ¡1 §
                                                  nÑV An

       is called the radius of convergence of the series3.

2 By convention, when the term (x ¡ c)0 appears in a power series, it has value 1 for all values of x, even

     x = c.
3 The use of the word "radius" might seem a little odd here, since we are really describing the interval

      in the real line where the series converges. However, when one starts to consider power series over
      complex numbers, the radius of convergence does describe a circle inside the complex plane and so
      "radius" is a more natural descriptor.

                                                         340
POWER SERIES                                                         6.1 RADIUS OF CONVERGENCE

· If the limit of ratios exists and is zero

                                             lim §§ A § n+1 §§§ = 0

                                             nÑV An

              §      §
                    § An+1 §
then                              =  0  for  every  x  and   the     ratio  test  tells  us  that  the  series
°V    limnÑV § An §|x ¡ c|
  n=0 An(x ¡ c) converges for every number x. In this case we say that the seriesn

has an infinite radius of convergence.

· If the limit of ratios diverges to +V

                                         lim §§ A § n+1 §§§ = +V

                                         nÑV An

              §      §
              | § An+1 §  ¡   c|     +V                   $
then  limnÑV                      =      for  every    x     c.  The  ratio  test  then  tells  us  that  the
      °V      § A §x

                     n
series n=0 An(x ¡ c) diverges for every number x $ c. As we have seen above,n

when x = c, the series reduces to A0 + 0 + 0 + 0 + 0 + ¤ ¤ ¤ , which of course converges.
In this case we say that the series has radius of convergence zero.

  §   §
· If §§ AAn+1 § n § does not approach a limit as n Ñ V, then we learn nothing from the ratio
test and we must use other tools to understand the convergence of the series.

All of these possibilities do happen. We give an example of each below. But first, the
concept of "radius of convergence" is important enough to warrant a formal definition.

Definition6.1.3.

                           °V
(a) Let 0 R V. If n=0 An(x ¡ c) converges for |x ¡ c| R, and divergesn

  for |x ¡ c| ¡ R, then we say that the series has radius of convergence R.

      °V
(b) If n=0 An(x ¡ c) converges for every number x, we say that the series hasn

  an infinite radius of convergence.

      °V
(c) If n=0 An(x ¡ c) diverges for every x $ c, we say that the series has radiusn

  of convergence zero.

Example 6.1.4 (Finite nonzero radius of convergence)

We already know that, if a $ 0, the geometric series ° V axn converges when |x| 1 and

                                                                                          n=0

diverges when |x| ¥ 1. So, in the terminology of Definition 6.1.3, the geometric series has

radius of convergence R = 1. As a consistency check, we can also compute R using (6.1.2).

            V

                             n

The series ° ax has An = a. So

                  n=0

                        R = lim §§ A § n+1 §§ ¡1 § = lim 1 ¡1 = 1
                                  nÑV An                  nÑV

                                              341
POWER SERIES                                        6.1 RADIUS OF CONVERGENCE
as expected.                                                          Example 6.1.4

Example 6.1.5 (Radius of convergence = +V)

            ° V xn 1

The series n! has An = n! . So
n=0
                                                    1¢2¢3¢¤¤¤¢n
§ lim § A § n+1 §§ 1/(n+1)! n! § = lim = lim = lim
nÑV An nÑV 1/n! nÑV (n + 1)! nÑV 1 ¢ 2 ¢ 3 ¢ ¤ ¤ ¤ ¢ n ¢ (n + 1)
              = lim 1
              nÑV n + 1

              =0

     ° V xn

and n! has radius of convergence V. It converges for every x.

       n=0

                                                               Example 6.1.5

Example 6.1.6 (Radius of convergence = 0)

The series ° V n!xn has An = n!. So

                  n=0

lim §§ A § n+1 §§ (n + 1)! § = lim = lim       1 ¢ 2 ¢ 3 ¢ 4 ¢ ¤ ¤ ¤ ¢ n ¢ (n + 1)
nÑV An nÑV n!                        nÑV           1¢2¢3¢4¢¤¤¤¢n

                  = lim (n + 1)                It converges only for x = 0, where
                                                                                 Example
                    nÑV

                  = +V

and ° V n!xn has radius of convergence zero4.                                             it takes
                                                                                          6.1.6
       n=0

the value 0! = 1.

 Example 6.1.7

Comparing the series

                          1 + 2x + x2 + 2x3 + x4 + 2x5 + ¤ ¤ ¤

to

                    ¸ V

                   Anxn =A0+A1x+A2x2+A3x3+A4x4+A5x5+ ¤ ¤ ¤

                               n=1

4 Because of this, it might seem that such a series is fairly pointless. However there are all sorts of
      mathematical games that can be played with them without worrying about their convergence. Such
      "formal" power series can still impart useful information and the interested reader is invited to look up
      "generating functions" with their preferred search engine.

                                                         342
POWER SERIES                                                           6.1 RADIUS OF CONVERGENCE

we see that            A1 = 2      A2 = 1              A3 = 2         A4 = 1        A5 = 2 ¤ ¤ ¤
          A0 = 1

so that                A1 A0 = 2 A2 A1 = 12 A3 A2 = 2 A4 A3 = 12 A5 A4 = 2 ¤ ¤ ¤

and  An+1  does not converge as n            Ñ  V.  Since the limit of the ratios does not exist, we
      An
cannot tell anything from the ratio test. Nonetheless, we can still figure out for which x's
our power series converges.

· Because every coefficient An is either 1 or 2, the nth term in our series obeys

                                §§Anxn§§ ¤ 2|x|n

     and   so  is  smaller  than   the  nth  term  in  the  geometric  series  °V      2|x|n.  This   geometric

                                                                                  n=0
     series converges if |x| 1. So, by the comparison test, our series converges for
     |x| 1 too.

· Since every An is at least one, the nth term in our series obeys

                                 §§Anxn§§ ¥ |x|n

     If |x| ¥ 1, this an = Anxn cannot converge to zero as n Ñ V, and our series diverges

     by the divergence test.

In conclusion, our series converges if and only if |x|                 1, and so has radius of conver-

gence 1.

                                                                                          Example 6.1.7

Example 6.1.8

Lets construct a series from the digits of . Now to avoid dividing by zero, let us set

                                        An = 1 + the nth digit of 

Since  = 3.141591 . . .

     A0 = 4 A1 = 2 A2 = 5 A3 = 2 A4 = 6 A5 = 10 A6 = 2 ¤ ¤ ¤

Consequently every An is an integer between 1 and 10 and gives us the series

                      ¸ V

                    Anxn = 4 + 2x + 5x2 + 2x3 + 6x4 + 10x5 + ¤ ¤ ¤

                                  n=0

The  number        is  irrational  and  consequently   the     ratio  An+1  cannot  have  a    limit  as  n  Ñ  V.
                                                                       An
If you do not understand why this is the case then don't worry too much about it5. As in

5 This is a little beyond the scope of the course. Roughly speaking, think about what would happen if
      the limit of the ratios did exist. If the limit were smaller than 1, then it would tell you that the terms of
      our series must be getting smaller and smaller and smaller -- which is impossible because they are all
      integers between 1 and 10. Similarly if the limit existed and were bigger than 1 then the terms of the
      series would have to get bigger and bigger and bigger -- also impossible. Hence if the ratio exists then
      it must be equal to 1 -- but in that case because the terms are integers, they would have to be all equal
      when n became big enough. But that means that the expansion of  would be eventually periodic --
      something that only rational numbers do.

                                                         343
POWER SERIES                                                     6.1 RADIUS OF CONVERGENCE

the last example, the limit of the ratios does not exist and we cannot tell anything from
the ratio test. But we can still figure out for which x's it converges.

· Because every coefficient An is no bigger (in magnitude) than 10, the nth term in our
   series obeys

                                §§Anxn§§ ¤ 10|x|n

and  so  is   smaller  than  the  nth  term  in  the  geometric  series  °V      10|x|n.  This  geomet-

                                                                            n=0
ric series converges if |x| 1. So, by the comparison test, our series converges for
|x| 1 too.

· Since every An is at least one, the nth term in our series obeys

                                 §§Anxn§§ ¥ |x|n
  If |x| ¥ 1, this an = Anxn cannot converge to zero as n Ñ V, and our series diverges

   by the divergence test.

In conclusion, our series converges if and only if |x|           1, and so has radius of conver-
                                                                                    Example 6.1.8
gence 1.

Though we won't prove it, it is §true t§hat every power series has a radius of conver-
                                       § An+1 §
gence, whether or not the limit   lim
                                       § A § exists.
                                  nÑV n

 Theorem6.1.9.

Let ° V An(x ¡ c)n be a power series. Then one of the following alternatives must

      n=0

hold.

(a) The power series converges for every number x. In this case we say that the

   radius of convergence is V.
(b) There is a number 0 R V such that the series converges for |x ¡ c| R

   and diverges for |x ¡ c| ¡ R. Then R is called the radius of convergence.
(c) The series converges for x = c and diverges for all x $ c. In this case, we say

     that the radius of convergence is 0.

                                                 344
POWER SERIES                                6.1 RADIUS OF CONVERGENCE

Definition6.1.10.

Consider the power series

                            ¸ V

                               An(x ¡ c)n.

                            n=0

The set of real x-values for which it converges is called the interval of conver-
gence of the series.

  Suppose that the power series ° V An(x ¡ c)n has radius of convergence R. Then from

Theorem 6.1.9, we have that n=0

· if R = V, then its interval of convergence is ¡V x V, which is also denoted
  (¡V, V), and

· if R = 0, then its interval of convergence is just the point x = c, and

· if 0 R V, then we know that the series converges for any x which obeys

                   |x ¡ c|  R or equivalently ¡ R x ¡ c R
                               or equivalently c ¡ R x c + R

       But we do not (yet) know whether or not the series converges at the two end points
       of that interval. We do know, however, that its interval of convergence must be one
       of

       ¥ c ¡ R x c + R, which is also denoted (c ¡ R , c + R), or
       ¥ c ¡ R ¤ x c + R, which is also denoted [c ¡ R , c + R), or
       ¥ c ¡ R x ¤ c + R, which is also denoted (c ¡ R , c + R], or
       ¥ c ¡ R ¤ x ¤ c + R, which is also denoted [c ¡ R , c + R].

To reiterate -- while the radius convergence, R with 0 R V, tells us that the series
converges for |x ¡ c| R and diverges for |x ¡ c| ¡ R, it does not (by itself) tell us whether
or not the series converges when |x ¡ c| = R, i.e. when x = c ¨ R. We will not generally

concern ourselves with these final details. (Determining the endpoints of the interval of
convergence often goes smoothest with the Alternating Series Test, which is available for
your interest in Appendix A.12 but is not a part of our syllabus.)

 Example 6.1.11

We are told that a certain power series with centre c = 3, converges at x = 4 and diverges
at x = 1. What else can we say about the convergence or divergence of the series for other
values of x?

                            345
POWER SERIES                        6.1 RADIUS OF CONVERGENCE

  We are told that the series is centred at 3, so its terms are all powers of (x ¡ 3) and it is

of the form

                                                                                          ¸

                                   An(x ¡ 3)n.

                                         n¥0

A good way to summarise the convergence data we are given is with a figure like the one
below. Green dots mark the values of x where the series is known to converge. (Recall
that every power series converges at its centre.) The red dot marks the value of x where
the series is known to diverge. The centre is at x = 3.

              1  34

Can we say more about the convergence and/or divergence of the series for other values
of x? Yes!

    Let us think about the radius of convergence, R, of the series. We know that it must
exist and the information we have been given allows us to bound R. Recall that

  · the series converges at x provided that |x ¡ 3| R and
  · the series diverges at x if |x ¡ 3| ¡ R.

We have been told that

   · the series converges when x = 4, which tells us that

       ¥ x = 4 cannot obey |x ¡ 3| ¡ R so
       ¥ x = 4 must obey |x ¡ 3| ¤ R, i.e. |4 ¡ 3| ¤ R, i.e. R ¥ 1

   · the series diverges when x = 1 so we also know that

       ¥ x = 1 cannot obey |x ¡ 3| R so
       ¥ x = 1 must obey |x ¡ 3| ¥ R, i.e. |1 ¡ 3| ¥ R, i.e. R ¤ 2
We still don't know R exactly. But we do know that 1 ¤ R ¤ 2. Consequently,
  · since 1 is the smallest that R could be, the series certainly converges at x if |x ¡ 3| 1,

       i.e. if 2 x 4 and

  · since 2 is the largest that R could be, the series certainly diverges at x if |x ¡ 3| ¡ 2,
    i.e. if x ¡ 5 or if x 1.

The following figure provides a resume of all of this convergence data -- there is conver-
gence at green x's and divergence at red x's.

              12345
                               346
POWER SERIES                                    6.2 WORKING WITH POWER SERIES

Notice that from the data given we cannot say anything about the convergence or diver-
gence of the series on the intervals (1, 2] and (4, 5].

One lesson that we can derive from this example is that,

· if a series has centre c and converges at a,

· then it also converges at all points between c and a, as well as at all points of distance

  strictly less than |a ¡ c| from c on the other side of c from a.

                                                          Example 6.1.11

6.2 Working With Power Series

     Just as we have done previously with limits, differentiation and integration, we can con-
     struct power series representations of more complicated functions by using those of sim-
     pler functions. Here is a theorem that helps us to do so.

                                                              347
POWER SERIES                                    6.2 WORKING WITH POWER SERIES

Theorem6.2.1 (Operations on Power Series).

Assume that the functions f (x) and g(x) are given by the power series

                       ¸ V                           ¸ V

               f (x) = An(x ¡ c)n            g(x) = Bn(x ¡ c)n

                           n=0                           n=0

for all x obeying |x ¡ c| R. In particular, we are assuming that both power

series have radius of convergence at least R. Also let K be a constant. Then

                ¸ V

f (x) + g(x) = [An + Bn] (x ¡ c)n

                              n=0

                         ¸ V

               K f (x) = K An (x ¡ c)n

                           n=0          for any integer N ¥ 1

                  ¸ V

(x ¡ c)N f (x) = An (x ¡ c)n+N

                   n=0                  where k = n + N

                  ¸ V

               = Ak¡N (x ¡ c)k

                            k=N

               f I(x) = ¸ V An n (x ¡ c)n¡1 = ¸ V An n (x ¡ c)n¡1

               n=0                        n=1
» x f ¸ V (t) dt = An (x ¡ c)n+1
c n=0 n + 1                             + C with C an arbitrary constant
               ¸ V An (x ¡ c)n+1
»              n=0 n + 1

   f (x) dx =

for all x obeying |x ¡ c| R.
In particular the radius of convergence of each of the six power series on the right

                                                                         V

                                                                                                                                            n
hand sides is at least R. In fact, if R is the radius of convergence of ° An(x ¡ c) ,
                                                                   n=0
then R is also the radius of convergence of all of the above right hand sides, with
                    V                           ° V
the possible exceptions of ° [An + Bn] (x ¡ c) and KAn (x ¡ c) when K = 0.nn

                    n=0                         n=0

Example 6.2.2

The last statement of Theorem 6.2.1 might seem a little odd, but consider the following two
power series centred at 0:

                    ¸ V                 ¸ V
                              2nxn and (1 ¡ 2n)xn.

                    n=0                 n=0

                                        348
POWER SERIES                                                                         6.2 WORKING WITH POWER SERIES

The ratio test tells us that they both have radius of convergence                                          R  =  1.   However their

sum is                                                                                                           2

                                      ¸ V                         ¸ V                     ¸ V
                                                       2nxn + (1 ¡ 2n)xn = xn

                                      n=0                         n=0                     n=0

which has the larger radius of convergence 1.
    A more extreme example of the same phenomenon is supplied by the two series

                                                       ¸ V                  ¸ V
                                                            2nxn and (¡2n)xn.

                                                       n=0                  n=0

They    are  both  geometric    series                 with  radius    of   convergence          R  =  1.  But   their  sum  is

                                                                                                       2

                                      ¸ V                         ¸ V                ¸ V
                                                       2nxn + (¡2n)xn = (0)xn

                                     n=0                         n=0                 n=0

which has radius of convergence +V.

                                                                                                                   Example 6.2.2

    We'll now use this theorem to build power series representations for a bunch of func-
tions out of the one simple power series representation that we know -- the geometric
series
                                                       1 = ¸ V xn for all |x| 1
                                      1 ¡ x n=0

Example 6.2.3               1

                          1¡x2

Find    a  power   series  representation                   for     1 2.

                                                                  1¡x

Solution. The secret to finding power series representations for a good many functions
is  to  manipulate        them  into  a                form  in   which       1     appears      and   use    the     geometric  series
                                °V n
                       1                                                    1¡y
representation 1¡y = n=0 y . We have deliberately renamed the variable to y here -- it
does    not  have  to  be  x.   We  can                use  that  strategy      to  find  a  power     series    expansion   for    1

--  we     just  have  to  recognize  that               1       is  the  same   as    1     if  we  set  y  to  x2.              1¡x2

                                                       1¡x2                          1¡y

                       1 = 1 §§§                                       ¸ V  yn            if |y| 1, i.e. |x| 1

                                                    §        =
                   1 ¡ x2 1 ¡ y y=x2
                                                                     n=0 y=x2
                                = ¸ V x2 n                      ¸ V

                                                             = x2n

                                n=0                               n=0

                                = 1 + x2 + x4 + x6 + ¤ ¤ ¤

This is a perfectly good power series. There is nothing wrong with the power of x being 2n.
(This just means that the coefficients of all odd powers of x are zero.) In fact, you should

                                                                       349
POWER SERIES                                                                6.2 WORKING WITH POWER SERIES

try to always write power series in forms that are as easy to understand as possible. The
geometric series that we used at the end of the first line converges for

                        |y| 1 ðñ §§x2§§ 1 ðñ |x| 1
So our power series has radius of convergence 1 and interval of convergence ¡1 x 1.

                                                                                                Example 6.2.3

Example 6.2.4            x
                       2+x2

Find a power series representation for 2+xx2 .

Solution. This example is just a more algebraically involved variant of the last one. Again,
the  strategy  is  to  manipulate              x    into  a  form  in  which     1    appears.
                                             2+x2
                                                                               1¡y

x          x1                             x  1                 set ¡ x2 = 2 y
2 + x2 = 2 1 + x2/2 = 2 1 ¡ ¡x2/2
                                          = x ¸ V yn
         =x        1 §§                                            if |y| 1

                          §
                          §
           2 1 ¡ y y=¡ x2                    2 n=0            x2
                                       2
            x ¸ V                                     y=¡ 2
                       ¡ x2 = 2 2n 2 x = 2n+1 x n x ¸ V (¡1)n 2n ¸ V (¡1)n 2n+1
         =2                                                                                 by Theorem 6.2.1, twice

               n=0                           n=0                       n=0

         = x2 ¡ x4 + 3 x58 ¡ x16 + 7 ¤ ¤ ¤

The geometric series that we used in the second line converges when

               |y| 1 ðñ §§¡x2/ § 2§ 1 ðñ |x|2 2 ðñ |x| c2

Socthe givenc power series has radius of convergence c2 and interval of convergence
¡ 2 x 2.

                                                                                                Example 6.2.4

Example 6.2.5 (Nonzero centre)

Find  a  power  series       representation         for     1  with    centre  3.

                                                          5¡x

Solution. The new wrinkle in this example is the requirement that the centre be 3. That
the centre is to be 3 means that we need a pow°er series in powers of x ¡ c, with c = 3. So
we are looking for a power series of the form                       V       An(x   ¡  3)n.  The  easy  way  to  find  such

                                                                    n=0
a series is to force an x ¡ 3 to appear by adding and subtracting a 3.

                                               1= 1 = 1

                                             5 ¡ x 5 ¡ (x ¡ 3) ¡ 3 2 ¡ (x ¡ 3)

                                                               350
POWER SERIES                                                                       6.2 WORKING WITH POWER SERIES

Now   we  continue,     as  in  the     last  example,       by  manipulating                 1     into  a  form  in  which

  1  appears.                                                                            2¡(x¡3)

1¡y

                1 = 1 = x 1 1 ¡3 set x ¡ 3 = y
          5 ¡ x 2 ¡ (x ¡ 3) 2 1 ¡ 2                                                2

                                        =1         1 §§                    = 1 ¸ V yn               if |y| 1

                                                          §
                                                          §
                                              2 1 ¡ y y= x¡3               2 n=0         y= x¡3
                                                                        2
                                           1 ¸ V                                                2
                                                         x ¡ 3 n ¸ V (x ¡ 3)n
                                        =2                   2=
                                              n=0                          n=0          2n+1

                                        = x ¡ 3 2 + (x ¡ 3) 4 + 8 + 2 (x ¡ 3)3 ¤ ¤ ¤

The geometric series that we used in the second line converges when

      |y| 1 ðñ § 2 § 1 §§ x ¡ 3§§ ðñ |x ¡ 3| 2 ðñ ¡2 x ¡ 3 2 ðñ 1 x 5

So the power series has radius of convergence 2 and interval of convergence 1 x 5.

                                                                                                          Example 6.2.5

    In the previous two examples, to construct a new series from an existing series, we
replaced x by a simple function. The following theorem gives us some more (but certainly
not all) commonly used substitutions.

      Theorem6.2.6 (Substituting in a Power Series).

     Assume that the function f (x) is given by the power series

                                                      ¸ V

                                              f (x) = Anxn

                                                          n=0

     for all x in the interval I. Also let K and k be real constants. Then

                                              f Kxk     ¸ V

                                                     = AnKn xkn

                                                         n=0

     whenever      Kxk  is  in  I.  In  particular,  if  °V                Anxn    has  radius  of  convergence    R,  K
                                                                           °V      AnKn  xkn
         nonz ero  and      is                number,       n=0                                     radius       conver-
     is                 k       a   natural                  then             n=0             has            of
     gence k R/|K|.

Example 6.2.7         1

                   (1¡x)2

Find  a  power  series  representation        for    1 2.

                                                   (1¡x)

                                                             351
POWER SERIES                                                      6.2 WORKING WITH POWER SERIES

Solution.  Once  again  the  trick  is  to  express     1     in  terms  of   1.  Notice  that

                                                     (1¡x)2                  1¡x

                            1 =d 4 1 B

                        (1 ¡ x)2 dx 1 ¡ x

                                 = d ¸ 5 V C xn

                                       dx n=0

                                    ¸ V
                                 = nxn¡1 by Theorem 6.2.1

                                           n=1

Note that the n = 0 term has disappeared because, for n = 0,

                                    ddx xn = ddx x0 = ddx 1 = 0

Also note that the radius of convergence of this series is one. We can see this via Theo-
rem 6.2.1. That theorem tells us that the° radius of convergence of a power series is not
changed by differentiation -- and since              V    xn  has  radius    of  convergence    one,  so   too
does its derivative.
                                                     n=0

    Without much more work we can determine the interval of convergence by testing at

x = ¨1. When x = ¨1 the terms of the series do not go to zero as n Ñ V and so, by the

divergence test, the series does not converge there. Hence the interval of convergence for

the series is ¡1 x 1.

                                                                                                Example 6.2.7

Notice that, in this last example, we differentiated a known series to get to our answer. As
per Theorem 6.2.1, the radius of convergence didn't change. In addition, in this particular
example, the interval of convergence didn't change. This is not always the case. Differ-
entiation of some series causes the interval of convergence to shrink. In particular the
differentiated series may no longer be convergent at the end points of the interval6. Sim-
ilarly, when we integrate a power series the radius of convergence is unchanged, but the
interval of convergence may expand to include one or both ends, as illustrated by the next
example.

Example 6.2.8 (ln(1 + x))

Find a power series representation for ln(1 + x).

                             °V xn
6 Consider the power series n=1 n . We know that its interval of convergence is ¡1°¤ x 1. (Indeed
see the next example.) When we differentiate the series we get the geometric series       V     xn  which  has
interval of convergence ¡1 x 1.
                                                                                          n=0

                                            352
POWER SERIES                                                           6.2 WORKING WITH POWER SERIES

Solution.  Recall  that  d   ln(1  +  x)  =      1  so  that     ln(1  +  t)  is  an  antiderivative  of   1   and
                         dx                    1+x                                                        1+t

                     » ln x (1 + x) = dt                     »x  ¸ V
                                          0 1+t
                                                        =          (¡t)n dt
                                                              0
                                                                 n=0
                                          ¸ V » x   (¡t)n dt
                                                                   by Theorem 6.2.1
                                   =      n=0 0

                                   = ( ¸ V ¡1)n xn+1 n + 1
                                          n=0

                                   = x ¡ x2 + 2 x33 ¡ x4 + 4 ¤ ¤ ¤

Theorem 6.2.1 guarantees that th° e radius of convergence is exactly one (the radius of con-
vergence of the geometric series          V    (¡t)n)    and     that

                                          n=0

                   ln(1 + x) = ( ¸ V ¡1)n xn+1 n + 1             for all ¡ 1 x 1

                                       n=0

In general, we won't worry about the endpoints of the interval of convergence. So, in
general, we wouldn't bother testing x = 1 and x = ¡1. However, in this instance, both
examples are pretty accessible. We incl° ude them below for interest.
When x = ¡1 our series reduces to                   V    ¡1 ,    which    is  (minus)    the  harmonic    series  and

                                                    n=0  n+1
so diverges. That's no surprise: ln(1 + (¡1)) = ln 0 is undefined, with lim ln x = ¡V.
                                                                                              xÑ0+
When x = 1, we get the alternating harmonic series, which converges. (It is possible to
prove by continuity, though we won't do so here, that the sum is ln 2.)
So the interval of convergence is ¡1 x ¤ 1.

                                                                                              Example 6.2.8

Example 6.2.9 (arctan x)

Find a power series representation for arctan x.

Solution.  Recall  that  d   arctan x  =    1       so  that  arctan t    is  an  antiderivative  of      1   and
                         dx               1+x2                                                          1+t2

           arctan x           »x   dt » x           ( ¸ V ¡t2)n        dt =       ¸ V » x  (¡1)nt2n dt
                                      2=
                         =                          n=0
                             0 1+t             0                                  n=0 0

                         = ( ¸ V ¡1)n x2n+1 2n + 1

                              n=0

                         = x ¡ x3 + 3 x55 ¡ ¤ ¤ ¤

Theorem 6.2.1 guarantees that th° e radius of convergence is exactly one (the radius of con-

vergence of the geometric series Vn=0(¡t2)n) and that

                     arctan x = ( ¸ V ¡1)n x2n+1 2n + 1                for all ¡1 x 1

                                         n=0

                                                        353
POWER SERIES                                      6.3 EXTENDING TAYLOR POLYNOMIALS

Since we're not generally concerned with the endpoints of the interval of convergence,

we'll leave as a mystery whether the series converges at x = 1 and x = ¡1.

                                                                                                Example 6.2.9

    The operations on power series dealt with in Theorem 6.2.1 are fairly easy to apply.
Unfortunately taking the product, ratio or composition of two power series is more in-
volved and is beyond the scope of this course7. Unfortunately Theorem 6.2.1 alone will
not get us power series representations of many of our standard functions (like ex and
sin x). Fortunately we can find such representations by extending Taylor polynomials8 to
Taylor series.

6.3 Extending Taylor Polynomials

Recall9 that Taylor polynomials provide a hierarchy of approximations to a given function
f (x) near a given point a. Typically, the quality of these approximations improves as we
move up the hierarchy.

  · The crudest approximation is the constant approximation f (x)  f (a).
  · Then comes the linear, or tangent line, approximation f (x)  f (a) + f I(a) (x ¡ a).

· Then comes the quadratic approximation

                   f (x)  f (a) + f I(a) (x ¡ a) + 12 f P(a) (x ¡ a)2

· In general, the Taylor polynomial of degree n, for the function f (x), about the ex-
pansion point a, is the polynomial, Tn(x), determined by the requirements that
                (k)             ¤     ¤
f (k)(a)  =                        k     n.  That is,  f  and Tn have the same derivatives
              Tn (a) for all 0
at a, up to order n. Explicitly,

f (x)  Tn(x) = f (a) + f I(a) (x ¡ a) + 12 f P(a) (x ¡ a)2 + ¤ ¤ ¤ + 1n! f (n)(a) (x ¡ a)n
           = ¸ f n 1 (k)(a) (x ¡ a)k

                     k=0 k!

These are, of course, approximations -- often very good approximations near x = a -- but
still just approximations. One might hope that if we let the degree, n, of the approximation
go to infinity then the error in the approximation might go to zero. If that is the case then
the "infinite" Taylor polynomial would be an exact representation of the function. Let's
see how this might work.

    Fix a real number a and suppose that all derivatives of the function f (x) exist. Then,
for any natural number n,

7 As always, a quick visit to your favourite search engine will direct the interested reader to more infor-
      mation.

8 Now is a good time to review your notes from last term, though we'll give you a whirlwind review
      over the next page or two.

9 Please review your notes from last term if this material is feeling a little unfamiliar.

                                             354
POWER SERIES                           6.3 EXTENDING TAYLOR POLYNOMIALS

                                                                      Equation 6.3.1.

                                 f (x) = Tn(x) + En(x)

where Tn(x) is the Taylor polynomial of degree n for the function f (x) expanded about a,

and En(x) = f (x) ¡ Tn(x) is the error in our approximation. The Taylor polynomial10 is

given by the formula

                                                                      Equation 6.3.1-a

              Tn(x)  =  f (a) +  f I(a) (x ¡ a) + ¤ ¤ ¤ +  1   f (n)(a) (x ¡ a)n
                                                           n!

while the error satisfies                                             Equation 6.3.1-b

                        En(x) = 1 f (n+1)(c) (x ¡ a)n+1

                                                              (n+1)!

for some c strictly between a and x. Note that we typically do not know the value of c in
the formula for the error. Instead we use the bounds on c to find bounds on f (n+1)(c) and
so bound the error11.

    In order for our Taylor polynomial to be an exact representation of the function f (x)
we need the error En(x) to be zero. This will not happen when n is finite unless f (x) is a

polynomial. However it can happen in the limit as n Ñ V, and in that case we can write

f (x) as the limit

              f (x) = lim Tn(x) = lim  ¸ n  1 f (k)(a) (x ¡ a)k

                        nÑV nÑV k=0         k!

This is really a limit of partial sums, and so we can write

                        f (x) =  ¸ V  1 f (k)(a) (x ¡ a)k

                                 k=0  k!

which is a power series representation of the function. Let us formalise this in a definition.

10 Did you take a quick look at your notes?
11 The discussion here is only supposed to jog your memory. If it is feeling insufficiently jogged, then

      please look at your notes from last term.

                                                         355
POWER SERIES                                                     6.3 EXTENDING TAYLOR POLYNOMIALS

     Definition6.3.2 (Taylor series).

     The Taylor series for the function f (x) expanded around a is the power series

                                           ¸ V

                                              1 f (n)(a) (x ¡ a)n

                                                 n!
                                           n=0

     provided the series converges. When a = 0 it is also called the Maclaurin series
     of f (x).

     If lim En = 0, then                        ¸ V

       nÑ0

                                      f (x) =        1 f (n)(a) (x ¡ a)n.

                                                n=0  n!

We generally use Taylor series as an alternate way of representing a function. If f (x) is too
                                              °V      1      (n)(a)      ¡   a)n,
difficult to work with, and if     f  (x)  =          n!  f          (x            then  working  with   the  series
                                                 n=0
may be easier, since the series has many characteristics in common with polynomials.
                                             $  °V        1      (n)(a)      ¡  a)n,
     Unfortunately,  sometimes        f (x)               n!  f          (x           even  when  the  series  con-
                                                   n=0
verges. That's why checking En Ñ 0 is important. Demonstrating that for an arbitrary
function can be difficult, but for many of the standard functions you are used to dealing
with, it turns out to be pretty easy. Let's compute a few Taylor series and see how we do
it.

Example 6.3.3 (Exponential Series)

     Find the Maclaurin series12 for f (x) = ex.

Solution. Just as was the case for computing Taylor polynomials, we need to compute the
derivatives of the function at the particular choice of a. Since we are asked for a Maclaurin
series, a = 0. So now we just need to find f (k)(0) for all integers k ¥ 0.
     We  know  that  d ex     ex  and  so
                           =
                     dx

         ex = f (x) = f I(x) = f P(x) = ¤ ¤ ¤ = f (k)(x) = ¤ ¤ ¤                            which gives

         1 = f (0) = f I(0) = f P(0) = ¤ ¤ ¤ = f (k)(0) = ¤ ¤ ¤ .

Equations (6.3.1) and (6.3.1-a) then give us

                           ex = f (x) = 1 + x + x2! + 2 ¤ ¤ ¤ + xn! + n En(x)

We shall see, in the optional Example 6.3.6 below, that, for any fixed x, lim En(x) = 0.

                                                                                 nÑV

Consequently, for all x,

               ex = lim 1 + x + 1 x2 + 1 x3 + ¤ ¤ ¤ + 1 xn = ¸ V 1 xn
                     nÑV                      2 3!                       n!                 n!
                                                                                      n=0

12 Taylor series centred at a = 0

                                                      356
POWER SERIES                                                       6.3 EXTENDING TAYLOR POLYNOMIALS

                                                                                                        Example 6.3.3

We have now seen power series representations for the functions

  1                       1                        ln(1 + x)                               arctan(x)    ex.

1¡x                   (1 ¡ x)2

We do not think that you, the reader, will be terribly surprised to see that we develop
series for sine and cosine next.

 Example 6.3.4 (Sine and Cosine Series)

The trigonometric functions sin x and cos x also have widely used Maclaurin series ex-
pansions (i.e. Taylor series expansions about a = 0). To find them, we first compute all
derivatives at general x.

 f (x) = sin x f I(x) = cos x f P(x) = ¡ sin x f (3)(x) = ¡ cos x f (4)(x) = sin x ¤ ¤ ¤
 g(x) = cos x gI(x) = ¡ sin x gP(x) = ¡ cos x g(3)(x) = sin x g(4)(x) = cos x ¤ ¤ ¤

Now set x = a = 0.

    f (x) = sin x f (0) = 0 f I(0) = 1 f P(0) = 0 f (3)(0) = ¡1 f (4)(0) = 0 ¤ ¤ ¤
    g(x) = cos x g(0) = 1 gI(0) = 0 gP(0) = ¡1 g(3)(0) = 0 g(4)(0) = 1 ¤ ¤ ¤

For sin x, all even numbered derivatives (at x = 0) are zero, while the odd numbered

derivatives alternate between 1 and ¡1. Very similarly, for cos x, all odd numbered deriva-
tives (at x = 0) are zero, while the even numbered derivatives alternate between 1 and ¡1.

So, the Taylor polynomials that best approximate sin x and cos x near x = a = 0 are

                               sin     x       x  ¡   1   x3    +  1     x5    ¡  ¤  ¤  ¤
                                                      3!           5!
                                                  ¡   1   x2       1   x4      ¡  ¤  ¤  ¤
                               cos     x       1      2!        +  4!

We shall see, in the optional Example 6.3.8 below, that, for both sin x and cos x, we have
lim En(x) = 0 so that

nÑV

              f (x) = lim              f  (0)  +   f  I(0)      x  +  ¤  ¤  ¤  +  1     f  (n)(0)   xn
                            nÑV                                                   n!

              g(x) = lim            g(0)       +   gI(0)        x  +  ¤  ¤  ¤  +  1     g(n)(0)     xn
                            nÑV                                                   n!

Reviewing the patterns we found in the derivatives, we conclude that, for all x,

                                                ¸ V3!5!

              sin x = x ¡ 1 x3 + 1 x5 ¡ ¤ ¤ ¤ = (¡1)n 1 x2n+1
                                                                                           (2n+1)!
                                                                   n=0
                                                                   ¸ V
              cos  x     1  ¡  1   x2     1    x4  ¡  ¤   ¤  ¤              (¡1)n 1 x2n
                      =        2!      +  4!                    =
                                                                                      (2n)!
                                                                   n=0

                                                      357
POWER SERIES                      6.3 EXTENDING TAYLOR POLYNOMIALS

and, in particular, both of the series on the right hand sides converge for all x.
    We could also test for convergence of the series using the ratio test. Computing the

ratios of successive terms in these two series gives us

              §§§ An+1 §§§ = |x|2n+3/(2n + 3)! = |x|2

                                   2n+1
              § An § |x| /(2n + 1)! (2n + 3)(2n + 2)
              §§§ An+1 §§§ = |x|2n+2/(2n + 2)! = |x|2
                                          2n
              § An §  |x| /(2n)!  (2n + 2)(2n + 1)

for sine and cosine respectively. Hence as n Ñ V these ratios go to zero and consequently

both series are convergent for all x. (This is very similar to what was observed in Exam-
ple 6.1.5.)

                                                                                                Example 6.3.4

    We have developed power series representations for a number of important func-
tions13 . Here is a theorem that summarizes them.

13 The reader might ask whether or not we will give the series for other trigonometric functions or their
      inverses. While the tangent function has a perfectly well defined series, its coefficients are not as simple
      as those of the series we have seen -- they form a sequence of numbers known (perhaps unsurprisingly)
      as the "tangent numbers". They, and the related Bernoulli numbers, have many interesting properties,
      links to which the interested reader can find with their favourite search engine. The Maclaurin series
      for inverse sine is

                                    arcsin(x) = 2n + 1 (n!)2 ¸ V 4¡n (2n)! x2n+1

                                                                                  n=0

      which is quite tidy, but proving it is beyond the scope of the course.

                                                         358
POWER SERIES                                             6.3 EXTENDING TAYLOR POLYNOMIALS

    Theorem6.3.5.

          ex = ¸ V xn                         = 1 + x + 1 x2 + 1 x3 + ¤ ¤ ¤      for all ¡V x V
                  n=0 n!                                 2! 3!                   for all ¡V x V
                                                                                 for all ¡V x V
    sin(x) = ( ¸ V ¡1)n 1 x2n+1 = x ¡ 1 x3 + 1 x5 ¡ ¤ ¤ ¤                        for all ¡1 x 1
                  n=0 (2n + 1)!                    3! 5!                         for all ¡1 x ¤ 1
                                                                                 for all ¡1 ¤ x ¤ 1
    cos(x) = ( ¸ V ¡1)n 1 x2n                 = 1 ¡ 1 x2 + 1 x4 ¡ ¤ ¤ ¤
                  n=0 (2n)!                        2! 4!

          1 = ¸ V xn                          = 1 + x + x2 + x3 + ¤ ¤ ¤
    1 ¡ x n=0
ln(1 + x) = ( ¸ V ¡1)n xn+1
                                              = x ¡ x + 2 x3 ¡ x + 4 ¤ ¤ ¤
                  n=0 n + 1                        2 34

    arctan x = ( ¸ V ¡1)n x2n+1               = x ¡ x + 3 x5 ¡ ¤ ¤ ¤
                  n=0 2n + 1                       35

    Notice that the series for sine and cosine sum to something that looks very similar to
the series for ex:

          sin(x) + cos(x) = x ¡ 13! x3 + 15! x5 ¡ ¤ ¤ ¤ + 1 ¡ 12! x2 + 14! x4 ¡ ¤ ¤ ¤

                            = 1 + x ¡ 12! x2 ¡ 13! x3 + 14! x4 + 15! x5 ¡ ¤ ¤ ¤
                          ex = 1 + x + 1 x2 + 1 x3 + 1 x4 + 1 x5 + ¤ ¤ ¤

                                           2! 3! 4! 5!

So  both  series  have    coefficients  with  the  same  absolute  value  (namely  1 ),  but  there  are
differences in sign14.
                                                                                   n!

Example 6.3.6                        °V 1 n x

                  Optional -- Why n=0 n! x is e .

    We have already seen, in Example 6.3.3, that

                          ex = 1 + x + x2! + 2 ¤ ¤ ¤ + xn! + n En(x)

By (6.3.1-b)                            En(x) = 1 (n + 1)! ecxn+1

for some (unknown) c between 0 and x. Fix any real number x. We'll now show that En(x)

converges to zero as n Ñ V.

14 Warning: antique sign-sine pun. No doubt the reader first saw it many years syne.

                                                         359
POWER SERIES                                   6.3 EXTENDING TAYLOR POLYNOMIALS

    To do this we need get bound the size of ec, and to do this, consider what happens if x
is positive or negative.

  · If x 0 then x ¤ c ¤ 0 and hence ex ¤ ec ¤ e0 = 1.

  · On the other hand, if x ¥ 0 then 0 ¤ c ¤ x and so 1 = e0 ¤ ec ¤ ex.
In either case we have that 0 ¤ ec ¤ 1 + ex. Because of this the error term

                    |En(x)| = § (n + 1)! x § §§ ec n+1§§ ¤ [ex + 1] |x|n+1 (n + 1)!

We claim that this upper bound, and hence the error En(x), quickly shrinks to zero as

n Ñ V.

    Call the upper bound (except for the factor ex + 1, which is independent of n) en(x) =

|x|n+1

(n+1)! . To show that this shrinks to zero as n Ñ V, let's write it as follows.

                                                                   hkkkkkkkkkkkknkk+kkk1i fakcktkokrkskkkkkkkkkkkkj

                 en(x) = |x| (n + 1)! = n+1 |x|1 ¤ |x|2 ¤ |x|3 ¤ ¤ ¤ |x|n ¤ | |x| n + 1|

Now let k be an integer bigger than |x|. We can split the product

                            hkkkkkkkkkkkkkfkai ctokkrkskkkkkkkkkkj  |x| k + 1 ¤ ¤ ¤ | |x| n + 1|
                                                                     |x| n+1¡k
              en(x) = |x|1 ¤ |x|2 ¤ |x|3 ¤ ¤ ¤ |x|k ¤
                                                                    k+1
                   ¤ |x| ¤ |x| ¤ |x| ¤ ¤ ¤ |x| ¤

                            123 k

                                 looooooooooooomooooooooooooon

              = Q(x) ¤       =Q(x)  n+1¡k

                              |x|

                             k+1

Since k does not depend not n (though it does depend on x), the function Q(x) does not
change as we increase n. Additionally, we know that |x|                               |x|
we let n Ñ V the above bound must go to zero.                                                                             1. Hence as
                                                                        k + 1 and so k+1

Alternatively, compare en(x) and en+1(x).

                                         |x|n+2

                             en+1(x) (n+2)! |x|

                              en(x) = |x|n+1 = n + 2

                                                (n+1)!

When n is bigger than, for example 2|x|, we have ene+n(1x(x))           1.  That                                     is,  increasing  the  index

                                                                        2
on en(x) by one decreases the size of en(x) by a factor of at least two. As a result en(x)
must tend to zero as n Ñ V.
Consequently, for all x, lim En(x) = 0, as claimed, and we really have
                   nÑV

              ex = lim 1 + x + 1 x2 + 1 x3 + ¤ ¤ ¤ + 1 xn = ¸ V 1 xn
              nÑV            2 3!                                   n!                                               n!
                                                                            n=0

                                    360
POWER SERIES                                       6.3 EXTENDING TAYLOR POLYNOMIALS

                                                                                    Example 6.3.6

                                                       °V xn                                       x
There is another way to prove that the series n=0 n! converges to the function e .
Rather than looking at how the error term En(x) behaves as n Ñ V, we can show that
the series satisfies the same simple differential equation15 and the same initial condition
as the function.

Example 6.3.7     Optional  --  Another  approach  to  showing    that  °V      1   xn  is  ex.
                                                                                n!
                                                                           n=0

                                                            °V 1 n

We already know from Example 6.1.5, that the series n=0 n! x converges to some func-
tion f (x) for all values of x . All that remains to do is to show that f (x) is really ex. We will
do this by showing that f (x) and ex satisfy the same differential equation with the same
initial conditions16. We know that y = ex satisfies

                      dy dx = y and y(0) = 1
and by Theorem 3.9.10 (with a = 1, b = 0 and y(0) = 1), this is the only solution. So it

                               °V xn

suffices to show that f (x) = n=0 n! satisfies

                  d f dx = f (x) and f (0) = 1.

· By Theorem 6.2.1,

                  d f = d ¸ 5 V 1 xn ¸ C V = n xn¡1 ¸ V = 1 xn¡1
                  dx dx n=0 n!           n=1 n!                   n=1 (n ¡ 1)!

                                         hkkni =3kkj hkkni =4kkj
                     hkkni =1kkj hkkni =2kkj = 1 + x + x2 + x3 + ¤ ¤ ¤
                                         2!            3!
                     = f (x)

   · When we substitute x = 0 into the series we get (see the discussion after Defini-
       tion 6.1.1)

                             f (0) = 1 + 01! + 02! + ¤ ¤ ¤ = 1.

Hence f (x) solves the same initial value problem and we must have f (x) = ex.

15 Recall, you studied that differential equation in the section on separable differential equations (Theo-
      rem 3.9.10 in Section 3.9) as well as wayyyy back in the section on exponential growth and decay in
      differential calculus.

16 Recall that when we solve of a separable differential equation our general solution will have an arbitrary
      constant in it. That constant cannot be determined from the differential equation alone and we need
      some extra data to find it. This extra information is often information about the system at its beginning
      (for example when position or time is zero) -- hence "initial conditions". Of course the reader is already
      familiar with this because it was covered back in Section 3.9.

                                         361
POWER SERIES                                         6.4 COMPUTING WITH TAYLOR SERIES

                                                                                    Example 6.3.7

    We can show that the error terms in Maclaurin polynomials17 for sine and cosine go to

zero as n Ñ V using very much the same approach as in Example 6.3.6.

                           °V (¡1)n 2n+1                                        °V (¡1)n 2n
Example 6.3.8 Optional -- Why n=0 (2n+1)! x = sin x and n=0 (2n)! x = cos x

Let f (x) be either sin x or cos x. We know that every derivative of f (x) will be one

of ¨ sin(x) or ¨ cos(x). Con§sequently§, when we compute the error term using equa-
tion (6.3.1-b) we always have § f (n+1)(c)§ ¤ 1 and hence

                              |En(x)| ¤ |x|n+1 (n + 1)! .

                                       |x|n+1

In Example 6.3.3, we showed that (n+1)! Ñ 0 as n Ñ V -- so all the hard work is already

done. Since the error term shrinks to zero for both f (x) = sin x and f (x) = cos x, and

              f (x) = lim  f  (0)  +  f  I(0)  x  +  ¤  ¤  ¤  +  1   f  (n)(0)  xn
              nÑV                                                n!

as required.

                                                                                    Example 6.3.8

6.4 Computing with Taylor Series

     Taylor series have a great many applications. (Hence their place in this course.) One of
     the most immediate of these is that they give us an alternate way of computing many
     functions. For example, the first definition we see for the sine and cosine functions is
     in terms of triangles. Those definitions, however, do not lend themselves to computing
     sine and cosine except at very special angles. Armed with power series representations,
     however, we can compute them to very high precision at any angle. To illustrate this,
     consider the computation of  -- a problem that dates back to the Babylonians.

      Example 6.4.1 (Computing the number )
     There are numerous methods for computing  to any desired degree of accuracy18. Many
     of them use the Maclaurin expansion19

                              arctan x = ( ¸ V ¡1)n x2n+1 2n + 1

                                                                               n=0

      17 Taylor polynomials centred at a = 0
      18 The computation of  has a very, very long history and your favourite search engine will turn up many

            sites that explore the topic. For a more comprehensive history one can turn to books such as "A history
            of Pi" by Petr Beckmann and "The joy of " by David Blatner.
      19 Taylor expansion centred at a = 0

                                                              362
POWER SERIES                                                    6.4 COMPUTING WITH TAYLOR SERIES

of  Theorem        6.3.5.  Since  arctan(1)  =  ,  the  series  gives  us  a  very  pretty  formula  for  :

                                                4

                                   = arctan 1 = ¸ V (¡1)n

                                  4 n=0 2n + 1

                                                 = 4 1 ¡ 13 + 15 ¡ 17 + ¤ ¤ ¤

Unfortunately, this series is not very useful for computing  because it converges so
slowly. If we approximate the series by its Nth partial sum, then the alternating series
test (Theorem A.12.1 in the appendix) tells us that the error is bounded by the first term
we drop. To guarantee that we have 2 decimal digits of  correct, we need to sum about
the first 200 terms!
     A much better way to compute  using this series is to take advantage of the fact that
tan        c1   :
     6  =    3

                                    1 ¸ V n 1                   c 2n+1 1

                    = 6 arctan c = 6 (¡1)
                                  3                        2n + 1 ( 3)
                                                n=0
                   = 2c3 ( ¸ V ¡1)n n=0 2n + 1 3n 1 1
                   = 2c3 1 ¡ 1 + 1 ¡ 1 + 1 ¡ 1 + ¤ ¤ ¤
                                  3 ¢ 3 5 ¢ 9 7 ¢ 27 9 ¢ 81 11 ¢ 243

Again, this is an alternating series and so (via Theorem A.12.1 in the appendix) the error
we introduce by truncating it is bounded by the first term dropped. For example, if we
keep ten terms, stopping at n = 9, we get  = 3.141591 (to 6 decimal places) with an error
between zero and                                2c3

                                                       10  3 ¢ 10¡6
                                             21 ¢ 3
In 1699, the English astronomer/mathematician Abraham Sharp (1653-1742) used 150
terms of this series to compute 72 digits of  -- by hand!
     This is just one of very many ways to compute . Another one, which still uses the
Maclaurin expansion20 of arctan x, but is much more efficient, is

                          = 16 arctan 15 ¡ 4 arctan 1 239

This formula was used by John Machin in 1706 to compute  to 100 decimal digits --
again, by hand.

    (You won't be asked to compute errors using Theorem A.12.1, but we include them
here for interest.)

                                                                                                Example 6.4.1

    Power series also give us access to new functions which might not be easily expressed
in terms of the functions we have been introduced to so far. The following is a good
example of this.

20 Taylor expansion centred at a = 0

                                                         363
POWER SERIES                                      6.4 COMPUTING WITH TAYLOR SERIES

Example 6.4.2 (Error function)

The error function                         2 » x ¡t2

                                erf(x) = c e dt

                                              0

is used in computing "bell curve" probabilities. The indefinite integral of the integrand

e¡t2 cannot be expressed in terms of standard functions. But we can still evaluate the

integral to within any desired degree of accuracy by using the Taylor expansion of the
exponential. Start with the Maclaurin series21 for ex:

                                ex = ¸ V 1 xn

                                      n=0 n!

and then substitute x = ¡t2 into this:
                              e¡t2 = ¸ V (¡1)n t2n

                                                       n=0 n!

We can then apply Theorem 6.2.1 to integrate term-by-term:

                           erf(x) = c2 » x ¸ V (¡t2)n          dt

                                        0 n=0 n!
                                    2 ¸ V n
                                                  x2n+1
                                = c (¡1)
                                        n=0      (2n + 1)n!

For example, for the bell curve, the probability of being within one standard deviation of
the mean22, is

                    2 ¸ V       1 c 2n+1          ¸ V
erf 1/ 2 = c (¡1)nc             ( / 2)       =c2                   1
                                                    (¡1)n
                                                                         n
                     n=0        (2n + 1)n!       2 n=0             (2n + 1)2 n!

                    2 1 1 1 1
                    =  1 ¡ 3 ¢ 2 + 5 ¢ 22 ¢ 2 ¡ 7 ¢ 23 ¢ 3! + 9 ¢ 24 ¢ 4! ¡ ¤ ¤ ¤

This is yet another alternating series. If we keep five terms, stopping at n = 4, we get
0.68271 (to 5 decimal places) with, by Theorem A.12.1 in the appendix again, an error
between zero and the first dropped term, which is minus

                           2 1                   2 ¢ 10¡5

                              11 ¢ 25 ¢ 5!

(You won't be asked to compute such an error, but we include it for interest.)
                                                                                            Example 6.4.2

21 Taylor series centred at a = 0
22 If you don't know what this means (forgive the pun) don't worry, because it is not part of the course.

      Standard deviation a way of quantifying variation within a population.

                                                         364
POWER SERIES                         6.4 COMPUTING WITH TAYLOR SERIES

Example 6.4.3

Evaluate               n3n ¸ V (¡1)n¡1 and n3n ¸ V 1

               n=1                   n=1

Solution. There are not very many series that can be easily evaluated exactly. But occa-
sionally one encounters a series that can be evaluated simply by realizing that it is exactly
one of the series in Theorem 6.3.5, just with a specific value of x. The left hand given series

¸ is V (¡1)n¡1 1 1 1 1 1 1 1 1
                              n = ¡ 2 + 3 ¡ 4 +¤¤¤

                           n=1 n 3 3 2 3 3 3 4 3

The series in Theorem 6.3.5 that this most closely resembles is

               ln(1 + x) = x ¡ x2 + 2 x33 ¡ x44 ¡ ¤ ¤ ¤

Indeed

               n=1 n 3n = ¸ V (¡1)n¡1 1 13 ¡ 2 32 1 1 + 3 33 1 1 ¡ 4 34 1 1 + ¤ ¤ ¤

                              = x ¡ x + 2 x3 ¡ x4 ¡ ¤ ¤ ¤
                              2 34                               x= 1
                                                                     3

                              = ln(1 + x) 1

                                                      x= 3

                              = ln 43

The right hand series above differs from the left hand series above only that the signs of
the left hand series alternate while those of the right hand series do not. We can flip every
second sign in a power series just by using a negative x.

               ln(1 + x) 1 = x ¡ x + 2 x3 ¡ x4 ¡ ¤ ¤ ¤
                       x=¡ 3  2 34                               x=¡ 31

                              = ¡13 ¡ 2 32 1 1 ¡ 3 33 1 1 ¡ 4 34 1 1 + ¤ ¤ ¤

which is exactly minus the desired right hand series. So

               n = ¸ V 1 ¡ ln(1 + x) 1 = ¡ ln 2 = ln 3      3
               n=1 n3         x=¡ 3                              2

                                                                                     Example 6.4.3

 Example 6.4.4
Let f (x) = sin(2x3). Find f (15)(0), the fifteenth derivative of f at x = 0.

                                                         365
POWER SERIES                                                          6.4 COMPUTING WITH TAYLOR SERIES

Solution. This is a bit of a trick question. We could of course use the product and chain
rules to directly apply fifteen derivatives and then set x = 0, but that would be extremely
tedious23. There is a much more efficient approach that exploits two pieces of knowledge
that we have.

· From equation (6.3.1-a), we see that the coefficient of (x ¡ a)n in the Taylor series of
f (x) with expansion point a is exactly                     1 f (n)(a).      So  f (n)(a) is exactly n! times the

                                                            n!
coefficient of (x ¡ a)n in the Taylor series of f (x) with expansion point a.

· We know, or at least can easily find, the Taylor series for sin(2x3).

Let's apply that strategy.

· First, we know that, for all y,

                                        sin y = y ¡ 13! y3 + 15! y5 ¡ ¤ ¤ ¤

· Just substituting y = 2x3, we have

                    sin(2x3) = 2x3 ¡ 13! (2x3)3 + 15! (2x3)5 ¡ ¤ ¤ ¤
                            = 2x3 ¡ 8 x9 + 25 x15 ¡ ¤ ¤ ¤

                                                      3! 5!

· So the coefficient of x15 in the Taylor series of f (x) = sin(2x3) with expansion point

                   25

   a = 0 is 5!

and we have                    f (15)(0) = 15! ¢ 25! = 5 348,713,164,800

                                                                                      Example 6.4.4

Example 6.4.5 (Optional -- Computing the number e)

Back in Example 6.3.6, we saw that

              e = 1 + x + 2! + ¤ ¤ ¤ + n! + (n+1)! e xx2          xn
                            x                                                1 c n+1

for some (unknown) c between 0 and x. This can be used to approximate the number e,
with any desired degree of accuracy. Setting x = 1 in this equation gives

                               e  =  1  +  1  +   1   +  ¤  ¤  ¤  +   1   +    1 ec
                                                  2!                  n!
                                                                             (n+1)!

23 We could get a computer algebra system to do it for us without much difficulty -- but we wouldn't
      learn much in the process. The point of this example is to illustrate that one can do more than just
      represent a function with Taylor series. More on this in the next section.

                                                      366
POWER SERIES                                                           6.4 COMPUTING WITH TAYLOR SERIES

for some c between 0 and 1. Even though we don't know c exactly, we can bound that

term quite readily. We do know that ec in an increasing function24 of c, and so 1 = e0 ¤
ec ¤ e1 = e. Thus we know that

                             1        ¤e¡   1   +   1  +  1   +  ¤  ¤  ¤  +  1   ¤  e
                                                          2!                 n!
                          (n + 1)!                                                  (n + 1)!

So we have a lower bound on the error, but our upper bound involves the e -- precisely
the quantity we are trying to get a handle on.
    But all is not lost. Let's look a little more closely at the right-hand inequality when
n = 1:
                    e ¡ (1 + 1) ¤ e2
                                                                 move the e's to one side

                                2e ¤2                                            and clean it up

                                  e ¤ 4.

Now this is a pretty crude bound25 but it isn't hard to improve. Try this again with n = 2:

                    e ¡ (1 + 1 + 12 ) ¤ e6                                 move e's to one side
                               5e ¤ 5

                                     62

                                e ¤ 3.

Better. Now we can rewrite our bound:                                      ¤ e (n + 1)! ¤ 3 (n + 1)!

             1 (n + 1)! ¤ e ¡ 1 + 1 + 21! + ¤ ¤ ¤ + n1!

If we set n = 4 in this we get

                          1 120 = 15! ¤ e ¡ 1 + 1 + 12 + 16 + 124 ¤ 3 120

So  the  error  is  between   1   and   3   =   1   --  this  approximation         isn't  guaranteed    to   give  us
                             120       120      40
the first 2 decimal places. If we ramp n up to 9 however, we get

                                110! ¤ e ¡ 1 + 1 + 12 + ¤ ¤ ¤ + 19! ¤ 310!

Since  10!  =   3628800,  the  upper   bound    on     the  error      is      3        3      =  10¡6,  and  we  can
                                                                           3628800  3000000
approximate e by

    1+1+ 1 + 1 + 1 + 1 + 1 + 12!3!4!        5!            6!                 7!     +1     8!         +1 9!

=1 + 1 + 0.5 + 0.16 + 0.0416 + 0.0083 + 0.00138 + 0.0001984 + 0.0000248 + 0.0000028

=2.718282

and it is correct to six decimal places.

                                                                                                  Example 6.4.5

24 Check the derivative!
25 The authors hope that by now we all "know" that e is between 2 and 3, but maybe we don't know how

      to prove it.

                                                         367
POWER SERIES                              6.5 EVALUATING LIMITS USING TAYLOR EXPANSIONS

6.5 Evaluating Limits using Taylor Expansions

Taylor polynomials provide a good way to understand the behaviour of a function near a
specified point and so are useful for evaluating complicated limits. Here are some exam-
ples.

 Example 6.5.1

In this example, we'll start with a relatively simple limit, namely

                                                lim sin x

                                                xÑ0 x

The first thing to notice about this limit is that, as x tends to zero, both the numerator, sin x,
and the denominator, x, tend to 0. So we may not evaluate the limit of the ratio by simply
dividing the limits of the numerator and denominator. To find the limit, or show that it
does not exist, we are going to have to exhibit a cancellation between the numerator and
the denominator. Let's start by taking a closer look at the numerator. By Example 6.3.4,

                                     sin x = x ¡ 13! x3 + 15! x5 ¡ ¤ ¤ ¤

Consequently26                       sin x x = 1 ¡ 13! x2 + 15! x4 ¡ ¤ ¤ ¤

Every term in this series, except for the very first term, is proportional to a strictly positive
power of x. Consequently, as x tends to zero, all terms in this series, except for the very
first term, tend to zero. In fact the sum of all terms, starting with the second term, also
tends to zero. That is,
                           lim ¡ 1 x2 + 1 x4 ¡ ¤ ¤ ¤ = 0
                           xÑ0 3!                        5!

We won't justify that statement here, but it will be justified in the following (optional)
subsection. So

                           lim sin x = lim 1 ¡ 1 x2 + 1 x4 ¡ ¤ ¤ ¤
                           xÑ0 x          xÑ0            3!           5!
                                     = 1 + lim ¡ 1 x2 + 1 x4 ¡ ¤ ¤ ¤
                                                xÑ0 3!                    5!

                                     =1

26 We are hiding some mathematics behind this "consequently". What we are really using our knowledge
      of Taylor polynomials to write

                           f (x) = sin(x) = x ¡ 13! x3 + 15! x5 + E5(x)

                            f (6)(c) 6

where E5(x) = 6! x and c is between 0 and x. We are effectively hiding "E5(x)" inside the "¤ ¤ ¤ ".
Now we can divide both sides by x (assuming x $ 0):

                                     sin(x) x = 1 ¡ 13! x2 + 15! x4 + E5(x) x .

and  everything  is  fine  provided  the  term  E5 ( x)  stays  well  behaved.
                                                  x

                                                         368
POWER SERIES                 6.5 EVALUATING LIMITS USING TAYLOR EXPANSIONS

                                                                          Example 6.5.1

    The limit in the previous example can also be evaluated relatively easily using l'Ho^ pital's
rule27. While the following limit can also, in principal, be evaluated using l'Ho^ pital's rule,
it is much more efficient to use Taylor series28.

 Example 6.5.2

In this example we evaluate  lim arctan x ¡ x
                             xÑ0 sin x ¡ x

Once again, the first thing to notice about this limit is that, as x tends to zero, the numera-

tor tends to arctan 0 ¡ 0, which is 0, and the denominator tends to sin 0 ¡ 0, which is also

0. So we may not evaluate the limit of the ratio by simply dividing the limits of the nu-
merator and denominator. Again, to find the limit, or show that it does not exist, we are
going to have to exhibit a cancellation between the numerator and the denominator. To
get a more detailed understanding of the behaviour of the numerator and denominator
near x = 0, we find their Taylor expansions. By Example 6.2.9,

                             arctan x = x ¡ x3 + 3 x55 ¡ ¤ ¤ ¤

so the numerator             arctan x ¡ x = ¡ x3 + 3 x55 ¡ ¤ ¤ ¤

By Example 6.3.4,            sin x = x ¡ 13! x3 + 15! x5 ¡ ¤ ¤ ¤

so the denominator           sin x ¡ x = ¡ 13! x3 + 15! x5 ¡ ¤ ¤ ¤

and the ratio                                   x3 x5
                             arctan x ¡ x ¡ 3 + 5 ¡ ¤ ¤ ¤
                             sin x ¡ x  =  ¡ 1 x3       1 x5   ¡     ¤¤¤
                                              3!     +
                                                        5!

Notice that every term in both the numerator and the denominator contains a common
factor of x3, which we can cancel out.

                             arctan x ¡ x  =  ¡1     +  x2  ¡  ¤  ¤  ¤
                                                 3      5
                             sin x ¡ x        ¡1        1 x2  ¡   ¤¤¤
                                                 3!  +
                                                        5!

As x tends to zero,

27 Many of you learned about l'Ho^ pital's rule in school and all of you should have seen it last term in your
      differential calculus course.

28 It takes 3 applications of l'Ho^ pital's rule and some careful cleaning up of the intermediate expressions.
      Oof!

                                           369
POWER SERIES                                6.5 EVALUATING LIMITS USING TAYLOR EXPANSIONS

·  the  numerator  tends  to  ¡   1  ,  which     is    not  0,  and
                                  3

·  the  denominator  tends    to  ¡     1   =  ¡  1  ,  which      is  also  not         0.
                                        3!        6

so we may now legitimately evaluate the limit of the ratio by simply dividing the limits
of the numerator and denominator.

                        arctan x ¡ x                         ¡1    +   x2    ¡  ¤  ¤  ¤
                                                                3      5
                   lim                         = lim 1 1 2
                   xÑ0 sin x ¡ x xÑ0 ¡3! + 5! x ¡ ¤ ¤ ¤
                                                                                   x2
                                                        limxÑ0         ¡  1  +     5     ¡   ¤  ¤  ¤
                                               = limxÑ0                   3
                                                                   ¡   1        1         ¡     ¤  ¤  ¤
                                                                       3!    +  5!    x2

                                                     ¡1/3
                                               = ¡1/3!
                                               =2

                                                                                                Example 6.5.2
    Chapter 5 of this work was adapted from Chapter 3 of CLP 2 - Integral Calculus by
Feldman, Rechnitzer, and Yeager under a Creative Commons Attribution-NonCommercial-
ShareAlike 4.0 International license.

                                                        370
             Appendix A

             PROOFS AND SUPPLEMENTS

A.1 Folding the First Octant of R3

      This text, whether you're reading it on a computer screen or a printed page, exists in
      two dimensions. So, anything we draw in three dimensions is going to require a little bit
      of imagination. If you're struggling to understand the figures with three coordinates, it
      might help to make your own model of these axes.

           In the Cartesian plane, the first quadrant is the part of the plane where both x and y
      are positive. R3 divides three-dimensional space into eight regions, called octants. The
      first octant is the region where all of x, y, and z are positive.

           Following the instructions below, you can fold a piece of paper into an octant.
          1. Fold your paper in half "hamburger style" (so that the fold goes along the shorter

              dimension of the paper). Position it so that it opens like a book1.

          2. Bring the corner of your folded paper up to the side.

          3. Your paper now has a triangle sitting on top of a rectangle. Where the triangle ends,
              make a crease in the underlying rectangle shapes.

        1 in a language written left-to-right

                                                               371
PROOFS AND SUPPLEMENTS            A.2 VECTORS
                          crease

4. Your paper has four layers, with the triangle shapes on top. Open the paper so that
   three layers are on top, and one is on the bottom. The result should look like the
   inside corner of a box.
                  open

    Your octant is created! The vertical crease is the z axis, the crease to the left is the x axis,
and the crease to the right is the y axis. In the picture below, the blue sphere indicates that
the octant is open towards you: if you were to put a marble inside the paper structure, it
would sit as shown.

                z

x  y

    To practice with your octant, label the following points directly on the paper:
   · (1, 1, 0)
   · (0, 1, 1)
   · (1, 0, 1)
The next collection of points will exist out in space, not on any of the paper sides. Point to
their positions relative to your octant:
   · (1, 1, 1)
   · (1, 2, 3)

  · (1, ¡1, 1)
  · (1, 1, ¡1)

A.2 Vectors

      In many of our applications in 2d and 3d, we will encounter quantities that have both a
      magnitude (like a distance) and also a direction. Such quantities are called vectors. That is,

                                                               372
PROOFS AND SUPPLEMENTS                                          A.2 VECTORS

a vector is a quantity which has both a direction and a magnitude, like a velocity. If you are
moving, the magnitude (length) of your velocity vector is your speed (distance travelled
per unit time) and the direction of your velocity vector is your direction of motion. To
specify a vector in three dimensions you have to give three components, just as for a
point. To draw the vector with components a, b, c you can draw an arrow from the point
(0, 0, 0) to the point (a, b, c). Similarly, to specify a vector in two dimensions you have to

y                       (a, b)             z         pa, b, cq
         a              b                            c
                                       a
                               x             b              y

                                  x

give two components. To draw the vector with components a and b , you can draw an
arrow from the point (0, 0) to the point (a, b).

    There are many situations in which it is preferable to draw a vector with its tail at
some point other than the origin. For example, it is natural to draw the velocity vector
of a moving particle with the tail of the velocity vector at the position of the particle,
whether or not the particle is at the origin. The sketch below shows a moving particle and
its velocity vector at two different times.

                        y
                                                  v

                                  v
                                       x

As a second example, suppose that you are analyzing the motion of a pendulum. There
are three forces acting on the pendulum bob: gravity g, which is pulling the bob straight
down, tension t in the rod, which is pulling the bob in the direction of the rod, and air
resistance r, which is pulling the bob in a direction opposite to its direction of motion. All
three forces are acting on the bob. So it is natural to draw all three arrows representing the
forces with their tails at the ball.

                                                         373
PROOFS AND SUPPLEMENTS                                     A.2 VECTORS

                                tr

                                                             g
    In this text, we will used bold faced letters, like v, t, g, to designate vectors. In hand-
writing, it is clearer to use a small overhead arrow2, as in v, t, g, instead. Also, when we
want to emphasize that some quantity is a number, rather than a vector, we will call the
number a scalar.
    Both points and vectors in 2d are specified by two numbers. Until you get used to this,
it might confuse you sometimes -- does a given pair of numbers represent a point or a
vector? To distinguish3 between the components of a vector and the coordinates of the
point at its head, when its tail is at some point other than the origin, we shall use angle
brackets rather than round brackets around the components of a vector. For example, the
figure below shows the two-dimensional vector 2, 1 drawn in three different positions.
In each case, when the tail is at the point (u, v) the head is at (2 + u, 1 + v). We warn you
that, out in the real world4, no one uses notation that distinguishes between components
of a vector and the coordinates of its head -- usually round brackets are used for both. It
is up to you to keep straight which is being referred to.

    y                           2, 1 (6, 3)
(0, 0)
                        (2, 1)  (4, 2)       2, 1 (10, 1)

                                             (8, 0) x

By way of summary,

  NotationA.2.1.

 we use

     · bold faced letters, like v, t, g, to designate vectors, and
     · angle brackets, like 2, 1, around the components of a vector, but use
     · round brackets, like (2, 1), around the coordinates of a point, and use
     · "scalar" to emphasise that some quantity is a number, rather than a vector.

2 Some people use an underline, as in v, rather than an arrow.
3 Or, in the Wikipedia jargon, disambiguate.
4 OK. OK. Out in that (admittedly very small) part of the real world that actually knows what a vector is.

                                                         374
PROOFS AND SUPPLEMENTS                                      A.2 VECTORS

A.2.1  Addition of Vectors and Multiplication of a Vector by a Scalar

        Just as we have done many times in the texts, when we define a new type of object, we
        want to understand how it interacts with the basic operations of addition and multipli-
        cation. Vectors are no different, and the following is a natural way to define addition of
        vectors. Multiplication will be more subtle, and we start with multiplication of a vector
        by a number (rather than with multiplication of a vector by another vector).

DefinitionA.2.2 (Adding Vectors and Multiplying a Vector by a Number).

These two operations have the obvious definitions

a = a1, a2 , b = b1, b2             ùñ  a + b = a1 + b1, a2 + b2
                                    ùñ
a = a1, a2 , s a number                 sa = sa1, sa2

and similarly in three dimensions.

    Pictorially, you add the vector b to the vector a by drawing b with its tail at the head
of a and then drawing a vector from the tail of a to the head of b, as in the figure on the
left below. For a number s, we can draw the vector sa, by just

  · changing the vector a's length by the factor |s|, and,

    · if s 0, reversing the arrow's direction,
as in the other two figures below.

a2 ` b2 a ` b 2a2 2a                                                    a

b2     b
a2 a2 a

    a                                                  ´2a

The special case of multiplication by s = ¡1 appears so frequently that (¡1)a is given the
shorter notation ¡a. That is,

                             ¡ a1, a2 = ¡a1, ¡a2
Of course a + (¡a) is 0, the vector all of whose components are zero.

  To subtract b from a pictorially, you may add ¡b (which is drawn by reversing the

direction of b) to a. Alternatively, if you draw a and b with their tails at a common point,

then a ¡ b is the vector from the head of b to the head of a. That is, a ¡ b is the vector you

must add to b in order to get a.

                                                         375
PROOFS AND SUPPLEMENTS                                                 A.2 VECTORS

                                                       -b  a-b
                                           a-b

                                                        a

                                                       b

    The operations of addition and multiplication by a scalar that we have just defined are
quite natural and rarely cause any problems, because they inherit from the real numbers
the properties of addition and multiplication that you are used to.

     TheoremA.2.3 (Properties of Addition and Scalar Multiplication).

     Let a, b and c be vectors and s and t be scalars. Then

     (1) a + b = b + a                                     (2) a + (b + c) = (a + b) + c
     (3) a + 0 = a
     (5) s(a + b) = sa + sb                                (4) a + (¡a) = 0
     (7) (st)a = s(ta)
                                                           (6) (s + t)a = sa + ta

                                                           (8) 1a = a

We have just been introduced to many definitions. Let's see some of them in action.
 Example A.2.4

For example, if  a = 1, 2, 3 b = 3, 2, 1 c = 1, 0, 1
then

                  2a = 2 1, 2, 3 = 2, 4, 6

                 ¡b = ¡ 3, 2, 1 = ¡3, ¡2, ¡1

                  3c = 3 1, 0, 1 = 3, 0, 3

and

                 2a ¡ b + 3c = 2, 4, 6 + ¡3, ¡2, ¡1 + 3, 0, 3
                           = 2 ¡ 3 + 3 , 4 ¡ 2 + 0 , 6 ¡ 1 + 3

                                = 2, 2, 8

                                                                    Example A.2.4
                             376
PROOFS AND SUPPLEMENTS                                                       A.2 VECTORS

    There are some vectors that occur sufficiently commonly that they are given special
names. One is the vector 0. Some others are the "standard basis vectors".

     DefinitionA.2.5.

(a) The standard basis vectors in two dimensions are

                                                        y

              i^ = 1, 0       ^ = 0, 1                     ^

                                                               ^i         z

(b) The standard basis vectors in three dimensions are             x         k^

i^ = 1, 0, 0  ^ = 0, 1, 0              k^ = 0, 0, 1                              ^ y

                                                                   x ^i

    We'll explain the little hats in the notation i^, ^, k^ shortly. Some people rename i^, ^ and
k^ to e1, e2 and e3 respectively. Using the above properties we have, for all vectors,

a1, a2 = a1 i^ + a2 ^                  a1, a2, a3 = a1 i^ + a2 ^ + a3 k^

A sum of numbers times vectors, like a1i^ + a2^ is called a linear combination of the vectors.
Thus all vectors can be expressed as linear combinations of the standard basis vectors.
This makes basis vectors very helpful in computations. The standard basis vectors are unit

vectors, meaning that they are of length one, where the length of a vector a is denoted5 |a|

and is defined by

DefinitionA.2.6 (Length of a Vector).

                              ùñ        |a| =  

              a = a1, a2                              a2 + a2
              a = a1, a2, a3
                                                       12

                              ùñ        |a| =         a2 + a2 + a2

                                                       123

A unit vector is a vector of length one. We'll sometimes use the accent ^ to em-

phasise that the vector a^ is a unit vector. That is, |a^| = 1.

 Example A.2.7
Recall that multiplying a vector a by a positive number s, changes the length of the vector

by a factor s without changing the direction of the vector. So (assuming that |a| $ 0) |aa|

is a unit vector that has the same direction as a. For example, 1c,1,1 3 is a unit vector that

points in the same direction as 1, 1, 1.

5 The notation }a} is also used for the length of a.

                                                         377
PROOFS AND SUPPLEMENTS                                                 A.2 VECTORS
                                                                   Example A.2.7

A.2.2  The Dot Product

        Let's get back to the arithmetic operations of addition and multiplication. We will be using
        both scalars and vectors. So, for each operation there are three possibilities that we need
        to explore:

            · "scalar plus scalar", "scalar plus vector" and "vector plus vector"
            · "scalar times scalar", "scalar times vector" and "vector times vector"

        We have been using "scalar plus scalar" and "scalar times scalar" since childhood. "Vector
        plus vector" and "scalar times vector" were just defined above. There is no sensible way
        to define "scalar plus vector", so we won't. This leaves "vector times vector". There are
        actually two widely used such products. The first is the dot product, which is the topic of
        this section, and which is used to easily determine the angle  (or more precisely, cos )
        between two vectors. (The second widely-used product of two vectors, the cross product,
        is not a part of this course.)

DefinitionA.2.8 (Dot Product).

The dot product of the vectors a and b is denoted a ¤ b and is defined by

a = a1, a2 , b = b1, b2                    ùñ a ¤ b = a1b1 + a2b2
a = a1, a2, a3 , b = b1, b2, b3 ùñ a ¤ b = a1b1 + a2b2 + a3b3

in two and three dimensions respectively.

The properties of the dot product are as follows:

  TheoremA.2.9 (Properties of the Dot Product).

 Let a, b and c be vectors and let s be a scalar. Then

         (0) a, b are vectors and a ¤ b is a scalar
         (1) a ¤ a = |a|2
         (2) a ¤ b = b ¤ a
         (3) a ¤ (b + c) = a ¤ b + a ¤ c, (a + b) ¤ c = a ¤ c + b ¤ c
         (4) (sa) ¤ b = s(a ¤ b)
         (5) 0 ¤ a = 0
         (6) a ¤ b = |a| |b| cos  where  is the angle between a and b
         (7) a ¤ b = 0 ðñ a = 0 or b = 0 or a u b

                                378
PROOFS AND SUPPLEMENTS                                                                                A.2 VECTORS

Proof. Properties 0 through 5 are almost immediate consequences of the definition. For
example, for property 3 (which is called the distributive law) in dimension 2,

a ¤ (b + c) = a1, a2 ¤ b1 + c1, b2 + c2

              = a1(b1 + c1) + a2(b2 + c2) = a1b1 + a1c1 + a2b2 + a2c2

a ¤ b + a ¤ c = a1, a2 ¤ b1, b2 + a1, a2 ¤ c1, c2

              = a1b1 + a2b2 + a1c1 + a2c2

    Property 6 is sufficiently important that it is often used as the definition of dot product.

It is not at all an obvious consequence of the definition. To verify it, we just write |a ¡ b|2
in two different ways. The first expresses |a ¡ b|2 in terms of a ¤ b. It is

                      |a  ¡  b|2    1    (a    ¡  b  )  ¤  (a  ¡  b  )

                                    =

                                    3    a  ¤  a  ¡  a  ¤  b  ¡  b  ¤   a  +  b  ¤  b

                                    =

                                    1,2  |a|2     +  |b|2  ¡   2a    ¤  b

                                    =

           1

Here, =, for example, means that the equality is a consequence of property 1. The second

way we write |a ¡ b|2 involves cos  and follows from the cosine law for triangles. Just

in case you don't remember the cosine law, we'll derive it right now! Start by applying
Pythagoras to the shaded triangle in the right hand figure of

   a                                a´b              |a| sin  |a|                            |a ´ b|

                                                               
             b                                                              |b|

                                                               |a| cos 

That triangle is a right triangle whose hypotenuse has length |a ¡ b| and whose other two
sides have lengths |b| ¡ |a| cos  and |a| sin . So Pythagoras gives

|a ¡ b|2 = |b| ¡ |a| cos  2 + |a| sin  2
       = |b|2 ¡ 2|a| |b| cos  + |a|2 cos2  + |a|2 sin2 
       = |b|2 ¡ 2|a| |b| cos  + |a|2

This is precisely the cosine law6.  Observe that, when                        =     ,  this  reduces  to,  (surpise!)

Pythagoras' Theorem.                                                                2

Setting our two expressions for |a ¡ b|2 equal to each other,

|a ¡ b|2 = |a|2 + |b|2 ¡ 2a ¤ b = |b|2 ¡ 2|a| |b| cos  + |a|2

6 You may be used to seeing it written as c2 = a2 + b2 ¡ 2ab cos C, where a, b and c are the lengths of the

      three sides of the triangle and C is the angle opposite the side of length c

                                                  379
PROOFS AND SUPPLEMENTS                                                                            A.2 VECTORS

cancelling the |a|2 and |b|2 common to both sides

                                            ¡2a ¤ b = ¡2|a| |b| cos 

and dividing by ¡2 gives

                                                 a ¤ b = |a| |b| cos 

which is exactly property 6.
Property 7 follows directly from property 6. First note that the dot product a ¤ b =
|a| |b| cos  is zero if and only if at least one of the three factors |a|, |b|, cos  is zero. The
first factor is zero if and only if a = 0. The second factor is zero if and only if b = 0. The
third  factor  is  zero  if  and  only  if       ¨        2k,  for  some  integer  k,  which  in  turn  is  true  if
                                              =     2  +

and only if a and b are mutually perpendicular.

    Because of Property 7 of Theorem A.2.9, the dot product can be used to test whether or
not two vectors are perpendicular to each other. That is, whether or not the angle between

the two vectors is 90¥. Another name7 for "perpendicular" is "orthogonal". Testing for

orthogonality is one of the main uses of the dot product.

Example A.2.10

Consider the three vectors

                             a = 1, 1, 0 b = 1, 0, 1 c = ¡1, 1, 1

Their dot products

                   a ¤ b = 1, 1, 0 ¤ 1, 0, 1 = 1 ¢ 1 + 1 ¢ 0 + 0 ¢ 1 = 1
                   a ¤ c = 1, 1, 0 ¤ ¡1, 1, 1 = 1 ¢ (¡1) + 1 ¢ 1 + 0 ¢ 1 = 0
                   b ¤ c = 1, 0, 1 ¤ ¡1, 1, 1 = 1 ¢ (¡1) + 0 ¢ 1 + 1 ¢ 1 = 0
                                                                                       c                    c
tell us that c is perpendicular to both a and b. Since both |a| = |b| = 12 + 12 + 02 = 2
the first dot product tells us that the angle, , between a and b obeys

                                  cos  = |a ¤ b a| |b| = 12 ùñ  = 3

                                                    z               ´1, 1, 1
                                        1, 0, 1

                                                                    y

                                              x                1, 1, 0

                                                                                          Example A.2.10

7 The concepts of the dot product and perpendicularity have been generalized a lot in mathematics (for
      example, from 2d and 3d vectors to functions). The generalization of the dot product is called the "inner
      product" and the generalization of perpendicularity is called "orthogonality".

                                                         380
PROOFS AND SUPPLEMENTS           A.3 CONIC SECTIONS AND QUADRIC SURFACES

A.3 Conic Sections and Quadric Surfaces

      A conic section is the curve of intersection of a cone and a plane that does not pass through
      the vertex of the cone. This is illustrated in the figures below. An equivalent8 (and often

circle                  ellipse  parabola  hyperbola

used) definition is that a conic section is the set of all points in the xy-plane that obey
Q(x, y) = 0 with

                          Q(x, y) = Ax2 + By2 + Cxy + Dx + Ey + F = 0
being a polynomial of degree two9. By rotating and translating our coordinate system the
equation of the conic section can be brought into one of the forms10

  · x2 + y2 =  with , ,  ¡ 0, which is an ellipse (or a circle),
  · x2 ¡ y2 =  with ,  ¡ 0,  $ 0, which is a hyperbola,
  · x2 = y, with  $ 0 which is a parabola.

    The three dimensional analogs of conic sections, surfaces in three dimensions given by
quadratic equations, are called quadrics. An example is the sphere x2 + y2 + z2 = 1. Here
are some tables giving all of the quadric surfaces.

8 It is outside our scope to prove this equivalence.
9 Technically, we should also require that the constants A, B, C, D, E, F, are real numbers, that A, B, C are

     not all zero, that Q(x, y) = 0 has more than one real solution, and that the polynomial can't be factored
      into the product of two polynomials of degree one.
10 This statement can be justified using a linear algebra eigenvalue/eigenvector analysis. It is beyond
      what we can cover here, but is not too difficult for a standard linear algeba course.

                                                         381
PROOFS AND SUPPLEMENTS           A.3 CONIC SECTIONS AND QUADRIC SURFACES

      name     elliptic          parabolic    hyperbolic         sphere
               cylinder          cylinder     cylinder     x2 + y2 + z2 = r2
equation in                       y = ax2
standard form  x2 y2              one line    x2 y2               circle
x = constant                     two lines                        circle
cross-section  a2 + b2 = 1       parabola     a2 ¡ b2 = 1         circle
y = constant    two lines
cross-section                                 two lines
z = constant    two lines
cross-section                                 two lines
                 ellipse
                                              hyperbola

sketch

      name        ellipsoid       elliptic           elliptic
                                  paraboloid         cone
equation in    x2 y2 z2
standard form                    x2 y2 z            x2 y2 z2
x = constant   a2 + b2 + c2 = 1
cross-section      ellipse       a2 + b2 = c      a2 + b2 = c2
y = constant       ellipse         parabola
cross-section      ellipse                    two lines if x = 0
z = constant                       parabola
cross-section                                 hyperbola if x $ 0
                                    ellipse
                                              two lines if y = 0

                                              hyperbola if y $ 0

                                                      ellipse

sketch

                                 382
PROOFS AND SUPPLEMENTS                             A.4 MIXED PARTIAL DERIVATIVES

      name     hyperboloid                hyperboloid             hyperbolic
               of one sheet               of two sheets           paraboloid
equation in
standard form   x2 y2 z2                  x2 y2 z2                  y2 x2 z
x = constant
cross-section  a2 + b2 ¡ c2 = 1           a2 + b2 ¡ c2 = ¡1     b2 ¡ a2 = c
y = constant
cross-section     hyperbola                  hyperbola             parabola
z = constant
cross-section     hyperbola                  hyperbola               ellipse
                                                             two lines if z = 0
                    ellipse                     ellipse
                                                             hyperbola if z $ 0

sketch

    Section A.3 of this work was adapted from Appendix G of CLP 3 - Multivariable
Calculus by Feldman, Rechnitzer, and Yeager under a Creative Commons Attribution-
NonCommercial-ShareAlike 4.0 International license.

A.4 Mixed Partial Derivatives

A.4.1  Clairaut: The Proof of Theorem 2.2.5

 Outline

Here is an outline of the proof of Theorem 2.2.5. The (numbered) details are in the subsec-
tion below.

    Fix real numbers x0 and y0 and define

F(h, k) = 1hk f (x0 + h, y0 + k) ¡ f (x0, y0 + k) ¡ f (x0 + h, y0) + f (x0, y0) .

                                                             f2 f                 f2 f
We define F(h, k) in this way because both partial derivatives fxfy (x0, y0) and fyfx (x0, y0)
are limits of F(h, k) as h, k Ñ 0. We show in item (1) in the details below that

                        f f f (x0, y0) = lim lim F(h, k)
                        fy fx             kÑ0 hÑ0
                        f f f (x0, y0) = lim lim F(h, k)
                        fx fy             hÑ0 kÑ0

                                 f2 f              f2 f
and therefore the partial derivatives fxfy (x0, y0) and fyfx (x0, y0) are identical except for
the order in which the limits are taken.

                                          383
PROOFS AND SUPPLEMENTS                                    A.4 MIXED PARTIAL DERIVATIVES

    Now, by applying the Mean Value Theorem multiple times (see items (2) to (5) for more
details) we get

                           (2) 1 f f                      ff
                    F(h, k) =  h fy    (x0 + h, y0 + 1k) ¡ (x0, y0 + 1k)
                                                          fy
                           (3) f f f
                           =   fx fy  (x0 + 2h, y0 + 1k)

                           (4) 1 f f                      ff
                    F(h, k) =          (x0 + 3h, y0 + k) ¡ (x0 + 3h, y0)
                               k fx                       fx
                           (5) f f f
                           =   fy fx  (x0 + 3h, y0 + 4k)

for some numbers 0 1, 2, 3, 4 1. All of the numbers 1, 2, 3, 4 depend on x0, y0, h, k.
Hence
                    f f f (x0 + 2h, y0 + 1k) = f f f (x0 + 3h, y0 + 4k)
                    fx fy                     fy fx

for all h and k. Taking the limit (h, k) Ñ (0, 0) and using the assumed continuity of both

partial derivatives at (x0, y0) gives

                    lim F(h, k) = f f f (x0, y0) = f f f (x0, y0)
                    (h,k)Ñ(0,0)        fx fy              fy fx

as desired. To complete the proof we just have to justify the details (1), (2), (3), (4) and (5).

 The Details

(1) By definition,

f f f (x0, y0) = lim 1 f f (x0, y0 + k) ¡ f f (x0, y0)
fy fx               kÑ0 k fx           fx
                    = lim 1 lim f (x0 + h, y0 + k) ¡ f (x0, y0 + k) ¡ lim f (x0 + h, y0) ¡ f (x0, y0)
                    kÑ0 k hÑ0                 h                  hÑ0      h
                    = lim lim f (x0 + h, y0 + k) ¡ f (x0, y0 + k) ¡ f (x0 + h, y0) + f (x0, y0)
                    kÑ0 hÑ0                               hk

                    = lim lim F(h, k)

                      kÑ0 hÑ0

Similarly,

f f f (x0, y0) = lim 1 f f (x0 + h, y0) ¡ f f (x0, y0)
fx fy               hÑ0 h fy           fy
                    = lim 1 lim f (x0 + h, y0 + k) ¡ f (x0 + h, y0) ¡ lim f (x0, y0 + k) ¡ f (x0, y0)
                    hÑ0 h kÑ0                 k                  kÑ0      k
                    = lim lim f (x0 + h, y0 + k) ¡ f (x0 + h, y0) ¡ f (x0, y0 + k) + f (x0, y0)
                    hÑ0 kÑ0                               hk

                    = lim lim F(h, k)

                      hÑ0 kÑ0

                                       384
PROOFS AND SUPPLEMENTS                        A.4 MIXED PARTIAL DERIVATIVES

(2) The Mean Value Theorem (probably covered in your last calculus class) says that, for
    any differentiable function (x),

· the slope of the line joining the points x0, (x0) and x0 + k, (x0 + k) on the
   graph of 

is the same as

· the slope of the tangent to the graph at some point between x0 and x0 + k.

That is, there is some 0  1 1 such that

                          (x0 + k) ¡ (x0) k = d dx (x0 + 1k)

                             y
                                                         y " pxq

                             x0 x0`1k x0`k x

Applying this with x replaced by y and  replaced by G(y) = f (x0 + h, y) ¡ f (x0, y)

gives

G(y0 + k) ¡ G(y0) k = dG dy (y0 + 1k) for some 0 1 1
                             = f f (x0 + h, y0 + 1k) ¡ f f (x0, y0 + 1k)
                             fy               fy

Hence, for some 0 1 1,

F(h, k) = 1 G(y0 + k) ¡ G(y0) = 1 f f (x0 + h, y0 + 1k) ¡ f f (x0, y0 + 1k)
                h         k      h fy                             fy

                     ff
(3) Define H(x) = fy (x, y0 + 1k). By the Mean Value Theorem,

                   F(h, k) = 1h [H(x0 + h) ¡ H(x0)]

                                      = dH (x0 + 2h) for some 0 2 1
                                            dx

                            f ff
                          = fx fy (x0 + 2h, y0 + 1k)

                                 385
PROOFS AND SUPPLEMENTS                                    A.4 MIXED PARTIAL DERIVATIVES

(4) Define A(x) = f (x, y0 + k) ¡ f (x, y0). By the Mean Value Theorem,

                    F(h, k) = 1 A(x0 + h) ¡ A(x0) k h

                                = 1 dA k dx (x0 + 3h) for some 0 3 1
                                = 1 f f (x0 + 3h, y0 + k) ¡ f f (x0 + 3h, y0)
                                k fx                      fx

                     ff
(5) Define B(y) = fx (x0 + 3h, y). By the Mean Value Theorem

                   F(h, k) = 1k [B(y0 + k) ¡ B(y0)]

                                      = dB (y0 + 4k) for some 0 4 1
                                            dy

                          = f f f (x0 + 3h, y0 + 4k)
                            fy fx

This completes the proof of Theorem 2.2.5.
    Section A.4.1 of this work was adapted from Section 2.3.1 of CLP 3 - Multivariable

Calculus by Feldman, Rechnitzer, and Yeager under a Creative Commons Attribution-
NonCommercial-ShareAlike 4.0 International license.

                    f2 f                 f2 f
A.4.2  An Example of fxfy (x0, y0)  fyfx (x0, y0)

                                f2 f           f2 f                                                    f2 f
In Theorem 2.2.5, we showed that fxfy (x0, y0) = fyfx (x0, y0) if the partial derivatives fxfy
      f2 f
and fyfx exist and are continuous at (x0, y0). Here is an example which shows that if
                    f2 f        f2 f
the partial derivatives fxfy and fyfx are not continuous at (x0, y0), then it is possible that
f2 f          f2 f
fxfy (x0, y0) $ fyfx (x0, y0).
      Define
                                5 f (x, y) = xy xx2+y2 2¡y2 if (x, y) $ (0, 0)
                                      0        if (x, y) = (0, 0)

This function is continuous everywhere. Note that f (x, 0) = 0 for all x and f (0, y) = 0 for

all y. We now compute the first order partial derivatives. For (x, y) $ (0, 0),

      f f (x, y) = y 2 2 x + 2 ¡ y2 xy 2 2 2x ¡ xy 2 2x(x = 2 ¡ y2) y 2 2 x + 2 ¡ y2 xyfx4xy2
                    x +y        x +y                          x +y
                                                                                                    2
                                               (x2 + y2)                                 (x2 + y2)

      fyf f (x, y) = x 2 2 x2 ¡ y2 ¡ xy 2 2 2y ¡ xy 2 2y(x = 2 ¡ y2) x 2 2 x2 ¡ y2 ¡ xy  4yx2
                    x +y        x +y           (x2 + y2)      x +y
                                                                                                    2
                                                                                         (x2 + y2)

                                         386
PROOFS AND SUPPLEMENTS                                     A.5 THE (MULTIVARIABLE) CHAIN RULE

For (x, y) = (0, 0),

                          f f (0, 0) =  ddx f (x, 0)      =        d 0 =0
                          fx            ddy f (0, y)               dx x=0
                          f f (0, 0) =                x=0          d 0 =0
                          fy                                       dy y=0
                                                          =

                                                      y=0

By way of summary, the two first order partial derivatives are

                                   6 x2¡y2          4x2y3          if (x, y) $ (0, 0)
                          8 fx(x, y) = y x2+y2 + (x2+y2)2
                                   70                              if (x, y) = (0, 0)

                                   6 x2¡y2          4x3y2          if (x, y) $ (0, 0)
                          8 fy(x, y) = x x2+y2 ¡ (x2+y2)2
                                   70                              if (x, y) = (0, 0)

Both fx (x, y) and fy (x, y) are continuous. Finally, we computeffff

f ( 2 f 0, 0) =      ddx fy(x, 0)  = lim 1 fy(h, 0) ¡ fy(0, 0) = lim 1                 h h2 + 02 h2 ¡ 02 ¡ 0    =1
fxfy                 ddy fx(0, y)  x=0 hÑ0 h                           hÑ0 h           k 02 + k2 02 ¡ k2 ¡ 0
f ( 2 f 0, 0) =                                                                                               = ¡1
fyfx                               = lim 1 [ fx(0, k) ¡ fx(0, 0)] = lim 1
                                   y=0 kÑ0 k                           kÑ0 k

    Section A.4.2 of this work was adapted from Section 2.3.2 of CLP 3 - Multivariable
Calculus by Feldman, Rechnitzer, and Yeager under a Creative Commons Attribution-
NonCommercial-ShareAlike 4.0 International license.

A.5 The (multivariable) chain rule

You already routinely use the one dimensional chain rule

                                   ddt f x(t) = d f dx x(t) dx dt (t)

in doing computations like              ddt sin(t2) = cos(t2) 2t

In this example, f (x) = sin(x) and x(t) = t2.
We now generalize the chain rule to functions of more than one variable. For con-
creteness, we concentrate on the case in which all functions are functions of two variables.
That  is,  we  find  the  partial  derivatives  fF  and  fF    of  a  function  F(s, t)  that  is  defined    as    a
composition                                     fs       ft

                                   F(s, t) = f x(s, t) , y(s, t)

We are using the name F for the new function F(s, t) as a reminder that it is closely related
to, though not the same as, the function            f (x, y).  The partial derivative    fF    is the rate of
                                                                                         fs

                                                    387
PROOFS AND SUPPLEMENTS                        A.5 THE (MULTIVARIABLE) CHAIN RULE

change of F when s is varied with t held constant. When s is varied, both the x-argument,
x(s, t), and the y-argument, y(s, t), in f x(s, t) , y(s, t) vary. Consequently, the chain rule
for f x(s, t) , y(s, t) is a sum of two terms -- one resulting from the variation of the x-
argument and the other resulting from the variation of the y-argument.

      TheoremA.5.1 (The Chain Rule).

Assume that all first order partial derivatives of f (x, y), x(s, t) and y(s, t) exist
and are continuous. Then the same is true for F(s, t) = f x(s, t) , y(s, t) and

     fF (s, t) = f f  x(s, t) , y(s, t)  fx (s, t) + f f  x(s, t) , y(s, t)  fy (s, t)
     fs         fx    x(s, t) , y(s, t)  fs           fy  x(s, t) , y(s, t)  fs
     fF (s, t) = f f                     fx (s, t) + f f                     fy (s, t)
     ft         fx                       ft           fy                     ft

We will give the proof of this theorem in §A.5.2, below. It is common to state this chain
rule as

                              fF = f f fx + f f fy
                              fs fx fs fy fs
                              fF = f f fx + f f fy
                              ft fx ft fy ft

That is, it is common to suppress the function arguments. But you should make sure that
you understand what the arguments are before doing so.

    Theorem A.5.1 is given for the case that F is the composition of a function of two
variables, f (x, y), with two functions, x(s, t) and y(s, t), of two variables each. There is
nothing magical about the number two. There are obvious variants for any numbers of
variables. For example,

                                                                 Equation A.5.2.

if F(t) = f x(t), y(t), z(t) , then

     dF (t) = f f     x(t) , y(t) , z(t) dx (t) + f f x(t) , y(t) , z(t)     dy dt (t)
     dt         fx                       dt fy
                                + f f x(t) , y(t) , z(t) dz (t)
                                fz                        dt

and

                                                                 Equation A.5.3.

if F(s, t) = f  x(s, t) , then

                        fF (s, t) = d f      x(s, t)  fx (s, t)
                        ft               dx           ft

    To give you an idea of how the proof of Theorem A.5.1 will go, we first review the
proof of the familiar one dimensional chain rule.

                                         388
       PROOFS AND SUPPLEMENTS                                A.5 THE (MULTIVARIABLE) CHAIN RULE

A.5.1    Review  of  the  Proof  of  d   f     x(t)       df          dx (t)
                                     dt
                                                     = dx x(t)        dt

As a warm up, let's review the proof of the one dimensional chain rule

                                   ddt f x(t) = d f dx x(t) dx dt (t)

We wish to find the derivative of F(t) = f x(t) . By definition

                          FI(t) = lim F(t + h) ¡ F(t)     h
                                            hÑ0
                                        = lim f x(t + h) ¡ f x(t)
                                            hÑ0                 h

Notice that the numerator is the difference of f (x) evaluated at two nearby values of
x, namely x1 = x(t + h) and x0 = x(t). The Mean Value Theorem is a good tool for
studying the difference in the values of f (x) at two nearby points. Recall that the Mean
Value Theorem says that, for any given x0 and x1, there exists an (in general unknown) c
between them so that

                         f (x1) ¡ f (x0) = f I(c) (x1 ¡ x0)

For this proof, we choose x0 = x(t) and x1 = x(t + h). The Mean Value Theorem tells us
that there exists a ch so that

           f x(t + h) ¡ f x(t) = f (x1) ¡ f (x0) = f I(ch) x(t + h) ¡ x(t)

We have put the subscript h on ch to emphasise that ch, which is between x0 = x(t) and
x1 = x(t + h), may depend on h. Now since ch is trapped between x(t) and x(t + h) and

since x(t + h) Ñ x(t) as h Ñ 0, we have that ch must also tend to x(t) as h Ñ 0. Plugging

ths into the definition of FI(t),

                          FI(t) = lim f x(t + h) ¡ f x(t)    h
                                        hÑ0
                                   = lim f I(ch) x(t + h) ¡ x(t)
                                        hÑ0                  h
                                   = lim f I(ch) lim x(t + h) ¡ x(t)
                                        hÑ0          hÑ0           h
                                   = f I x(t) xI(t)

as desired.

A.5.2  Proof of Theorem A.5.1

We'll    now  prove  the  formula  for  f   f  x(s, t) , y(s, t)   that is given in Theorem A.5.1. The
                                        fs
proof uses the same ideas as the proof of the one variable chain rule, that we have just
reviewed.

                                                     389
PROOFS AND SUPPLEMENTS                 A.5 THE (MULTIVARIABLE) CHAIN RULE

    We wish to find the partial derivative with respect to s of F(s, t) = f x(s, t) , y(s, t) .
By definition

fF (s, t) = lim F(s + h, t) ¡ F(s, t)
fs  hÑ0                 h
    = lim f x(s + h, t) , y(s + h, t) ¡ f x(s, t) , y(s, t)
    hÑ0                                h

The numerator is the difference of f (x, y) evaluated at two nearby values of (x, y), namely
(x1, y1) = x(s + h, t) , y(s + h, t) and (x0, y0) = x(s, t) , y(s, t) . In going from (x0, y0) to
(x1, y1), both the x and y-coordinates change. By adding and subtracting we can separate
the change in the x-coordinate from the change in the y-coordinate.

f (x1, y1) ¡ f (x0, y0) = 2 f (x1, y1) ¡ f (x0, y1)@ + 2 f (x0, y1) ¡ f (x0, y0)@

The first half, 2 f (x1, y1) ¡ f (x0, y1)@, has the same y argument in both terms and so is the

difference of the function of one variable g(x) = f (x, y1) (viewing y1 just as a constant)
evaluated at the two nearby values, x0, x1, of x. Consequently, we can make use of the
Mean Value Theorem as we did in §A.5.1 above. There is a cx,h between x0 = x(s, t) and
x1 = x(s + h, t) such that

     f (x1, y1) ¡ f (x0, y1) = g(x1) ¡ g(x0) = gI(cx,h)[x1 ¡ x0] = f f (cx,h, y1) [x1 ¡ x0]
                                                       fx

                      = f f cx,h , y(s + h, t) x(s + h, t) ¡ x(s, t)
                         fx

We have introduced the two subscripts in cx,h to remind ourselves that it may depend on
h and that it lies between the two x-values x0 and x1.

  Similarly, the second half, 2 f (x0, y1) ¡ f (x0, y0)@, is the difference of the function of

one variable h(y) = f (x0, y) (viewing x0 just as a constant) evaluated at the two nearby
values, y0, y1, of y. So, by the mean value theorem,

     f (x0, y1) ¡ f (x0, y0) = h(y1) ¡ h(y0) = hI(cy,h)[y1 ¡ y0] = f f (x0, cy,h) [y1 ¡ y0]
                                                       fy

                      = f f x(s, t) , cy,h y(s + h, t) ¡ y(s, t)
                         fy

for some (unknown) cy,h between y0 = y(s, t) and y1 = y(s + h, t). Agan, the two sub-
scripts in cy,h remind ourselves that it may depend on h and that it lies between the two
y-values y0 and y1. So, noting that, as h tends to zero, cx,h, which is trapped between
x(s, t) and x(s + h, t), must tend to x(s, t), and cy,h, which is trapped between y(s, t) and

                                                         390
PROOFS AND SUPPLEMENTS                                      A.5 THE (MULTIVARIABLE) CHAIN RULE

y(s + h, t), must tend to y(s, t),

fF (s, t)) = lim f x(s + h, t) , y(s + h, t) ¡ f x(s, t) , y(s, t)
fs               hÑ0                                        h
                        ff
                 = lim
                        fx cx,h , y(s + h, t) x(s + h, t) ¡ x(s, t)
                 hÑ0                                     h
                                         ff
                         + lim
                                         fy x(s, t) , cy,h y(s + h, t) ¡ y(s, t)

                                    hÑ0                          h
                 = lim f f cx,h , y(s + h, t) lim x(s + h, t) ¡ x(s, t)
                 hÑ0 fx                                     hÑ0       h
                         + lim f f x(s, t) , cy,h lim y(s + h, t) ¡ y(s, t)
                                    hÑ0 fy                       hÑ0     h
                 = f f x(s, t) , y(s, t) fx (s, t) + f f x(s, t) , y(s, t) fy (s, t)
                 fx                         fs                   fy           fs

We can of course follow the same procedure to evaluate the partial derivative with respect
to t. This concludes the proof of Theorem A.5.1.

 Example A.5.4 (Implicit Differentiation on Level Curves)
Level curves of the surface z = f (x, y) are points (x, y) such that f (x, y) = z0, where z0 is
some fixed constant. We can think of level curves as existing in an xy-plane by ignoring
the z coordinate (which, remember, is constant). Consider a point (a, b, z0) on a level curve
f (x, y) = z0. In the two-dimensional view, near (a, b) we can think of y as a function of x:
if x moves a little but, then y changes as well to "compensate" and maintain the constant
z-value.[picture] So, we can write y(x) to remember that y depends on x in this situation.

                                         z0 = f (x, y(x))

    Now we can think about the single-variable function g(x) = f (x, y(x)). Since this
function is equal to the constant value z0, its derivative is zero. Then, using the chain rule:

                 0 = gI(x) = d [ f (x, y(x))] = f f dx + f f dy
                                    dx                           fx dx fy dx

                                    = fx ¤ 1 + fy ¤ dy dx

If fy $ 0, then

                        dy dx = ¡ fxfy

What we've proved is the following.
                                                    391
PROOFS AND SUPPLEMENTS                                            A.5 THE (MULTIVARIABLE) CHAIN RULE

     TheoremA.5.5.

     The derivative of the curve in the xy plane that is implicitly defined by the equa-
     tion

                                                z0 = f (x, y)
     for some constant z0 and some differentiable function f (x, y) is

                                                      dy dx = ¡ fxfy

     as long as fy $ 0.

                                                                                               Example A.5.4

      DefinitionA.5.6.
     The vector fx(a, b) , fy(a, b) is denoted  f (a, b) and is called "the gradient of
     the function f at the point (a, b)".

      CorollaryA.5.7.
     Let f (x, y) be a function whose partial derivatives exist.  f (a, b) is perpendicu-

     lar to the level curve f (x, y) = f (a, b) at (a, b) as long as  f (a, b) $ 0.

Proof. First, suppose fy(a, b) $ 0. Using Theorem A.5.5, the line tangent to the level curve
                                  ¡  fx
has  slope  (in  the  xy  plane)     fy  .  So,  one  vector  in  the  direction  tangent  to  the  level  curve  is

¡ fy, fx . Then

                                                 ¡fy, fx ¤ fx, fy = 0

so ¡ fy, fx and  f = fx, fy are perpendicular.

    Second, consider the case fy(a, b) = 0. In this case, at (a, b) the level curve has a

vertical tangent line. If  f (a, b) $ 0, then fx(a, b) $ 0, so the gradient  f (a, b) =  fx, 0

is horizontal.

    Section A.5 of this work was adapted from Section 2.4 of CLP 3 - Multivariable Calcu-
lus by Feldman, Rechnitzer, and Yeager under a Creative Commons Attribution-NonCommercial-
ShareAlike 4.0 International license.

                                                         392
      PROOFS AND SUPPLEMENTS A.6 LAGRANGE MULTIPLIERS: PROOF OF THEOREM 2.5.2

A.6 Lagrange Multipliers: Proof of Theorem 2.5.2

      First, some intuition. When we talk about derivatives on a surface, we need to think
      about the derivatives in a particular direction.11 Consider in particular the surface formed
      by all points (x, y) such that f (x, y) = z, for some function f (x, y). The directions giving
      zero rate of increase are those that keep you on a level curve. By Corollary A.5.7, those
      directions are perpendicular to  f (a, b).

          The corresponding statement in three dimensions is that F(a, b, c) is perpendicular to
      the level surface F(x, y, z) = F(a, b, c) at (a, b, c). Hence a good way to find a vector normal
      to the surface F(x, y, z) = 0 at the point (a, b, c) is to compute the gradient F(a, b, c).

             TheoremA.6.1 (Lagrange Multipliers).
            Let f (x, y, z) and g(x, y, z) have continuous first partial derivatives in a region
            of R3 that contains the surface S given by the equation g(x, y, z) = 0. Further

        sssume that g(x, y, z) $ 0 on S.

            If f , restricted to the surface S, has a local extreme value at the point (a, b, c) on
            S, then there is a real number  such that

                                                f (a, b, c) = g(a, b, c)
            that is

                                                 fx(a, b, c) =  gx(a, b, c)
                                                 fy(a, b, c) =  gy(a, b, c)
                                                 fz(a, b, c) =  gz(a, b, c)
            The number  is called a Lagrange multiplier.

    Proof. Suppose that (a, b, c) is a point of S and that f (x, y, z) ¥ f (a, b, c) for all points

      (x, y, z) on S that are close to (a, b, c). That is (a, b, c) is a local minimum for f on S. Of
      course the argument for a local maximum is virtually identical.

       Imagine that we go for a walk on S, with the time t running, say, from t = ¡1 to t = +1

      and that at time t = 0 we happen to be exactly at (a, b, c). Let's say that our position is
       x(t), y(t), z(t) at time t. Write

                                                F(t) = f x(t), y(t), z(t)
      So F(t) is the value of f that we see on our walk at time t. Then for all t close to 0,
       x(t), y(t), z(t) is close to x(0), y(0), z(0) = (a, b, c) so that

               F(0) = f x(0), y(0), z(0) = f (a, b, c) ¤ f x(t), y(t), z(t) = F(t)

     for all t close to zero. So F(t) has a local minimum at t = 0 and consequently FI(0) = 0.

        11 If you're walking along hilly terrain, changing direction can cause you to change from going uphill to
              downhill. Direction definitely matters!

                                                               393
PROOFS AND SUPPLEMENTS                   A.7 A MORE RIGOROUS AREA COMPUTATION

By the chain rule, Theorem A.5.1,

FI(0) = d § f x(t), y(t), z(t) §§
               dt                        t=0
               = fx a, b, c xI(0) + fy a, b, c yI(0) + fz a, b, c zI(0) = 0              (¦)

We may rewrite this as a dot product:

                   0 = FI(0) =  f (a, b, c) ¤ xI(0) , yI(0) , zI(0)
                    ùñ  f (a, b, c) u xI(0) , yI(0) , zI(0)

This is true for all paths on S that pass through (a, b, c) at time 0. In particular it is true for

all vectors xI(0) , yI(0) , zI(0) that are tangent to S at (a, b, c). So  f (a, b, c) is perpendic-

ular to S at (a, b, c).
    But we already know, by the three-dimensional analogue to Corollary A.5.7, that g(a, b, c)

is also perpendicular to S at (a, b, c). So  f (a, b, c) and g(a, b, c) have to be parallel vec-
tors. That is,

                                         f (a, b, c) = g(a, b, c)
for some number . That's the Lagrange multiplier rule of our theorem.

    Section A.6 of this work was adapted from Section 2.10 of CLP 3 - Multivariable
Calculus by Feldman, Rechnitzer, and Yeager under a Creative Commons Attribution-
NonCommercial-ShareAlike 4.0 International license.

A.7 A More Rigorous Area Computation

In Example 3.1.1 above we considered the area of the region 2 (x, y) §§ 0 ¤ y ¤ ex, 0 ¤
x ¤ 1 @. We approximated that area by the area of a union of n thin rectangles. We then

claimed that upon taking the number of rectangles to infinity, the approximation of the
area became the exact area. However we did not justify the claim. The purpose of this
optional section is to make that calculation rigorous.

    The broad set-up is the same. We divide the region up into n vertical strips, each of
width 1/n and we then approximate those strips by rectangles. However rather than an
uncontrolled approximation, we construct two sets of rectangles -- one set always smaller
than the original area and one always larger. This then gives us lower and upper bounds
on the area of the region. Finally we make use of the squeeze theorem12 to establish the
result.

· To find our upper and lower bounds we make use of the fact that ex is an increasing
                                                     d ex     ex
function.  We  know  this  because  the  derivative        =      is  always  positive.  Conse-
                                                     dx
quently, the smallest and largest values of ex on the interval a ¤ x ¤ b are ea and eb,
respectively.

12 Recall that if we have 3 functions f (x), g(x), h(x) that satisfy f (x) ¤ g(x) ¤ h(x) and we know that

    limxÑa f (x) = limxÑa h(x) = L exists and is finite, then the SqueezeTheorem tells us that limxÑa g(x) =

      L.

                                                         394
PROOFS AND SUPPLEMENTS      A.7 A MORE RIGOROUS AREA COMPUTATION

· In particular, for 0 ¤ x ¤ 1/n, ex takes values only between e0 and e1/n. As a result,

   the first strip

                                                § 2 § 1 x @

                         (x, y) 0 ¤ x ¤ /n, 0 ¤ y ¤ e

    - contains the rectangle of 0 ¤ x ¤ 1/n, 0 ¤ y ¤ e0 (the lighter rectangle in the

         figure on the left below) and

    - is contained in the rectangle 0 ¤ x ¤ 1/n, 0 ¤ y ¤ e1/n (the largest rectangle in

         the figure on the left below).

Hence

                     1 0 § 2 § 1                          x @ 1 1/n
                   n  e ¤ Area (x, y) 0 ¤ x ¤ /n, 0 ¤ y ¤ e ¤ en

                y        y = ex                        y         y = ex

       e1/n e0                                e2/n
                                              e1/n e0

                      1  x                                n n 1 2 · · · nn x

                      n

· Similarly, for the second, third, . . . , last strips, as in the figure on the right above,

       n1 1/n § 2 § 1 2 x @                                      ¤ 1n e2/n
                                                                 ¤ 1 e3/n
         e ¤ Area (x, y) /n ¤ x ¤ /n, 0 ¤ y ¤ e
                                                                    n
       n1 2/n § 2 § 2 3 x @                                          ..
                                                                     .
         e ¤ Area (x, y) /n ¤ x ¤ /n, 0 ¤ y ¤ e

                ...         ...

       1n e(n¡1)/n ¤ Area2 (x, y) §§ (n¡1)/n ¤ x ¤ n/n, 0 ¤ y ¤ ex @ ¤ 1n en/n

· Adding these n inequalities together gives

1 1 + e1/n + ¤ ¤ ¤ + e(n¡1)/n

n 2§ @

                 ¤ Area (x, y) § 0 ¤ x ¤ 1, 0 ¤ y ¤ ex
                                             ¤ 1n e1/n + e2/n + ¤ ¤ ¤ + en/n

· We can then recycle equation (3.1.3) with r = e1/n, so that rn = e1/n n = e. Thus we
   have

       1/n 1 e ¡ 1 ¤ Area2 (x, y) §§ 0 ¤ x ¤ 1, 0 ¤ y ¤ ex @ ¤ 1 e 1/n 1/n e ¡ 1
       ne ¡1                                              n e ¡1

                             395
PROOFS AND SUPPLEMENTS       A.8 CAREFUL DEFINITION OF THE INTEGRAL

where we have used the fact that the upper bound is a simple multiple of the lower
bound:

             e1/n + e2/n + ¤ ¤ ¤ + en/n = e1/n 1 + e1/n + ¤ ¤ ¤ + e(n¡1)/n .

· We now apply the Squeeze Theorem to the above inequalities. In particular, the
   limits of the lower and upper bounds are

lim 1/n 1 e ¡ 1 = (e ¡ 1) lim XX = e ¡ 1
nÑV n e ¡ 1                  X=1/nÑ0 e ¡ 1

(by l'Ho^ pital's rule) and

lim 1 e 1/n 1/n e ¡ 1 = (e ¡ 1) lim ¤ XXeX
nÑV n e ¡ 1                  X=1/nÑ0 e ¡ 1
                             = (e ¡ 1) lim eX ¤ lim XX
                             XÑ0 X=Ñ0 e ¡ 1
                             = (e ¡ 1) ¤ 1 ¤ 1

Thus, since the exact area is trapped between the lower and upper bounds, the
squeeze theorem then implies that

                             Exact area = e ¡ 1.

    Section A.7 of this work was adapted from Section 1.1.1 of CLP 2 - Integral Calculus by
Feldman, Rechnitzer, and Yeager under a Creative Commons Attribution-NonCommercial-
ShareAlike 4.0 International license.

A.8 Careful Definition of the Integral

      In this optional section we give a more mathematically rigorous definition of the definite

                       »b

      integral f (x)dx. Some textbooks use a sneakier, but equivalent, definition. The integral

                         a

      will be defined as the limit of a family of approximations to the area between the graph of
      y = f (x) and the x-axis, with x running from a to b. We will then show conditions under
      which this limit is guaranteed to exist. We should state up front that these conditions are
      more restrictive than is strictly necessary -- this is done so as to keep the proof accessible.

           The family of approximations needed is slightly more general than that used to define
      Riemann sums in the previous sections, though it is quite similar. The main difference is
      that we do not require that all the subintervals have the same size.

          · We start by selecting a positive integer n. As was the case previously, this will be the
              number of subintervals used in the approximation and eventually we will take the

         limit as n Ñ V.

                                                               396
PROOFS AND SUPPLEMENTS                                        A.8 CAREFUL DEFINITION OF THE INTEGRAL

· Now subdivide the interval from a to b into n subintervals by selecting n + 1 values
   of x that obey

                                         a = x0 x1 x2 ¤ ¤ ¤ xn¡1 xn = b.

The subinterval number i runs from xi¡1 to xi. This formulation does not require

the subintervals to have the same size. However we will eventually require that the

widths of the subintervals shrink towards zero as n Ñ V.

· Then for each subinterval we select a value of x in that interval. That is, for i =
1,  2,   .  .     .  ,  n,  choose  x¦   satisfying  xi¡1  ¤  x¦   ¤  xi.  We  will  use  these  values  of  x  to  help

                                      i                         i
approximate f (x) on each subinterval.

· The area between the graph of y = f (x) and the x-axis, with x running from xi¡1

                            y

                                                                           y = f (x)

                               a = x0 x1 x2 x3 · · ·                                             x
                                                                               xn-1 xn = b

                                         ³xi
to xi, i.e. the contribution, xi¡1 f (x)dx, from interval number i to the integral, is
         ¦
approximated by the area of a rectangle. The rectangle has width xi ¡ xi¡1 and height
f  (  x  i  )  .

· Thus the approximation to the integral, using all n subintervals, is

        f (x)dx  f (x1 » b ¦)[x1 ¡ x0] + f (x2¦)[x2 ¡ x1] + ¤ ¤ ¤ + f (xn¦)[xn ¡ xn¡1]
                    a
                                                     397
PROOFS AND SUPPLEMENTS                                          A.8 CAREFUL DEFINITION OF THE INTEGRAL

·  Of  course  every  different               choice  of     n  and            x1, x2, . . . , xn¡1   and         x  ¦  ,  x  ¦  ,  .  .  .  ,  x  ¦  gives  a

                                                                                                                     1        2                    n
   different approximation. So to simplify the discussion that follows, let us denote a
   particular choice of all these numbers by P:

                                  P = (n, x1, x2, ¤ ¤ ¤ , xn¡1, x1¦, x2¦, ¤ ¤ ¤ , xn¦) .

   Similarly let us denote the resulting approximation by I (P):

               I (P)  =  f  (  x  ¦  )  [  x  1  ¡ x0] +  f  (  x  ¦  )  [  x  2  ¡ x1] + ¤ ¤ ¤ +  f  (  x  ¦  )  [  x  n  ¡ xn¡1]

                                  1                                2                                        n

· We claim that, for any reasonable13 function f (x), if you take any reasonable14 se-
   quence of these approximations you always get the exactly the same limiting value.

                       ³b

   We define a f (x)dx to be this limiting value.
· Let's be more precise. We can take the limit of these approximations in two equiv-

   alent ways. Above we did this by taking the number of subintervals n to infinity.
   When we did this, the width of all the subintervals went to zero. With the formu-
   lation we are now using, simply taking the number of subintervals to be very large
   does not imply that they will all shrink in size. We could have one very large subin-
   terval and a large number of tiny ones. Thus we take the limit we need by taking the
   width of the subintervals to zero. So for any choice P, we define

                 M(P) = max 2x1 ¡ x0 , x2 ¡ x1 , ¤ ¤ ¤ , xn ¡ xn¡1@

   that is the maximum width of the subintervals used in the approximation deter-
   mined by P. By forcing the maximum width to go to zero, the widths of all the
   subintervals go to zero.

· We then define the definite integral as the limit

                                                 »b  f (x)dx = lim I(P).

                                                 a                          M(P)Ñ0

Of course, one is now left with the question of determining when the above limit exists. A
proof of the very general conditions which guarantee existence of this limit is beyond the
scope of this course, so we instead give a weaker result (with stronger conditions) which
is far easier to prove.

    For the rest of this section, assume

  · that f (x) is continuous for a ¤ x ¤ b,

   · that f (x) is differentiable for a x b, and

  · that f I(x) is bounded -- ie | f I(x)| ¤ F for some constant F.

13 We'll be more precise about what "reasonable" means shortly.
14 Again, we'll explain this "reasonable" shortly

                                                         398
PROOFS AND SUPPLEMENTS                                        A.8 CAREFUL DEFINITION OF THE INTEGRAL

We will now show that, under these hypotheses, as M(P) approaches zero, I (P) always
approaches the area, A, between the graph of y = f (x) and the x-axis, with x running
from a to b.

    These assumptions are chosen to make the argument particularly transparent. With a
little more work one can weaken the hypotheses considerably. We are cheating a little by
implicitly assuming that the area A exists. In fact, one can adjust the argument below to
remove this implicit assumption.

  · Consider Aj, the part of the area coming from xj¡1 ¤ x ¤ xj.

   We  have  approximated            this  area  by     f  (  x  ¦  )  [  x  j  ¡  xj¡1]   (see  figure  left).

                                                                 j

· Let f (xj) and f (xj) be the largest and smallest values15 of f (x) for xj¡1 ¤ x ¤ xj.

   Then the true area is bounded by

                               f (xj)[xj ¡ xj¡1] ¤ Aj ¤ f (xj)[xj ¡ xj¡1].

   (see figure right).

·  Now since  f (xj)  ¤  f  (  x  ¦  )  ¤  f (xj), we also know that

                                  j

              f (xj)[xj              ¡  xj¡1]  ¤  f  (  x  ¦  )  [  x  j  ¡  1  ¡  xj]  ¤  f (xj)[xj  ¡  xj¡1].

                                                           j

· So both the true area, Aj, and our approximation of that area f (x¦j )[xj ¡ xj¡1] have
  to lie between f (xj)[xj ¡ xj¡1] and f (xj)[xj ¡ xj¡1]. Combining these bounds we

   have that the difference between the true area and our approximation of that area is
   bounded by

                    §§ ¦ §§

                 Aj ¡ f (xj )[xj ¡ xj¡1] ¤ [ f (xj) ¡ f (xj)] ¤ [xj ¡ xj¡1].

   (To see this think about the smallest the true area can be and the largest our approx-
   imation can be and vice versa.)

15 Here we are using the Extreme Value Theorem -- its proof is beyond the scope of this course. The
      theorem says that any continuous function on a closed interval must attain a minimum and maximum

   at least once. In this situation this implies that for any continuous function f (x), there are xj¡1 ¤
   xj, xj ¤ xj such that f (xj) ¤ f (x) ¤ f (xj) for all xj¡1 ¤ x ¤ xj.

                                                         399
PROOFS AND SUPPLEMENTS       A.8 CAREFUL DEFINITION OF THE INTEGRAL

· Now since our function, f (x) is differentiable we can apply one of the main theo-
   rems we learned in first-semester calculus -- the Mean Value Theorem16. The MVT
   implies that there exists a c between xj and xj such that

                         f (xj) ¡ f (xj) = f I(c) ¤ [xj ¡ xj]

· By the assumption that | f I(x)| ¤ F for all x and the fact that xj and xj must both be

  between xj¡1 and xj

                   §§ f (xj) ¡ f (xj)§§ ¤ F ¤ §§xj ¡ xj§§ ¤ F ¤ [xj ¡ xj¡1]

   Hence the error in this part of our approximation obeys

                           §§ ¦ §§ 2

                      Aj ¡ f (xj )[xj ¡ xj¡1] ¤ F ¤ [xj ¡ xj¡1] .

· That was just the error in approximating Aj. Now we bound the total error by com-
   bining the errors from approximating on all the subintervals. This gives

§                                 §

|A ¡ I (P)| = §§ Aj ¡ f (x §§¸ n ¸ n ¦j )[xj ¡ xj¡1]§§§§
§j=1                    j=1
                                  §

      §                                                                     §  triangle inequality
                                                                                        from above
    §n                                                                      §

      §¸                         ¦ §§

= §§                    Aj ¡ f (xj )[xj ¡ xj¡1] §

    §j=1                                                                    §

  ¸ § n § ¦ §§

¤ §Aj ¡ f (xj )[xj ¡ xj¡1]§

    j=1

    ¸ n

¤ F ¤ [xj ¡ xj¡1]2

    j=1

Now do something a little sneaky. Replace one of these factors of [xj ¡ xj¡1] (which

is just the width of the jth subinterval) by the maximum width of the subintervals:

    ¸ n                                                                        F and M(P) are constant
                                                                                        sum is total width
¤ F ¤ M(P) ¤ [xj ¡ xj¡1]

    j=1

                      ¸ n

¤ F ¤ M(P) ¤ [xj ¡ xj¡1]

                     j=1

= F ¤ M(P) ¤ (b ¡ a).

16 Recall that the Mean Value Theorem states that for a function continuous on [a, b] and differentiable on
     (a, b), there exists a number c between a and b so that

                                     f I(c) = f (b) ¡ f (a) .
                                               b¡a

                             400
PROOFS AND SUPPLEMENTS                    A.9 INTEGRATING sec x AND csc x

· Since a, b and F are fixed, this tends to zero as the maximum rectangle width M(P)
   tends to zero.

Thus, we have proven

    TheoremA.8.1.

   Assume that f (x) is continuous for a ¤ x ¤ b, and is differentiable for all a x
   b with | f I(x)| ¤ F, for some constant F. Then, as the maximum rectangle width

   M(P) tends to zero, I (P) always converges to A, the area between the graph of
   y = f (x) and the x-axis, with x running from a to b.

    Section A.8 of this work was adapted from Section 1.1.6 of CLP 2 - Integral Calculus by
Feldman, Rechnitzer, and Yeager under a Creative Commons Attribution-NonCommercial-
ShareAlike 4.0 International license.

A.9 Integrating sec x and csc x

      The antiderivatives of secant and (to a lesser extent) cosecant come up commonly enough
      that we include their computations here.

           In a traditional integral³calculus course, students may learn general methods to com-
      pute integrals of the form secn x tanm xdx. As of 2021, Math 105 no longer includes this
      content in its syllabus.

        Example A.9.1 (³ sec xdx -- by trickery)

      Solution. There is a very sneaky trick to compute this integral.

·  The standard trick for this integral is to multiply the integrand by 1 =              sec x+tan x
                                                                                         sec x+tan x

         sec x = sec x sec x + tan x sec x + tan x = sec2 x + sec x tan x sec x + tan x

· Notice now that the numerator of this expression is exactly the derivative its denom-
   inator. Hence we can substitute u = sec x + tan x and du = (sec x tan x + sec2 x) dx.

· Hence

         » » sec xdx = sec x sec x + tan x » dx = sec2 x + sec x tan x dx
                           sec x + tan x  sec x + tan x
         » = 1 du
                        u
         = ln |u| + C
         = ln | sec x + tan x| + C

                           401
PROOFS AND SUPPLEMENTS                                A.9 INTEGRATING sec x AND csc x

· The above trick appears both totally unguessable and very hard to remember. For-
   tunately, there is a simple way17 to recover the trick. Here it is.
      - The goal is to guess a function whose derivative is sec x.
      - So get out a table of derivatives and look for functions whose derivatives at
         least contain sec x. There are two:
                                              ddx tan x = sec2 x
                                              d sec x = tan x sec x
                                                dx
      - Notice that if we add these together we get

         ddx sec x + tan x = (sec x + tan x) sec x ùñ d sec x + tan x = sec x dx sec x + tan x

      - We've done it! The right hand side is sec x and the left hand side is the deriva-

      tive of ln | sec x + tan x|.

                                                                                            Example A.9.1

Example A.9.2 (³ csc xdx -- by the same trick)

Solution. The integral ³ csc xdx may also be evaluated by the method above. That is,

by multiplying the integrand by a cleverly chosen 1   =  cot x¡csc x  and then substituting
u = cot x ¡ csc x, du = (¡ csc2 x + csc x cot x) dx.     cot x¡csc x

» » csc xdx = csc x cot x ¡ csc x » dx = csc x cot x ¡ csc2 x dx
                           cot x ¡ csc x                 cot x ¡ csc x
» = 1 du
                        u
= ln |u| + C
= ln §§ cot x ¡ csc x§§ + C

                                                                        Example A.9.2

    Section A.9 of this work was adapted from Section 1.8.3 of CLP 2 - Integral Calculus by
Feldman, Rechnitzer, and Yeager under a Creative Commons Attribution-NonCommercial-
ShareAlike 4.0 International license.

17 We thank Serban Raianu for bringing this to our attention.

                                                         402
          PROOFS AND SUPPLEMENTS A.10 FURTHER READING ON NUMERICAL INTEGRATION

A.10 Further Reading on Numerical Integration

A.10.1  The Midpoint Rule

                 NotationA.10.1 (Midpoints).

             In what follows we need to refer to the midpoint between xj¡1 and xj very fre-

                quently. To save on typing (and reading) we introduce the notation

                                               x¯j = 12 xj¡1 + xj .

                             ³xj

    The integral xj¡1 f (x) dx represents the area between the curve y = f (x) and the x-

axis with x running from xj¡1 to xj. The width of this region is xj ¡ xj¡1 = x. The height

varies over the different values that f (x) takes as x runs from xj¡1 to xj.

  The midpoint rule approximates this area by the area of a rectangle of width xj ¡ xj¡1 =

x and height f (x¯j) which is the exact height at the midpoint of the range covered by x.

  f (xj)                f xj-1+xj 2
f (xj-1)

          xj-1 xj                    xj-1 x¯j xj

The area of the approximating rectangle is f (x¯j)x, and the midpoint rule approximates
each subintegral by

                                                          » xj

                                 f (x) dx  f (x¯j)x

                                            xj¡1
.

    Applying this approximation to each subinterval and summing gives us the following
approximation of the full integral:

» b » f x (x) dx = 1 » f x (x) dx + 2 » f x (x) dx + ¤ ¤ ¤ + n f (x) dx
a         x0       x1                xn¡1

           f (x¯1)x + f (x¯2)x + ¤ ¤ ¤ + f (x¯n)x

So notice that the approximation is the sum of the function evaluated at the midpoint
of each interval and then multiplied by x. Our other approximations will have similar
forms.

    In summary:

                   403
PROOFS AND SUPPLEMENTS A.10 FURTHER READING ON NUMERICAL INTEGRATION

                                                             Equation A.10.2(The midpoint rule).

   The midpoint rule approximation is

                          »b

                            f (x) dx  f (x¯1) + f (x¯2) + ¤ ¤ ¤ + f (x¯n) x

                            a

   where   x  =    b¡a  and

                    n

   x0 = a x1 = a + x x2 = a + 2x ¤ ¤ ¤ xn¡1 = b ¡ x                                          xn = b
                                                           ¤ ¤ ¤ x¯n¡1 = xn¡2+xn¡1                  xn¡1 + xn
              x¯1 = x0+x1 x¯2 = x1+x22           2                                  2
                                                                                             x¯n = 2

                               ³1 4

Example A.10.3 0 1+x2 dx

We approximate the above integral using the midpoint rule with n = 8 steps.

Solution.

·  First we set up all the x-values that we will need.                   Note that a         = 0, b  = 1, x       =  1  and
                                                                                                                     8

           x0 = 0            x1  =   1       x2      =  2       ¤¤¤      x7         =     7          x8  =  8  =  1
                                     8                  8                                 8                 8

   Consequently

              x¯1  =  1              x¯2  =  3             x¯3  =  5                ¤¤¤              x¯8 = 15
                      16                     16                    16
                                                                                                              16

· We now apply Equation (A.10.2) to the integrand f (x) = 1+4x2 :

                            f (x¯1)         f (x¯2)        f (x¯n¡1)       f (x¯n)

                          hkkikkj         hkkikkj          hkkikkj       hkkikkj

   » 1 4 dx                  2 4 + 2 4 +¤ ¤ ¤+ 2 4 + 2 4 x
                          1 + x¯1 1 + x¯2                    1 + x¯7 1 + x¯8
    0 1 + x2

           4              4               4             4             4                4             4               41
   = 1 + 32 + 52 + 72 + 92 + 112 + 132 + 152 8
           1 + 162 1 + 162 1 + 162 1 + 162 1 + 162 1 + 162 1 + 162 1 + 162
   = 3.98444 + 3.86415 + 3.64413 + 3.35738 + 3.03858 + 2.71618 + 2.40941 + 2.12890 18
   = 3.1429

   where we have rounded to four decimal places.
· In this case we can compute the integral exactly (which is one of the reasons it was

   chosen as a first example):
                                      » 1 4 §§1
                                      0 1 + x2 dx = 4 arctan x§0 = 

· So the error in the approximation generated by eight steps of the midpoint rule is

                             |3.1429 ¡ | = 0.0013

                                                        404
PROOFS AND SUPPLEMENTS A.10 FURTHER READING ON NUMERICAL INTEGRATION

· The relative error is then

                  |approximate ¡ exact| exact = |3.1429 ¡ |  = 0.0004

   That is the error is 0.0004 times the actual value of the integral.

· We can write this as a percentage error by multiplying it by 100

             percentage error = 100 ¢ |approximate ¡ exact| exact = 0.04%

   That is, the error is about 0.04% of the exact value.

                                                                                                Example A.10.3
The midpoint rule gives us quite good estimates of the integral without too much work
-- though it is perhaps a little tedious to do by hand18.

                                 ³

 Example A.10.4 0 sin x dx
As a second example, we apply the midpoint rule with n = 8 steps to the above integral.

· We again start by setting up all the x-values that we will need. So a = 0, b = ,
x        and
   =  8

      x0 = 0         x1  =     x2 = 2            ¤¤¤      x7 = 7           x8  =  8   =  
                            8                                                      8
                                         8                          8

Consequently,

         x¯1  =             x¯2 = 3         ¤¤¤       x¯7 = 13             x¯8 = 15
                 16
                                      16                        16                   16

· Now apply Equation (A.10.2) to the integrand f (x) = sin x:

»

  sin x dx  sin(x¯1) + sin(x¯2) + ¤ ¤ ¤ + sin(x¯8) x

  0

= sin(  ) + sin( 3 ) + sin( 5 ) + sin( 7 ) + sin( 9 ) + sin( 11 ) + sin( 13 ) + sin( 15 ) 
         16          16        16           16        16               16         16       16 8

= 0.1951 + 0.5556 + 0.8315 + 0.9808 + 0.9808 + 0.8315 + 0.5556 + 0.1951 ¢ 0.3927

= 5.1260 ¢ 0.3927 = 2.013

    · Again, we have chosen this example so that we can compare it against the exact
       value:

                                          » 

                       sin xdx = ¡ cos x 0 = ¡ cos  + cos 0 = 2.

                                            0

18 Thankfully it is very easy to write a program to apply the midpoint rule.

                                                         405
PROOFS AND SUPPLEMENTS A.10 FURTHER READING ON NUMERICAL INTEGRATION
    · So with eight steps of the midpoint rule we achieved

                       absolute error = |2.013 ¡ 2| = 0.013
                        relative error = |2.013 ¡ 2| 2 = 0.0065
                     percentage error = 100 ¢ |2.013 ¡ 2| = 0.65%

                                                                         2
       With little work we have managed to estimate the integral to within 1% of its true
       value.

                                                                                                Example A.10.4
    Subsection A.10.1 of this work is from Section 1.11.1 of CLP 2 - Integral Calculus by
Feldman, Rechnitzer, and Yeager under a Creative Commons Attribution-NonCommercial-
ShareAlike 4.0 International license.

A.10.2  The Trapezoidal Rule

         Consider again the area represented by the integral ³xxjj¡1 f (x) dx. The trapezoidal rule19
          (unsurprisingly) approximates this area by a trapezoid20 whose vertices lie at

                                (xj¡1, 0), (xj¡1, f (xj¡1)), (xj, f (xj)) and (xj, 0).

  f (xj)             f (xj)
f (xj-1)           f (xj-1)

          xj-1 xj            xj-1 xj

                                                                                     ³xj

The trapezoidal approximation of the integral xj¡1 f (x) dx is the shaded region in the

figure on the right above. It has width xj ¡ xj¡1 = x. Its left hand side has height f (xj¡1)

and its right hand side has height f (xj).
    As the figure below shows, the area of a trapezoid is its width times its average height.

19 This method is also called the "trapezoid rule" and "trapezium rule".
20 A trapezoid is a four sided polygon, like a rectangle. But, unlike a rectangle, the top and bottom of a

      trapezoid need not be parallel.

                                                         406
PROOFS AND SUPPLEMENTS A.10 FURTHER READING ON NUMERICAL INTEGRATION

                  y

                  r
                                   area (r - )w/2

                   area (r + )w/2
                                   area w

                                       w        x

    So the trapezoidal rule approximates each subintegral by

                          » xj f (x) dx  f (xj¡1)+ f (x 2 j) x

                                        xj¡1
Applying this approximation to each subinterval and then summing the result gives us
the following approximation of the full integral

       »b                     » x1                   » x2                +¤¤¤ +        » xn
                  f (x) dx = f (x) dx
               a                 x0             + f (x) dx                                    f (x) dx
                                                                                        xn¡1
                                                       x1

                              f (x0)+ f (x1)           f (x1)+ f (x2)               f (xn¡1)+ f (xn)
                            2 x + 2 x + ¤ ¤ ¤ +                                              2           x

                           =     1  f  (x0)  +  f (x1) +  f (x2) + ¤ ¤ ¤ +  f  (xn¡1)  +     1  f  (xn)  x
                                 2                                                           2

So notice that the approximation has a very similar form to the midpoint rule, excepting
that

· we evaluate the function at the xj's rather than at the midpoints, and

· we multiply the value of the function at the endpoints x0, xn by 1/2.
In summary:

                                                            Equation A.10.5(The trapezoidal rule).

The trapezoidal rule approximation is

       »b                  1  f  (x0)  +     f (x1) +  f (x2) + ¤ ¤ ¤ +  f  (xn¡1)  +  1  f  (xn)  x
                           2                                                           2
         f (x) dx 

         a

where

x = b¡a ,         x0 = a,     x1 = a + x, x2 = a + 2x, ¤ ¤ ¤ , xn¡1 = b ¡ x,                                xn = b

            n

    To compare and contrast we apply the trapezoidal rule to the examples we did above
with the midpoint rule.

                                 ³1 4

 Example A.10.6 0 1+x2 dx -- using the trapezoidal rule
Solution. We proceed very similarly to Example A.10.3 and again use n = 8 steps.

                                                       407
PROOFS AND SUPPLEMENTS A.10 FURTHER READING ON NUMERICAL INTEGRATION

·  We again have     f (x)     =  1+4x2 , a  = 0, b       = 1, x         =    1  and
                                                                              8

          x0 = 0            x1  =    1          x2  =     2              ¤¤¤           x7  =  7        x8     =    8  =  1
                                     8                    8                                   8                    8

· Applying the trapezoidal rule, Equation (A.10.5), gives

                                          f (x0)            f (x1)               f (xn¡1)             f (xn)

                                        hkkikkj           hkkikkj                hkkikkj            hkkikkj

              »1 4       2 dx           14                      4                      4 14
                                                2 + 2 +¤ ¤ ¤+ 2 +                                      2 x
              0 1+x                     2 1 + x0 1 + x1                          1 + x7 2 1 + x8

                                        14                      4             4            4
                                = 2 1 + 02 + 1 + 1 + 22 + 32
                                                                   82 1 + 82 1 + 82

                                             4                  4             4            4 14 1
                                     + 42 + 52 + 62 + 72 + 2 82 8
                                        1 + 82 1 + 82 1 + 82 1 + 82                                    1 + 82
                                = 12 ¢ 4 + 3.939 + 3.765 + 3.507
                                     + 3.2 + 2.876 + 2.56 + 2.266 + 1 ¢ 2 1
                                                                                       28
                                = 3.139

   to three decimal places.

· The exact value of the integral is still . So the error in the approximation generated
                                                                |3.139   ¡    |                                    |3.139¡|
   by  eight  steps  of  the   trapezoidal      rule      is                     =  0.0026,   which    is     100            %  =
                                                                                                                        
   0.08% of the exact answer. Notice that this is roughly twice the error that we achieved
   using the midpoint rule in Example A.10.3.

                                                                                                       Example A.10.6

    Let us also redo Example A.10.4 using the trapezoidal rule.

                                 ³

 Example A.10.7 0 sin x dx -- using the trapezoidal rule
Solution. We proceed very similarly to Example A.10.4 and again use n = 8 steps.

·  We again have a       = 0, b   =     , x     =         and
                                                       8

          x0 = 0         x1    =             x2 = 2                      ¤¤¤        x7 = 7             x8     =  8    =  
                                  8                                                                               8
                                                       8                                      8

· Applying the trapezoidal rule, Equation (A.10.5), gives

   »   sin x dx      1   sin(x0)        sin(x1)           ¤  ¤  ¤     sin(x7)       1  sin(x8)      x
                     2                                                              2
   0                                 +              +              +             +

   = 1 sin 0 + sin  + sin 2 + sin 3 + sin 4 + sin 5 + sin 6 + sin 7 + 1 sin 8 8
       2                 8           8              8                            8               8            82            88

   =   1  ¢0  +  0.3827     +  0.7071   +  0.9239      +      1.0000     +    0.9239   +   0.7071   +  0.3827      +  1  ¢0  ¢ 0.3927
       2                                                                                                              2

   = 5.0274 ¢ 0.3927 = 1.974

                                                          408
PROOFS AND SUPPLEMENTS A.10 FURTHER READING ON NUMERICAL INTEGRATION

                                               ³ §§

  · The exact answer is 0 sin x dx = ¡ cos x§ = 2. So with eight steps of the trape-

                                      |1.974¡2| 0

       zoidal rule we achieved 100 2 = 1.3% accuracy. Again this is approximately
       twice the error we achieved in Example A.10.4 using the midpoint rule.

                                                                                                Example A.10.7

    These two examples suggest that the midpoint rule is more accurate than the trape-
zoidal rule. Indeed, this observation is born out by a rigorous analysis of the error -- see
A.10.3 .

    Subsection A.10.2 of this work is included from Section 1.11.2 of CLP 2 - Integral
Calculus by Feldman, Rechnitzer, and Yeager under a Creative Commons Attribution-
NonCommercial-ShareAlike 4.0 International license.

A.10.3  Error Behaviour

         As mentioned in Section 3.6.2, n steps of Simpson's rule requires us to evaluate f (x) a total
         of n + 1 times. For the trapezoid rule, it is the same; for the midpoint rule, we evaluate
          f (x) only n times. So in all three rules, the amount of "effort" needed is roughly equivalent
          in most circumstances.

              To get a first impression of the error behaviour of these methods, we apply them to a
          problem whose answer we know exactly:

                                                                    » §

                                    sin x dx = ¡ cos x§ = 2.

                                                                      00

          To be a little more precise, we would like to understand how the errors of the three meth-
          ods change as we increase the effort we put in (as measured by the number of steps n). The
          following table lists the error in the approximate value for this number generated by our
          three rules applied with three different choices of n. It also lists the number of evaluations
          of f required to compute the approximation.

   Midpoint  Trapezoidal  Simpson's

n  error # evals error # evals error # evals
10 8.2 ¢ 10¡3 10 1.6 ¢ 10¡2 11 1.1 ¢ 10¡4 11
100 8.2 ¢ 10¡5 100 1.6 ¢ 10¡4 101 1.1 ¢ 10¡8 101
1000 8.2 ¢ 10¡7 1000 1.6 ¢ 10¡6 1001 1.1 ¢ 10¡12 1001

Observe that
    · Using 101 evaluations of f worth of Simpson's rule gives an error 80 times smaller
       than 1000 evaluations of f worth of the midpoint rule. (See why we focus on Simp-
       son's over midpoint?)
    · The trapezoidal rule error with n steps is about twice the midpoint rule error with n
       steps. (Hence its relegation to this appendix.)

             409
PROOFS AND SUPPLEMENTS A.10 FURTHER READING ON NUMERICAL INTEGRATION

· With the midpoint rule, increasing the number of steps by a factor of 10 appears to
   reduce the error by about a factor of 100 = 102 = n2.

· With the trapezoidal rule, increasing the number of steps by a factor of 10 appears
   to reduce the error by about a factor of 102 = n2.

· With Simpson's rule, increasing the number of steps by a factor of 10 appears to
   reduce the error by about a factor of 104 = n4.

So it looks like

                             »b   f (x) dx given by n midpoint steps     »  b     f (x) dx + KM ¤ n21
                                  f (x) dx given by n trapezoidal steps        a  f (x) dx + KT ¤ n21
approx value of                   f (x) dx given by n Simpson's steps             f (x) dx + KS ¤ n41
                                                                         »  b
                               a                                               a
                             »b
                                                                         »  b
approx value of                                                                a

                               a
                             »b

approx value of

                               a

with some constants KM, KT and KS. It also seems that KT  2KM. The intuition, about the

error behaviour, that we have just developed is in fact correct -- provided the integrand
f (x) is reasonably smooth. To be more precise:

TheoremA.10.8 (Numerical integration errors).

Assume that | f P(x)| ¤ M for all a ¤ x ¤ b. Then

the total error introduced by the midpoint rule is bounded by                     M (b ¡ a)3
and
the total error introduced by the trapezoidal rule is bounded by                  24 n2

                                                                                  M (b ¡ a)3

                                                                                  12 n2

                                      »b

when approximating f (x)dx. Further, if | f (4)(x)| ¤ L for all a ¤ x ¤ b, then
                                        a

the total error introduced by Simpson's rule is bounded by 180 n4 L (b ¡ a)5 .

              Subsection A.10.3 of this work is adapted from Section 1.11.4 of CLP 2 - Integral
          Calculus by Feldman, Rechnitzer, and Yeager under a Creative Commons Attribution-
          NonCommercial-ShareAlike 4.0 International license.

A.10.4  An Error Bound for the Midpoint Rule

          We now try develop some understanding as to why we got the experimental results of
          section A.10.3. We start with the error generated by a single step of the midpoint rule.

                                                                   410
PROOFS AND SUPPLEMENTS A.10 FURTHER READING ON NUMERICAL INTEGRATION

That is, the error introduced by the approximation

  » x1                          where  x              =  x1 ¡ x0,  x¯1  =  x0+x1
                                                                              2
     f (x) dx  f (x¯1)x

    x0

To do this we are going to need to apply integration by parts in a sneaky way. Let us start

by considering21 a subinterval  ¤ x ¤  and let's call the width of the subinterval 2q so

that  =  + 2q. If we were to now apply the midpoint rule to this subinterval, then we
would write

                                  »

                    f (x)dx  2q ¤ f ( + q) = q f ( + q) + q f ( ¡ q)

                                    

since the interval has width 2q and the midpoint is  + q =  ¡ q.

    The sneaky trick we will employ is to write

    »  f (x)dx =         » +q                         »
                                 f (x)dx + ¡q f (x)dx
                           

and then examine each of the integrals on the right-hand side (using integration by parts)
and show that they are each of the form

    » +q

        f (x)dx  q f ( + q) + small error term

      
     »

        f (x)dx  q f ( ¡ q) + small error term

     ¡q

   Let us apply integration by parts to  ³+q f (x)dx -- with u = f (x), dv = dx so du =

f I(x)dx and we will make the slightly non-standard choice of v = x ¡ :

  f (x)dx = (x ¡ ) f (x) + » +q q » +q  ¡ (x ¡ ) f I(x)dx
                                                      
       = q f ( + q) ¡ (x ¡ ) f » +q I(x)dx
                                

Notice that the first term on the right-hand side is the term we need, and that our non-
standard choice of v allowed us to avoid introducing an f () term.

  Now integrate by parts again using u = f I(x), dv = (x ¡ )dx, so du = f P(x), v =

(x¡)2

   2:

f (x)dx = q f ( + q) ¡ (x ¡ ) f » +q » +q I(x)dx
                         
    = q f ( + q) ¡ (x ¡ )2 f I +q » +q (x) + (x ¡ )2 f P(x)dx
                             2                                          2
                                                    
    = q f ( + q) ¡ q2 f I » +q ( + q) + (x ¡ )2 f P(x)dx
                  2                                      2

21 We chose this interval so that we didn't have lots of subscripts floating around in the algebra.

                                411
PROOFS AND SUPPLEMENTS A.10 FURTHER READING ON NUMERICAL INTEGRATION

To obtain a similar expression for the other integral, we repeat the above steps and obtain:

              f (x)dx = q f ( ¡q ¡ q) + 2 f »  q2 I( ¡ q) + f »  (x ¡ )2 P(x)dx ¡q 2

Now add together these two expressions

f (x)dx + f (x)dx = q f ( + q) + q f (  ¡q ¡ q) + 2 ( f » +q »  q2 I( ¡ q) ¡ f I( + q))

                                       » +q + (x ¡ )2 f P »  (x)dx + (x ¡ )2 f P(x)dx2
                                                                                                   ¡q 2
                                             

Then since  + q =  ¡ q we can combine the integrals on the left-hand side and eliminate

some terms from the right-hand side:

              f (x)dx = 2q f ( + q) + f »  » +q (x ¡ )2 P(x)dx + f »  (x ¡ )2 P(x)dx
                                                                                             2                   ¡q 2
                                                                              

Rearrange this expression a little and take absolute values

      §                                      § § ( §§ §§» +q x ¡ )2 P                              §§ §§»                                          §

      §»                                                                                           §§       (x ¡ )2 f P § (x)dx§§

      §
      § f (x)dx ¡ 2q f ( + q)§ ¤ §                                                     f (x)dx§ + §
      §                                      §                             2                       § ¡q 2                §

where we have also made use of the triangle inequality22. By assumption | f P(x)| ¤ M on
the interval  ¤ x ¤ , so

           § § ( §§»  §§ » +q x § f (x)dx ¡ 2q f ( + q)§ ¤ M ¡ )2 » dx  + M (x ¡ )2 dx 2
           §                                      §                                                         ¡q 2

                                                     = Mq3 = M( ¡ )3
                                                                  3                       24
                                  ¡
where we have used q = 2 in the last step.
   Thus on any interval xi ¤ x ¤ xi+1 = xi + x

                        §§» xi+1                                           xi + xi+1            §  M
                                                                               2
                        §              f (x)dx ¡ x f                                            §§§ ¤ 24 (x)  3
                        §
                              xi

    Putting everything together we see that the error using the midpoint rule is bounded
by

§                                                                                   §
§» b
                                                                                    §
§§ f (x)dx ¡ [ f (x¯1) + f (x¯2) + ¤ ¤ ¤ + f (x¯n)] x§§
§a                                                                                  §

                  §» x                                               §                 §                          §
                                                                                       §» x
              ¤ §§§1 § §n §                                                   ¤                                   §
                                             ¡                             ¤     ¤              f (x)dx ¡ x f (x¯n)§
                           f  (  x  )  d  x       x  f  (  x¯  1  )  §  +           +  §
                                                                     §
                    x0                                                                 § xn¡1                     §

                                                                                 M                    M b ¡ a 3 M(b ¡ a)3
                                                               ¤ n ¢ (x) = n ¢               3                        =
                                                                              24                      24 n               24n                          2

22 The triangle inequality says that for any real numbers x, y

                                      |x + y| ¤ |x| + |y|.

                                                                        412
PROOFS AND SUPPLEMENTS                            A.11 COMPARISON TESTS PROOF

as required.
    A very similar analysis shows that, as was stated in Theorem 3.6.5 above,

                                                                     M (b ¡ a)3
· the total error introduced by the trapezoidal rule is bounded by              2,
                                                                     12 n

· the total error introduced by Simpson's rule is bounded by 180 n4 M (b ¡ a)5

    Subsection A.10.4 of this work was adapted from Section 1.11.5 of CLP 2 - Integral
Calculus by Feldman, Rechnitzer, and Yeager under a Creative Commons Attribution-
NonCommercial-ShareAlike 4.0 International license.

A.11 Comparison Tests Proof

In this and the next optional section we provide proofs of two convergence tests. We shall

repeatedly use the fact that any sequence a1, a2, a3, ¤ ¤ ¤ , of real numbers which is increasing
(i.e. an+1 ¥ an for all n) and bounded (i.e. there is a constant M such that an ¤ M for all n)

converges. We shall not prove this fact23.
    We start with the comparison test, and then move on to the alternating series test.

TheoremA.11.1 (The Comparison Test).

Let N0 be a natural number and let K ¡ 0.

(a) If |an| ¤ Kcn for all n ¥ N0 and ° V cn converges, then ° V an converges.
                             n=0                    n=0

(b) If an ¥ Kdn ¥ 0 for all n ¥ N0 and ° V dn diverges, then ° V an diverges.
                                        n=0         n=0

°V                                                                   °V
Proof. (a) By hypothesis n=0 cn converges. So it suffices to prove that n=0[Kcn ¡ an]
converges, because then, by our Arithmetic of series Theorem 5.2.9,

                        ¸ V  ¸ V             ¸ V
                             an = Kcn ¡ [Kcn ¡ an]

                        n=0  n=0             n=0

will converge too. But for all n ¥ N0, Kcn ¡ an ¥ 0 so that, for all N ¥ N0, the partial sums

                                        ¸ N

                             SN = [Kcn ¡ an]

                                       n=0

increase with N, but never gets bigger than the finite number ° [ N0 Kcn ¡ an] + K ° V cn. So
                                                    n=0                         n=N0+1
the partial sums SN converge as N Ñ V.

23 It is one way to state a property of the real number system called "completeness". The interested reader
      should use their favourite search engine to look up "completeness of the real numbers".

                                        413
PROOFS AND SUPPLEMENTS                                    A.12 ALTERNATING SERIES

(b) For all N ¡ N0, the partial sum

                                     ¸ N  ¸ N0       ¸ N
                               SN = an ¥ an + K dn

                                     n=0  n=0   n=N0+1

                           °N

By hypothesis, n=N0+1 dn, and hence SN, grows without bound as N Ñ V. So SN Ñ V
as N Ñ V.

    Section A.11 of this work was adapted from Section 3.3.10 of CLP 2 - Integral Calculus
by Feldman, Rechnitzer, and Yeager under a Creative Commons Attribution-NonCommercial-
ShareAlike 4.0 International license.

A.12 Alternating Series

A.12.1  The Alternating Series Test

A common convergence test for series that is not included in our learning goals is the
Alternating Series Test. First, we need to know what an alternating series is.
When the signs of successive terms in a series alternate between + and ¡, like for
example in  1¡  1     1  ¡  1  + ¤ ¤ ¤ , the series is called an alternating series.  More generally, the
                2  +  3     4

¸ series V
                            A1 ¡ A2 + A3 ¡ A4 + ¤ ¤ ¤ = (¡1)n¡1An

                                                n=1

is alternating if every An ¥ 0. Often (but not always) the terms in alternating series get
successively smaller. That is, then A1 ¥ A2 ¥ A3 ¥ ¤ ¤ ¤ . In this case:

· The first partial sum is S1 = A1.

· The second partial sum, S2 = A1 ¡ A2, is smaller than S1 by A2.
· The third partial sum, S3 = S2 + A3, is bigger than S2 by A3, but because A3 ¤ A2,

   S3 remains smaller than S1. See the figure below.

· The fourth partial sum, S4 = S3 ¡ A4, is smaller than S3 by A4, but because A4 ¤ A3,

   S4 remains bigger than S2. Again, see the figure below.

· And so on.

So the successive partial sums oscillate, but with ever decreasing amplitude. If, in ad-

dition, An tends to 0 as n tends to V, the amplitude of oscillation tends to zero and the
sequence S1, S2, S3, ¤ ¤ ¤ converges to some limit S.

    Here is a convergence test for alternating series that exploits this structure, and that is
really easy to apply.

                                          414
PROOFS AND SUPPLEMENTS                                          A.12 ALTERNATING SERIES

TheoremA.12.1 (Alternating Series Test).

    2 @V

Let An n=1 be a sequence of real numbers that obeys

 (i) An ¥ 0 for all n ¥ 1 and
 (ii) An+1 ¤ An for all n ¥ 1 (i.e. the sequence is monotone decreasing) and

(iii) limnÑV An = 0.

Then              A1 ¡ A2 + A3 ¡ A4 + ¤ ¤ ¤ = ( ¸ V ¡1)n¡1An = S

                                                 n=1

converges and, for each natural number N, S ¡ SN is between 0 and (the first
dropped term) (¡1)N AN+1. Here SN is, as previously, the Nth partial sum
° N (¡1)n¡1 An.

n=1

"Proof". We shall only give part of the proof here. For the rest of the proof see the ap-
pendix section A.11. We shall fix any natural number N and concentrate on the last state-
ment, which gives a bound on the truncation error (which is the error introduced when
you approximate the full series by the partial sum SN)

   EN = S ¡ SN = ( ¸ V ¡1)n¡1 An = (¡1)N AN+1 ¡ AN+2 + AN+3 ¡ AN+4 + ¤ ¤ ¤

                                  n=N+1

This is of course another series. We're going to study the partial sums

                  SN, = ( ¸  ¡1)n¡1 An = (¡1)N ( ¸ ¡N ¡1)m¡1 AN+m

                  n=N+1                               m=1

for that series.

· If I ¡ N + 1, with I ¡ N even,

                         ¥0                     ¥0                    hkkkkkkk¥i0kkkkkkkj

                  hkkkkkkkkkikkkkkkkkkj  hkkkkkkkkkikkkkkkkkkj

(¡1)NSN,I = (AN+1 ¡ AN+2) + (AN+3 ¡ AN+4) + ¤ ¤ ¤ + (AI¡1 ¡ AI) ¥ 0                        and

               hkkkkk¥i0kkkkkj hkk¥i0kkj

(¡1)NSN,I+1 = (¡1)NSN,I + AI+1 ¥ 0

This tells us that (¡1)NSN, ¥ 0 for all  ¡ N + 1, both even and odd.

· Similarly, if I ¡ N + 1, with I ¡ N odd,

                        hkkkkkkk¥i0kkkkkkkj      hkkkkkkk¥i0kkkkkkkj     hkkkkkkk¥i0kkkkkkkj

(¡1)NSN,I = AN+1 ¡ (AN+2 ¡ AN+3) ¡ (AN+4 ¡ AN+5) ¡ ¤ ¤ ¤ ¡ (AI¡1 ¡ AI) ¤ AN+1
                    ¤AN+1
                                 hkk¥i0kkj
                  hkkkkkikkkkkj

(¡1)NSN,I+1 = (¡1)NSN,I ¡ AI+1 ¤ AN+1

This tells us that (¡1)NSN, ¤ AN+1 for all for all  ¡ N + 1, both even and odd.

                                            415
PROOFS AND SUPPLEMENTS                                                   A.12 ALTERNATING SERIES

So we now know that SN, lies between its first term, (¡1)N AN+1, and 0 for all  ¡ N + 1.

While we are not going to prove it here (see the optional section A.11), this implies that,

since AN+1 Ñ 0 as N Ñ V, the series converges and that
                               S ¡ SN = lim SN,

                                                  ÑV

lies between (¡1)N AN+1 and 0.

Example A.12.2

                                                                         °V 1
We have already seen, in Example 5.3.7, that the harmonic series n=1 n diverges. On the
other  hand,  the   series     °V (¡1)n¡1 1          converges  by  the  alternating  series  test  with  An  =  1.
                                 n=1           n
Note that                                                                                                        n

(i)    An =   1  ¥  0  for  all  n  ¥  1,  so  that  °V (¡1)n¡1     1  really is an alternating series, and
              n                                                     n
(ii)          1                                         n=1
       An =   n  decreases as n increases, and

(iii)  lim  An   =  lim     1  = 0.
       nÑV          nÑV     n

so that all of the hypotheses of the alternating series test, i.e. of Theorem A.12.1, are
satisfied. We shall see, in Example 6.2.8, that

                                               = ¸ V (¡1)n¡1 ln 2.

                                               n=1 n

                                                                                              Example A.12.2

 Example A.12.3 (e)

                                 x °V xn

You may already know that e = n=0 n! . In any event, we shall prove this in Exam-
ple 6.3.3, below. In particular

              1 = e¡1 = = ¸ V (¡1)n 1 ¡ 1 + 1 ¡ 1 + 1 ¡ 1 + ¤ ¤ ¤

                      e n=0 n! 1! 2! 3! 4! 5!
is an alternating series and satisfies all of the conditions of the alternating series test, The-
orem A.12.1a:

  (i) The terms in the series alternate in sign.
 (ii) The magnitude of the nth term in the series decreases monotonically as n increases.

(iii) The nth term in the series converges to zero as n Ñ V.

So the alternating series test guarantees that, if we approximate, for example,

                     1e  12! ¡ 13! + 14! ¡ 15! + 16! ¡ 17! + 18! ¡ 19!

                                                         416
PROOFS AND SUPPLEMENTS                                                             A.12 ALTERNATING SERIES

then the error in this approximation lies between 0 and the next term in the series, which
is  1.   That  is

    10!

12! ¡ 13! + 14! ¡ 15! + 16! ¡ 17! + 18! ¡ 19! ¤ 1e ¤ 12! ¡ 13! + 14! ¡ 15! + 16! ¡ 17! + 18! ¡ 19! + 110!

so that

                            1                             1 ¤ e ¤ 1 1 1 1 1 1 1 1 1
                                                                     2! ¡ 3! + 4! ¡ 5! + 6! ¡ 7! + 8! ¡ 9!
    11 11 11 11
    2! ¡ 3! + 4! ¡ 5! + 6! ¡ 7! + 8! ¡ 9! + 10!

which, to seven decimal places says

                                            2.7182816 ¤ e ¤2.7182837

(To seven decimal places e = 2.7182818.)
    The alternating series test tells us that, for any natural number N, the error that we
                                                                               °N (¡1)n
make when we approximate e by the partial sum SN = n=0 n! has magnitude no1

larger   than     1.       This  tends  to  zero  spectacularly      quickly   as  N  increases,  simply  because

               (N+1)!
(N + 1)! increases spectacularly quickly as N increases24. For example 20!  2.4 ¢ 1027.

                                                                                               Example A.12.3

Example A.12.4

We will shortly see, in Example 6.2.8, that if ¡1 x ¤ 1, then

                       ln(1 + x) = x ¡ x + 2 x3 ¡ x + 4 ¤ ¤ ¤ = ( ¸ V ¡1)n¡1 xn
                                              2 34                             n=1 n

Suppose  that      we  have  to  compute    ln    11  to   within  an  accuracy    of  10¡12.  Since  11  =  1+  1,
                   11                             10             1,                                   10
we  can  get   ln  10  by  evaluating   ln(1      x)  at   x         so  that                                    10
                                                                 10
                                              +               =

    ln 1110 = ln 1 + 110 = 110 ¡ 2 ¢ 102 1 + 3 ¢ 103 1 ¡ 4 ¢ 104 1 + ¤ ¤ ¤ = ( ¸ V ¡1)n¡1 n=1 n ¢ 10n 1

By the alternating series test, this series converges. Also by the alternating series test,
approximating      ln  11  by    throwing   away      all  but  the  first  N  terms
                       10

ln 1110  110 ¡ 2 ¢ 102 1 + 3 ¢ 103 1 ¡ 4 ¢ 104 1 + ¤ ¤ ¤ + (¡1)N¡1 N ¢ 10N 1 = ( ¸ N ¡1)n¡1 n=1 n ¢ 10n 1

introduces an error whose magnitude is no more than the magnitude of the first term that
we threw away.

                            error ¤ (N + 1) ¢ 10N+1 1

24 cThe interested reader may wish to check out "Stirling's approximation", which says that n! 

        2n n n.

                     e

                                                           417
PROOFS AND SUPPLEMENTS                                                                   A.12 ALTERNATING SERIES

To achieve an error that is no more than 10¡12, we have to choose N so that

                                                            1        ¤ 10¡12
                                  (N + 1) ¢ 10N+1

The best way to do so is simply to guess -- we are not going to be able to manipulate the
inequality           1   ¤    1   into  the            form    N  ¤  ¤¤¤,  and  even     if  we  could,  it  would  not   be
                            1012
            (N+1)¢10N+1
worth the effort. We need to choose N so that the denominator (N + 1) ¢ 10N+1 is at least
1012. That is easy, because the denominator contains the factor 10N+1 which is at least 1012
whenever N + 1 ¥ 12, i.e. whenever N ¥ 11. So we will achieve an error of less than
10¡12 if we choose N = 11.

                                  1 §§§ = 1 1

                         (N + 1) ¢ 10N+1 §N=11 12 ¢ 1012 1012

This is not the smallest possible choice of N, but in practice that just doesn't matter -- your
computer is not going to care whether or not you ask it to compute a few extra terms. If
you really need the smallest   N  that obeys                            1   ¤     1   ,  you  can  next  just  try  N     10,
                                                                                1012                                   =
                                                               (N+1)¢10N+1
then N = 9, and so on.

                            1 §§§ = 1 1
            (N + 1) ¢ 10N+1 §N=11 12 ¢ 1012 1012
                            1 §§                                    1              1               1
                                                                            10 ¢ 1011 = 1012
            (N + 1)                              §  N=10    = 11 ¢ 1011

                            ¢ 10N+1 §               §

                            1                       §       = 10 ¢ 1010 = 1011 ¡ 101211      1

            (N + 1)         ¢ 10N+1 §               §

                                                       N=9

So in this problem, the smallest acceptable N = 10.                                                   Example A.12.4
                                                         418
PROOFS AND SUPPLEMENTS                   A.13 DELICACY OF CONDITIONAL CONVERGENCE

A.12.2  Alternating Series Test Proof

     TheoremA.12.5 (Alternating Series Test).

         2 @V

     Let an n=1 be a sequence of real numbers that obeys

      (i) an ¥ 0 for all n ¥ 1 and
      (ii) an+1 ¤ an for all n ¥ 1 (i.e. the sequence is monotone decreasing) and

     (iii) limnÑV an = 0.

     Then             a1 ¡ a2 + a3 ¡ a4 + ¤ ¤ ¤ = ( ¸ V ¡1)n¡1an = S

                                                    n=1

     converges and, for each natural number N, S ¡ SN is between 0 and (the first
     dropped term) (¡1)N aN+1. Here SN is, as previously, the Nth partial sum
     ° N (¡1)n¡1an.

     n=1

Proof.  Let 2n  be an even natural number. Then the 2nth partial sum obeys
        S2n =
                hkkk¥i0kkkj hkkk¥i0kkkj  hkkkkkk¥i0kkkkkkj
           ¤
                (a1 ¡ a2) + (a3 ¡ a4) + ¤ ¤ ¤ + (a2n¡1 ¡ a2n)         ¥0
                hkkk¥i0kkkj hkkk¥i0kkkj  hkkkkkk¥i0kkkkkkj
                                                               hkkkkkkkkikkkkkkkkj

                (a1 ¡ a2) + (a3 ¡ a4) + ¤ ¤ ¤ + (a2n¡1 ¡ a2n) + (a2n+1 ¡ a2n+2) =   S2(n+1)

and

                      hkk¥i0kkj          hkk¥i0kkj              ¥0            hkk¥i0kkj

                                                         hkkkkkkkkikkkkkkkkj

                S2n = a1 ¡ (a2 ¡ a3) ¡ (a4 ¡ a5) ¡ ¤ ¤ ¤ ¡ (a2n¡2 ¡ a2n¡1) ¡ a2n
                ¤ a1

So the sequence S2, S4, S6, ¤ ¤ ¤ of even partial sums is a bounded, increasing sequence and

hence converges to some real number S. Since S2n+1 = S2n + a2n+1 and a2n+1 converges

zero as n Ñ V, the odd partial sums S2n+1 also converge to S. That S ¡ SN is between 0
and (the first dropped term) (¡1)N aN+1 was already proved in §A.12.1.

    Section A.12 of this work was adapted from Sections 3.3.4 and 3.3.10 of CLP 2 - Integral
Calculus by Feldman, Rechnitzer, and Yeager under a Creative Commons Attribution-
NonCommercial-ShareAlike 4.0 International license.

A.13 Delicacy of Conditional Convergence

        Conditionally convergent series have to be treated with great care. For example, switching
        the order of the terms in a finite sum does not change its value.

                                     1+2+3+4+5+6 = 6+3+5+2+4+1

                                                                  419
PROOFS AND SUPPLEMENTS                           A.13 DELICACY OF CONDITIONAL CONVERGENCE

The same is true for absolutely convergent series. But it is not true for conditionally con-
vergent series. In fact by reordering any conditionally convergent series, you can make it

add up to any number you like, including +V and ¡V. This very strange result is known

as Riemann's rearrangement Theorem, named after Bernhard Riemann (1826-1866). The
following example illustrates the phenomenon.

 Example A.13.1

The alternating Harmonic series

                                                 ( ¸ V ¡1)n¡1 1n

                                                 n=1

is a very good example of conditional convergence. We can show, quite explicitly, how
we can rearrange the terms to make it add up to two different numbers. Later, in Exam-
ple 6.2.8, we'll show that this series is equal to ln 2. However, by rearranging the terms we
can  make  it  sum  to  1  ln  2.  The  usual  order   is
                        2

                                        11 ¡ 12 + 13 ¡ 14 + 15 ¡ 16 + ¤ ¤ ¤

For the moment think of the terms being paired as follows:

                                   11 ¡ 12 + 13 ¡ 14 + 15 ¡ 16 + ¤ ¤ ¤

so the denominators go odd-even odd-even. Now rearrange the terms so the denomina-
tors are odd-even-even odd-even-even:

                 1 ¡ 12 ¡ 14 + 13 ¡ 16 ¡ 18 + 15 ¡ 110 ¡ 112 + ¤ ¤ ¤

Now notice that the first term in each triple is exactly twice the second term. If we now
combine those terms we get

                                                                             

                     1 1 1 1 1 1 1 1 

                    1¡ ¡ + ¡ ¡ + ¡ ¡ +¤¤¤

                    loomoo2n 4  l3oomoo6n 8  l5oom1oo0n 12 

                           =1/2                  =1/6             =1/10

                    = 12 ¡ 14 + 16 ¡ 18 + 110 ¡ 112 + ¤ ¤ ¤

We   can  now  extract  a  factor  of   1  from  each  term,  so
                                        2

                    = 1 1 2 1 ¡ 12 + 1 1 2 3 ¡ 14 + 1 1 2 5 ¡ 16 + ¤ ¤ ¤
                    = 1 1 2 1 ¡ 12 + 13 ¡ 14 + 15 ¡ 16 + ¤ ¤ ¤

So by rearranging the terms, the sum of the series is now exactly half the original sum!

                                                       420
PROOFS AND SUPPLEMENTS             A.13 DELICACY OF CONDITIONAL CONVERGENCE

                                                                                 Example A.13.1

    In fact, we can go even further, and show how we can rearrange the terms of the
alternating harmonic series to add up to any given number25. For the purposes of the
example we have chosen 1.234, but it could really be any number. The example below can
actually be formalised to give a proof of the rearrangement Theorem.

 Example A.13.2

                                                                           ° V n¡1 1

  We'll show how to reorder the conditionally convergent series (¡1) n so that it

                                                                                                                  n=1

adds up to exactly 1.234 (but the reader should keep in mind that any fixed number will
work).

    · First create two lists of numbers -- the first list consisting of the positive terms of the
       series, in order, and the second consisting of the negative numbers of the series, in
       order.

               1, 13, 15, 17, ¤ ¤ ¤ and ¡12, ¡14, ¡16, ¤ ¤ ¤

· Notice that that if we add together the numbers in the second list,we get

                                   ¡12 1 + 12 + 13 + ¤ ¤ ¤

which  is  just  ¡1    times  the  harmonic  series.  So  the  numbers  in  the  second  list  add  up
to ¡V.              2

Also, if we add together the numbers in the first list, we get

       1 + 13 + 15 + 17 ¤ ¤ ¤      which is greater than       12 + 14 + 16 + 18 + ¤ ¤ ¤

That is, the sum of the first set of numbers must be bigger than the sum of the second

set of numbers (which is just ¡1 times the second list). So the numbers in the first
list add up to +V.

· Now we build up our reordered series. Start by moving just enough numbers from
   the beginning of the first list into the reordered series to get a sum bigger than 1.234.

                                            1 + 13 = 1.3333
We know that we can do this, because the sum of the terms in the first list diverges

to +V.

25 This is reminiscent of the accounting trick of pushing all the company's debts off to next year so that
      this year's accounts look really good and you can collect your bonus.

                                                         421
PROOFS AND SUPPLEMENTS  A.13 DELICACY OF CONDITIONAL CONVERGENCE

· Next move just enough numbers from the beginning of the second list into the re-
   ordered series to get a number less than 1.234.

                              1 + 13 ¡ 12 = 0.8333

   Again, we know that we can do this because the sum of the numbers in the second

  list diverges to ¡V.

· Next move just enough numbers from the beginning of the remaining part of the
   first list into the reordered series to get a number bigger than 1.234.

                        1 + 13 ¡ 12 + 15 + 17 + 19 = 1.2873

   Again, this is possible because the sum of the numbers in the first list diverges. Even
   though we have already used the first few numbers, the sum of the rest of the list
   will still diverge.
· Next move just enough numbers from the beginning of the remaining part of the
   second list into the reordered series to get a number less than 1.234.

                      1 + 13 ¡ 12 + 15 + 17 + 19 ¡ 14 = 1.0373

· At this point the idea is clear, just keep going like this. At the end of each step,
   the difference between the sum and 1.234 is smaller than the magnitude of the first
   unused number in the lists. Since the numbers in both lists tend to zero as you go
   farther and farther up the list, this procedure will generate a series whose sum is
   exactly 1.234. Since in each step we remove at least one number from a list and we
   alternate between the two lists, the reordered series will contain all of the terms from

   ° V n¡1 1

     (¡1) n , with each term appearing exactly once.

    n=1

                                                                                            Example A.13.2

    Section A.13 of this work was adapted from Section 3.4.2 of CLP 2 - Integral Calculus
by Feldman, Rechnitzer, and Yeager under a Creative Commons Attribution-NonCommercial-
ShareAlike 4.0 International license.

                        422
             Appendix B

              HIGH SCHOOL MATERIAL

      This chapter is really split into three parts.
          · Sections B.1 to B.11 contains results that we expect you to understand and know.
          · Then Section B.14 contains results that we don't expect you to memorise, but that
             we think you should be able to quickly derive from other results you know.
          · The remaining sections contain some material (that may be new to you) that is re-
             lated to topics covered in the main body of these notes.

B.1 Similar Triangles

      Two triangles T1, T2 are similar when
          · (AAA -- angle angle angle) The angles of T1 are the same as the angles of T2.
          · (SSS -- side side side) The ratios of the side lengths are the same. That is
                                                           Aa = Bb = Cc
          · (SAS -- side angle side) Two sides have lengths in the same ratio and the angle
             between them is the same. For example
                                                 Aa = Cc and angle  is same
                                                               423
HIGH SCHOOL MATERIAL                                                    B.2 PYTHAGORAS

B.2 Pythagoras

      For a right-angled triangle the length of the hypotenuse is related to the lengths of the
      other two sides by

                                 (adjacent)2 + (opposite)2 = (hypotenuse)2

B.3 Trigonometry -- Definitions

                                 sin             = opposite hypotenuse  csc  = 1 sin 
                                 cos             = adjacent hypotenuse  sec  = 1 cos 
                                 tan             = opposite adjacent    cot  = 1 tan 

B.4 Radians, Arcs and Sectors

For a circle of radius r and angle of  radians:

· Arc length L() = r.

·  Area of sector  A()  =   r2.

                           2

                                 424
HIGH SCHOOL MATERIAL                                          B.5 TRIGONOMETRY -- GRAPHS
                                                                                     tan 
B.5 Trigonometry -- Graphs

              sin                                 cos 

          1                                   1

¡  ¡        3 22     2              ¡  ¡           3 22    2          ¡    ¡         2  3 22
       2                                   2                                   2

   ¡1                                  ¡1

B.6 Trigonometry -- Special Triangles

From the above pair of special triangles we have                             c3

              14         2             sin 6 = 12                        sin 3 = 2
                                                                         cos 3 = 12
          sin = c                          c3
                                                                         tan  = c3
               14        2             cos 6 = 2
                                                                              3
          cos = c

          tan 4 = 1                         1 6         3

                                       tan = c

B.7 Trigonometry -- Simple Identities

· Periodicity

                    sin( + 2) = sin()                      cos( + 2) = cos()

· Reflection

                    sin(¡) = ¡ sin()                          cos(¡) = cos()

· Reflection around /4

                    sin        ¡    = cos                     cos     ¡    = sin 
                            2                                      2

                                              425
HIGH SCHOOL MATERIAL                B.8 TRIGONOMETRY -- ADD AND SUBTRACT ANGLES

· Reflection around /2                   cos ( ¡ ) = ¡ cos 

               sin ( ¡ ) = sin 

· Rotation by                            cos ( + ) = ¡ cos 

              sin ( + ) = ¡ sin 

· Pythagoras

                                    sin2  + cos2  = 1

B.8 Trigonometry -- Add and Subtract Angles

· Sine

                              sin( ¨ ) = sin() cos() ¨ cos() sin()

· Cosine

                           cos( ¨ ) = cos() cos() © sin() sin()

B.9 Inverse Trigonometric Functions

Some of you may not have studied inverse trigonometric functions in highschool, how-
ever we still expect you to know them by the end of the course.

        arcsin x                           arccos x                  arctan x

    Domain: ¡1 ¤ x ¤ 1            Domain: ¡1 ¤ x ¤ 1      Domain: all real numbers
                                 Range: 0 ¤ arccos x ¤ 
Range:  ¡     ¤  arcsin x  ¤                              Range:  ¡                                   arctan x  
           2                  2                                      2                                          2

          /2                                                            
                                                                        2

¡1                                  /2

                              1

        ¡/2                                                               ¡
                                ¡1                                                                 2

                                                          1

Since these functions are inverses of each other we have

                  arcsin(sin ) =                          ¡2 ¤  ¤ 2
                  arccos(cos ) =                            0¤¤
                  arctan(tan ) = 
                                                          ¡2 ¤  ¤ 2

                                    426
HIGH SCHOOL MATERIAL                                                                 B.10 AREAS

and also

                      sin(arcsin x) = x                    ¡1 ¤ x ¤ 1
                      cos(arccos x) = x                    ¡1 ¤ x ¤ 1
                      tan(arctan x) = x
                                                            any real x

            arccsc x                     arcsec x                      arccot x
                                                           Domain: all real numbers
       Domain: |x| ¥ 1              Domain: |x| ¥ 1         Range: 0 arccot x 

Range:    ¡     ¤  arccsc x  ¤     Range: 0 ¤ arcsec x ¤                        
             2                  2                   $
          arccsc x $ 0                   arcsec  x     
                                                       2

                                         
                2

                                                                        
                                         2                              2
            ¡1     1

            ¡                            ¡1
                2

                                                    1

Again              arccsc(csc ) =                         ¡2 ¤  ¤ 2 ,  $ 0
and                arcsec(sec ) =                          0 ¤  ¤ ,  $ 
                   arccot(cot ) = 
                                                                                  2
                                                                       0  

                      csc(arccsc x) = x                      |x| ¥ 1
                      sec(arcsec x) = x                      |x| ¥ 1
                      cot(arccot x) = x
                                                           any real x

B.10 Areas

· Area of a rectangle

                                              A = bh
                                             427
        HIGH SCHOOL MATERIAL                              B.11 VOLUMES
            · Area of a triangle
                                  A = 12 bh = 12 ab sin 
            · Area of a circle           A = r2
            · Area of an ellipse         A = ab

B.11 Volumes

· Volume of a rectangular prism    V = lwh
· Volume of a cylinder             V = r2h
· Volume of a cone                V = 13 r2h
· Volume of a sphere              V = 43 r3

B.12 Powers

        In the following, x and y are arbitrary real numbers, and q is an arbitrary constant that is
        strictly bigger than zero.

           · q0 = 1

                                                                 428
HIGH SCHOOL MATERIAL                                                    B.13 LOGARITHMS

·  qx+y  = qxqy, qx¡y     =   qxq

                               y

·  q¡x =    q1

              x

· qx y = qxy

· lim qx = V, lim qx = 0 if q ¡ 1
   xÑV           xÑ¡V

· lim qx = 0, lim qx = V if 0 q 1
   xÑV           xÑ¡V

· The graph of 2x is given below. The graph of qx, for any q ¡ 1, is similar.

                                    y                     y = 2x

                                    6

                                    4

                                                    2                x
                                                    1
                                                       1  2       3
                          -3 -2 -1

B.13 Logarithms

In the following, x and y are arbitrary real numbers that are strictly bigger than 0, and p
and q are arbitrary constants that are strictly bigger than one.

· qlogq x = x, logq qx = x

· logq x = logp q logp x

· logq 1 = 0, logq q = 1

· logq(xy) = logq x + logq y

· logq   x       = logq x ¡ logq y
         y

· logq   1       = ¡ logq y,
         y

· logq(xy) = y logq x

· lim logq x = V, lim logq x = ¡V
   xÑV                    xÑ0

· The graph of log10 x is given below. The graph of logq x, for any q ¡ 1, is similar.

                                    429
HIGH SCHOOL MATERIAL                                           B.14 YOU SHOULD BE ABLE TO DERIVE
                                        y        y = log10 x

                                     1.0
                                     0.5

                                           1         5        10 15 x

                    -0.5

                    -1.0

B.14 Highschool Material You Should be Able to Derive

            · Graphs of csc , sec  and cot :

           csc                                          sec                         cot 

      1                                              1

¡  ¡       2  3 22                         ¡  ¡      1    3 22         2  ¡  ¡      2  3 2            2
                                                                                 2
      2¡1                                        2¡

· More Pythagoras                                    divide by cos2       tan2  + 1 = sec2 
              sin2  + cos2  = 1                                           1 + cot2  = csc2 
              sin2  + cos2  = 1                      ÞÝÝÝÝÝÝÝÝÝÝÑ

                                                      divide by sin2 

                                                     ÞÝÝÝÝÝÝÝÝÝÑ

· Sine -- double angle (set  =  in sine angle addition formula)
                                        sin(2) = 2 sin() cos()

· Cosine -- double angle (set  =  in cosine angle addition formula)

           cos(2) = cos2() ¡ sin2()                           (use sin2() = 1 ¡ cos2())
                  = 2 cos2() ¡ 1                              (use cos2() = 1 ¡ sin2())
                  = 1 ¡ 2 sin2()

· Composition of trigonometric and inverse trigonometric functions:

                                                                                                    

              cos(arcsin x) = 1 ¡ x2                          sec(arctan x) = 1 + x2

   and similar expressions.

                                                        430
HIGH SCHOOL MATERIAL                                B.15 CARTESIAN COORDINATES

B.15 Cartesian Coordinates

        Each point in two dimensions may be labeled by two coordinates (x, y) which specify the
        position of the point in some units with respect to some axes as in the figure below.

                                                     y
                                                                           (x, y)
                                                                           y

                                           x     x

The set of all points in two dimensions is denoted R2. Observe that

  · the distance from the point (x, y) to the x-axis is |y|
  · the distance from the point (x, y) to the y-axis is |x| 

   · the distance from the point (x, y) to the origin (0, 0) is x2 + y2
    Similarly, each point in three dimensions may be labeled by three coordinates (x, y, z),
as in the two figures below.

                      z                             z
                                (x, y, z)
                                                              (x, y, z)
                         z
                                                              z
   xy                                                                  y

                      y                                          x
                                                      y

x                                             x

The set of all points in three dimensions is denoted R3. The plane that contains, for exam-
ple, the x- and y-axes is called the xy-plane.

   · The xy-plane is the set of all points (x, y, z) that obey z = 0.
   · The xz-plane is the set of all points (x, y, z) that obey y = 0.
   · The yz-plane is the set of all points (x, y, z) that obey x = 0.
More generally,
   · The set of all points (x, y, z) that obey z = c is a plane that is parallel to the xy-plane

    and is a distance |c| from it. If c ¡ 0, the plane z = c is above the xy-plane. If

       c 0, the plane z = c is below the xy-plane. We say that the plane z = c is a signed
       distance c from the xy-plane.

                                                         431
HIGH SCHOOL MATERIAL                              B.16 ROOTS OF POLYNOMIALS

· The set of all points (x, y, z) that obey y = b is a plane that is parallel to the xz-plane
   and is a signed distance b from it.

· The set of all points (x, y, z) that obey x = a is a plane that is parallel to the yz-plane
   and is a signed distance a from it.

   z                        z                        z
         z=c                            y=b                             y
                                               y
                      y

                                                     x=a

x                        x                        x

Observe that

  · the distance from the point (x, y, z) to the xy-plane is |z|
  · the distance from the point (x, y, z) to the xz-plane is |y|
  · the distance from the point (x, y, z) to the yz-plane is |x| 

   · the distance from the point (x, y, z) to the origin (0, 0, 0) is x2 + y2 + z2

The distance from the point (x, y, z) to the point (xI, yI, zI) is

                                                                   

                          (x ¡ xI)2 + (y ¡ yI)2 + (z ¡ zI)2

so that the equation of the sphere centered on (1, 2, 3) with radius 4, that is, the set of all
points (x, y, z) whose distance from (1, 2, 3) is 4, is

                        (x ¡ 1)2 + (y ¡ 2)2 + (z ¡ 3)2 = 16

B.16 Roots of Polynomials

        Being able to factor polynomials is a very important part of many of the computations in
        this course. Related to this is the process of finding roots (or zeros) of polynomials. That
        is, given a polynomial P(x), find all numbers r so that P(r) = 0.

            In the case of a quadratic P(x) = ax2 + bx + c, we can use the formula

                                   x = ¡b ¨ cb2 ¡ 4ac

                                                                     2a
        The corresponding formulas for cubics and quartics1 are extremely cumbersome, and no
        such formula exists for polynomials of degree 5 and higher2.

          1 The method for cubics was developed in the 15th century by del Ferro, Cardano and Ferrari (Cardano's
                student). Ferrari then went on to discover a formula for the roots of a quartic. His formula requires the
                solution of an associated cubic polynomial.

          2 This is the famous Abel-Ruffini Theorem.

                                                                 432
HIGH SCHOOL MATERIAL        B.16 ROOTS OF POLYNOMIALS

    Despite this there are many tricks3 for finding roots of polynomials that work well in
some situations but not all. Here we describe approaches that will help you find integer
and rational roots of polynomials that will work well on exams, quizzes and homework
assignments.

  Consider the quadratic equation x2 ¡ 5x + 6 = 0. We could4 solve this using the

quadratic formula

x = 5 ¨ c25 ¡ 4 ¢ 1 ¢ 6 = 5 ¨ 1 = 2, 3.22

Hence x2 ¡ 5x + 6 has roots x = 2, 3 and so it factors as (x ¡ 3)(x ¡ 2). Notice5 that the

numbers 2 and 3 divide the constant term of the polynomial, 6. This happens in general
and forms the basis of our first trick.

 TrickB.16.1 (A very useful trick).

If r or ¡r is an integer root of a polynomial P(x) = anxn + ¤ ¤ ¤ + a1x + a0 with

integer coefficients, then r is a factor of the constant term a0.

Proof. If r is a root of the polynomial we know that P(r) = 0. Hence

                          an ¤ rn + ¤ ¤ ¤ + a1 ¤ r + a0 = 0

If we isolate a0 in this expression we get

                            a0 = ¡ anrn + ¤ ¤ ¤ + a1r

We can see that r divides every term on the right-hand side. This means that the right-
hand side is an integer times r. Thus the left-hand side, being a0, is an integer times r, as

required. The argument for when ¡r is a root is almost identical.

    Let us put this observation to work.
 Example B.16.1

Find the integer roots of P(x) = x3 ¡ x2 + 2.

Solution.
    · The constant term in this polynomial is 2.

  · The only divisors of 2 are 1, 2. So the only candidates for integer roots are ¨1, ¨2.

3 There is actually a large body of mathematics devoted to developing methods for factoring polyno-
      mials. Polynomial factorisation is a fundamental problem for most computer algebra systems. The
      interested reader should make use of their favourite search engine to find out more.

4 We probably shouldn't do it this way for such a simple polynomial, but for pedagogical purposes we
      do here.

5 Many of you may have been taught this approach in highschool.

                                                         433
HIGH SCHOOL MATERIAL                                          B.16 ROOTS OF POLYNOMIALS

    · Trying each in turn                                 P(¡1) = 0
                                 P(1) = 2                 P(¡2) = ¡10
                                 P(2) = 6
                                                                                Example B.16.1
  · Thus the only integer root is ¡1.

Example B.16.2

Find the integer roots of P(x) = 3x3 + 8x2 ¡ 5x ¡ 6.

Solution.

· The constant term is ¡6.
· The divisors of 6 are 1, 2, 3, 6. So the only candidates for integer roots are ¨1, ¨2, ¨3, ¨6.

· We try each in turn (it is tedious but not difficult):

                P(1) = 0                                  P(¡1) = 4
                P(2) = 40                                 P(¡2) = 12
                P(3) = 132                                P(¡3) = 0
                P(6) = 900                                P(¡6) = ¡336

· Thus the only integer roots are 1 and ¡3.

                                                                        Example B.16.2

We can generalise this approach in order to find rational roots. Consider the polyno-
mial 6x2 ¡ x ¡ 2. We can find its zeros using the quadratic formula:
                x = 1 ¨ c1 + 48 = 1 ¨ 7 = ¡1, 2.
                            12                  12        23

Notice now that the numerators, 1 and 2, both divide the constant term of the polynomial
(being 2). Similarly, the denominators, 2 and 3, both divide the coefficient of the highest
power of x (being 6). This is quite general.

 TrickB.16.2 (Another nice trick).

If b/d or ¡b/d is a rational root in lowest terms (i.e. b and d are integers with
no common factors) of a polynomial Q(x) = anxn + ¤ ¤ ¤ + a1x + a0 with inte-

ger coefficients, then the numerator b is a factor of the constant term a0 and the
denominator d is a factor of an.

                                           434
HIGH SCHOOL MATERIAL                                          B.16 ROOTS OF POLYNOMIALS

Proof. Since b/d is a root of P(x) we know that

                       an(b/d)n + ¤ ¤ ¤ + a1(b/d) + a0 = 0

Multiply this equation through by dn to get

                        anbn + ¤ ¤ ¤ + a1bdn¡1 + a0dn = 0

Move terms around to isolate a0dn:

                        a0dn = ¡ anbn + ¤ ¤ ¤ + a1bdn¡1

Now every term on the right-hand side is some integer times b. Thus the left-hand side
must also be an integer times b. We know that d does not contain any factors of b, hence
a0 must be some integer times b (as required).

    Similarly we can isolate the term anbn:

                   anbn = ¡ an¡1bn¡1d + ¤ ¤ ¤ + a1bdn¡1 + a0dn

Now every term on the right-hand side is some integer times d. Thus the left-hand side
must also be an integer times d. We know that b does not contain any factors of d, hence
an must be some integer times d (as required).

  The argument when ¡b/d is a root is nearly identical.

    We should put this to work:
 Example B.16.3

P(x) = 2x2 ¡ x ¡ 3.

Solution.

· The constant term in this polynomial is 3 = 1 ¢ 3 and the coefficient of the highest
  power of x is 2 = 1 ¢ 2.

· Thus the only candidates for integer roots are ¨1, ¨3.

·  By  our  newest   trick,  the    only  candidates  for  fractional  roots  are  ¨  1  ,  ¨ 23 .
                                                                                      2

· We try each in turn6

                               P(1) = ¡2                      P(¡1) = 0
                                                              P(¡3) = 18
                               P(3) = 12

                            P  1      = ¡3                 P           ¡1    = ¡2
                               2                                          2

                            P    3    =0                   P           ¡3    =3
                                 2                                        2

   so  the  roots  are  ¡1  and   3.

                                  2

6 Again, this is a little tedious, but not difficult. Its actually pretty easy to code up for a computer to do.
      Modern polynomial factoring algorithms do more sophisticated things, but these are a pretty good way
      to start.

                                            435
HIGH SCHOOL MATERIAL                            B.16 ROOTS OF POLYNOMIALS

                                                                                                Example B.16.3

    The tricks above help us to find integer and rational roots of polynomials. With a little
extra work we can extend those methods to help us factor polynomials. Say we have a
polynomial P(x) of degree p and have established that r is one of its roots. That is, we

know P(r) = 0. Then we can factor (x ¡ r) out from P(x) -- it is always possible to find a
polynomial Q(x) of degree p ¡ 1 so that

                              P(x) = (x ¡ r)Q(x)

    In sufficiently simple cases, you can probably do this factoring by inspection. For

example, P(x) = x2 ¡ 4 has r = 2 as a root because P(2) = 22 ¡ 4 = 0. In this case,
P(x) = (x ¡ 2)(x + 2) so that Q(x) = (x + 2). As another example, P(x) = x2 ¡ 2x ¡ 3
has r = ¡1 as a root because P(¡1) = (¡1)2 ¡ 2(¡1) ¡ 3 = 1 + 2 ¡ 3 = 0. In this case,
P(x) = (x + 1)(x ¡ 3) so that Q(x) = (x ¡ 3).

    For higher degree polynomials we need to use something more systematic -- long
divison.

      TrickB.16.3 (Long Division).

   Once you have found a root r of a polynomial, even if you cannot factor (x ¡ r)
   out of the polynomial by inspection, you can find Q(x) by dividing P(x) by x ¡ r,

     using the long division algorithm you learned7 in school, but with 10 replaced
     by x.

Example B.16.4

Factor P(x) = x3 ¡ x2 + 2.

Solution.

· We can go hunting for integer roots of the polynomial by looking at the divisors of

  the constant term. This tells us to try x = ¨1, ¨2.

· A quick computation shows that P(¡1) = 0 while P(1), P(¡2), P(2) $ 0. Hence
  x = ¡1 is a root of the polynomial and so x + 1 must be a factor.

·  So we divide  x3¡x2+2    The first term,  x2, in the quotient is chosen so that when you

                   x+1 .
   multiply it by the denominator, x2(x + 1) = x3 + x2, the leading term, x3, matches
   the leading term in the numerator, x3 ¡ x2 + 2, exactly.

                            x2

                            x + 1 x3 - x2 +  2  x2(x + 1)
                            x3 + x2

7 This is a standard part of most highschool mathematics curricula, but perhaps not all. You should revise
      this carefully.

                                                         436
HIGH SCHOOL MATERIAL                                             B.16 ROOTS OF POLYNOMIALS

· When you subtract x2(x + 1) = x3 + x2 from the numerator x3 ¡ x2 + 2 you get the
  remainder ¡2x2 + 2. Just like in public school, the 2 is not normally "brought down"

   until it is actually needed.

                           x2

                      x + 1 x3 - x2 +                         2  x2(x + 1)
                           x3 + x2

                               -2x2

· The next term, ¡2x, in the quotient is chosen so that when you multiply it by the
  denominator, ¡2x(x + 1) = ¡2x2 ¡ 2x, the leading term ¡2x2 matches the leading

   term in the remainder exactly.

                           x2 - 2x

                      x + 1 x3 - x2 +   2                         x2(x + 1)
                           x3 + x2                               -2x(x + 1)

                           -2x2
                           -2x2 - 2x

And so on.

                           x2 - 2x + 2

                      x+1  x3 - x2 +    2                         x2(x + 1)
                           x3 + x2                               -2x(x + 1)

                           -2x2                                    2(x + 1)
                           -2x2 - 2x

                                       2x + 2
                                       2x + 2

                                        0

· Note that we finally end up with a remainder 0. A nonzero remainder would have

  signalled a computational error, since we know that the denominator x ¡ (¡1) must
  divide the numerator x3 ¡ x2 + 2 exactly.

· We conclude that

                       (x + 1)(x2 ¡ 2x + 2) = x3 ¡ x2 + 2

   To check this, just multiply out the left hand side explicitly.

                                              ¡b¨cb2¡4ac 2
· Applying the high school quadratic root formula 2a to x ¡ 2x + 2 tells us

   that it has no real roots and that we cannot factor it further8.
                                                                                            Example B.16.4

8 Because we are not permitted to use complex numbers.

                                                         437
HIGH SCHOOL MATERIAL                                     B.16 ROOTS OF POLYNOMIALS

    We finish by describing an alternative to long division. The approach is roughly equiv-
alent, but is perhaps more straightforward at the expense of requiring more algebra.

 Example B.16.5

Factor P(x) = x3 ¡ x2 + 2, again.

Solution. Let us do this again but avoid long division.

·  From the previous example, we know that    x3¡x2+2    must be a polynomial (since ¡1

                                                 x+1
   is a root of the numerator) of degree 2. So write

                            x x + 1 = 3 ¡ x2 + 2 ax2 + bx + c

   for some, as yet unknown, coefficients a, b and c.

· Cross multiplying and simplifying gives us

   x3 ¡ x2 + 2 = (ax2 + bx + c)(x + 1)

                 = ax3 + (a + b)x2 + (b + c)x + c

· Now matching coefficients of the various powers of x on the left and right hand
   sides

                      coefficient of x3:          a=1
                      coefficient of x2:
                      coefficient of x1:      a + b = ¡1
                      coefficient of x0:
                                              b+c = 0

                                                   c=2

· This gives us a system of equations that we can solve quite directly. Indeed it tells

  us immediately that a = 1 and c = 2. Subbing a = 1 into a + b = ¡1 tells us that
  1 + b = ¡1 and hence b = ¡2.

· Thus

                       x3 ¡ x2 + 2 = (x + 1)(x2 ¡ 2x + 2).

                                                               Example B.16.5

    Appendix B of this work was taken from Appendix A of CLP 2 - Integral Calculus by
Feldman, Rechnitzer, and Yeager under a Creative Commons Attribution-NonCommercial-
ShareAlike 4.0 International license.

                      438
