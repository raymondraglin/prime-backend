Applied Discrete Structures
Applied Discrete Structures

                       Al Doerr
      University of Massachusetts Lowell

                   Ken Levasseur
      University of Massachusetts Lowell

                    May 30, 2025
Edition: 3rd Edition - version 12
Website: https://discretemath.org1
©2025 Al Doerr, Ken Levasseur
Applied Discrete Structures by Alan Doerr and Kenneth Levasseur is licensed
under a Creative Commons Attribution-NonCommercial-ShareAlike 3.0 United
States License. You are free to Share: copy and redistribute the material in
any medium or format; Adapt: remix, transform, and build upon the material.
You may not use the material for commercial purposes. The licensor cannot
revoke these freedoms as long as you follow the license terms.

   1discretemath.org
                      To our families
Donna, Christopher, Melissa, and Patrick Doerr
Karen, Joseph, Kathryn, and Matthew Levasseur
Acknowledgements

We would like to acknowledge the following instructors and inde-
pendent readers for their helpful comments and suggestions.

· Tibor Beke, UMass Lowell      · Sitansu Mittra, UMass
                                   Lowell
· Hanson Char
                                · Ravi Montenegro, UMass
· Hellen Colman, Wilbur            Lowell
   Wright College (IL)
                                · Tony Penta, UMass Lowell
· Alex DeCourcy, UMass
   Lowell                       · Jim Propp, UMass Lowell

· Vince DiChiacchio             · Bob Resendes

· Warren Grieff, UMass Low-     · Ivan Temesvari, Oakton
   ell                             College

· Matthew Haner, Mansfield      · Thao Tran, UMass Lowell
   University (PA)
                                · Richard Voss, Florida At-
· Dan Klain, UMass Lowell          lantic U.

       I'd like to particularly single out Jim Propp for his close scrutiny,
       along with that of his students, many of whom are listed below.

I would like to thank Rob Beezer, David Farmer, Karl-Dieter Crisman and
other participants on the pretext-xml-support group for their guidance and
work on MathBook XML, which has now been renamed PreTeXt. Thanks to
the Pedagogy Subcommittee of the UMass Lowell Transformational Education
Committee for their financial assistance in helping getting this project started.

       Many students have provided feedback and pointed out typos in
       several editions of this book. They are listed below. Students with
       no affiliation listed are from UMass Lowell.

· Ryan Allen                    · Declan Battell
· Rebecca Alves
· Anonymous student from        · Raymond Berger, Eckerd
                                   College
   Florida Atlantic U.
· David Arakelian               · Ron Burkey, Independant
· Junaid Baig                      Contributor
· Anju Balaji
· Carlos Barrientos             · Andrew Bernal

                                · Chris Berns

                                · Brianne Bindas

                             v
· Nicholas Bishop                                                          vi
· Nathan Blood
· Cameron Bolduc               · Eunji Jang
· Sam Bouchard                 · Matthew Jarek
· Amber Breslau                · Kyle Joaquim
· Rachel Bryan                 · Mathew John
· Nam Bui                      · Devin Johnson
· Courtney Caldwell            · Jeremy Joubert
· Joseph Calles                · William Jozefczyk
· Rebecca Campbelli            · Roshan Karthik
· AJ Capone                    · Joel Keaton
· Eric Carey                   · Antony Kellermann
· Emily Cashman                · Caroline Kenney
· Cora Casteel                 · Yorgo A. Kennos
· Rachel Chaiser, U. of Puget  · Thomas Kiley
                               · Cody Kingman
   Sound                       · Leant Seu Kim
· Sam Chambers                 · Jessica Kramer
· Vanessa Chen                 · John Kuczynski
· Hannah Chiodo                · Auris Kveraga
· Sofya Chow                   · Justin LaGree
· David Connolly               · Daven Lagu
· Sean Cummings                · Kendra Lansing
· Jayden Danquah               · Gregory Lawrence
· Alex DeCourcy                · Pearl Laxague
· Ryan Delosh                  · Kevin Le
· Hillari Denny                · Thien Tran Le
· Matthew Edwards              · Matt LeBlanc
· John El-Helou                · Maxwell Leduc
· Adam Espinola                · Ariel Leva
· Josh Everett                 · Robert Liana
· Alexandra Fabian             · Tammy Liu
· Christian Franco             · Anson Lu
· Anthony Gaeta                · Laura Lucaciu
· Connor Gallivan              · Kelly Ly
· David Genis                  · Kevin Mackie, Learning As-
· Lisa Gieng
· Holly Goodreau                  sistant
· Lilia Heimold                · Alexandra Mai
· Kevin Holmes                 · Andrew Magee
· Benjamin Houle               · Matthew Malone
· Alexa Hyde                   · Logan Mann
· Michael Ingemi               · Sam Marquis
                               · Nishitha Reddy Matta
                               · Amy Mazzucotelli
                               · Jason McAdam
                                                         vii

· Nick McArdle                 · Doug Salvati
· Christine McCarthy           · Chita Sano
· Shelbylynn McCoy             · Noah Schultz
· Conor McNierney              · Anna Sergienko
· Nishitha Reddy Matta         · Ian Sharpe
· Albara Mehene                · Ben Shipman
· Colby Mei                    · Florens Shosho
· Adam Melle                   · Lorraine Sill
· Matthew Mendre               · Jonathan Silva
· Joshua Michaud               · Joshua Simard
· Max Mints                    · Mason Sirois
· Charles Mirabile             · Gabriel Shahrouzi
· Timothy Miskell              · Sana Shaikh
· Genevieve Moore              · Ian Sharpe
· Mike Morley                  · Joel Slebodnick
· Brandon Moy                  · Greg Smelkov
· Zach Mulcahy                 · Andrew Somerville
· Tessa Munoz                  · Samuel Stanley
· Zachary Murphy               · Alicia Stransky
· Logan Nadeau                 · Brandon Swanberg
· Carol Nguyen                 · Joshua Sullivan
· Hung Nguyen                  · James Tan
· Tam Nguyen                   · Huylong Tang
· Shelly Noll                  · Steven Tang
· Steven Oslan, the cham-      · Amitha Thalanki
                               · Elliott Tinkler
   pion typo finder!           · Bunchhoung Tiv
· Harsh Patel                  · Andy Tran
· Beck Peterson                · Tina Tran
· Donna Petitti                · Mary Tsykora
· Paola Pevzner                · Joanel Vasquez
· Zach Phillips                · Rolando Vera
· Sam Pizette                  · Anh Vo
· Angelo Pocoli                · Nick Wackowski
· Samantha Poirier             · Ryan Wallace
· Roshan Ravi                  · Uriah Wardlaw
· Ian Roberts                  · Phoebe Watkins
· John Raisbeck                · Zach Weaver
· Adelia Reid                  · Steve Werren
· Derek Ross                   · Laura Wikoff
· Tyler Ross                   · Henry Zhu
· Jacob Rothmel                · Several students at
· Zach Rush
· Ryan Saadah                     Luzurne County Commu-
· Steve Sadler, Bellevue Col-     nity College (PA)

   lege (WA)
Preface

Applied Discrete Structures is designed for use in a university course in dis-
crete mathematics spanning up to two semesters. Its original design was for
computer science majors to be introduced to the mathematical topics that are
useful in computer science. It can also serve the same purpose for mathematics
majors, providing a first exposure to many essential topics.

    We embarked on this open-source project in 2010, twenty-one years after
the publication of the 2nd edition of Applied Discrete Structures for Computer
Science in 1989. We had signed a contract for the second edition with Science
Research Associates in 1988 but by the time the book was ready to print, SRA
had been sold to MacMillan. Soon after, the rights had been passed on to
Pearson Education, Inc. In 2010, the long-term future of printed textbooks
was uncertain. In the meantime, textbook prices (both printed and e-books)
had increased and a growing open source textbook movement had started. One
of our objectives in revisiting this text is to make it available to our students in
an affordable format. In its original form, the text was peer-reviewed and was
adopted for use at several universities throughout the country. For this reason,
we see Applied Discrete Structures as not only an inexpensive alternative, but
a high quality alternative.

    The current version of Applied Discrete Structures has been developed us-
ing PreTeXt, a lightweight XML application for authors of scientific articles,
textbooks and monographs initiated by Rob Beezer, U. of Puget Sound. When
the PreTeXt project was launched, it was the natural next step. The features
of PreTeXt make it far more readable, with easy production of web, pdf and
print formats.

    The current computing landscape is very different from the 1980's and this
accounts for the most significant changes in the text. One of the most common
programming languages of the 1980's was Pascal. We used it to illustrate many
of the concepts in the text. Although it isn't totally dead, Pascal is far from
the mainstream of computing in the 21st century. The open source software
movement was just starting in the late 1980's and in 2005, the first version of
Sage (later renamed SageMath), an open-source computer algebra system, was
first released. In Applied Discrete Structures we have replaced "Pascal Notes"
with "SageMath Notes."

    Many of the concepts introduced in this text are illustrated using SageMath
code. SageMath (sagemath.org2) is a free, open source, software system for
advanced mathematics. Sage can be used either on your own computer, a
local server, or on SageMathCloud (https://cloud.sagemath.com).

                                                                                    Ken Levasseur
                                                                                    Lowell, MA

   2sagemath.org

                                                 viii
Contents

Acknowledgements      v

Preface               viii

1 Set Theory          1

1.1 Set Notation and Relations . . . . . . . . . . . . . . 1
1.2 Basic Set Operations . . . . . . . . . . . . . . . . 5
1.3 Cartesian Products and Power Sets . . . . . . . . . . . 11
1.4 Binary Representation of Positive Integers . . . . . . . . . 13
1.5 Summation Notation and Generalizations . . . . . . . . . 16

2 Combinatorics       20

2.1 Basic Counting Techniques - The Rule of Products. . . . . . 20
2.2 Permutations . . . . . . . . . . . . . . . . . . . 24
2.3 Partitions of Sets and the Law of Addition. . . . . . . . . 29
2.4 Combinations and the Binomial Theorem . . . . . . . . . 33

3 Logic               40

3.1 Propositions and Logical Operators . . . . . . . . . . . 40
3.2 Truth Tables and Propositions Generated by a Set . . . . . . 45
3.3 Equivalence and Implication . . . . . . . . . . . . . . 47
3.4 The Laws of Logic . . . . . . . . . . . . . . . . . 51
3.5 Mathematical Systems and Proofs . . . . . . . . . . . . 53
3.6 Propositions over a Universe . . . . . . . . . . . . . . 58
3.7 Mathematical Induction . . . . . . . . . . . . . . . 61
3.8 Quantifiers . . . . . . . . . . . . . . . . . . . . 67
3.9 A Review of Methods of Proof . . . . . . . . . . . . . 72

4 More on Sets        75

4.1 Methods of Proof for Sets . . . . . . . . . . . . . . . 75
4.2 Laws of Set Theory . . . . . . . . . . . . . . . . . 80
4.3 Minsets . . . . . . . . . . . . . . . . . . . . . 83
4.4 The Duality Principle . . . . . . . . . . . . . . . . 86

                  ix
CONTENTS                              x

5 Introduction to Matrix Algebra      88

5.1 Basic Definitions and Operations . . . . . . . . . . . . 88
5.2 Special Types of Matrices . . . . . . . . . . . . . . . 94
5.3 Laws of Matrix Algebra . . . . . . . . . . . . . . . 98
5.4 Matrix Oddities . . . . . . . . . . . . . . . . . . 99

6 Relations                           102

6.1 Basic Definitions . . . . . . . . . . . . . . . . . . 102
6.2 Graphs of Relations on a Set. . . . . . . . . . . . . . 106
6.3 Properties of Relations . . . . . . . . . . . . . . . . 108
6.4 Matrices of Relations . . . . . . . . . . . . . . . . 117
6.5 Closure Operations on Relations . . . . . . . . . . . . 120

7 Functions                           126

7.1 Definition and Notation . . . . . . . . . . . . . . . 126
7.2 Properties of Functions . . . . . . . . . . . . . . . . 130
7.3 Function Composition . . . . . . . . . . . . . . . . 135

8 Recursion and Recurrence Relations  141

8.1 The Many Faces of Recursion . . . . . . . . . . . . . 141
8.2 Sequences . . . . . . . . . . . . . . . . . . . . 148
8.3 Recurrence Relations . . . . . . . . . . . . . . . . 151
8.4 Some Common Recurrence Relations . . . . . . . . . . . 161
8.5 Generating Functions . . . . . . . . . . . . . . . . 169

9 Graph Theory                        184

9.1 Graphs - General Introduction . . . . . . . . . . . . . 184
9.2 Data Structures for Graphs . . . . . . . . . . . . . . 195
9.3 Connectivity . . . . . . . . . . . . . . . . . . . 199
9.4 Traversals: Eulerian and Hamiltonian Graphs . . . . . . . 209
9.5 Graph Optimization . . . . . . . . . . . . . . . . . 219
9.6 Planarity and Colorings . . . . . . . . . . . . . . . 231

10 Trees                              241

10.1 What Is a Tree? . . . . . . . . . . . . . . . . . . 241
10.2 Spanning Trees. . . . . . . . . . . . . . . . . . . 244
10.3 Rooted Trees . . . . . . . . . . . . . . . . . . . 251
10.4 Binary Trees . . . . . . . . . . . . . . . . . . . 258

11 Algebraic Structures               269

11.1 Operations . . . . . . . . . . . . . . . . . . . . 269
11.2 Algebraic Systems . . . . . . . . . . . . . . . . . 273
11.3 Some General Properties of Groups . . . . . . . . . . . 278
11.4 Greatest Common Divisors and the Integers Modulo n . . . . 282
11.5 Subsystems . . . . . . . . . . . . . . . . . . . . 292
11.6 Direct Products . . . . . . . . . . . . . . . . . . 297
11.7 Isomorphisms . . . . . . . . . . . . . . . . . . . 303
CONTENTS                                xi

12 More Matrix Algebra                  311

12.1 Systems of Linear Equations . . . . . . . . . . . . . . 311
12.2 Matrix Inversion . . . . . . . . . . . . . . . . . . 320
12.3 An Introduction to Vector Spaces . . . . . . . . . . . . 324
12.4 The Diagonalization Process . . . . . . . . . . . . . . 331
12.5 Some Applications . . . . . . . . . . . . . . . . . 339
12.6 Linear Equations over the Integers Mod 2 . . . . . . . . . 345

13 Boolean Algebra                      348

13.1 Posets Revisited . . . . . . . . . . . . . . . . . . 350
13.2 Lattices . . . . . . . . . . . . . . . . . . . . . 354
13.3 Boolean Algebras . . . . . . . . . . . . . . . . . . 356
13.4 Atoms of a Boolean Algebra . . . . . . . . . . . . . . 360
13.5 Finite Boolean Algebras as n-tuples of 0's and 1's . . . . . . 364
13.6 Boolean Expressions . . . . . . . . . . . . . . . . . 365
13.7 A Brief Introduction to Switching Theory and Logic Design . . 369

14 Monoids and Automata                 376

14.1 Monoids . . . . . . . . . . . . . . . . . . . . . 376
14.2 Free Monoids and Languages . . . . . . . . . . . . . 379
14.3 Automata, Finite-State Machines . . . . . . . . . . . . 385
14.4 The Monoid of a Finite-State Machine . . . . . . . . . . 390
14.5 The Machine of a Monoid . . . . . . . . . . . . . . . 393

15 Group Theory and Applications        396

15.1 Cyclic Groups . . . . . . . . . . . . . . . . . . . 396
15.2 Cosets and Factor Groups. . . . . . . . . . . . . . . 402
15.3 Permutation Groups . . . . . . . . . . . . . . . . . 408
15.4 Normal Subgroups and Group Homomorphisms . . . . . . . 417
15.5 Coding Theory, Linear Codes . . . . . . . . . . . . . 424

16 An Introduction to Rings and Fields  434

16.1 Rings, Basic Definitions and Concepts . . . . . . . . . . 434
16.2 Fields . . . . . . . . . . . . . . . . . . . . . . 443
16.3 Polynomial Rings . . . . . . . . . . . . . . . . . . 446
16.4 Field Extensions . . . . . . . . . . . . . . . . . . 452
16.5 Power Series. . . . . . . . . . . . . . . . . . . . 455

Appendices

A Algorithms                            461

A.1 An Introduction to Algorithms . . . . . . . . . . . . . 461
A.2 The Invariant Relation Theorem . . . . . . . . . . . . 465

B Python and SageMath                   468

B.1 Python Iterators . . . . . . . . . . . . . . . . . . 468
B.2 Dictionaries . . . . . . . . . . . . . . . . . . . . 469
CONTENTS                                     xii

C Determinants                               472

C.1 Definition. . . . . . . . . . . . . . . . . . . . . 472
C.2 Computation . . . . . . . . . . . . . . . . . . . 474

D Notation                                   476

E An Informal Glossary of Terms              480

Glossary . . . . . . . . . . . . . . . . . . . . . . . 480

F Hints and Solutions to Selected Exercises  483

Back Matter

References                                   567

Index                                        570
Chapter 1

Set Theory

                                   empty set

                          Betty's math teacher said, in a sweat:
                          "I will teach you some set theory yet!"

                                  But his best efforts failed,
                                    And at Betty he railed:

                           "Your insights? A true empty set!"

         SheilaB, The Omnificent English Dictionary In Limerick Form

Many of the topics in this book are defined in terms of sets. It is essential
to understand basic set theory and how it is use to define basic structures
such as relation, functions, graphs and algebraic structures. We begin this
chapter with some of the basic set language and notation that will be used
throughout the text. We then consider basic set operations. Venn diagrams
will be introduced in order to give the reader a clear picture of these operations.
In addition, we will review the binary representation of positive integers and
introduce summation notation and its generalizations.

1.1 Set Notation and Relations

1.1.1 The notion of a set

The term set is intuitively understood by most people to mean a collection
of objects that are called elements (of the set). This concept is the starting
point on which we will build more complex ideas, much as in geometry where
the concepts of point and line are left undefined. Because a set is such a
simple notion, you may be surprised to learn that it is one of the most difficult
concepts for mathematicians to define to their own liking. For example, the
description above is not a proper definition because it requires the definition
of a collection. (How would you define "collection"?) Even deeper problems
arise when you consider the possibility that a set could contain itself. Although
these problems are of real concern to some mathematicians, they will not be
of any concern to us. Our first concern will be how to describe a set; that is,
how do we most conveniently describe a set and the elements that are in it?
If we are going to discuss a set for any length of time, we usually give it a
name in the form of a capital letter (or occasionally some other symbol). In
discussing set A, if x is an element of A, then we will write x  A. On the

                                                  1
CHAPTER 1. SET THEORY  2

other hand, if x is not an element of A, we write x / A. The most convenient
way of describing the elements of a set will vary depending on the specific set.

    Enumeration. When the elements of a set are enumerated (or listed) it is
traditional to enclose them in braces. For example, the set of binary digits is
{0, 1} and the set of decimal digits is {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}. The choice of a
name for these sets would be arbitrary; but it would be "logical" to call them
B and D, respectively. The choice of a set name is much like the choice of an
identifier name in programming.

    Some large sets can be enumerated without actually listing all the elements.
For example, the letters of the alphabet and the integers from 1 to 100 could
be described as A = {a, b, c, . . . , x, y, z}, and G = {1, 2, . . . , 99, 100}. The three
consecutive "dots" are called an ellipsis. We use them when it is clear what
elements are included but not listed. An ellipsis is used in two other situations.
To enumerate the positive integers, we would write {1, 2, 3, . . .}, indicating that
the list goes on infinitely. If we want to list a more general set such as the
integers between 1 and n, where n is some undetermined positive integer, we
might write {1, . . . , n}.

    Standard Symbols. Sets that are frequently encountered are usually
given symbols that are reserved for them alone. For example, since we will be
referring to the positive integers throughout this book, we will use the symbol
P instead of writing {1, 2, 3, . . .}. A few of the other sets of numbers that we
will use are:

   · (N): the natural numbers, {0, 1, 2, 3, . . .}

   · (Z): the integers, {. . . , -3, -2, -1, 0, 1, 2, 3, . . .}

   · (Q): the rational numbers

   · (R): the real numbers

   · (C): the complex numbers

    Set-Builder Notation. Another way of describing sets is to use set-
builder notation. For example, we could define the rational numbers as

                                 Q = {a/b | a, b  Z, b = 0}.

Note that in the set-builder description for the rational numbers:

   · a/b indicates that a typical element of the set is a "fraction."

   · The vertical line, |, is read "such that" or "where," and is used inter-
       changeably with a colon.

   · a, b  Z is an abbreviated way of saying a and b are integers.

   · Commas in mathematics are read as "and."

    The important fact to keep in mind in set notation, or in any mathematical
notation, is that it is meant to be a help, not a hindrance. We hope that
notation will assist us in a more complete understanding of the collection of
objects under consideration and will enable us to describe it in a concise manner.
However, brevity of notation is not the aim of sets. If you prefer to write a  Z
and b  Z instead of a, b  Z, you should do so. Also, there are frequently
many different, and equally good, ways of describing sets. For example, {x 
R | x2 - 5x + 6 = 0} and {x | x  R, x2 - 5x + 6 = 0} both describe the solution
set {2, 3}.
CHAPTER 1. SET THEORY                                        3

    A proper definition of the real numbers is beyond the scope of this text.
It is sufficient to think of the real numbers as the set of points on a number
line. The complex numbers can be defined using set-builder notation as C =
{a + bi : a, b  R}, where i2 = -1.

    In the following definition we will leave the word "finite" undefined.

Definition 1.1.1 Finite Set. A set is a finite set if it has a finite number of

elements. Any set that is not finite is an infinite set.     

Definition 1.1.2 Cardinality. Let A be a finite set. The number of different

elements in A is called its cardinality. The cardinality of a finite set A is denoted

|A|.                                                         

As we will see later, there are different infinite cardinalities. We can't make

this distinction until Chapter 7, so we will restrict cardinality to finite sets for

now.

1.1.2 Subsets

Definition 1.1.3 Subset. Let A and B be sets. We say that A is a subset

of B if and only if every element of A is an element of B. We write A  B to

denote the fact that A is a subset of B.                     

Example 1.1.4 Some Subsets.

(a) If A = {3, 5, 8} and B = {5, 8, 3, 2, 6}, then A  B.

(b) N  Z  Q  R  C
(c) If S = {3, 5, 8} and T = {5, 3, 8}, then S  T and T  S.

                                                             

Definition 1.1.5 Set Equality. Let A and B be sets. We say that A is

equal to B (notation A = B) if and only if every element of A is an element of

B and conversely every element of B is an element of A; that is, A  B and

B  A.                                                        

Example 1.1.6 Examples illustrating set equality.

(a) In Example 1.1.4, S = T . Note that the ordering of the elements is
     unimportant.

(b) The number of times that an element appears in an enumeration doesn't
     affect a set. For example, if A = {1, 5, 3, 5} and B = {1, 5, 3}, then
     A = B. Warning to readers of other texts: Some books introduce the
     concept of a multiset, in which the number of occurrences of an element
     matters.

                                                                                                     
    A few comments are in order about the expression "if and only if" as used
in our definitions. This expression means "is equivalent to saying," or more
exactly, that the word (or concept) being defined can at any time be replaced
by the defining expression. Conversely, the expression that defines the word
(or concept) can be replaced by the word.
    Occasionally there is need to discuss the set that contains no elements,
namely the empty set, which is denoted by  . This set is also called the null
set. Another acceptable way to denote the empty set is { }.
    It is clear, we hope, from the definition of a subset, that given any set A
we have A  A and   A. If A is nonempty, then A is called an improper
CHAPTER 1. SET THEORY  4

subset of A. All other subsets of A, including the empty set, are called proper
subsets of A. The empty set is an improper subset of itself.

Note 1.1.7 Not everyone is in agreement on whether the empty set is a proper
subset of any set. In fact earlier editions of this book sided with those who
considered the empty set an improper subset. However, we bow to the emerging
consensus at this time.

1.1.3 Exercises for Section 1.1

1. List four elements of each of the following sets:

        (a) {k  P | k - 1 is a multiple of 7}
        (b) {x | x is a fruit and its skin is normally eaten}
         (c) {x  Q | 1  Z}

                          x
        (d) {2n | n  Z, n < 0}
         (e) {s | s = 1 + 2 + · · · + n for some n  P}
2. List all elements of the following sets:

        (a) { 1 | n  {3, 4, 5, 6}}
                n

        (b) {  the alphabet |  precedes F}
         (c) {x  Z | x = x + 1}
        (d) {n2 | n = -2, -1, 0, 1, 2}
         (e) {n  P | n is a factor of 24 }
3. Describe the following sets using set-builder notation.

        (a) {5, 7, 9, . . . , 77, 79}
        (b) the rational numbers that are strictly between -1 and 1
         (c) the even integers

        (d) {-18, -9, 0, 9, 18, 27, . . . }
4. Use set-builder notation to describe the following sets:

        (a) {1, 2, 3, 4, 5, 6, 7}
        (b) {1, 10, 100, 1000, 10000}
         (c) {1, 1/2, 1/3, 1/4, 1/5, ...}
        (d) {0}
5. Let A = {0, 2, 3}, B = {2, 3}, and C = {1, 5, 9}. Determine which of the
      following statements are true. Give reasons for your answers.
CHAPTER 1. SET THEORY                                                 5

(a) 3  A                              (e) A  B

(b) {3}  A                            (f)   C

(c) {3}  A                            (g)   A

(d) B  A                              (h) A  A

6. (From [28]) Explain why there is no set A which satisfies A = {2, | A |}.

7. We introduced the empty set in this section and pointed out the two
      standard ways to denote this set,  and { }. Explain why {} is not a
      correct way to denote the empty set.

8. One reason that we left the definition of a set vague is Russell's Paradox.
      Many mathematics and logic books contain an account of this paradox.
      Two references are [42] and [37]. Find one such reference and read it. If
      you don't have access to a book, you could Google "Russell's Paradox"
      and there are several sites that describe it.

1.2 Basic Set Operations

1.2.1 Definitions

Definition 1.2.1 Intersection. Let A and B be sets. The intersection of A

and B (denoted by A  B) is the set of all elements that are in both A and B.

That is, A  B = {x : x  A and x  B}.                                  

Example 1.2.2 Some Intersections.

· Let A = {1, 3, 8} and B = {-9, 22, 3}. Then A  B = {3}.

· Solving a system of simultaneous equations such as x+y = 7 and x-y = 3
   can be viewed as an intersection. Let A = {(x, y) : x + y = 7, x, y  R}
   and B = {(x, y) : x - y = 3, x, y  R}. These two sets are lines in
   the plane and their intersection, A  B = {(5, 2)}, is the solution to the
   system.

· Z  Q = Z.
· If A = {3, 5, 9} and B = {-5, 8}, then A  B = .

                                                                      

Definition 1.2.3 Disjoint Sets. Two sets are disjoint if they have no

elements in common. That is, A and B are disjoint if A  B = .         

Definition 1.2.4 Union. Let A and B be sets. The union of A and B

(denoted by A  B) is the set of all elements that are in A or in B or in both

A and B. That is, A  B = {x : x  A or x  B}.                          

It is important to note in the set-builder notation for A  B, the word "or"

is used in the inclusive sense; it includes the case where x is in both A and B.

Example 1.2.5 Some Unions.

· If A = {2, 5, 8} and B = {7, 5, 22}, then A  B = {2, 5, 8, 7, 22}.

· Z  Q = Q.
· A   = A for any set A.

                                                                      
CHAPTER 1. SET THEORY                                        6

    Frequently, when doing mathematics, we need to establish a universe or
set of elements under discussion. For example, the set A = {x : 81x4 - 16 =
0} contains different elements depending on what kinds of numbers we allow
ourselves to use in solving the equation 81x4 - 16 = 0. This set of numbers
would be our universe. For example, if the universe is the integers, then A is

empty. If our universe is the rational numbers, then A is {2/3, -2/3} and if
the universe is the complex numbers, then A is {2/3, -2/3, 2i/3, -2i/3}.

Definition 1.2.6 Universe. The universe, or universal set, is the set of

all elements under discussion for possible membership in a set. We normally

reserve the letter U for a universe in general discussions.  

1.2.2 Set Operations and their Venn Diagrams

When working with sets, as in other branches of mathematics, it is often quite
useful to be able to draw a picture or diagram of the situation under consid-
eration. A diagram of a set is called a Venn diagram. The universal set U
is represented by the interior of a rectangle and the sets by disks inside the
rectangle.

Example 1.2.7 Venn Diagram Examples. A  B is illustrated in Fig-
ure 1.2.8 by shading the appropriate region.

Figure 1.2.8 Venn Diagram for the Intersection of Two Sets
    The union A  B is illustrated in Figure 1.2.9.

Figure 1.2.9 Venn Diagram for the Union A  B

In a Venn diagram, the region representing A  B does not appear empty;

however, in some instances it will represent the empty set. The same is true

for any other region in a Venn diagram.                      
CHAPTER 1. SET THEORY              7

Definition 1.2.10 Complement of a set. Let A and B be sets. The

complement of A relative to B (notation B - A) is the set of elements that

are in B and not in A. That is, B - A = {x : x  B and x / A}. If U is the

universal set, then U - A is denoted by Ac and is called simply the complement

of A. Ac = {x  U : x / A}.         

Figure 1.2.11 Venn Diagram for B - A

Example 1.2.12 Some Complements.

  (a) Let U = {1, 2, 3, ..., 10} and A = {2, 4, 6, 8, 10}. Then U - A =
       {1, 3, 5, 7, 9} and A - U = .

  (b) If U = R, then the complement of the set of rational numbers is the set
       of irrational numbers.

  (c) U c =  and c = U .

  (d) The Venn diagram of B - A is represented in Figure 1.2.11.
  (e) The Venn diagram of Ac is represented in Figure 1.2.13.

  (f) If B  A, then the Venn diagram of A - B is as shown in Figure 1.2.14.

  (g) In the universe of integers, the set of even integers,
       {. . . , -4, -2, 0, 2, 4, . . .}, has the set of odd integers as its comple-
       ment.

Figure 1.2.13 Venn Diagram for Ac
CHAPTER 1. SET THEORY  8

Figure 1.2.14 Venn Diagram for A - B when B is a subset of A
                                                                                                     

Definition 1.2.15 Symmetric Difference. Let A and B be sets. The
symmetric difference of A and B (denoted by A  B) is the set of all elements
that are in A and B but not in both. That is, A  B = (A  B) - (A  B). 
Example 1.2.16 Some Symmetric Differences.

  (a) Let A = {1, 3, 8} and B = {2, 4, 8}. Then A  B = {1, 2, 3, 4}.
  (b) A   = A and A  A =  for any set A.
  (c) R  Q is the set of irrational numbers.
  (d) The Venn diagram of A  B is represented in Figure 1.2.17.

Figure 1.2.17 Venn Diagram for the symmetric difference A  B
                                                                                                     

Why Venn? Venn diagrams are named after the logician John Venn, who
introduced them in a paper in 1880. In his paper, he acknowledged that they
were not new. In fact he referred to them as Euler Circles, because the famous
mathematician Leonhard Euler (pronounced Oy-ler) introduced them in the
1700's. Don't feel bad for Euler though. He has plenty of other things named
after him, including some we see later in this book.

1.2.3 SageMath Note: Sets

To work with sets in Sage, a set is an expression of the form Set(list). By
wrapping a list with Set( ), the order of elements appearing in the list and
their duplication are ignored. For example, L1 and L2 are two different lists,
but notice how as sets they are considered equal:
CHAPTER 1. SET THEORY                                9

 L1 =[3 ,6 ,9 ,0 ,3]
 L2 =[9 ,6 ,3 ,0 ,9]
 [L1==L2, Set(L1)==Set(L2) ]

 [False , True]
    The standard set operations are all methods and/or functions that can act

on Sage sets. You need to evaluate the following cell to use the subsequent cell.

 A= Set ( srange (5 ,50 ,5) )
 B= Set ( srange (6 ,50 ,6) )
 [A,B]

  [{35, 5, 40, 10, 45, 15, 20, 25, 30}, {36, 6, 42, 12, 48,
        18, 24, 30}]

    We can test membership, asking whether 10 is in each of the sets:

 [10 in A, 10 in B]

 [True , False]
    The ampersand is used for the intersection of sets. Change it to the vertical

bar, |, for union.

 A&B

  {30}
    Symmetric difference and set complement are defined as "methods" in Sage.

Here is how to compute the symmetric difference of A with B, followed by their
differences.
 [A.symmetric_difference(B),A.difference(B),B.difference(A)]

  [{35, 36, 5, 6, 40, 42, 12, 45, 15, 48, 18, 20, 24, 25, 10},
   {35, 5, 40, 10, 45, 15, 20, 25},
   {48, 18, 36, 6, 24, 42, 12}]

1.2.4 Exercises

1. Let A = {0, 2, 3}, B = {2, 3}, C = {1, 5, 9}, and let the universal set be
      U = {0, 1, 2, ..., 9}. Determine:

(a) A  B               (e) A - B  (i) A  C

(b) A  B               (f) B - A  (j) A  B
(c) B  A               (g) Ac

(d) A  C               (h) Cc

2. Let A, B, and C be as in Exercise 1, let D = {3, 2}, and let E = {2, 3, 2}.

Determine which of the following are true. Give reasons for your decisions.

(a) A = B                         (e) A  B = B  A
(b) B = C                         (f) A  B = B  A
(c) B = D                         (g) A - B = B - A
(d) E = D                         (h) A  B = B  A
CHAPTER 1. SET THEORY                                                       10

3. Let U = {1, 2, 3, ..., 9}. Give examples of sets A, B, and C for which:

(a) A  (B  C) = (A  B)  C      (d) A  Ac = U

(b) A(B C) = (AB)(AC) (e) A  A  B

(c) (A  B)c = Ac  Bc           (f) A  B  A

4. Let U = {1, 2, 3, ..., 9}. Give examples to illustrate the following facts:

(a) If A  B and B  C, then A  C.

(b) There are sets A and B such that A - B = B - A

         (c) If U = A  B and A  B = , it always follows that A = U - B.

5. What can you say about A if U = {1, 2, 3, 4, 5}, B = {2, 3}, and (sepa-
      rately)

(a) A  B = {1, 2, 3, 4}

(b) A  B = {2}

         (c) A  B = {3, 4, 5}

6. Suppose that U is an infinite universal set, and A and B are infinite
      subsets of U . Answer the following questions with a brief explanation.

        (a) Must Ac be finite?

        (b) Must A  B be infinite?

         (c) Must A  B be infinite?
7. Given that U = all students at a university, D = day students, M =

      mathematics majors, and G = graduate students. Draw Venn diagrams
      illustrating this situation and shade in the following sets:

(a) evening students           (c) non-math graduate students

(b) undergraduate mathematics (d) non-math undergraduate stu-

majors                            dents

8. Let the sets D, M , G, and U be as in exercise 7. Let |U | = 16, 000,

|D| = 9, 000, |M | = 300, and |G| = 1, 000. Also assume that the number of

day students who are mathematics majors is 250, 50 of whom are graduate

students, that there are 95 graduate mathematics majors, and that the

total number of day graduate students is 700. Determine the number of

students who are:

(a) evening students           (e) evening graduate students

(b) nonmathematics majors      (f) evening graduate mathemat-
                                    ics majors
(c) undergraduates (day or
     evening)                  (g) evening undergraduate non-
                                    mathematics majors
(d) day graduate nonmathemat-
     ics majors
CHAPTER 1. SET THEORY                                 11

1.3 Cartesian Products and Power Sets

1.3.1 Cartesian Products

Definition 1.3.1 Cartesian Product. Let A and B be sets. The Cartesian

product of A and B, denoted by A × B, is defined as follows: A × B = {(a, b) |

a  A and b  B}, that is, A × B is the set of all possible ordered pairs

whose first component comes from A and whose second component comes from

B.                                                    

Example 1.3.2 Some Cartesian Products. Notation in mathematics is

often developed for good reason. In this case, a few examples will make clear

why the symbol × is used for Cartesian products.

    · Let A = {1, 2, 3} and B = {4, 5}. Then A × B =
       {(1, 4), (1, 5), (2, 4), (2, 5), (3, 4), (3, 5)}. Note that |A×B| = 6 = |A|×|B|.

    · A × A = {(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 1), (3, 2), (3, 3)}. Note
       that |A × A| = 9 = |A|2.

                                                                                                    
    These two examples illustrate the general rule that if A and B are finite
sets, then |A × B| = |A| × |B|.
    We can define the Cartesian product of three (or more) sets similarly. For
example, A × B × C = {(a, b, c) : a  A, b  B, c  C}.
    It is common to use exponents if the sets in a Cartesian product are the
same:

                                           A2 = A × A

                        A3 = A × A × A

and in general,

                        An = A × A × . . . × A.

                                           n factors

1.3.2 Power Sets

Definition 1.3.3 Power Set. If A is any set, the power set of A is the set

of all subsets of A, denoted P(A).                    

    The two extreme cases, the empty set and all of A, are both included in

P (A).

Example 1.3.4 Some Power Sets.

    · P() = {}

    · P({1}) = {, {1}}

    · P({1, 2}) = {, {1}, {2}, {1, 2}}.

    We will leave it to you to guess at a general formula for the number of

elements in the power set of a finite set. In Chapter 2, we will discuss counting

rules that will help us derive this formula.          

1.3.3 SageMath Note: Cartesian Products and Power Sets

Here is a simple example of a cartesian product of two sets:
CHAPTER 1. SET THEORY                            12

 A= Set ([0 ,1 ,2])
 B=Set([ 'a ' , 'b ' ])
 P= cartesian_product ([A ,B ]) ;P

  The Cartesian product of ({0, 1, 2}, { 'a ' , 'b ' })

    Here is the cardinality of the cartesian product.

 P. cardinality ()

 6

    The power set of a set is an iterable, as you can see from the output of this
next cell

 U= Set ([0 ,1 ,2 ,3])
 subsets(U)

  <generator object powerset at 0x7fec5ffd33c0 >
    You can iterate over a powerset. Here is a trivial example.

 for a in subsets(U):
         print(str(a)+ " has " +str(len(a))+" elements.")

  [] has 0 elements.
  [0] has 1 elements.
  [1] has 1 elements.
  [0, 1] has 2 elements.
  [2] has 1 elements.
  [0, 2] has 2 elements.
  [1, 2] has 2 elements.
  [0, 1, 2] has 3 elements.
  [3] has 1 elements.
  [0, 3] has 2 elements.
  [1, 3] has 2 elements.
  [0, 1, 3] has 3 elements.
  [2, 3] has 2 elements.
  [0, 2, 3] has 3 elements.
  [1, 2, 3] has 3 elements.
  [0, 1, 2, 3] has 4 elements.

1.3.4 Exercises

1. Let A = {0, 2, 3}, B = {2, 3}, C = {1, 4}, and let the universal set be
      U = {0, 1, 2, 3, 4}. List the elements of

(a) A × B              (e) A × Ac

(b) B × A              (f) B2

(c) A × B × C          (g) B3

(d) U ×                (h) B × P(B)

2. Suppose that you are about to flip a coin and then roll a die. Let

A = {HEADS, T AILS} and B = {1, 2, 3, 4, 5, 6}.

(a) What is |A × B|?
(b) How could you interpret the set A × B ?
CHAPTER 1. SET THEORY  13

3. List all two-element sets in P({a, b, c, d})
4. List all three-element sets in P({a, b, c, d}).
5. How many singleton (one-element) sets are there in P(A) if |A| = n ?
6. A person has four coins in his pocket: a penny, a nickel, a dime, and a

      quarter. How many different sums of money can he take out if he removes
      3 coins at a time?
7. Let A = {+, -} and B = {00, 01, 10, 11}.

        (a) List the elements of A × B

        (b) How many elements do A4 and (A × B)3 have?
8. Let A = {·, , } and B = {, , ·}.

        (a) List the elements of A × B and B × A. The parentheses and comma
              in an ordered pair are not necessary in cases such as this where the
              elements of each set are individual symbols.

        (b) Identify the intersection of A × B and B × A for the case above, and
              then guess at a general rule for the intersection of A × B and B × A,
              where A and B are any two sets.

9. Let A and B be nonempty sets. When are A × B and B × A equal?

1.4 Binary Representation of Positive Integers

1.4.1 Grouping by Twos

Recall that the set of positive integers, P, is {1, 2, 3, ...}. Positive integers are
naturally used to count things. There are many ways to count and many ways
to record, or represent, the results of counting. For example, if we wanted to
count five hundred twenty-three apples, we might group the apples by tens.
There would be fifty-two groups of ten with three single apples left over. The
fifty-two groups of ten could be put into five groups of ten tens (hundreds), with
two tens left over. The five hundreds, two tens, and three units is recorded
as 523. This system of counting is called the base ten positional system, or
decimal system. It is quite natural for us to do grouping by tens, hundreds,
thousands, . . . since it is the method that all of us use in everyday life.

    The term positional refers to the fact that each digit in the decimal repre-
sentation of a number has a significance based on its position. Of course this
means that rearranging digits will change the number being described. You
may have learned of numeration systems in which the position of symbols does
not have any significance (e.g., the ancient Egyptian system). Most of these
systems are merely curiosities to us now.

    The binary number system differs from the decimal number system in that
units are grouped by twos, fours, eights, etc. That is, the group sizes are powers
of two instead of powers of ten. For example, twenty-three can be grouped into
eleven groups of two with one left over. The eleven twos can be grouped into
five groups of four with one group of two left over. Continuing along the same
lines, we find that twenty-three can be described as one sixteen, zero eights,
one four, one two, and one one, which is abbreviated 10111two, or simply 10111
if the context is clear.
CHAPTER 1. SET THEORY                                              14

1.4.2 A Conversion Algorithm

The process that we used to determine the binary representation of 23 can be
described in general terms to determine the binary representation of any posi-
tive integer n. A general description of a process such as this one is called an
algorithm. Since this is the first algorithm in the book, we will first write it out
using less formal language than usual, and then introduce some "algorithmic
notation." If you are unfamiliar with algorithms, we refer you to Section A.1

  (1) Start with an empty list of bits.

  (2) Assign the variable k the value n.

  (3) While k's value is positive, continue performing the following three steps
       until k becomes zero and then stop.

        (a) divide k by 2, obtaining a quotient q (often denoted k div 2) and a
              remainder r (denoted (k mod 2)).

        (b) attach r to the left-hand side of the list of bits.
         (c) assign the variable k the value q.

Example 1.4.1 An example of conversion to binary. To determine the
binary representation of 41 we take the following steps:

· 41 = 2 × 20 + 1 List = 1
· 20 = 2 × 10 + 0 List = 01
· 10 = 2 × 5 + 0 List = 001
· 5 = 2 × 2 + 1 List = 1001
· 2 = 2 × 1 + 0 List = 01001
· 1 = 2 × 0+1 List = 101001

Therefore, 41 = 101001two                                          

The notation that we will use to describe this algorithm and all others is

called pseudocode, an informal variation of the instructions that are commonly

used in many computer languages. Read the following description carefully,

comparing it with the informal description above. Appendix B, which contains

a general discussion of the components of the algorithms in this book, should

clear up any lingering questions. Anything after // are comments.

Algorithm 1.4.2 Binary Conversion Algorithm. An algorithm for de-
termining the binary representation of a positive integer.

    Input: a positive integer n.
    Output: the binary representation of n in the form of a list of bits, with
units bit last, twos bit next to last, etc.

(1) k := n    //initialize k

(2) L := { }  //initialize L to an empty list

(3) While k > 0 do

(a) q := k div 2    //divide k by 2

(b) r := k mod 2

(c) L := prepend r to L           //add r to the front of L

(d) k := q          //reassign k
CHAPTER 1. SET THEORY                                               15

    Here is a Sage version of the algorithm with two alterations. It outputs the
binary representation as a string, and it handles all integers, not just positive
ones.

 def binary_rep(n):
        if n==0:
                return '0 '
         else:
                k=abs(n)
                s= ' '
                while k>0:
                       s=str(k%2)+s
                       k=k//2
                if n < 0:
                       s= '- '+s
                return s

 binary_rep (41)

  ' 101001 '

    Now that you've read this section, you should get this joke.

Figure 1.4.3 With permission from Randall Munroe, http://xkcd.com.
CHAPTER 1. SET THEORY                                                 16

1.4.3 Exercises

1. Find the binary representation of each of the following positive integers
      by working through the algorithm by hand. You can check your answer
      using the sage cell above.

(a) 31                               (c) 10

(b) 32                               (d) 100

2. Find the binary representation of each of the following positive integers

by working through the algorithm by hand. You can check your answer

using the sage cell above.

(a) 64                               (c) 28

(b) 67                               (d) 256

3. What positive integers have the following binary representations?

(a) 10010                            (c) 101010

(b) 10011                            (d) 10011110000

4. What positive integers have the following binary representations?

(a) 100001                           (c) 1000000000

(b) 1001001                          (d) 1001110000

5. The number of bits in the binary representations of integers increases

by one as the numbers double. Using this fact, determine how many bits

the binary representations of the following decimal numbers have without

actually doing the full conversion.

(a) 2017     (b) 4000                (c) 4500         (d) 250

6. Let m be a positive integer with n-bit binary representation:

an-1an-2 · · · a1a0 with an-1 = 1 What are the smallest and largest values
that m could have?

7. If a positive integer is a multiple of 100, we can identify this fact from its

decimal representation, since it will end with two zeros. What can you say

about a positive integer if its binary representation ends with two zeros?

What if it ends in k zeros?

8. Can a multiple of ten be easily identified from its binary representation?

1.5 Summation Notation and Generalizations

1.5.1 Sums

Most operations such as addition of numbers are introduced as binary oper-
ations. That is, we are taught that two numbers may be added together to
give us a single number. Before long, we run into situations where more than
two numbers are to be added. For example, if four numbers, a1, a2, a3, and
a4 are to be added, their sum may be written down in several ways, such as
((a1 + a2) + a3) + a4 or (a1 + a2) + (a3 + a4). In the first expression, the first
two numbers are added, the result is added to the third number, and that
result is added to the fourth number. In the second expression the first two
numbers and the last two numbers are added and the results of these additions
CHAPTER 1. SET THEORY                                                     17

are added. Of course, we know that the final results will be the same. This

is due to the fact that addition of numbers is an associative operation. For

such operations, there is no need to describe how more than two objects will

be operated on. A sum of numbers such as a1 + a2 + a3 + a4 is called a series
and is often written k=1 4 ak in what is called summation notation.

    We first recall some basic facts about series that you probably have seen

before. A more formal treatment of sequences and series is covered in Chapter

8. The purpose here is to give the reader a working knowledge of summation

notation and to carry this notation through to intersection and union of sets

and other mathematical operations.

A finite series is an expression such as a1 + a2 + a3 + · · · + an =  k=1 n ak
In the expression k=1 n ak:

· The variable k is referred to as the index, or the index of summation.

· The expression ak is the general term of the series. It defines the numbers
   that are being added together in the series.

· The value of k below the summation symbol is the initial index and the
   value above the summation symbol is the terminal index.

· It is understood that the series is a sum of the general terms where
   the index starts with the initial index and increases by one up to and
   including the terminal index.

Example 1.5.1 Some finite series.

         4

(a) ai = a1 + a2 + a3 + a4

        i=1

          5

(b) bk = b0 + b1 + b2 + b3 + b4 + b5

       k=0

     2

(c)        ci = c-2 + c-1 + c0 + c1 + c2

     i=-2

                                                                                                    
Example 1.5.2 More finite series. If the general terms in a series are more
specific, the sum can often be simplified. For example,

          4

(a) i2 = 12 + 22 + 32 + 42 = 30

        i=1

(b)

     5

          (2i - 1) = (2 · 1 - 1) + (2 · 2 - 1) + (2 · 3 - 1) + (2 · 4 - 1) + (2 · 5 - 1)

     i=1                                                                                              .

           =1+3+5+7+9

           = 25

                                                                          
CHAPTER 1. SET THEORY                                      18

1.5.2 Generalizations

Summation notation can be generalized to many mathematical operations, for

                                                             4

example, A1  A2  A3  A4 =  Ai

                                                           i=1

Definition 1.5.3 Generalized Set Operations. Let A1, A2, . . . , An be sets.
Then:

                                                     n

  (a) A1  A2  · · ·  An =  Ai

                                                    i=1

                                                     n

  (b) A1  A2  · · ·  An =  Ai

                                                    i=1

                                                       n

  (c) A1 × A2 × · · · × An = × Ai

                                                     i=1

                                                       n

  (d) A1  A2  · · ·  An =  Ai

                                                     i=1

Example 1.5.4 Some generalized operations.                                   
{1, 2, 3, 6}, and A3 = {-1, 0, 3, 9}, then      If A1 = {0, 2, 3}, A2 =

                         3

                         Ai = A1  A2  A3 = {3}

                        i=1

and

                                  3

                        Ai = A1  A2  A3 = {-1, 0, 1, 2, 3, 6, 9}.

                                i=1

With this notation it is quite easy to write lengthy expressions in a fairly
compact form. For example, the statement

A  (B1  B2  · · ·  Bn) = (A  B1)  (A  B2)  · · ·  (A  Bn)

becomes                      n           n

                        A   Bi =  (A  Bi) .
                             i=1         i=1

                                                           

1.5.3 Exercises

1. Calculate the following series:

         3                                    (c) j=0 n 2j for n = 1, 2, 3, 4
                                              (d) k=1 n (2k - 1) for n = 1, 2, 3, 4
(a) (2 + 3i)

        i=1

         1

(b)         i2

                    i=-2

2. Calculate the following series:

(a)      3    kn  for  n  =  1, 2, 3, 4
         k=1

          5

(b) 20

        i=1

(c)      3      nj + 1    for n = 1, 2, 3, 4
         j=0
CHAPTER 1. SET THEORY                                                                      19

        (d) k=-n n k for n = 1, 2, 3, 4
3.

    (a) Express the formula       n      1    =                         n  without  using  summation
         notation.                                                    n+1
                                  i=1 i(i+1)

    (b) Verify this formula for n = 3.

         (c) Repeat parts (a) and (b) for i=1 n i3 = 4 n2(n+1)2
4. Verify the following properties for n = 3.

           n             n        n

    (a) (ai + bi) = ai + bi

    i=1                  i=1      i=1

    (b) c     n                n

                 ai      = cai

              i=1        i=1

5. Rewrite the following without summation sign for n = 3. It is not

    necessary that you understand or expand the notation n at this
                                                                                    k

    point. (x + y)n = nk=0 nk xn-kyk.

6.

                                                                   3

    (a) Draw the Venn diagram for  Ai.

                                                                 i=1

                                                                      n    n
    (b) Express in "expanded format": A  (  Bi) =  (A  Bi).
                                                                      i=1  i=1

7. For any positive integer k, let Ak = {x  Q : k - 1 < x  k} and
      Bk = {x  Q : -k < x < k}. What are the following sets?

             5                                         5

    (a)  Ai                                   (c)  Ai

           i=1                                       i=1

           5                                                          5
    (b)  Bi                                   (d)  Bi
    i=1                                                               i=1
8. For any positive integer k, let Ak = {x  Q : 0 < x < 1/k} and
    Bk = {x  Q : 0 < x < k}. What are the following sets?

                                                      

    (a)  Ai                                   (c)  Ai

           i=1                                       i=1

                                                                      
    (b)  Bi                                   (d)  Bi
    i=1                                                               i=1
9. The symbol  is used for the product of numbers in the same way that

     is used for sums. For example,         i=1 5 xi = x1x2x3x4x5. Evaluate the
    following:

                      3                                3

        (a) i2                                (b) (2i + 1)

                    i=1                              i=1

10. Evaluate

             3                                100 (b) k
                                                        k+1
    (a) 2k
                                                     k=1
           k=0
Chapter 2

Combinatorics

                     Enumerative Combinatorics

                              Enumerative combinatorics
                             Date back to the first prehistorics

                                    Who counted; relations
                                    Like sets' permutations
                         To them were part cult, part folklorics.

   Michael Toalster, The Omnificent English Dictionary In Limerick Form

Throughout this book we will be counting things. In this chapter we will
outline some of the tools that will help us count.

    Counting occurs not only in highly sophisticated applications of mathemat-
ics to engineering and computer science but also in many basic applications.
Like many other powerful and useful tools in mathematics, the concepts are
simple; we only have to recognize when and how they can be applied.

2.1 Basic Counting Techniques - The Rule of Prod-
     ucts

2.1.1 What is Combinatorics?

One of the first concepts our parents taught us was the "art of counting."
We were taught to raise three fingers to indicate that we were three years
old. The question of "how many" is a natural and frequently asked question.
Combinatorics is the "art of counting." It is the study of techniques that will
help us to count the number of objects in a set quickly. Highly sophisticated
results can be obtained with this simple concept. The following examples
will illustrate that many questions concerned with counting involve the same
process.
Example 2.1.1 How many lunches can you have? A snack bar serves
five different sandwiches and three different beverages. How many different
lunches can a person order? One way of determining the number of possible
lunches is by listing or enumerating all the possibilities. One systematic way
of doing this is by means of a tree, as in the following figure.

                                                  20
CHAPTER 2. COMBINATORICS                                                    21

Figure 2.1.2 Tree diagram to enumerate the number of possible lunches.

Every path that begins at the position labeled START and goes to the right

can be interpreted as a choice of one of the five sandwiches followed by a choice

of one of the three beverages. Note that considerable work is required to arrive

at the number fifteen this way; but we also get more than just a number. The

result is a complete list of all possible lunches. If we need to answer a question

that starts with "How many . . . ," enumeration would be done only as a last

resort. In a later chapter we will examine more enumeration techniques.

An alternative method of solution for this example is to make the simple

observation that there are five different choices for sandwiches and three differ-

ent choices for beverages, so there are 5 · 3 = 15 different lunches that can be

ordered.                                                                    

Example 2.1.3 Counting elements in a cartesian product. Let A =

{a, b, c, d, e} and B = {1, 2, 3}. From Chapter 1 we know how to list the

elements in A × B = {(a, 1), (a, 2), (a, 3), ..., (e, 3)}. Since the first entry of

each pair can be any one of the five elements a, b, c, d, and e, and since the

second can be any one of the three numbers 1, 2, and 3, it is quite clear there

are 5 · 3 = 15 different elements in A × B.                                 

Example 2.1.4 A True-False Questionnaire. A person is to complete a

true-false questionnaire consisting of ten questions. How many different ways

are there to answer the questionnaire? Since each question can be answered in

either of two ways (true or false), and there are ten questions, there are

          2 · 2 · 2 · 2 · 2 · 2 · 2 · 2 · 2 · 2 = 210 = 1024

different ways of answering the questionnaire. The reader is encouraged to

visualize the tree diagram of this example, but not to draw it!             

We formalize the procedures developed in the previous examples with the

following rule and its extension.

2.1.2 The Rule Of Products

Theorem 2.1.5 The Rule Of Products. If two operations must be per-
formed, and if the first operation can always be performed p1 different ways
and the second operation can always be performed p2 different ways, then there
are p1p2 different ways that the two operations can be performed.

    Note: It is important that p2 does not depend on the option that is chosen
in the first operation. Another way of saying this is that p2 is independent of
the first operation. If p2 is dependent on the first operation, then the rule of
CHAPTER 2. COMBINATORICS                          22

products does not apply.

Example 2.1.6 Reduced Lunch Possibilities. Assume in Example 2.1.1,

coffee is not served with a beef or chicken sandwiches. Then by inspection of

Figure 2.1.2 we see that there are only thirteen different choices for lunch. The

rule of products does not apply, since the choice of beverage depends on one's

choice of a sandwich.                             

The rule of products can be extended to include sequences of more than

two operations.

Theorem 2.1.7 Extended Rule Of Products. If n operations must be

performed, and the number of options for each operation is p1, p2, . . . , pn re-
spectively, with each pi independent of previous choices, then the n operations
can be performed p1 · p2 · · · · · pn different ways.

Example 2.1.8 A Multiple Choice Questionnaire. A questionnaire

contains four questions that have two possible answers and three questions

with five possible answers. Since the answer to each question is independent

of the answers to the other questions, the extended rule of products applies

and there are 2 · 2 · 2 · 2 · 5 · 5 · 5 = 24 · 53 = 2000 different ways to answer the

questionnaire.                                    

In Chapter 1 we introduced the power set of a set A, P(A), which is the set

of all subsets of A. Can we predict how many elements are in P(A) for a given

finite set A? The answer is yes, and in fact if |A| = n, then |P(A)| = 2n. The

ease with which we can prove this fact demonstrates the power and usefulness

of the rule of products. Do not underestimate the usefulness of simple ideas.

Theorem 2.1.9 Power Set Cardinality Theorem. If A is a finite set,
then |P(A)| = 2|A|.

Proof. Proof: Consider how we might determine any B  P(A), where |A| = n.
For each element x  A there are two choices, either x  B or x / B. Since
there are n elements of A we have, by the rule of products,

                          2 · 2 · · · · · 2 = 2n

                             n factors

different subsets of A. Therefore, P(A) = 2n.     

2.1.3 Exercises

1. In horse racing, to bet the "daily double" is to select the winners of the
      first two races of the day. You win only if both selections are correct. In
      terms of the number of horses that are entered in the first two races, how
      many different daily double bets could be made?

2. Professor Shortcut records his grades using only his students' first and
      last initials. What is the smallest class size that will definitely force Prof.
      S. to use a different system?

3. A certain shirt comes in four sizes and six colors. One also has the choice
      of a dragon, an alligator, or no emblem on the pocket. How many different
      shirts could you order?

4. A builder of modular homes would like to impress his potential customers
      with the variety of styles of his houses. For each house there are blueprints
      for three different living rooms, four different bedroom configurations, and
      two different garage styles. In addition, the outside can be finished in cedar
      shingles or brick. How many different houses can be designed from these
      plans?
CHAPTER 2. COMBINATORICS          23

5. The Pi Mu Epsilon mathematics honorary society of Outstanding Uni-
      versity wishes to have a picture taken of its six officers. There will be
      two rows of three people. How many different way can the six officers be
      arranged?

6. An automobile dealer has several options available for each of three dif-
      ferent packages of a particular model car: a choice of two styles of seats
      in three different colors, a choice of four different radios, and five different
      exteriors. How many choices of automobile does a customer have?

7. A clothing manufacturer has put out a mix-and-match collection consist-
      ing of two blouses, two pairs of pants, a skirt, and a blazer. How many
      outfits can you make? Did you consider that the blazer is optional? How
      many outfits can you make if the manufacturer adds a sweater to the
      collection?

8. As a freshman, suppose you had to take two of four lab science courses,
      one of two literature courses, two of three math courses, and one of
      seven physical education courses. Disregarding possible time conflicts,
      how many different schedules do you have to choose from?

9. (a) Suppose each single character stored in a computer uses eight bits.
      Then each character is represented by a different sequence of eight 0's and
      1's called a bit pattern. How many different bit patterns are there? (That
      is, how many different characters could be represented?)
           (b) How many bit patterns are palindromes (the same backwards as
      forwards)?
           (c) How many different bit patterns have an even number of 1's?

10. Automobile license plates in Massachusetts usually consist of three digits
      followed by three letters. The first digit is never zero. How many different
      plates of this type could be made?

11.

        (a) Let A = {1, 2, 3, 4}. Determine the number of different subsets of
              A.

        (b) Let A = {1, 2, 3, 4, 5}. Determine the number of proper subsets of
              A.

12. How many integers from 100 to 999 can be written in base ten without
      using the digit 7?

13. Consider three persons, A, B, and C, who are to be seated in a row of
      three chairs. Suppose A and B are identical twins. How many seating
      arrangements of these persons can there be

(a) If you are a total stranger?  (b) If you are A and B's mother?

           This problem is designed to show you that different people can have
      different correct answers to the same problem.

14. How many ways can a student do a ten-question true-false exam if he or
      she can choose not to answer any number of questions?

15. Suppose you have a choice of fish, lamb, or beef for a main course, a
      choice of peas or carrots for a vegetable, and a choice of pie, cake, or ice
      cream for dessert. If you must order one item from each category, how
      many different dinners are possible?

16. Suppose you have a choice of vanilla, chocolate, maple walnut or straw-
      berry for ice cream, a choice of peanuts or walnuts for chopped nuts, and
CHAPTER 2. COMBINATORICS  24

      a choice of hot fudge or marshmallow for topping. You don't have to order
      nuts. How many different sundaes are possible?

17. A questionnaire contains six questions each having yes-no answers. For
      each yes response, there is a follow-up question with four possible re-
      sponses.

        (a) Draw a tree diagram that illustrates how many ways a single ques-
              tion in the questionnaire can be answered.

        (b) How many ways can the questionnaire be answered?

18. Six people are invited to a dinner party. How many ways are there of
      seating them at a round table? If the six people consist of three who
      identify as male and three who identify as female, how many ways are
      there of seating them if each male must be surrounded by two females?
      Assume we are only concerned with the relative positions around the table.
      So if we rotate everyone we wouldn't consider this a change in the seating.

19. How many ways can you separate a set with n elements into two nonempty
      subsets if the order of the subsets is immaterial? What if the order of the
      subsets is important?

20. A gardener has three flowering shrubs and four nonflowering shrubs,
      where all shrubs are distinguishable from one another. He must plant
      these shrubs in a row using an alternating pattern, that is, a shrub must
      be of a different type from that on either side. How many ways can he
      plant these shrubs? If he has to plant these shrubs in a circle using the
      same pattern, how many ways can he plant this circle? Note that one
      nonflowering shrub will be left out at the end.

2.2 Permutations

2.2.1 Ordering Things

A number of applications of the rule of products are of a specific type, and
because of their frequent appearance they are given their own designation,
permutations. Consider the following examples.

Example 2.2.1 Ordering the elements of a set. How many different ways
can we order the three different elements of the set A = {a, b, c}? Since we
have three choices for position one, two choices for position two, and one choice
for the third position, we have, by the rule of products, 3 · 2 · 1 = 6 different
ways of ordering the three letters. We illustrate through a tree diagram.
CHAPTER 2. COMBINATORICS                                               25

Figure 2.2.2 A tree to enumerate permutations of a three element set.

Each of the six orderings is called a permutation of the set A.        

Example 2.2.3 Preference Voting. In an election that uses preference
voting, voters rank candidates 1st, 2nd, 3rd etc. in order of their preference
instead of just selecting their first preference. How many different ways can a
voter cast a ballot with five candidates? Each way to vote is a permutation of
the five candidates. There are 5 · 4 · 3 · 2 · 1 = 120 different ways to vote. 

    In each of the above examples of the rule of products we observe that:

(a) We are asked to order or arrange elements from a single set.

(b) Each element is listed exactly once in each list (permutation). So if there

are n choices for position one in a list, there are n - 1 choices for position
two, n - 2 choices for position three, etc.

Example 2.2.4 Some orderings of a baseball team. The alphabetical or-

dering of the players of a baseball team is one permutation of the set of players.

Other orderings of the players' names might be done by batting average, age,

or height. The information that determines the ordering is called the key. We

would expect that each key would give a different permutation of the names.

If there are twenty-five players on the team, there are 25 · 24 · 23 · · · · · 3 · 2 · 1
different permutations of the players.

This number of permutations is huge.  In fact it is

15511210043330985984000000, but writing it like this isn't all that in-

structive, while leaving it as a product as we originally had makes it easier to

see where the number comes from. We just need to find a more compact way

of writing these products.                                             

We now develop notation that will be useful for permutation problems.

Definition 2.2.5 Factorial. If n is a positive integer then n factorial is

the product of the first n positive integers and is denoted n!. Additionally, we

define zero factorial, 0!, to be 1.                                    
CHAPTER 2. COMBINATORICS                                                                                26

The first few factorials are

             n 0123 4 5 6 7 .
             n! 1 1 2 6 24 120 720 5040

Note that 4! is 4 times 3!, or 24, and 5! is 5 times 4!, or 120. In addition,

note that as n grows in size, n! grows extremely quickly. For example, 11! =

39916800. If the answer to a problem happens to be 25!, as in the previous

example, you would never be expected to write that number out completely.

However,  a  problem  with  an  answer  of  25!  can  be  reduced  to  25 · 24,                   or  600.
                                            23!
If |A| = n, there are n! ways of permuting all n elements of A . We next

consider the more general situation where we would like to permute k elements

out of a set of n objects, where k  n.

Example 2.2.6 Choosing Club Officers. A club of twenty-five mem-

bers will hold an election for president, secretary, and treasurer in that order.

Assume a person can hold only one position. How many ways are there of

choosing these three officers? By the rule of products there are 25 · 24 · 23 ways

of making a selection.                                                                                      

Definition 2.2.7 Permutation. An ordered arrangement of k elements

selected from a set of n elements, 0  k  n, where no two elements of the

arrangement are the same, is called a permutation of n objects taken k at a

time. The total number of such permutations is denoted by P (n, k).                                         

Theorem 2.2.8 Permutation Counting Formula. The number of possible
permutations of k elements taken from a set of n elements is

                                                                                             k-1  n! .

P (n, k) = n · (n - 1) · (n - 2) · · · · · (n - k + 1) = (n - j) =
                                                          j=0 (n - k)!

Proof. Case I: If k = n we have P (n, n) = n! = (n-n)! n! .
Case II: If 0  k < n,then we have k positions to fill using n elements and

(a) Position 1 can be filled by any one of n - 0 = n elements
(b) Position 2 can be filled by any one of n - 1 elements
(c) · · ·
(d) Position k can be filled by any one of n - (k - 1) = n - k + 1 elements

Hence, by the rule of products,

          P (n, k) = n · (n - 1) · (n - 2) · · · · · (n - k + 1) = n! .
                                                                           (n - k)!

                                                                                                    
    It is important to note that the derivation of the permutation formula given
above was done solely through the rule of products. This serves to reiterate
our introductory remarks in this section that permutation problems are really
rule-of-products problems. We close this section with several examples.

Example 2.2.9 Another example of choosing officers. A club has eight
members eligible to serve as president, vice-president, and treasurer. How many
ways are there of choosing these officers?

    Solution 1: Using the rule of products. There are eight possible choices for
the presidency, seven for the vice-presidency, and six for the office of treasurer.
By the rule of products there are 8 · 7 · 6 = 336 ways of choosing these officers.
CHAPTER 2. COMBINATORICS                                                          27

    Solution 2: Using the permutation formula. We want the total number of
permutations of eight objects taken three at a time:

                 8!
P (8, 3) = (8 - 3)! = 8 · 7 · 6 = 336

                                                                                                    
Example 2.2.10 Preference Voting, revisited. To count the number
of ways to vote for five candidates in a preference system, we can use the
permutation formula. We want the number of permutations of five candidates
taken five at a time:

                               P (5, 5) = 5! = 5! = 120.
                                             (5 - 5)!

                                                                                                    
Example 2.2.11 Ordering of digits under different conditions. Con-
sider only the digits 1, 2, 3, 4, and 5.

a How many three-digit numbers can be formed if no repetition of digits
   can occur?

b How many three-digit numbers can be formed if repetition of digits is
   allowed?

c How many three-digit numbers can be formed if only non-consecutive
   repetition of digits are allowed?

    Solutions to (a): Solution 1: Using the rule of products. We have any one
of five choices for digit one, any one of four choices for digit two, and three
choices for digit three. Hence, 5 · 4 · 3 = 60 different three-digit numbers can
be formed.

    Solution 2; Using the permutation formula. We want the total number of
permutations of five digits taken three at a time:

P (5, 3) = 5! = 5 · 4 · 3 = 60.
             (5 - 3)!

Solution to (b): The definition of permutation indicates "...no two elements

in each list are the same." Hence the permutation formula cannot be used.

However, the rule of products still applies. We have any one of five choices for

the first digit, five choices for the second, and five for the third. So there are

5 · 5 · 5 = 125 possible different three-digit numbers if repetition is allowed.

Solution to (c): Again, the rule of products applies here. We have any

one of five choices for the first digit, but then for the next two digits we have

four choices since we are not allowed to repeat the previous digit So there

are 5 · 4 · 4 = 80 possible different three-digit numbers if only non-consecutive

repetitions are allowed.                                                          

2.2.2 Exercises

1. If a raffle has three different prizes and there are 1,000 raffle tickets sold,
      how many different ways can the prizes be distributed?

2.

        (a) How many three-digit numbers can be formed from the digits 1, 2,
              3 if no repetition of digits is allowed? List the three-digit numbers.
CHAPTER 2. COMBINATORICS  28

        (b) How many two-digit numbers can be formed if no repetition of digits
              is allowed? List them.

         (c) How many two-digit numbers can be obtained if repetition is al-
              lowed?

3. How many eight-letter words can be formed from the 26 letters in the
      alphabet? Even without concerning ourselves about whether the words
      make sense, there are two interpretations of this problem. Answer both.

4. Let A be a set with |A| = n. Determine

        (a) |A3|

        (b) |{(a, b, c) | a, b, c  A and each coordinate is different}|
5. The state finals of a high school track meet involves fifteen schools. How

      many ways can these schools be listed in the program?
6. Consider the three-digit numbers that can be formed from the digits 1,

      2, 3, 4, and 5 with no repetition of digits allowed.

        (a) How many of these are even numbers?

        (b) How many are greater than 250?
7. All 15 players on the Tall U. basketball team are capable of playing any

      position.

        (a) How many ways can the coach at Tall U. fill the five starting posi-
              tions in a game?

        (b) What is the answer if the center must be one of two players?
8. With circular arrangements like the ones described in this problem it's

      common to assume that two arrangements are considered that same if one
      can be rotated to equal the other. However, since you can't rotate planted
      shrubs so easily, you might want to also count the possibilities assuming
      there are five designated positions: front, side right, side left, back right,
      back left.

        (a) How many ways can a gardener plant five different species of shrubs
              in a circle?

        (b) What is the answer if two of the shrubs are the same?

         (c) What is the answer if all the shrubs are identical?
9. The president of the Math and Computer Club would like to arrange a

      meeting with six attendees, the president included. There will be three
      computer science majors and three math majors at the meeting. How
      many ways can the six people be seated at a circular table if the president
      does not want people with the same majors to sit next to one other?
10. Six people apply for three identical jobs and all are qualified for the
      positions. Two will work in New York and the other one will work in San
      Diego. How many ways can the positions be filled?
11. Let A = {1, 2, 3, 4}. Determine the cardinality of

        (a) {(a1, a2) | a1 = a2}

        (b) What is the answer to the previous part if |A| = n

         (c) If |A| = n, determine the number of m-tuples in A, m  n, where
CHAPTER 2. COMBINATORICS                                  29

each coordinate is different from the other coordinates.

2.3 Partitions of Sets and the Law of Addition

2.3.1 Partitions

One way of counting the number of students in your class would be to count the
number in each row and to add these totals. Of course this problem is simple
because there are no duplications, no person is sitting in two different rows.
The basic counting technique that you used involves an extremely important
first step, namely that of partitioning a set. The concept of a partition must
be clearly understood before we proceed further.

Definition 2.3.1 Partition. A partition of set A is a set of one or more
nonempty subsets of A: A1, A2, A3, · · ·, such that every element of A is in
exactly one set. Symbolically,

(a) A1  A2  A3  · · · = A
(b) If i = j then Ai  Aj = 

                                                                                                     
    The subsets in a partition are often referred to as blocks. Note how our
definition allows us to partition infinite sets, and to partition a set into an
infinite number of subsets. Of course, if A is finite the number of subsets can
be no larger than |A|.

Example 2.3.2 Some partitions of a four element set. Let A =
{a, b, c, d}. Examples of partitions of A are:

· {{a}, {b}, {c, d}}
· {{a, b}, {c, d}}
· {{a}, {b}, {c}, {d}}

How many others are there, do you suppose?

There are 15 different partitions. The most efficient way to count them

all is to classify them by the size of blocks. For example, the partition

{{a}, {b}, {c, d}} has block sizes 1, 1, and 2.           

Example 2.3.3 Some Integer Partitions. Two examples of partitions of
the set of integers Z are

· {{n} | n  Z} and
· {{n  Z | n < 0}, {0}, {n  Z | 0 < n}}.

    The set of subsets {{n  Z | n  0}, {n  Z | n  0}} is not a partition
because the two subsets have a nonempty intersection. A second example of

a non-partition is {{n  Z | |n| = k} | k = -1, 0, 1, 2, · · · } because one of the
blocks, when k = -1 is empty.
                                                          

One could also think of the concept of partitioning a set as a "packaging

problem." How can one "package" a carton of, say, twenty-four cans? We could

use: four six-packs, three eight-packs, two twelve-packs, etc. In all cases: (a)

the sum of all cans in all packs must be twenty-four, and (b) a can must be in

one and only one pack.
CHAPTER 2. COMBINATORICS                                         30

2.3.2 Addition Laws

Theorem 2.3.4 The Basic Law Of Addition:. If A is a finite set, and if
{A1, A2, . . . , An} is a partition of A , then

                                                                                                   n

                         |A| = |A1| + |A2| + · · · + |An| = |Ak|

                                                                                                 k=1

    The basic law of addition can be rephrased as follows: If A is a finite set
where A1  A2  · · ·  An = A and where Ai  Aj =  whenever i = j, then

         |A| = |A1  A2  · · ·  An| = |A1| + |A2| + · · · + |An|

Example 2.3.5 Counting All Students. The number of students in a

class could be determined by adding the numbers of students who are fresh-

men, sophomores, juniors, and seniors, and those who belong to none of these

categories. However, you probably couldn't add the students by major, since

some students may have double majors.                            

Example 2.3.6 Counting Students in Disjoint Classes. The sophomore

computer science majors were told they must take one and only one of the

following courses that are open only to them: Cryptography, Data Structures,

or JavaScript. The numbers in each course, respectively, for sophomore CS

majors, were 75, 60, 55. How many sophomore CS majors are there? The Law

of Addition applies here. There are exactly 75 + 60 + 55 = 190 CS majors since

the rosters of the three courses listed above would be a partition of the CS

majors.                                                          

Example 2.3.7 Counting Students in Non-disjoint Classes. It was
determined that all junior computer science majors take at least one of the fol-
lowing courses: Algorithms, Logic Design, and Compiler Construction. Assume
the number in each course was 75, 60 and 55, respectively for the three courses
listed. Further investigation indicated ten juniors took all three courses, twenty-
five took Algorithms and Logic Design, twelve took Algorithms and Compiler
Construction, and fifteen took Logic Design and Compiler Construction. How
many junior C.S. majors are there?

    Example 2.3.6 was a simple application of the law of addition, however
in this example some students are taking two or more courses, so a simple
application of the law of addition would lead to double or triple counting. We
rephrase information in the language of sets to describe the situation more
explicitly.

    A = the set of all junior computer science majors
    A1 = the set of all junior computer science majors who took Algorithms
    A2 = the set of all junior computer science majors who took Logic Design
    A3 = the set of all junior computer science majors who took Compiler
Construction
    Since all junior CS majors must take at least one of the courses, the number
we want is:

         |A| = |A1  A2  A3| = |A1| + |A2| + |A3| - repeats.

    A Venn diagram is helpful to visualize the problem. In this case the univer-
sal set U can stand for all students in the university.
CHAPTER 2. COMBINATORICS  31

Figure 2.3.8 Venn Diagram
    We see that the whole universal set is naturally partitioned into subsets

that are labeled by the numbers 1 through 8, and the set A is partitioned
into subsets labeled 1 through 7. The region labeled 8 represents all students
who are not junior CS majors. Note also that students in the subsets labeled
2, 3, and 4 are double counted, and those in the subset labeled 1 are triple
counted. To adjust, we must subtract the numbers in regions 2, 3 and 4. This
can be done by subtracting the numbers in the intersections of each pair of
sets. However, the individuals in region 1 will have been removed three times,
just as they had been originally added three times. Therefore, we must finally
add their number back in.

|A| = |A1  A2  A3|
     = |A1| + |A2| + |A3| - repeats
     = |A1| + |A2| + |A3| - duplicates + triplicates
     = |A1| + |A2| + |A3| - (|A1  A2| + |A1  A3| + |A2  A3|) + |A1  A2  A3|
     = 75 + 60 + 55 - 25 - 12 - 15 + 10 = 148

                                                                                                     
    The ideas used in this latest example gives rise to a basic counting tech-
nique:

Theorem 2.3.9 Laws of Inclusion-Exclusion. Given finite sets A1, A2, A3,
then

  (a) The Two Set Inclusion-Exclusion Law:

                                |A1  A2| = |A1| + |A2| - |A1  A2|
CHAPTER 2. COMBINATORICS                                                                      32

  (b) The Three Set Inclusion-Exclusion Law:

                  |A1  A2  A3| = |A1| + |A2| + |A3|

                                         - (|A1  A2| + |A1  A3| + |A2  A3|)

                                         + |A1  A2  A3|
    The inclusion-exclusion laws extend to more than three sets, as will be
explored in the exercises.
    In this section we saw that being able to partition a set into disjoint subsets
gives rise to a handy counting technique. Given a set, there are many ways to
partition depending on what one would wish to accomplish. One natural par-
titioning of sets is apparent when one draws a Venn diagram. This particular
partitioning of a set will be discussed further in Chapters 4 and 13.

2.3.3 Exercises

1. List all partitions of the set A = {a, b, c}.
2. Which of the following collections of subsets of the plane, R2, are parti-

      tions?

    (a) {{(x, y) | x + y = c} | c  R}
    (b) The set of all circles in R2
    (c) The set of all circles in R2 centered at the origin together with the

         set {(0, 0)}

        (d) {{(x, y)} | (x, y)  R2}

3. A student, on an exam paper, defined the term partition the following
      way: "Let A be a set. A partition of A is any set of nonempty subsets
      A1, A2, A3, . . . of A such that each element of A is in one of the subsets."
      Is this definition correct? Why?

4. Let A1 and A2 be subsets of a set U . Draw a Venn diagram of this

    situation  and  shade  in  the  subsets  A1    A2,  Ac      A2,  A1    Ac2,  and  Ac      Ac

                                                           1                             1       2

    . Use the resulting diagram and the definition of partition to convince

    yourself that the subset of these four subsets that are nonempty form a

    partition of U .

5. Show that {{2n | n  Z}, {2n + 1 | n  Z}} is a partition of Z. Describe
      this partition using only words.

6.

    (a) A group of 30 students were surveyed and it was found that 18 of
         them took Calculus and 12 took Physics. If all students took at least
         one course, how many took both Calculus and Physics? Illustrate
         using a Venn diagram.

        (b) What is the answer to the question in part (a) if five students did
              not take either of the two courses? Illustrate using a Venn diagram.

7. A survey of 90 people, 47 of them played tennis and 42 of them swam. If
      17 of them participated in both activities, how many of them participated
      in neither?

8. A survey of 300 people found that 60 owned an iPhone, 75 owned a
      Blackberry, and 30 owned an Android phone. Furthermore, 40 owned both
      an iPhone and a Blackberry, 12 owned both an iPhone and an Android
      phone, and 8 owned a Blackberry and an Android phone. Finally, 3 owned
CHAPTER 2. COMBINATORICS                                                                     33

all three phones.

        (a) How many people surveyed owned none of the three phones?

        (b) How many people owned a Blackberry but not an iPhone?

         (c) How many owned a Blackberry but not an Android?
9. Regarding Theorem 2.3.9,

        (a) Use the two set inclusion-exclusion law to derive the three set
             inclusion-exclusion law. Note: A knowledge of basic set laws is
             needed for this exercise.

        (b) State and derive the inclusion-exclusion law for four sets.

10. To complete your spring schedule, you must add Calculus and Physics.
      At 9:30, there are three Calculus sections and two Physics sections; while
      at 11:30, there are two Calculus sections and three Physics sections. How
      many ways can you complete your schedule if your only open periods are
      9:30 and 11:30?

11. The definition of Q = {a/b | a, b  Z, b = 0} given in Chapter 1 is
awkward. If we use the definition to list elements in Q, we will have
duplications      such  as  12 ,  -2  and  300  Try     to  write  a  more  precise  definition
                                  -4       600
of the rational numbers so that there is no duplication of elements.

2.4 Combinations and the Binomial Theorem

2.4.1 Combinations

In Section 2.1 we investigated the most basic concept in combinatorics, namely,
the rule of products. It is of paramount importance to keep this fundamental
rule in mind. In Section 2.2 we saw a subclass of rule-of-products problems,
permutations, and we derived a formula as a computational aid to assist us.
In this section we will investigate another counting formula, one that is used
to count combinations, which are subsets of a certain size.

    In many rule-of-products applications the ordering is important, such as
the batting order of a baseball team. In other cases it is not important, as in
placing coins in a vending machine or in the listing of the elements of a set.
Order is important in permutations. Order is not important in combinations.

Example 2.4.1 Counting Permutations. How many different ways are

there to permute three letters from the set A = {a, b, c, d}? From the Permu-

tation  Counting  Formula   there     are  P (4, 3)  =     4!   =  24  different  orderings  of
                                                        (4-3)!
three letters from A
                                                                                             

Example 2.4.2 Counting with No Order. How many ways can we select

a set of three letters from A = {a, b, c, d}? Note here that we are not concerned

with the order of the three letters. By trial and error, abc, abd, acd, and bcd

are the only listings possible. To repeat, we were looking for all three-element

subsets of the set A. Order is not important in sets. The notation for choosing

3 elements from 4 is most commonly         4    or occasionally C(4, 3), either of which
                                           3
is read "4 choose 3" or the number of combinations for four objects taken three

at a time.                                                                                   

Definition 2.4.3 Binomial Coefficient. Let n and k be nonnegative inte-

gers. The binomial coefficient        n  represents the number of combinations of n
                                      k
objects taken k at a time, and is read "n choose k."                                         
CHAPTER 2. COMBINATORICS                                                34

We would now like to investigate the relationship between permutation and

combination problems in order to derive a formula for         n
                                                              k
Let us reconsider the Counting with No Order. There are 3! = 6 different

orderings for each of the three-element subsets. The table below lists each

subset of A and all permutations of each subset on the same line.

                          subset                permutations
                          {a, b, c}     abc, acb, bca, bac, cab, cba
                          {a, b, d}     abd, adb, bda, bad, dab, dba .
                          {a, c, d}     acd, adc, cda, cad, dac, dca
                          {b, c, d}     bcd, bdc, cdb, cbd, dbc, dcb

Hence, 34 = 3! P (4,3) = (4-3)!·3! 4! = 4
We generalize this result in the following theorem:

Theorem 2.4.4 Binomial Coefficient Formula. If n and k are nonnegative

integers with 0  k  n, then the number k-element subsets of an n element

set is equal to

                                        n      n! .
                                            =
                                        k (n - k)! · k!

Proof. Proof 1: There are k! ways of ordering the elements of any k element

set. Therefore,

                          n P (n, k)           =     n! ..
                                     =
                          k             k!        (n - k)!k!

Proof 2: To "construct" a permutation of k objects from a set of n elements,
we can first choose one of the subsets of objects and second, choose one of the
k! permutations of those objects. By the rule of products,

                                                       n
                                        P (n, k) = k · k!

and solving for     n  we get the desired formula.                      
                    k

Example 2.4.5 Flipping Coins. Assume an evenly balanced coin is tossed

five times. In how many ways can three heads be obtained? This is a combi-

nation problem, because the order in which the heads appear does not matter.

We can think of this as a situation involving sets by considering the set of flips

of the coin, 1 through 5, in which heads comes up. The number of ways to get

three heads is   5     = 5·4 2·1 = 10.                                  
                 3

Example 2.4.6 Counting five ordered flips two ways. We determine

the total number of ordered ways a fair coin can land if tossed five consecutive

times. The five tosses can produce any one of the following mutually exclusive,

disjoint events: 5 heads, 4 heads, 3 heads, 2 heads, 1 head, or 0 heads. For

example, by the previous example, there are       5  = 10 sequences in which three
                                                  3
heads appear. Counting the other possibilities in the same way, by the law of

addition we have:

5      5               5  5             5      5
       + + + + + = 1 + 5 + 10 + 10 + 5 + 1 = 32
5      4               3  2             1      0

ways to observe the five flips.

Of course, we could also have applied the extended rule of products, and

since there are two possible outcomes for each of the five tosses, we have 25 = 32

ways.                                                                   
CHAPTER 2. COMBINATORICS                                                   35

    You might think that counting something two ways is a waste of time but

solving a problem two different ways often is instructive and leads to valuable
insights. In this case, it suggests a general formula for the sum k=0 k n n . In
the case of n = 5, we get 25 so it is reasonable to expect that the general
sum is 2n, and it is. A logical argument to prove the general statement simply

involves generalizing the previous example to n coin flips.

Example 2.4.7 A Committee of Five. A committee usually starts as an

unstructured set of people selected from a larger membership. Therefore, a

committee can be thought of as a combination. If a club of 25 members has a

five-member social committee, there are     25  = 25·24·23·22·21 5! = 53130 different
                                            5
possible social committees. If any structure or restriction is placed on the

way the social committee is to be selected, the number of possible committees

will probably change. For example, if the club has a rule that the treasurer

must be on the social committee, then the number of possibilities is reduced

to 244 = 24·23·22·21 4! = 10626.
    If we further require that a chairperson other than the treasurer be selected

for the social committee, we have  24    · 4 = 42504 different possible social
                                   4
                                                                           24
committees. The choice of the four non-treasurers accounts for the factor  4

while the need to choose a chairperson accounts for the 4.                 

Example 2.4.8 Binomial Coefficients - Extreme Cases. By simply

applying the definition of a Binomial Coefficient as a number of subsets we see

that there is  n  = 1 way of choosing a combination of zero elements from a set
               0
                                         n
of n. In addition, we see that there is  n  = 1 way of choosing a combination

of n elements from a set of n.

    We could compute these values using the formula we have developed, but

no arithmetic is really needed here. Other properties of binomial coefficients

that can be derived using the subset definition will be seen in the exercises 

2.4.2 The Binomial Theorem

The binomial theorem gives us a formula for expanding (x + y)n, where n
is a nonnegative integer. The coefficients of this expansion are precisely the
binomial coefficients that we have used to count combinations. Using high
school algebra we can expand the expression for integers from 0 to 5:

                  n                (x + y)n

                  0                      1

                  1                      x+y

                  2                x2 + 2xy + y2

                  3             x3 + 3x2y + 3xy2 + y3

                  4     x4 + 4x3y + 6x2y2 + 4xy3 + y4

                  5 x5 + 5x4y + 10x3y2 + 10x2y3 + 5xy4 + y5

    In the expansion of (x + y)5 we note that the coefficient of the third term is

5   = 10, and that of the sixth term is  5  = 1. We can rewrite the expansion
3                                        5
as

    5 x5 + 5 x4y + 5 x3y2 + 5 x2y3 + 5 xy4 + 5 y5.
    0                1          2           3          4     5

    In summary, in the expansion of (x + y)n we note:

(a) The first term is xn and the last term is yn.

(b) With each successive term, exponents of x decrease by 1 as those of y
     increase by 1. For any term the sum of the exponents is n.
CHAPTER 2. COMBINATORICS                                                       36

(c) The coefficient of xn-kyk is kn .

(d) The triangular array of binomial coefficients is called Pascal's triangle
     after the seventeenth-century French mathematician Blaise Pascal. Note
     that each number in the triangle other than the 1's at the ends of each
     row is the sum of the two numbers to the right and left of it in the row
     above.

Theorem 2.4.9 The Binomial Theorem. If n  0, and x and y are

numbers, then

                         (x + y)n =  n

                                          n n-k k
                                            x y.
                                     k=0 k

Proof. This theorem will be proven using a logical procedure called mathemat-

ical induction, which will be introduced in Chapter 3.                         

Example 2.4.10 Identifying a term in an expansion. Find the third

term in the expansion of (x - y)4 = (x + (-y))4. The third term, when k = 2,
is 42 x4-2(-y)2 = 6x2y2. 

Example 2.4.11 A Binomial Expansion. Expand (3x - 2)3. If we replace
x and y in the Binomial Theorem with 3x and -2, respectively, we get

33          n-k       k  3  3          0    3      2    1       3         1    2   3  0  3
     k (3x) (-2) = 0 (3x) (-2) + 1 (3x) (-2) + 2 (3x) (-2) + 3 (3x) (-2) .
k=0

                         = 27x3 - 54x2 + 36x - 8

                                                                               

2.4.3 SageMath Note

A bridge hand is a 13 element subset of a standard 52 card deck. The order

in which the cards come to the player doesn't matter. From the point of view

of a single player, the number of possible bridge hands is  52  ,  which  can  be
                                                            13
easily computed with Sage.

binomial (52 ,13)

635013559600

     In bridge, the location of a hand in relation to the dealer has some bearing

on the game. An even truer indication of the number of possible hands takes

into account each player's possible hand. It is customary to refer to bridge

positions as West, North, East and South. We can apply the rule of product

to get the total number of bridge hands with the following logic. West can get

any of the  52  hands identified above. Then North get 13 of the remaining 39
            13
                  39
cards and so has  13     possible hands. East then gets 13 of the 26 remaining

cards, which has  26     possibilities. South gets the remaining cards. Therefore
                  13
the number of bridge hands is computed using the Product Rule.

binomial (52 ,13) * binomial (39 ,13) * binomial (26 ,13)

53644737765488792839237440000
CHAPTER 2. COMBINATORICS  37

2.4.4 Exercises

1. The judiciary committee at a college is made up of three faculty members
      and four students. If ten faculty members and 25 students have been
      nominated for the committee, how many judiciary committees could be
      formed at this point?

2. Suppose that a single character is stored in a computer using eight bits.
           a. How many bit patterns have exactly three 1's?
           b. How many bit patterns have at least two 1's?

      Hint. Think of the set of positions that contain a 1 to turn this is into
      a question about sets.

3. How many subsets of {1, 2, 3, . . . , 10} contain at least seven elements?

4. The congressional committees on mathematics and computer science are
      made up of five representatives each, and a congressional rule is that the
      two committees must be disjoint. If there are 385 members of congress,
      how many ways could the committees be selected?

5. The image below shows a 6 by 6 grid and an example of a lattice path
      that could be taken from (0, 0) to (6, 6), which is a path taken by traveling
      along grid lines going only to the right and up. How many different lattice
      paths are there of this type? Generalize to the case of lattice paths from
      (0, 0) to (m, n) for any nonnegative integers m and n.

      Figure 2.4.12 A lattice path

      Hint. Think of each path as a sequence of instructions to go right (R)
      and up (U).
6.

        (a) How many of the lattice paths from (0, 0) to (6, 6) pass through (3, 3)
              as the one in Figure 12 does?

        (b) How many the paths pass through (2, 3) but not necessarily (3, 3)?

         (c) How many the paths pass through (2, 3) and avoid (3, 3)?
7. A poker game is played with 52 cards. At the start of a game, each player

      gets five of the cards. The order in which cards are dealt doesn't matter.

        (a) How many "hands" of five cards are possible?

        (b) If there are four people playing, how many initial five-card "hands"
              are possible, taking into account all players and their positions at
CHAPTER 2. COMBINATORICS          38

              the table? Position with respect to the dealer does matter.

8. A flush in a five-card poker hand is five cards of the same suit. The
      suits are spades, clubs, diamonds and hearts. How many spade flushes
      are possible in a 52-card deck? How many flushes are possible in any
      suit?

9. How many five-card poker hands using 52 cards contain exactly two aces?

10. In poker, a full house is three-of-a-kind and a pair in one hand; for
      example, three fives and two queens. How many full houses are possible
      from a 52-card deck? You can use the sage cell in the SageMath Note
      to do this calculation, but also write your answer in terms of binomial
      coefficients.

11. A class of twelve computer science students are to be divided into three
      groups of 3, 4, and 5 students to work on a project. How many ways can
      this be done if every student is to be in exactly one group?

12. Explain in words why the following equalities are true based on number
      of subsets, and then verify the equalities using the formula for binomial
      coefficients.

        (a) n = n
                1

        (b) kn = n-k n , 0  k  n.
13. There are ten points, P1, P2, . . . , P10 on a plane, no three on the same

      line.

        (a) How many lines are determined by the points?

        (b) How many triangles are determined by the points?

14. How many ways can n persons be grouped into pairs when n is even?
      Assume the order of the pairs matters, but not the order within the pairs.
      For example, if n = 4, the six different groupings would be

{1, 2}                    {3, 4}
{1, 3}                    {2, 4}
{1, 4}                    {2, 3}
{2, 3}                    {1, 4}
{2, 4}                    {1, 3}
{3, 4}                    {1, 2}

15. Use the binomial theorem to prove that if A is a finite set, then |P (A)| =
      2|A|

16.

(a) A state's lottery involves choosing six different numbers out of a
     possible 36. How many ways can a person choose six numbers?

        (b) What is the probability of a person winning with one bet?

17. Use the binomial theorem to calculate 99983.

      Hint. 9998 = 10000 - 2
18. In the card game Blackjack, there are one or more players and a dealer.

      Initially, each player is dealt two cards and the dealer is dealt one card
      down and one facing up. As in bridge, the order of the hands, but not
      the order of the cards in the hands, matters. Starting with a single 52
      card deck, and three players, how many ways can the first two cards be
CHAPTER 2. COMBINATORICS  39

dealt out? You can use the sage cell in the SageMath Note to do this
calculation.
Chapter 3

Logic

                                  formal logic

                          You can write any letters you choose;
                         Formal logic, though, likes p's and q's

                                To form statements -- a lot,
                                Using IF, OR, AND, NOT --
                             To determine the falses and trues.

          Goldie, The Omnificent English Dictionary In Limerick Form

In this chapter, we will introduce some of the basic concepts of mathematical
logic. In order to fully understand some of the later concepts in this book, you
must be able to recognize valid logical arguments. Although these arguments
will usually be applied to mathematics, they employ the same techniques that
are used by a lawyer in a courtroom or a physician examining a patient. An
added reason for the importance of this chapter is that the circuits that make
up digital computers are designed using the same algebra of propositions that
we will be discussing.

3.1 Propositions and Logical Operators

3.1.1 Propositions

Definition 3.1.1 Proposition. A proposition is a sentence to which one

and only one of the terms true or false can be meaningfully applied.  

Example 3.1.2 Some Propositions. "Four is even,", "4  {1, 3, 5}" and

"43 > 21" are propositions.                                           

In traditional logic, a declarative statement with a definite truth value is

considered a proposition. Although our ultimate aim is to discuss mathemat-

ical logic, we won't separate ourselves completely from the traditional setting.

This is natural because the basic assumptions, or postulates, of mathemati-

cal logic are modeled after the logic we use in everyday life. Since compound

sentences are frequently used in everyday speech, we expect that logical propo-

sitions contain connectives like the word "and." The statement "Europa sup-

ports life or Mars supports life" is a proposition and, hence, must have a definite

truth value. Whatever that truth value is, it should be the same as the truth

value of "Mars supports life or Europa supports life."

                             40
CHAPTER 3. LOGIC         41

3.1.2 Logical Operations

There are several ways in which we commonly combine simple statements into
compound ones. The words/phrases and, or, not, if ... then..., and ...if and
only if ... can be added to one or more propositions to create a new proposi-
tion. To avoid any confusion, we will precisely define each one's meaning and
introduce its standard symbol. With the exception of negation (not), all of
the operations act on pairs of propositions. Since each proposition has two
possible truth values, there are four ways that truth can be assigned to two
propositions. In defining the effect that a logical operation has on two propo-
sitions, the result must be specified for all four cases. The most convenient
way of doing this is with a truth table, which we will illustrate by defining the
word and.

Definition 3.1.3 Logical Conjunction. If p and q are propositions, their
conjunction, p and q (denoted p  q), is defined by the truth table

                                            p q pq
                                            00 0
                                            01 0
                                            10 0
                                            11 1

                                                                                                     
    Notes:

  (a) The numbers 0 and 1 are used to denote false and true, respectively.
       This is consistent with the way that many programming languages treat
       logical, or Boolean, variables since a single bit, 0 or 1, can represent a
       truth value. Many people use either False/True or F/T instead of 0/1 in
       truth table. Although 0/1 usage seems to be in the minority, we prefer
       to use it in order make a connection with the binary representation of
       numbers, as pointed out below.

       One notable case where False/True notation is used is in Sage, as can be
       seen in the following Sage cell. Notice that Sage uses an ampersand for
       the conjunction symbol.

          r = propcalc.formula( 'p & q ')
          r. truthtable ()

p      q          value
False  False      False
False  True       False
True   False      False
True   True       True

(b) To read this truth table, you must realize that any one line represents a
     case: one possible set of truth values for p and q.

(c) For each case, the symbol under p represents the truth value of p. The
     same is true for q. The symbol under p  q represents its truth value for
     that case. For example, the second row of the truth table represents the
     case in which p is false, q is true, and the resulting truth value for p  q
     is false. As in everyday speech, p  q is true only when both propositions
     are true.
CHAPTER 3. LOGIC  42

  (d) Just as the letters x, y and z are frequently used in algebra to represent
       numeric variables, p, q and r seem to be the most commonly used symbols
       for logical variables. When we say that p is a logical variable, we mean
       that any proposition can take the place of p.

  (e) One final comment: The order in which we list the cases in a truth table
       is standardized in this book. If the truth table involves two simple propo-
       sitions, the numbers under the simple propositions can be interpreted as
       the two-digit binary integers in increasing order, 00, 01, 10, and 11, for
       0, 1, 2, and 3, respectively.

Definition 3.1.4 Logical Disjunction. If p and q are propositions, their
disjunction, p or q (denoted p  q), is defined by the truth table

                                            p q pq
                                            00 0
                                            01 1
                                            10 1
                                            11 1

                                                                                                     
Definition 3.1.5 Logical Negation. If p is a proposition, its negation,
not p, denoted ¬p, and is defined by the truth table

                                               p ¬p
                                               01
                                               10

                                                                                                     
Note: Negation is the only standard operator that acts on a single proposition;
hence only two cases are needed.

    Consider the following propositions from everyday speech:

  (a) I'm going to quit if I don't get a raise.

  (b) If I pass the final, then I'll graduate.

  (c) I'll be going to the movies provided that my car starts.

    All three propositions are conditional, they can all be restated to fit into
the form "If Condition, then Conclusion." For example, the first statement can
be rewritten as "If I don't get a raise, then I'm going to quit."

    A conditional statement is meant to be interpreted as a guarantee; if the
condition is true, then the conclusion is expected to be true. It says no more
and no less.
Definition 3.1.6 Conditional Statement. The conditional statement "If
p then q," denoted p  q, is defined by the truth table

Table 3.1.7 Truth Table for p  q

                                          p q pq
                                          00 1
                                          01 1
                                          10 0
                                          11 1

                                                                                                     
CHAPTER 3. LOGIC                                                          43

Example 3.1.8 Analysis of a Conditional Proposition. Assume your

instructor told you "If you receive a grade of 95 or better in the final exami-

nation, then you will receive an A in this course." Your instructor has made a

promise to you. If you fulfill his condition, you expect the conclusion (getting

an A) to be forthcoming. Suppose your graded final has been returned to you.

Has your instructor told the truth or is your instructor guilty of a falsehood?

Case I: Your final exam score was less than 95 (the condition is false) and

you did not receive an A (the conclusion is false). The instructor told the truth.

Case II: Your final exam score was less than 95, yet you received an A for

the course. The instructor told the truth. (Perhaps your overall course average

was excellent.)

Case III: Your final exam score was greater than 95, but you did not receive

an A. The instructor lied.

Case IV: Your final exam score was greater than 95, and you received an

A. The instructor told the truth.

To sum up, the only case in which a conditional proposition is false is when

the condition is true and the conclusion is false.                        

The order of the condition and conclusion in a conditional proposition is im-

portant. If the condition and conclusion are exchanged, a different proposition

is produced.

Definition 3.1.9 Converse. The converse of the proposition p  q is the

proposition q  p.                                                         

The converse of "If you receive a grade of 95 or better in the final exam,

then you will receive an A in this course," is "If you receive an A in this course,

then you received a grade of 95 or better in the final exam." It should be clear

that these two statements say different things.

There is a proposition related to p  q that does have the same logical

meaning. This is the contrapositive.

Definition 3.1.10 Contrapositive. The contrapositive of the proposition

p  q is the proposition ¬q  ¬p.                                           

As we will see when we discuss logical proofs, we can prove a conditional

proposition by proving its contrapositive, which may be somewhat easier.

Finally, there is a third variation on the proposition p  q, the inverse,

which we will see that has the same logical meaning as the converse.

Definition 3.1.11 Logical Inverse. The inverse of the proposition p  q

is the proposition ¬p  ¬q.                                                

The inverse of "If it snows today, we have a day off." would be "If it doesn't

snow today, we don't have a day off." Can you see that the original proposition

and the inverse are saying different things?

Our final logical operator is a conjunction of two conditionals

Definition 3.1.12 Biconditional Proposition. If p and q are propositions,
the biconditional statement "p if and only if q," denoted p  q, is defined by
the truth table

                                           p q pq

                                           00 1

                                           01 0

                                           10 0

                                           11 1

                                                                                                     
    Note that p  q is true when p and q have the same truth values. It is

common to abbreviate "if and only if" to "iff."
CHAPTER 3. LOGIC  44

    Although "if ... then..." and "...if and only if ..." are frequently used in
everyday speech, there are several alternate forms that you should be aware of.
They are summarized in the following lists.

    All of the following are equivalent to "If p then q":

   · p implies q.
   · q follows from p.
   · p, only if q.
   · q, if p.
   · p is sufficient for q.
   · q is necessary for p.

    All of the following are equivalent to "p if and only if q":

   · p is necessary and sufficient for q.
   · p is equivalent to q.
   · If p, then q, and if q, then p.
   · If p, then q and conversely.

3.1.3 Exercises

1. Let d = "I like discrete structures", c = "I will pass this course" and s =
      "I will do my assignments." Express each of the following propositions in
      symbolic form:

        (a) I like discrete structures and I will pass this course.

        (b) I will do my assignments or I will not pass this course.

         (c) It is not true that I both like discrete structures, and will do my
              assignments.

        (d) I will not do my assignment and I will not pass this course.
2. For each of the following propositions, identify simple propositions, ex-

      press the compound proposition in symbolic form, and determine whether
      it is true or false:

        (a) The world is flat or zero is an even integer.

        (b) If 432,802 is a multiple of 4, then 432,802 is even.

         (c) 5 is a prime number and 6 is not divisible by 4.

        (d) 3  Z and 3  Q.
         (e) 2/3  Z and 2/3  Q.
         (f) The sum of two even integers is even and the sum of two odd integers

              is odd.
3. Let p ="2  5", q = "8 is an even integer," and r = "11 is a prime

      number." Express the following as a statement in English and determine
      whether the statement is true or false:
CHAPTER 3. LOGIC                             45

(a) ¬p  q            (d) p  (q  (¬r))

(b) p  q             (e) p  ((¬q)  (¬r))

(c) (p  q)  r        (f) (¬q)  (¬p)

4. Rewrite each of the following statements using the other conditional

forms:

        (a) It is sufficient for an integer to be even that it is a multiple of four.

        (b) The fact that a polygon is a square is a sufficient condition that it
              is a rectangle.

         (c) If x = 5, then x2 = 25.

        (d) If x2 - 5x + 6 = 0, then x = 2 or x = 3.

         (e) x2 = y2 is a necessary condition for x = y.
5. Write the converse of the propositions in exercise 4. Compare the truth

      of each proposition and its converse.

3.2 Truth Tables and Propositions Generated by
     a Set

3.2.1 Truth Tables

Consider the compound proposition c = (p  q)  (¬q  r), where p, q, and
r are propositions. This is an example of a proposition generated by p, q,
and r. We will define this terminology later in the section. Since each of the
three simple propositions has two possible truth values, it follows that there
are eight different combinations of truth values that determine a value for c.
These values can be obtained from a truth table for c. To construct the truth
table, we build c from p, q, and r and from the logical operators. The result
is the truth table below. Strictly speaking, the first three columns and the
last column make up the truth table for c. The other columns are work space
needed to build up to c.

Table 3.2.1 Truth Table for c = (p  q)  (¬q  r)

        p q r p  q ¬q ¬q  r (p  q)  (¬q  r)

        000 0 1   0  0

        001 0 1   1  1

        010 0 0   0  0

        011 0 0   0  0

        100 0 1   0  0

        101 0 1   1  1

        110 1 0   0  1

        111 1 0   0  1

    Note that the first three columns of the truth table are an enumeration
of the eight three-digit binary integers. This standardizes the order in which
the cases are listed. In general, if c is generated by n simple propositions,
then the truth table for c will have 2n rows with the first n columns being an
enumeration of the n digit binary integers. In our example, we can see at a
glance that for exactly four of the eight cases, c will be true. For example, if p
CHAPTER 3. LOGIC  46

and r are true and q is false (the sixth case), then c is true.
    Let S be any set of propositions. We will give two definitions of a propo-

sition generated by S. The first is a bit imprecise, but should be clear. The
second definition is called a recursive definition. If you find it confusing, use
the first definition and return to the second later.

3.2.2 Propositions Generated by a Set

Definition 3.2.2 Proposition Generated by a Set. Let S be any set
of propositions. A proposition generated by S is any valid combination of
propositions in S with conjunction, disjunction, and negation. Or, to be more
precise,

  (a) If p  S, then p is a proposition generated by S, and

  (b) If x and y are propositions generated by S, then so are (x), ¬x, x  y ,
       and x  y.

                                                                                                     
    Note: We have not included the conditional and biconditional in the defi-
nition because they can both be generated from conjunction, disjunction, and
negation, as we will see later.
    If S is a finite set, then we may use slightly different terminology. For
example, if S = {p, q, r}, we might say that a proposition is generated by p, q,
and r instead of from {p, q, r}.
    It is customary to use the following hierarchy for interpreting propositions,
with parentheses overriding this order:

   · First: Negation

   · Second: Conjunction

   · Third: Disjunction

   · Fourth: The conditional operation

   · Fifth: The biconditional operation

    Within any level of the hierarchy, work from left to right. Using these rules,
p  q  r is taken to mean (p  q)  r. These precedence rules are universal, and
are exactly those used by computer languages to interpret logical expressions.
Example 3.2.3 Examples of the Hierarchy of Logical Operations. A
few shortened expressions and their fully parenthesized versions:

  (a) p  q  r is (p  q)  r.

  (b) ¬p  ¬r is (¬p)  (¬r).

  (c) ¬¬p is ¬(¬p).

  (d) p  q  r  s is p  ((q  r)  s).

                                                                                                    
    A proposition generated by a set S need not include each element of S in
its expression. For example, ¬q  r is a proposition generated by p, q, and r.
CHAPTER 3. LOGIC                                                          47

3.2.3 SageMath Truth Tables

Truth tables can be generated using SageMath. Note the use of the alternate
notation False/True instead of 0/1. Here is the truth table for p  (¬q  r)

 x = propcalc.formula("p | (~q & r)")
 x. truthtable ()

p      q      r      value
False  False  False  False
False  False  True   True
False  True   False  False
False  True   True   False
True   False  False  True
True   False  True   True
True   True   False  True
True   True   True   True

3.2.4 Exercises

1. Construct the truth tables of:

        (a) p  p                        (c) p  (¬p)
                                        (d) p  p
        (b) p  (¬p)
2. Construct the truth tables of:

(a) ¬(p  q)                             (d) (p  q)  (q  r)  (r  p)

(b) p  (¬q)                             (e) ¬p  ¬q

(c) (p  q)  r                           (f) p  q  r  s

3. Rewrite the following with as few extraneous parentheses as possible:

(a) (¬((p)  (r)))  (s)                  (b) ((p)  (q))  ((r)  (q))

4. In what order are the operations in the following propositions performed?

(a) p  ¬q  r  ¬p                        (b) p  ¬q  r  ¬p

5. Determine the number of rows in the truth table of a proposition con-

taining four variables p, q, r, and s.

6. If there are 45 lines on a sheet of paper, and you want to reserve one line
      for each line in a truth table, how large could |S| be if you can write truth
      tables of propositions generated by S on the sheet of paper?

3.3 Equivalence and Implication

Consider two propositions generated by p and q: ¬(p  q) and ¬p  ¬q. At first
glance, they are different propositions. In form, they are different, but they
have the same meaning. One way to see this is to substitute actual propositions
for p and q; such as p: I've been to Toronto; and q: I've been to Chicago.

    Then ¬(p  q) translates to "I haven't been to both Toronto and Chicago,"
while ¬p  ¬q is "I haven't been to Toronto or I haven't been to Chicago."
Determine the truth values of these propositions. Naturally, they will be true
for some people and false for others. What is important is that no matter
what truth values they have, ¬(p  q) and ¬p  ¬q will have the same truth
CHAPTER 3. LOGIC                                             48

value. The easiest way to see this is by examining the truth tables of these
propositions.

Table 3.3.1 Truth Tables for ¬(p  q) and ¬p  ¬q

                         p q ¬(p  q) ¬p  ¬q

                         00  1  1

                         01  1  1

                         10  1  1

                         11  0  0

    In all four cases, ¬(p  q) and ¬p  ¬q have the same truth value. Further-
more, when the biconditional operator is applied to them, the result is a value
of true in all cases. A proposition such as this is called a tautology.

3.3.1 Tautologies and Contradictions

Definition 3.3.2 Tautology. An expression involving logical variables that
is true in all cases is a tautology. The number 1 is used to symbolize a tautology.

                                                                                                     
Example 3.3.3 Some Tautologies. All of the following are tautologies
because their truth tables consist of a column of 1's.

(a) (¬(p  q))  (¬p  ¬q).
(b) p  ¬p
(c) (p  q)  p
(d) q  (p  q)
(e) (p  q)  (q  p)

                                                                      

Definition 3.3.4 Contradiction. An expression involving logical variables

that is false for all cases is called a contradiction. The number 0 is used to

symbolize a contradiction.                                            

Example 3.3.5 Some Contradictions. p  ¬p and (p  q)  (¬p)  (¬q) are

contradictions.                                                       

3.3.2 Equivalence

Definition 3.3.6 Equivalence. Let S be a set of propositions and let r and

s be propositions generated by S. r and s are equivalent if and only if r  s

is a tautology. The equivalence of r and s is denoted r  s.           

Equivalence is to logic as equality is to algebra. Just as there are many ways

of writing an algebraic expression, the same logical meaning can be expressed

in many different ways.

Example 3.3.7 Some Equivalences. The following are all equivalences:

(a) (p  q)  (¬p  q)  q.

(b) p  q  ¬q  ¬p

(c) p  q  q  p.

                                                                      
CHAPTER 3. LOGIC                                         49

All tautologies are equivalent to one another.

Example 3.3.8 An equivalence to 1. p  ¬p  1.             

All contradictions are equivalent to one another.

Example 3.3.9 An equivalence to 0. p  ¬p  0.             

3.3.3 Implication

Consider the two propositions:

Table 3.3.10

                   x: The money is behind Door A; and
               y: The money is behind Door A or Door B.

    Imagine that you were told that there is a large sum of money behind one
of two doors marked A and B, and that one of the two propositions x and y
is true and the other is false. Which door would you choose? All that you
need to realize is that if x is true, then y will also be true. Since we know that
this can't be the case, y must be the true proposition and the money is behind
Door B.

    This is an example of a situation in which the truth of one proposition leads
to the truth of another. Certainly, y can be true when x is false; but x can't
be true when y is false. In this case, we say that x implies y.

    Consider the truth table of p  q, Table 3.1.7. If p implies q, then the third
case can be ruled out, since it is the case that makes a conditional proposition
false.

Definition 3.3.11 Implication. Let S be a set of propositions and let r

and s be propositions generated by S. We say that r implies s if r  s is a

tautology. We write r  s to indicate this implication.   

Example 3.3.12 Disjunctive Addition. A commonly used implication

called "disjunctive addition" is p  (p  q), which is verified by truth table

Table 3.3.13.                                            

Table 3.3.13 Truth Table to verify that p  (p  q)

                   p q pq ppq

                   00 0         1

                   01 1         1

                   10 1         1

                   11 1         1

    If we let p represent "The money is behind Door A" and q represent "The
money is behind Door B," p  (p  q) is a formalized version of the reasoning
used in Example 3.3.12. A common name for this implication is disjunctive
addition. In the next section we will consider some of the most commonly used
implications and equivalences.

    When we defined what we mean by a Proposition Generated by a Set, we
didn't include the conditional and biconditional operators. This was because of
the two equivalences p  q  ¬pq and p  q  (pq)(¬p¬q). Therefore,
any proposition that includes the conditional or biconditional operators can be
written in an equivalent way using only conjunction, disjunction, and negation.
We could even dispense with disjunction since pq is equivalent to a proposition
that uses only conjunction and negation.
CHAPTER 3. LOGIC                                                   50

3.3.4 A Universal Operation

We close this section with a final logical operation, the Sheffer Stroke, that has
the interesting property that all other logical operations can be created from
it. You can explore this operation in Exercise 3.3.5.8

Definition 3.3.14 The Sheffer Stroke. The Sheffer Stroke is the logical
operator defined by the following truth table:

Table 3.3.15 Truth Table for the Sheffer Stroke

                                           p q p|q
                                           00 1
                                           01 1
                                           10 1
                                           11 0

                                                                                                     

3.3.5 Exercises

1. Given the following propositions generated by p, q, and r, which are
      equivalent to one another?

(a) (p  r)  q      (e) (p  q)  (r  q)

(b) p  (r  q)      (f) r  p

(c) r  p           (g) r  ¬p

        (d) ¬r  p  (h) p  r
2.

(a) Construct the truth table for x = (p  ¬q)  (r  p).

(b) Give an example other than x itself of a proposition generated by p,
     q, and r that is equivalent to x.

(c) Give an example of a proposition other than x that implies x.

        (d) Give an example of a proposition other than x that is implied by x.

3. Is an implication equivalent to its converse? Verify your answer using a
      truth table.

4. Suppose that x is a proposition generated by p, q, and r that is equivalent
      to p  ¬q. Write out the truth table for x.

5. How large is the largest set of propositions generated by p and q with the
      property that no two elements are equivalent?

6. Find a proposition that is equivalent to p  q and uses only conjunction
      and negation.

7. Explain why a contradiction implies any proposition and any proposition
      implies a tautology.

8. The significance of the Sheffer Stroke is that it is a "universal" operation
      in that all other logical operations can be built from it.

        (a) Prove that p|q is equivalent to ¬(p  q).

        (b) Prove that ¬p  p|p.

         (c) Build  using only the Sheffer Stroke.
CHAPTER 3. LOGIC                      51

        (d) Build  using only the Sheffer Stroke.

9. Are the converse and inverse of a conditional proposition equivalent?
      Verify your answer using a truth table.

3.4 The Laws of Logic

3.4.1

In this section, we will list the most basic equivalences and implications of
logic. Most of the equivalences listed in Table Table 3.4.3 should be obvious
to the reader. Remember, 0 stands for contradiction, 1 for tautology. Many
logical laws are similar to algebraic laws. For example, there is a logical law
corresponding to the associative law of addition, a + (b + c) = (a + b) + c. In
fact, associativity of both conjunction and disjunction are among the laws of
logic. Notice that with one exception, the laws are paired in such a way that
exchanging the symbols , , 1 and 0 for , , 0, and 1, respectively, in any
law gives you a second law. For example, p  0  p results in p  1  p. This is
called a duality principle. For now, think of it as a way of remembering two laws
for the price of one. We will leave it to the reader to verify a few of these laws
with truth tables. However, the reader should be careful in applying duality
to the conditional operator and implication since the dual involves taking the
converse. For example, the dual of p  q  p is p  q  p, which is usually
written p  p  q.

Example 3.4.1 Verification of an Identity Law. The Identity Law can
be verified with this truth table. The fact that (p  1)  p is a tautology serves
as a valid proof.

Table 3.4.2 Truth table to demonstrate the identity law for conjunc-
tion.

                  p 1 p  1 (p  1)  p

                  01 0  1

                  11 1  1

                                                                                                     
    Some of the logical laws in Table Table 3.4.4 might be less obvious to you.
For any that you are not comfortable with, substitute actual propositions for
the logical variables. For example, if p is "John owns a pet store" and q is
"John likes pets," the detachment law should make sense.
CHAPTER 3. LOGIC                               52

Table 3.4.3 Basic Logical Laws - Equivalences

          pq  qp           Commutative Laws              pq  qp
   (p  q)  r  p  (q  r)     Associative Laws      (p  q)  r  p  (q  r)
p  (q  r)  (p  q)  (p  r)   Distributive Laws  p  (q  r)  (p  q)  (p  r)
                              Identity Laws
             p0p              Negation Laws                 p1p
            p  ¬p  0        Idempotent Laws                p  ¬p  1
             ppp                 Null Laws                  ppp
             p00            Absorption Laws                 p11
         p  (p  q)  p       DeMorgan's Laws             p  (p  q)  p
    ¬(p  q)  (¬p)  (¬q)      Involution Law        ¬(p  q)  (¬p)  (¬q)
                                ¬(¬p)  p

Table 3.4.4 Basic Logical Laws - Common Implications and Equiva-
lences

    Detachment (AKA Modus Ponens)                              (p  q)  p  q
Indirect Reasoning (AKA Modus Tollens)                       (p  q)  ¬q  ¬p

             Disjunctive Addition                                 p  (p  q)
          Conjunctive Simplification                   (p  q)  p and (p  q)  q
          Disjunctive Simplification            (p  q)  ¬p  q and (p  q)  ¬q  p
                                                      (p  q)  (q  r)  (p  r)
                    Chain Rule
           Conditional Equivalence                             p  q  ¬p  q
         Biconditional Equivalences     (p  q)  (p  q)  (q  p)  (p  q)  (¬p  ¬q)

                  Contrapositive                           (p  q)  (¬q  ¬p)

3.4.2 Exercises

1. Write the following in symbolic notation and determine whether it is a
      tautology: "If I study then I will learn. I will not learn. Therefore, I do
      not study."

2. Show that the common fallacy (p  q)  ¬p  ¬q is not a law of logic.
3. Describe, in general, how duality can be applied to implications if we

      introduce the relation , read "is implied by." We define this relation by

                                          (p  q)  (q  p).
4. Write the dual of the following statements:

        (a) (p  q)  p

        (b) (p  q)  ¬q  p
CHAPTER 3. LOGIC                                          53

3.5 Mathematical Systems and Proofs

3.5.1 Mathematical Systems

In this section, we present an overview of what a mathematical system is and
how logic plays an important role in one. The axiomatic method that we
will use here will not be duplicated with as much formality anywhere else in
the book, but we hope an emphasis on how mathematical facts are developed
and organized will help to unify the concepts we will present. The system of
propositions and logical operators we have developed will serve as a model for
our discussion. Roughly, a mathematical system can be defined as follows.

Definition 3.5.1 Mathematical System. A mathematical system consists
of:

(1) A set or universe, U .

(2) Definitions: sentences that explain the meaning of concepts that relate to
     the universe. Any term used in describing the universe itself is said to be
     undefined. All definitions are given in terms of these undefined concepts
     of objects.

(3) Axioms: assertions about the properties of the universe and rules for
     creating and justifying more assertions. These rules always include the
     system of logic that we have developed to this point.

(4) Theorems: the additional assertions mentioned above.

                                                          

Example 3.5.2 Euclidean Geometry. In Euclidean geometry the universe

consists of points and lines (two undefined terms). Among the definitions is a

definition of parallel lines and among the axioms is the axiom that two distinct

parallel lines never meet.                                

Example 3.5.3 Propositional Calculus. Propositional calculus is a formal

name for the logical system that we've been discussing. The universe consists of

propositions. The axioms are the truth tables for the logical operators and the

key definitions are those of equivalence and implication. We use propositions

to describe any other mathematical system; therefore, this is the minimum

amount of structure that a mathematical system can have.  

Definition 3.5.4 Theorem. A true proposition derived from the axioms of

a mathematical system is called a theorem.                

Theorems are normally expressed in terms of a finite number of propositions,

p1, p2, ..., pn , called the premises, and a proposition,C, called the conclusion.

These theorems take the form

                            p1  p2  · · ·  pn  C

or more informally,

                            p1, p2, ..., and pn imply C

For a theorem of this type, we say that the premises imply the conclusion.
When a theorem is stated, it is assumed that the axioms of the system are true.
In addition, any previously proven theorem can be considered an extension
of the axioms and can be used in demonstrating that the new theorem is
true. When the proof is complete, the new theorem can be used to prove
subsequent theorems. A mathematical system can be visualized as an inverted
CHAPTER 3. LOGIC                                             54

pyramid with the axioms at the base and the theorems expanding out in various
directions.

Figure 3.5.5 The body of knowledge in a mathematical system

Definition 3.5.6 Proof. A proof of a theorem is a finite sequence of log-

ically valid steps that demonstrate that the premises of a theorem imply its

conclusion.                                                  

Exactly what constitutes a proof is not always clear. For example, a re-

search mathematician might require only a few steps to prove a theorem to a

collegue, but might take an hour to give an effective proof to a class of students.

Therefore, what constitutes a proof often depends on the audience. But the

audience is not the only factor. One of the most famous theorems in graph

theory, The Four-Color Theorem, was proven in 1976, after over a century

of effort by many mathematicians. Part of the proof consisted of having a

computer check many different graphs for a certain property. Without the aid

of the computer, this checking would have taken years. In the eyes of some

mathematicians, this proof was considered questionable. Shorter proofs have

been developed since 1976 and there is no controversy associated with The

Four Color Theorem at this time.

3.5.2 Direct Proof

Theoretically, you can prove anything in propositional calculus with truth ta-
bles. In fact, the laws of logic stated in Section 3.4 are all theorems. Propo-
sitional calculus is one of the few mathematical systems for which any valid
sentence can be determined true or false by mechanical means. A program
to write truth tables is not too difficult to write; however, what can be done
theoretically is not always practical. For example,

                                a, a  b, b  c, ..., y  z  z

is a theorem in propositional calculus. However, suppose that you wrote such
a program and you had it write the truth table for

                       (a  (a  b)  (b  c)  · · ·  (y  z))  z

The truth table will have 226 cases. At one million cases per second, it would
take approximately one hour to verify the theorem. Now if you decided to
check a similar theorem,

                            p1, p1  p2, . . . , p99  p100  p100
CHAPTER 3. LOGIC                                            55

you would really have time trouble. There would be 2100  1.26765 × 1030
cases to check in the truth table. At one million cases per second it would
take approximately 1.46719 × 1019 days to check all cases. For most of the
remainder of this section, we will discuss an alternate method for proving
theorems in propositional calculus. It is the same method that we will use
in a less formal way for proofs in other systems. Formal axiomatic methods
would be too unwieldy to actually use in later sections. However, none of the
theorems in later chapters would be stated if they couldn't be proven by the
axiomatic method.

    We will introduce two types of proof here, direct and indirect.

Example 3.5.7 A typical direct proof. This is a theorem: p  r, q 
s, p  q  s  r. A direct proof of this theorem is:

Table 3.5.8 Direct proof of p  r, q  s, p  q  s  r

Step Proposition         Justification

1.                pq     Premise

2.                ¬p  q  (1), conditional rule

3.                qs     Premise

4.                ¬p  s  (2), (3), chain rule

5.                ¬s  p  (4), contrapositive

6.                pr     Premise

7.                ¬s  r  (5), (6), chain rule

8.                sr     (7), conditional rule 

                                                                                                    
    Note that  marks the end of a proof.
    Example 3.5.7 illustrates the usual method of formal proof in a formal
mathematical system. The rules governing these proofs are:

(1) A proof must end in a finite number of steps.

(2) Each step must be either a premise or a proposition that is implied from
     previous steps using any valid equivalence or implication.

(3) For a direct proof, the last step must be the conclusion of the theorem.
     For an indirect proof (see below), the last step must be a contradiction.

(4) Justification Column. The column labeled "justification" is analogous
     to the comments that appear in most good computer programs. They
     simply make the proof more readable.

Example 3.5.9 Two proofs of the same theorem. Here are two direct
proofs of ¬p  q, s  p, ¬q  s:

Table 3.5.10 Direct proof of ¬p  q, s  p, ¬q  s

1. ¬p  q                 Premise

2. ¬q                    Premise

3. ¬p             Disjunctive simplification, (1), (2)

4. s  p                  Premise

5. s Disjunctive simplification, (3), (4). 

You are invited to justify the steps in this second proof:
CHAPTER 3. LOGIC                                                56

Table 3.5.11 Alternate proof of ¬p  q, s  p, ¬q  s

                  1. ¬p  q

                  2. ¬q  ¬p

                  3. s  p

                  4. p  s

                  5. ¬p  s

                  6. ¬q  s

                  7.  ¬q

                  8. s 

                                                                                                    
The conclusion of a theorem is often a conditional proposition. The condition
of the conclusion can be included as a premise in the proof of the theorem. The
object of the proof is then to prove the consequence of the conclusion. This
rule is justified by the logical law

                  p  (h  c)  (p  h)  c

Example 3.5.12 Example of a proof with a conditional conclusion.
The following proof of p  (q  s), ¬r  p, q  r  s includes r as a fourth
premise. Inference of truth of s completes the proof.

Table 3.5.13 Proof of a theorem with a conditional conclusion.

1. ¬r  p                    Premise

2.  r                 Added premise

3.  p             (1), (2), disjunction simplification

4. p  (q  s)                Premise

5.  qs                (3), (4), detachment

6.  q                       Premise

7.  s                 (5), (6), detachment. 

                                                                

3.5.3 Indirect Proof

Consider a theorem P  C, where P represents p1, p2, ..., and pn, the premises.
The method of indirect proof is based on the equivalence P  C  ¬(P 
¬C). In words, this logical law states that if P  C, then P  ¬C is always
false; that is, P  ¬C is a contradiction. This means that a valid method of
proof is to negate the conclusion of a theorem and add this negation to the
premises. If a contradiction can be implied from this set of propositions, the
proof is complete. For the proofs in this section, a contradiction will often take
the form t  ¬t.

    For proofs involving numbers, a contradiction might be 1 = 0 or 0 < 0.
Indirect proofs involving sets might conclude with x   or (x  A and x 
Ac). Indirect proofs are often more convenient than direct proofs in certain
situations. Indirect proofs are often called proofs by contradiction.

Example 3.5.14 An Indirect Proof. Here is an example of an indirect
proof of the theorem in Example 3.5.7.
CHAPTER 3. LOGIC                                                57

Table 3.5.15 An Indirect proof of p  r, q  s, p  q  s  r

1. ¬(s  r)              Negated conclusion

2. ¬s  ¬r               DeMorgan's Law, (1)

3.                ¬s    Conjunctive simplification, (2)

4.       qs             Premise

5.                ¬q    Indirect reasoning, (3), (4)

6.                ¬r    Conjunctive simplification, (2)

7.       pr             Premise

8.                ¬p    Indirect reasoning, (6), (7)

9. (¬p)  (¬q)           Conjunctive, (5), (8)

10. ¬(p  q)             DeMorgan's Law, (9)

11.               pq    Premise

12.               0     (10), (11) 

                                                                                                    
Note 3.5.16 Proof Style. The rules allow you to list the premises of a
theorem immediately; however, a proof is much easier to follow if the premises
are only listed when they are needed.

Example 3.5.17 Yet Another Indirect Proof. Here is an indirect proof
of a  b, ¬(b  c)  ¬a.

Table 3.5.18 Indirect proof of a  b, ¬(b  c)  ¬a

     1.              a  Negation of the conclusion

     2. a  b            Premise

     3.              b  (1), (2), detachment

     4. b  c (3), disjunctive addition

     5. ¬(b  c)         Premise

     6.              0  (4), (5) 

                                                                                                    
    As we mentioned at the outset of this section, we are only presenting an
overview of what a mathematical system is. For greater detail on axiomatic
theories, see Stoll (1961). An excellent description of how propositional calcu-
lus plays a part in artificial intelligence is contained in Hofstadter (1980). If
you enjoy the challenge of constructing proofs in propositional calculus, you
should enjoy the game WFF'N PROOF (1962), by L.E. Allen.

3.5.4 Exercises

1. Prove with truth tables:

        (a) p  q, ¬q  p
        (b) p  q, ¬q  ¬p
2. Prove with truth tables:

        (a) q, ¬q  p
        (b) p  q  ¬p  q
3. Give direct and indirect proofs of:

        (a) a  b, c  b, d  (a  c), d  b.
        (b) (p  q)  (r  s), (q  t)  (s  u), ¬(t  u), p  r  ¬p.
CHAPTER 3. LOGIC                                                   58

         (c) p  (q  r), ¬s  p, q  s  r.

        (d) p  q, q  r, ¬(p  r), p  r  r.

         (e) ¬q, p  q, p  t  t
4. Give direct and indirect proofs of:

        (a) p  q, ¬r  ¬q, ¬r  ¬p.

        (b) p  ¬q, ¬r  q, p  r.

         (c) a  b, c  d, a  ¬c  b.
5. Are the following arguments valid? If they are valid, construct formal

      proofs; if they aren't valid, explain why not.

        (a) If wages increase, then there will be inflation. The cost of living will
              not increase if there is no inflation. Wages will increase. Therefore,
              the cost of living will increase.

        (b) If the races are fixed or the casinos are crooked, then the tourist
              trade will decline. If the tourist trade decreases, then the police will
              be happy. The police force is never happy. Therefore, the races are
              not fixed.

6. My salad contains beets and okra. If my salad contains cottage cheese
      then it doesn't contain beets. My salad contains cottage cheese or hummus.
      Therefore, my salad contains hummus.

7. Describe how p1, p1  p2, . . . , p99  p100  p100 could be proved in 199
      steps.

3.6 Propositions over a Universe

3.6.1 Propositions over a Universe

Consider the sentence "He was a member of the Boston Red Sox." There is no
way that we can assign a truth value to this sentence unless "he" is specified.
For that reason, we would not consider it a proposition. However, "he" can
be considered a variable that holds a place for any name. We might want
to restrict the value of "he" to all names in the major-league baseball record
books. If that is the case, we say that the sentence is a proposition over the
set of major-league baseball players, past and present.

Definition 3.6.1 Proposition over a Universe. Let U be a nonempty

set. A proposition over U is a sentence that contains a variable that can take

on any value in U and that has a definite truth value as a result of any such

substitution.                                                      

A proposition over a universe is also referred to as a predicate.

Example 3.6.2 Some propositions over a variety of universes.

(a) A few propositions over the integers are 4x2 - 3x = 0, 0  n  5, and "k
     is a multiple of 3."

(b) A few propositions over the rational numbers are 4x2 - 3x = 0, y2 = 2,
     and (s - 1)(s + 1) = s2 - 1.

(c) A few propositions over the subsets of P are (A = )  (A = P), 3  A,
     and A  {1, 2, 3} = .
CHAPTER 3. LOGIC                                                        59

                                                                                                    
    All of the laws of logic that we listed in Section 3.4 are valid for propositions
over a universe. For example, if p and q are propositions over the integers, we
can be certain that p  q  p, because (p  q)  p is a tautology and is true
no matter what values the variables in p and q are given. If we specify p and q
to be p(n) : n < 4 and q(n) : n < 8, we can also say that p implies p  q. This
is not a usual implication, but for the propositions under discussion, it is true.
One way of describing this situation in general is with truth sets.

3.6.2 Truth Sets

Definition 3.6.3 Truth Set. If p is a proposition over U , the truth set of p

is Tp = {a  U | p(a) is true}.                                          

Example 3.6.4 Truth Set Example. The truth set of the proposition

{1, 2}  A = , taken as a proposition over the power set of {1, 2, 3, 4} is

{, {3}, {4}, {3, 4}}.                                                   

Example 3.6.5 Truth sets depend on the universe. Over the universe Z
(the integers), the truth set of 4x2 - 3x = 0 is {0}. If the universe is expanded

to the rational numbers, the truth set becomes {0, 3/4}. The term solution set

is often used for the truth set of an equation such as the one in this example.

                                                                        

Definition 3.6.6 Tautologies and Contradictions over a Universe. A

proposition over U is a tautology if its truth set is U . It is a contradiction if

its truth set is empty.                                                 

Example 3.6.7 Tautology, Contradiction over Q. (s - 1)(s + 1) = s2 - 1
is a tautology over the rational numbers. x2 - 2 = 0 is a contradiction over the

rationals.                                                              

The truth sets of compound propositions can be expressed in terms of the

truth sets of simple propositions. For example, if a  Tpq if and only if a

makes p  q true. This is true if and only if a makes both p and q true, which,

in turn, is true if and only if a  Tp  Tq. This explains why the truth set of

the conjunction of two propositions equals the intersection of the truth sets of

the two propositions. The following list summarizes the connection between

compound and simple truth sets

Table 3.6.8 Truth Sets of Compound Statements

                                   Tpq = Tp  Tq

                                   Tpq = Tp  Tq
                                      T¬p = Tpc

                         Tpq = (Tp  Tq)  (Tpc  Tqc)
                                  Tpq = Tpc  Tq

Definition 3.6.9 Equivalence of propositions over a universe. Two

propositions, p and q, are equivalent if p  q is a tautology. In terms of truth

sets, this means that p and q are equivalent if Tp = Tq .               

Example 3.6.10 Some pairs of equivalent propositions.

(a) n + 4 = 9 and n = 5 are equivalent propositions over the integers.

(b) A  {4} =  and 4  A are equivalent propositions over the power set of
     the natural numbers.

                                                                        
CHAPTER 3. LOGIC                                                     60

Definition 3.6.11 Implication for propositions over a universe. If p

and q are propositions over U , p implies q if p  q is a tautology.  

Since the truth set of p  q is Tpc  Tq, the Venn diagram for Tpq in

Figure 12 shows that p  q when Tp  Tq.

Figure 3.6.12 Venn Diagram for Tpq

Example 3.6.13 Examples of Implications.

  (a) Over the natural numbers: n  4  n  8 since {0, 1, 2, 3, 4} 
       {0, 1, 2, 3, 4, 5, 6, 7, 8}

  (b) Over the power set of the integers: |Ac| = 1 implies A  {0, 1} = 

  (c) Over the power set of the integers, A  even integers  A 
        odd integers = 

                                                                                                    

3.6.3 Exercises

1. If U = P({1, 2, 3, 4}), what are the truth sets of the following proposi-
      tions?

(a) A  {2, 4} = .

(b) 3  A and 1 / A.

(c) A  {1} = A.

(d) A is a proper subset of {2, 3, 4}.

         (e) |A| = |Ac|.
2. Over the universe of positive integers, define

      Table 3.6.14

                   p(n):  n is prime and n < 32.
                   q(n):  n is a power of 3.
                   r(n):  n is a divisor of 27.

(a) What are the truth sets of these propositions?
(b) Which of the three propositions implies one of the others?
CHAPTER 3. LOGIC                                                      61

3. If U = {0, 1, 2}, how many propositions over U could you list without
      listing two that are equivalent?

4. Given the propositions over the natural numbers:
      Table 3.6.15

                    p : n < 4, q : 2n > 17, and r : n is a divisor of 18

           What are the truth sets of:

    (a) q         (c) r

    (b) p  q      (d) q  r

5. Suppose that s is a proposition over {1, 2, . . . , 8}. If Ts = {1, 3, 5, 7}, give
      two examples of propositions that are equivalent to s.

6.

    (a) Determine the truth sets of the following propositions over the pos-
         itive integers:

                  p(n) : n is a perfect square and n < 100

                  q(n) : n = |P(A)| for some set A.

        (b) Determine Tpq for p and q above.
7. Let the universe be Z, the set of integers. Which of the following propo-

      sitions are equivalent over Z?
      Table 3.6.16

                                            a: 0 < n2 < 9
                                            b: 0 < n3 < 27
                                            c: 0 < n < 3

3.7 Mathematical Induction

3.7.1 Introduction, First Example

In this section, we will examine mathematical induction, a technique for prov-
ing propositions over the positive integers. Mathematical induction reduces the
proof that all of the positive integers belong to a truth set to a finite number
of steps.

Example 3.7.1 Formula for Triangular Numbers. Consider the following

proposition over the positive integers, which we will label p(n): The sum of the

positive integers from 1 to n is 2 n(n+1) . This is a well-known formula that is
quite simple to verify for a given value of n. For example, p(5) is: The sum of

the positive integers from 1 to 5 is 2 5(5+1) . Indeed, 1+2+3+4+5 = 15 = 2 5(5+1) .
However, this doesn't serve as a proof that p(n) is a tautology. All that we've

established is that 5 is in the truth set of p. Since the positive integers are

infinite, we certainly can't use this approach to prove the formula.  

    An Analogy: A proof by mathematical induction is similar to knocking over

a row of closely spaced dominos that are standing on end. To knock over the

dominos in Figure 3.7.2, all you need to do is push the first domino over. To

be assured that they all will be knocked over, some work must be done ahead
CHAPTER 3. LOGIC  62

of time. The dominos must be positioned so that if any domino is pushed is
knocked over, it will push the next domino in the line.

Figure 3.7.2 An analogy for Mathematical Induction, Creative Commons
photo by Ranveig Thattai

    Returning to Example 3.7.1 imagine the propositions p(1), p(2), p(3), . . . to
be an infinite line of dominos. Let's see if these propositions are in the same
formation as the dominos were. First, we will focus on one specific point of
the line: p(99) and p(100). We are not going to prove that either of these
propositions is true, just that the truth of p(99) implies the truth of p(100). In
terms of our analogy, if p(99) is knocked over, it will knock over p(100).

    In proving p(99)  p(100), we will use p(99) as our premise. We must
prove: The sum of the positive integers from 1 to 100 is 2 100(100+1) . We start
by observing that the sum of the positive integers from 1 to 100 is (1 + 2 + · · · +
99) + 100. That is, the sum of the positive integers from 1 to 100 equals the
sum of the first ninety-nine plus the final number, 100. We can now apply our
premise, p(99), to the sum 1 + 2 + · · · + 99. After rearranging our numbers, we
CHAPTER 3. LOGIC                                                    63

obtain the desired expression for 1 + 2 + · · · + 100:

1 + 2 + · · · + 99 + 100 = (1 + 2 + · · · + 99) + 100

                  = 99 · (99 + 1) + 100 by our assumption of p(99)
                            2

                  2= 99 · 100 + 2 · 100 .2

                  = 100 · 101
                          2

                  = 100 · (100 + 1)
                              2

    What we've just done is analogous to checking two dominos in a line and
finding that they are properly positioned. Since we are dealing with an infinite
line, we must check all pairs at once. This is accomplished by proving that
p(n)  p(n + 1) for all n  1:

               1 + 2 + · · · + n + (n + 1) = (1 + 2 + · · · + n) + (n + 1)

                                                = n(n + 1) + (n + 1) by p(n)
                                                        2

                                                    n(n + 1) 2(n + 1)
                                                = 2+2 .

                                                    (n + 1)(n + 2)
                                                =

                                                            2
                                                    (n + 1)((n + 1) + 1)
                                                =

                                                                2

    They are all lined up! Now look at p(1): The sum of the positive integers
from 1 to 1 is 2 1·(1+1) . Clearly, p(1) is true. This sets off a chain reaction. Since
p(1)  p(2), p(2) is true. Since p(2)  p(3), p(3) is true; and so on. 
Theorem 3.7.3 The Principle of Mathematical Induction. Let p(n) be
a proposition over the positive integers. If

  (1) p(1) is true, and

  (2) for all n  1, p(n)  p(n + 1),

then p(n) is a tautology.
    Note: The truth of p(1) is called the basis for the induction proof. The

premise that p(n) is true in the second part is called the induction hypothe-
sis. The proof that p(n) implies p(n + 1) is called the induction step of the
proof. Despite our analogy, the basis is usually done first in an induction proof.
However, order doesn't really matter.

3.7.2 More Examples

Example 3.7.4 Generalized Detachment. Consider the implication over
the positive integers.

                    p(n) : q0  q1, q1  q2, . . . , qn-1  qn, q0  qn

A proof that p(n) is a tautology follows. Basis: p(1) is q0  q1, q0  q1. This
is the logical law of detachment which we know is true. If you haven't done so
yet, write out the truth table of ((q0  q1)  q0)  q1 to verify this step.

    Induction: Assume that p(n) is true for some n  1. We want to prove that
CHAPTER 3. LOGIC                                                                       64

p(n + 1) must be true. That is:

              q0  q1, q1  q2, . . . , qn-1  qn, qn  qn+1, q0  qn+1

Here is a direct proof of p(n + 1):

Table 3.7.5

    Step                       Proposition                           Justification
1 - (n + 1)     q0  q1, q1  q2, . . . , qn-1  qn, q0                   Premises

   n+2                               qn                          (1) - (n + 1), p(n)
   n+3                          qn  qn+1                                Premise
   n+4
                                    qn+1                (n + 2), (n + 3), detachment 

                                                                                                     

Example 3.7.6 An example from Number Theory. For all n  1, n3+2n
is a multiple of 3. An inductive proof follows:

    Basis: 13 + 2(1) = 3 is a multiple of 3. The basis is almost always this easy!
    Induction: Assume that n  1 and n3 + 2n is a multiple of 3. Consider
(n + 1)3 + 2(n + 1). Is it a multiple of 3?

              (n + 1)3 + 2(n + 1) = n3 + 3n2 + 3n + 1 + (2n + 2)

                                     = n3 + 2n + 3n2 + 3n + 3         .

                                     = (n3 + 2n) + 3(n2 + n + 1)

    Yes, (n + 1)3 + 2(n + 1) is the sum of two multiples of 3; therefore, it is also

a multiple of 3.                                                                          

    Now we will discuss some of the variations of the principle of mathematical

induction. The first simply allows for universes that are similar to P such as
{-2, -1, 0, 1, . . .} or {5, 6, 7, 8, . . .}.

Theorem 3.7.7 Principle of Mathematical Induction (Generalized).

If p(n) is a proposition over {k0, k0 + 1, k0 + 2, . . .}, where k0 is any integer,
then p(n) is a tautology if

  (1) p(k0) is true, and

  (2) for all n  k0, p(n)  p(n + 1).

Example 3.7.8 A proof of the permutations formula. In Chapter 2,
we stated that the number of different permutations of k elements taken from
an n element set, P (n; k), can be computed with the formula (n-k)! n! . We can
prove this statement by induction on n. For n  0, let q(n) be the proposition

                    P (n; k) = n! for all k, 0  k  n.
                                 (n - k)!

    Basis: q(0) states that P (0; 0) if is the number of ways that 0 elements can

be  selected  from  the  empty  set  and  arranged  in  order,  then  P (0; 0)  =  0!  =  1.
                                                                                   0!
This is true. A general law in combinatorics is that there is exactly one way of

doing nothing.

    Induction: Assume that q(n) is true for some natural number n. It is left

for us to prove that this assumption implies that q(n + 1) is true. Suppose

that we have a set of cardinality n + 1 and want to select and arrange k of its

elements. There are two cases to consider, the first of which is easy. If k = 0,
CHAPTER 3. LOGIC                                                      65

then there is one way of selecting zero elements from the set; hence

                                                          (n + 1)!
                               P (n + 1; 0) = 1 =

                                                       (n + 1 + 0)!

and the formula works in this case.
    The more challenging case is to verify the formula when k is positive and

less than or equal to n + 1. Here we count the value of P (n + 1; k) by counting
the number of ways that the first element in the arrangement can be filled and
then counting the number of ways that the remaining k - 1 elements can be
filled in using the induction hypothesis.

    There are n + 1 possible choices for the first element. Since that leaves n
elements to fill in the remaining k - 1 positions, there are P (n; k - 1) ways of
completing the arrangement. By the rule of products,

  P (n + 1; k) = (n + 1)P (n; k - 1)
                                      n!

                 = (n + 1)
                              (n - (k - 1))!

                      (n + 1)n!
                 =

                     (n - k + 1)!
                         (n + 1)!

                 =
                     ((n + 1) - k)!

                                                                      

3.7.3 Course of Values Induction

A second variation allows for the expansion of the induction hypothesis. The
course-of-values principle includes the previous generalization. It is also some-
times called strong induction.

Theorem 3.7.9 The Course-of-Values Principle of Mathematical In-
duction. If p(n) is a proposition over {k0, k0 + 1, k0 + 2, . . .}, where k0 is any
integer, then p(n) is a tautology if

  (1) p(k0) is true, and

  (2) for all n  k0, p(k0), p(k0 + 1), ..., p(n)  p(n + 1).
    A prime number is defined as a positive integer that has exactly two

positive divisors, 1 and itself. There are an infinite number of primes. The list
of primes starts with 2, 3, 5, 7, 11, . . ..

    The proposition over {2, 3, 4, ...} that we will prove here is p(n): n can be
written as the product of one or more primes. In most texts, the assertion that
p(n) is a tautology would appear as

Theorem 3.7.10 Existence of Prime Factorizations. Every positive
integer greater than or equal to 2 has a prime decomposition.
Proof. If you were to encounter this theorem outside the context of a discussion
of mathematical induction, it might not be obvious that the proof can be done
by induction. Recognizing when an induction proof is appropriate is mostly a
matter of experience. Now on to the proof!
Basis: Since 2 is a prime, it is already decomposed into primes (one of them).
Induction: Suppose that for some n  2 all of the integers 2, 3, ..., n have a
prime decomposition. Notice the course-of-value hypothesis. Consider n + 1.
Either n + 1 is prime or it isn't. If n + 1 is prime, it is already decomposed
into primes. If not, then n + 1 has a divisor, d, other than 1 and n + 1. Hence,
CHAPTER 3. LOGIC                                                           66

n+1 = cd where both c and d are between 2 and n. By the induction hypothesis,

c and d have prime decompositions, c1c2 · · · cs and d1d2 · · · dt , respectively.

Therefore, n + 1 has the prime decomposition c1c2 · · · csd1d2 · · · dt.   

Peano Postulates and Induction. Mathematical induction originated in
the late nineteenth century. Two mathematicians who were prominent in its
development were Richard Dedekind and Giuseppe Peano. Dedekind developed
a set of axioms that describe the positive integers. Peano refined these axioms
and gave a logical interpretation to them. The axioms are usually called the
Peano Postulates.

Axiom 3.7.11 Peano Postulates. The system of positive integers consists of
a nonempty set, P; a least element of P, denoted 1; and a "successor function,"
s, with the properties

(1) If k  P , then there is an element of P called the successor of k, denoted
     s(k).

(2) No two elements of P have the same successor.
(3) No element of P has 1 as its successor.
(4) If S  P, 1  S, and k  S  s(k)  S, then S = P.

  Notes:

· You might recognize s(k) as simply being k + 1.

· Axiom 4 is the one that makes mathematical induction possible. In
   an induction proof, we simply apply that axiom to the truth set of a
   proposition.

3.7.4 Exercises

1. Prove that the sum of the first n odd positive integers equals n2 .

2. Prove that if n  1, then 1(1!) + 2(2!) + · · · + n(n!) = (n + 1)! - 1.
3. Prove that for n  1: k=1 n k2 = 16 n(n + 1)(2n + 1).
4. Prove that for n  0: nk=0 2k = 2n+1 - 1.
5. Use mathematical induction to show that for n  1,

                  1 + 1 +···+ 1 = n .
                 1·2 2·3  n(n + 1) n + 1

6. Prove that if n  2, the generalized DeMorgan's Law is true:

                     ¬(p1  p2  ...  pn)  (¬p1)  (¬p2)  · · ·  (¬pn).

7. The number of strings of n zeros and ones that contain an even number
      of ones is 2n-1. Prove this fact by induction for n  1.

8. Let p(n) be 8n - 3n is a multiple of 5. Prove that p(n) is a tautology over
      N.

9. Suppose that there are n people in a room, n  1, and that they all
      shake hands with one another. Prove that 2 n(n-1) handshakes will have
      occurred.

10. Prove that it is possible to make up any postage of eight cents or more
      using only three- and five-cent stamps.

11. Generalized associativity. It is well known that if a1, a2, and a3 are
      numbers, then no matter what order the sums in the expression a1+a2+a3
CHAPTER 3. LOGIC                                                                  67

      are taken, the result is always the same. Call this fact p(3). Prove using
      course-of-values induction that if a1, a2, . . . , and an are numbers, then
      no matter what order the sums in the expression a1 + a2 + · · · + an are
      taken, the result is always the same.

12. Let S be the set of all numbers that can be produced by applying any of
      the rules below in any order a finite number of times.

·  Rule 1:   1   S
             2

· Rule 2: 1  S

· Rule 3: If a and b have been produced by the rules, then ab  S.

·  Rule  4:  If      a  and  b  have  been  produced  by  the  rules,  then  a+b   S.
                                                                               2

      Prove that a  S  0  a  1.

      Hint. The number of times the rules are applied should be the integer
      that you do the induction on.

13. Proofs involving objects that are defined recursively are often inductive.
      A recursive definition is similar to an inductive proof. It consists of a
      basis, usually the simple part of the definition, and the recursion, which
      defines complex objects in terms of simpler ones. For example, if x is a
      real number and n is a positive integer, we can define xn as follows:

· Basis: x1 = x.

· Recursion: if n  2, xn = xn-1x.

For example, x3 = x2x = (x1x)x = (xx)x.
    Prove that if n, m  P, xm+n = xmxn. There is much more on recur-

sion in Chapter 8.

Hint. Let p(m) be the proposition that xm+n = xmxn for all n  1.

3.8 Quantifiers

As we saw in Section 3.6, if p(n) is a proposition over a universe U , its truth set
Tp is equal to a subset of U . In many cases, such as when p(n) is an equation,
we are most concerned with whether Tp is empty or not. In other cases, we
might be interested in whether Tp = U ; that is, whether p(n) is a tautology.
Since the conditions Tp =  and Tp = U are so often an issue, we have a special
system of notation for them.

3.8.1 The Existential Quantifier

Definition 3.8.1 The Existential Quantifier. If p(n) is a proposition over

U with Tp = , we commonly say "There exists an n in U such that p(n) (is

true)." We abbreviate this with the symbols (n)U (p(n)). The symbol  is

called the existential quantifier. If the context is clear, the mention of U is

dropped: (n)(p(n)).                                                               

Example 3.8.2 Some examples of existential quantifiers.

(a) (k)Z(k2 - k - 12 = 0) is another way of saying that there is an integer
     that solves the equation k2 - k - 12 = 0. The fact that two such integers

     exist doesn't affect the truth of this proposition in any way.
CHAPTER 3. LOGIC                                       68

 (b) (k)Z(3k = 102) simply states that 102 is a multiple of 3, which is true.
       On the other hand, (k)Z(3k = 100) states that 100 is a multiple of 3,
       which is false.

  (c) (x)R(x2 + 1 = 0) is false since the solution set of the equation x2 + 1 = 0
       in the real numbers is empty. It is common to write (x)R(x2 + 1 = 0)
       in this case.

                                                                                                    
    There are a wide variety of ways that you can write a proposition with an
existential quantifier. Table 3.8.5 contains a list of different variations that
could be used for both the existential and universal quantifiers.

3.8.2 The Universal Quantifier

Definition 3.8.3 The Universal Quantifier. If p(n) is a proposition over
U with Tp = U , we commonly say "For all n in U , p(n) (is true)." We abbre-
viate this with the symbols (n)U (p(n)). The symbol  is called the universal
quantifier. If the context is clear, the mention of U is dropped: (n)(p(n)). 

Example 3.8.4 Some Universal Quantifiers.

(a) We can say that the square of every real number is non-negative symbol-
     ically with a universal quantifier: (x)R(x2  0).

(b) (n)Z(n + 0 = 0 + n = n) says that the sum of zero and any integer n is
     n. This fact is called the identity property of zero for addition.

                                                                                                    
Table 3.8.5 Notational Variations with Quantified Expressions

   Universal Quantifier       Existential Quantifier
        (n)U (p(n))
                                     (n)U (p(n))
      (n  U )(p(n))                (n  U )(p(n))
        n  U, p(n)            n  U such that p(n)
        p(n), n  U         p(n) is true for some n  U

p(n) is true for all n  U

3.8.3 The Negation of Quantified Propositions

When you negate a quantified proposition, the existential and universal quan-
tifiers complement one another.

Example 3.8.6 Negation of an Existential Quantifier. Over the universe
of animals, define F (x): x is a fish and W (x): x lives in the water. We
know that the proposition W (x)  F (x) is not always true. In other words,
(x)(W (x)  F (x)) is false. Another way of stating this fact is that there
exists an animal that lives in the water and is not a fish; that is,

                   ¬(x)(W (x)  F (x))  (x)(¬(W (x)  F (x))).
                                                 (x)(W (x)  ¬F (x))

                                                                                                     
    Note that the negation of a universally quantified proposition is an exis-
tentially quantified proposition. In addition, when you negate an existentially
quantified proposition, you get a universally quantified proposition. Symboli-
cally,
CHAPTER 3. LOGIC  69

Table 3.8.7 Negation of Quantified Expressions

                              ¬((n)U (p(n)))  (n)U (¬p(n))
                              ¬((n)U (p(n)))  (n)U (¬p(n))

Example 3.8.8 More Negations of Quantified Expressions.
                                                             

  (a) Theancient Greeks first discovered that 2 is an irrational number; that
       is, 2 is not a rational number. ¬((r)Q(r2 = 2)) and (r)Q(r2 = 2)
       both state this fact symbolically.

  (b) ¬((n)P(n2 - n + 41 is prime)) is equivalent to (n)P(n2 - n +
       41 is composite). They are either both true or both false.

                                                                                                    

3.8.4 Multiple Quantifiers

If a proposition has more than one variable, then you can quantify it more
than once. For example, p(x, y) : x2 - y2 = (x + y)(x - y) is a tautology
over the set of all pairs of real numbers because it is true for each pair (x, y)
in R × R. Another way to look at this proposition is as a proposition with
two variables. The assertion that p(x, y) is a tautology could be quantified as
(x)R((y)R(p(x, y))) or (y)R((x)R(p(x, y)))

    In general, multiple universal quantifiers can be arranged in any order with-
out logically changing the meaning of the resulting proposition. The same is
true for multiple existential quantifiers. For example, p(x, y) : x+y = 4 and x-
y = 2 is a proposition over R × R. (x)R((y)R(x + y = 4 and x - y = 2)) and
(y)R ((x)R(x + y = 4 and x - y = 2)) are equivalent. A proposition with mul-
tiple existential quantifiers such as this one says that there are simultaneous
values for the quantified variables that make the proposition true. A similar
example is q(x, y) : 2x - y = 2 and 4x - 2y = 5, which is always false; and the
following are all equivalent:

                ¬((x)R((y)R(q(x, y))))  ¬(y)R((x)R(q(x, y)))

                                                   (y)R(¬((x)R(q(x, y))))

                                                   ((y)R((x)R(¬q(x, y))))

                                                   ((x)R((y)R(¬q(x, y))))

    When existential and universal quantifiers are mixed, the order cannot be
exchanged without possibly changing the meaning of the proposition. For
example, let R+ be the positive real numbers, x : (a)R+ ((b)R+ (ab = 1)) and
y : (b)R+ ((a)R+ (ab = 1)) have different logical values; x is true, while y is
false.

    Tips on Reading Multiply-Quantified Propositions. It is understandable
that you would find propositions such as x difficult to read. The trick to
deciphering these expressions is to "peel" one quantifier off the proposition
just as you would peel off the layers of an onion (but quantifiers shouldn't
make you cry!). Since the outermost quantifier in x is universal, x says that
z(a) : (b)R+ (ab = 1) is true for each value that a can take on. Now take
the time to select a value for a, like 6. For the value that we selected, we
get z(6) : (b)R+ (6b = 1), which is obviously true since 6b = 1 has a solution
in the positive real numbers. We will get that same truth value no matter
which positive real number we choose for a; therefore, z(a) is a tautology over
R+ and we are justified in saying that x is true. The key to understanding
CHAPTER 3. LOGIC                                                                                                             70

propositions like x on your own is to experiment with actual values for the
outermost variables as we did above.

    Now consider y. To see that y is false, we peel off the outer quantifier.
Since it is an existential quantifier, all that y says is that some positive real
number makes w(b) : (a)R+ (ab = 1) true. Choose a few values of b to see
if you can find one that makes w(b) true. For example, if we pick b = 2, we
get (a)R+ (2a = 1), which is false, since 2a is almost always different from 1.
You should be able to convince yourself that no value of b will make w(b) true.
Therefore, y is false.

    Another way of convincing yourself that y is false is to convince yourself
that ¬y is true:

             ¬((b)R+ ((a)R+ (ab = 1)))  (b)R+ ¬((a)R+ (ab = 1))
                                                  (b)R+ ((a)R+ (ab = 1))

In words, for each value of b, there is a value for a that makes ab = 1. One

such  value  is   a  =  1  + 1.  Therefore,   ¬y  is  true.
                        b
    One final example that serves as a preview to how quantifiers appear in

calculus.

Example 3.8.9 The Limit of a Sequence. What does it mean that 0.999...
= 1? The ellipsis (. . .) implies that there are an infinite number of 9's on the left
of the equals sign. Any way to try to justify this equality boils down to the idea
of limits. After many years of struggling with what this means, mathematicians
have come up with a universally accepted interpretation involving quantifiers.
It is that

                      ()R+ ((N )P)(n  N  |1 - 0. 99..9 | < ))

                                                                                              n 9's

In calculus, the symbol  is usually reserved for small positive real numbers.

Let's pick a value for  and peel the universal quantifier off the statement above.

Let's try  equal to         1    =  1024 1 .  In addition we note that 0. 99..9 = 1 - 10n 1 .
                           210

                                                                                                                      n 9's

With our choice of  we get

                                                                        1
                           (N )P(n  N  |1 - 0. 99..9 | < 1024 )

                                                                         n 9's

or                                                    1      1

                                 (N )P(n  N  10n < 1024 )

This last statement is true - one value of N that would work is 11. You just

have to convince yourself that any positive value of , no matter how small,

will produce a true statement. If you see that, you've convinced yourself that

0.999 · · · = 1!                                                                                                             

3.8.5 Exercises

1. Let C(x) be "x is cold-blooded," let F (x) be "x is a fish," and let S(x)
      be "x lives in the sea."

      (a) Translate into a formula: Every fish is cold-blooded.
      (b) Translate into English: (x)(S(x)  ¬F (x)).
      (c) Translate into English: (x)(F (x)  S(x)).
CHAPTER 3. LOGIC  71

2. Let M (x) be "x is a mammal," let A(x) be "x is an animal," and let
      W (x) be "x is warm-blooded."

        (a) Translate into a formula: Every mammal is warm-blooded.

        (b) Translate into English: (x)(A(x)  (¬M (x))).
3. Over the universe of books, define the propositions B(x): x has a blue

      cover, M (x): x is a mathematics book, U (x): x is published in the United
      States, and R(x, y) : The bibliography of x includes y.

           Translate into words:

        (a) (x)(¬B(x)).

        (b) (x)(M (x)  U (x)  B(x)).

         (c) (x)(M (x)  ¬B(x)).

        (d) (y)((x)(M (x)  R(x, y))).

         (e) Express using quantifiers: Every book with a blue cover is a mathe-
              matics book.

         (f) Express using quantifiers: There are mathematics books that are
              published outside the United States.

        (g) Express using quantifiers: Not all books have bibliographies.
4. Let the universe of discourse, U , be the set of all people, and let M (x, y)

      be "x is the mother of y."
           Which of the following is a true statement? Translate it into English.

        (a) (x)U ((y)U (M (x, y)))

        (b) (y)U ((x)U (M (x, y)))

         (c) Translate the following statement into logical notation using quanti-
              fiers and the proposition M (x, y) : "Everyone has a maternal grand-
              mother."

5. Translate into your own words and indicate whether it is true or false
      that (u)Z(4u2 - 9 = 0).
                                            

6. Use quantifiers to say that 3 is an irrational number.
7. What do the following propositions say, where U is the power set of

      {1, 2, . . . , 9}? Which of these propositions are true?

        (a) (A)U |A| = |Ac|.

        (b) (A)U (B)U (|A| = 5, |B| = 5, and A  B = ).

         (c) (A)U (B)U (A - B = Bc - Ac).
8. Use quantifiers to state that for every positive integer, there is a larger

      positive integer.
9. Use quantifiers to state that the sum of any two rational numbers is

      rational.
10. Over the universe of real numbers, use quantifiers to say that the equation

      a + x = b has a solution for all values of a and b.
      Hint. You will need three quantifiers.
CHAPTER 3. LOGIC                                                                       72

11. Let n be a positive integer. Describe using quantifiers:

                              n

        (a) x   Ak

                            k=1

                              n

        (b) x   Ak

                            k=1

12. Prove that (x)(y)(p(x, y))  (y)(x)(p(x, y)), but that converse is
      not true.

3.9 A Review of Methods of Proof

One of the major goals of this chapter is to acquaint the reader with the key
concepts in the nature of proof in logic, which of course carries over into all
areas of mathematics and its applications. In this section we will stop, reflect,
and "smell the roses," so that these key ideas are not lost in the many concepts
covered in logic. In Chapter 4 we will use set theory as a vehicle for further
practice and insights into methods of proof.

3.9.1 Key Concepts in Proof

All theorems in mathematics can be expressed in the form "If P then C"
(P  C), or in the form "C1 if and only if C2" (C1  C2). The latter is
equivalent to "If C1 then C2," and "If C2 then C1."

    In "If P then C," P is the premise (or hypothesis) and C is the conclusion.
It is important to realize that a theorem makes a statement that is dependent
on the premise being true.

    There are two basic methods for proving P  C:

· Directly: Assume P is true and prove C is true.

· Indirectly (or by contradiction): Assume P is true and C is false and
   prove that this leads to a contradiction of some premise, theorem, or
   basic truth.

    The method of proof for "If and only if" theorems is found in the law
(P  C)  ((P  C)  (C  P )). Hence to prove an "If and only if"
statement one must prove an "if . . . then ..." statement and its converse.

    The initial response of most people when confronted with the task of being
told they must be able to read and do proofs is often "Why?" or "I can't do
proofs." To answer the first question, doing proofs or problem solving, even on
the most trivial level, involves being able to read statements. First we must
understand the problem and know the hypothesis; second, we must realize
when we are done and we must understand the conclusion. To apply theorems
or algorithms we must be able to read theorems and their proofs intelligently.

    To be able to do the actual proofs of theorems we are forced to learn:

· the actual meaning of the theorems, and

· the basic definitions and concepts of the topic discussed.

For example, when we discuss rational numbers and refer to a number x as

being  rational,  this  means  we  can  substitute  a  fraction  p  in  place  of  x,  with
                                                                 q
the understanding that p and q are integers and q = 0. Therefore, to prove a

theorem about rational numbers it is absolutely necessary that you know what

a rational number "looks like."
CHAPTER 3. LOGIC                                       73

    It's easy to comment on the response, "I cannot do proofs." Have you
tried? As elementary school students we may have been in awe of anyone who
could handle algebraic expressions, especially complicated ones. We learned by
trying and applying ourselves. Maybe we cannot solve all problems in algebra
or calculus, but we are comfortable enough with these subjects to know that
we can solve many and can express ourselves intelligently in these areas. The
same remarks hold true for proofs.

3.9.2 The Art of Proving P  C

First one must completely realize what is given, the hypothesis. The impor-
tance of this is usually overlooked by beginners. It makes sense, whenever you
begin any task, to spend considerable time thinking about the tools at your
disposal. Write down the premise in precise language. Similarly, you have to
know when the task is finished. Write down the conclusion in precise language.
Then you usually start with P and attempt to show that C follows logically.
How do you begin? Basically you attack the proof the same way you solve a
complicated equation in elementary algebra. You may not know exactly what
each and every step is but you must try something. If we are lucky, C follows
naturally; if it doesn't, try something else. Often what is helpful is to work
backward from C. Finally, we have all learned, possibly the hard way, that
mathematics is a participating sport, not a spectator sport. One learns proofs
by doing them, not by watching others do them. We give several illustrations
of how to set up the proofs of several examples. Our aim here is not to prove
the statements given, but to concentrate on the logical procedure.

Example 3.9.1 The Sum of Odd Integers. We will outline a proof that
the sum of any two odd integers is even. Our first step will be to write the
theorem in the familiar conditional form: If x and y are odd integers, then
x + y is even. The premise and conclusion of this theorem should be clear now.
Notice that if x and y are not both odd, then the conclusion may or may not
be true. Our only objective is to show that the truth of the premise forces the
conclusion to be true. Therefore, we can express the integers x and y in the
form that all odd integers take; that is:

          n  Z is odd implies that (m  Z)(n = 2m + 1)

This observation allows us to examine the sum x + y and to verify that it must

be even.

One final important point: This example involves two odd integers that

may or may not be equal. If we use the fact that x is odd and infer that

x = 2m + 1 for some integer m, we can do a similar thing with y. However, in

this context we cannot write y = 2m + 1 since we have already linked m to x.

We need to use a different variable, maybe q or m - any other symbol that is

not already used in our discussion.                    

Example 3.9.2 The Square of an Even Integer. Let n  Z. We will
outline a proof that n2 is even if and only if n is even.

    Outline of a proof: Since this is an "If and only if" theorem we must prove
two things:

(i) () If n2 is even, then n is even. To do this directly, assume that n2 is
    even and prove that n is even. To do this indirectly, assume n2 is even
    and that n is odd, and reach a contradiction. It turns out that the latter
    of the two approaches is easiest here.
CHAPTER 3. LOGIC                                                                            74

(ii) () If n is even, then n2 is even. To do this directly, assume that n is
     even and prove that n2 is even.

    Now that we have broken the theorem down into two parts and know what

to prove, we proceed to prove the two implications. The final ingredient that

we need is a convenient way of describing even integers. When we refer to

an integer n (or m, or k,. . . ) as even, we can always replace it with a

product of the form 2q, where q is an integer (more precisely, (q)Z(n = 2q)).

In other words, for an integer to be even it must have a factor of two in its

prime decomposition.                                                                          

                     
Example 3.9.3 2 is irrational. Our final example will be an outline of

the proof that the square root of 2 is irrational (not an element of Q). This is
an example of the theorem that does not appear to be in the standard P  C

form. One way to rephrase the theorem is: If x is a rational number, then

x2 = 2. A direct proof of this theorem would require that we verify that the

square of every rational number is not equal to 2. There is no convenient way

of doing this, so we must turn to the indirect method of proof. In such a proof,

we assume that x is a rational number and that x2 = 2. This will lead to a

contradiction. In order to reach this contradiction, we need to use the following

facts:

    · A rational number is a quotient of two integers.

    · Every fraction can be reduced to lowest terms, so that the numerator
       and denominator have no common factor greater than 1.

    · If n is an integer, n2 is even if and only if n is even.

                                                                                              

3.9.3 Exercises

1. Prove that the sum of two odd positive integers is an even positive integer.
      You might want to read Example 3.9.1 before attempting this.

2. Write out a complete proof that if n is an integer, n2 is even if and only
      if n is even.
                                                   

3. Write out a complete proof that 2 is irrational.

4. Prove that the cube root of 2 is an irrational number.

5.      Prove  that  if  x  and  y  are  real  numbers  such  that  x  +  y    1,  then  x    1
                                                                                              2
    or y  12 .
Chapter 4

More on Sets

In this chapter we shall look more closely at some basic facts about sets. One
question we could ask ourselves is: Can we manipulate sets similarly to the
way we manipulated expressions in basic algebra, or to the way we manipulated
propositions in logic? In basic algebra we are aware that a·(b+c) = a·b+a·c for
all real numbers a, b, and c. In logic we verified an analogue of this statement,
namely, p  (q  r)  (p  q)  (p  r)), where p, q, and r were arbitrary
propositions. If A, B, and C are arbitrary sets, is A(BC) = (AB)(AC)?
How do we convince ourselves of it is truth, or discover that it is false? Let
us consider some approaches to this problem, look at their pros and cons, and
determine their validity. Later in this chapter, we introduce partitions of sets
and minsets.

4.1 Methods of Proof for Sets

If A, B, and C are arbitrary sets, is it always true that A  (B  C) = (A 
B)  (A  C)? There are a variety of ways that we could attempt to prove that
this distributive law for intersection over union is indeed true. We start with
a common "non-proof" and then work toward more acceptable methods.

4.1.1 Examples and Counterexamples

We could, for example, let A = {1, 2}, B = {5, 8, 10}, and C = {3, 2, 5}, and
determine whether the distributive law is true for these values of A, B, and C.
In doing this we will have only determined that the distributive law is true for
this one example. It does not prove the distributive law for all possible sets
A, B, and C and hence is an invalid method of proof. However, trying a few
examples has considerable merit insofar as it makes us more comfortable with
the statement in question. Indeed, if the statement is not true for the example,
we have disproved the statement.

Definition 4.1.1 Counterexample. An example that disproves a statement

is called a counterexample.         

Example 4.1.2 Disproving distributivity of addition over multi-
plication. From basic algebra we learned that multiplication is distribu-
tive over addition. Is addition distributive over multiplication? That is, is
a + (b · c) = (a + b) · (a + c) always true? If we choose the values a = 3, b = 4,
and c = 1, we find that 3 + (4 · 1) = (3 + 4) · (3 + 1). Therefore, this set of values
serves as a counterexample to a distributive law of addition over multiplication.

                             75
CHAPTER 4. MORE ON SETS                                                      76

                                                                             

4.1.2 Proof Using Venn Diagrams

In this method, we illustrate both sides of the statement via a Venn diagram
and determine whether both Venn diagrams give us the same "picture," For
example, the left side of the distributive law is developed in Figure 4.1.3 and
the right side in Figure 4.1.4. Note that the final results give you the same
shaded area.

    The advantage of this method is that it is relatively quick and mechanical.
The disadvantage is that it is workable only if there are a small number of
sets under consideration. In addition, it doesn't work very well in a static
environment like a book or test paper. Venn diagrams tend to work well if you
have a potentially dynamic environment like a blackboard or video.

Figure 4.1.3 Development of the left side of the distributive law for sets

Figure 4.1.4 Development of the right side of the distributive law for sets
CHAPTER 4. MORE ON SETS           77

4.1.3 Proof using Set-membership Tables

Let A be a subset of a universal set U and let u  U . To use this method we
note that exactly one of the following is true: u  A or u / A. Denote the
situation where u  A by 1 and that where u / A by 0. Working with two
subsets of U , A and B, and u  U , there are four possible anwers to "Where
is u?" What are they? The set-membership table for A  B is:

Table 4.1.5 Membership Table for A  B

          A B AB
          00 0
          01 1
          10 1
          11 1

    This table illustrates that u  A  B if and only if u  A or u  B.
    In order to prove the distributive law via a set-membership table, write out
the table for each side of the set statement to be proved and note that if S
and T are two columns in a table, then the set statement S is equal to the set
statement T if and only if corresponding entries in each row are the same.
    To prove A  (B  C) = (A  B)  (A  C), first note that the statement
involves three sets, A, B, and C, so there are 23 = 8 possibilities for the
membership of an element in the sets.

Table 4.1.6 Membership table to prove the distributive law of inter-
section over union

A B C B  C A  B A  C A  (B  C) (A  B)  (A  C)

000 0  0                 0  0  0

001 1  0                 0  0  0

010 1  0                 0  0  0

011 1  0                 0  0  0

100 0  0                 0  0  0

101 1  0                 1  1  1

110 1  1                 0  1  1

111 1  1                 1  1  1

    Since each entry in Column 7 is the same as the corresponding entry in
Column 8, we have shown that A  (B  C) = (A  B)  (A  C) for any sets
A, B, and C. The main advantage of this method is that it is mechanical.
The main disadvantage is that it is reasonable to use only for a relatively
small number of sets. If we are trying to prove a statement involving five sets,
there are 25 = 32 rows, which would test anyone's patience doing the work by
hand.

4.1.4 Proof Using Definitions

This method involves using definitions and basic concepts to prove the given
statement. This procedure forces one to learn, relearn, and understand basic
definitions and concepts. It helps individuals to focus their attention on the
main ideas of each topic and therefore is the most useful method of proof.
One does not learn a topic by memorizing or occasionally glancing at core
topics, but by using them in a variety of contexts. The word proof panics most
people; however, everyone can become comfortable with proofs. Do not expect
to prove every statement immediately. In fact, it is not our purpose to prove
every theorem or fact encountered, only those that illustrate methods and/or
CHAPTER 4. MORE ON SETS  78

basic concepts. Throughout the text we will focus in on main techniques of
proofs. Let's illustrate by proving the distributive law.

    Proof Technique 1. State or restate the theorem so you understand what
is given (the hypothesis) and what you are trying to prove (the conclusion).

Theorem 4.1.7 The Distributive Law of Intersection over Union. If
A, B, and C are sets, then A  (B  C) = (A  B)  (A  C).
Proof. What we can assume: A, B, and C are sets.
What we are to prove: A  (B  C) = (A  B)  (A  C).
Commentary: What types of objects am I working with: sets? real numbers?
propositions? The answer is sets: sets of elements that can be anything you
care to imagine. The universe from which we draw our elements plays no part
in the proof of this theorem.
We need to show that the two sets are equal. Let's call them the left-hand set
(LHS) and the right-hand set (RHS). To prove that LHS = RHS, we must
prove two things: (a) LHS  RHS, and (b) RHS  LHS.
To prove part a and, similarly, part b, we must show that each element of LHS
is an element of RHS. Once we have diagnosed the problem we are ready to
begin.
We must prove: (a) A  (B  C)  (A  B)  (A  C).
Let x  A  (B  C):

           x  A  (B  C)  x  A and (x  B or x  C)
                                    def. of union and intersection

                                   (x  A and x  B) or (x  A and x  C)
                                    distributive law of logic

                                   (x  A  B) or (x  A  C)
                                    def. of intersection

                                   x  (A  B)  (A  C)
                                    def. of union

We must also prove (b) (A  B)  (A  C)  A  (B  C).

    x  (A  B)  (A  C)  (x  A  B)or (x  A  C)
                                      Why?

                                    (x  A and x  B) or (x  A and x  C)
                                      Why?

                                    x  A and (x  B or x  C) .
                                      Why?

                                    x  A  (B  C)
                                      Why? 

                                                                                                  
  Proof Technique 2

(1) To prove that A  B, we must show that if x  A, then x  B.

(2) To prove that A = B, we must show:

      (a) A  B and
      (b) B  A.
CHAPTER 4. MORE ON SETS  79

    To further illustrate the Proof-by-Definition technique, let's prove the fol-
lowing theorem.

Theorem 4.1.8 Another Proof using Definitions. If A, B, and C are
any sets, then A × (B  C) = (A × B)  (A × C).
Proof. Commentary; We again ask ourselves: What are we trying to prove?
What types of objects are we dealing with? We realize that we wish to prove
two facts: (a) LHS  RHS, and (b) RHS  LHS.
To prove part (a), and similarly part (b), we'll begin the same way. Let ___ 
LHS to show ___  RHS. What should ___ be? What does a typical object
in the LHS look like?
Now, on to the actual proof.
(a) A × (B  C)  (A × B)  (A × C).
Let (x, y)  A × (B  C).

       (x, y)  A × (B  C)  x  A and y  (B  C)
                                       Why?

                                    x  A and (y  B and y  C)
                                    Why?
                                    (x  A and y  B) and (x  A and y  C)

                                       Why?
                                    (x, y)  (A × B) and (x, y)  (A × C)

                                       Why?
                                    (x, y)  (A × B)  (A × C)

                                       Why?

(b) (A × B)  (A × C)  A × (B  C).
Let (x, y)  (A × B)  (A × C).

   (x, y)  (A × B)  (A × C)  (x, y)  A × B and (x, y)  A × C
                                           Why?

                                         (x  A and y  B) and (x  A and y  C)
                                           Why?

                                         x  A and (y  B and y  C)
                                           Why?

                                         x  A and y  (B  C)
                                           Why?

                                         (x, y)  A × (B  C)
                                           Why?

                                                                                                     

4.1.5 Exercises

1. Prove the following:

         (a) Let A, B, and C be sets. If A  B and B  C, then A  C.

        (b) Let A and B be sets. Then A - B = A  Bc .

         (c) Let A, B, and C be sets. If (A  B and A  C) then A  B  C.

        (d) Let A and B be sets. A  B if and only if Bc  Ac .
CHAPTER 4. MORE ON SETS  80

         (e) Let A, B, and C be sets. If A  B then A × C  B × C.
2. For any integer k, let kZ = {k · j | j  Z}, the multiples of k.

        (a) Prove that 2Z  3Z = 6Z.
        (b) Is it true that 2Z  4Z = 8Z? Explain your answer.
3. Disprove the following, assuming A, B, and C are sets:

        (a) A - B = B - A.

        (b) A × B = B × A.

         (c) A  B = A  C implies B = C.

        (d) A  (B  C) = (A  B)  (A  C)
4. Let A, B, and C be sets. Write the following in "if . . . then . . ."

      language and prove:

        (a) x  B is a sufficient condition for x  A  B.

        (b) A  B  C =  is a necessary condition for A  B = .

         (c) A  B = B is a necessary and sufficient condition for A  B.
5. Prove by induction that if A, B1, B2, ... , Bn are sets, n  2, then

      A  (B1  B2  · · ·  Bn) = (A  B1)  (A  B2)  · · ·  (A  Bn).
6. Let A, B and C be sets. Prove or disprove:

                               A  B = , B  C =   A  C = 

4.2 Laws of Set Theory

4.2.1 Tables of Laws

The following basic set laws can be derived using either the Basic Definition
or the Set-Membership approach and can be illustrated by Venn diagrams.
CHAPTER 4. MORE ON SETS                             81

Table 4.2.1 Basic Laws of Set Theory

            (1) A  B = B  A     Commutative Laws                (1) A  B = B  A
   (2) A  (B  C) = (A  B)  C     Associative Laws      (2) A  (B  C) = (A  B)  C
(3) A  (B  C) = (A  B)  (A  C)   Distributive Laws  (3) A  (B  C) = (A  B)  (A  C)
                                   Identity Laws
         (4) A   =   A = A      Complement Laws             (4) A  U = U  A = A
              (5) A  Ac = U      Idempotent Laws                  (5) A  Ac = 
               (6) A  A = A           Null Laws                    (6) A  A = A
              (7) A  U = U       Absorption Laws                   (7) A   = 
                                 DeMorgan's Laws
           (8) A  (A  B) = A      Involution Law               (8) A  (A  B) = A
         (9) (A  B)c = Ac  Bc     (10) (Ac)c = A             (9) (A  B)c = Ac  Bc

    It is quite clear that most of these laws resemble or, in fact, are analogues
of laws in basic algebra and the algebra of propositions.

4.2.2 Proof Using Previously Proven Theorems

Once a few basic laws or theorems have been established, we frequently use
them to prove additional theorems. This method of proof is usually more effi-
cient than that of proof by Definition. To illustrate, let us prove the following
Corollary to the Distributive Law. The term "corollary" is used for theorems
that can be proven with relative ease from previously proven theorems.

Corollary 4.2.2 A Corollary to the Distributive Law of Sets. Let A
and B be sets. Then (A  B)  (A  Bc) = A.
Proof.

                           (A  B)  (A  Bc) = A  (B  Bc)
                                                        Why?

                                                      =AU .
                                                        Why?

                                                      =A
                                                        Why?

                                                                                                     

4.2.3 Proof Using the Indirect Method/Contradiction

The procedure one most frequently uses to prove a theorem in mathematics is
the Direct Method, as illustrated in Theorem 4.1.7 and Theorem 4.1.8. Occa-
sionally there are situations where this method is not applicable. Consider the
CHAPTER 4. MORE ON SETS  82

following:

Theorem 4.2.3 An Indirect Proof in Set Theory. Let A, B, C be sets.
If A  B and B  C = , then A  C = .
Proof. Commentary: The usual and first approach would be to assume A  B
and B  C =  is true and to attempt to prove A  C =  is true. To do this
you would need to show that nothing is contained in the set A  C. Think
about how you would show that something doesn't exist. It is very difficult to
do directly.
The Indirect Method is much easier: If we assume the conclusion is false and
we obtain a contradiction --- then the theorem must be true. This approach is
on sound logical footing since it is exactly the same method of indirect proof
that we discussed in Subsection 3.5.3.
Assume A  B and B  C = , and A  C = . To prove that this cannot
occur, let x  A  C.

                              x  A  C  x  A and x  C
                                              x  B and x  C.
                                             xBC

But this contradicts the second premise. Hence, the theorem is proven. 

4.2.4 Exercises

In the exercises that follow it is most important that you outline the logical
procedures or methods you use.

1.
        (a) Prove the associative law for intersection (Law 2) with a Venn dia-
              gram.
        (b) Prove DeMorgan's Law (Law 9) with a membership table.
         (c) Prove the Idempotent Law (Law 6) using basic definitions.

2.
        (a) Prove the Absorption Law (Law 8) with a membership table.
        (b) Prove the Involution Law (Law 10) using basic definitions.

3. Prove the following using the set theory laws, as well as any other theo-
      rems proved so far.

        (a) A  (B - A) = A  B
        (b) A - B = Bc - Ac
         (c) A  B, A  C =   B  C = 
        (d) A  (B - C) = (A  B) - (A  C)
         (e) A - (B  C) = (A - B)  (A - C)
4. Use previously proven theorems to prove the following.

        (a) A  (B  C)c = (A  Bc)  (A  Cc)
        (b) A  (B  (A  B)c) = 
CHAPTER 4. MORE ON SETS                                      83

         (c) (A  B)  Bc = A  Bc

        (d) A  (B - C) = (A  B) - (C - A).

5. Hierarchy of Set Operations. The rules that determine the order of
      evaluation in a set expression that involves more than one operation are
      similar to the rules for logic. In the absence of parentheses, complemen-
      tations are done first, intersections second, and unions third. Parentheses
      are used to override this order. If the same operation appears two or
      more consecutive times, evaluate from left to right. In what order are the
      following expressions performed?

(a) A  Bc  C.                         (c) A  B  Cc

        (b) A  B  C  B.
6. There are several ways that we can use to format the proofs in this

      chapter. One that should be familiar to you from Chapter 3 is illustrated
      with the following alternate proof of part (a) in Theorem 4.1.7:

Table 4.2.4 An alternate format for the proof of Theorem 4.1.7

(1)            x  A  (B  C)                         Premise

(2)  (x  A)  (x  B  C)                (1), definition of intersection

(3)  (x  A)  ((x  B)  (x  C))         (2), definition of union

(4) (x  A)  (x  B)  (x  A)  (x  C) (3), distribute  over 

(5)  (x  A  B)  (x  A  C)             (4), definition of intersection

(6)  x  (A  B)  (A  C)                (5), definition of union 

Prove part (b) of Theorem 4.1.8 and Theorem 4.2.3 using this format.

4.3 Minsets

4.3.1 Definition of Minsets

Let B1 and B2 be subsets of a set A. Notice that the Venn diagram of Fig-
ure 4.3.1 is naturally partitioned into the subsets A1, A2, A3, and A4. Further
we observe that A1, A2, A3, and A4 can be described in terms of B1 and B2
as follows:

Figure 4.3.1 Venn Diagram of Minsets
CHAPTER 4. MORE ON SETS                                                                                                 84

Table 4.3.2 Minsets generated by two sets

                                           A1          =  B1        Bc

                                                                       2

                                           A2 = B1  B2

                                           A3          =  Bc        B2

                                                             1

                                           A4          =  Bc        Bc

                                                             1         2

    Each Ai is called a minset generated by B1 and B2. We note that each
minset is formed by taking the intersection of two sets where each may be
either Bk or its complement, Bkc. Note also, given two sets, there are 22 = 4
minsets.

    Minsets are occasionally called minterms.
    The reader should note that if we apply all possible combinations of the
operations intersection, union, and complementation to the sets B1 and B2 of
Figure 1, the smallest sets generated will be exactly the minsets, the minimum
sets. Hence the derivation of the term minset.
    Next, consider the Venn diagram containing three sets, B1, B2, and B3.
Draw it right now and count the regions! What are the minsets generated by
B1, B2, and B3? How many are there? Following the procedures outlined
above, we note that the following are three of the 23 = 8 minsets. What are
the others?

Table 4.3.3 Three of the minsets generated by B1, B2, and B3

                                                 B1       B2        Bc

                                                                       3

                                                 B1       Bc        B3

                                                             2

                                                 B1       Bc        Bc

                                                             2         3

Definition 4.3.4 Minset. Let {B1, B2, . . . , Bn} be a set of subsets of set A.

Sets of the form D1  D2  · · ·  Dn, where each Di may be either Bi or Bic, is
called a minset generated by B1, B2,... and Bn.
                                                                                                                        

Example 4.3.5 A concrete example of some minsets. Consider the

following example. Let A = {1, 2, 3, 4, 5, 6} with subsets B1 = {1, 3, 5} and
B2 = {1, 2, 3}. How can we use set operations to produce a partition of A? As
a first attempt, we might try these three sets:

Table 4.3.6

                                           B1  B2 = {1, 3}

                                                 Bc    =  {2,   4,  6}

                                                    1

                                           Bc          =  {4,   5,  6}.

                                              2

      We have produced all elements of A but we have 4 and 6 repeated in two

sets.   In    place  of   Bc    and  B2c,  let's  try     Bc     B2       and    B1     Bc    ,  respectively:

                             1                               1                             2

Table 4.3.7

                                           Bc        B2   =     {2}  and

                                              1

                                           B1          Bc    =      {5}.

                                                          2

      We   have     now   produced    the  elements             1,  2,    3,  and  5  using      B1       B2,   Bc      B2

              Bc                                                                                                   1

and    B1        2   yet  we    have  not  listed      the      elements      4  and    6.    Most        ways  that    we

could combine B1 and B2 such as B1  B2 or B1  B2c will produce duplications

of listed elements and will not produce both 4 and 6. However we note that

Bc      Bc    =  {4,  6},  exactly    the  elements         we      need.

   1       2

      After more experimenting, we might reach a conclusion that each element

of  A   appears     exactly     once  in   one   of    the  four    minsets      B1    B2        ,  Bc     B2,  B1     B2c

                                                                                                       1
and B1c B2c. Hence, we have a partition of A. In fact this is the finest partition
CHAPTER 4. MORE ON SETS                                               85

of A in that all other partitions we could generate consist of selected unions of

these minsets.

At this point, we might ask and be able to answer the question "How

many different subsets of our universe can we generate from B1 and B2?" The
answer is 2number of nonempty minsets, which is 24 = 16 in this case. Notice that in

general, it would be impossible to find two sets from which we could generate

all subsets of A = {1, 2, 3, 4, 5, 6} since there will never be more than four

nonempty minsets. If we allowed ourselves three subsets and tried to generate

all sets from them, then the number of minsets would be 23 = 8. With only

six elements in A, there could be six minsets, each containing a single element.

In that case we could generate the whole power set of A.              

4.3.2 Properties of Minsets

Theorem 4.3.8 Minset Partition Theorem. Let A be a set and let B1,

B2 . . . , Bn be subsets of A. The set of nonempty minsets generated by B1, B2

. . . , Bn is a partition of A.

Proof. The proof of this theorem is left to the reader.               

One of the most significant facts about minsets is that any subset of A that

can be obtained from B1, B2 . . ., Bn, using the standard set operations can be

obtained in a standard form by taking the union of selected minsets.

Definition 4.3.9 Minset Normal Form. A set is said to be in minset

normal form when it is expressed as the union of zero or more distinct nonempty

minsets.                                                              

Notes:

   · The union of zero sets is the empty set, .

   · Minset normal form is also called canonical form.

Definition 4.3.10 Compact Minset Notation. Let {B1, B2, . . . , Bn} be
a set of subsets of set A. If b is equal to 0 or 1 and C is any set, then C(b)
is defined to be C if b = 1 and Cc if b = 0. Then we can denote a minset
compactly as an expression Mb1b2...bn where

                             Mb1b2...bn = B1b1  B2b2  · · ·  Bbnn

Example 4.3.11 Another Concrete Example of Minsets.                            
{-2, -1, 0, 1, 2}, B1 = {0, 1, 2}, and B2 = {0, 2}. Then              Let U =

Table 4.3.12

                     M11 = B1  B2 = {0, 2}

                                 M01  =     Bc      B2    =  

                                               1

                                 M10  =     B1      Bc    =  {1}

                                                       2

                     M00         =    Bc      Bc    =     {-2,  -1}

                                         1       2

In this case, there are only three nonempty minsets, producing the partition

{{0, 2}, {1}, {-2, -1}}. An example of a set that could not be produced from

just B1 and B2 is the set of even elements of U , {-2, 0, 2}. This is because

-2 and -1 cannot be separated. They are in the same minset and any union

of minsets either includes or excludes them both. In general, there are 23 = 8

different minset normal forms because there are three nonempty minsets. This

means that only 8 of the 25 = 32 subsets of U could be generated from any

two sets B1 and B2.                                                   
CHAPTER 4. MORE ON SETS    86

4.3.3 Exercises

1. Consider the subsets A = {1, 7, 8}, B = {1, 6, 9, 10}, and C = {1, 9, 10},
      where U = {1, 2, ..., 10}.

        (a) List the nonempty minsets generated by A, B, and C.

        (b) How many elements of the power set of U can be generated by A,
              B, and C? Compare this number with | P(U ) |. Give an example
              of one subset that cannot be generated by A, B, and C.

2.

        (a) Partition {1, 2, ....9} into the minsets generated by B1 = {5, 6, 7},
              B2 = {2, 4, 5, 9}, and B3 = {3, 4, 5, 6, 8, 9}.

        (b) How many different subsets of {1, 2, ..., 9} can you create using
              B1, B2, and B3 with the standard set operations?

         (c) Do there exist subsets C1, C2, C3 whose minsets will generate every
              subset of {1, 2, ..., 9}?

3. Partition the set of strings of 0's and 1's of length two or less, using
      the minsets generated by B1 = {s | s has length 2}, and B2 = {s |
      s starts with a 0}.

4. Let B1, B2, and B3 be subsets of a universal set U ,

        (a) Symbolically list all minsets generated by B1, B2, and B3.

        (b) Illustrate with a Venn diagram all minsets obtained in part (a).

         (c) Express the following sets in minset normal form: B1c, B1  B2 ,
              B1  B2c.

5.

        (a) Partition A = {0, 1, 2, 3, 4, 5} with the nonempty minsets generated
              by B1 = {0, 2, 4} and B2 = {1, 5}.

        (b) How many different subsets of A can you generate from B1 and B2?
6. If {B1, B2, . . . , Bn} is a partition of A, how many minsets are generated

      by B1, B2, . . . , Bn?
7. Prove Theorem 4.3.8

4.4 The Duality Principle

4.4.1

In Section 4.2, we observed that each of the Table 4.2.1 labeled 1 through 9
had an analogue 1 through 9. We notice that each of the laws in one column
can be obtained from the corresponding law in the other column by replacing
 by ,  by ,  by U , U by , and leaving the complement unchanged.

Definition 4.4.1 Duality Principle for Sets. Let S be any identity in-

volving sets and the operations complement, intersection and union. If S is

obtained from S by making the substitutions   ,   ,   U , and

U  , then the statement S is also true and it is called the dual of the

statement S.               
CHAPTER 4. MORE ON SETS          87

Example 4.4.2 Example of a dual. The dual of (A  B)  (A  Bc) = A

is (A  B)  (A  Bc) = A.          

One should not underestimate the importance of this concept. It gives us

a whole second set of identities, theorems, and concepts. For example, we can

consider the dual of minsets and minset normal form to obtain what is called

maxsets and maxset normal form.

4.4.2 Exercises

1. State the dual of each of the following:

        (a) A  (B  A) = A.
        (b) A  ((Bc  A)  B)c = U
         (c) (A  Bc)c  B = Ac  B
2. Examine Table 3.4.3 and then write a description of the principle of
      duality for logic.
3. Write the dual of each of the following:

        (a) p  ¬((¬q  p)  q)  1

        (b) (¬(p  (¬q))  q)  (¬p  q).
4. Use the principle of duality and the definition of minset to write the

      definition of maxset.
5. Let A = {1, 2, 3, 4, 5, 6} and let B1 = {1, 3, 5} and B2 = {1, 2, 3}.

        (a) Find the maxsets generated by B1 and B2. Note the set of maxsets
              does not constitute a partition of A. Can you explain why?

        (b) Write out the definition of maxset normal form.

         (c) Repeat Exercise 4.3.3.4 for maxsets.
6. What is the dual of the expression in Exercise 4.1.5.5 ?
Chapter 5

Introduction to Matrix Al-
gebra

                               diagonal matrix

                          "It's totally right what you say, Trix,
                                That in a diagonal matrix
                                   You'll find," Al confirms,
                                      "Off-diagonal terms

                       Are all zero. Now bug off and play, Trix!"

         Bob Egg, The Omnificent English Dictionary In Limerick Form

The purpose of this chapter is to introduce you to matrix algebra, which has
many applications. You are already familiar with several algebras: elementary
algebra, the algebra of logic, the algebra of sets. We hope that as you studied
the algebra of logic and the algebra of sets, you compared them with elementary
algebra and noted that the basic laws of each are similar. We will see that
matrix algebra is also similar. As in previous discussions, we begin by defining
the objects in question and the basic operations.

5.1 Basic Definitions and Operations

5.1.1 Matrix Order and Equality

Definition 5.1.1  matrix. A matrix is a rectangular array of elements of the
form
                   a11 a12 a13 · · · a1n 

                          a21  a22      a23  ···  a2n  
                                                       
                          a31  a32      a33  ···  a3n  
                  A=                                   
                           ..   ..      .. . .    ..   
                          .    .        .       ..     

                          am1 am2 am3 · · · amn

                                                                                                     
    A convenient way of describing a matrix in general is to designate each

entry via its position in the array. That is, the entry a34 is the entry in the
third row and fourth column of the matrix A. Depending on the situation, we

will decide in advance to which set the entries in a matrix will belong. For

example, we might assume that each entry aij (1  i  m, 1  j  n) is a real

                                    88
CHAPTER 5. INTRODUCTION TO MATRIX ALGEBRA                     89

number. In that case we would use Mm×n(R) to stand for the set of all m by
n matrices whose entries are real numbers. If we decide that the entries in a
matrix must come from a set S, we use Mm×n(S) to denote all such matrices.

Definition 5.1.2 The Order of a Matrix. A matrix A that has m rows

and n columns is called an m × n (read "m by n") matrix, and is said to have

order m × n.                                                  

  Since it is rather cumbersome to write out the large rectangular array above

each time we wish to discuss the generalized form of a matrix, it is common

practice to replace the above by A = (aij). In general, matrices are often given

names that are capital letters and the corresponding lower case letter is used

for individual entries. For example the entry in the third row, second column

of a matrix called C would be c32.

Example 5.1.3       Orders of Some Matrices.  A=    23        ,B=
                                                    0 -5
                                    
    0                     125

  1    , and D =  6       -2    3  are 2 × 2, 3 × 1, and 3 × 3 matrices,
  2

  15                      428

respectively.                                                 

  Since we now understand what a matrix looks like, we are in a position

to investigate the operations of matrix algebra for which users have found the

most applications.

  First we ask ourselves: Is the matrix A = 1 2 equal to the matrix
                                                               34

B=    1 2 ? No, they are not because the corresponding entries in the
      35

second row, second column of the two matrices are not equal.

  Next, is A =         123      equal to B =  1 2 ? No, although the
                       456                    45

corresponding entries in the first two columns are identical, B doesn't have a

third column to compare to that of A. We formalize these observations in the

following definition.

Definition 5.1.4 Equality of Matrices. A matrix A is said to be equal to
matrix B (written A = B) if and only if:

(1) A and B have the same order, and

(2) all corresponding entries are equal: that is, aij = bij for all appropriate
     i and j.

                                                              

5.1.2 Matrix Addition and Scalar Multiplication

The first two operations we introduce are very natural and are not likely cause

much confusion. The first is matrix addition. It seems natural that if A =

  10           and B =     34       , then
  2 -1                    -5 2

               A+B = 1+3 0+4 = 4 4 .
                          2 - 5 -1 + 2        -3 1

  However, if A =       123         and B =   3 0 , is there a natural way
                        012                   28
CHAPTER 5. INTRODUCTION TO MATRIX ALGEBRA        90

to add them to give us A + B? No, the orders of the two matrices must be
identical.

Definition 5.1.5 Matrix Addition. Let A and B be m × n matrices. Then
A + B is an m × n matrix where (A + B)ij = aij + bij (read "The ith jth entry
of the matrix A + B is obtained by adding the ith jth entry of A to the ith jth
entry of B"). If the orders of A and B are not identical, A + B is not defined.

                                                                                                     
    In short, A + B is defined if and only if A and B are of the same order.
    Another frequently used operation is that of multiplying a matrix by a
number, commonly called a scalar in this context. Scalars normally come from
the same set as the entries in a matrix. For example, if A  Mm×n(R), a scalar
can be any real number.

Example 5.1.6 A Scalar Product. If c = 3 and if A = 1 -2 and
                                                                                     35

we wish to find cA, it seems natural to multiply each entry of A by 3 so that

3A =  3 -6 , and this is precisely the way scalar multiplication is defined.
      9 15

                                                 

Definition 5.1.7 Scalar Multiplication. Let A be an m × n matrix and c

a scalar. Then cA is the m × n matrix obtained by multiplying c times each

entry of A; that is (cA)ij = caij.               

5.1.3 Matrix Multiplication

A definition that is more awkward to motivate is the product of two matrices.
See Exercise 5.1.4.8 for an attempt to do so. In time, the reader will see that
the following definition of the product of matrices will be very useful, and will
provide an algebraic system that is quite similar to elementary algebra.

Definition 5.1.8 Matrix Multiplication. Let A be an m × n matrix and
let B be an n × p matrix. The product of A and B, denoted by AB, is an m × p
matrix whose ith row jth column entry is

      (AB)ij = ai1b1j + ai2b2j + · · · + ainbnj

                           n

                = aikbkj

                        k=1

for 1  i  m and 1  j  p.                         

The mechanics of computing one entry in the product of two matrices is

illustrated in Figure 5.1.9.
CHAPTER 5. INTRODUCTION TO MATRIX ALGEBRA                      91

Figure 5.1.9 Computation of one entry in the product of two 3 by 3 matrices

The computation of a product can take a considerable amount of time in

comparison to the time required to add two matrices. Suppose that A and B

are n×n matrices; then (AB)ij is determined performing n multiplications and

n-1 additions. The full product takes n3 multiplications and n3 -n2 additions.

This compares with n2 additions for the sum of two n×n matrices. The product

of two 10 by 10 matrices will require 1,000 multiplications and 900 additions,

clearly a job that you would assign to a computer. The sum of two matrices

requires a more modest 100 additions. This analysis is based on the assumption

that matrix multiplication will be done using the formula that is given in the

definition. There are more advanced methods that, in theory, reduce operation

counts. For example, Strassen's algorithm (en.wikipedia.org/wiki/Strassen_

algorithm) computes the product of two n by n matrices in 7·7log2 n-6·4log2 n 

7n2.808 operations. There are practical issues involved in actually using the

algorithm in many situations. For example, round-off error can be more of a

problem than with the standard formula.

                                                  10    

Example 5.1.10 A Matrix Product. Let A =  3 2 , a 3×2 matrix,

                                                  -5 1

and let B =  6 , a 2 × 1 matrix. Then AB is a 3 × 1 matrix:
             1

               10                        1·6+0·1          6  

AB =  3 2  1           6 =  3 · 6 + 2 · 1  =  20 

               -5 1      -5 · 6 + 1 · 1                 -29

                                                                                                  
  Remarks:

(1) The product AB is defined only if A is an m × n matrix and B is an n × p
     matrix; that is, the two "inner" numbers must be equal. Furthermore,
CHAPTER 5. INTRODUCTION TO MATRIX ALGEBRA                      92

the order of the product matrix AB is the "outer" numbers, in this case
m × p.

(2) It is wise to first determine the order of a product matrix. For example,

if A is a 3 × 2 matrix and B is a 2 × 2 matrix, then AB is a 3 × 2 matrix

of the form                                         
                                          c11  c12
                                               c22 
                              AB =  c21

                                   c31 c32

Then to obtain, for example, c31, we multiply corresponding entries in
the third row of A times the first column of B and add the results.

Example 5.1.11    Multiplication with a diagonal matrix. Let

A=          -1 0  and B =                      3 10 .     Then AB =
             03                                21

-1 · 3 + 0 · 2 -1 · 10 + 0 · 1 = -3 -10
0 · 3 + 3 · 2 0 · 10 + 3 · 1       63

The net effect is to multiply the first row of B by -1 and the second row

of B by 3.

Note: BA =        -3 30       = AB. The columns of B are multiplied by -1
                  -2 3

and 3 when the order is switched.                                  

Remarks:

· An n × n matrix is called a square matrix.

· If A is a square matrix, AA is defined and is denoted by A2 , and AAA =
   A3, etc.

· The m × n matrices whose entries are all 0 are denoted by 0m×n, or
   simply 0, when no confusion arises regarding the order.

5.1.4 Exercises

1. Let A = 1 -1 , B = 0 1 , and C = 0 1 -1
             23                    3 -5                3 -2 2

(a) Compute AB and BA.

(b) Compute A + B and B + A.

(c) If c = 3, show that c(A + B) = cA + cB.

(d) Show that (AB)C = A(BC).

(e) Compute A2C.

    (f) Compute B + 0.

(g) Compute A02×2 and 02×2A, where 02×2 is the 2 × 2 zero matrix.

(h) Compute 0A, where 0 is the real number (scalar) zero.

    (i) Let c = 2 and d = 3. Show that (c + d)A = cA + dA.

                  102                            023      

2. Let A =  2 -1 5  , B =  1 1 2  , and C =

                  321                            -1 3 -2
CHAPTER 5. INTRODUCTION TO MATRIX ALGEBRA                           93

      2 1 23     

     4 0 1 1  Compute, if possible;

      3 -1 4 1

    (a) A - B                       (e) CA - CB

    (b) AB                                 
    (c) AC - BC                                x
    (d) A(BC)
                                           y
                                    (f)    C              
                                               z          

                                               w

3. Let A = 2 0 . Find a matrix B such that AB = I and BA = I,
                       03

    where I =  10 .
               01

4. Find AI and BI where I is as in Exercise 3, where A = 1 8 and
                                                                                       95

    B = -2 3 . What do you notice?
               5 -7

                   100     

5. Find A3 if A =  0 2 0  . What is A15 equal to?

                   003

6.

                                    100    

    (a) Determine I2 and I3 if I =  0 1 0 .

                                    001

    (b) What is In equal to for any n  1?

         (c) Prove your answer to part (b) by induction.
7.

    (a) If

               A = 2 1 , X = x1 , and B = 3 ,
                     1 -1           x2                        1

      show that AX = B is a way of expressing the system 2x1 + x2 = 3
                                                                             x1 - x2 = 1

      using matrices.

    (b) Express the following systems of equations using matrices:

      (i) 2x1 - x2 = 4                     x1 + x2            =3
            x1 + x2 = 0
                                    (iii)                 x2  =5

               x1 + x2 + 2x3 = 1           x1 + 3x3 = 6

      (ii) x1 + 2x2 - x3 = -1

                       x1 + 3x2 + x3 = 5
8. In this exercise, we propose to show how matrix multiplication is a nat-

    ural operation. Suppose a bakery produces bread, cakes and pies every

    weekday, Monday through Friday. Based on past sales history, the bakery

    produces various numbers of each product each day, summarized in the

    5 × 3 matrix D. It should be noted that the order could be described as
CHAPTER 5. INTRODUCTION TO MATRIX ALGEBRA         94

"number of days by number of products." For example, on Wednesday
(the third day) the number of cakes (second product in our list) that are
produced is d3,2 = 4.

                                    25 5 5 

                                     14  5  8
                                               
                  D      =           20  4  15  
                                                
                                    18 5 7 

                                     35 10 9

The main ingredients of these products are flour, sugar and eggs. We

assume that other ingredients are always in ample supply, but we need

to be sure to have the three main ones available. For each of the three

products, The amount of each ingredient that is needed is summarized in

the 3 × 3, or "number of products by number of ingredients" matrix P .

For example, to bake a cake (second product) we need P2,1 = 1.5 cups of

flour (first ingredient). Regarding units: flour and sugar are given in cups

per unit of each product, while eggs are given in individual eggs per unit

of each product.                                

                                     2 0.5 0

                  P =  1.5 1 2 

                                     1 11

These amounts are "made up", so don't used them to do your own baking!

(a) How many cups of flour will the bakery need every Monday? Pay
     close attention to how you compute your answer and the units of
     each number.

(b) How many eggs will the bakery need every Wednesday?

(c) Compute the matrix product DP . What do you notice?

(d) Suppose the costs of ingredients are $0.12 for a cup of flour, $0.15
     for a cup of sugar and $0.19 for one egg. How can this information
     be put into a matrix that can meaningfully be multiplied by one of
     the other matrices in this problem?

5.2 Special Types of Matrices

5.2.1 Diagonal Matrices

We have already investigated, in exercises in the previous section, one special
type of matrix. That was the zero matrix, and found that it behaves in matrix
algebra in an analogous fashion to the real number 0; that is, as the additive
identity. We will now investigate the properties of a few other special matrices.

Definition 5.2.1 Diagonal Matrix. A square matrix D is called a diagonal

matrix if dij = 0 whenever i = j.                 
CHAPTER 5. INTRODUCTION TO MATRIX ALGEBRA                                  95

                                                            100          

Example 5.2.2 Some diagonal matrices. A =  0 2 0 , B =

                                                            005

  30 0                     100

 0 0 0 , and I =  0 1 0  are all diagonal matrices.                        

  0 0 -5                   001

5.2.2 The Identity Matrix and Matrix Inverses

In the example above, the 3 × 3 diagonal matrix I whose diagonal entries are
all 1's has the distinctive property that for any other 3 × 3 matrix A we have
AI = IA = A. For example:

Example 5.2.3 Multiplying by the Identity Matrix. If A =
  12 5                          12 5                        12 5

 6 7 -2 , then AI =  6 7 -2  and IA =  6 7 -2 .

  3 -3 0                        3 -3 0                      3 -3 0

                                                                                                  
  In other words, the matrix I behaves in matrix algebra like the real number

1; that is, as a multiplicative identity. In matrix algebra, the matrix I is called

simply the identity matrix. Convince yourself that if A is any n × n matrix

AI = IA = A.

Definition 5.2.4 Identity Matrix. The n × n diagonal matrix In whose

diagonal components are all 1's is called the identity matrix. If the context is

clear, we simply use I.                                                    

  In the set of real numbers we recall that, given a nonzero real number x,

there exists a real number y such that xy = yx = 1. We know that real numbers

commute under multiplication so that the two equations can be summarized

as xy = 1. Further we know that y = x-1 = 1x . Do we have an analogous
situation in Mn×n(R)? Can we define the multiplicative inverse of an n × n
matrix A? It seems natural to imitate the definition of multiplicative inverse

in the real numbers.

Definition 5.2.5 Matrix Inverse. Let A be an n × n matrix. If there exists

an n × n matrix B such that AB = BA = I, then B is a multiplicative inverse

of A (called simply an inverse of A) and is denoted by A-1                 

  When we are doing computations involving matrices, it would be helpful to

know that when we find A-1, the answer we obtain is the only inverse of the

given matrix. This would let us refer to the inverse of a matrix. We refrained

from saying that in the definition, but the theorem below justifies it.

  Remark: Those unfamiliar with the laws of matrix algebra should return

to the following proof after they have familiarized themselves with the Laws of

Matrix Algebra in Section 5.5.

Theorem 5.2.6 Inverses are unique. The inverse of an n × n matrix A,
when it exists, is unique.
Proof. Let A be an n × n matrix. Assume to the contrary, that A has two
(different) inverses, say B and C. Then

        B = BI Identity property of I
           = B(AC) Assumption that C is an inverse of A
           = (BA)C Associativity of matrix multiplication
           = IC Assumption that B is an inverse of A
           = C Identity property of I
CHAPTER 5. INTRODUCTION TO MATRIX ALGEBRA                         96

Let A =             20                                                                           
                    03      . What is A-1 ? Without too much difficulty, by trial

and error, we determine that A-1 =  12 0           . This might lead us to guess

                                           1
                                    03
that the inverse is found by taking the reciprocal of all nonzero entries of a

matrix. Alas, it isn't that easy!

If A =         12           , the "reciprocal rule" would tell us that the inverse of
              -3 5

A is B =      11         . Try computing AB and you will see that you don't get
                    2
              -1    1

                         35

the identity matrix. So, what is A-1? In order to understand more completely

the notion of the inverse of a matrix, it would be beneficial to have a formula

that would enable us to compute the inverse of at least a 2 × 2 matrix. To do
this, we introduce the definition of the determinant of a 2 × 2 matrix.

Definition 5.2.7 Determinant of a 2 by 2 matrix. Let A =          ab .
                                                                  cd

The determinant of A is the number det A = ad - bc.               

In addition to det A, common notation for the determinant of matrix A is

|A|. This is particularly common when writing out the whole matrix, which

case we would write a b for the determinant of the general 2 × 2 matrix.
                              cd

Example 5.2.8 Some determinants of two by two matrices.           If A =
                                                                     then
1 2 then det A = 1 · 5 - 2 · (-3) = 11. If B = 1 2                      
-3 5                                                          24

det B = 1 · 4 - 2 · 2 = 0.

Theorem 5.2.9 Inverse of 2 by 2 matrix. Let A =               a b . If
                                                              cd

det A  =  0,  then  A-1  =     1    d -b .
                            det A  -c a

Proof. See Exercise 4 at the end of this section.                 

Example 5.2.10 Finding Inverses. Can we find the inverses of the matrices

in Example 5.2.8? If A = 1 2 then
                                      -3 5

                       A-1 = 1     5 -2 =     115 - 112
                                                   3  1
                            11 3 1
                                              11 11

The reader should verify that AA-1 = A-1A = I.

The second matrix, B, has a determinant equal to zero. If we tried to apply

the formula in Theorem 5.2.9, we would be dividing by zero. For this reason,

the formula can't be applied and in fact B-1 does not exist.      

Remarks:

· In general, if A is a 2 × 2 matrix and if det A = 0, then A-1 does not
   exist.

· A formula for the inverse of n × n matrices n  3 can be derived that
   also involves det A. Hence, in general, if the determinant of a matrix is
   zero, the matrix does not have an inverse. However the formula for even
   a 3 × 3 matrix is very long and is not the most efficient way to compute
   the inverse of a matrix.
CHAPTER 5. INTRODUCTION TO MATRIX ALGEBRA                           97

    · In Chapter 12 we will develop a technique to compute the inverse of a
       higher-order matrix, if it exists.

    · Matrix inversion comes first in the hierarchy of matrix operations; there-
       fore, AB-1 is A(B-1).

5.2.3 Exercises

1. For the given matrices A find A-1 if it exists and verify that AA-1 =
      A-1A = I. If A-1 does not exist explain why.

    (a) A = 1 3
                   21

    (b) A =  6 -3
             8 -4

    (c) A =  1 -3
             01

    (d) A = 1 0
                   01

    (e) Use the definition of the inverse of a matrix to find A-1:  A=
                       
      30 0

     0 12 0 

      0 0 -5

2. For the given matrices A find A-1 if it exists and verify that AA-1 =
      A-1A = I. If A-1 does not exist explain why.

    (a) A =   2 -1
             -1 2

    (b) A = 0 1
                   02

    (c) A =  1c
             01

    (d) A =  a b , where |a| = |b|.
             ba

3.

    (a) Let A =        23  and B =   3 -3 . Verify that (AB)-1 =
         B-1A-1.       14            21

    (b) Let A and B be n × n invertible matrices. Prove that (AB)-1 =
         B-1A-1. Why is the right side of the above statement written

         "backwards"? Is this necessary? Hint: Use Theorem 5.2.6

4. Let A = a b . Derive the formula for A-1.
                       cd

5. Linearity of Determinants.

    (a) Let A and B be 2-by-2 matrices. Show that det(AB) =
CHAPTER 5. INTRODUCTION TO MATRIX ALGEBRA                         98

(det A)(det B).

(b) It can be shown that the statement in part (a) is true for all
     n × n matrices. Let A be any invertible n × n matrix. Prove that
     det A-1 = (det A)-1. Note: The determinant of the identity ma-
     trix In is 1 for all n.

(c) Verify that the equation in part (b) is true for the matrix in exercise
     1(a) of this section.

6. Prove by induction that for n  1,                n  =  an 0n.

                                      a0

                                      0b                  0b

7. Use the assumptions in Exercise 5.2.3.5 to prove by induction that if
      n  1, det (An) = (det A)n.

8. Prove: If the determinant of a matrix A is zero, then A does not have an
      inverse. Hint: Use the indirect method of proof and exercise 5.

9.

(a) Let A, B, and D be n × n matrices. Assume that B is invertible. If
     A = BDB-1 , prove by induction that Am = BDmB-1 is true for

     m  1.

(b) Given that A =  -8 15             =B  10              B-1 where B =
                    -6 11                 02

53              what is A10?
32

5.3 Laws of Matrix Algebra

5.3.1 The Laws

The following is a summary of the basic laws of matrix operations. Assume that
the indicated operations are defined; that is, that the orders of the matrices A,
B and C are such that the operations make sense.

Table 5.3.1 Laws of Matrix Algebra

            (1) Commutative Law of Addition                                  A+B =B+A
              (2) Associative Law of Addition
                                                                     A + (B + C) = (A + B) + C
    (3) Distributive Law of a Scalar over Matrices               c(A + B) = cA + cB, where c  R.
     (4) Distributive Law of Scalars over a Matrix          (c1 + c2) A = c1A + c2A, where c1, c2  R.
     (5) Associative Law of Scalar Multiplication             c1 (c2A) = (c1 · c2) A, where c1, c2  R.
                                                                0A = 0, where 0 is the zero matrix.
        (6) Zero Matrix Annihilates all Products          0A = 0, where 0 on the left is the scalar zero.
        (7) Zero Scalar Annihilates all Products
      (8) Zero Matrix is an identity for Addition                               A + 0 = A.
         (9) Negation produces additive inverses                             A + (-1)A = 0.
(10) Right Distributive Law of Matrix Multiplication                    (B + C)A = BA + CA.
 (11) Left Distributive Law of Matrix Multiplication                    A(B + C) = AB + AC.
         (12) Associative Law of Multiplication                             A(BC) = (AB)C.
   (13) Identity Matrix is a Multiplicative Identity                      IA = A and AI = A.
                                                                     If A-1 exists, A-1 -1 = A.
           (14) Involution Property of Inverses             If A-1 and B-1 exist, (AB)-1 = B-1A-1
                (15) Inverse of Product Rule
CHAPTER 5. INTRODUCTION TO MATRIX ALGEBRA                            99

5.3.2 Commentary

Example 5.3.2 More Precise Statement of one Law. If we wished to
write out each of the above laws more completely, we would specify the orders
of the matrices. For example, Law 10 should read:

Let A, B, and C be m × n, n × p, and n × p matrices, respectively,
then A(B + C) = AB + AC

                                                                                                
Remarks:

· Notice the absence of the "law" AB = BA. Why?

   · Is it really necessary to have both a right (No. 11) and a left (No. 10)
       distributive law? Why?

5.3.3 Exercises

1. Rewrite the above laws specifying as in Example 5.3.2 the orders of the
      matrices.

2. Verify each of the Laws of Matrix Algebra using examples.

3. Let A = 1 2 , B = 3 7 6 , and C = 0 -2 4 .
        0 -1        2 -1 5                       711

Compute the following as efficiently as possible by using any of the Laws

of Matrix Algebra:

(a) AB + AC
(b) A-1

(c) A(B + C)
(d) A2 -1

(e) (C + B)-1A-1

4. Let A = 7 4 and B = 3 5 . Compute the following as
        21          24

efficiently as possible by using any of the Laws of Matrix Algebra:

(a) AB

        (b) A + B

         (c) A2 + AB + BA + B2

        (d) B-1A-1

         (e) A2 + BA
5. Let A and B be n × n matrices of real numbers. Is A2 - B2 = (A -

      B)(A + B)? Explain.

5.4 Matrix Oddities

5.4.1 Dissimilarities with elementary algebra

We have seen that matrix algebra is similar in many ways to elementary algebra.
Indeed, if we want to solve the matrix equation AX = B for the unknown X,
CHAPTER 5. INTRODUCTION TO MATRIX ALGEBRA                      100

we imitate the procedure used in elementary algebra for solving the equation
ax = b. One assumption we need is that A is a square matrix that has an
inverse. Notice how exactly the same properties are used in the following
detailed solutions of both equations.

Table 5.4.1

Equation in the algebra of real numbers  Associative Property     Equation in matrix algebra
                                           Inverse Property
                      ax = b               Identity Property                  AX = B
          a-1(ax) = a-1b if a = 0                              A-1(AX) = A-1B if A-1 exists

                 a-1a x = a-1b                                          A-1A X = A-1B
                   1x = a-1b                                                IX = A-1B
                    x = a-1b                                                X = A-1B

    Certainly the solution process for solving AX = B is the same as that of
solving ax = b.

    The solution of xa = b is x = ba-1 = a-1b. In fact, we usually write
the solution of both equations as x = ba . In matrix algebra, the solution of
XA = B is X = BA-1 , which is not necessarily equal to A-1B. So in matrix
algebra, since the commutative law (under multiplication) is not true, we have
to be more careful in the methods we use to solve equations.

    It is clear from the above that if we wrote the solution of AX = B as
X = BA , we would not know how to interpret BA . Does it mean A-1B or
BA-1? Because of this, A-1 is never written as IA .

Observation 5.4.2 Matrix Oddities. Some of the main dissimilarities
between matrix algebra and elementary algebra are that in matrix algebra:

(1) AB may be different from BA.

(2) There exist matrices A and B such that AB = 0, and yet A = 0 and
     B = 0.

(3) There exist matrices A where A = 0, and yet A2 = 0.
(4) There exist matrices A where A2 = A with A = I and A = 0
(5) There exist matrices A where A2 = I, where A = I and A = -I

5.4.2 Exercises

1. Discuss each of the "Matrix Oddities" with respect to elementary algebra.
2. Determine 2 × 2 matrices which show that each of the "Matrix Oddities"

      are true.
3. Prove or disprove the following implications.

        (a) A2 = A and det A = 0  A = I

        (b) A2 = I and det A = 0  A = I or A = -I.
4. Let Mn×n(R) be the set of real n × n matrices. Let P  Mn×n(R) be the

      subset of matrices defined by A  P if and only if A2 = A. Let Q  P be
      defined by A  Q if and only if det A = 0.

        (a) Determine the cardinality of Q.

        (b) Consider the special case n = 2 and prove that a sufficient condition
              for A  P  M2×2(R) is that A has a zero determinant (i.e., A is
CHAPTER 5. INTRODUCTION TO MATRIX ALGEBRA                     101

              singular) and tr(A) = 1 where tr(A) = a11 + a22 is the sum of the
              main diagonal elements of A.

         (c) Is the condition of part b a necessary condition?
5. Write each of the following systems in the form AX = B, and then solve

      the systems using matrices.

(a) 2x1 + x2 = 3                 (d) 2x1 + x2 = 1
       x1 - x2 = 1                      x1 - x2 = -1

        (b) 2x1 - x2 = 4         (e) 3x1 + 2x2 = 1
                x1 - x2 = 0            6x1 + 4x2 = -1

         (c) 2x1 + x2 = 1
                x1 - x2 = 1

6. For those who know calculus:

(a) Write the series expansion for ea centered around a = 0.

(b) Use the idea of exercise 6 to write what would be a plausible defini-
     tion of eA where A is an n × n matrix.

(c) If A = 1 1 and B = 0 -1 , use the series in part (b)
00                               00

to show that eA =     e e - 1 and eB =  1 -1 .
                      01                01

(d) Show that eAeB = eBeA.

(e) Show that eA+B =  e0 .
                      01

(f) Is eAeB = eA+B?
Chapter 6

Relations

                              adjacency matrix

                             An adjacency matrix will show
                            Where the edges 'tween vertices go.

                                    For a nice simple graph
                               You can cut through the chaff:
                          Noughts and ones in symmetrical flow.

           psheil, The Omnificent English Dictionary In Limerick Form

One understands a set of objects completely only if the structure of that set
is made clear by the interrelationships between its elements. For example,
the individuals in a crowd can be compared by height, by age, or through
any number of other criteria. In mathematics, such comparisons are called
relations. The goal of this chapter is to develop the language, tools, and
concepts of relations.

6.1 Basic Definitions

In Chapter 1 we introduced the concept of the Cartesian product of sets. Let's
assume that a person owns three shirts and two pairs of slacks. More precisely,
let A = {blue shirt, tan shirt, mint green shirt} and B = {grey slacks, tan slacks}.
Then A × B is the set of all six possible combinations of shirts and slacks that
the individual could wear. However, an individual may wish to restrict himself
or herself to combinations which are color coordinated, or "related." This may
not be all possible pairs in A × B but will certainly be a subset of A × B. For
example, one such subset may be

{(blue shirt, grey slacks), (blue shirt, tan slacks), (mint green shirt, tan slacks)}.

6.1.1 Relations between two sets

Definition 6.1.1 Relation. Let A and B be sets. A relation from A into B

is any subset of A × B.                          

Example 6.1.2 A simple example. Let A = {1, 2, 3} and B = {4, 5}.

Then {(1, 4), (2, 4), (3, 5)} is a relation from A into B. Of course, there are

many others we could describe; 64, to be exact.  

                         102
CHAPTER 6. RELATIONS                                                                  103

Example 6.1.3 Divisibility Example. Let A = {2, 3, 5, 6} and define a rela-
tion r from A into A by (a, b)  r if and only if a divides evenly into b. The set of
pairs that qualify for membership is r = {(2, 2), (3, 3), (5, 5), (6, 6), (2, 6), (3, 6)}.

                                                                                                    

6.1.2 Relations on a Set

Definition 6.1.4 Relation on a Set. A relation from a set A into itself is

called a relation on A.                                                                    

The relation "divides" in Example 6.1.3 will appear throughout the book.

Here is a general definition on the whole set of integers.

Definition 6.1.5 Divides. Let a, b  Z, a = 0. We say that a divides b,
denoted a | b, if and only if there exists an integer k such that ak = b.
                                                                                           

Be very careful in writing about the relation "divides." The vertical line

symbol use for this relation, if written carelessly, can look like division. While

a | b is either true or false, a/b is a number.

    Based on the equation ak = b, we can say that a|b is equivalent to k = ba ,
or a divides evenly into b. In fact the "divides" is short for "divides evenly

into."  You  might  find  the  equation  k  =  b  initially  easier  to  understand,  but  in
                                               a
the long run we will find the equation ak = b more convenient.

Sometimes it is helpful to illustrate a relation with a graph. Consider

Example 6.1.2. A graph of r can be drawn as in Figure 6.1.6. The arrows

indicate that 1 is related to 4 under r. Also, 2 is related to 4 under r, and 3 is

related to 5, while the upper arrow denotes that r is a relation from the whole

set A into the set B.

Figure 6.1.6 The graph of a relation

    A typical element in a relation r is an ordered pair (x, y). In some cases, r
can be described by actually listing the pairs which are in r, as in the previous
examples. This may not be convenient if r is relatively large. Other notations
are used with certain well-known relations. Consider the "less than or equal"
relation on the real numbers. We could define it as a set of ordered pairs this
way:

                                       = {(x, y)|x  y}

However, the notation x  y is clear and self-explanatory; it is a more natural,
and hence preferred, notation to use than (x, y) .
CHAPTER 6. RELATIONS  104

    Many of the relations we will work with "resemble" the relation , so xsy
is a common way to express the fact that x is related to y through the relation
s.

    Relation Notation Let s be a relation from a set A into a set B. Then the
fact that (x, y)  s is frequently written xsy.

6.1.3 Composition of Relations

With A = {2, 3, 5, 8}, B = {4, 6, 16}, and C = {1, 4, 5, 7}, let r be the relation
"divides," from A into B, and let s be the relation  from B into C. So
r = {(2, 4), (2, 6), (2, 16), (3, 6), (8, 16)} and s = {(4, 4), (4, 5), (4, 7), (6, 7)}.

    Notice that in Figure 6.1.8 that we can, for certain elements of A, go through
elements in B to results in C. That is:

Table 6.1.7

                                           2|4 and 4  4
                                           2|4 and 4  5
                                           2|4 and 4  7
                                           2|6 and 6  7
                                           3|6 and 6  7

Figure 6.1.8 Relation Composition - a graphical view

    Based on this observation, we can define a new relation, call it rs, from
A into C. In order for (a, c) to be in rs, it must be possible to travel along
a path in Figure 6.1.8 from a to c. In other words, (a, c)  rs if and only if
(b)B(arb and bsc). The name rs was chosen because it reminds us that this
new relation was formed by the two previous relations r and s. The complete
listing of all elements in rs is {(2, 4), (2, 5), (2, 7), (3, 7)}. We summarize in a
definition.

Definition 6.1.9 Composition of Relations. Let r be a relation from a
set A into a set B, and let s be a relation from B into a set C. The composition
of r with s, written rs, is the set of pairs of the form (a, c)  A × C, where
(a, c)  rs if and only if there exists b  B such that (a, b)  r and (b, c)  s.

                                                                                                     
    Remark: A word of warning to those readers familiar with composition of
functions. (For those who are not, disregard this remark. It will be repeated at
CHAPTER 6. RELATIONS  105

an appropriate place in the next chapter.) As indicated above, the traditional
way of describing a composition of two relations is rs where r is the first relation
and s the second. However, function composition is traditionally expressed in
the opposite order: s  r, where r is the first function and s is the second.

6.1.4 Exercises

1. For each of the following relations r defined on P, determine which of the
      given ordered pairs belong to r

        (a) xry iff x|y; (2, 3), (2, 4), (2, 8), (2, 17)

        (b) xry iff x  y; (2, 3), (3, 2), (2, 4), (5, 8)

         (c) xry iff y = x2 ; (1,1), (2, 3), (2, 4), (2, 6)
2. The following relations are on P = {0, 1, 2, . . . 8, 9}. Let

                          A = {(9, 8), (9, 7), (6, 5), (6, 4), (3, 2), (3, 1)}

      and
                         B = {((8, 6), (7, 6), (5, 3), (4, 3), (2, 0), (1, 0)}.

        (a) List all elements in AB.

        (b) List all elements in BA.

         (c) Illustrate AB and BA via a diagraph.

        (d) In one version of the game of nim players A and B take turns
              removing one or two stones from a pile. The player who manages to
              remove the last stone wins. Explain how these two relations describe
              the winning moves for B if A plays first with nine stones in the pile
              at the start of the game.

3. Let A = {1, 2, 3, 4, 5} and define r on A by xry iff x + 1 = y. We define
      r2 = rr and r3 = r2r. Find:

        (a) r

        (b) r2

         (c) r3
4. Given s and t, relations on Z, s = {(1, n) : n  Z} and t = {(n, 1) : n  Z},

      what are st and ts? Hint: Even when a relation involves infinite sets, you
      can often get insights into them by drawing partial graphs.
5. Let  be the relation on the power set, P(S), of a finite set S of cardinality
      n defined  by (A, B)   iff A  B = .

        (a) Consider the specific case n = 3, and determine the cardinality of
              the set .

        (b) What is the cardinality of  for an arbitrary n? Express your answer
              in terms of n. (Hint: There are three places that each element of S
              can go in building an element of .)

6. Consider the two relations on people: M , where aM b if a's mother is
      b; and S, where aSb if a and b are siblings. Describe, in words, the two
      relations M S and SM in simple English terms.
CHAPTER 6. RELATIONS  106

7. Let r1, r2, and r3 be relations on any set A. Prove that if r1  r2 then
      r1r3  r2r3.

6.2 Graphs of Relations on a Set

In this section we introduce directed graphs as a way to visualize relations on
a set.

6.2.1 Digraphs

Let A = {0, 1, 2, 3}, and let

                       r = {(0, 0), (0, 3), (1, 2), (2, 1), (3, 2), (2, 0)}

In representing this relation as a graph, elements of A are called the vertices
of the graph. They are typically represented by labeled points or small circles.
We connect vertex a to vertex b with an arrow, called an edge, going from
vertex a to vertex b if and only if arb. This type of graph of a relation r is
called a directed graph or digraph. Figure 6.2.1 is a digraph for r. Notice
that since 0 is related to itself, we draw a "self-loop" at 0.

Figure 6.2.1 Digraph of a relation

    The actual location of the vertices in a digraph is immaterial. The actual
location of vertices we choose is called an embedding of a graph. The main
idea is to place the vertices in such a way that the graph is easy to read.
After drawing a rough-draft graph of a relation, we may decide to relocate
the vertices so that the final result will be neater. Figure 6.2.1 could also be
presented as in Figure 6.2.2.
CHAPTER 6. RELATIONS  107

Figure 6.2.2 Alternate embedding of the previous directed graph
    A vertex of a graph is also called a node, point, or a junction. An edge of a

graph is also referred to as an arc, a line, or a branch. Do not be concerned if
two graphs of a given relation look different as long as the connections between
vertices are the same in the two graphs.
Example 6.2.3 Another directed graph. Consider the relation s
whose digraph is Figure 6.2.4. What information does this give us? The
graph tells us that s is a relation on A = {1, 2, 3} and that s =
{(1, 2), (2, 1), (1, 3), (3, 1), (2, 3), (3, 3)}.

Figure 6.2.4 Digraph of the relation s
                                                                                                    

    We will be building on the next example in the following section.
Example 6.2.5 Ordering subsets of a two element universe. Let
B = {1, 2}, and let A = P(B) = {, {1}, {2}, {1, 2}}. Then  is a relation on
A whose digraph is Figure 6.2.6.
CHAPTER 6. RELATIONS  108

Figure 6.2.6 Graph for set containment on subsets of {1, 2}
    We will see in the next section that since  has certain structural properties

that describe "partial orderings." We will be able to draw a much simpler type
graph than this one, but for now the graph above serves our purposes. 

6.2.2 Exercises

1. Let A = {1, 2, 3, 4}, and let r be the relation  on A. Draw a digraph
      for r.

2. Let B = {1, 2, 3, 4, 6, 8, 12, 24}, and let s be the relation "divides" on B.
      Draw a digraph for s.

3. Let A = {1, 2, 3, 4, 5}. Define t on A by atb if and only if b - a is even.
      Draw a digraph for t.

4. Let A be the set of strings of 0's and 1's of length 2 or less. This includes
      the empty string, , which is the only string of length zero.

        (a) Define the relation of d on A by xdy if x is contained within y. For
              example, 1d01. Draw a digraph for this relation.

        (b) Do the same for the relation p defined by xpy if x is a prefix of y.
              For example, 1p10, but 1p01 is false.

5. Recall the relation in Exercise 5 of Section 6.1,  defined on the power
      set, P(S), of a set S. The definition was (A, B)   iff A  B = . Draw
      the digraph for  where S = {a, b}.

6. Let C = {1, 2, 3, 4, 6, 12}, the divisors of 12, and define t on C by atb
      if and only if a and b share a common divisor greater than 1. Draw a
      digraph for t.

6.3 Properties of Relations

6.3.1 Individual Properties

Consider the set B = {1, 2, 3, 4, 6, 12, 36, 48} and the relations "divides" and
 on B. We notice that these two relations on B have three properties in
common:

   · Every element in B divides itself and is less than or equal to itself. This
       is called the reflexive property.
CHAPTER 6. RELATIONS                                                    109

· If we search for two elements from B where the first divides the second
   and the second divides the first, then we are forced to choose the two
   numbers to be the same. In other words, no two different numbers are
   related in both directions. The reader can verify that a similar fact is
   true for the relation  on B. This is called the antisymmetric property.

· Next if we choose three values (not necessarily distinct) from B such
   that the first divides the second and the second divides the third, then
   we always find that the first number divides the third. Again, the same is
   true if we replace "divides" with "is less than or equal to." This is called
   the transitive property.

    Relations that satisfy these properties are of special interest to us. Formal
definitions of the properties follow.

Definition 6.3.1 Reflexive Relation. Let A be a set and let r be a relation

on A. Then r is reflexive if and only if ara for all a  A.              

Definition 6.3.2 Antisymmetric Relation. Let A be a set and let r be

a relation on A. Then r is antisymmetric if and only if whenever arb and

a = b then bra is false.                                                

An equivalent condition for antisymmetry is that if arb and bra then a = b.

You are encouraged to convince yourself that this is true. This condition is

often more convenient to prove than the definition, even though the definition

is probably easier to understand.

A word of warning about antisymmetry: Students frequently find it difficult

to understand this definition. Keep in mind that this term is defined through

an "If...then..." statement. The question that you must ask is: Is it true that

whenever there are elements a and b from A where arb and a = b, it follows

that b is not related to a? If so, then the relation is antisymmetric.

Another way to determine whether a relation is antisymmetric is to examine

(or imagine) its digraph. The relation is not antisymmetric if there exists a

pair of vertices that are connected by edges in both directions.

Definition 6.3.3 Transitive Relation. Let A be a set and let r be a relation

on A. r is transitive if and only if whenever arb and brc then arc.     

6.3.2 Partial Orderings

Not all relations have all three of the properties discussed above, but those
that do are a special type of relation.

Definition 6.3.4 Partial Ordering. A relation on a set A that is reflexive,

antisymmetric, and transitive is called a partial ordering on A. A set on

which there is a partial ordering relation defined is called a partially ordered

set or poset.                                                           

Example 6.3.5 Set Containment as a Partial Ordering. Let A be a
set. Then P(A) together with the relation  (set containment) is a poset. To
prove this we observe that the three properties hold, as discussed in Chapter
4.

· Let B  P(A). The fact that B  B follows from the definition of subset.
   Hence, set containment is reflexive.

· Let B1, B2  P(A) and assume that B1  B2 and B1 = B2 . Could it
   be that B2  B1? No. There must be some element a  A such that
   a / B1, but a  B2. This is exactly what we need to conclude that B2 is
   not contained in B1. Hence, set containment is antisymmetric.
CHAPTER 6. RELATIONS  110

· Let B1, B2, B3  P(A) and assume that B1  B2 and B2  B3 . Does
   it follow that B1  B3 ? Yes, if a  B1, then a  B2 because B1  B2.
   Now that we have a  B2 and we have assumed B2  B3, we conclude
   that a  B3. Therefore, B1  B3 and so set containment is transitive.

Figure 6.2.6 is the graph for the "set containment" relation on the power

set of {1, 2}.        

Figure 6.2.6 is helpful insofar as it reminds us that each set is a subset of

itself and shows us at a glance the relationship between the various subsets in

P({1, 2}). However, when a relation is a partial ordering, we can streamline

a graph like this one. The streamlined form of a graph is called a Hasse

diagram or ordering diagram. A Hasse diagram takes into account the

following facts.

· By the reflexive property, each vertex must be related to itself, so the
   arrows from a vertex to itself (called "self-loops") are not drawn in a
   Hasse diagram. They are simply assumed.

· By the antisymmetry property, connections between two distinct ele-
   ments in a directed graph can only go one way, if at all. When there is a
   connection, we agree to always place the second element above the first
   (as we do above with the connection from {1} to {1, 2}). For this reason,
   we can just draw a connection without an arrow, just a line.

· By the transitive property, if there are edges connecting one element up
   to a second element and the second element up to a third element, then
   there will be a direct connection from the first to the third. We see
   this in Figure 6.2.6 with  connected to {1}and then {1} connected to
   {1, 2}. Notice the edge connecting  to {1, 2}. Whenever we identify this
   situation, remove the connection from the first to the third in a Hasse
   diagram and simply observe that an upward path of any length implies
   that the lower element is related to the upper one.

    Using these observations as a guide, we can draw a Hasse diagram for 
on {1, 2} as in Figure 6.3.6.

Figure 6.3.6 Hasse diagram for set containment on subsets of {1, 2}

Example 6.3.7 Definition of a relation using a Hasse diagram. Con-
sider the partial ordering relation s whose Hasse diagram is Figure 6.3.8.
CHAPTER 6. RELATIONS  111

Figure 6.3.8 Hasse diagram for the pentagonal poset
    How do we read this diagram? What is A? What is s? What does the

digraph of s look like? Certainly A = {1, 2, 3, 4, 5} and 1s2, 3s4, 1s4, 1s5,
etc., Notice that 1s5 is implied by the fact that there is a path of length three
upward from 1 to 5. This follows from the edges that are shown and the
transitive property that is presumed in a poset. Since 1s3 and 3s4, we know
that 1s4. We then combine 1s4 with 4s5 to infer 1s5. Without going into
details why, here is a complete list of pairs defined by s.
s = {(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (1, 3), (1, 4), (1, 5), (1, 2), (3, 4), (3, 5), (4, 5), (2, 5)}

    A digraph for s is Figure 6.3.9. It is certainly more complicated to read
and difficult to draw than the Hasse diagram.

Figure 6.3.9 Digraph for the pentagonal poset
                                                                                                     

    A classic example of a partial ordering relation is  on the real numbers,
R. Indeed, when graphing partial ordering relations, it is natural to "plot"
the elements from the given poset starting with the "least" element to the
"greatest" and to use terms like "least," "greatest," etc. Because of this the
reader should be forewarned that some texts use the symbol  for arbitrary
partial orderings. This can be quite confusing for the novice, so we continue
to use generic letters r, s, etc.
CHAPTER 6. RELATIONS                                                                 112

6.3.3 Equivalence Relations

Another common property of relations is symmetry.

Definition 6.3.10 Symmetric Relation. Let r be a relation on a set A. r

is symmetric if and only if whenever arb, it follows that bra.                       

Consider the relation of equality defined on any set A. Certainly a = b

implies that b = a so equality is a symmetric relation on A.

Surprisingly, equality is also an antisymmetric relation on A. This is due

to the fact that the condition that defines the antisymmetry property, a = b

and a = b, is a contradiction. Remember, a conditional proposition is always

true when the condition is false. So a relation can be both symmetric and

antisymmetric on a set! Again recall that these terms are not negatives of one

other. That said, there are very few important relations other than equality

that are both symmetric and antisymmetric.

Definition 6.3.11 Equivalence Relation. A relation r on a set A is called
an equivalence relation if and only if it is reflexive, symmetric, and transitive.

                                                                                                     
    The classic example of an equivalence relation is equality on a set A. In fact,
the term equivalence relation is used because those relations which satisfy the
definition behave quite like the equality relation. Here is another important
equivalence relation.

Example 6.3.12 Equivalent Fractions. Let Z be the set of nonzero
integers. One of the most basic equivalence relations in mathematics is the

relation q on Z × Z defined by (a, b)q(c, d) if and only if ad = bc. We will leave
it to the reader to, verify that q is indeed an equivalence relation. Be aware

that since the elements of Z × Z are ordered pairs, proving symmetry involves
four numbers and transitivity involves six numbers. Two ordered pairs, (a, b)

and  (c, d),  are  related  if  the  fractions  a  and  c  are  numerically  equal.
                                                b       d
Reflecting on these comments on fractions, we see that any fraction is a

member of a set of equivalent fractions that can be exchanged for one another

when doing arithmetic. This is an instance of an important property of all

equivalence relations that motivates the following definition.                       

Definition 6.3.13 Equivalence Classes. Let r be an equivalence relation
on A, and a  A. The equivalence class of a is the set, [a], of all elements to
which a is related.

                                     [a] = {b  A : arb}

The set of all equivalence classes with respect to r is denoted A/r, read "A

mod r."                                                                              

When we want to make it clear that an equivalence class defined by an

element a is based on a specific equivalence relation r we would refer to it as

"the equivalence class of a under r." Whenever we encounter an equivalence

relation on a set, we should immediately think about how the set is partitioned

because of the following theorem.

Theorem 6.3.14 Let r be an equivalence relation on A. Then the set of all

distinct equivalence classes determined by r form a partition of A denoted A/r

and read "A mod r."

Proof. We leave it to the reader to prove this theorem. All three properties of

an equivalence relation play a role in the proof.                                    

Our next example involves the following fundamental relations on the set

of integers.
CHAPTER 6. RELATIONS                                 113

Definition 6.3.15 Congruence Modulo n. Let n be a positive integer,
n  2. We define congruence modulo n to be the relation n defined on
the integers by

                                      a n b  n | (a - b)

                                                                                                     
    We observe the following about congruence modulo n:

   · This relation is reflexive, for if a  Z, n | (a - a)  a n a.

   · This relation is symmetric. We can prove this through the following chain
       of implications.

         a n b  n | (a - b)

                       For some k  Z, a - b = nk

                       b - a = n(-k)              .

                       n | (b - a)

                       b n a

   · Finally, this relation is transitive. We leave it to the reader to prove that
       if a n b and b n c, then a n c.

Checkpoint 6.3.16 Go ahead and prove that conguence modulo n is transi-
tive!
Frequently, you will see the equivalent notation a  b(mod n) for congruence
modulo n.
Example 6.3.17 Random Relations usually have no properties. Con-
sider the relation s described by the digraph in Figure 6.3.18. This was created
by randomly selecting whether or not two elements from {a, b, c} were related
or not. Convince yourself that the following are true:

   · This relation is not reflexive.

   · It is not antisymmetric.

   · Also, it is not symmetric.

   · It is not transitive.

   · Is s an equivalence relation or a partial ordering?

Figure 6.3.18 Digraph of a random relation r

Not every random choice of a relation will be so totally negative, but as the

underlying set increases, the likelihood any of the properties are true begins to

vanish.                                              
CHAPTER 6. RELATIONS  114

6.3.4 Exercises

1. Prove that Definition 6.1.5 on the set of positive integers is a partial
      ordering. Note that this will imply that the relation is a partial ordering
      on any subset of the positive integers as well.

2.

        (a) Let B = {a, b} and U = P(B). Draw a Hasse diagram for  on U .

        (b) Let A = {1, 2, 3, 6}. Draw a Hasse diagram for divides on A.

         (c) Compare the graphs of parts a and b. What can you observe?

        (d) Repeat the previous steps with B = {a, b, c} and A =
              {1, 2, 3, 5, 6, 10, 15, 30}.

3. Consider the relations defined by the digraphs in Figure 6.3.19.

        (a) Determine whether the given relations are reflexive, symmetric, anti-
              symmetric, or transitive. Try to develop procedures for determining
              the validity of these properties from the graphs,

        (b) Which of the graphs are of equivalence relations or of partial order-
              ings?
CHAPTER 6. RELATIONS  115

      Figure 6.3.19 Some digraphs of relations

4. Determine which of the following are equivalence relations and/or partial
      ordering relations for the given sets:
CHAPTER 6. RELATIONS  116

        (a) A = { lines in the plane}, and r defined by xry if and only if x is
              parallel to y. Assume every line is parallel to itself.

        (b) A = R and r defined by xry if and only if |x - y|  7.
5. Consider the relation on {1, 2, 3, 4, 5, 6} defined by r = {(i, j) : |i - j| =

      2}.

        (a) Is r reflexive?

        (b) Is r symmetric?

         (c) Is r transitive?

        (d) Draw a graph of r.
6. Let A = {0, 1, 2, 3} and let

           r = {(0, 0), (1, 1), (2, 2), (3, 3), (1, 2), (2, 1), (3, 2), (2, 3), (3, 1), (1, 3)}

        (a) Verify that r is an equivalence relation on A.

        (b) Find [a] for each element a  A, and observe that {[a] | a  A}
              forms a partition of A.

7. Let r be an equivalence relation on an arbitrary nonempty set A. Prove
      that the set of all equivalence classes under r constitutes a partition of A.

8. Define r on the power set of some set U by ArB  |A| = |B|. Prove
      that r is an equivalence relation. What are the equivalence classes under
      r if U = {1, 2, 3}?

9. Consider the following relations on Z8 = {0, 1, ..., 7}. Which are equiva-
      lence relations? For the equivalence relations, list the equivalence classes.

        (a) arb iff the English spellings of a and b begin with the same letter.

        (b) asb iff a - b is a positive integer.

         (c) atb iff a - b is an even integer.
10. Let n be a positive integer greater than or equal to two.

        (a) Prove that congruence modulo n is transitive.

        (b) What are the equivalence classes under congruence modulo 2? How
              many distinct equivalence classes are there?

         (c) What are the equivalence classes under congruence modulo 10? How
              many distinct equivalence classes are there?

11. In this exercise, we prove that implication is a partial ordering. Let A
      be any set of propositions, no two of which is equivalent to one another.

        (a) Verify that q  q is a tautology, thereby showing that  is a reflex-
              ive relation on A.

        (b) Prove that  is antisymmetric on A. Note: we do not use = when
              speaking of propositions, but rather equivalence, .

         (c) Prove that  is transitive on A.

        (d) Given that qi is the proposition n < i on N, draw the Hasse diagram
              for the relation  on {q1, q2, q3, . . .}.
CHAPTER 6. RELATIONS                                                117

6.4 Matrices of Relations

We have discussed two of the many possible ways of representing a relation,
namely as a digraph or as a set of ordered pairs. In this section we will discuss
the representation of relations by matrices.

6.4.1 Representing a Relation with a Matrix

Definition 6.4.1 Relation Matrix. Let A = {a1, a2, . . . , am} and B =

{b1, b2, . . . , bn} be finite sets of cardinality m and n, respectively. Let r be a

relation from A into B. Then r can be represented by the m × n matrix R

defined by

                     Rij =  1 if airbj
                            0 otherwise

R is called the relation matrix (or simply the matrix) of r.        

Note 6.4.2 Alternate Terminology. There are a wide variety of terms
that also used to refer to the matrix of a relation. They include logical matrix,
binary matrix, Boolean matrix, and (0, 1)-matrix. For relations on a set, the
relation matrix is also referred to as an adjacency matrix, a term we will use
in our future study of graphs.

Example 6.4.3 A simple example. Let A = {2, 5, 6} and let r be the
relation {(2, 2), (2, 5), (5, 6), (6, 6)} on A. Since r is a relation from A into the
same set A (the B of the definition), we have a1 = 2, a2 = 5, and a3 = 6, while
b1 = 2, b2 = 5, and b3 = 6. Next, since

· 2r2, we have R11 = 1
· 2r5, we have R12 = 1
· 5r6, we have R23 = 1
· 6r6, we have R33 = 1

All other entries of R are zero, so

                                     110  

                        R= 0 0 1 

                                     001

                                                                    

6.4.2 Composition as Matrix Multiplication

From the definition of r and of composition, we note that

                     r2 = {(2, 2), (2, 5), (2, 6), (5, 6), (6, 6)}

The matrix of r2 is                       

                                     111

                        R2 =  0 0 1  .

                                     001

    We do not write R2 only for notational purposes. In fact, R2 can be ob-
tained from the matrix product RR; however, we must use a slightly different
form of arithmetic.
CHAPTER 6. RELATIONS                                       118

Definition 6.4.4 Boolean Arithmetic. Boolean arithmetic is the arith-
metic defined on {0, 1} using Boolean addition and Boolean multiplication,
defined by

Table 6.4.5

               0+0=0 0+1=1+0=1 1+1=1
               0·0=0 0·1=1·0=0 1·1=1

                                                                                                     
    Notice that from Chapter 3, this is the "arithmetic of logic," where + re-

places "or" and · replaces "and."

Example 6.4.6 Composition by Multiplication. Suppose that R =
                                  
    0100               0111

 1 0 1 0      and S =  0 0 1 1   . Then using Boolean arithmetic,
    0101               0001

    0010               0000                 
                                
      0011                        1111

RS =  0 1 1 1      and SR =  0 1 1 1   . 
      0011                        0010

      0001                        0000

Theorem 6.4.7 Composition is Matrix Multiplication. Let A1, A2, and
A3 be finite sets where r1 is a relation from A1 into A2 and r2 is a relation from
A2 into A3. If R1 and R2 are the adjacency matrices of r1 and r2, respectively,
then the product R1R2 using Boolean arithmetic is the relation matrix of the
composition r1r2.

    Remark: A convenient help in constructing the matrix of a relation from a
set A into a set B is to write the elements from A in a column preceding the
first column of the matrix, and the elements of B in a row above the first row.
Initially, R in Example 3 would be

                                  256

                          2

                          5          

                          6

To fill in the matrix, Rij is 1 if and only if (ai, bj)  r. So that, since the pair
(2, 5)  r, the entry of R corresponding to the row labeled 2 and the column
labeled 5 in the matrix is a 1.

Example 6.4.8 Relations and Information. This final example gives

an insight into how relational data base programs can systematically answer

questions pertaining to large masses of information. Matrices R (on the left)

and S (on the right) define the relations r and s where arb if software a can be

run with operating system b, and bsc if operating system b can run on computer

c.

             OS1 OS2 OS3 OS4                  C1 C2 C3
                                                         
      P1         1010                  OS1      110

      P2         1  1  0     0         OS2      0  1  0  
                                                         
      P3       0 0 0 1                 OS3  0 0 1 

      P4         0011                  OS4      011

Although the relation between the software and computers is not implicit from
the data given, we can easily compute this information. The matrix of rs is
CHAPTER 6. RELATIONS                                                               119

RS, which is

                                     C1 C2 C3
                                                  
                      P1               111

                      P2               1  1    0  
                                                  
                      P3  0 1 1 

                      P4               011

This matrix tells us at a glance which software will run on the computers

listed. In this case, all software will run on all computers with the exception

of program P2, which will not run on the computer C3, and programs P3 and

P4, which will not run on the computer C1.                                         

6.4.3 Exercises

1. Let A1 = {1, 2, 3, 4}, A2 = {4, 5, 6}, and A3 = {6, 7, 8}. Let r1 be the
      relation from A1 into A2 defined by r1 = {(x, y) | y - x = 2}, and let r2
      be the relation from A2 into A3 defined by r2 = {(x, y) | y - x = 1}.

        (a) Determine the adjacency matrices of r1 and r2.

        (b) Use the definition of composition to find r1r2.

         (c) Verify the result in part b by finding the product of the adjacency
              matrices of r1 and r2.

2.

        (a) Determine the matrix of each relation given by the following di-
              graphs.

(b)  Using    the  matrices  found   in  part  (a),  determine  the  matrices  of  r2

     and r22.                                                                       1

(c)  Draw     the  digraphs  of  r2  and  r2  directly  from  the  definition  of  the

                                  1        2

     square of relation and compare your results with those of part (b).

3. Suppose that the matrices in Example 6.4.6 are relations on {1, 2, 3, 4}.
      What relations do R and S describe?

4. Let D be the set of weekdays, Monday through Friday, let
      W be a set of employees {1, 2, 3} of a tutoring center, and let
      V be a set of computer languages for which tutoring is offered,
      {A(P L), B(asic), C(++), J(ava), L(isp), P (ython)}. We define s (sched-
      ule) from D into W by dsw if w is scheduled to work on day d. We also
      define r from W into V by wrl if w can tutor students in language l. If s
      and r are defined by matrices
CHAPTER 6. RELATIONS                                 120

         M    1 2 3                       AB C J LP 
S= T              101

         W     0 1 1    1  and R =          011001
         R
         F    1 0 1                    2  1 1 0 1 0 1
              0 1 0
                                       3    010011

                 110

(a) Compute SR using Boolean arithmetic and give an interpretation
     of the relation it defines, and

        (b) Compute SR using regular arithmetic and give an interpretation of
              what the result describes.

5. How many different reflexive, symmetric relations are there on a set with
      three elements?

Hint. Consider the possible matrices.

6. Let A = {a, b, c, d}. Let r be the relation on A with relation matrix

         a  a b c d
R= b            1000

         c    0  1  0  0  
                          
            1 1 1 0

d             0101

        (a) Explain why r is a partial ordering on A.

        (b) Draw its Hasse diagram.
7. Define relations p and q on {1, 2, 3, 4} by p = {(a, b) | |a - b| = 1} and

      q = {(a, b) | a - b is even}.

        (a) Represent p and q as both graphs and matrices.

        (b) Determine pq, p2, and q2; and represent them clearly in any way.
8. Let r be a relation on a set A.

        (a) Prove that if r is a transitive if and only if r2  r.

        (b) Find an example of a transitive relation for which r2 = r.
9. We define  on the set of all n × n relation matrices by the rule that if R

      and S are any two n × n relation matrices, R  S if and only if Rij  Sij
      for all 1  i, j  n.

(a) Prove that  is a partial ordering on all n × n relation matrices.

(b) Prove that R  S  R2  S2 , but the converse is not true.

(c) If R and S are matrices of equivalence relations and R  S, how
     are the equivalence classes defined by R related to the equivalence
     classes defined by S?

6.5 Closure Operations on Relations

In Section 6.1, we studied relations and one important operation on relations,
namely composition. This operation enables us to generate new relations from
previously known relations. In Section 6.3, we discussed some key properties
CHAPTER 6. RELATIONS                                                            121

of relations. We now wish to consider the situation of constructing a new
relation r+ from an existing relation r where, first, r+ contains r and, second,
r+ satisfies the transitive property.

6.5.1 Transitive Closure

Consider a telephone network in which the main office a is connected to, and
can communicate to, individuals b and c. Both b and c can communicate
to another person, d; however, the main office cannot communicate with d.
Assume communication is only one way, as indicated. This situation can be
described by the relation r = {(a, b), (a, c), (b, d), (c, d)}. We would like to
change the system so that the main office a can communicate with person d and
still maintain the previous system. We, of course, want the most economical
system.

    This can be rephrased as follows; Find the smallest relation r+ which con-
tains r as a subset and which is transitive; r+ = {(a, b), (a, c), (b, d), (c, d), (a, d)}.

Definition 6.5.1 Transitive Closure. Let A be a set and r be a relation

on A. The transitive closure of r, denoted by r+, is the smallest transitive

relation that contains r as a subset.                                           

Let A = {1, 2, 3, 4}, and let S = {(1, 2), (2, 3), (3, 4)} be a relation on A.

This relation is called the successor relation on A since each element is related

to its successor. How do we compute S+? By inspection we note that (1, 3)

must be in S+ . Let's analyze why. This is so because (1, 2)  S and (2, 3)  S,

and the transitive property forces (1, 3) to be in S+.

In general, it follows that if (a, b)  S and (b, c)  S, then (a, c)  S+. This

condition is exactly the membership requirement for the pair (a, c) to be in

the composition SS = S2. So every element in S2 must be an element in S+

. So we now know that, S+ contains at least S  S2 . In particular, for this

example, since S = {(1, 2), (2, 3), (3, 4)} and S2 = {(1, 3), (2, 4)}, we have

S  S2 = {(1, 2), (2, 3), (3, 4), (1, 3), (2, 4)}

    Is the relation S  S2 transitive? Again, by inspection, (1, 4) is not an
element of S  S2, but (1, 3)  S2 and (3, 4)  S. Therefore, the composition
S2S = S3 produces (1, 4), and it must be an element of S+ since (1, 3) and
(3, 4) are required to be in S+. This shows that S3  S+. This process must
be continued until the resulting relation is transitive. If A is finite, as is true

in this example, the transitive closure will be obtained in a finite number of

steps. For this example,

            S+ = S  S2  S3 = {(1, 2), (2, 3), (3, 4), (1, 3), (2, 4), (1, 4)}

Theorem 6.5.2 Transitive Closure on a Finite Set. If r is a relation on
a set A and |A| = n, then the transitive closure of r is the union of the first n
powers of r. That is,

                                  r+ = r  r2  r3  · · ·  rn.
    Let's now consider the matrix analogue of the transitive closure.
    Consider the relation

r = {(1, 4), (2, 1), (2, 2), (2, 3), (3, 2), (4, 3), (4, 5), (5, 1)}
CHAPTER 6. RELATIONS                                                    122

on the set A = {1, 2, 3, 4, 5}. The matrix of r is

                              0 0 0 1 0

                              1    1  1   0         0
                                                       
                        R  =    0  1  0   0         0  
                                                       
                              0 0 1 0 1

                                10000

    Recall that r2, r3, . . . can be determined through computing the matrix
powers R2, R3, . . .. For our example,

Table 6.5.3

                0 0 1 0 1                    1 1 0 0 0

                1    1  1  1    0            1            1  1  1  1
                                                                      
R2           =    1  1  1  0    0     R3  =            1  1  1  1  0  
                                                                      
                1 1 0 0 0                    1 1 1 1 0

                0 0 0 1 0                    0 0 1 0 1
                    11110                        11111

                1    1  1  1    1            1            1  1  1  1
                                                                      
R4           =    1  1  1  1    1     R5  =            1  1  1  1  1  
                                                                      
                1 1 1 1 1                    1 1 1 1 1

                  11000                                11110

                                    5i

How do we relate  r to the powers of R?

                                  i=1

Theorem 6.5.4 Matrix of a Transitive Closure. Let r be a relation on a
finite set and R its matrix. Let R+ be the matrix of r+, the transitive closure
of r. Then R+ = R + R2 + · · · + Rn, using Boolean arithmetic.

    Using this theorem, we find R+ is the 5 × 5 matrix consisting of all 1s,
thus, r+ is all of A × A.

6.5.2 Algorithms for computing transitive closure

Let r be a relation on the set {1, 2, . . . , n} with relation matrix R. The matrix
of the transitive closure R+, can be computed by the equation R+ = R + R2 +
· · · + Rn. By using ordinary polynomial evaluation methods, you can compute
R+ with n - 1 matrix multiplications:

                         R+ = R(I + R(I + (· · · R(I + R) · · · )))

    For example, if n = 3, R+ = R(I + R(I + R)).
    We can make use of the fact that if T is a relation matrix, T + T = T due
to the fact that 1 + 1 = 1 in Boolean arithmetic. Let Sk = R + R2 + · · · + Rk.
Then

                     R = S1

             S1(I + S1) = R(I + R) = R + R2 = S2

             S2(I + S2) = (R + R2)(I + R + R2)                     .

                        = (R + R2) + (R2 + R3) + (R3 + R4)

                        = R + R2 + R3 + R4 = S4

Similarly,

                              S4(I + S4) = S8
CHAPTER 6. RELATIONS  123

and by induction we can prove

                                     S2k (I + S2k ) = S2k+1

    Notice how each matrix multiplication doubles the number of terms that
have been added to the sum that you currently have computed. In algorithmic
form, we can compute R+ as follows.

Algorithm 6.5.5 Transitive Closure Algorithm. Let R be a relation
matrix and let R+ be its transitive closure matrix, which is to be computed as
matrix T

   1. S = R

   2. T= S(I+S)

   3. While T != S

        (a) S = T
         (b) T= S(I+S) // using Boolean arithmetic

   4. Return T
Note 6.5.6

   · Often the higher-powered terms in Sn do not contribute anything to R+.
       When the condition T = S becomes true in Step 3, this is an indication
       that no higher-powered terms are needed.

   · To compute R+ using this algorithm, you need to perform no more than
       log2 n matrix multiplications, where x is the least integer that is
       greater than or equal to x. For example, if r is a relation on 25 elements,
       no more than log2 25 = 5 matrix multiplications are needed.

    A second algorithm, Warshall's Algorithm, reduces computation time to
the time that it takes to multiply two square matrices with the same order as
the relation matrix in question.

Algorithm 6.5.7 Warshall's Algorithm. Let R be an n×n relation matrix
and let R+ be its transitive closure matrix, which is to be computed as matrix
T using Boolean arithmetic

   1. T = R

   2. for k = 1 to n:

          1. for i = 1 to n:
                1. for j = 1 to n:
                     1. T[i,j]= T[i,j] + T[i,k]  T[k,j]

   3. Return T

6.5.3 Exercises

1. Let A = {0, 1, 2, 3, 4} and S = {(0, 1), (1, 3), (2, 3), (3, 4), (4, 1)}. Com-
      pute S+ using the matrix representation of S. Verify your results by
      checking against the result obtained directly from the definition of transi-
      tive closure.

2. Let A = {1, 2, 3, 4, 6, 12} and t = {(a, b) | b/a is a prime number}. Deter-
      mine t+ by any means. Represent your answer as a matrix.
CHAPTER 6. RELATIONS  124

3.

        (a) Draw digraphs of the relations S, S2, S3 , and S+ where S is defined
              in the first exercise above.

        (b) Verify that in terms of the graph of S, aS+b if and only if b is
              reachable from a along a path of any finite nonzero length.

4. Let r be the relation represented by the following digraph.

        (a) Determine r+ based on paths in the give graph.

        (b) Verify your result in part (a) by using the Transitive Closure Algo-
              rithm.

      Figure 6.5.8 Digraph of r in exercise 4.
5.

        (a) Define reflexive closure and symmetric closure by imitating the def-
              inition of transitive closure.

        (b) Use your definitions to compute the reflexive and symmetric closures
              of examples in the text.

         (c) What are the transitive reflexive closures of these examples?

        (d) Convince yourself that the reflexive closure of the relation < on the
              set of positive integers P is .

6. What common relations on Z are the transitive closures of the following
      relations?

        (a) aSb if and only if a + 1 = b.

        (b) aRb if and only if |a - b| = 2.
7.

        (a) Let A be any set and r a relation on A, prove that (r+)+ = r+.

        (b) Is the transitive closure of a symmetric relation always both sym-
              metric and reflexive? Explain.
CHAPTER 6. RELATIONS  125

8. The definition of the Transitive Closure of r refers to the "smallest tran-
      sitive relation that contains r as a subset." Show that the intersection of
      all transitive relations on A containing r is a transitive relation containing
      r and is precisely r+.
Chapter 7

Functions

                             countably infinite

                                  A countably infinite set
                            Is as simple as things like this get.

                                   Just start counting at 1,
                                   Then continue--it's fun!
                   I'll check back when you're done, so don't sweat.

      Chris Doyle, The Omnificent English Dictionary In Limerick Form

In this chapter we will consider some basic concepts of the relations that are
called functions. A large variety of mathematical ideas and applications can
be more completely understood when expressed through the function concept.

7.1 Definition and Notation

7.1.1 Fundamentals

Definition 7.1.1 Function. A function from a set A into a set B is a relation

from A into B such that each element of A is related to exactly one element

of the set B. The set A is called the domain of the function and the set B is

called the codomain.              

The reader should note that a function f is a relation from A into B with

two important restrictions:

· Each element in the set A, the domain of f , must be related to some
   element of B, the codomain.

   · The phrase "is related to exactly one element of the set B" means that
       if (a, b)  f and (a, c)  f , then b = c.

Example 7.1.2 A function as a list of ordered pairs.
Let A = {-2, -1, 0, 1, 2} and B = {0, 1, 2, 3, 4}, and if s =
{(-2, 4), (-1, 1), (0, 0), (1, 1), (2, 4)}, then s is a function from A into B. 

Note 7.1.3 Array Representation of Functions. For relatively small
domains, a convenient way to define a function if there is no simple formula
that will do it, is to use a two line array with the first line listing all of the
domain elements. For each domain element, it's image is placed below it in the
second line. If f is is a function with domain {a1, a2, . . . , an} then we could

                             126
CHAPTER 7. FUNCTIONS                                                                     127

write

                            f = a1              a2 · · · an

                                   f (a1) f (a2) · · · f (an)

For example, the function in Example 2 could be defined as

                            s = -2 -1 0 1 2
                                      4 1 014

Example 7.1.4 A function as a set of ordered pairs in set-builder

notation. Let R be the real numbers. Then L = {(x, 3x) | x  R} is a
function from R into R, or, more simply, L is a function on R.
                                                                                            

It is customary to use a different system of notation for functions than the one

we used for relations. If f is a function from the set A into the set B, we will

write f : A  B.

The reader is probably more familiar with the notation for describing func-

tions   that  is  used  in  basic  algebra  or  calculus  courses.  For  example,  y  =  1  or
                                                                                         x
          1   both  define  the    function     x, 1x x  R, x = 0 . Here the domain
f (x)  =  x

was assumed to be those elements of R whose substitutions for x make sense,
the nonzero real numbers, and the codomain was assumed to be R. In most
cases, we will make a point of listing the domain and codomain in addition to

describing what the function does in order to define a function.

The terms mapping, map, and transformation are also used for func-

tions.

Definition 7.1.5 The Set of Functions Between Two Sets. Given two

sets, A and B, the set of all functions from A into B is denoted BA.                        

The notation used for sets of functions makes sense in light of Exercise 5.

One way to imagine a function and what it does is to think of it as a machine.

The machine could be mechanical, electronic, hydraulic, or abstract. Imagine

that the machine only accepts certain objects as raw materials or input. The

possible raw materials make up the domain. Given some input, the machine

produces a finished product that depends on the input. The possible finished

products that we imagine could come out of this process make up the codomain.

Example 7.1.6 A definition based on images. We can define a function

based on specifying the codomain element to which each domain element is re-

lated. For example, f : R  R defined by f (x) = x2 is an alternate description
of f = x, x2 x  R .
                                                                                            

Definition 7.1.7 Image of an element under a function. Let f : A  B,

read "Let f be a function from the set A into the set B." If a  A, then f (a)

is used to denote that element of B to which a is related. f (a) is called the

image of a, or, more precisely, the image of a under f . We write f (a) = b to

indicate that the image of a is b.                                                          

In Example 7.1.6, the image of 2 under f is 4; that is, f (2) = 4. In

Example 7.1.2, the image of -1 under s is 1; that is, s(-1) = 1.

Definition 7.1.8 Range of a Function. The range of a function is the set
of images of its domain. If f : X  Y , then the range of f is denoted f (X),
and

          f (X) = {f (a) | a  X} = {b  Y | a  X such that f (a) = b}.

                                                                                                     
    Note that the range of a function is a subset of its codomain. f (X) is also

read as "the image of the set X under the function f " or simply "the image of
CHAPTER 7. FUNCTIONS                                                            128

f ."
    In Example 7.1.2, s(A) = {0, 1, 4}. Notice that 2 and 3 are not images of

any element of A. In addition, note that both 1 and 4 are related to more than
one element of the domain: s(1) = s(-1) = 1 and s(2) = s(-2) = 4. This
does not violate the definition of a function. Go back and read the definition
if this isn't clear to you.

    In Example 7.1.4, the range of L is equal to its codomain, R. If b is any real
number, we can demonstrate that it belongs to L(R) by finding a real number
x for which L(x) = b. By the definition of L, L(x) = 3x, which leads us to the
equation 3x = b. This equation always has a solution, b3 ; thus L(R) = R.

    The formula that we used to describe the image of a real number under
L, L(x) = 3x, is preferred over the set notation for L due to its brevity. Any
time a function can be described with a rule or formula, we will use this form
of description. In Example 7.1.2, the image of each element of A is its square.
To describe that fact, we write s(a) = a2 (a  A), or S : A  B defined by
S(a) = a2.

    There are many ways that a function can be described. Many factors, such
as the complexity of the function, dictate its representation.

Example 7.1.9 Data as a function. Suppose a survey of 1,000 persons is
done asking how many hours of television each watches per day. Consider the
function W : {0, 1, . . . , 24}  {0, 1, 2, . . . , 1000} defined by

         W (t) = the number of persons who gave a response of t hours

This function will probably have no formula such as the ones for s and L above.
                                                                                                    

Example 7.1.10 Conditional definition of a function. Consider the
function m : P  Q defined by the set

                     m = {(1, 1), (2, 1/2), (3, 9), (4, 1/4), (5, 25), ...}

No simple single formula could describe m, but if we assume that the pattern
given continues, we can write

                    m(x) =       x2 if x is odd
                                 1/x if x is even

                                                                                

7.1.2 Functions of Two Variables

If the domain of a function is the Cartesian product of two sets, then our

notation and terminology changes slightly. For example, consider the function

G  :  N  ×  N    N  defined  by  G ((n1, n2))  =  n2   +  n2   -  n1n2  +  10.  For this

                                                    1       2

function, we would drop one set of parentheses and write G(4, 2) = 22, not

G((4, 2)) = 22. We call G a function of two variables. From one point of view,

this function is no different from any others that we have seen. The elements

of the domain happen to be slightly more complicated. On the other hand, we

can look at the individual components of the ordered pairs as being separate.

If we interpret G as giving us the cost of producing quantities of two products,

we can imagine varying n1 while n2 is fixed, or vice versa.

   The same observations can be made for function of three or more vari-

ables.
CHAPTER 7. FUNCTIONS                                                       129

7.1.3 SageMath Note                                   The simplest way to

There are several ways to define a function in Sage.
implement f is as follows.

 f(x)=x^2
 f

x |--> x^2

 [f(4),f(1.2)]

  [16, 1.44000000000000]
    Sage is built upon the programming language Python, which is a strongly

typed language and so you can't evaluate expressions such as f('Hello'). How-
ever a function such as f , as defined above, will accept any type of number, so
a bit more work is needed to restrict the inputs of f to the integers.

    A second way to define a function in Sage is based on Python syntax.

 def fa(x):
         return x^2

 #end of definition - now we test it:
 [ fa (2) ,fa (1.2) ]

  [16, 1.44000000000000]

7.1.4 Non-Functions

We close this section with two examples of relations that are not functions.

Example 7.1.11 A non-function. Let A = B = {1, 2, 3} and let f =

{(1, 2), (2, 3)}. Here f is not a function from A into B because 3 is not related

to anything in the codomain. In other words, f does not act on, or "use," all

elements of A.                                                                

Example 7.1.12 Another non-function. Let A = B = {1, 2, 3} and let

g = {(1, 2), (2, 3), (2, 1), (3, 2)}. We note that g acts on all of A. However,

g is still not a function since (2, 3)  g and (2, 1)  g and the condition on

each domain element being related to exactly one element of the codomain is

violated.                                                                     

7.1.5 Exercises

1. Let A = {1, 2, 3, 4} and B = {a, b, c, d}. Determine which of the following
      are functions from A into B. Explain.

        (a) f  A × B, where f = {(1, a), (2, b), (3, c), (4, d)}.
        (b) g  A × B, where g = {(1, a), (2, a), (3, b), (4, d)}.
         (c) h  A × B, where h = {(1, a), (2, b), (3, c)}.
        (d) k  A × B, where k = {(1, a), (2, b), (2, c), (3, a), (4, a)}.
         (e) L  A × A, where L = {(1, 1), (2, 1), (3, 1), (4, 1)}.
2. Find the ranges of the following functions on Z:
        (a) g = {(x, 4x + 1)|x  Z}.
CHAPTER 7. FUNCTIONS                                                130

(b) h(x) = the least integer that is greater than or equal to |x|.

(c) P (x) = x + 10.

3. Find the ranges of each of the relations that are functions in Exercise 1.

4. Let U be a set and let S be any subset of U . Let S : U  {0, 1} be

defined by

                      S(x) =  1 if x  S
                              0 if x / S

The function S is called the characteristic function of S.

        (a) If U = {a, b, c} and S = {a, b}, list the elements of S .

        (b) If U = {a, b, c, d, e} and S = {a, c, e}, list the elements of S.

         (c) If U = {a, b, c}, what are  and U ?
5. If A and B are finite sets, how many different functions are there from

      A into B?
6. Let U be a set with subsets A and B.

        (a) Show that g : U  {0, 1} defined by g(a) = min (A(a), B(a)) is
              the characteristic function of A  B.

        (b) What characteristic function is h : U  {0, 1} defined by h(a) =
              max (A(a), B(a))?

         (c) How are the characteristic functions of A and Ac related?

7. Let f be a function with domain A and codomain B. Consider the
      relation K  A × A defined on the domain of f by (x, y)  K if and only
      if f (x) = f (y). The relation K is called the kernel of f .

        (a) Prove that K is an equivalence relation.

        (b) For the specific case of A = Z, where Z is the set of integers, let
              f : Z  Z be defined by f (x) = x2. Describe the equivalence classes
              of the kernel for this specific function.

8. Let f : P  P, where f (a) is the largest power of two that evenly divides a;
      for example, f (12) = 4, f (9) = 1, andf (8) = 8. Describe the equivalence
      classes of the kernel of f .

7.2 Properties of Functions

7.2.1 Properties

Consider the following functions:
    Let A = {1, 2, 3, 4} and B = {a, b, c, d}, and define f : A  B by

                        f (1) = a, f (2) = b, f (3) = c and f (4) = d

    Let A = {1, 2, 3, 4} and B = {a, b, c, d}, and define g : A  B by

                        g(1) = a, g(2) = b, g(3) = a and g(4) = b.

    The first function, f , gives us more information about the set B than
the second function, g. Since A clearly has four elements, f tells us that
B contains at least four elements since each element of A is mapped onto a
CHAPTER 7. FUNCTIONS                                                     131

different element of B. The properties that f has, and g does not have, are the
most basic properties that we look for in a function. The following definitions
summarize the basic vocabulary for function properties.

Definition 7.2.1 Injective Function, Injection. A function f : A  B is
injective if

                               a, b  A, a = b  f (a) = f (b)

An injective function is called an injection, or a one-to-one function.  

Notice that the condition for an injective function is logically equivalent to

                             f (a) = f (b)  a = b.

for all a, b  A. This is often a more convenient condition to prove than what
is given in the definition.

Definition 7.2.2 Surjective Function, Surjection. A function f : A  B

is surjective if its range, f (A), is equal to its codomain, B. A surjective function

is called a surjection, or an onto function.                             

Notice that the condition for a surjective function is equivalent to

For all b  B, there exists a  A such that f (a) = b.

Definition 7.2.3 Bijective Function, Bijection. A function f : A  B is

bijective if it is both injective and surjective. Bijective functions are also called

one-to-one, onto functions.                                              

The function f that we opened this section with is bijective. The function

g is neither injective nor surjective.

Example 7.2.4 Injective but not surjective function. Let A = {1, 2, 3}

and B = {a, b, c, d}, and define f : A  B by f (1) = b, f (2) = c, and f (3) = a.

Then f is injective but not surjective.                                  

Example 7.2.5 Characteristic Functions. The characteristic function,

S, in Exercise 7.1.5.4 is surjective if S is a proper subset of A, but never

injective if |A| > 2.                                                    

7.2.2 Counting

Example 7.2.6 Seating Students. Let A be the set of students who are

sitting in a classroom, let B be the set of seats in the classroom, and let s

be the function which maps each student into the chair he or she is sitting in.

When is s one to one? When is it onto? Under normal circumstances, s would

always be injective since no two different students would be in the same seat.

In order for s to be surjective, we need all seats to be used, so s is a surjection

if the classroom is filled to capacity.                                  

Functions can also be used for counting the elements in large finite sets

or in infinite sets. Let's say we wished to count the occupants in an audito-

rium containing 1,500 seats. If each seat is occupied, the answer is obvious,

1,500 people. What we have done is to set up a one-to-one correspondence, or

bijection, from seats to people. We formalize in a definition.

Definition 7.2.7 Cardinality. Two sets are said to have the same cardinality

if there exists a bijection between them. If a set has the same cardinality as

the set {1, 2, 3, . . . , n}, then we say its cardinality is n.          

The function f that opened this section serves to show that the two sets

A = {1, 2, 3, 4} and B = {a, b, c, d} have the same cardinality. Notice in

applying the definition of cardinality, we don't actually appear to count either
CHAPTER 7. FUNCTIONS                                            132

set, we just match up the elements. However, matching the letters in B with
the numbers 1, 2, 3, and 4 is precisely how we count the letters.

Definition 7.2.8 Countable Set. If a set is finite or has the same cardinality

as the set of positive integers, it is called a countable set.  

Example 7.2.9 Counting the Alphabet. The alphabet {A, B, C, ..., Z}
has cardinality 26 through the following bijection into the set {1, 2, 3, . . . , 26}.

                                      A B C ··· Z
                                         ···  .
                                      1 2 3 · · · 26

                                                                                                    
Example 7.2.10 As many evens as all positive integers. Recall that
2P = {b  P | b = 2k for some k  P}. Paradoxically, 2P has the same
cardinality as the set P of positive integers. To prove this, we must find a
bijection from P to 2P. Such a function isn't unique, but this one is the
simplest: f : P  2P where f (m) = 2m. Two statements must be proven to
justify our claim that f is a bijection:

· f is one-to-one.

   Proof: Let a, b  P and assume that f (a) = f (b). We must prove that
   a = b.

                            f (a) = f (b) = 2a = 2b = a = b.

   · f is onto.

       Proof: Let b  2P. We want to show that there exists an element a  P
       such that f (a) = b. If b  2P, b = 2k for some k  P by the definition of
       2P. So we have f (k) = 2k = b. Hence, each element of 2P is the image
       of some element of P.

                                                                                                    
    Another way to look at any function with P as its domain is creating a list
of the form f (1), f (2), f (3), . . .. In the previous example, the list is 2, 4, 6, . . ..
This infinite list clearly has no duplicate entries and every even positive integer
appears in the list eventually.
    A function f : P  A is a bijection if the infinite list f (1), f (2), f (3), . . .
contains no duplicates, and every element of A appears once in the list. In this
case, we say the A is countably infinite, or simply countable.

Example 7.2.11 A First Paradox of Infinity. When studying infinity,
paradoxes abound. One of the first instances of this is when we observe that
the set of even positive integers, in spite of the fact that they make up only
half of the positive integers, has the same cardinality as the whole set of posi-
tive integers. This follows from our definition of cardinality with the function
f (k) = 2k, which is a bijection from the positive integers to the even positive
integers. We can make a similar observation that the seemingly smaller set
of powers of 10, {100, 101, 102, 103, . . . }, also has the same cardinality as the
positive integer. Here, the function g(k) = 10k serves as our justification.

    Going in the opposite direction, there are seemingly larger sets than the
positive integer that are countably infinite. One such example is the Cartesian
product of the positive integers with itself, P × P. A function that justifies this
claim doesn't have such a neat formula, but it would start like this:
CHAPTER 7. FUNCTIONS                                                        133

Table 7.2.12

        f (1) = (1, 1)     f (3) = (2, 1)  f (6) = (3, 1)  f (10) = (4, 1)
        f (2) = (1, 2)     f (5) = (2, 2)  f (9) = (3, 2)
        f (4) = (1, 3)     f (8) = (2, 3)
        f (7) = (1, 4)

See the pattern? If it continues, every positive integer will map to a different

pair and every pair of positive integer will be in the range of f .         

Readers who have studied real analysis should recall that the set of rational

numbers is a countable set, while the set of real numbers is not a countable

set. See the exercises at the end of this section for an another example of such

a set.

We close this section with a theorem called the Pigeonhole Principle, which

has numerous applications even though it is an obvious, common-sense state-

ment. Never underestimate the importance of simple ideas. The Pigeonhole

Principle states that if there are more pigeons than pigeonholes, then two or

more pigeons must share the same pigeonhole. A more rigorous mathematical

statement of the principle follows.

Theorem 7.2.13 The Pigeonhole Principle. Let f be a function from a
finite set X into a finite set Y . If n  1 and |X| > n|Y |, then there exists an
element of Y that is the image under f of at least n + 1 elements of X.

Proof. Assume no such element exists. For each y  Y , let Ay = {x  X |
f (x) = y}. Then it must be that |Ay|  n. Furthermore, the set of nonempty
Ay form a partition of X. Therefore,

                           |X| = |Ay|  n|Y |

                                       yY

which is a contradiction.                                                   

Example 7.2.14 A duplicate name is assured. Assume that a room

contains four students with the first names John, James, and Mary. Prove

that two students have the same first name. We can visualize a mapping from

the set of students to the set of first names; each student has a first name. The

pigeonhole principle applies with n = 1, and we can conclude that at least two

of the students have the same first name.                                   

7.2.3 Exercises

1. Determine which of the functions in Exercise 7.1.5.1 of Section 7.1 are
      one- to-one and which are onto.

2.

        (a) Determine all bijections from {1, 2, 3} into {a, b, c}.

        (b) Determine all bijections from {1, 2, 3} into {a, b, c, d}.
3. Which of the following are one-to-one, onto, or both?

        (a) f1 : R  R defined by f1(x) = x3 - x.
        (b) f2 : Z  Z defined by f2(x) = -x + 2.
         (c) f3 : N × N  N defined by f3(j, k) = 2j3k.
        (d) f4 : P  P defined by f4(n) = n/2, where x is the ceiling of x,

              the smallest integer greater than or equal to x.
CHAPTER 7. FUNCTIONS                                                   134

         (e) f5 : N  N defined by f5(n) = n2 + n.

         (f) f6 : N  N × N defined by f6(n) = (2n, 2n + 1).
4. Which of the following are injections, surjections, or bijections on R, the

      set of real numbers?

(a) f (x) = -2x.
(b) g(x) = x2 - 1.

(c) h(x) =     x x<0
               x2 x  0

(d) q(x) = 2x

(e) r(x) = x3

(f) s(x) = x3 - x

5. Suppose that m pairs of socks are mixed up in your sock drawer. Use the
      Pigeonhole Principle to explain why, if you pick m + 1 socks at random,
      at least two will make up a matching pair.

6. Given five points on the unit square, {(x, y) | 0  x, y  1}, prove
that there are two of the points a distance of no more than   2  from  one
                                                             2
another.

7. Let A = {1, 2, 3, 4, 5}. Find functions, if they exist that have the prop-
      erties specified below.

        (a) A function that is one-to-one and onto.

        (b) A function that is neither one-to-one nor onto.

         (c) A function that is one-to-one but not onto.

        (d) A function that is onto but not one-to-one.
8.

        (a) Define functions, if they exist, on the positive integers, P, with the
              same properties as in Exercise 7 (if possible).

        (b) Let A and B be finite sets where |A| = |B|. Is it possible to define
              a function f : A  B that is one-to-one but not onto? Is it possible
              to find a function g : A  B that is onto but not one-to-one?

9.

        (a) Prove that the set of natural numbers is countable.

        (b) Prove that the set of integers is countable.

         (c) Prove that the set of rational numbers is countable.
10.

        (a) Prove that the set of finite strings of 0's and 1's is countable.

        (b) Prove that the set of odd integers is countable.

         (c) Prove that the set N × N is countable.
        (d) Prove that the set N × N × N is countable.
CHAPTER 7. FUNCTIONS                                                                  135

11. Use the Pigeonhole Principle to prove that an injection cannot exist
      between a finite set A and a finite set B if the cardinality of A is greater
      than the cardinality of B.

12. The important properties of relations are not generally of interest for
      functions. Most functions are not reflexive, symmetric, antisymmetric,
      or transitive. Can you give examples of functions that do have these
      properties?

13. Prove that the set of all infinite sequences of 0's and 1's is not a countable
      set.

14. Prove that the set of all functions on the integers is an uncountable set.

7.3 Function Composition

Now that we have a good understanding of what a function is, our next step
is to consider an important operation on functions. Our purpose is not to
develop the algebra of functions as completely as we did for the algebras of
logic, matrices, and sets, but the reader should be aware of the similarities
between the algebra of functions and that of matrices. We first define equality
of functions.

7.3.1 Function Equality

Definition 7.3.1 Equality of Functions. Let f, g : A  B; that is, let f

and g both be functions from A into B. Then f is equal to g (denoted f = g)

if and only if f (x) = g(x) for all x  A.                                                 

      Two functions that have different domains cannot be equal. For example,

f : Z  Z defined by f (x) = x2 and g : R  R defined by g(x) = x2 are not
equal even though the formula that defines them is the same.

      On the other hand, it is not uncommon for two functions to be equal

even though they are defined differently. For example consider the functions

h and k, where h : {-1, 0, 1, 2}  {0, 1, 2} is defined by h(x) = |x| and

k  :  {-1, 0, 1, 2}    {0, 1, 2}  is  defined  by  k(x)  =  - 3x3  + x2 +  x  appear  to  be
                                                                           3
very different functions. However, they are equal because h(x) = k(x) for

x = -1, 0, 1, and 2.

7.3.2 Function Composition

One of the most important operations on functions is that of composition.

Definition 7.3.2 Composition of Functions. Let f : A  B and g : B 

C. Then the composition of f followed by g, written g  f , is a function from

A into C defined by (g  f )(x) = g(f (x)), which is read "g of f of x."                   

      The reader should note that it is traditional to write the composition of

functions from right to left. Thus, in the above definition, the first function

performed in computing g  f is f . On the other hand, for relations, the

composition rs is read from left to right, so that the first relation is r.

Example 7.3.3 A basic example. Let f : {1, 2, 3}  {a, b} be defined
by f (1) = a, f (2) = a, and f (3) = b. Let g : {a, b}  {5, 6, 7} be defined
by g(a) = 5 and g(b) = 7. Then g  f : {1, 2, 3}  {5, 6, 7} is defined by
(g  f )(1) = 5, (g  f )(2) = 5, and (g  f )(3) = 7. For example, (g  f )(1) =
g(f (l)) = g(a) = 5. Note that f  g is not defined. Why?

    Let f : R  R be defined by f (x) = x3 and let g : R  R be defined by
CHAPTER 7. FUNCTIONS  136

g(x) = 3x + 1. Then, since

                         (g  f )(x) = g(f (x)) = g x3 = 3x3 + 1

we have g f : R  R is defined by (g f )(x) = 3x3 +1. Here f g is also defined
and f g : R  R is defined by (f g)(x) = (3x+1)3 . Moreover, since 3x3 +1 =
(3x+1)3 for at least one real number, g f = f g. Therefore, the commutative
law is not true for functions under the operation of composition. However, the
associative law is true for functions under the operation of composition. 
Theorem 7.3.4 Function composition is associative. If f : A  B,
g : B  C, and h : C  D, then h  (g  f ) = (h  g)  f .
Proof. Note: In order to prove that two functions are equal, we must use the
definition of equality of functions. Assuming that the functions have the same
domain, they are equal if, for each domain element, the images of that element
under the two functions are equal.
We wish to prove that (h  (g  f ))(x) = ((h  g)  f )(x) for all x  A, which is
the domain of both functions.

          (h  (g  f ))(x) = h((g  f )(x)) by the definition of composition
                              = h(g(f (x))) by the definition of composition

Similarly,

         ((h  g)  f )(x) = (h  g)(f (x)) by the definition of composition.
                              = h(g(f (x))) by the definition of composition

Notice that no matter how the functions in the expression h  g  f is grouped,
the final image of any element of x  A is h(g(f (x))) and so h(gf ) = (hg)f .

                                                                                                     
    If f is a function on a set A, then the compositions f  f , f  f  f, . . . are
valid, and we denote them as f 2 , f 3, . . .. Repeated compositions of f with
itself can be defined recursively. We will discuss this form of definition in detail
in Section 8.1.

Definition 7.3.5 Powers of Functions. Let f : A  A.

    · f 1 = f ; that is, f 1(a) = f (a), for a  A.

    · For n  1, f n+1 = f  f n; that is, f n+1(a) = f (f n(a)) for a  A.

                                                                                                     
    Two useful theorems concerning composition are given below. The proofs
are left for the exercises.

Theorem 7.3.6 The composition of injections is an injection. If
f : A  B and g : B  C are injections, then g  f : A  C is an injection.

Theorem 7.3.7 The composition of surjections is a surjection. If
f : A  B and g : B  C are surjections, then g  f : A  C is a surjection.

    We would now like to define the concepts of identity and inverse for func-
tions under composition. The motivation and descriptions of the definitions of
these terms come from the definitions of the terms in the set of real numbers
and for matrices. For real numbers, the numbers 0 and 1 play the unique role
that x + 0 = 0 + x = x and x · 1 = 1 · x = x for any real number x. 0 and
1 are the identity elements for the reals under the operations of addition and
multiplication, respectively. Similarly, the n × n zero matrix 0 and the n × n
identity matrix I are such that for any n × n matrix A, A + 0 = 0 + A = A and
CHAPTER 7. FUNCTIONS                                                  137

AI = IA = A. Hence, an elegant way of defining the identity function under
the operation of composition would be to imitate the above well-known facts.

Definition 7.3.8 Identity Function. For any set A, the identity function

on A is a function from A onto A, denoted by i (or, more specifically, iA) such

that i(a) = a for all a  A.                                           

Based on the definition of i, we can show that for all functions f : A  A,

f  i = i  f = f.

Example 7.3.9 The identity function on {1, 2, 3}. If A = {1, 2, 3}, then

the identity function i : A  A is defined by i(1) = 1, i(2) = 2, and i(3) = 3.

                                                                      

Example 7.3.10 The identity function on R. The identity function on
R is i : R  R defined by i(x) = x.
                                                                      

7.3.3 Inverse Functions

We will introduce the inverse of a function with a special case: the inverse of a
function on a set. After you've taken the time to understand this concept, you
can read about the inverse of a function from one set into another. The reader
is encouraged to reread the definition of the inverse of a matrix in Section 5.2
(Definition 5.2.5) to see that the following definition of the inverse function is
a direct analogue of that definition.

Definition 7.3.11 Inverse of a Function on a Set. Let f : A  A. If

there exists a function g : A  A such that g  f = f  g = i, then g is called

the inverse of f and is denoted by f -1 , read "f inverse."           

Notice that in the definition we refer to "the inverse" as opposed to "an

inverse." It can be proven that a function can never have more than one inverse

(see exercises).

An alternate description of the inverse of a function, which can be proven

from the definition, is as follows: Let f : A  A be such that f (a) = b. Then

when it exists, f -1 is a function from A to A such that f -1(b) = a. Note that

f -1 "undoes" what f does.

Example 7.3.12 The inverse of a function on {1, 2, 3}. Let A = {1, 2, 3}

and let f be the function defined on A such that f (1) = 2, f (2) = 3, and

f (3) = 1. Then f -1 : A  A is defined by f -1(1) = 3, f -1(2) = 1, and

f -1(3) = 2.                                                          

Example 7.3.13 Inverse of a real function. If g : R  R is defined by
g(x) = x3 , then g-1 is the function that undoes what g does. Since g cubes
real numbers, g-1 must be the "reverse" process, namely, takes cube roots.
Therefore, g-1 : R  R is defined by g-1(x) = 3 x. We should show that
g-1  g = i and g  g-1 = i. We will do the first, and the reader is encouraged
to do the second.

              g-1  g  (x) = g-1(g(x)) Definition of composition
                          = g-1 x3 Definition of g
                          = 3 x3 Definition of g-1
                          = x Definition of cube root
                          = i(x) Definition of the identity function

Therefore, g-1  g = i. Why?                                           
CHAPTER 7. FUNCTIONS                                                     138

    The definition of the inverse of a function alludes to the fact that not all
functions have inverses. How do we determine when the inverse of a function
exists?

Theorem 7.3.14 Bijections have inverses. Let f : A  A. f -1 exists if
and only if f is a bijection; i. e. f is one-to-one and onto.

Proof. () In this half of the proof, assume that f -1 exists and we must prove

that f is one-to-one and onto. To do so, it is convenient for us to use the

relation notation, where f (s) = t is equivalent to (s, t)  f . To prove that f

is one-to-one, assume that f (a) = f (b) = c. Alternatively, that means (a, c)

and (b, c) are elements of f . We must show that a = b. Since (a, b), (c, b)  f ,

(c, a) and (c, b) are in f -1. By the fact that f -1 is a function and c cannot

have two images, a and b must be equal, so f is one-to-one.

Next, to prove that f is onto, observe that for f -1 to be a function, it must

use all of its domain, namely A. Let b be any element of A. Then b has an

image under f -1 , f -1(b). Another way of writing this is b, f -1(b)  f -1,

By the definition of the inverse, this is equivalent to f -1(b), b  f . Hence, b

is in the range of f . Since b was chosen arbitrarily, this shows that the range

of f must be all of A.

( ) Assume f is one-to-one and onto and we are to prove f -1 exists. We

leave this half of the proof to the reader.                              

Definition 7.3.15 Permutation. A bijection of a set A into itself is called

a permutation of A.                                                      

Next, we will consider the functions for which the domain and codomain

are not necessarily equal. How do we define the inverse in this case?

Definition 7.3.16 Inverse of a Function (General Case). Let f : A  B,

If there exists a function g : B  A such that g  f = iA and f  g = iB , then

g is called the inverse of f and is denoted by f -1 , read "f inverse."  

Note the slightly more complicated condition for the inverse in this case

because the domains of f  g and g  f are different if A and B are different.

The proof of the following theorem isn't really very different from the special

case where A = B.

Theorem 7.3.17 When does a function have an inverse? Let f : A  B.
f -1 exists if and only if f is a bijection.

Example 7.3.18 Another inverse. Let A = {1, 2, 3} and B = {a, b, c}.
Define f : A  B by f (1) = a, f (2) = b, and f (3) = c. Then g : B  A
defined by g(a) = 1, g(b) = 2, and g(c) = 3 is the inverse of f .

                                                   
(g  f )(1) = 1                  (f  g)(a) = a 
(g  f )(2) = 2   g  f = iA and  (f  g)(b) = b   f  g = iB
(g  f )(3) = 3                  (f  g)(c) = c

                                                                         

7.3.4 Exercises

1. Let A = {1, 2, 3, 4, 5}, B = {a, b, c, d, e, f }, and C = {+, -}. Define
      f : A  B by f (k) equal to the kth letter in the alphabet, and define
      g : B  C by g() = + if  is a vowel and g() = - if  is a consonant.

(a) Find g  f .
(b) Does it make sense to discuss f  g? If not, why not?
CHAPTER 7. FUNCTIONS  139

         (c) Does f -1 exist? Why?

        (d) Does g-1 exist? Why?
2. Let A = {1, 2, 3}. Definef : A  A by f (1) = 2, f (2) = 1, and f (3) = 3.

      Find f 2, f 3, f 4 and f -1.
3. Let A = {1, 2, 3}.

        (a) List all permutations of A.

        (b) Find the inverse and square of each of the permutations of part a,
              where the square of a permutation, f , is the composition f  f .

         (c) Show that the composition of any two permutations of A is a per-
              mutation of A.

        (d) Prove that if A is any set where |A| = n, then the number of per-
              mutations of A is n!.

4. Define s, u, and d, all functions on the integers, by s(n) = n2 , u(n) =
      n + 1, and d(n) = n - 1. Determine:

        (a) u  s  d

        (b) s  u  d

         (c) d  s  u
5. Consider the following functions on the set of bit strings of length 4. In

      these definitions, addition is done modulo 2, so that 1 + 1 = 0. Which of
      these functions has an inverse? For those that have an inverse, what is it?
      For those that don't explain why.

        (a) f1(b1b2b3b4) = b2b3b4b1

        (b) f2(b1b2b3b4) = b4b3b2b1

         (c) f3(b1b2b3b4) = (b1 + b2)(b2 + b3)(b3 + b4)(b4 + b1)

        (d) f4(b1b2b3b4) = b1(b1 + b2)(b1 + b2 + b3)(b1 + b2 + b3 + b4)
6. Inverse images. If f is any function from A into B, we can describe

      the inverse image as a function from B into P(A), which is also commonly
      denoted f -1. If b  B, f -1(b) = {a  A | f (a) = b}. If f does have an
      inverse, the inverse image of b is f -1(b) .

        (a) Let g : R  R be defined by g(x) = x2. What are g-1(4), g-1(0)
              and g-1(-1)?

        (b) If r : R  Z, where r(x) = x, what is r-1(1)?
7. Let f, g, and h all be functions from Z into Z defined by f (n) = n + 5,

      g(n) = n - 2, and h(n) = n2. Define:

        (a) f  g

        (b) f 3

         (c) f  h
8. Define the following functions on the integers by f (k) = k + 1, g(k) = 2k,

      and h(k) = k/2
CHAPTER 7. FUNCTIONS                                  140

(a) Which of these functions are one-to-one?

(b) Which of these functions are onto?

         (c) Express in simplest terms the compositions f  g, g  f , g  h, h  g,
              and h2.

9. Let A be a nonempty set. Prove that if f is a bijection on A and f f = f ,
      then f is the identity function, i

      Hint. You have seen a similar proof in matrix algebra.

10. For the real matrix A =  a b , det(A) = ad - bc.
                             cd

Recall that a bijection from a set to itself is also referred to as a

permutation of the set. Let  be a permutation of {a, b, c, d} such that

a becomes (a), b becomes (b), etc.

Let B =  (a) (b) . How many permutations of  leave the
         (c) (d)

determinant of A invariant, that is, det A = det B?

11. State and prove a theorem on inverse functions analogous to the one that
      says that if a matrix has an inverse, that inverse is unique.

12. Let f and g be functions whose inverses exist. Prove that (f  g)-1 =
      g-1  f -1.

      Hint. See Exercise 3 of Section 5.4.

13. Prove Theorem 7.3.6 and Theorem 7.3.7.

14. Prove the second half of Theorem 7.3.14.

15. Prove by induction that if n  2 and f1, f2, . . . , fn are invertible functions
      on some nonempty set A, then (f1  f2  · · ·  fn) -1 = fn-1 · · ·f2-1 f1-1.
      The basis has been taken care of in Exercise 7.3.4.12.

16.

(a) Our definition of cardinality states that two sets, A and B, have
     the same cardinality if there exists a bijection between the two sets.
     Why does it not matter whether the bijection is from A into B or
     B into A?

        (b) Prove that "has the same cardinality as" is an equivalence relation
              on sets.

17. Construct a table listing as many "Laws of Function Composition" as
      you can identify. Use previous lists of laws as a guide.

18. Based on the definition of the identity function, show that for all functions
      f : A  A, f  i = i  f = f .
Chapter 8

Recursion and Recurrence Re-
lations

                            Fibonacci sequence

                       Zero, one! One, two, three! Five and eight!
                         Then thirteen, twenty-one! At this rate
                                      Fibonacci appears;
                                The man's sequence for years
                          Has kept math students studying late.

          Goldie, The Omnificent English Dictionary In Limerick Form

An essential tool that anyone interested in computer science must master is
how to think recursively. The ability to understand definitions, concepts, al-
gorithms, etc., that are presented recursively and the ability to put thoughts
into a recursive framework are essential in computer science. One of our goals
in this chapter is to help the reader become more comfortable with recursion
in its commonly encountered forms.

    A second goal is to discuss recurrence relations. We will concentrate on
methods of solving recurrence relations, including an introduction to generating
functions.

8.1 The Many Faces of Recursion

Consider the following definitions, all of which should be somewhat familiar to
you. When reading them, concentrate on how they are similar.

8.1.1 Binomial Coefficients

Here is a recursive definition of binomial coefficients, which we introduced in
Chapter 2.

Definition 8.1.1 Binomial Coefficient - Recursion Definition. Assume

n  0 and n  k  0. We define  n  by
                             k

· n =1
      0

·  n  = 1 and
   n

                                141
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                               142

· kn = k n-1 + k-1 n-1 if n > k > 0

                                                                                                     

Observation 8.1.2 A word about definitions: Strictly speaking, when mathe-
matical objects such as binomial coefficients are defined, they should be defined
just once. Since we defined binomial coefficients earlier, in Definition 2.4.3,
other statements describing them should be theorems. The theorem, in this
case, would be that the "definition" above is consistent with the original defini-
tion. Our point in this chapter in discussing recursion is to observe alternative
definitions that have a recursive nature. In the exercises, you will have the
opportunity to prove that the two definitions are indeed equivalent.

    Here is how we can apply the recursive definition to compute 25 .

             5  4                     4
                =+
             2  2                     1

                               3      3        3  3
                =( + )+( + )
                               2      1        1  0

                3                        3
                = +2 +1
                2                        1

                               2      2        2  2
                = ( + ) + 2( + ) + 1
                               2      1        1  0

                                  2         2
                = (1 + ) + 2( + 1) + 1
                                  1         1

                      2
                =3 +4

                      1

                               1         1
                = 3( + ) + 4
                               1         0

                = 3(1 + 1) + 4 = 10

8.1.2 Polynomials and Their Evaluation

Definition 8.1.3 Polynomial Expression in x over S (Non-Recursive).

Let n be an integer, n  0. An nth degree polynomial in x is an expression

of the form anxn + an-1xn-1 + · · · + a1x + a0, where an, an-1, . . . , a1, a0 are

elements of some designated set of numbers, S, called the set of coefficients

and an = 0.                                                                 

We refer to x as a variable here, although the more precise term for x is

an indeterminate. There is a distinction between the terms indeterminate and

variable, but that distinction will not come into play in our discussions.

Zeroth degree polynomials are called constant polynomials and are simply

elements of the set of coefficients.

This definition is often introduced in algebra courses to describe expressions

such as f (n) = 4n3 + 2n2 - 8n + 9, a third-degree, or cubic, polynomial in n.

This definition has a drawback when the variable is given a value and the

expression must be evaluated. For example, suppose that n = 7. Your first

impulse is likely to do this:

                f (7) = 4 · 73 + 2 · 72 - 8 · 7 + 9
                      = 4 · 343 + 2 · 49 - 8 · 7 + 9
                      = 1423
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS  143

    A count of the number of operations performed shows that five multiplica-
tions and three additions/subtractions were performed. The first two multipli-
cations compute 72 and 73, and the last three multiply the powers of 7 times
the coefficients. This gives you the four terms; and adding/subtracting a list
of k numbers requires k - 1 addition/subtractions. The following definition of
a polynomial expression suggests another more efficient method of evaluation.

Definition 8.1.4 Polynomial Expression in x over S (Recursive). Let
S be a set of coefficients and x a variable.

  (a) A zeroth degree polynomial expression in x over S is a nonzero element
       of S.

  (b) For n  1, an nth degree polynomial expression in x over S is an expres-
       sion of the form p(x)x + a where p(x) is an (n - 1)st degree polynomial
       expression in x and a  S.

                                                                                                     
    We can easily verify that f (n) = 4n3 + 2n2 - 8n + 9 is a third-degree
polynomial expression in n over Z based on this definition:

                  f (n) = 4n3 + 2n2 - 8n + 9 = ((4n + 2)n - 8)n + 9

Notice that 4 is a zeroth degree polynomial since it is an integer. Therefore
4n + 2 is a first-degree polynomial; therefore, (4n + 2)n - 8 is a second-degree
polynomial in n over Z; therefore, f (n) is a third-degree polynomial in n over
Z. The final expression for f (n) is called its telescoping form. If we use
it to calculate f (7), we need only three multiplications and three additions/
subtractions. This is called Horner's method for evaluating a polynomial
expression.

Example 8.1.5 More Telescoping Polynomials.

  (a) The telescoping form of p(x) = 5x4 + 12x3 - 6x2 + x + 6 is (((5x +
       12)x - 6)x + 1)x + 6. Using Horner's method, computing the value of p(c)
       requires four multiplications and four additions/subtractions for any real
       number c.

  (b) g(x) = -x5 + 3x4 + 2x2 + x has the telescoping form ((((-x + 3)x)x +
       2)x + 1)x.

                                                                                                    
    Many computer languages represent polynomials as lists of coefficients, usu-
ally starting with the constant term. For example, g(x) = -x5 + 3x4 + 2x2 + x
would be represented with the list {0, 1, 2, 0, 3, -1}. In both Mathematica and
Sage, polynomial expressions can be entered and manipulated, so the list rep-
resentation is only internal. Some programming languages require users to
program polynomial operations with lists. We will leave these programming
issues to another source.

8.1.3 Recursive Searching - The Binary Search

Next, we consider a recursive algorithm for a binary search within a sorted
list of items. Suppose r = {r(1), r(2), . . . , r(n)} represent a list of n items
sorted by a numeric key in descending order. The jth item is denoted r(j)
and its key value by r(j).key. For example, each item might contain data on
the buildings in a city and the key value might be the height of the building.
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS  144

Then r(1) would be the item for the tallest building and r(1).key would be
its height. The algorithm BinarySearch(j, k) can be applied to search for an
item in r with key value C. This would be accomplished by the execution of
BinarySearch(1, n). When the algorithm is completed, the variable Found will
have a value of true if an item with the desired key value was found, and the
value of location will be the index of an item whose key is C. If Found keeps
the value false, no such item exists in the list. The general idea behind the
algorithm is illustrated in Figure 8.1.6

Figure 8.1.6 General Scheme for a Binary Search

    In the following implementation of the Binary Search in SageMath, we
search within a sorted list of integers. Therefore, the items themselves are the
keys.

 def BinarySearch(r,j,k,C):
       found = False
       if j <= k:
            mid = floor((j + k)/2)
            print( ' probing at position '+str(mid))
            if r[mid] == C:
                  location = mid
                  found = True
                  print( ' found in position '+str(location))
                  return location
            else:
                if r[mid] > C:
                     BinarySearch(r,j, mid - 1,C)
                else:
                     BinarySearch(r,mid + 1,k,C)
       else:
            print( ' not found ')
            return False

 s =[1 ,9 ,13 ,16 ,30 ,31 ,32 ,33 ,36 ,37 ,38 ,45 ,49 ,50 ,52 ,61 ,63 ,64 ,69 ,77 ,79 ,80 ,81 ,83 ,86 ,90 ,93 ,96]
 BinarySearch(s,0,len(s) -1,30)

  probing at position 13
  probing at position 6
  probing at position 2
  probing at position 4
  found in position 4

8.1.4 Recursively Defined Sequences

For the next two examples, consider a sequence of numbers to be a list of
numbers consisting of a zeroth number, first number, second number, ... . If
a sequence is given the name S, the kth number of S is usually written Sk or
S(k).
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS  145

Example 8.1.7  Geometric Growth Sequence.     Define the sequence of
numbers B by                    B0 = 100 and

               Bk = 1.08Bk-1 for k  1.

    These rules stipulate that each number in the list is 1.08 times the previous
number, with the starting number equal to 100. For example

               B3 = 1.08B2
                   = 1.08 (1.08B1)
                   = 1.08 (1.08 (1.08B0))
                   = 1.08(1.08(1.08 · 100))
                   = 1.083 · 100 = 125.971

                                                                                                    
Example 8.1.8 The Fibonacci Sequence. The Fibonacci sequence is the
sequence F defined by

                                      F0 = 1, F1 = 1 and

                                 Fk = Fk-2 + Fk-1 for k  2

                                                                                                    

8.1.5 Recursion

All of the previous examples were presented recursively. That is, every "object"
is described in one of two forms. One form is by a simple definition, which is
usually called the basis for the recursion. The second form is by a recursive
description in which objects are described in terms of themselves, with the fol-
lowing qualification. What is essential for a proper use of recursion is that the
objects can be expressed in terms of simpler objects, where "simpler" means
closer to the basis of the recursion. To avoid what might be considered a circu-
lar definition, the basis must be reached after a finite number of applications
of the recursion.

    To determine, for example, the fourth item in the Fibonacci sequence we
repeatedly apply the recursive rule for F until we are left with an expression
involving F0 and F1:

                            F4 = F2 + F3

                                = (F0 + F1) + (F1 + F2)

                                = (F0 + F1) + (F1 + (F0 + F1))

                                = (1 + 1) + (1 + (1 + 1))

                                =5

8.1.6 Iteration

On the other hand, we could compute a term in the Fibonacci sequence such
as F5 by starting with the basis terms and working forward as follows:
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                                  146

Table 8.1.9

                F2 = F0 + F1 = 1 + 1 = 2
                F3 = F1 + F2 = 1 + 2 = 3
                F4 = F2 + F3 = 2 + 3 = 5
                F5 = F3 + F4 = 3 + 5 = 8

This is called an iterative computation of the Fibonacci sequence. Here we

start with the basis and work our way forward to a less simple number, such

as 5. Try to compute F5 using the recursive definition for F as we did for F4.

It will take much more time than it would have taken to do the computations

above. Iterative computations usually tend to be faster than computations

that apply recursion. Therefore, one useful skill is being able to convert a

recursive formula into a nonrecursive formula, such as one that requires only

iteration or a faster method, if possible.

An iterative formula for  n  is also much more efficient than an application
                          k
of the recursive definition. The recursive definition is not without its merits,

however. First, the recursive equation is often useful in manipulating algebraic

expressions involving binomial coefficients. Second, it gives us an insight into

the combinatoric interpretation of  n  .  In choosing k  elements from {1, 2, ..., n},
                                    k
           n-1                                                                 n-1
there are    k  ways of choosing all k from {1, 2, ..., n - 1}, and there are  k-1

ways of choosing the k elements if n is to be selected and the remaining k - 1

elements come from {1, 2, ..., n - 1}. Note how we used the Law of Addition

from Chapter 2 in our reasoning.

BinarySearch Revisited. In the binary search algorithm, the place where

recursion is used is easy to pick out. When an item is examined and the key

is not the one you want, the search is cut down to a sublist of no more than

half the number of items that you were searching in before. Obviously, this

is a simpler search. The basis is hidden in the algorithm. The two cases that

complete the search can be thought of as the basis. Either you find an item

that you want, or the sublist that you have been left to search in is empty,

when j > k.

BinarySearch can be translated without much difficulty into any language

that allows recursive calls to its subprograms. The advantage to such a program

is that its coding would be much shorter than a nonrecursive program that does

a binary search. However, in most cases the recursive version will be slower

and require more memory at execution time.

8.1.7 Induction and Recursion

The definition of the positive integers in terms of Peano's Postulates is a re-
cursive definition. The basis element is the number 1 and the recursion is that
if n is a positive integer, then so is its successor. In this case, n is the simple
object and the recursion is of a forward type. Of course, the validity of an
induction proof is based on our acceptance of this definition. Therefore, the
appearance of induction proofs when recursion is used is no coincidence.

Example 8.1.10 Proof of a formula for B. A formula for the sequence B
in Example 8.1.7 is B = 100(1.08)k for k  0. A proof by induction follow.

    If k = 0, then B = 100(1.08)0 = 100, as defined. Now assume that for some
k  1, the formula for Bk is true.

               Bk+1 = 1.08Bk by the recursive definition
                       = 1.08 100(1.08)k by the induction hypothesis

                       = 100(1.08)k+1
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                                147

hence the formula is true for k + 1

    The formula that we have just proven for B is called a closed form expres-

sion. It involves no recursion or summation signs.                           

Definition 8.1.11 Closed Form Expression. Let E = E (x1, x2, . . . , xn) be

an algebraic expression involving variables x1, x2, . . . , xn which are allowed to

take on values from some predetermined set. E is a closed form expression

if there exists a number T such that the evaluation of E with any allowed

values of the variables will take no more than T operations (alternatively, T

time units).                                                                 

Example 8.1.12 Reducing a summation to closed form. The sum

E(n) = k=1 n k is not a closed form expression because the number of addi-
tions needed to evaluate E(n) grows indefinitely with n. A closed form expres-

sion that computes the value of E(n) is 2 n(n+1) , which only requires T = 3
operations.                                                                  

8.1.8 Exercises

1.  By the recursive definition of binomial coefficients,  7  =  6  +  6  .  Con-
                                                           2     2     1
                     7
    tinue expanding  2  to express it in terms of quantities defined by the

    basis. Check your result by applying the factorial definition of kn .

2. Define the sequence L by L0 = 5 and for k  1, Lk = 2Lk-1 - 7.
      Determine L4 and prove by induction that Lk = 7 - 2k+1.

3. Let p(x) = x5 + 3x4 - 15x3 + x - 10.

    (a) Write p(x) in telescoping form.

    (b) Use a calculator to compute p(3) using the original form of p(x).

    (c) Use a calculator to compute p(3) using the telescoping form of p(x).

        (d) Compare your speed in parts b and c.

4. Suppose that a list of nine items, (r(l), r(2), ..., r(9)), is sorted by key in
      decending order so that r(3).key = 12 and r(4).key = 10. List the execu-
      tions of the BinarySearch algorithms that would be needed to complete
      BinarySearch(1,9) when:

    (a) The search key is C = 12         (b) The search key is C = 11

           Assume that distinct items have distinct keys.

5. What is wrong with the following definition of f : R  R? f (0) = 1 and
      f (x) = f (x/2)/2 if x = 0.

6. Prove the two definitions of binomials coefficients, Definition 2.4.3 and
      Definition 8.1.1, are equivalent.

7. Prove by induction that if n  0, k=0 k n n = 2n
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                      148

8.2 Sequences

8.2.1 Sequences and Ways They Are Defined

Definition 8.2.1 Sequence. A sequence is a function from the natural

numbers into some predetermined set. The image of any natural number k can

be written as S(k) or Sk and is called the kth term of S. The variable k is

called the index or argument of the sequence.                      

For example, a sequence of integers would be a function S : N  Z.

Example 8.2.2 Three sequences defined in different ways.

(a) The sequence A defined by A(k) = k2 -k, k  0, is a sequence of integers.

(b) The sequence B defined recursively by B(0) = 2 and B(k) = B(k - 1) + 3
     for k  1 is a sequence of integers. The terms of B can be computed
     either by applying the recursion formula or by iteration. For example,

                            B(3) = B(2) + 3
                                   = (B(1) + 3) + 3
                                   = ((B(0) + 3) + 3) + 3
                                   = ((2 + 3) + 3) + 3 = 11

or
                            B(1) = B(0) + 3 = 2 + 3 = 5
                            B(2) = B(1) + 3 = 5 + 3 = 8
                           B(3) = B(2) + 3 = 8 + 3 = 11

(c) Let Cr be the number of strings of 0's and 1's of length r having no
     consecutive zeros. These terms define a sequence C of integers.

                                                                                                  
  Remarks:

(1) A sequence is often called a discrete function.

(2) Although it is important to keep in mind that a sequence is a func-
     tion, another useful way of visualizing a sequence is as a list. For ex-
     ample, the sequence A in the previous example could be written as
     (0, 0, 2, 6, 12, 20, . . . ). Finite sequences can appear much the same way
     when they are the input to or output from a computer. The index of
     a sequence can be thought of as a time variable. Imagine the terms of
     a sequence flashing on a screen every second. Then sk would be what
     you see in the kth second. It is convenient to use terminology like this in
     describing sequences. For example, the terms that precede the kth term
     of A would be A(0), A(1), ..., A(k - 1). They might be called the earlier
     terms.

8.2.2 A Fundamental Problem

Given the definition of any sequence, a fundamental problem that we will
concern ourselves with is to devise a method for determining any specific term
in a minimum amount of time. Generally, time can be equated with the number
of operations needed. In counting operations, the application of a recursive
formula would be considered an operation.
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS  149

(a) The terms of A in Example 8.2.2 are very easy to compute because of
     the closed form expression. No matter what term you decide to compute,
     only three operations need to be performed.

(b) How to compute the terms of B is not so clear. Suppose that you wanted
     to know B(100). One approach would be to apply the definition recur-
     sively:
                       B(100) = B(99) + 3 = (B(98) + 3) + 3 = · · ·

     The recursion equation for B would be applied 100 times and 100 ad-
     ditions would then follow. To compute B(k) by this method, 2k opera-
     tions are needed. An iterative computation of B(k) is an improvement:
     B(1) = B(0) + 3 = 2 + 3 = 5

     B(2) = B(1) + 3 = 5 + 3 = 8

     etc. Only k additions are needed. This still isn't a good situation. As k
     gets large, we take more and more time to compute B(k). The formula
     B(k) = B(k - 1) + 3 is called a recurrence relation on B. The process
     of finding a closed form expression for B(k), one that requires no more
     than some fixed number of operations, is called solving the recurrence
     relation.

(c) The determination of Ck is a standard kind of problem in combinatorics.
     One solution is by way of a recurrence relation. In fact, many problems
     in combinatorics are most easily solved by first searching for a recurrence
     relation and then solving it. The following observation will suggest the
     recurrence relation that we need to determine Ck. If k  2, then every
     string of 0's and 1's with length k and no two consecutive 0's is either
     1sk-1 or 01sk-2, where sk-1 and sk-2 are strings with no two consecutive
     0's of length k - 1 and k - 2 respectively. From this observation we can
     see that Ck = Ck-2 + Ck-1 for k  2. The terms C0 = 1 and C1 = 2
     are easy to determine by enumeration. Now, by iteration, any Ck can
     be easily determined. For example, C5 = 21 can be computed with five
     additions. A closed form expression for Ck would be an improvement.
     Note that the recurrence relation for Ck is identical to the one for The
     Fibonacci Sequence. Only the basis is different.

8.2.3 Exercises

1. Prove by induction that B(k) = 3k + 2, k  0, is a closed form expression
      for the sequence B in Example 8.2.2

2. The sequence of first differences of any sequence S is the sequence S(k +
      1) - S(k). The sequence of second differences is the sequence of first
      differences of the first differences:

      (S(k + 2) - S(k + 1)) - (S(k + 1) - S(k)) = S(k + 2) - 2S(k + 1) + S(k).

        (a) Consider sequence Q defined by Q(k) = 2k + 9, k  1. Complete
              the table below and determine a recurrence relation that describes
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS  150

                    k Q(k) Q(k + 1) - Q(k)
                    0
                    1
              Q. 2
                    3
                    4
                    5

        (b) Let A(k) = k2 - k, k  0. Complete the table below and determine
              a recurrence relation for A.

                    k A(k) A(k + 1) - A(k) A(k + 2) - 2A(k + 1) + A(k)
                    0
                    1
                    2
                    3
                    4
                    5

3. Given k lines (k  0) on a plane such that no two lines are parallel
      and no three lines meet at the same point, let P (k) be the number of
      regions into which the lines divide the plane (including the infinite ones
      (see Figure 8.2.3). Describe how the recurrence relation P (k) = P (k -
      1) + k can be derived. Given that P (0) = 1, determine P (5).

      Figure 8.2.3 A general configuration of three lines

4. A sample of a radioactive substance is expected to decay by 0.15 percent
      each hour. If wt, t  0, is the weight of the sample t hours into an
      experiment, write a recurrence relation for w.

5. Let M (n) be the number of multiplications needed to evaluate an nth
      degree polynomial. Use the recursive definition of a polynomial expression
      to define M recursively.

6. Let S be sequence of integers. Using short English sentences, not sym-
      bols, describe what the following propositions say about S. Are the two
      propositions equivalent?

        (a) (M )N((n)N(S(n)  M ))
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS         151

(b) (M )N((N )N((n)N(n  N  S(n)  M )))

8.3 Recurrence Relations

In this section we will begin our study of recurrence relations and their solu-
tions. Our primary focus will be on the class of finite order linear recurrence
relations with constant coefficients (shortened to finite order linear relations).
First, we will examine closed form expressions from which these relations arise.
Second, we will present an algorithm for solving them. In later sections we
will consider some other common relations (8.4) and introduce two additional
tools for studying recurrence relations: generating functions (8.5) and matrix
methods (Chapter 12).

8.3.1 Definition and Terminology

Definition 8.3.1 Recurrence Relation. Let S be a sequence of numbers.

A recurrence relation on S is a formula that relates all but a finite number of

terms of S to previous terms of S. That is, there is a k0 in the domain of S
such that if k  k0, then S(k) is expressed in terms of some (and possibly all)
of the terms that precede S(k). If the domain of S is {0, 1, 2, . . . }, the terms
S(0), S(1), ..., S (k0 - 1) are not defined by the recurrence formula. Their values
are the initial conditions (or boundary conditions, or basis) that complete the

definition of S.                                      

Example 8.3.2 Some Examples of Recurrence Relations.

(a) The Fibonacci sequence is defined by the recurrence relation Fk = Fk-2 +
     Fk-1, k  2, with the initial conditions F0 = 1 and F1 = 1. The
     recurrence relation is called a second-order relation because Fk depends
     on the two previous terms of F . Recall that the sequence C in Section

     8.2, Example 8.2.2, can be defined with the same recurrence relation, but

     with different initial conditions.

(b) The relation T (k) = 2T (k-1)2-kT (k-3) is a third-order recurrence rela-
     tion. If values of T (0), T (1), and T (2) are specified, then T is completely
     defined.

(c) The recurrence relation S(n) = S(n/2) + 5, n > 0, with S(0) = 0 has
     infinite order. To determine S(n) when n is even, you must go back n/2
     terms. Since n/2 grows unbounded with n, no finite order can be given
     to S.

                                                      

8.3.2 Solving Recurrence Relations

Sequences are often most easily defined with a recurrence relation; however,
the calculation of terms by directly applying a recurrence relation can be time-
consuming. The process of determining a closed form expression for the terms
of a sequence from its recurrence relation is called solving the relation. There
is no single technique or algorithm that can be used to solve all recurrence
relations. In fact, some recurrence relations cannot be solved. The relation
that defines T above is one such example. Most of the recurrence relations
that you are likely to encounter in the future are classified as finite order linear
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                     152

recurrence relations with constant coefficients. This class is the one that we
will spend most of our time with in this chapter.

Definition 8.3.3 nth Order Linear Recurrence Relation. Let S be
a sequence of numbers with domain k  0. An nth order linear recurrence
relation on S with constant coefficients is a recurrence relation that can be
written in the form

           S(k) + C1S(k - 1) + ... + CnS(k - n) = f (k) for k  n

where C1, C2, . . . , Cn are constants and f is a numeric function that is defined

for k  n.                                                         

Note: We will shorten the name of this class of relations to nth order linear

relations. Therefore, in further discussions, S(k) + 2kS(k - 1) = 0 would not

be considered a first-order linear relation.

Example 8.3.4 Some Finite Order Linear Relations.

(a) The Fibonacci sequence is defined by the second-order linear relation
     because Fk - Fk-1 - Fk-2 = 0

(b) The relation P (j) + 2P (j - 3) = j2 is a third-order linear relation. In
     this case, C1 = C2 = 0.

(c) The relation A(k) = 2(A(k - 1) + k) can be written as A(k) - 2A(k - 1) =
     2k. Therefore, it is a first-order linear relation.

                                                                  

8.3.3 Recurrence Relations Obtained from "Solutions"

Before giving an algorithm for solving finite order linear relations, we will
examine recurrence relations that arise from certain closed form expressions.
The closed form expressions are selected so that we will obtain finite order
linear relations from them. This approach may seem a bit contrived, but if
you were to write down a few simple algebraic expressions, chances are that
most of them would be similar to the ones we are about to examine.

    For our first example, consider D, defined by D(k) = 5 · 2k, k  0. If k  1,
D(k) = 5 · 2k = 2 · 5 · 2k-1 = 2D(k - 1). Therefore, D satisfies the first order
linear relation D(k) - 2D(k - 1) = 0 and the initial condition D(0) = 5 serves
as an initial condition for D.

    As a second example, consider C(k) = 3k-1 + 2k+1 + k , k  0. Quite a bit
more algebraic manipulation is required to get our result:
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                  153

Table 8.3.5

C(k) = 3k-1 + 2k+1 + k                         Original equation
3C(k - 1) = 3k-1 + 3 · 2k + 3(k - 1)           Substitute k - 1 for k
                                                and multiply by 3
C(k) - 3C(k - 1) = -2k - 2k + 3                Subtract the second equation
2C(k - 1) - 6C(k - 2) = -2k - 2(2(k - 1)) + 6  from the first.
                                               3k-1 term is eliminated.
C(k) - 5C(k - 1) + 6C(k - 2) = 2k - 7           This is a first order relation.
                                               Substitute k - 1 for k in the
                                               third equation, multiply by 2.
                                               Subtract the 4th equation from the 3rd.
                                               2k+1term is eliminated.
                                               This is 2nd order relation.

    The recurrence relation that we have just obtained, defined for k  2,
together with the initial conditions C(0) = 7/3 and C(1) = 6, define C.

    Table 8.3.6 summarizes our results together with a few other examples that
we will let the reader derive. Based on these results, we might conjecture
that any closed form expression for a sequence that combines exponential ex-
pressions and polynomial expressions will be solutions of finite order linear
relations. Not only is this true, but the converse is true: a finite order linear
relation defines a closed form expression that is similar to the ones that were
just examined. The only additional information that is needed is a set of initial
conditions.

Table 8.3.6 Recurrence Relations Obtained from Given Sequences

Closed Form Expression              Recurrence Relation
       D(k) = 5 · 2k               D(k) - 2D(k - 1) = 0
                        C(k) - 2C(k - 1) - 6C(k - 2) = 2k - 7
C(k) = 3k-1 + 2k+1 + k              Q(k) - Q(k - 1) = 2
                            A(k) - 2A(k - 1) + A(k - 2) = 2
      Q(k) = 2k + 9         B(k) - 2B(k - 1) + B(k - 2) = 4
      A(k) = k2 - k        G(k) - G(k - 1) + 12G(k - 2) = 0
     B(k) = 2k2 + 1         J(k) - 4J(k - 1) + 4J(k - 2) = 0
G(k) = 2 · 4k - 5(-3)k
    J(k) = (3 + k)2k

Definition 8.3.7 Homogeneous Recurrence Relation. An nth order

linear relation is homogeneous if f (k) = 0 for all k. For each recurrence relation

S(k)+C1S(k-1)+. . .+CnS(k-n) = f (k), the associated homogeneous relation

is S(k) + C1S(k - 1) + . . . + CnS(k - n) = 0                  

Example 8.3.8 First Order Homogeneous Recurrence Relations.

D(k) - 2D(k - 1) = 0 is a first-order homogeneous relation. Since it can
also be written as D(k) = 2D(k - 1), it should be no surprise that it arose
from an expression that involves powers of 2. More generally, you would expect
that the solution of L(k) - aL(k - 1) would involve ak. Actually, the solution
is L(k) = L(0)ak, where the value of L(0) is given by the initial condition. 

Example 8.3.9 A Second Order Example. Consider the second-order
homogeneous relation S(k) - 7S(k - 1) + 12S(k - 2) = 0 together with the
initial conditions S(0) = 4 and S(1) = 4. From our discussion above, we can
predict that the solution to this relation involves terms of the form bak, where
b and a are nonzero constants that must be determined. If the solution were
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                          154

to equal this quantity exactly, then

                           S(k) = bak
                       S(k - 1) = bak-1
                       S(k - 2) = bak-2

Substitute these expressions into the recurrence relation to get

                       bak - 7bak-1 + 12bak-2 = 0

Each term on the left-hand side of this equation has a factor of bak-2, which
is nonzero. Dividing through by this common factor yields

                     a2 - 7a + 12 = (a - 3)(a - 4) = 0                 (8.3.1)

    Therefore, the only possible values of a are 3 and 4. Equation (8.3.1) is
called the characteristic equation of the recurrence relation. The fact is that
our original recurrence relation is true for any sequence of the form S(k) =
b13k +b24k, where b1 and b2 are real numbers. This set of sequences is called the
general solution of the recurrence relation. If we didn't have initial conditions
for S, we would stop here. The initial conditions make it possible for us to find
definite values for b1 and b2.

           S(0) = 4    b130 + b240 = 4            b1 + b2 = 4
           S(1) = 4                                     3b1 + 4b2 = 4
                       b13 + b24 = 41 1

The solution of this set of simultaneous equations is b1 = 12 and b2 = -8

and so the solution is S(k) = 12 · 3k - 8 · 4k.                        

Definition 8.3.10 Characteristic Equation. The characteristic equation
of the homogeneous nth order linear relation S(k) + C1S(k - 1) + . . . + CnS(k -
n) = 0 is the nth degree polynomial equation

                      n

           an + Cj an-j = an + C1an-1 + · · · + Cn-1a + Cn = 0

                     j=1

The left-hand side of this equation is called the characteristic polynomial. The

roots of the characteristic polynomial are called the characteristic roots of the

equation.                                                              

Example 8.3.11 Some characteristic equations.

(a) The characteristic equation of F (k)-F (k-1)-F (k-2) = 0 is a2-a-1 =
     0.

(b) The characteristic equation of Q(k)+2Q(k-1)-3Q(k-2)-6Q(k-4) = 0
     is a4 + 2a3 - 3a2 - 6 = 0. Note that the absence of a Q(k - 3) term
     means that there is not an x4-3 = x term appearing in the characteristic

     equation.

                                                                                                    
Algorithm 8.3.12 Algorithm for Solving Homogeneous Finite Order
Linear Relations.

  (a) Write out the characteristic equation of the relation S(k) + C1S(k - 1) +
       . . . + CnS(k - n) = 0, which is an + C1an-1 + · · · + Cn-1a + Cn = 0.

  (b) Find all roots of the characteristic equation, the characteristic roots.
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                                                               155

(c) If there are n distinct characteristic roots, a1, a2, . . . an, then the general

     solution of the recurrence relation is S(k) = b1a1k + b2a2k + · · · + bnank.

     If there are fewer than n characteristic roots, then at least one root is a

     multiple root. If aj is a double root, then the bjajk term is replaced with

     (bj,0  +  b  j,  1  k  )  a  k  .  In  general,  if  aj  is  a  root  of  multiplicity  p,  then  the  bj aj k
                                  j

     term is replaced with bj,0 + bj,1k + · · · + bj,(p-1)kp-1 akj .

(d) If n initial conditions are given, we get n linear equations in n unknowns
     (the bjs from Step 3) by substitution. If possible, solve these equations
     to determine a final form for S(k).

Although this algorithm is valid for all values of n, there are limits to the

size of n for which the algorithm is feasible. Using just a pencil and paper, we

can always solve second-order equations. The quadratic formula for the roots

of ax2 + bx + c = 0 is                                     
                                              x = -b ± b2 - 4ac

                                                            2a

The solutions of a2 + C1a + C2 = 0 are then

            1                               C12 - 4C2        and 1 -C1 -       C12 - 4C2
            2 -C1 +                                                2

    Although cubic and quartic formulas exist, they are too lengthy to introduce
here. For this reason, the only higher-order relations (n  3) that you could
be expected to solve by hand are ones for which there is an easy factorization
of the characteristic polynomial.

Example 8.3.13 A solution using the algorithm. Suppose that T is
defined by T (k) = 7T (k - 1) - 10T (k - 2), with T (0) = 4 and T (1) = 17. We
can solve this recurrence relation with Algorithm 8.3.12:

(a) Note that we have written the recurrence relation in "nonstandard" form.

     To avoid errors in this easy step, you might consider a rearrangement of

     the equation to, in this case, T (k)-7T (k-1)+10T (k-2) = 0. Therefore,

     the characteristic equation is a2 - 7a + 10 = 0.

(b) The characteristic roots are 21 7 + 49 - 40                                                  = 5 and
               
     2 7 - 49 - 40 = 2. These roots can be just as easily obtained1

     by factoring the characteristic polynomial into (a - 5)(a - 2).

(c) The general solution of the recurrence relation is T (k) = b12k + b25k.

(d)            T (0) = 4                              b120 + b250 = 4                        b1 + b2 = 4

            T (1) = 17                        b12 + b25 = 171        1           2b1 + 5b2 = 17

     The simultaneous equations have the solution b1 = 1 and b2 = 3. There-

     fore, T (k) = 2k + 3 · 5k.

                                                                                                    
    Here is one rule that might come in handy: If the coefficients of the char-
acteristic polynomial are all integers, with the constant term equal to m, then
the only possible rational characteristic roots are divisors of m (both positive
and negative).
    With the aid of a computer (or possibly only a calculator), we can increase n.
Approximations of the characteristic roots can be obtained by any of several
well-known methods, some of which are part of standard software packages.
There is no general rule that specifies the values of n for which numerical
approximations will be feasible. The accuracy that you get will depend on the
relation that you try to solve. (See Exercise 17 of this section.)
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                     156

Example 8.3.14 Solution of a Third Order Recurrence Relation.
Solve S(k) - 7S(k - 2) + 6S(k - 3) = 0, where S(0) = 8, S(1) = 6, and
S(2) = 22.

(a) The characteristic equation is a3 - 7a + 6 = 0.

(b) The only rational roots that we can attempt are ±1, ±2, ±3, and ± 6. By
     checking these, we obtain the three roots 1, 2, and -3.

(c) The general solution is S(k) = b11k + b22k + b3(-3)k. The first term can

simply be written b1 .

                                             
 S(0) = 8       b1 + b2 + b3 = 8 

(d)  S(1) = 6    b1 + 2b2 - 3b3 = 6  You can solve this sys-
  S(2) = 22             b1 + 4b2 + 9b3 = 22

tem by elimination to obtain b1 = 5, b2 = 2, and b3 = 1. Therefore,

S(k) = 5 + 2 · 2k + (-3)k = 5 + 2k+1 + (-3)k

                                                                                                    
Example 8.3.15 Solution with a Double Characteristic Root. Solve
D(k) - 8D(k - 1) + 16D(k - 2) = 0, where D(2) = 16 and D(3) = 80.

(a) Characteristic equation: a2 - 8a + 16 = 0.
(b) a2 - 8a + 16 = (a - 4)2. Therefore, there is a double characteristic root,

     4.

(c) General solution: D(k) = (b1,0 + b1,1k) 4k.
(d)

  D(2) = 16             (b1,0 + b1,12) 42 = 16
  D(3) = 80
                        3(b1,0 + b1,13) 4 = 80

                        16b1,0 + 32b1,1 = 16           b1,0 = 21

                        64b1,0 + 192b1,1 = 80          b1,1 = 41

Therefore D(k) = (1/2 + (1/4)k)4k = (2 + k)4k-1.
                                                                                             

8.3.4 Solution of Nonhomogeneous Finite Order Linear Re-
        lations

Our algorithm for nonhomogeneous relations will not be as complete as for
the homogeneous case. This is due to the fact that different right-hand sides
(f (k)'s) call for different rules in obtaining a particular solution.

Algorithm 8.3.16 Algorithm for Solving Nonhomogeneous Finite
Order Linear Relations. To solve the recurrence relation S(k) + C1S(k -
1) + . . . + CnS(k - n) = f (k)

  (1) Write the associated homogeneous relation and find its general solution
       (Steps (a) through (c) of Algorithm 8.3.12). Call this the homogeneous
       solution, S(h)(k).

  (2) Start to obtain what is called a particular solution, S(p)(k) of the recur-
       rence relation by taking an educated guess at the form of a particular
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS           157

       solution. For a large class of right-hand sides, this is not really a guess,
       since the particular solution is often the same type of function as f (k)
       (see Table 8.3.17).

  (3) Substitute your guess from Step 2 into the recurrence relation. If you
       made a good guess, you should be able to determine the unknown coeffi-
       cients of your guess. If you made a wrong guess, it should be apparent
       from the result of this substitution, so go back to Step 2.

  (4) The general solution of the recurrence relation is the sum of the homoge-
       neous and particular solutions. If no conditions are given, then you are
       finished. If n initial conditions are given, they will translate to n linear
       equations in n unknowns and solve the system to get a complete solution.

Table 8.3.17 Particular solutions for given right-hand sides

               Right Hand Side, f (k)                  Form of Particular Solution, S(p)(k)

                       Constant, q                                     Constant, d

             Linear Function, q0 + q1k                       Linear Function, d0 + d1k
mth degree polynomial, q0 + q1k + · · · + qmkm  mth degree polynomial, d0 + d1k + · · · + dmkm

             exponential function, qak                        exponential function, dak

Example 8.3.18 Solution of a Nonhomogeneous First Order Recur-
rence Relation. Solve S(k) + 5S(k - 1) = 9, with S(0) = 6.

(a) The associated homogeneous relation,S(k)+5S(k -1) = 0 has the charac-
     teristic equation a + 5 = 0; therefore, a = -5. The homogeneous solution
     is S(h)(k) = b(-5)k.

(b) Since the right-hand side is a constant, we guess that the particular so-
     lution will be a constant, d.

(c) If we substitute S(p)(k) = d into the recurrence relation, we get d+5d = 9,
     or 6d = 9. Therefore, S(p)(k) = 1.5.

(d) The general solution of the recurrence relation is S(k) = S(h)(k) +
     S(p)(k) = b(-5)k + 1.5 The initial condition will give us one equation
     to solve in order to determine b. S(0) = 6  b(-5)0 + 1.5 = 6 
      b + 1.5 = 6 Therefore, b = 4.5 and S(k) = 4.5(-5)k + 1.5.

                                                                                                    
Example 8.3.19 Solution of a Nonhomogeneous Second Order Re-
currence Relation. Consider T (k) - 7T (k - 1) + 10T (k - 2) = 6 + 8k with
T (0) = 1 and T (1) = 2.

(a) From Example 8.3.13, we know that T (h)(k) = b12k+b25k. Caution:Don't
     apply the initial conditions to T (h) until you add T (p)!

(b) Since the right-hand side is a linear polynomial, T (p) is linear; that is,
     T (p)(k) = d0 + d1k.

(c) Substitution into the recurrence relation yields: (d0 + d1k) -

7 (d0 + d1(k - 1)) + 10 (d0 + d1(k - 2)) = 6 + 8k  (4d0 - 13d1) +
(4d1) k = 6 + 8k Two polynomials are equal only if their coefficients

are equal. Therefore,  4d0 - 13d1 = 6  d0 = 8
                       4d1 = 8                  d1 = 2

(d) Use the general solution T (k) = b12k + b25k + 8 + 2k and the
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                       158

initial conditions to get a final solution:    T (0) = 1 
                                               T (1) = 2
      b1 + b2 + 8 = 1
   2b1 + 5b2 + 10 = 2
 b1 + b2 = -7

       2b1 + 5b2 = -8
 b1 = -9

        b2 = 2
Therefore, T (k) = -9 · 2k + 2 · 5k + 8 + 2k.

                                                                                                     
Note 8.3.20 A quick note on interest rates. When a quantity, such as
a savings account balance, is increased by some fixed percent, it is most easily
computed with a multiplier. In the case of an 8% increase, the multiplier is
1.08 because any original amount A, has 0.08A added to it, so that the new
balance is A + 0.08A = (1 + 0.08)A = 1.08A.

    Another example is that if the interest rate is 3.5%, the multiplier would
be 1.035. This presumes that the interest is applied at the end of year for
3.5% annual interest, often called simple interest. If the interest is applied
monthly, and we assume a simplifed case where each month has the same
length, the multiplier after every month would be 1 + 12 0.035  1.00292. After
a year passes, this multiplier would be applied 12 times, which is the same as
multiplying by 1.0029212  1.03557. That increase from 1.035 to 1.03557 is
the effect of compound interest.

Example 8.3.21 A Sort of Annuity. Suppose you open a savings account
that pays an annual interest rate of 8%. In addition, suppose you decide to
deposit one dollar when you open the account, and you intend to double your
deposit each year. Let B(k) be your balance after k years. B can be described
by the relation B(k) = 1.08B(k -1)+2k, with S(0) = 1. If, instead of doubling
the deposit each year, you deposited a constant amount, q, the 2k term would
be replaced with q. A sequence of regular deposits such as this is called a
simple annuity.

    Returning to the original situation,

(a) B(h)(k) = b1(1.08)k
(b) B(p)(k) should be of the form d2k.
(c)

d2k = 1.08d2k-1 + 2k  (2d)2k-1 = 1.08d2k-1 + 2 · 2k-1
                              2d = 1.08d + 2
                              .92d = 2
                              d = 2.174 to the nearest thousandth)

     Therefore B(p)(k) = 2.174 · 2k.
(d) B(0) = 1  b1 + 2.174 = 1

 b1 = -1.174
Therefore, B(k) = -1.174 · 1.08k + 2.174 · 2k.

                                                                                             
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS  159

Example 8.3.22 Matching Roots. Find the general solution to S(k) -
3S(k - 1) - 4S(k - 2) = 4k.

  (a) The characteristic roots of the associated homogeneous relation are -1
       and 4. Therefore, S(h)(k) = b1(-1)k + b24k.

  (b) A function of the form d4k will not be a particular solution of the nonho-
       mogeneous relation since it solves the associated homogeneous relation.
       When the right-hand side involves an exponential function with a base
       that equals a characteristic root,you should multiply your guess at a par-
       ticular solution by k. Our guess at S(p)(k) would then be dk4k . See
       Observation 8.3.23 for a more complete description of this rule.

  (c) Substitute dk4k into the recurrence relation for S(k):

                          dk4k - 3d(k - 1)4k-1 - 4d(k - 2)4k-2 = 4k
                      16dk4k-2 - 12d(k - 1)4k-2 - 4d(k - 2)4k-2 = 4k

       Each term on the left-hand side has a factor of 4k-2

                   16dk - 12d(k - 1) - 4d(k - 2) = 4220d = 16  d = 0.8

       Therefore, S(p)(k) = 0.8k4k.

  (d) The general solution to the recurrence relation is

                                  S(k) = b1(-1)k + b24k + 0.8k4k

                                                                                                    
Observation 8.3.23 When the base of right-hand side is equal to a
characteristic root. If the right-hand side of a nonhomogeneous relation
involves an exponential with base a, and a is also a characteristic root of
multiplicity p, then multiply your guess at a particular solution as prescribed
in Table 8.3.17 by kp, where k is the index of the sequence.

Example 8.3.24 Examples of matching bases.

  (a) If S(k) - 9S(k - 1) + 20S(k - 2) = 2 · 5k, the characteristic roots are 4
       and 5. Since 5 matches the base of the right side, S(p)(k) will take the
       form dk5k.

  (b) If S(n) - 6S(n - 1) + 9S(n - 2) = 3n+1 the only characteristic root is
       3, but it is a double root (multiplicity 2). Therefore, the form of the
       particular solution is dn23n.

  (c) If Q(j)-Q(j -1)-12Q(j -2) = (-3)j +6·4j, the characteristic roots are
       -3 and 4. The form of the particular solution will be d1j(-3)j + d2j · 4j.

  (d) If S(k) - 9S(k - 1) + 8S(k - 2) = 9k + 1 = (9k + 1)1k, the characteristic
       roots are 1 and 8. If the right-hand side is a polynomial, as it is in this
       case, then the exponential factor 1k can be introduced. The particular
       solution will take the form k (d0 + d1k).

                                                                                                    
    We conclude this section with a comment on the situation in which the
characteristic equation gives rise to complex roots. If we restrict the coefficients
of our finite order linear relations to real numbers, or even to integers, we
can still encounter characteristic equations whose roots are complex. Here,
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS  160

we will simply take the time to point out that our algorithms are still valid
with complex characteristic roots, but the customary method for expressing
the solutions of these relations is different. Since an understanding of these
representations requires some background in complex numbers, we will simply
suggest that an interested reader can refer to a more advanced treatment of
recurrence relations (see also difference equations).

8.3.5 Exercises

Exercise Group. Solve the following sets of recurrence relations and initial
conditions:

     1. S(k) - 10S(k - 1) + 9S(k - 2) = 0, S(0) = 3, S(1) = 11
     2. S(k) - 9S(k - 1) + 18S(k - 2) = 0, S(0) = 0, S(1) = 3
     3. S(k) - 0.25S(k - 1) = 0, S(0) = 6
     4. S(k) - 20S(k - 1) + 100S(k - 2) = 0, S(0) = 2, S(1) = 50
     5. S(k) - 2S(k - 1) + S(k - 2) = 2, S(0) = 25, S(1) = 16
     6. S(k) - S(k - 1) - 6S(k - 2) = -30, S(0) = 7, S(1) = 6

     7. S(k) - 5S(k - 1) = 5k, S(0) = 3
     8. S(k) - 5S(k - 1) + 6S(k - 2) = 2, S(0) = -1, S(1) = 0

     9. S(k) - 4S(k - 1) + 4S(k - 2) = 3k + 2k, S(0) = 1, S(1) = 1
     10. S(k) = rS(k - 1) + a, S(0) = 0, r, a  0, r = 1
     11. S(k) - 4S(k - 1) - 11S(k - 2) + 30S(k - 3) = 0, S(0) = 0,S(1) =

           -35, S(2) = -85
12. Find a closed form expression for P (k) in Exercise 8.2.3.3 of Section 8.2.
13.

(a) Find a closed form expression for the terms of the Fibonacci sequence
     (see Example 8.1.8).

        (b) The sequence C was defined by Cr = the number of strings of
              zeros and ones with length r having no consecutive zeros (Exam-
              ple 8.2.2(c)). Its recurrence relation is the same as that of the Fi-
              bonacci sequence. Determine a closed form expression for Cr, r  1.

14. If S(n) = j=1 n g(j),n  1, then S can be described with the recurrence
      relation S(n) = S(n - 1) + g(n). For each of the following sequences that
      are defined using a summation, find a closed form expression:

(a) S(n) =       j=1 n j, n  1
(b) Q(n) =       j=1 n j2, n  1

         (c) P (n) = j=1 2 n 1 j , n  1

        (d) T (n) = j=1 n j3, n  1
15. Let D(n) be the number of ways that the set {1, 2, ..., n}, n  1, can be

      partitioned into two nonempty subsets.

(a) Find a recurrence relation for D. (Hint: It will be a first-order linear
     relation.)

(b) Solve the recurrence relation.
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS  161

16. If you were to deposit a certain amount of money at the end of each
      year for a number of years, this sequence of payments would be called an
      annuity (see Example 8.3.21).

        (a) Find a closed form expression for the balance or value of an annuity
              that consists of payments of q dollars at a rate of interest of i. Note
              that for a normal annuity, the first payment is made after one year.
              However, assume that there is an initial balance b0. This will be
              convenient to apply our solution to the case of a loan.

        (b) With an interest rate of 5.5 percent, how much would you need to
              deposit into an annuity to have a value of one million dollars after
              18 years?

         (c) The payment of a loan is a form of annuity in which the initial value
              is some negative amount (the amount of the loan) and the annuity
              ends when the value is raised to zero. How much could you borrow
              if you can afford to pay $5,000 per year for 25 years at 11 percent
              interest?

17. Suppose that C is a small positive number. Consider the recurrence
      relation B(k) - 2B(k - 1) + 1 - C2 B(k - 2) = C2, with initial condi-
      tions B(0) = 1 and B(1) = 1. If C is small enough, we might consider
      approximating the relation by replacing 1 - C2 with 1 and C2 with 0.
      Solve the original relation and its approximation. Let Ba a be the solu-
      tion of the approximation. Compare closed form expressions for B(k) and
      Ba(k). Their forms are very different because the characteristic roots of
      the original relation were close together and the approximation resulted
      in one double characteristic root. If characteristic roots of a relation are
      relatively far apart, this problem will not occur. For example, compare
      the general solutions of S(k) + 1.001S(k - 1) - 2.004002S(k - 2) = 0.0001
      and Sa(k) + Sa(k - 1) - 2Sa(k - 2) = 0.

8.4 Some Common Recurrence Relations

In this section we intend to examine a variety of recurrence relations that
are not finite-order linear with constant coefficients. For each part of this
section, we will consider a concrete example, present a solution, and, if possible,
examine a more general form of the original relation.

8.4.1 A First Basic Example

Consider the homogeneous first-order linear relation without constant coeffi-
cients, S(n) - nS(n - 1) = 0, n  1, with initial condition S(0) = 1. Upon
close examination of this relation, we see that the nth term is n times the
(n - 1)st term, which is a property of n factorial. S(n) = n! is a solution of
this relation, for if n  1,

                          S(n) = n! = n · (n - 1)! = n · S(n - 1)

In addition, since 0! = 1, the initial condition is satisfied. It should be pointed
out that from a computational point of view, our "solution" really isn't much
of an improvement since the exact calculation of n! takes n - 1 multiplications.

    If we examine a similar relation, G(k)-2kG(k-1) = 0, k  1 with G(0) = 1,
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                                 162

a table of values for G suggests a possible solution:

                            k 01 2 3 4 5
                          G(k) 1 2 23 26 210 215

The exponent of 2 in G(k) is growing according to the relation E(k) = E(k -

1) + k,  with  E(0) = 0.  Thus  E(k) =  k(k+1)  and  G(k) = 2k(k+1)/2.  Note  that
                                            2
G(k) could also be written as 202122 · · · 2k, for k  0, but this is not a closed

form expression.

In general, the relation P (n) = f (n)P (n - 1) for n  1 with P (0) = f (0),

where f is a function that is defined for all n  0, has the "solution"

                                                 n

                                P (n) = f (k)

                                               k=0

This product form of P (n) is not a closed form expression because as n grows,
the number of multiplications grow. Thus, it is really not a true solution.
Often, as for G(k) above, a closed form expression can be derived from the
product form.

8.4.2 An Analysis of the Binary Search Algorithm

8.4.2.1

Suppose you intend to use a binary search algorithm (see Subsection 8.1.3) on
lists of zero or more sorted items, and that the items are stored in an array,
so that you have easy access to each item. A natural question to ask is "How
much time will it take to complete the search?" When a question like this is
asked, the time we refer to is often the so-called worst-case time. That is, if
we were to search through n items, what is the longest amount of time that
we will need to complete the search? In order to make an analysis such as
this independent of the computer to be used, time is measured by counting the
number of steps that are executed. Each step (or sequence of steps) is assigned
an absolute time, or weight; therefore, our answer will not be in seconds, but
in absolute time units. If the steps in two different algorithms are assigned
weights that are consistent, then analyses of the algorithms can be used to
compare their relative efficiencies. There are two major steps that must be
executed in a call of the binary search algorithm:

(1) If the lower index is less than or equal to the upper index, then the middle
     of the list is located and its key is compared to the value that you are
     searching for.

(2) In the worst case, the algorithm must be executed with a list that is
     roughly half as large as in the previous execution. If we assume that
     Step 1 takes one time unit and T (n) is the worst-case time for a list of n
     items, then

                          T (n) = 1 + T (n/2), n > 0                    (8.4.1)

For simplicity, we will assume that

                                        T (0) = 0                       (8.4.2)

even though the conditions of Step 1 must be evaluated as false if n = 0.
You might wonder why n/2 is truncated in (8.4.1). If n is odd, then
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS  163

n = 2k + 1 for some k  0, the middle of the list will be the (k + 1)st
item, and no matter what half of the list the search is directed to, the
reduced list will have k = n/2 items. On the other hand, if n is even,
then n = 2k for k > 0. The middle of the list will be the kth item, and
the worst case will occur if we are directed to the k items that come after
the middle (the (k + 1)st through (2k)th items). Again the reduced list
has n/2 items.

    Solution to (8.4.1) and (8.4.2). To determine T (n), the easiest case is when
n is a power of two. If we compute T (2m), m  0 , by iteration, our results
are

                                      T (1) = 1 + T (0) = 1

                                      T (2) = 1 + T (1) = 2

                                      T (4) = 1 + T (2) = 3

                                      T (8) = 1 + T (4) = 4

The pattern that is established makes it clear that T (2m) = m + 1. This result
would seem to indicate that every time you double the size of your list, the
search time increases by only one unit.

    A more complete solution can be obtained if we represent n in binary form.
For each n  1, there exists a non-negative integer r such that

     2r-1  n < 2r                              (8.4.3)

For example, if n = 21, 24  21 < 25; therefore, r = 5. If n satisfies (8.4.3), its
binary representation requires r digits. For example, 21ten = 10101two.

    In general, n = (a1a2 . . . ar)two. where a1 = 1. Note that in this form,
n/2 is easy to describe: it is the r - 1 digit binary number (a1a2 . . . ar-1)two

    Therefore,

T (n) = T (a1a2 . . . ar)

= 1 + T (a1a2 . . . ar-1)

= 1 + (1 + T (a1a2 . . . ar-2))

= 2 + T (a1a2 . . . ar-2)

...                              .

= (r - 1) + T (a1)
= (r - 1) + 1 since T (1) = 1

=r

    From the pattern that we've just established, T (n) reduces to r. A formal
inductive proof of this statement is possible. However, we expect that most
readers would be satisfied with the argument above. Any skeptics are invited
to provide the inductive proof.

    For those who prefer to see a numeric example, suppose n = 21.

T (21) = T (10101)
        = 1 + T (1010)
        = 1 + (1 + T (101))
        = 1 + (1 + (1 + T (10)))
        = 1 + (1 + (1 + (1 + T (1))))
        = 1 + (1 + (1 + (1 + (1 + T (0)))))
        =5
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS  164

    Our general conclusion is that the solution to (8.4.1) and (8.4.2) is that for
n  1, T (n) = r, where 2r-1  n < 2r.

    A less cumbersome statement of this fact is that T (n) = log2 n + 1. For
example, T (21) = log2 21 + 1 = 4 + 1 = 5.

8.4.2.2 Review of Logarithms

Any discussion of logarithms must start by establishing a base, which can be
any positive number other than 1. With the exception of Theorem 5, our base
will be 2. We will see that the use of a different base (10 and e  2.171828
are the other common ones) only has the effect of multiplying each logarithm
by a constant. Therefore, the base that you use really isn't very important.
Our choice of base 2 logarithms is convenient for the problems that we are
considering.

Definition 8.4.1 Base 2 logarithm. The base 2 logarithm of a positive
number represents an exponent and is defined by the following equivalence for
any positive real numbers a.

                                  log2 a = x  2x = a.

                                                                                                     

Figure 8.4.2 Plot of the logarithm, bases 2, function

    For example, log2 8 = 3 because 23 = 8 and log2 1.414  0.5 because
20.5  1.414. A graph of the function f (x) = log2 x in Figure 8.4.2 shows that
if a < b, the log2 a < log2 b; that is, when x increases, log2 x also increases.
However, if we move x from 210 = 1024 to 211 = 2048, log2 x only increases
from 10 to 11. This slow rate of increase of the logarithm function is an
important point to remember. An algorithm acting on n pieces of data that
can be executed in log2 n time units can handle significantly larger sets of data
than an algorithm that can be executed in n/100 or n time units. The graph
of T (n) = log2 n + 1 would show the same behavior.

    A few more properties that we will use in subsequent discussions involving
logarithms are summarized in the following theorem.

Theorem 8.4.3 Fundamental Properties of Logarithms. Let a and b
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                         165

be positive real numbers, and r a real number.

                       log2 1 = 0                               (8.4.4)
                                                                (8.4.5)
               log2 ab = log2 a + log2 b                        (8.4.6)
               log2 a = log2 a - log2 b
                                                                (8.4.7)
                     b                                          (8.4.8)
                   log2 ar = r log2 a

                       2log2 a = a

Definition 8.4.4 Logarithms base b. If b > 0, b = 1, then for a > 0,

               logb a = x  bx = a

                                                                      

Theorem 8.4.5 How logarithms with different bases are related. Let
                                             log2 a
b > 0, b = 1.  Then for all a > 0, logb a =           Therefore, if b > 1, base b
                                             log b .
                                                  2
logarithms can be computed from base 2 logarithms by dividing by the positive

scaling factor log2 b. If b < 1, this scaling factor is negative.
Proof. By an analogue of (8.4.8), a = blogb a. Therefore, if we take the base 2

logarithm of both sides of this equality we get:

               log2 a = log2 blogb a  log2 a = logb a · log2 b

Finally, divide both sides of the last equation by log2 b.            

Note 8.4.6 log2 10  3.32192 and log2 e  1.4427.

8.4.2.3

Returning to the binary search algorithm, we can derive the final expression for
T (n) using the properties of logarithms, including that the logarithm function
is increasing so that inequalities are maintained when taking logarithms of
numbers.

                         T (n) = r  2r-1  n < 2r
                                      log2 2r-1  log2 n < log2 2r
                                      r - 1  log2 n < r
                                      r - 1 = log2 n
                                      T (n) = r = log2 n + 1

    We can apply several of these properties of logarithms to get an alternate
expression for T (n):

                               log2 n + 1 = log2 n + 1
                                               = log2 n + log2 2
                                               = log2 2n

    If the time that was assigned to Step 1 of the binary search algorithm is
changed, we wouldn't expect the form of the solution to be very different. If
T (n) = a + T (n/2) with T (0) = c, then T (n) = c + a log2 2n.

    A further generalization would be to add a coefficient to T (n/2): T (n) =
a + bT (n/2) with T (0) = c, where a, b, c  R, and b = 0 is not quite as simple
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                       166

to derive. First, if we consider values of n that are powers of 2:

                                  T (1) = a + bT (0) = a + bc
                            T (2) = a + b(a + bc) = a + ab + cb2
                   T (4) = a + b a + ab + cb2 = a + ab + ab2 + cb3

                                                   ..
                                                   .
                        T (2r) = a + ab + ab2 + · · · + abr + cbr+1

If n is not a power of 2, by reasoning that is identical to what we used to
(8.4.1) and (8.4.2),

                                                                     r

                                    T (n) = abk + cbr+1

                                                                  k=0

where r = log2 n.
    The first term of this expression is a geometric sum, which can be written

in closed form. Let x be that sum:

                                 x = a + ab + ab2 + · · · + abr
                             bx = ab + ab2 + · · · + abr + abr+1

We've multiplied each term of x by b and aligned the identical terms in x and
bx. Now if we subtract the two equations,

                     x - bx = a - abr+1  x(1 - b) = a 1 - br+1

Therefore, x = a b-1 br+1-1 .
    A closed form expression for T (n) is

                             br+1 - 1 r+1
                  T (n) = a          + cb where r = log2 n
                             b-1

8.4.3 Analysis of Bubble Sort and Merge Sort

The efficiency of any search algorithm such as the binary search relies on fact

that the search list is sorted according to a key value and that the search is

based on the key value. There are several methods for sorting a list. One

example is the bubble sort. You might be familiar with this one since it is a

popular "first sorting algorithm." A time analysis of the algorithm shows that

if B(n) is the worst-case time needed to complete the bubble sort on n items,

then B(n) = (n - 1) + B(n - 1) and B(1) = 0. The solution of this relation

is  a  quadratic  function  B(n)  =  1  n2 - n .  The growth rate of a quadratic
                                     2
function such as this one is controlled by its squared term. Any other terms

are dwarfed by it as n gets large. For the bubble sort, this means that if

we double the size of the list that we are to sort, n changes to 2n and so n2

becomes 4n2 . Therefore, the time needed to do a bubble sort is quadrupled.

One alternative to bubble sort is the merge sort. Here is a simple version of

this algorithm for sorting F = {r(1), r(2), . . . , r(n)}, n  1. If n = 1, the list

is sorted trivially. If n  2 then:

    (1) Divide F into F1 = {r(1), . . . , r(n/2)} and F2 = {r(n/2+1), . . . , r(n)}.

    (2) Sort F1 and F2 using a merge sort.

    (3) Merge the sorted lists F1 and F2 into one sorted list. If the sort is to be
         done in descending order of key values, you continue to choose the higher

         key value from the fronts of F1 and F2 and place them in the back of F .
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS           167

    Note that F1 will always have n/2 items and F2 will have n/2 items;
thus, if n is odd, F2 gets one more item than F1. We will assume that the
time required to perform Step 1 of the algorithm is insignificant compared to

the other steps; therefore, we will assign a time value of zero to this step. Step

3 requires roughly n comparisons and n movements of items from F1 and F2
to F ; thus, its time is proportional to n. For this reason, we will assume that

Step 3 takes n time units. Since Step 2 requires T (n/2) + T (n/2) time
units,

       T (n) = n + T (n/2) + T (n/2)                    (8.4.9)

with the initial condition

                                  T (1) = 0             (8.4.10)

    Instead of an exact solution of these equations, we will be content with an
estimate for T (n). First, consider the case of n = 2r, r  1:

       T 21 = T (2) = 2 + T (1) + T (1) = 2 = 1 · 2
       T 22 = T (4) = 4 + T (2) + T (2) = 8 = 2 · 4
       T 23 = T (8) = 8 + T (4) + T (4) = 24 = 3 · 8

                                    ..
                                    .

                    T (2r) = r2r = 2r log2 2r

    Thus, if n is a power of 2, T (n) = n log2 n. Now if, for some r  2,
2r-1  n  2r, then (r-1)2r-1  T (n) < r2r. This can be proved by induction
on r. As n increases from 2r-1 to 2r, T (n) increases from (r - 1)2r-1to r2r
and is slightly larger than n log2 n. The discrepancy is small enough so that
Te(n) = n log2 n can be considered a solution of (8.4.9) and (8.4.10) for
the purposes of comparing the merge sort with other algorithms. Table 8.4.7
compares B(n) with Te(n) for selected values of n.

Table 8.4.7 Comparison of Times for Bubble Sort and Merge Sort

                              n    B(n)      Te(n)
                             10      45        34
                             50               283
                            100    1225       665
                            500    4950
                            1000  124750     4483
                                  499500     9966

8.4.4 Derangements

A derangement is a permutation on a set that has no "fixed points". Here is a
formal definition:

Definition 8.4.8 Derangement. A derangement of a nonempty set A is a

permutation of A (i.e., a bijection from A into A) such that f (a) = a for all

a  A.                                                   

If A = {1, 2, ..., n}, an interesting question might be "How many derange-

ments are there of A?" We know that our answer is bounded above by n!. We

can also expect our answer to be quite a bit smaller than n! since n is the

image of itself for (n - 1)! of the permutations of A.

Let D(n) be the number of derangements of {1, 2, ..., n}. Our answer will

come from discovering a recurrence relation on D. Suppose that n  3. If we
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                                          168

are to construct a derangement of {1, 2, . . . , n}, f , then f (n) = k = n. Thus,
the image of n can be selected in n - 1 different ways. No matter which of the
n - 1 choices we make, we can complete the definition of f in one of two ways.
First, we can decide to make f (k) = n, leaving D(n - 2) ways of completing
the definition of f , since f will be a derangement of {1, 2, . . . , n} - {n, k}.
Second, if we decide to select f (k) = n, each of the D(n - 1) derangements of
{1, 2, . . . , n-1} can be used to define f . If g is a derangement of {1, 2, . . . , n-1}
such that g(p) = k, then define f by

                                                    if j = p
                               n                    if j = n
                      f (j) =  k                   otherwise

                                   g(j)

    Note that with our second construction of f , f (f (n)) = f (k) = n, while
in the first construction, f (f (n)) = f (k) = n. Therefore, no derangement of
{1, 2, ..., n} with f (n) = k can be constructed by both methods.

    To recap our result, we see that f is determined by first choosing one of
n - 1 images of n and then constructing the remainder of f in one of D(n -
2) + D(n - 1) ways. Therefore,

                      D(n) = (n - 1)(D(n - 2) + D(n - 1))                       (8.4.11)

This homogeneous second-order linear relation with variable coefficients,

together with the initial conditions D(1) = 0 and D(2) = 1, completely de-

fines D. Instead of deriving a solution of this relation by analytical methods,

we will give an empirical derivation of an approximation of D(n). Since the

derangements of {1, 2..., n} are drawn from a pool of n! permutations, we will

see what percentage of these permutations are derangements by listing the

values of n!, D(n), and n! D(n) . The results we observe will indicate that as n

grows,  D(n)  hardly  changes  at  all.  If  this  quotient   is  computed  to  eight  deci-
          n!
mal places, for n  12, D(n)/n! = 0.36787944. The reciprocal of this number,

which D(n)/n! seems to be tending toward, is, to eight places, 2.7182818. This

number appears in so many places in mathematics that it has its own name, e.

An approximate solution of our recurrence relation on D is then D(n)  en! .

def D(n):
       if n<=2:
              return n-1
       else:
              return (n-1)*(D(n-2)+D(n-1))

list(map(lambda
      k:[k,D(k),(D(k)/factorial(k)).n(digits =8)],range (1 ,16)))

[[1, 0, 0.00000000] ,
 [2, 1, 0.50000000] ,
 [3, 2, 0.33333333] ,
 [4, 9, 0.37500000] ,
 [5, 44, 0.36666667] ,
 [6, 265, 0.36805556] ,
 [7, 1854, 0.36785714] ,
 [8, 14833, 0.36788194] ,
 [9, 133496, 0.36787919] ,
 [10, 1334961, 0.36787946] ,
 [11, 14684570, 0.36787944] ,
 [12, 176214841 , 0.36787944] ,
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS               169

[13, 2290792932 , 0.36787944] ,
[14, 32071101049 , 0.36787944] ,
[15, 481066515734 , 0.36787944]]

8.4.5 Exercises

1. Solve the following recurrence relations. Indicate whether your solution
      is an improvement over iteration.

(a) nS(n) - S(n - 1) = 0, S(0) = 1.

(b) T (k) + 3kT (k - 1) = 0, T (0) = 1.

(c)  U (k) -  k-1  U  (k  -  1)  =  0,  k   2,  U (1) = 1.
                k

2. Prove that if n  0, n/2 + n/2 = n. (Hint: Consider the cases of n
      odd and n even separately.)

3. Solve as completely as possible:

        (a) T (n) = 3 + T (n/2), T (0) = 0.

        (b) T (n) = 1 + 12 T (n/2), T (0) = 2.

         (c) V (n) = 1 + V n/8), V (0) = 0. (Hint: Write n in octal form.)
4. Prove by induction that if T (n) = 1 + T (n/2), T (0) = 0, and 2r-1 

      n < 2r , r  1, then T (n) = r.
      Hint. Prove by induction on r.
5. Use the substitution S(n) = T (n + 1)/T (n) to solve T (n)T (n - 2) =
      T (n - 1)2 for n  2, with T (0) = 1, T (1) = 6, and T (n)  0.
6. Consider the sequence S defined by T (n)2 - T (n - 1)2 = 1 for n  1, with
      the conditions T (0) = 10 and T (n)  0 for all n. Use the substitution
      G(n) = T (n)2 to solve for S.
7. Solve as completely as possible:

        (a) Q(n) = 1 + Q (n), n  2, Q(1) = 0.

        (b) R(n) = n + R(n/2), n  1, R(0) = 0.
8. Suppose Step 1 of the merge sort algorithm did take a significant amount

      of time. Assume it takes 0.1 time unit, independent of the value of n.

(a) Write out a new recurrence relation for T (n) that takes this factor
     into account.

(b) Solve for T (2r), r  0.

(c) Assuming the solution for powers of 2 is a good estimate for all n,
     compare your result to the solution in the text. As n gets large, is
     there really much difference?

8.5 Generating Functions

This section contains an introduction to the topic of generating functions and
how they are used to solve recurrence relations, among other problems. Meth-
ods that employ generating functions are based on the concept that you can
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                                 170

take a problem involving sequences and translate it into a problem involving
generating functions. Once you've solved the new problem, a translation back
to sequences gives you a solution of the original problem.

    This section covers:

  (1) The definition of a generating function.

  (2) Solution of a recurrence relation using generating functions to identify
       the skills needed to use generating functions.

  (3) An introduction and/or review of the skills identified in point 2.

  (4) Some applications of generating functions.

8.5.1 Definition

Definition 8.5.1 Generating Function of a Sequence. The generating
function of a sequence S with terms S0, S1, S2, . . ., is the infinite sum

                     

G(S; z) = Snzn = S0 + S1z + S2z2 + S3z3 + · · ·

                   n=0

The domain and codomain of generating functions will not be of any concern

to us since we will only be performing algebraic operations on them.                    

Example 8.5.2 First Examples.

(a) If Sn = 3n,n  0, then

                  G(S; z) = 1 + 3z + 9z2 + 27z3 + · · ·

                                       

                            = 3nzn

                                     n=0
                                       

                            = (3z)n

                                     n=0

We can get a closed form expression for G(S; z) by observing that
G(S; z) - 3zG(S; z) = 1. Therefore, G(S; z) = 1-3z 1 .

(b) Finite sequences have generating functions. For example, the sequence

of binomial coefficients   0n ,  n  ,  . . .,  n  ,  n    1  has  generating  function
                                 1             n

                  n              n             n                  n zn
G( · ; z) = 0 + 1 z + · · · +                                     n

                                       n zk
                                       k
                           =

                               k=0

                           = (1 + z)n

     by application of the binomial formula.

(c) If Q(n) = n2, G(Q; z) = n=0  n2zn = k=0  k2zk. Note that the index
     that is used in the summation has no significance. Also, note that the
     lower limit of the summation could start at 1 since Q(0) = 0.

                                                                              
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                      171

8.5.2 Solution of a Recurrence Relation Using Generating
        Functions

We illustrate the use of generating functions by solving S(n) - 2S(n - 1) -
3S(n - 2) = 0, n  2, with S(0) = 3 and S(1) = 1.

(1) Translate the recurrence relation into an equation about generating func-
     tions.

     Let V (n) = S(n) - 2S(n - 1) - 3S(n - 2), n  2, with V (0) = 0 and
     V (1) = 0. Therefore,

                                                        

            G(V ; z) = 0 + 0z + (S(n) - 2S(n - 1) - 3S(n - 2))zn = 0

                                                       n=2

(2) Solve for the generating function of the unknown sequence, G(S; z) =
        n=0  Snzn.

              

     0 = (S(n) - 2S(n - 1) - 3S(n - 2))zn

     n=2

                                                     

     = S(n)zn - 2          S(n - 1)zn - 3              S(n - 2)zn

     n=2              n=2                    n=2

Close examination of the three sums above shows:

(a)

                           

                      Snzn = Snzn - S(0) - S(1)z

                 n=2       n=0

                        = G(S; z) - 3 - z

     since S(0) = 3 and S(1) = 1.
(b)

                                        

                    S(n - 1)zn = z         S(n - 1)zn-1

                 n=2                    n=2

                                        

                           =z                S(n)zn

                                        n=1

                                        

                           =z                S(n)zn - S(0)

                                        n=0

                           = z(G(S; z) - 3)

(c)

                                        

                    S(n - 2)zn = z2        S(n - 2)zn-2

                 n=2                    n=2

                           = z2G(S; z)

     Therefore,

     (G(S; z) - 3 - z) - 2z(G(S; z) - 3) - 3z2G(S; z) = 0

        G(S; z) - 2zG(S; z) - 3z2G(S; z) = 3 - 5z

        G(S; z) =     3 - 5z

                                     2
                      1 - 2z - 3z
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                            172

(3) Determine the sequence whose generating function is the one we got in
     Step 2.

     For our example, we need to know one general fact about the closed form
     expression of an exponential sequence (a proof will be given later):

            T (n) = ban, n  0  G(T ; z) = b                          (8.5.1)
                                                      1 - az

Now, in order to recognize S in our example, we must write our closed
form expression for G(S; z) as a sum of terms like G(T ; z) above. Note
that the denominator of G(S; z) can be factored:

            G(S; z) =  3 - 5z                  3 - 5z
                                 2=
                       1 - 2z - 3z (1 - 3z)(1 + z)

If you look at this last expression for G(S; z) closely, you can imagine
how it could be the result of addition of two fractions,

            3 - 5z              =  A    +      B                     (8.5.2)

            (1 - 3z)(1 + z) 1 - 3z 1 + z

where A and B are two real numbers that must be determined. Starting
on the right of (8.5.2), it should be clear that the sum, for any A and B,
would look like the left-hand side. The process of finding values of A and
B that make (8.5.2) true is called the partial fractions decomposition
of the left-hand side:

               A + B = A(1 + z) + B(1 - 3z)
            1 - 3z 1 + z (1 - 3z)(1 + z) (1 - 3z)(1 + z)

                                = (A + B) + (A - 3B)z
                                        (1 - 3z)(1 + z)

Therefore,

            A+B =3  A=1
            A - 3B = -5                 B=2

and                             1       2

            G(S; z) =                +
                                1 - 3z 1 + z

We can apply (8.5.1) to each term of G(S; z):

·       1   is the generating function for S1(n) = 1 · 3n = 3n
     1-3z

·      2   is the generating function for S2(n) = 2(-1)n.
     1+z

Therefore, S(n) = 3n + 2(-1)n.

    From this example, we see that there are several skills that must be mas-
tered in order to work with generating functions. You must be able to:

(a) Manipulate summation expressions and their indices (in Step 2).

(b) Solve algebraic equations and manipulate algebraic expressions, including
     partial function decompositions (Steps 2 and 3).

(c) Identify sequences with their generating functions (Steps 1 and 3).

    We will concentrate on the last skill first, a proficiency in the other skills is a
product of doing as many exercises and reading as many examples as possible.

    First, we will identify the operations on sequences and on generating func-
tions.
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS  173

8.5.3 Operations on Sequences

Definition 8.5.3 Operations on Sequences. Let S and T be sequences of
numbers and let c be a real number. Define the sum S + T , the scalar product
cS, the product ST , the convolution S  T , the pop operation S  (read "S
pop"), and the push operation S  (read "S push") term-wise for k  0 by

(S + T )(k) = S(k) + T (k)                     (8.5.3)

(cS)(k) = cS(k)                                (8.5.4)

(S · T )(k) = S(k)T (k)                        (8.5.5)

                           k                   (8.5.6)

(S  T )(k) = S(j)T (k - j)

                         j=0

(S )(k) = S(k + 1)                             (8.5.7)

(S )(k) =      0     if k = 0                  (8.5.8)
           S(k - 1)  if k > 0

                                                                                                     
    If one imagines a sequence to be a matrix with one row and an infinite
number of columns, S + T and cS are exactly as in matrix addition and scalar
multiplication. There is no obvious similarity between the other operations
and matrix operations.
    The pop and push operations can be understood by imagining a sequence
to be an infinite stack of numbers with S(0) at the top, S(1) next, etc., as in
Figure 8.5.4a. The sequence S  is obtained by "popping" S(0) from the stack,
leaving a stack as in Figure 8.5.4b, with S(1) at the top, S(2) next, etc. The
sequence S  is obtained by placing a zero at the top of the stack, resulting in
a stack as in Figure 8.5.4c. Keep these figures in mind when we discuss the
pop and push operations.
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                174

Figure 8.5.4 Stack interpretation of pop and push operation

Example 8.5.5 Some Sequence Operations. If S(n) = n, T (n) = n2,
U (n) = 2n, and R(n) = n2n:

(a) (S + T )(n) = n + n2

(b) (U + R)(n) = 2n + n2n = (1 + n)2n

(c) (2U )(n) = 2 · 2n = 2n+1

(d) 1 R (n) = 1 n2n = n2n-1
   2             2

(e) (S · T )(n) = nn2 = n3

                 n                       n

(f) (S  T )(n) = S(j)T (n - j) = j(n - j)2

                 j=0                  j=0

      n

=        jn2 - 2nj2 + j3

   j=0

         n            n        n

= n2 j - 2n j2 + j3

         j=0        j=0        j=0

= n2 n(n + 1) - 2n (2n + 1)(n + 1)n + 1 n2(n + 1)2
              2                       6     4

   n2(n + 1)(n - 1)
=

             12

                                   n

(g) (U  U )(n) = U (j)U (n - j)

                          j=0
      n

= 2j 2n-j

   j=0

= (n + 1)2n

(h) (S )(n) = n + 1

(i) (S )(n) = max(0, n - 1)

(j) ((S ) )(n) = max(0, n - 2)
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS            175

(k) (U )(n) =      2n-1    if n > 0
                     0     if n = 0

(l) ((U ) )(n) = (U )(n + 1) = 2n = U (n)

(m) ((U ) )(n) =     0     if n = 0
                   U (n)   if n > 0

                                                                                                    
    Note that (U ) = (U ) .

Definition 8.5.6 Multiple Pop and Push. If S is a sequence of numbers
and p a positive integer greater than 1, define

S  p = (S  (p - 1))  if p  2 and S  1 = S 

Similarly, define

S  p = (S  (p - 1))  if p  2 and S  1 = S 

                                                                                                
In general, (S  p)(k) = S(k + p), and

                   (S  p)(k) =           0     if k < p
                                     S(k - p)  if k  p

8.5.4 Operations on Generating Functions

Definition 8.5.7 Operations on Generating Functions. If G(z) =
   k=0  akzk and H(z) = k=0  bkzk are generating functions and c is a real

number, then the sum G + H, scalar product cG, product GH, and monomial

product zpG, p  1 are generating functions, where

                                                          (8.5.9)
                                                         (8.5.10)
                   (G + H)(z) = (ak + bk) zk             (8.5.11)
                                                         (8.5.12)
                                            k=0
                                                

                           (cG)(z) = cakzk

                                          k=0

                                                    k

                   (GH)(z) = ckzk where ck = ajbk-j

                           k=0                      j=0

                                                    

(zpG) (z) = zp akzk = akzk+p = an-pzn

                   k=0               k=0            n=p

    The last sum is obtained by substituting n - p for k in the previous sum.
                                                                                                     

Example 8.5.8 Some operations on generating functions. If D(z) =
   k=0  kzk and H(z) =  k=0 2kzk then

                                                                          

                                (D + H)(z) = k + 2k zk

                                                                         k=0

                                               

                   (2H)(z) = 2 · 2kzk = 2k+1zk

                             k=0               k=0
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                                 176

                                             

(zD)(z) = z kzk = kzk+1

              k=0                            k=0

                                                                   

           = (k - 1)zk = D(z) - zk

            k=1                                                 k=1

(DH)(z) =                                    k         
                                                j2k-j  zk
                                        

                      k=0 j=0

                   k                                          

(HH)(z) =             2j 2k-j  zk =                              (k + 1)2kzk

           k=0 j=0                                            k=0

Note: D(z) = G(S; z), and H(z) = G(U ; z) from Example 5.                     

Now we establish the connection between the operations on sequences and

generating functions. Let S and T be sequences and let c be a real number.

G(S + T ; z) = G(S; z) + G(T ; z)                                             (8.5.13)

              G(cS; z) = cG(S; z)                                             (8.5.14)

G(S  T ; z) = G(S; z)G(T ; z)                                                 (8.5.15)

G(S ; z) = (G(S; z) - S(0))/z                                                 (8.5.16)

              G(S ; z) = zG(S; z)                                             (8.5.17)

    In words, (8.5.13) says that the generating function of the sum of two
sequences equals the sum of the generating functions of those sequences. Take
the time to write out the other four identities in your own words. From the
previous examples, these identities should be fairly obvious, with the possible
exception of the last two. We will prove (8.5.16) as part of the next theorem
and leave the proof of (8.5.17) to the interested reader. Note that there is no
operation on generating functions that is related to sequence multiplication;
that is, G(S · T ; z) cannot be simplified.

Theorem 8.5.9 Generating functions related to Pop and Push. If
p > 1,

                                                         p-1

(a) G(S  p; z) = G(S; z) - S(k)zk /zk

                                                         k=0

  (b) G(S  p; z) = zpG(S; z).
Proof. We prove (a) by induction and leave the proof of (b) to the reader.
Basis:

                        

G(S ; z) = S(k + 1)zk

               k=0
                

           = S(k)zk-1

              k=1

              

           =          S(k)zk z

              k=1

                                  

           = S(0) + S(k)zk - S(0) z

                                        k=1

           = (G(S; z) - S(0))/z

Therefore, part (a) is true for p = 1.
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                              177

Induction: Suppose that for some p  1, the statement in part (a) is true:

G(S  (p + 1); z) = G((S  p) ; z)

                      = (G(S  p; z) - (S  p)(0))/z by the basis
                          (G(S;z)- k=0 p-1 S(k)zk) - S(p)

                      = zp
                                           z

by the induction hypothesis. Now write S(p) in the last expression above as
(S(p)zp) /zp so that it fits into the finite summation:

G(S  (p + 1); z) =          G(S; z) - pk=0 S(k)zk z
                      =                   zp

                                                 p

                            G(S; z) - S(k)zk /zp+1

                                               k=0

Therefore the statement is true for p + 1.                                 

8.5.5 Closed Form Expressions for Generating Functions

The most basic tool used to express generating functions in closed form is the
closed form expression for the geometric series, which is an expression of the
form a + ar + ar2 + · · ·. It can either be terminated or extended infinitely.

    Finite Geometric Series:

a + ar + ar2 + · · · + arn = a 1 - rn+1                                 (8.5.18)
                                           1-r

Infinite Geometric Series:

a + ar + ar2 + · · · = a                                                (8.5.19)
                            1-r

    Restrictions: a and r represent constants and the right sides of the two
equations apply under the following conditions:

(1) r must not equal 1 in the finite case. Note that a+ar +· · · arn = (n+1)a
     if r = 1.

(2) In the infinite case, the absolute value of r must be less than 1.

    These restrictions don't come into play with generating functions. We
could derive (8.5.18) by noting that if S(n) = a + ar + · · · + arn, n > 0, then
S(n) = rS(n-1)+a (See Exercise 10 of Section 8.3). An alternative derivation
was used in Section 8.4. We will take the same steps to derive (8.5.19). Let
x = a + ar + ar2 + · · ·. Then

              rx = ar + ar2 + · · · = x - a  x - rx = a  x = a
                                                                                 1-r

Example 8.5.10 Generating Functions involving Geometric Sums.

  (a) If S(n) = 9 · 5n, n  0, G(S; z) is an infinite geometric series with a = 9
       and r = 5z.Therefore, G(S; z) = 1-5z 9 .

  (b) If T (n) = 4, n 0, then G(T ; z) = 4/(1 - z).

  (c) If U (n) = 3(-1)n, then G(U ; z) = 3/(1 + z).
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                           178

(d) Let C(n) = S(n) + T (n) + U (n) = 9 · 5n + 4 + 3(-1)n. Then

        G(C; z) = G(S; z) + G(T ; z) + G(U ; z)

                               9         4        3
                        = 1 - 5z + 1 - z + 1 + z .

                              14z2 + 34z - 16
                        = - 5z3 - z2 - 5z + 1

Given a choice between the last form of G(C; z) and the previous sum
of three fractions, we would prefer leaving it as a sum of three functions.
As we saw in an earlier example, a partial fractions decomposition of a
fraction such as the last expression requires some effort to produce.

(e) If G(Q; z) = 34/(2 - 3z), then Q can be determined by multiplying the
     numerator and denominator by 1/2 to obtain 1- 3 z 17 . We recognize this

                                                                                                                                               2

     fraction as the sum of the infinite geometric series with a = 17 and r = 32 z.
     Therefore Q(n) = 17(3/2)n.

(f) If G(A; z) = (1 + z)3 , then we expand (1 + z)3 to 1 + 3z + 3z2 + z3

. Therefore A(0) = 1, A(1) = 3 A(2) = 3, A(3) = 1, and, since there

are no higher-powered terms, A(n) = 0, n  4. A more concise way of

describing A is A(k) =  3   ,  since  n  is interpreted as 0 of k > n.
                        k             k

                                                                                                    
    Table 8.5.11 lists some closed form expressions for the generating functions
of some common sequences.

Table 8.5.11 Closed Form Expressions of some Generating Functions

         Sequence                        Generating Function
        S(k) = bak
                                            G(S; z)  =     b
                                                        1-az
                                                            z
        S(k) = k                         G(S; z)  =     (1-z)2

        S(k) = bkak                      G(S; z) = abz (1-az)2

        S(k)  =         1                   G(S; z) = ez
                        k!
        n
S(k) =  k               0kn              G(S; z) = (1 + z)n

        0 k>n

Example 8.5.12 Another Complete Solution. Solve S(k) + 3S(k - 1) -
4S(k - 2) = 0, k  2, with S(0) = 3 and S(1) = -2. The solution will be
derived using the same steps that were used earlier in this section, with one
variation.

  (1) Translate to an equation about generating functions. First, we change
       the index of the recurrence relation by substituting n + 2 for k. The
       result is S(n + 2) + 3S(n + 1) - 4S(n) = 0, n  0. Now, if V (n) =
       S(n + 2) + 3S(n + 1) - 4S(n), then V is the zero sequence, which has
       a zero generating function. Furthermore, V = S  2 + 3(S ) - 4S.
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                                          179

Therefore,

0 = G(V ; z)

= G(S  2; z) + 3G(S ; z) - 4G(S; z)

=           G(S; z) - S(0) - S(1)z (G(S; z) - S(0))                        - 4G(S; z)
                                            +4
                            z  2                            z

(2) We want to now solve the following equation for G(S; z):

G(S; z) - S(0) - S(1)z + 4 (G(S; z) - S(0)) - 4G(S; z) = 0
                       z2                               z

Multiply by z2 :

           G(S; z) - 3 + 2z + 3z(G(S; z) - 3) - 4z2G(S; z) = 0

Expand and collect all terms involving G(S; z) on one side of the equation:

                   G(S; z) + 3zG(S; z) - 4z2G(S; z) = 3 + 7z
                           1 + 3z - 4z2 G(S; z) = 3 + 7z

Therefore,

                                                    3 + 7z
                                  G(S; z) = 1 + 3z - 4z2

(3) Determine S from its generating function. 1 + 3z - 4z2 = (1 + 4z)(1 - z)
     thus a partial fraction decomposition of G(S; z) would be:

A + B = Az - A - 4Bz - B = (A + B) + (4B - A)z
1 + 4z 1 - z                      (z - 1)(4z + 1)                 (z - 1)(4z + 1)

Therefore, A + B = 3 and 4B - A = 7. The solution of this set of

equations   is  A  =   1   and    B  =  2.  G(S; z)  =     1   +  1-z 2 .
                                                        1+4z

   1               is  the  generating      function  of    S1(n) = (-4)n,  and
1+4z

              2    is  the  generating      function    of  S2(n) = 2(1)n  =2
            1-z

In conclusion, since G(S; z) = G (S1; z) + G (S2; z), S(n) = 2 + (-4)n.

                                                                                                    

Example 8.5.13 An Application to Counting. Let A = {a, b, c, d, e}
and let A be the set of all strings of length zero or more that can be made

using each of the elements of A zero or more times. By the generalized rule
of products, there are 5n such strings that have length n, n  0, Suppose that
Xn is the set of strings of length n with the property that all of the a's and b's
precede all of the c's, d's, and e's. Thus aaabde  X6, but abcabc / X6. Let
R(n) = |Xn|. A closed form expression for R can be obtained by recognizing
R as the convolution of two sequences. To illustrate our point, we will consider

the calculation of R(6).

    Note that if a string belongs to X6, it starts with k characters from {a, b}
and is followed by 6 - k characters from {c, d, e}. Let S(k) be the number of
strings of a's and b's with length k and let T (k) be the number of strings of
c's, d's, and e's with length k. By the generalized rule of products, S(k) = 2k
and T (k) = 3k. Among the strings in X6 are the ones that start with two a's
and b's and end with c's, d's, and e's. There are S(2)T (4) such strings. By the
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                                      180

law of addition,

|X6| = R(6) = S(0)T (6) + S(1)T (5) + · · · + S(5)T (1) + S(6)T (0)

Note that the sixth term of R is the sixth term of the convolution of S with
T , S  T . Think about the general situation for a while and it should be clear
that R = S  T . Now, our course of action will be to:

(a) Determine the generating functions of S and T ,

(b) Multiply G(S; z) and G(T ; z) to obtain G(S  T ; z) = G(R; z), and

(c) Determine R on the basis of G(R; z).

(a) G(S; z) =       k=0  2kzk  =     1  ,  and  G(T ; z) =   k=0  3kzk = 1-3z 1
                                  1-2z

(b) G(R; z) = G(S; z)G(T ; z) = 1
                                           (1 - 2z)(1 - 3z)

(c) To recognize R from G(R; z), we must do a partial fractions decomposi-
     tion:

     1 = A + B = -3Az + A - 2Bz + B = (A + B) + (-3A - 2B)z
(1 - 2z)(1 - 3z) 1 - 2z 1 - 3z                  (2z - 1)(3z - 1)                   (2z - 1)(3z - 1)

Therefore, A + B = 1 and -3A - 2B = 0. The solution of this pair
of equations is A = -2 and B = 3. Since G(R; z) = 1-2z -2 + 1-3z 3 ,
which is the sum of the generating functions of -2(2)k and 3(3)k, R(k) =

-2(2)k + 3(3)k = 3k+1 - 2k+1

For example, R(6) = 37 - 27 = 2187 - 128 = 2059. Naturally, this equals

the sum that we get from (S  T )(6). To put this number in perspective,

the total number of strings of length 6 with no restrictions is 56 = 15625,

and  2059           0.131776.  Therefore   approximately     13  percent  of  the  strings
     15625
of length 6 satisfy the conditions of the problem.

                                                                                   

8.5.6 Extra for Experts

The remainder of this section is intended for readers who have had, or who
intend to take, a course in combinatorics. We do not advise that it be included
in a typical course. The method that was used in the previous example is a
very powerful one and can be used to solve many problems in combinatorics.
We close this section with a general description of the problems that can be
solved in this way, followed by some examples.

    Consider the situation in which P1, P2, . . ., Pm are m actions that must be
taken, each of which results in a well-defined outcome. For each k = 1, 2, ..., m
define Xk to be the set of possible outcomes of Pk . We will assume that
each outcome can be quantified in some way and that the quantification of
the elements of Xk is defined by the function Qk : Xk  {0, 1, 2, ...}. Thus,
each outcome has a non-negative integer associated with it. Finally, define
a frequency function Fk : {0, 1, 2, ...}  {0, 1, 2, ...} such that Fk(n) is the
number of elements of Xk that have a quantification of n.

    Now, based on these assumptions, we can define the problems that can be
solved. If a process P is defined as a sequence of actions P1, P2, . . . , Pm as above,
and if the outcome of P , which would be an element of X1 × X2 × · · · × Xm,
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS  181

is quantified by

                                                                                    m

                              Q (a1, a2, . . . , am) = Qk (ak)

                                                                                  k=1

then the frequency function, F , for P is the convolution of the frequency func-
tions forP1, P2, . . ., Pm, which has a generating function equal to the product
of the generating functions of the frequency functions F1, F2, . . ., Fm. That
is,

                          G(F ; z) = G (F1; z) G (F2; z) · · · (Fm; z)

Example 8.5.14 Rolling Two Dice. Suppose that you roll a die two times
and add up the numbers on the top face for each roll. Since the faces on
the die represent the integers 1 through 6, the sum must be between 2 and
12. How many ways can any one of these sums be obtained? Obviously, 2
can be obtained only one way, with two 1's. There are two sequences that
yield a sum of 3: 1-2 and 2-1. To obtain all of the frequencies with which the
numbers 2 through 12 can be obtained, we set up the situation as follows. For
j = 1, 2; Pj is the rolling of the die for the jth time. Xj = {1, 2, ..., 6} and
Qj : Xj  {0, 1, 2, 3, . . .} is defined by Qj(x) = x. Since each number appears
on a die exactly once, the frequency function is Fj(k) = 1 if 1  k  6, and
Fj(k) = 0 otherwise. The process of rolling the die two times is quantified by
adding up the Qjs; that is, Q (a1, a2) = Q1 (a1) + Q2 (a2) . The generating
function for the frequency function of rolling the die two times is then

 G(F ; z) = G (F1; z) G (F2; z)

            = (z6 + z5 + z4 + z3 + z2 + z)2

            = z12 + 2z11 + 3z10 + 4z9 + 5z8 + 6z7 + 5z6 + 4z5 + 3z4 + 2z3 + z2

    Now, to get F (k), just read the coefficient of zk. For example, the coefficient
of z5 is 4, so there are four ways to roll a total of 5.

    To apply this method, the crucial step is to decompose a large process in
the proper way so that it fits into the general situation that we've described.

                                                                                                     
Example 8.5.15 Distribution of a Committee. Suppose that an orga-
nization is divided into three geographic sections, A, B, and C. Suppose that
an executive committee of 11 members must be selected so that no more than
5 members from any one section are on the committee and that Sections A,
B, and C must have minimums of 3, 2, and 2 members, respectively, on the
committee. Looking only at the number of members from each section on the
committee, how many ways can the committee be made up? One example of
a valid committee would be 4 A's, 4 B's, and 3 C's.

    Let PA be the action of deciding how many members (not who) from Section
A will serve on the committee. XA = {3, 4, 5} and QA(k) = k. The frequency
function, FA , is defined by FA(k) = 1 if k  Xk , with FA(k) = 0 otherwise.
G (FA; z) is then z3+z4+z5 . Similarly, G (FB; z) = z2+z3+z4+z5 = G (FC ; z).
Since the committee must have 11 members, our answer will be the coefficient
of z11 in G (FA; z) G (FB; z) G (FC ; z), which is 10.

 %display latex
 var( 'z ')
 expand((z^3+ z^4+z^5)*(z^2+ z^3+ z ^4 + z^5)^2)

z^15 + 3*z^14 + 6*z^13 + 9*z^12 + 10*z^11 + 9*z^10 + 6*z^9 +
      3*z^8 + z^7
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                                    182

                                                                                 

8.5.7 Exercises

1. What sequences have the following generating functions?

        (a) 1

        (b) 10
              2-z

         (c) 1 + z

        (d) 3 + 3
              1 + 2z 1 - 3z

2. What sequences have the following generating functions?

        (a) 1
              1+z

        (b) 1
              4 - 3z

         (c) 2 + 1
              1-z 1+z

        (d) z + 2
              z+3

3. Find closed form expressions for the generating functions of the following
      sequences:

(a) V (n) = 9n

(b) P , where P (k) - 6P (k - 1) + 5P (k - 2) = 0 for k  2, with P (0) = 2
     and P (1) = 2.

         (c) The Fibonacci sequence: F (k + 2) = F (k + 1) + F (k), k  0, with
              F (0) = F (1) = 1.

4. Find closed form expressions for the generating functions of the following
      sequences:

(a) W (n) =     5         2n  for  0    n    5  and  W (n)  =  0  for  n  >  5.
                n

(b) Q, where Q(k) + Q(k - 1) - 42Q(k - 2) = 0 for k  2, with Q(0) = 2
     and Q(1) = 2.

         (c) H, where H(k + 3) = H(k + 2) + H(k + 1) + H(k) for k  0, with
              H(0) = H(1) = H(2) = 1.

5. For each of the following expressions, find the partial fraction decom-
      position and identify the sequence having the expression as a generating
      function.

(a)  5 + 2z

     1 - 4z  2

(b) 2 - 3z + z2 32 - 22z

(c) 1 - 11z + 30z2 6 - 29z
CHAPTER 8. RECURSION AND RECURRENCE RELATIONS                183

6. Find the partial fraction decompositions and identify the sequence having
      the following expressions:

    (a)  1

         1 - 9z  2

    (b)  1 + 3z

         16 - 8z + z  2

    (c)       2z

         1 - 6z - 7z  2

7. Given that S(k) = k and T (k) = 10k, what is the kth term of the

    generating function of each of the following sequences:

    (a) S + T

    (b) (S )  T

    (c) S  T

    (d) (S )  (S )

8.  Given that P (k) =   10   what is the the generating function of each of
                         k
    the following sequences:

        (a) P  P

        (b) P + P 

         (c) P + P 

9. A game is played by rolling a die five times. For the kth roll, one point is
      added to your score if you roll a number higher than k. Otherwise, your
      score is zero for that roll. For example, the sequence of rolls 2, 3, 4, 1, 2
      gives you a total score of three; while a sequence of 1,2,3,4,5 gives you a
      score of zero. Of the 65 = 7776 possible sequences of rolls, how many give
      you a score of zero?, of one? . . . of five?

10. Suppose that you roll a die five times in a row and record the square of
      each number that you roll. How many ways could the sum of the squares
      of your rolls equal 40? What is the most common outcome?
Chapter 9

Graph Theory

                                    Bipartite

                          Draw some lines joining dots in set A
                           To some dots in set B. Then we say

                                      It's bipartite if we
                                 Have no "B" joined to "B"
                         And no "A" joined to "A". That okay?

     Chris Howlett, The Omnificent English Dictionary In Limerick Form

This chapter has three principal goals. First, we will identify the basic com-
ponents of a graph and some of the features that many graphs have. Second,
we will discuss some of the questions that are most commonly asked of graphs.
Third, we want to make the reader aware of how graphs are used. In Section
9.1, we will discuss these topics in general, and in later sections we will take a
closer look at selected topics in graph theory.

    Chapter 10 will continue our discussion with an examination of trees, a
special type of graph.

9.1 Graphs - General Introduction

9.1.1 Definitions

Recall that we introduced directed graphs in Chapter 6 as a tool to visualize
relations on a set. Here is a formal definition.

Definition 9.1.1 Simple Directed Graph. A simple directed graph con-

sists of a nonempty set of vertices, V , and a set of edges, E, that is a subset

of the set V × V .                 

Note 9.1.2 Some Terminology and Comments. Each edge is an ordered

pair of elements from the vertex set. The first entry is the initial vertex

of the edge and the second entry is the terminal vertex. Despite the set

terminology in this definition, we often think of a graph as a picture, an aid

in visualizing a situation. In Chapter 6, we introduced this concept to help

understand relations on sets. Although those relations were principally of a

mathematical nature, it remains true that when we see a graph, it tells us

how the elements of a set are related to one another. We have chosen not to

allow a graph with an empty vertex set, the so-called empty graph. There are

both advantages and disadvantages to allowing the empty graph, so you may

                    184
CHAPTER 9. GRAPH THEORY              185

encounter it in other references.

Example 9.1.3 A Simple Directed Graph. Figure 9.1.4 is an example of
a simple directed graph. In set terms, this graph is (V, E), where V = {s, a, b}
and E = {(s, a), (s, b), (a, b), (b, a), (b, b)}. Note how each edge is labeled either
0 or 1. There are often reasons for labeling even simple graphs. Some labels
are to help make a graph easier to discuss; others are more significant. We will
discuss the significance of the labels on this graph later.

Figure 9.1.4 A directed graph

                                                                                                    
    There are cases where the order of the vertices is not significant and so we
use a different mathematical model for this situation:

Definition 9.1.5 Simple Undirected Graph. A simple undirected graph

consists of a nonempty set V , called a vertex set, and a set E of two-element

subsets of V , called the edge set.  

Henceforth, we will refer to simple undirected graphs as undirected graphs.

When drawing an undirected graph, the two-element subsets are drawn as

undirected lines or arcs connecting the vertices. It is customary to not allow

"self loops" in undirected graphs since {v, v} isn't a two element subset of

vertices.

Note 9.1.6 On Empty Graphs. It may occur to some readers that a
graph could be empty, in the sense that it has empty vertex and edge sets. We
might refer to this graph as the empty graph. However, there doesn't seem
to be a universally agreed upon definition of an empty graph. In some works,
a graph with any number of vertices and no edges is called an empty graph.
To avoid this dilemma, we have defined both directed and undirected graphs
to have nonempty vertex sets. For convenience, we've relaxed this rule in our
definition of a Binary Tree and allowed for an empty binary tree.

Example 9.1.7 An Undirected Graph. A network of computers can
be described easily using a graph. Figure 9.1.8 describes a network of five
computers, a, b, c, d, and e. An edge between any two vertices indicates that
direct two-way communication is possible between the two computers. Note
that the edges of this graph are not directed. This is due to the fact that the
relation that is being displayed is symmetric (i.e., if X can communicate with
Y , then Y can communicate with X). Although directed edges could be used
here, it would simply clutter the graph.
CHAPTER 9. GRAPH THEORY                                        186

Figure 9.1.8 Communications Map Figure 9.1.9 Island Road Map

This undirected graph, in set terms, is V = {a, b, c, d, e} and E =

{{a, b}, {a, d}, {b, c}, {b, d}, {c, e}, {b, e}}

There are several other situations for which this graph can serve as a model.

One of them is to interpret the vertices as cities and the edges as roads, an

abstraction of a map such as the one in Figure 9.1.9. Another interpretation

is as an abstraction of the floor plan of a house. See Exercise 9.1.5.11. Vertex

a represents the outside of the house; all others represent rooms. Two vertices

are connected if there is a door between them.                 

Definition 9.1.10 Complete Undirected Graph. A complete undirected

graph on n vertices is an undirected graph with the property that each pair of

distinct vertices are connected to one another. Such a graph is usually denoted

by Kn.                                                         

In certain cases there may be a need for more than one edge between two

vertices, and we need to expand the class of directed graphs.

Definition 9.1.11 Multigraph. A multigraph is a set of vertices V with a
set of edges that can contain more than one edge between the vertices. 

    One important point to keep in mind is that if we identify a graph as being
a multigraph, it isn't necessary that there are two or more edges between some
of the vertices. It is only just allowed. In other words, every simple graph is a
multigraph. This is analogous to how a rectangle is a more general geometric
figure than a square, but a square is still considered a rectangle.

Example 9.1.12 A Multigraph. A common occurrence of a multigraph is
a road map. The cities and towns on the map can be thought of as vertices,
while the roads are the edges. It is not uncommon to have more than one
road connecting two cities. In order to give clear travel directions, we name
or number roads so that there is no ambiguity. We use the same method to
describe the edges of the multigraph in Figure 9.1.13. There is no question
what e3 is; however, referring to the edge (2, 3) would be ambiguous.
CHAPTER 9. GRAPH THEORY  187

Figure 9.1.13 A directed multigraph

                                                                                                    
Example 9.1.14 A Labeled Graph. A flowchart is a common example
of a simple graph that requires labels for its vertices and some of its edges.
Figure 9.1.15 is one such example that illustrates how many problems are
solved.

Figure 9.1.15 A flow chart - an example of a labeled graph

    At the start of the problem-solving process, we are at the vertex labeled
"Start" and at the end (if we are lucky enough to have solved the problem)
we will be at the vertex labeled "End." The sequence of vertices that we pass
through as we move from "Start" to "End" is called a path. The "Start" vertex
is called the initial vertex of the path, while the "End" is called the final,
or terminal, vertex. Suppose that the problem is solved after two attempts;
then the path that was taken is Start, R, A, Q, L, A, Q, End. An alternate path
description would be to list the edges that were used: 1, 2, 3, No, 4, 3, Yes. This
CHAPTER 9. GRAPH THEORY  188

second method of describing a path has the advantage of being applicable for
multigraphs. On the graph in Figure 9.1.13, the vertex list 1, 2, 3, 4, 3 does not
clearly describe a path between 1 and 3, but e1, e4, e6, e7 is unambiguous. 

Note 9.1.16 A Summary of Path Notation and Terminology. If x and
y are two vertices of a graph, then a path between x and y describes a motion
from x to y along edges of the graph. Vertex x is called the initial vertex of the
path and y is called the terminal vertex. A path between x and y can always
be described by its edge list, the list of edges that were used: (e1, e2, . . . , en),
where: (1) the initial vertex of e1 is x; (2) the terminal vertex of ei is the
initial vertex of ei+1, i = 1, 2, . . . , n - 1; and (3) the terminal vertex of en is y.
The number of edges in the edge list is the path length. A path on a simple
graph can also be described by a vertex list. A path of length n will have a
list of n + 1 vertices v0 = x, v1, v2, . . . , vn = y, where, for k = 0, 1, 2, . . . , n - 1,
(vk, vk+1) is an edge on the graph. A circuit is a path that terminates at its
initial vertex.

    Suppose that a path between two vertices has an edge list (e1, e2, ..., en). A
subpath of this graph is any portion of the path described by one or more
consecutive edges in the edge list. For example, (3, No, 4) is a subpath of
(1, 2, 3, No, 4, 3, Yes). Any path is its own subpath; however, we call it an
improper subpath of itself. All other nonempty subpaths are called proper
subpaths.

    A path or circuit is simple if it contains no proper subpath that is a circuit.
This is the same as saying that a path or circuit is simple if it does not visit
any vertex more than once except for the common initial and terminal vertex
in the circuit. In the problem-solving method described in Figure 9.1.15, the
path that you take is simple only if you reach a solution on the first try.

9.1.2 Subgraphs

Intuitively, you could probably predict what the term "subgraph" means. A
graph contained within a graph, right? But since a graph involves two sets,
vertices and edges, does it involve a subset of both of these sets, or just one
of them? The answer is it could be either. There are different types of sub-
graphs. The two that we will define below will meet most of our future needs
in discussing the theory of graphs.

Definition 9.1.17 Subgraph. Let G = (V, E) be a graph of any kind:
directed, directed multigraph, or undirected. G = (V , E) is a subgraph of G
if V  = , V   V and e  E only if e  E and the vertices of e are in V . You
create a subgraph of G by removing zero or more vertices and all edges that
include the removed vertices and then you possibly remove some other edges.

    If the only removed edges are those that include the removed vertices, then
we say that G is an induced subgraph. Finally, G is a spanning subgraph
of G if V  = V , or, in other words, no vertices are removed from G, only edges.

                                                                                                     

Example 9.1.18 Some subgraphs. Consider the graph, G, in the top left
of Figure 9.1.19. The other three graphs in that figure are all subgraphs of G.
The graph in the top right was created by first removing vertex 5 and all edges
connecting it. In addition, we have removed the edge {1, 4}. That removed
edge disqualifies the graph from being an induced subgraph. The graphs in the
bottom left and right are both spanning subgraphs. The one on the bottom
right is a tree, and is referred to as a spanning subtree. Spanning subtrees will
be discussed in the chapter on Trees.
CHAPTER 9. GRAPH THEORY                                          189

Figure 9.1.19 A few subgraphs

                                                                                                     
    One set of subgraphs of any graph is the connected components of a graph.
For simplicity, we will define them for undirected graphs. Given a graph G =
(V, E), consider the relation "is connected to" on V . We interpret this relation
so that each vertex is connected to itself, and any two distinct vertices are
related if there is a path along edges of the graph from one to the other. It
shouldn't be too difficult to convince yourself that this is an equivalence relation
on V .

Definition 9.1.20 Connected Component. Given a graph G = (V, E), let

C be the relation "is connected to" on V . Then the connected components of

G are the induced subgraphs of G each with a vertex set that is an equivalence

class with respect to C.                                         

Example 9.1.21 If you ignore the duplicate names of vertices in the four

graphs of Figure 9.1.19, and consider the whole figure as one large graph, then

there are four connected components in that graph. It's as simple as that! It's

harder to describe precisely than to understand the concept.     

From the examples we've seen so far, we can see that although a graph can

be defined, in short, as a collection of vertices and edges, an integral part of

most graphs is the labeling of the vertices and edges that allows us to interpret

the graph as a model for some situation. We continue with a few more examples

to illustrate this point.

Example 9.1.22 A Graph as a Model for a Set of Strings. Suppose

that you would like to mechanically describe the set of strings of 0's and 1's

having no consecutive 1's. One way to visualize a string of this kind is with

the graph in Figure 9.1.4. Consider any path starting at vertex s. If the label

on each graph is considered to be the output to a printer, then the output will

have no consecutive 1's. For example, the path that is described by the vertex

list (s, a, b, b, a, b, b, a, b) would result in an output of 10010010. Conversely, any

string with no consecutive 1's determines a path starting at s.  

Example 9.1.23 A Tournament Graph. Suppose that four teams compete
in a round-robin sporting event; that is, each team meets every other team once,
and each game is played until a winner is determined. If the teams are named
A, B, C, and D, we can define the relation  on the set of teams by XY if X
beat Y . For one set of results, the graph of  might look like Figure 9.1.24.
CHAPTER 9. GRAPH THEORY  190

Figure 9.1.24 Round-robin tournament graph with four vertices

                                                                                                    
    There are many types of tournaments and they all can be modeled by
different types of graphs.

Definition 9.1.25 Tournament Graph.

  (a) A tournament graph is a directed graph with the property that no edge
       connects a vertex to itself, and between any two vertices there is at most
       one edge.

  (b) A complete (or round-robin) tournament graph is a tournament graph
       with the property that between any two distinct vertices there is exactly
       one edge.

  (c) A single-elimination tournament graph is a tournament graph with the
       properties that: (i) one vertex (the champion) has no edge terminating
       at it and at least one edge initiating from it; (ii) every other vertex is
       the terminal vertex of exactly one edge; and (iii) there is a path from the
       champion vertex to every other vertex.

                                                                                                     
Example 9.1.26 Graph of a Single Elimination Tournament. The
major league baseball championship is decided with a single-elimination tour-
nament, where each "game" is actually a series of games. From 1969 to 1994,
the two divisional champions in the American League (East and West) com-
peted in a series of games. The loser is eliminated and the winner competed
against the winner of the National League series (which is decided as in the
American League). The tournament graph of the 1983 championship is in
Figure 9.1.27
CHAPTER 9. GRAPH THEORY  191

Figure 9.1.27 A single elimination tournament graph
                                                                                                    

9.1.3 Graph Isomorphisms

Next, we establish the relation "is isomorphic to," a form of equality on graphs.
The graphs in Figure 9.1.28 obviously share some similarities, such as the
number of vertices and the number of edges. It happens that they are even
more similar than just that. If the letters a, b, c, and d in the left graph
are replaced with the numbers 1,3,4, and 2, respectively, and the vertices are
moved around so that they have the same position as the graph on the right,
you get the graph on the right.

Figure 9.1.28 Isomorphic Graphs
    Here is a more precise definition that reflects the fact that the actual posi-

tioning (or embedding) of vertices isn't an essential part of a graph.
Definition 9.1.29 Isomorphic Graphs. Two graphs (V, E) and (V , E)
are isomorphic if there exists a bijection f : V  V  such that (vi, vj)  E if
and only if (f (vi) , f (vj))  E. For multigraphs, we add that the number of
edges connecting vi to vj must equal the number of edges from f (vi) to f (vj).

                                                                                                     
    The most significant local characteristic of a vertex within a graph is its
degree. Collectively, the degrees can partially characterize a graph.
CHAPTER 9. GRAPH THEORY                                 192

Definition 9.1.30 Degree of a vertex.

  (a) Let v be a vertex of an undirected graph. The degree of v, denoted deg(v),
       is the number of edges that connect v to the other vertices in the graph.

  (b) If v is a vertex of a directed graph, then the outdegree of v, denoted
       outdeg(v), is the number of edges of the graph that initiate at v. The
       indegree of v, denoted indeg(v), is the number of edges that terminate
       at v.

                                                                                                     
Definition 9.1.31 Degree Sequence of a Graph. The degree sequence of
a simple undirected graph is the non-increasing sequence of its vertex degrees.

                                                                                                     
Example 9.1.32 Some degrees.

Figure 9.1.33 An undirected graph

(a) The degrees of vertices 1 through 5 in Figure 9.1.33 are 2, 3, 4, 1, and 2,
     respectively. The degree sequence of the graph is (4, 3, 2, 2, 1).

(b) In a tournament graph, outdeg(v) is the number of wins for v and indeg(v)
     is the number of losses. In a complete (round-robin) tournament graph
     with n vertices, outdeg(v) + indeg(v) = n - 1 for each vertex.

                                                        

Definition 9.1.34 Graphic Sequence. A finite nonincreasing sequence of

integers d1, d2, . . . , dn is graphic if there exists a simple undirected graph with

n vertices having the sequence as its degree sequence.  

For example, 4, 2, 1, 1, 1, 1 is graphic because the degrees of the graph in

Figure 9.1.35 match these numbers. There is no connection between the vertex

number and its degree in this graph.
CHAPTER 9. GRAPH THEORY  193

Figure 9.1.35 A graph that shows that 4, 2, 1, 1, 1, 1 is a graphic sequence.

    See [26] for more details on what are also referred to as graphical degree
sequences, including an algorithm for determining whether or not a sequence
is graphic.

9.1.4 Next Steps

    List 9.1.36 A Prospectus for the Rest of the Chapter

         The question "Once you have a graph, what do you do with it?"
    might come to mind. The following list of common questions and com-
    ments about graphs is a partial list that will give you an overview of
    the remainder of the chapter.

       (1) How can a graph be represented as a data structure for use on
            a computer? We will discuss some common data structures that
            are used to represent graphs in Section 9.2.

       (2) Given two vertices in a graph, does there exist a path between
            them? The existence of a path between any or all pairs of vertices
            in a graph will be discussed in Section 9.3. A related question
            is: How many paths of a certain type or length are there between
            two vertices?

       (3) Is there a path (or circuit) that passes through every vertex (or
            uses every edge) exactly once? Paths of this kind are called tra-
            versals. We will discuss traversals in Section 9.4.

       (4) Suppose that a cost is associated with the use of each vertex
            and/or edge in a path. What is the "cheapest" path, circuit, or
            traversal of a given kind? Problems of this kind will be discussed
            in Section 9.5.

       (5) Given the specifications of a graph, or the graph itself, what is
            the best way to draw the graph? The desire for neatness alone
            makes this a reasonable question, but there are other motivations.
            Another goal might be to avoid having edges of the graph cross
            one another. This is discussed in Section 9.6.
CHAPTER 9. GRAPH THEORY  194

9.1.5 Exercises

1. What is the significance of the fact that there is a path connecting vertex
      b with every other vertex in Figure 9.1.8, as it applies to various situations
      that it models?

2. Draw a graph similar to Figure 9.1.4 that represents the set of strings of
      0's and 1's containing no more than two consecutive 1's in any part of the
      string.

3. Draw a directed graph that models the set of strings of 0's and 1's (zero
      or more of each) where all of the 1's must appear consecutively.

4. In the NCAA final-four basketball tournament, the East champion plays
      the West champion, and the champions from the Mideast and Midwest
      play. The winners of the two games play for the national championship.
      How many different single-elimination tournament graphs could occur?

5. What is the maximum number of edges in an undirected graph with eight
      vertices?

6. Which of the graphs in Figure 9.1.37 are isomorphic? What is the corre-
      spondence between their vertices?

      Figure 9.1.37 Which graphs are isomorphic to one another?
7.

        (a) How many edges does a complete tournament graph with n vertices
              have?

        (b) How many edges does a single-elimination tournament graph with
              n vertices have?
CHAPTER 9. GRAPH THEORY  195

8. Draw complete undirected graphs with 1, 2, 3, 4, 5 and 6 vertices. How
      many edges does a Kn, a complete undirected graph with n vertices, have?

9. Determine whether the following sequences are graphic. Explain your
      logic.

        (a) (6, 5, 4, 3, 2, 1, 0)

        (b) (2, 2, 2, 2, 2, 2)

         (c) (3, 2, 2, 2, 2, 2)

        (d) (5, 3, 3, 3, 3, 3)

         (e) (1, 1, 1, 1, 1, 1)

         (f) (5, 5, 4, 3, 2, 1)
10.

        (a) Based on observations you might have made in exercise 9, describe
              as many characteristics as you can about graphic sequences of length
              n.

        (b) Consider the two graphs in Figure 9.1.38. Notice that they have the
              same degree sequences, (2, 2, 2, 2, 2, 2). Explain why the two graphs
              are not isomorphic.

      Figure 9.1.38 Two graphs with the same degree sequences
11. Draw a plan for the rooms of a house so that Figure 9.1.8 models con-

      nectedness of the rooms. That is, (a, b) is an edge if and only if a door
      connects rooms a and b.
12. How many subgraphs are there of a Kn, n  1. How many of them are
      spanning graphs? Assume the vertices are distinguishable. For example,
      if n = 3 and we remove one edge from the K3, we count three possible
      subgraphs depending on which edge is removed even though all three are
      isomorphic and would not be different if the vertices were indistinguish-
      able.

9.2 Data Structures for Graphs

In this section, we will describe data structures that are commonly used to
represent graphs. In addition we will introduce the basic syntax for graphs in
Sage.
CHAPTER 9. GRAPH THEORY                                       196

9.2.1 Basic Data Structures

    List 9.2.1 Data Structures for Graphs

         Assume that we have a graph with n vertices that can be indexed
    by the integers 1, 2, . . . , n. Here are three different data structures that
    can be employed to represent graphs.

      (a) Adjacency Matrix: As we saw in Chapter 6, the information about
            edges in a graph can be summarized with a matrix, G, where
            Gij = 1 if and only if vertex i is connected to vertex j in the
            graph. Matrices of this type were called relation matrices, but for
            graphs they are more commonly referred to as adjacency matrices.

      (b) Edge Dictionary: For each vertex in our graph, we maintain a list
            of edges that initiate at that vertex. If G represents the graph's
            edge information, then we denote by Gi the list of vertices that
            are terminal vertices of edges initiating at vertex i. The exact
            syntax that would be used can vary. We will use Sage/Python
            syntax in our examples.

       (c) Edge List: Note that in creating either of the first two data struc-
            tures, we would presume that a list of edges for the graph exists.
            A simple way to represent the edges is to maintain this list of or-
            dered pairs, or two element sets, depending on whether the graph
            is intended to be directed or undirected. We will not work with
            this data structure here, other than in the first example.

Example 9.2.2 A Very Small Example. We consider the representation
of the following graph:

Figure 9.2.3 Graph for a Very Small Example

The adjacency matrix that represents the graph would be

                         0101                

G =  0 0 1 1    .
          0010

                         1000

The same graph could be represented with the edge dictionary

{1:[2,4],2:[3,4],3:[3],4:[1]}.

Notice the general form of each item in the dictionary: vertex:[list of
vertices].
CHAPTER 9. GRAPH THEORY                                                              197

Finally, a list of edges [(1,2),(1,4),(2,3),(2,4),(3,3),(4,1)] also de-

scribes the same graph.                                                              

A natural question to ask is: Which data structure should be used in a

given situation? For small graphs, it really doesn't make much difference. For

larger matrices the edge count would be a consideration. If n is large and the

number of edges is relatively small, it might use less memory to maintain an

edge dictionary or list of edges instead of building an n × n matrix. Some

software for working with graphs will make the decision for you.

Example 9.2.4 NCAA Basketball. Consider the tournament graph repre-

senting a NCAA Division 1 men's (or women's) college basketball season in the

United States. There are approximately 350 teams in Division 1. Suppose we

constructed the graph with an edge from team A to team B if A beat B at least

once in the season; and we label the edge with the number of wins. Since the

average team plays around 30 games in a season, most of which will be against

other  Division  I  teams,  we  could  expect  around  30·350  =  5, 250  edges  in  the
                                                          2
graph. This would be somewhat reduced by games with lower division teams

and cases where two or more wins over the same team produces one edge. Since

5,250 is much smaller than 3502 = 122, 500 entries in an adjacency matrix, an

edge dictionary or edge list would be more compact than an adjacency matrix.

Even if we were to use software to create an adjacency matrix, many programs

will identify the fact that a matrix such as the one in this example would be

"sparse" and would leave data in list form and use sparse array methods to

work with it.                                                                        

9.2.2 Sage Graphs

The most common way to define a graph in Sage is to use an edge dictionary.
Here is how the graph in Example 9.2.2 is generated and then displayed. No-
tice that we simply wrap the function DiGraph() around the same dictionary
expression we identified earlier.

 G1 = DiGraph( {1 : [4, 2], 2 : [3, 4], 3 : [3], 4 : [1]})
 G1 . show ()

    You can get the adjacency matrix of a graph with the adjacency_matrix
method.

 G1 . adjacency_matrix ()

[0 1 0 1]
[0 0 1 1]
[0 0 1 0]
[1 0 0 0]

   You can also define a graph based on its adjacency matrix.

M = Matrix([[0,1,0,0,0],[0,0,1,0,0],[0,0,0,1,0],
                         [0 ,0 ,0 ,0 ,1] ,[1 ,0 ,0 ,0 ,0]])

DiGraph (M). show ()

  [0 1 0 1]
  [0 0 1 1]
  [0 0 1 0]
  [1 0 0 0]

    The edge list of any directed graph can be easily retrieved. If you replace
edges with edge_iterator, you can iterate through the edge list. The third
CHAPTER 9. GRAPH THEORY  198

coordinate of the items in the edge is the label of the edge, which is None in
this case.

 DiGraph (M). edges ()

  [(0, 1, None), (1, 2, None), (2, 3, None), (3, 4, None),
        (4, 0, None)]

    Replacing the wrapper DiGraph() with Graph() creates an undirected graph.

 G2 = Graph( {1 : [4, 2], 2 : [3, 4], 3 : [3], 4 : [1]})
 G2 . show ()

    There are many special graphs and graph families that are available in
Sage through the graphs module. They are referenced with the prefix graphs.
followed by the name and zero or more parameters inside parentheses. Here
are a couple of them, first a complete graph with five vertices.

 graphs.CompleteGraph (5).show()

    Here is a wheel graph, named for an obvious pattern of vertices and edges.
We assign a name to it first and then show the graph without labeling the
vertices.

 w= graphs . WheelGraph (20)
 w.show(vertex_labels=false)

    There are dozens of graph methods, one of which determines the degree
sequence of a graph. In this case, it's the wheel graph above.

 w. degree_sequence ()

  [19, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
        3]

    The degree sequence method is defined within the graphs module, but the
prefix graphs. is not needed because the value of w inherits the graphs meth-
ods.

9.2.3 Exercises

1. Estimate the number of vertices and edges in each of the following graphs.
      Would the graph be considered sparse, so that an adjacency matrix would
      be inefficient?

        (a) Vertices: Cities of the world that are served by at least one airline.
              Edges: Pairs of cities that are connected by a regular direct flight.

        (b) Vertices: ASCII characters. Edges: connect characters that differ
              in their binary code by exactly two bits.

         (c) Vertices: All English words. Edges: An edge connects word x to
              word y if x is a prefix of y.

2. Each edge of a graph is colored with one of the four colors red, blue,
      yellow, or green. How could you represent the edges in this graph using a
      variation of the adjacency matrix structure?

3. Directed graphs G1, . . . , G6 , each with vertex set {1, 2, 3, 4, 5} are rep-
      resented by the matrices below. Which graphs are isomorphic to one
      another?
CHAPTER 9. GRAPH THEORY                                                    199

            0     10   0 0                    0 0 0 0 0

            0     01   0  0                   0        0     1     0  0
                                                                         
  G1     :     0  00   1  0            G2  :     0     0     0     0  0    G3 :
                                                                         
            0          0 1                    1 1 1 0 1
                  00

1                 00   00                        00000
    0000                                                           
                                           01111
                  0

1     0     0  0  1                    0      0     0     0     0
                                                                   
  0   1     0  0  0    G4        :         0  0     0     0     0          G5 :
                                                                   
0 0 1 0           0                    0 0 1 0 0

0 0 1 0           0                        00000
    0000          1                                    
                                    00010

0     0     0  0  0              0     0   0  0     0
                                                       
  0   1     0  1  0       G6  :     1  1   0  0     0  
                                                       
0 0 0 0           1              0 0 1 0 0

  0010            0                 00010

4. The following Sage command verifies that the wheel graph with four
      vertices is isomorphic to the complete graph with four vertices.

graphs . WheelGraph (4) . is_isomorphic ( graphs . CompleteGraph (4) )

  True

    A list of all graphs in this the graphs database is available via tab
completion. Type "graphs." and then hit the tab key to see which graphs
are available. This can be done using the Sage application or SageMath-
Cloud, but not sage cells. Find some other pairs of isomorphic graphs in
the database.

9.3 Connectivity

This section is devoted to a question that, when posed in relation to the graphs
that we have examined, seems trivial. That question is: Given two vertices,
s and t, of a graph, is there a path from s to t? If s = t, this question is
interpreted as asking whether there is a circuit of positive length starting at
s. Of course, for the graphs we have seen up to now, this question can be
answered after a brief examination.

9.3.1 Preliminaries

There are two situations under which a question of this kind is nontrivial. One
is where the graph is very large and an "examination" of the graph could take a
considerable amount of time. Anyone who has tried to solve a maze may have
run into a similar problem. The second interesting situation is when we want to
pose the question to a machine. If only the information on the edges between
the vertices is part of the data structure for the graph, how can you put that
information together to determine whether two vertices can be connected by a
path?

Note 9.3.1 Connectivity Terminology. Let v and w be vertices of a
directed graph. Vertex v is connected to vertex w if there is a path from v to
w. Two vertices are strongly connected if they are connected in both directions
to one another. A graph is connected if, for each pair of distinct vertices, v and
w, v is connected to w or w is connected to v. A graph is strongly connected
CHAPTER 9. GRAPH THEORY                                           200

if every pair of its vertices is strongly connected. For an undirected graph, in
which edges can be used in either direction, the notions of strongly connected
and connected are the same.

Theorem 9.3.2 Maximal Path Theorem. If a graph has n vertices and

vertex u is connected to vertex w, then there exists a path from u to w of length

no more than n.

Proof. (Indirect): Suppose u is connected to w, but the shortest path from u

to w has length m, where m > n. A vertex list for a path of length m will have

m + 1 vertices. This path can be represented as (v0, v1, . . . , vm), where v0 = u

and vm = w. Note that since there are only n vertices in the graph and m

vertices are listed in the path after v0, we can apply the pigeonhole principle

and be assured that there must be some duplication in the last m vertices of

the vertex list, which represents a circuit in the path. This means that our

path of minimum length can be reduced, which is a contradiction.  

9.3.2 Adjacency Matrix Method

Algorithm 9.3.3 Adjacency Matrix Method. Suppose that the informa-
tion about edges in a graph is stored in an adjacency matrix, G. The relation,
r, that G defines is vrw if there is an edge connecting v to w. Recall that the
composition of r with itself, r2, is defined by vr2w if there exists a vertex y such
that vry and yrw; that is, v is connected to w by a path of length 2. We could
prove by induction that the relation rk, k  1, is defined by vrkw if and only if
there is a path of length k from v to w. Since the transitive closure, r+, is the
union of r, r2 , r3, . . ., we can answer our connectivity question by determining
the transitive closure of r, which can be done most easily by keeping our relation
in matrix form. Theorem 9.3.2 is significant in our calculations because it tells
us that we need only go as far as Gn to determine the matrix of the transitive
closure.

    The main advantage of the adjacency matrix method is that the transitive
closure matrix can answer all questions about the existence of paths between
any vertices. If G+ is the matrix of the transitive closure, vi is connected to
vj if and only if (G+)ij = 1. A directed graph is connected if (G+)ij = 1
or (G+)ji = 1 for each i = j. A directed graph is strongly connected if its
transitive closure matrix has no zeros.

    A disadvantage of the adjacency matrix method is that the transitive clo-
sure matrix tells us whether a path exists, but not what the path is. The next
algorithm will solve this problem.

9.3.3 Breadth-First Search

We will describe the Breadth-First Search Algorithm first with an example.
    The football team at Mediocre State University (MSU) has had a bad year,

2 wins and 9 losses. Thirty days after the end of the football season, the
university trustees are meeting to decide whether to rehire the head coach;
things look bad for him. However, on the day of the meeting, the coach issues
the following press release with results from the past year:

    List 9.3.4 Press Release: MSU completes successful season

         The Mediocre State University football team compared favorably
    with national champion Enormous State University this season.

        · Mediocre State defeated Local A and M.
CHAPTER 9. GRAPH THEORY  201

        · Local A and M defeated City College.

        · City College defeated Corn State U.

        · ... (25 results later)

        · Tough Tech defeated Enormous State University (ESU).

    ...and ESU went on to win the national championship!

    The trustees were so impressed that they rehired the coach with a raise!
How did the coach come up with such a list?

    In reality, such lists exist occasionally and have appeared in newspapers
from time to time. Of course they really don't prove anything since each team
that defeated MSU in our example above can produce a similar, shorter chain
of results. Since college football records are readily available, the coach could
have found this list by trial and error. All that he needed to start with was
that his team won at least one game. Since ESU lost one game, there was some
hope of producing the chain.

    The problem of finding this list is equivalent to finding a path in the tour-
nament graph for last year's football season that initiates at MSU and ends at
ESU. Such a graph is far from complete and is likely to be represented using
edge lists. To make the coach's problem interesting, let's imagine that only the
winner of any game remembers the result of the game. The coach's problem
has now taken on the flavor of a maze. To reach ESU, he must communicate
with the various teams along the path. One way that the coach could have
discovered his list in time is by sending the following messages to the coaches
of the two teams that MSU defeated during the season:

Note 9.3.5 When this example was first written, we commented that ties
should be ignored. Most recent NCAA rules call for a tiebreaker in college
football and so ties are no longer an issue. Email was also not common and we
described the process in terms of letters, not email messages. Another change
is that the coach could also have asked the MSU math department to use
Mathematica or Sage to find the path!

    List 9.3.6 The Coach's Letter

         Dear Football Coach:
         Please follow these directions exactly.

       (1) If you are the coach at ESU, contact the coach at MSU now and
            tell him who sent you this message.

       (2) If you are not the coach at ESU and this is the first message of
            this type that you have received, then:

               · Remember from whom you received this message.

               · Forward a copy of this message, signed by you, to each of
                   the coaches whose teams you defeated during the past year.

               · Ignore this message if you have received one like it already.

                    Signed,
                        Coach of MSU
CHAPTER 9. GRAPH THEORY  202

     List 9.3.7 Observations

         From the conditions of this message, it should be clear that if every-
     one cooperates and if coaches participate within a day of receiving the
     message:

       (1) If a path of length n exists from MSU to ESU, then the coach will
            know about it in n days.

       (2) By making a series of phone calls, the coach can construct a path
            that he wants by first calling the coach who defeated ESU (the
            person who sent ESU's coach that message). This coach will know
            who sent him a letter, and so on. Therefore, the vertex list of the
            desired path is constructed in reverse order.

       (3) If a total of M football games were played, no more than M
            messages will be sent out.

       (4) If a day passes without any message being sent out, no path from
            MSU to ESU exists.

       (5) This method could be extended to construct a list of all teams
            that a given team can be connected to. Simply imagine a series of
            letters like the one above sent by each football coach and targeted
            at every other coach.

     The general problem of finding a path between two vertices in a graph, if
one exists, can be solved exactly as we solved the problem above. The following
algorithm, commonly called a breadth-first search, uses a stack.

Stacks. A stack is a fundamental data structure in computer science. A
common analogy used to describe stacks is a stack of plates. If you put a plate
on the top of a stack and then want to use a plate, it's natural to use that top
plate. So the last plate in is the first plate out. "Last in, first out" is the short
description of the rule for stacks. This is contrast with a queue which uses a
"First in, first out" rule.

Algorithm 9.3.8 Breadth-first Search. A broadcasting algorithm for
finding a path between vertex i and vertex j of a graph having n vertices. Each
item Vk of a list V = {V1, V2, . . . , Vn}, consists of a Boolean field Vk.found
and an integer field Vk.from. The sets D1, D2, . . ., called depth sets, have the
property that if k  Dr, then the shortest path from vertex i to vertex k is of
length r. In Step 5, a stack is used to put the vertex list for the path from
the vertex i to vertex j in the proper order. That stack is the output of the
algorithm.

  (1) Set the value Vk.found equal to False, k = 1, 2, . . . , n

  (2) r = 0

  (3) Vi.found = T rue

  (4) D0 = {i}

  (5) while (¬Vj.found) and (Dr = )

          · Dr+1 = 
          · for each k in Dr:
CHAPTER 9. GRAPH THEORY  203

               for each edge (k,t):
                  If Vt.found == False:
                     Vt.found = True
                     Vt.from = k
                     Dr+1 = Dr+1  {t}

        · r=r+1

(6) if Vj.found:

        · S = EmptyStack

        · k=j

        · while Vk.from = i:
               Push k onto S
               k = Vk.from

        · Push k onto S

        · Push i onto S

  List 9.3.9 Notes on Breadth-first Search

      · If vi is the starting vertex and we initialize vi.f ound = F alse,
          then the algorithm will find the shortest circuit containing vi. If
          that is of interest, we would also not initialize the depth of Vi to
          {i}

      · This algorithm will produce one path from vertex i to vertex j,
          if one exists, and that path will be as short as possible. If more
          than one path of this length exists, then the one that is produced
          depends on the order in which the edges are examined and the
          order in which the elements of Dr are examined in Step 4.

      · The condition Dr =  is analogous to the condition that no mail
          is sent in a given stage of the process, in which case MSU cannot
          be connected to ESU.

      · This algorithm can be easily revised to find paths to all vertices
          that can be reached from vertex i. Step 5 would be put off until
          a specific path to a vertex is needed since the information in V
          contains an efficient list of all paths. The algorithm can also be
          extended further to find paths between any two vertices.

Example 9.3.10 A simple example. Consider the graph below. The
existence of a path from vertex 2 to vertex 3 is not difficult to determine by
examination. After a few seconds, you should be able to find two paths of
length four. Algorithm 9.3.8 will produce one of them.
CHAPTER 9. GRAPH THEORY                                        204

Figure 9.3.11 A simple example of breadth-first search

    Suppose that the edges from each vertex are sorted in ascending order
by terminal vertex. For example, the edges from vertex 3 would be in the
order (3, 1), (3, 4), (3, 5). In addition, assume that in the body of Step 4 of the
algorithm, the elements of Dr are used in ascending order. Then at the end of
Step 4, the value of V will be

k  123456

Vk.found T T T T T T

Vk.from 2 4 6 1 1 4

Depthset 1 3 4 2 2 3

Therefore, the path (2, 1, 4, 6, 3) is produced by the algorithm. Note that if we

wanted a path from 2 to 5, the information in V produces the path (2, 1, 5)

since Vk.from = 1 and V1.from = 2. A shortest circuit that initiates at vertex

2 is also available by noting that V2.from = 4, V4.from = 1, and V1.from = 2;

thus the circuit (2, 1, 4, 2) is the output of the algorithm.  

9.3.4 Graph Measurements

If we were to perform a breadth-first search from each vertex in a graph, we
could proceed to determine several key measurements relating to the general
connectivity of that graph. From each vertex v, the distance from v to any
other vertex w, d(v, w), is number of edges in the shortest path from v to
w. This number is also the index of the depth set to which w belongs in a
breadth-first search starting at v.

                                 d(v, w) = i  w  Dv(i)

where Dv is the family of depth sets starting at v.
    If the vector of "from-values" is known from the breadth-first search, then
CHAPTER 9. GRAPH THEORY                                          205

the distance can be determined recursively as follows:

                                            d(v, v) = 0
                           d(v, w) = 1 + d(v, w.f rom) if w = v
Example 9.3.12 Computing Distances.

Figure 9.3.13 Graph Measurements Example
    Consider Figure 9.3.13. If we perform a breadth first search of this graph

starting at vertex 2, for example, we get the following "from data" telling us
from what vertex each vertex is reached.

                 vertex 1 2 3 4 5 6 7 8 9 10 11 12
             vertex.from 7 2 10 6 9 7 2 4 2 7 9 2

For example, 4.from has a value of 6. We can compute d(2, 4):

                         d(2, 4) = 1 + d(2, 4.f rom) = 1 + d(2, 6)
                                   = 2 + d(2, 6.f rom) = 2 + d(2, 7)
                                   = 3 + d(2, 7.f rom) = 3 + d(2, 2)
                                   =3

                                                                                                    
    Once we know distances between any two vertices, we can determine the
eccentricity of each vertex; and the graph's diameter, radius and center. First,
we define these terms precisely.

Eccentricity of a Vertex
               The maximum distance from a vertex to all other vertices, e(v) =
               maxw d(v, w).

Diameter of a Graph
               The maximum eccentricity of vertices in a graph, denoted d(G).

Radius of a Graph
               The minimum eccentricity of vertices in a graph, denoted r(G).

Center of a Graph
               The set of vertices with minimal eccentricity, C(G) = {v  V |
               e(v) = r(G)}
CHAPTER 9. GRAPH THEORY                                                     206

Example 9.3.14 Measurements from distance matrices. If we compute
all distances between vertices, we can summarize the results in a distance
matrix, where the entry in row i, column j is the distance from vertex i to
vertex j. For the graph in Example 9.3.12, that matrix is

         0 2 2 2 3 1 1 3 3 1 2 2

         2    0  3  3  2      2  1  4  1  2         2  1
                                                          
           2  3  0  2  5      3  2  3  4  1         4  3  
                                                          
                                                          
           2  3  2  0  3      1  2  1  3  1         2  3  
          3 2 5 3 0 2 3 4 1 4 1 3 
         1 2 3 1 2 0 1 2 2 2 1 2
                                                          
         1 1 2 2 3 1 0 3 2 1 2 1
                                                          
         3 4 3 1 4 2 3 0 4 2 3 4
                                                          
         3    1  4  3  1      2  2  4  0  3         1  2
                                                          
           1  2  1  1  4      2  1  2  3  0         3  2  
                                                          
         2 2 4 2 1 1 2 3 1 3 0 3

           213332142230

If we scan the matrix, we can see that the maximum distance is the distance

between vertices 3 and 5, which is 5 and is the diameter of the graph. If

we focus on individual rows and identify the maximum values, which are the

eccentricities, their minimum is 3, which the graph's radius. This eccentricity

value is attained by vertices in the set {1, 4, 6, 7}, which is the center of the

graph.                                                                      

9.3.5 SageMath Note - Graph Searching

The following sequence of Sage cells illustrates how searching can be done in

graphs.

     Generate a random undirected graph with 18 vertices. For each pair of

vertices, an edge is included between them with probability 0.2. Since there

are  18  = 153 potential edges, we expect that there will be approximately
     2
0.2 · 153  31 edges. The random number generation is seeded first so that the

result will always be the same in spite of the random graph function. Changing

or removing that first line will let you experiment with different graphs.

set_random_seed (2002)
Gr=graphs.RandomGNP (18,0.2)
Gr . show ()

    Count the number of edges. In this case the number is a bit less than
expected.

 len(Gr.edges(labels=False))

27
   Find a shortest path from vertex 0 to vertex 8.

Gr.shortest_path(0, 8)

  [0, 7, 3, 8]

    Generate a list of vertices that would be reached in a breadth-first search.
The expression Gr.breadth_first_search(0) creates an iterator that is conve-
nient for programming. Wrapping list( ) around the expression shows the
CHAPTER 9. GRAPH THEORY                                            207

order in which the vertices are visited with the depth set indicated in the
second coordinates.

 list(Gr.breadth_first_search(0,report_distance= ' True '))

[(0, 0) ,(7, 1) ,(14,  1) ,(15, 1) ,(16, 2) ,(2, 2) ,(3, 2) ,(13,
      2) ,(17, 2),     2) ,(6, 2) ,(11, 2) ,(8, 3) ,(1, 3) ,(9,

 (4, 2) ,(5, 2) ,(10,
        3) ,(12, 3)]

9.3.6 Exercises

1. Apply Algorithm 9.3.8 to find a path from 5 to 1 in Figure 9.3.11. What
      would be the final value of V ? Assume that the terminal vertices in edge
      lists and elements of the depth sets are put into ascending order, as we
      assumed in Example 9.3.10.

2. Apply Algorithm 9.3.8 to find a path from d to c in the road graph
      in Example 9.1.7 using the edge list in that example. Assume that the
      elements of the depth sets are put into ascending order.

3. In a simple undirected graph with no self-loops, what is the maximum
      number of edges you can have, keeping the graph unconnected? What
      is the minimum number of edges that will assure that the graph is con-
      nected?

4. Use a broadcasting algorithm to determine the shortest path from vertex
      a to vertex i in the graphs shown in the Figure 9.3.15 below. List the
      depth sets and the stack that is created.
CHAPTER 9. GRAPH THEORY  208

      Figure 9.3.15 Shortest paths from a to i?

5. For each of the following graphs, determine the eccentricities of each
      vertex, and the diameter, radius, and center of the graph.
CHAPTER 9. GRAPH THEORY                              209

6.

    (a) The terms diameter, radius and center are familiar ones in the con-
         text of circles. Compare their usage in circles and graphs. How are
         they similar and how are they different?

    (b) "Eccentricity" might be less familiar. How is is used in geometry,
         and does it have a compatible use in graph theory?

7. Prove (by induction on k) that if the relation r on vertices of a graph is
      defined by vrw if there is an edge connecting v to w, then rk, k  1, is
      defined by vrkw if there is a path of length k from v to w.

8. For each of the following distance matrices of graphs, identify the diam-

    eter, radius and center. Assume the graphs vertices are the numbers 1

    through n for an n × n matrix.

          0212233211                         

          2  0  1  2  3  3  3       2  3  2  
                                             
                                             
          1  1  0  1  2  2  2       1  2  1  
     2 2 1 0 3 3 3 2 3 2 
    2 3 2 3 0 2 1 1 2 1
    (a)                                      
    3 3 2 3 2 0 1 1 3 2
                                             
    3 3 2 3 1 1 0 1 3 2
                                             
    2        2  1  2  1  1  1       0  2  1
                                             
    1 3 2 3 2 3 3 2 0 1

          1212122110

    0 2 2 2 3 3 3 1 2 3 1 1

    2        0  2  2  1  1  1       3  2  1  1  3
                                                   
          2  2  0  1  3  2  1       2  2  3  1  1  
                                                   
                                                   
          2  2  1  0  3  1  2       1  2  3  2  1  
     3 1 3 3 0 2 2 4 3 2 2 4 
    3 1 2 1 2 0 2 2 3 2 2 2
    (b)                                            
    3 1 1 2 2 2 0 3 3 2 2 2
                                                   
    1 3 2 1 4 2 3 0 3 4 2 2
                                                   
    2        2  2  2  3  3  3       3  0  1  3  1
                                                   
          3  1  3  3  2  2  2       4  1  0  2  2  
                                                   
    1 1 1 2 2 2 2 2 3 2 0 2

          131142221220
CHAPTER 9. GRAPH THEORY                                        210

9.4 Traversals: Eulerian and Hamiltonian Graphs

The subject of graph traversals has a long history. In fact, the solution by
Leonhard Euler (Switzerland, 1707-83) of the Koenigsberg Bridge Problem is
considered by many to represent the birth of graph theory.

9.4.1 Eulerian Graphs

Figure 9.4.1 A map of Koenigsberg,
circa 1735

                         Figure 9.4.2 A multigraph for the
                         bridges of Koenigsberg

    A map of the Prussian city of Koenigsberg (circa 1735) in Figure 1 shows
that there were seven bridges connecting the four land masses that made up
the city. The legend of this problem states that the citizens of Koenigsberg
searched in vain for a walking tour that passed over each bridge exactly once.
No one could design such a tour and the search was abruptly abandoned with
the publication of Euler's Theorem.

Theorem 9.4.3 Euler's Theorem: Koenigsberg Case. No walking tour
of Koenigsberg can be designed so that each bridge is used exactly once.
Proof. The map of Koenigsberg can be represented as an undirected multi-
graph, as in Figure 9.4.2. The four land masses are the vertices and each edge
represents a bridge.
The desired tour is then a path that uses each edge once and only once. Since
the path can start and end at two different vertices, there are two remaining
vertices that must be intermediate vertices in the path. If x is an intermediate
vertex, then every time that you visit x, you must use two of its incident edges,
one to enter and one to exit. Therefore, there must be an even number of edges
connecting x to the other vertices. Since every vertex in the Koenigsberg graph
has an odd number of edges, no tour of the type that is desired is possible. 

    As is typical of most mathematicians, Euler wasn't satisfied with solving
only the Koenigsberg problem. His original theorem, which is paraphrased be-
low, concerned the existence of paths and circuits like those sought in Koenigs-
berg. These paths and circuits have become associated with Euler's name.

Definition 9.4.4 Eulerian Paths, Circuits, Graphs. An Eulerian path

through a graph is a path whose edge list contains each edge of the graph

exactly once. If the path is a circuit, then it is called an Eulerian circuit. An

Eulerian graph is a graph that possesses an Eulerian circuit.  
CHAPTER 9. GRAPH THEORY  211

    Notice that if a graph has an Eulerian path that is not a circuit it is generally
not considered an Eulerian graph, although some authors will call it such. So
in any reference you read, be sure to check that definition that is used!

Example 9.4.5 An Eulerian Graph. Without tracing any paths, we can
be sure that the graph below has an Eulerian circuit because all vertices have
an even degree. This follows from the following theorem.

Figure 9.4.6 An Eulerian graph

                                                                                                     

Theorem 9.4.7 Euler's Theorem: General Case. An undirected graph
has an Eulerian path if and only if it is connected and has either zero or two
vertices with an odd degree. If no vertex has an odd degree, then the graph is
Eulerian.
Proof. It can be proven by induction that the number of vertices in an undi-
rected graph that have an odd degree must be even. We will leave the proof
of this fact to the reader as an exercise. The necessity of having either zero or
two vertices of odd degree is clear from the proof of the Koenigsberg case of
this theorem. Therefore, we will concentrate on proving that this condition is
sufficient to ensure that a graph has an Eulerian path. Let k be the number
of vertices with odd degree.
Phase 1. If k = 0, start at any vertex, v0, and travel along any path, not using
any edge twice. Since each vertex has an even degree, this path can always be
continued past each vertex that you reach except v0. The result is a circuit
that includes v0. If k = 2, let v0 be either one of the vertices of odd degree.
Trace any path starting at v0 using up edges until you can go no further, as
in the k = 0 case. This time, the path that you obtain must end at the other
vertex of odd degree that we will call v1. At the end of Phase 1, we have an
initial path that may or may not be Eulerian. If it is not Eulerian, Phase 2 can
be repeated until all of the edges have been used. Since the number of unused
edges is decreased in any use of Phase 2, an Eulerian path must be obtained
in a finite number of steps.
Phase 2. As we enter this phase, we have constructed a path that uses a proper
subset of the edges in our graph. We will refer to this path as the current path.
Let V be the vertices of our graph, E the edges, and Eu the edges that have
been used in the current path. Consider the graph G = (V, E - Eu). Note
that every vertex in G has an even degree. Select any edge, e, from G. Let
va and vb be the vertices that e connects. Trace a new path starting at va
CHAPTER 9. GRAPH THEORY              212

whose first edge is e. We can be sure that at least one vertex of the new path is
also in the current path since (V, E) is connected. Starting at va, there exists
a path in (V, E) to any vertex in the current path. At some point along this
path, which we can consider the start of the new path, we will have intersected
the current path. Since the degree of each vertex in G is even, any path that
we start at va can be continued until it is a circuit. Now, we simply augment
the current path with this circuit. As we travel along the current path, the
first time that we intersect the new path, we travel along it (see Figure 9.4.8).
Once we complete the circuit that is the new path, we resume the traversal of
the current path.

Figure 9.4.8 Path Augmentation Plan

If the result of this phase is an Eulerian path, then we are finished; otherwise,

repeat this phase.                   

Example 9.4.9 Complete Eulerian Graphs. The complete undirected

graphs K2n+1, n = 1, 2, 3, . . .. .., are Eulerian. If n  1, then K2n is not

Eulerian.                            

9.4.2 Hamiltonian Graphs

To search for a path that uses every vertex of a graph exactly once seems to
be a natural next problem after you have considered Eulerian graphs.The Irish
mathematician Sir William Rowan Hamilton (1805-65) is given credit for first
defining such paths. He is also credited with discovering the quaternions, for
which he was honored by the Irish government with a postage stamp in 2005.
CHAPTER 9. GRAPH THEORY                                        213

Figure 9.4.10 Irish stamp honoring Sir William Rowan Hamilton

Definition 9.4.11 Hamiltonian Path, Circuit, and Graphs. A Hamil-

tonian path through a graph is a path whose vertex list contains each vertex of

the graph exactly once, except if the path is a circuit, in which case the initial

vertex appears a second time as the terminal vertex. If the path is a circuit,

then it is called a Hamiltonian circuit. A Hamiltonian graph is a graph that

possesses a Hamiltonian circuit.                               

Example 9.4.12 The Original Hamiltonian Graph. Figure 9.4.14 shows
a graph that is Hamiltonian. In fact, it is the graph that Hamilton used as
an example to pose the question of existence of Hamiltonian paths in 1859. In
its original form, the puzzle that was posed to readers was called "Around the
World." The vertices were labeled with names of major cities of the world and
the object was to complete a tour of these cities. The graph is also referred
to as the dodecahedron graph, where vertices correspond with the corners of a
dodecahedron and the edges are the edges of the solid that connect the corners.

Figure 9.4.13 A Dodecahedron      Figure 9.4.14 The Dodecahedron
                                  Graph

                                                               

Problem 9.4.15 Unfortunately, a simple condition doesn't exist that charac-

terizes a Hamiltonian graph. An obvious necessary condition is that the graph

be connected; however, there is a connected undirected graph with four vertices

that is not Hamiltonian. Can you draw such a graph?            

Note 9.4.16 What Is Possible and What Is Impossible? The search
for a Hamiltonian path in a graph is typical of many simple-sounding problems
CHAPTER 9. GRAPH THEORY                                              214

in graph theory that have proven to be very difficult to solve. Although there
are simple algorithms for conducting the search, they are impractical for large
problems because they take such a long time to complete as graph size increases.
Currently, every algorithm to search for a Hamiltonian path in a graph takes
a time that grows at a rate that is greater than any polynomial as a function
of the number of vertices. Rates of this type are called "super-polynomial."
That is, if T (n) is the time it takes to search a graph of n vertices, and p(n)
is any polynomial, then T (n) > p(n) for all but possibly a finite number of
positive values for n.

    It is an unproven but widely held belief that no faster algorithm exists to
search for Hamiltonian paths in general graphs. To sum up, the problem of
determining whether a graph is Hamiltonian is theoretically possible; however,
for large graphs we consider it a practical impossibility. Many of the problems
we will discuss in the next section, particularly the Traveling Salesman Problem,
are thought to be impossible in the same sense.

Definition 9.4.17 The n-cube. Let n  1, and let Bn be the set of strings

of 0's and 1's with length n. The n-cube is the undirected graph with a vertex

for each string in Bn and an edge connecting each pair of strings that differ in

exactly one position. The n-cube is normally denoted Qn.             

The n-cube is among the graphs that are defined within the graphs package

of SageMath and is created with the expression graphs.CubeGraph(n).

graphs . CubeGraph (4) . show ( layout =" spring ")

Example 9.4.18 Analog-to-digital Conversion and the Gray Code. A
common problem encountered in engineering is that of analog-to-digital (a-d)
conversion, where the reading on a dial, for example, must be converted to a
numerical value. In order for this conversion to be done reliably and quickly,
one must solve an interesting problem in graph theory. Before this problem
is posed, we will make the connection between a-d conversion and the graph
problem using a simple example. Suppose a dial can be turned in any direction,
and that the positions will be converted to one of the numbers zero through
seven as depicted in Figure 9.4.19. The angles from 0 to 360 are divided into
eight equal parts, and each part is assigned a number starting with 0 and
increasing clockwise. If the dial points in any of these sectors the conversion
is to the number of that sector. If the dial is on the boundary, then we will be
satisfied with the conversion to either of the numbers in the bordering sectors.
This conversion can be thought of as giving an approximate angle of the dial,
for if the dial is in sector k, then the angle that the dial makes with east is
approximately 45k.
CHAPTER 9. GRAPH THEORY  215

Figure 9.4.19 Analog-Digital Dial

    Now that the desired conversion has been identified, we will describe a
"solution" that has one major error in it, and then identify how this prob-
lem can be rectified. All digital computers represent numbers in binary form,
as a sequence of 0's and 1's called bits, short for binary digits. The binary
representations of numbers 0 through 7 are:

                               0 = 000two = 0 · 4 + 0 · 2 + 0 · 1
                               1 = 001two = 0 · 4 + 0 · 2 + 1 · 1
                               2 = 010two = 0 · 4 + 1 · 2 + 0 · 1
                               3 = 011two = 0 · 4 + 1 · 2 + 1 · 1
                               4 = 100two = 1 · 4 + 0 · 2 + 0 · 1
                               5 = 101two = 1 · 4 + 0 · 2 + 1 · 1
                               6 = 110two = 1 · 4 + 1 · 2 + 0 · 1
                               7 = 111two = 1 · 4 + 1 · 2 + 1 · 1

    The way that we could send those bits to a computer is by coating parts
of the back of the dial with a metallic substance, as in Figure 9.4.20. For each
of the three concentric circles on the dial there is a small magnet. If a magnet
lies under a part of the dial that has been coated with metal, then it will turn
a switch ON, whereas the switch stays OFF when no metal is detected above
a magnet. Notice how every ON/OFF combination of the three switches is
possible given the way the back of the dial is coated.

    If the dial is placed so that the magnets are in the middle of a sector, we
expect this method to work well. There is a problem on certain boundaries,
however. If the dial is turned so that the magnets are between sectors three
and four, for example, then it is unclear what the result will be. This is due
to the fact that each magnet will have only a fraction of the required metal
above it to turn its switch ON. Due to expected irregularities in the coating
of the dial, we can be safe in saying that for each switch either ON or OFF
could be the result, and so if the dial is between sectors three and four, any
number could be indicated. This problem does not occur between every sector.
For example, between sectors 0 and 1, there is only one switch that cannot be
predicted. No matter what the outcome is for the units switch in this case,
the indicated sector must be either 0 or 1. This is consistent with the original
objective that a positioning of the dial on a boundary of two sectors should
produce the number of either sector.
CHAPTER 9. GRAPH THEORY  216

Figure 9.4.20 Coating scheme for the Analog-Digital Dial
    Is there a way to coat the sectors on the back of the dial so that each of

the eight patterns corresponding to the numbers 0 to 7 appears once, and so
that between any two adjacent sectors there is only one switch that will have
a questionable setting? What we are describing here is a Hamiltonian circuit
of the 3-cube (Figure 9.4.21). If one can draw a path along the edges in the
3-cube that starts at any vertex, passes through every other vertex once, and
returns to the start, then that sequence of bit patterns can be used to coat the
back of the dial so that between every sector there is only one questionable
switch. Such a path is not difficult to find, as we will see below.

Figure 9.4.21 The 3-cube
    Many A-D conversion problems require many more sectors and switches

than this example, and the same kinds of problems can occur. The solution
would be to find a path within a much larger yet similar graph. For example,
there might be 1,024 sectors with 10 switches, resulting in a graph with 1,024
vertices. Fortunately, our solution will apply to the n-cube for any positive
value of n.

    A Hamiltonian circuit of the n-cube can be described recursively. The
circuit itself, called the Gray Code, is not the only Hamiltonian circuit of the
n-cube, but it is the easiest to describe. The standard way to write the Gray
Code is as a column of strings, where the last string is followed by the first
string to complete the circuit.

    Basis for the Gray Code (n = 1): The Gray Code for the 1-cube is G1 =
CHAPTER 9. GRAPH THEORY                                                           217

0 . Note that the edge between 0 and 1 is used twice in this circuit. That
1

doesn't violate any rules for Hamiltonian circuits, but can only happen if a

graph has two vertices.

Recursive definition of the Gray Code: Given the Gray Code for the n-cube,

n  1, then Gn+1 is obtained by (1) listing Gn with each string prefixed with

0, and then (2) reversing the list of strings in Gn with each string prefixed

with 1.  Symbolically,   the  recursion  can  be  expressed  as  follows,  where  Gr    is

                                                                                     n

the reverse of list Gn.

                                Gn+1 =        0Gn
                                              1Grn

The Gray Codes for the 2-cube and 3-cube are

                                                      000    

                                                     001 
                                00                   011 
                                                             
                               01                    010 
                   G2    =               and  G3  =          
                                11                   110 
                                                             
                                10                   111 
                                                             
                                                     101 

                                                      100

One question might come to mind at this point. If the coatings of the dial

no longer in the sequence from 0 to 7, how would you interpret the patterns

that are on the back of the dial as numbers from 0 to 7? In Chapter 14 we will

see that if the Gray Code is used, this "decoding" is quite easy.                       

Example 9.4.22 Applications of the Gray Code. One application of the

Gray code was discussed in the Introduction to this book. Another application

is in statistics. In a statistical analysis, there is often a variable that depends

on several factors, but exactly which factors are significant may not be obvious.

For each subset of factors, there would be certain quantities to be calculated.

One such quantity is the multiple correlation coefficient for a subset. If the

correlation coefficient for a given subset, A, is known, then the value for any

subset that is obtained by either deleting or adding an element to A can be

obtained quickly. To calculate the correlation coefficient for each set, we simply

travel along Gn, where n is the number of factors being studied. The first vertex

will always be the string of 0's, which represents the empty set. For each vertex

that you visit, the set that it corresponds to contains the kth factor if the kth

character is a 1.                                                                       

The 3-cube and its generalization, the n-cube, play a role in the design

of a multiprocessor called a hypercube. A multiprocessor is a computer that

consists of several independent processors that can operate simultaneously and

are connected to one another by a network of connections. In a hypercube with

M = 2n processors, the processors are numbered 0 to M - 1. Two processors

are connected if their binary representations differ in exactly one bit. The

hypercube has proven to be the best possible network for certain problems

requiring the use of a "supercomputer."
CHAPTER 9. GRAPH THEORY  218

9.4.3 Exercises

1. Locate a map of New York City and draw a graph that represents its
      land masses, bridges and tunnels. Is there an Eulerian path through New
      York? You can do the same with any other city that has at least two land
      masses.

2. Which of the following drawings can be drawn without removing your
      pencil from the paper and without drawing any line twice?

      (a)

                                                                      (c)

                                      (b)
      Figure 9.4.23 Some Drawings
3. Write out the Gray Code for the 4-cube.
4. Find a Hamiltonian circuit for the dodecahedron graph in Figure 9.4.14.
5. The Euler Construction Company has been contracted to construct an
      extra bridge in Koenigsberg so that an Eulerian path through the town
      exists. Can this be done, and if so, where should the bridge be built?
6. Consider the graphs in Figure 9.4.24. Determine which of the graphs have
      an Eulerian path, and find an Eulerian path for the graphs that have one.
CHAPTER 9. GRAPH THEORY                           219

      Figure 9.4.24 Graphs for exercise 6

7. Formulate Euler's theorem for directed graphs.

8. Prove that the number of vertices in an undirected graph with odd degree
      must be even.

      Hint. You could prove this by induction on the number of edges, but an
      easier way would be to consider the degree sequence and use something
      you know about the sum of the entries.
9.

     (a) Under what conditions will a round-robin tournament graph be
          Eulerian?

     (b) Prove that every round-robin tournament graph has a Hamiltonian
          path.

10. For what values of n is the n-cube Eulerian?

11.  A particular set of dominoes has 21 tiles:

     (1, 1), (1, 2), . . . (1, 6), (2, 2), (2, 3), . . . , (6, 6). Is it possible to lay all

     21 tiles in a line so that each adjacent pair of tile ends matches (that is,

     each 1 abuts a 1, and so on)?

12. Let G be the graph below.
CHAPTER 9. GRAPH THEORY                                                  220

Figure 9.4.25

  (a) Explain why it's not possible to find an Eulerian circuit in G.

  (b) Remove two edges from G so the resulting graph H has an Eulerian
       circuit. Then list the vertices of an Eulerian circuit in H in the order
       in which they are visited by the circuit.

9.5 Graph Optimization

The common thread that connects all of the problems in this section is the
desire to optimize (maximize or minimize) a quantity that is associated with a
graph. We will concentrate most of our attention on two of these problems, the
Traveling Salesman Problem and the Maximum Flow Problem. At the close of
this section, we will discuss some other common optimization problems.

9.5.1 Weighted Graphs

Definition 9.5.1 Weighted Graph. A weighted graph, (V, E, w), is a graph

(V, E) together with a weight function w : E  R. If e  E, w(e) is the weight
on edge e.
                                                                         

As you will see in our examples, w(e) is often a cost associated with the

edge e; therefore, most weights will be positive.

Example 9.5.2 A Distance Graph. Let V be the set of six capital cities
in New England: Boston, Augusta, Hartford, Providence, Concord, and Mont-
pelier. Let E be the set of all possible undirected edges between these cities.
So (V, E) is a complete unordered graph. An example of a weight function on
this graph is w ({c1, c2}) = the distance, in miles, between c1 and c2.

    Many road maps that you could get at gas stations at one time defined
distance functions as in the following table.

Table 9.5.3 Distances between capital cities in New England

         --     Augusta  Boston  Concord           Hartford  Montpelier  Providence
 Augusta, ME        --     165      148               266        190          208
  Boston, MA       165      --       75               103        192           43
 Concord, NH       148      75       --               142        117          109
 Hartford, CT      266     103      142                --        204           70
Montpelier, VT     190     192      117               204          --         223
Providence, RI     208      43      109                70        223           --

                                                                         
CHAPTER 9. GRAPH THEORY                                                   221

9.5.2 The Traveling Salesman Problem

The Traveling Salesman Problem is, given a weighted graph, to find a circuit
(e1, e2, . . . , en) that visits every vertex at least once and minimizes the sum of
the weights, i=1 n w (ei). Any such circuit is called an optimal path.

    Some statements of the Traveling Salesman Problem require that the circuit
be Hamiltonian. In many applications, the graph in question will be complete
and this restriction presents no problem. If the weight on each edge is constant,
for example, w(e) = 1, then an optimal path would be any Hamiltonian circuit.

Example 9.5.4 The problem of a Boston salesman. The Traveling

Salesman Problem gets its name from the situation of a salesman who wants

to minimize the number of miles that he travels in visiting his customers. For

example, if a salesman from Boston must visit the other capital cities of New

England, then the problem is to find a circuit in the weighted graph of Ex-

ample 9.5.2. Note that distance and cost are clearly related in this case. In

addition, tolls and traffic congestion might also be taken into account.  

The search for an efficient algorithm that solves the Traveling Salesman

has occupied researchers for years. If the graph in question is complete, there

are (n - 1)! different circuits. As n gets large, it is impossible to check every

possible circuit. The most efficient algorithms for solving the Traveling Sales-

man Problem take an amount of time that is proportional to n2n. Since this

quantity grows so quickly, we can't expect to have the time to solve the Trav-

eling Salesman Problem for large values of n. Most of the useful algorithms

that have been developed have to be heuristic; that is, they find a circuit that

should be close to the optimal one. One such algorithm is the "closest neigh-

bor" algorithm, one of the earliest attempts at solving the Traveling Salesman

Problem. The general idea behind this algorithm is, starting at any vertex, to

visit the closest neighbor to the starting point. At each vertex, the next vertex

that is visited is the closest one that has not been reached. This shortsighted

approach typifies heuristic algorithms called greedy algorithms, which attempt

to solve a minimization (maximization) problem by minimizing (maximizing)

the quantity associated with only the first step.

Algorithm 9.5.5 The Closest Neighbor Algorithm. Let G = (V, E, w)
be a complete weighted graph with |V | = n. The closest neighbor circuit through
G starting at v1 is (v1, v2, . . . , vn), defined by the steps:

(1) V1 = V - {v1}.
(2) For k = 2 to n - 1

(a) vk = the closest vertex in Vk-1 to vk-1
     ## w (vk-1, vk) = min (w (vk-1, v) | v  Vk-1)
     ## In case of a tie for closest, vk may be chosen arbitrarily.

(b) Vk = Vk-1 - {vk}

(3) vn = the only element of Vn

    The cost of the closest neighbor circuit is k=1 n-1 w (vk, vk+1) + w (vn, v1)

Example 9.5.6 A small example. The closest neighbor circuit starting
at 1 in Figure 9.5.7 is (1, 3, 2, 4, 1), with a cost of 29. The optimal path is
(1, 2, 3, 4, 1), with a cost of 27.
CHAPTER 9. GRAPH THEORY                                                                    222

Figure 9.5.7 A small example

                                                                                                
Although the closest neighbor circuit is often not optimal, we may be sat-

isfied if it is close to optimal. If Copt and Ccn are the costs of optimal and

closest neighbor circuits in a graph, then it is always the case that Copt  Ccn

or Ccn Copt  1. We can assess how good the closest neighbor algorithm is by

determining  how   small  the  quantity  Ccn   gets.  If  it  is  always  near   1,  then  the
                                         Copt
algorithm is good. However, if there are graphs for which it is large, then the

algorithm may be discarded.    Note that in Example 9.5.6,        Ccn     =  29      1.074.  A
                                                                  Copt       27

7 percent increase in cost may or may not be considered significant, depending

on the situation.

Example 9.5.8 The One-way Street. A salesman must make stops at
vertices A, B, and C, which are all on the same one-way street. The graph in
Figure 9.5.9 is weighted by the function w(i, j) equal to the time it takes to
drive from vertex i to vertex j.
CHAPTER 9. GRAPH THEORY                                                                           223

Figure 9.5.9 Traveling a one-way street

Note that if j is down the one-way street from i, then w(i, j) < w(j, i). The

values of Copt, and Ccn are 20 and 32, respectively. Verify that Ccn is 32 by

using  the  closest  neighbor      algorithm.  The  value     of     Ccn   =    1.6  is  significant  in
                                                                     Copt
this case since our salesman would spend 60 percent more time on the road if

he used the closest neighbor algorithm.                                                               

A more general result relating to the closest neighbor algorithm presumes

that the graph in question is complete and that the weight function satisfies

the conditions

· w(x, y) = w(y, x) for all x, y in the vertex set, and

· w(x, y) + w(y, z)  w(x, z) for all x, y, z in the vertex set.

    The first condition is called the symmetry condition and the second is the
triangle inequality.

Theorem 9.5.10 If (V, E, w) is a complete weighted graph on n vertices that
satisfies the symmetry and triangle inequality conditions, then

                                   Ccn  log2(2n)
                                   Copt             2

Observation 9.5.11 If |V | = 8, then this theorem says that Ccn can be no

larger than twice the size of Copt; however, it doesn't say that the closest neigh-

bor circuit will necessarily be that far from an optimal circuit. The quantity

log2 (2n)   is  called  an  upper  bound  for  the  ratio  Ccn    .  It  tells  us   only  that  things
       2                                                   C
                                                           opt
can't be any worse than the upper bound. Certainly, there are many graphs

with eight vertices such that the optimal and closest neighbor circuits are the

same. What is left unstated in this theorem is whether there are graphs for

which the quantities are equal. If there are such graphs, we say that the upper

bound is sharp.

The    value    of   Ccn    in  Example   Example      9.5.8  is     1.6,  which     is  greater  than
                     Copt

2 log2(2·4) = 1.5; however, the weight function in this example does not satisfy
the conditions of the theorem.

Example 9.5.12 The Unit Square Problem. Suppose a robot is pro-
grammed to weld joints on square metal plates. Each plate must be welded
at prescribed points on the square. To minimize the time it takes to complete
the job, the total distance that a robot's arm moves should be minimized. Let
d(P, Q) be the distance between P and Q. Assume that before each plate can
CHAPTER 9. GRAPH THEORY                                      224

be welded, the arm must be positioned at a certain point P0 . Given a list of
n points, we want to put them in order so that

d (P0, P1) + d (P1, P2) + · · · + d (Pn-1, Pn) + d (Pn, P0)

is as small as possible.                                     

The type of problem that is outlined in the example above is of such im-

portance that it is one of the most studied version of the Traveling Sales-

man Problem. What follows is the usual statement of the problem. Let

[0, 1] = {x  R | 0  x  1}, and let S = [0, 1]2, the unit square. Given
n pairs of real numbers (x1, y1) , (x2, y2) , . . . , (xn, yn) in S that represent the

n vertices of a Kn, find a circuit of the graph that minimizes the sum of the

distances traveled in traversing the circuit.

Since the problem calls for a circuit, it doesn't matter which vertex we start

at; assume that we will start at (x1, y1). Once the problem is solved, we can

always change our starting position. A function can most efficiently describe a

circuit in this problem. Every bijection f : {1, ..., n}  {1, ..., n} with f (1) = 1

describes a circuit

                         (x1, y1) , xf(2), yf(2) , . . . , xf(n), yf(n)

There are (n - 1)! such bijections. Since a circuit and its reversal have the
same associated cost, there are 2 (n-1)! cases to consider. An examination of all
possible cases is not feasible for large values of n.

    One popular heuristic algorithm is the strip algorithm:
Heuristic 9.5.13 The Strip Algorithm. Given n points in the unit square:

    Phase 1:

  (1) Divide the square into n/2 vertical strips, as in Figure 9.5.14. Let
       d be the width of each strip. If a point lies on a boundary between two
       strips, consider it part of the left-hand strip.

  (2) Starting from the left, find the first strip that contains one of the points.
       Locate the starting point by selecting the first point that is encountered in
       that strip as you travel from bottom to top. We will assume that the first
       point is (x1, y1)

  (3) Alternate traveling up and down the strips that contain vertices until all
       of the vertices have been reached.

  (4) Return to the starting point.

    Phase 2:

  (1) Shift all strips d/2 units to the right (creating a small strip on the left).

  (2) Repeat Steps 1.2 through 1.4 of Phase 1 with the new strips.

    When the two phases are complete, choose the shorter of the two circuits
obtained.
CHAPTER 9. GRAPH THEORY                         225

Figure 9.5.14 The Strip Algorithm

    Step Item 3 may need a bit more explanation. How do you travel up or
down a strip? In most cases, the vertices in a strip will be vertically distributed
so that the order in which they are visited is obvious. In some cases, however,
the order might not be clear, as in the third strip in Phase I of Figure 9.5.14.
Within a strip, the order in which you visit the points (if you are going up the
strip) is determined thusly: (xi, yi) precedes (xj, yj) if yi < yj or if yi = yj
and xi < xj . In traveling down a strip, replace yi < yj with yi > yj.

    The selection of n/2 strips was made in [4]. It balances the problems

that arise if the number of strips is too small or too large. If the square is
divided into too few strips, some strips may be packed with vertices so that
visiting them would require excessive horizontal motion. If too many strips are
used, excessive vertical motion tends to be the result. An update on what is
known about this algorithm is contained in [40].

    Since the construction of a circuit in the square consists of sorting the given
points, it should come as no surprise that the strip algorithm requires a time
that is roughly a multiple of n log n time units when n points are to be visited.

    The worst case that has been encountered with this algorithm is one in
which the circuit obtained has a total distance of approximately 2n (see
Sopowit et al.).

9.5.3 Networks and the Maximum Flow Problem

Definition 9.5.15 Network. A network is a simple weighted directed graph

that contains two distinguished vertices called the source and the sink with the

properties that the indegree of the source and outdegree of the sink are both

zero, and source is connected to sink. The weight function on a network is the

capacity function, which has positive weights.  

An example of a real situation that can be represented by a network is

a city's water system. A reservoir would be the source, while a distribution

point in the city to all of the users would be the sink. The system of pumps

and pipes that carries the water from source to sink makes up the remaining

network. We can assume that the water that passes through a pipe in one

minute is controlled by a pump and the maximum rate is determined by the

size of the pipe and the strength of the pump. This maximum rate of flow

through a pipe is called its capacity and is the information that the weight

function of a network contains.
CHAPTER 9. GRAPH THEORY                                226

Example 9.5.16 A City Water System. Consider the system that is
illustrated in Figure 9.5.17. The numbers that appear next to each pipe indicate
the capacity of that pipe in thousands of gallons per minute. This map can be
drawn in the form of a network, as in Figure 9.5.18.

Figure 9.5.17 City Water System

Figure 9.5.18 Flow Diagram for a City's Water Network

Although the material passing through this network is water, networks can

also represent the flow of other materials, such as automobiles, electricity, bits,

telephone calls, or patients in a health system.       

Problem 9.5.19 The Maximum Flow Problem. The Maximum Flow
Problem is derived from the objective of moving the maximum amount of
water or other material from the source to the sink. To measure this amount, we
define a flow as a function f : E  R such that (1) the flow of material through
any edge is nonnegative and no larger than its capacity: 0  f (e)  w(e), for
all e  E; and (2) for each vertex other than the source and sink, the total
amount of material that is directed into a vertex is equal to the total amount
that is directed out:

(x,v)E f (x, v) =                (v,y)E f (v, y)       (9.5.1)
Flow into v =                    Flow out of v

The summation on the left of (9.5.1) represents the sum of the flows through
CHAPTER 9. GRAPH THEORY                                                   227

each edge in E that has v as a terminal vertex. The right-hand side indicates

that you should add all of the flows through edges that initiate at v.    

Theorem 9.5.20 Flow out of Source equals Flow in Sink. If f is a

flow, then  (source,v)E f (source, v) = (v,sink)E f (v, sink)

Proof. Subtract the right-hand side of (9.5.1) from the left-hand side. The
result is:

                             Flow into v - Flow out of v = 0

Now sum up these differences for each vertex in V  = V - {source, sink}. The

result is

                                                       

                         f (x, v) -                  f (v, y) = 0       (9.5.2)

            vV  (x,v)E                  (v,y)E

Now observe that if an edge connects two vertices in V , its flow appears as both
a positive and a negative term in (9.5.2). This means that the only positive
terms that are not cancelled out are the flows into the sink. In addition, the
only negative terms that remain are the flows out of the source. Therefore,

                         f (v, sink) -               f (source, v) = 0

            (v,sink)E                   (source,v)E

                                                                          

Definition 9.5.21 The Value of a Flow. The two values flow into the

sink and flow out of the source were proved to be equal in Theorem 9.5.20

and this common value is called the value of the flow. It is denoted by V (f ).

The value of a flow represents the amount of material that passes through the

network with that flow.                                                   

Since the Maximum Flow Problem consists of maximizing the amount of

material that passes through a given network, it is equivalent to finding a flow

with the largest possible value. Any such flow is called a maximal flow.

For the network in Figure 9.5.18, one flow is f1, defined by f1 (e1) = 25,

f1 (e2) = 20, f1 (e3) = 0, f1 (e4) = 25, and f1 (e5) = 20. The value of f1,

V (f1), is 45. Since the total flow into the sink can be no larger than 50

(w (e4) + w (e5) = 30 + 20), we can tell that f1 is not very far from the solution.

Can you improve on f1 at all? The sum of the capacities into the sink can't

always be obtained by a flow. The same is true for the sum of the capacities

out of the source. In this case, the sum of the capacities out of the source is

60, which obviously can't be reached in this network.

A solution of the Maximum Flow Problem for this network is the maximal

flow f2, where f2 (e1) = 25, f2 (e2) = 25, f2 (e3) = 5, f2 (e4) = 30, and

f2 (e5) = 20, with V (f2) = 50. This solution is not unique. In fact, there is

an infinite number of maximal flows for this problem.

There have been several algorithms developed to solve the Maximal Flow

Problem. One of these is the Ford and Fulkerson Algorithm (FFA). The FFA

consists of repeatedly finding paths in a network called flow augmenting paths

until no improvement can be made in the flow that has been obtained.

Definition 9.5.22 Flow Augmenting Path. Given a flow f in a network

(V, E), a flow augmenting path with respect to f is a simple path from the

source to the sink using edges both in their forward and their reverse directions

such that for each edge e in the path, w(e) - f (e) > 0 if e is used in its forward

direction and f (e) > 0 if e is used in the reverse direction.            
CHAPTER 9. GRAPH THEORY                                           228

Example 9.5.23 Augmenting City Water Flow. For f1 in Figure 9.5.18,

a flow augmenting path would be(e2, e3, e4) since w (e2)-f1 (e2) = 15, w (e3)-

f1 (e3) = 5, and w (e4) - f1 (e4) = 5.

These positive differences represent unused capacities, and the smallest

value represents the amount of flow that can be added to each edge in the

path. Note that by adding 5 to each edge in our path, we obtain f2, which is

maximal. If an edge with a positive flow is used in its reverse direction, it is

contributing a movement of material that is counterproductive to the objective

of maximizing flow. This is why the algorithm directs us to decrease the flow

through that edge.                                                          

Algorithm 9.5.24 The Ford and Fulkerson Algorithm.

(1) Define the flow function f0 by f0(e) = 0 for each edge e  E.

(2) i = 0.

(3) Repeat:

(a) If possible, find a flow augmenting path with respect to fi.
(b) If a flow augmenting path exists, then:

      (i) Determine

             d = min{{w(e) - fi(e) | e is used in the forward direction},
                       {fi(e) | e is used in the reverse direction}}

(ii) Define fi+1 by

               fi+1(e) = fi(e)          if e is not part of the flow augmenting path
             fi+1(e) = fi(e) + d             if e is used in the forward direction
             fi+1(e) = fi(e) - d             if e is used in the reverse direction

(iii) i = i + 1

     until no flow augmenting path exists.
(4) Terminate with a maximal flow fi

List 9.5.25 Notes on the Ford and Fulkerson Algorithm

(1) It should be clear that every flow augmenting path leads to a flow
     of increased value and that none of the capacities of the network
     can be violated.

(2) The depth-first search should be used to find flow augmenting
     paths since it is far more efficient than the breadth-first search in
     this situation. The depth-first search differs from the breadth-first
     algorithm in that you sequentially visit vertices until you reach a
    "dead end" and then backtrack.

(3) There have been networks discovered for which the FFA does not
     terminate in a finite number of steps. These examples all have
     irrational capacities. It has been proven that if all capacities are
     positive integers, the FFA terminates in a finite number of steps.
     See Ford and Fulkerson, Even, or Berge for details.
CHAPTER 9. GRAPH THEORY                                                229

(4) When you use the FFA to solve the Maximum Flow Problem by
     hand it is convenient to label each edge of the network with the
     fraction w(e) fi(e) .

Algorithm 9.5.26 Depth-First Search for a Flow Augmenting Path.
This is a depth-first search for the Sink Initiating at the Source. Let E be the
set of directed edges that can be used in producing a flow augmenting path. Add
to the network a vertex called start and the edge (start, source).

(1) S =vertex set of the network.

(2) p =source      Move p along the edge (start, source)

(3) while p is not equal to start or sink:

(a) if an edge in E exists that takes you from p to another vertex in S:

then set p to be that next vertex and delete the edge from E

else reassign p to be the vertex that p was reached from (i.e., backtrack).

(4) if p = start:

                   then no flow augmenting path exists.

else p = sink and you have found a flow augmenting path.

Example 9.5.27 A flow augmenting path going against the flow. Con-
sider the network in Figure 9.5.28, where the current flow, f , is indicated by a
labeling of the edges.

Figure 9.5.28 Current Flow

    The path (Source, v2, v1, v3, Sink) is a flow augmenting path that allows
us to increase the flow by one unit. Note that (v1, v3) is used in the reverse
direction, which is allowed because f (v1, v3) > 0. The value of the new flow
that we obtain is 8. This flow must be maximal since the capacities out of the
source add up to 8. This maximal flow is defined by Figure 9.5.29.
CHAPTER 9. GRAPH THEORY  230

Figure 9.5.29 Updated Flow

                                                                                                     

9.5.4 Other Graph Optimization Problems

  (1) The Minimum Spanning Tree Problem: Given a weighted graph, (V, E, w),
       find a subset E of E with the properties that (V, E) is connected and
       the sum of the weights of edges in E is as small as possible. We will
       discuss this problem in Chapter 10.

  (2) The Minimum Matching Problem: Given an undirected weighted graph,
       (K, E, w), with an even number of vertices, pair up the vertices so that
       each pair is connected by an edge and the sum of these edges is as small
       as possible. A unit square version of this problem has been studied
       extensively. See [40] for details on what is known about this version of
       the problem.

  (3) The Graph Center Problem: Given a connected, undirected, weighted
       graph, find a vertex (called a center) in the graph with the property
       that the distance from the center to every other vertex is as small as
       possible. "As small as possible" is normally interpreted as minimizing
       the maximum distance from the center to a vertex.

9.5.5 Exercises

1. Find the closest neighbor circuit through the six capitals of New England
      starting at Boston. If you start at a different city, will you get a different
      circuit?

2. Is the estimate in Theorem 9.5.10 sharp for n = 3? For n = 4?
3. Given the following sets of points in the unit square, find the shortest

      circuit that visits all the points and find the circuit that is obtained with
      the strip algorithm.

        (a) {(0.1k, 0.1k) : k = 0, 1, 2, ..., 10}

        (b) {(0.1, 0.3), (0.3, 0.8), (0.5, 0.3), (0.7, 0.9), (0.9, 0.1)}

         (c) {(0.0, 0.5), (0.5, 0.0), (0.5, 1.0), (1.0, 0.5)}

        (d) {(0, 0), (0.2, 0.6), (0.4, 0.1), (0.6, 0.8), (0.7, 0.5)}
CHAPTER 9. GRAPH THEORY  231

4. For n = 4, 5, and 6, locate n points in the unit square for which the strip
      algorithm works poorly.

5. Consider the network whose maximum capacities are shown on the fol-
      lowing graph.

      Figure 9.5.30
        (a) A function f is partially defined on the edges of this network by:
              f (Source, c) = 2, f (Source, b) = 2, f (Source, a) = 2, and f (a, d) = 1.
              Define f on the rest of the other edges so that f is a flow. What is
              the value of f ?
        (b) Find a flow augmenting path with respect to f for this network.
              What is the value of the augmented flow?
         (c) Is the augmented flow a maximum flow? Explain.

6. Given the following network with capacity function c and flow function
      f , find a maximal flow function. The labels on the edges of the network
      are of the form f (e)/c(e), where c(e) is the capacity of edge e and f (e) is
      the used capacity for flow f .

      Figure 9.5.31
7. Find maximal flows for the following networks.
CHAPTER 9. GRAPH THEORY                 232

                         Figure 9.5.33

Figure 9.5.32

      Figure 9.5.34
8. Suppose that the network in Figure 9.5.28 is updated so that the capacity

      of (v1, Sink) increased by 1 to 5.

        (a) Find two maximal flows for the updated network

        (b) Describe the set of all maximal flows for the same network.

         (c) Prove that if a network has two maximal flows, then it has an infinite
              number of maximal flows.

9. Discuss reasons that the closest neighbor algorithm is not used in the
      unit square version of the Traveling Salesman Problem.
      Hint. Count the number of comparisons of distances that must be done.

10. Explore the possibility of solving the Traveling Salesman Problem in the
      "unit box": [0, 1]3.

11. Devise a "closest neighbor" algorithm for matching points in the unit
      square.

9.6 Planarity and Colorings

The topics in this section are related to how graphs are drawn.
    Planarity: Can a given graph be drawn in a plane so that no edges intersect?

Certainly, it is natural to avoid intersections, but up to now we haven't gone
out of our way to do so.

    Colorings: Suppose that each vertex in an undirected graph is to be colored
so that no two vertices that are connected by an edge have the same color.
How many colors are needed? This question is motivated by the problem of
drawing a map so that no two bordering countries are colored the same. A
similar question can be asked for coloring edges.
CHAPTER 9. GRAPH THEORY             233

9.6.1 Planar Graphs

Definition 9.6.1 Planar Graph/Plane Graph. A graph is planar if it

can be drawn in a plane so that no edges cross. A drawing of a graph on the

plane such that there are no edge crossings is called a planar embedding of the

graph, or a plane graph for short.  

Example 9.6.2 A Planar Graph. The graph in Figure 9.6.3(a) is planar
but the drawing of it is not a plane graph. The drawing of the same graph in
Figure 9.6.3(b) is a planar graph.

Figure 9.6.3 A planar graph and a planar embedding that graph.
                                                                                                    

(a) In discussing planarity, we need only consider simple undirected graphs
     with no self-loops. All other graphs can be treated as such since all of
     the edges that relate any two vertices can be considered as one "bundle"
     that clearly can be drawn in a plane.

(b) Can you think of a graph that is not planar? How would you prove that
     it isn't planar? Proving the nonexistence of something is usually more
     difficult than proving its existence. This case is no exception. Intuitively,
     we would expect that sparse graphs would be planar and dense graphs
     would be nonplanar. Theorem 9.6.10 will verify that dense graphs are
     indeed nonplanar.

(c) The topic of planarity is a result of trying to restrict a graph to two
     dimensions. Is there an analogous topic for three dimensions? What
     graphs can be drawn in one dimension?

Definition 9.6.4 Path Graph. A path graph of length n, denoted Pn, is

an undirected graph with n + 1 vertices v0, v1, . . . , vn having n edges {vi, vi+1},

i = 0, 1, . . . , n - 1.            

Observation 9.6.5 Graphs in other dimensions. If a graph has only
a finite number of vertices, it can always be drawn in three dimensions with
no edge crossings. Is this also true for all graphs with an infinite number of
vertices? The only "one-dimensional" graphs are graphs consisting of a single
vertex, and path graphs, as shown in Figure 9.6.6.
CHAPTER 9. GRAPH THEORY  234

Figure 9.6.6 One dimensional graphs

A discussion of planarity is not complete without mentioning the famous Three
Utilities Puzzle. The object of the puzzle is to supply three houses, A, B, and
C, with the three utilities, gas, electric, and water. The constraint that makes
this puzzle impossible to solve is that no utility lines may intersect. There is
no planar embedding of the graph in Figure 9.6.7, which is commonly denoted
K3,3. This graph is one of two fundamental nonplanar graphs. The Kuratowski
Reduction Theorem states that if a graph is nonplanar then it "contains" either
a K3,3 or a K5. Containment is in the sense that if you start with a nonplanar
graph you can always perform a sequence of edge deletions and contractions
(shrinking an edge so that the two vertices connecting it coincide) to produce
one of the two graphs.

Figure 9.6.7 The Three Utilities Puzzle

    A planar graph divides the plane into one or more regions. Two points on
the plane lie in the same region if you can draw a curve connecting the two
points that does not pass through an edge. One of these regions will be of
infinite area. Each point on the plane is either a vertex, a point on an edge, or
a point in a region. A remarkable fact about the geography of planar graphs
is the following theorem that is attributed to Euler.

Activity 9.1

 (a) Experiment: Jot down a graph right now and count the number of ver-
       tices, regions, and edges that you have. If v + r - e is not 2, then your
       graph is either nonplanar or not connected.

Theorem 9.6.8 Euler's Formula. If G = (V, E) is a connected planar
graph with r regions, v vertices, and e edges, then

v+r-e=2                  (9.6.1)

Proof. We prove Euler's Formula by Induction on e, for e  0.
Basis: If e = 0, then G must be a graph with one vertex, v = 1; and there is
CHAPTER 9. GRAPH THEORY                         235

one infinite region, r = 1. Therefore, v + r - e = 1 + 1 - 0 = 2, and the basis
is true.

Induction: Suppose that G has k edges, k  1, and that all connected planar
graphs with less than k edges satisfy (9.6.1). Select any edge that is part of
the boundary of the infinite region and call it e1. Let G be the graph obtained
from G by deleting e1. Figure 9.6.9 illustrates the two different possibilities we
need to consider: either G is connected or it has two connected components,

G1 and G2.

Figure 9.6.9 Two cases in the proof of Euler's Formula

If G is connected, the induction hypothesis can be applied to it. If G has
v vertices, r regions and e edges, then v + r - e = 2 and in terms of the
corresponding numbers for G,

v = v      No vertices were removed to form G
r = r - 1  One region of G was merged with the infinite region when e1 was removed
e = k - 1  We assumed that G had k edges.

For the case where G is connected,

           v+r-e=v+r-k
                       = v + (r + 1) - (e + 1)
                       = v + r - e

                       =2

If G is not connected, it must consist of two connected components, G1 and

G2, since we started with a connected graph, G. We can apply the induction

hypothesis to each of the two components to complete the proof. We leave it

to the students to do this, with the reminder that in counting regions, G1 and

G2 will share the same infinite region.         

Theorem 9.6.10 A Bound on Edges of a Planar Graph. If G = (V, E)
is a connected planar graph with v vertices, v  3, and e edges, then

                             e  3v - 6          (9.6.2)

Proof. (Outline of a Proof)

(a) Let r be the number of regions in G. For each region, count the number
     of edges that comprise its border. The sum of these counts must be at
     least 3r. Recall that we are working with simple graphs here, so a region
     made by two edges connecting the same two vertices is not possible.

(b) Based on (a), infer that the number of edges in G must be at least 23r .
CHAPTER 9. GRAPH THEORY                                                        236

(c) e  3r  r  2e
     2               3

(d)  Substitute  2e  for  r  in  Euler's  Formula  to  obtain  an  inequality  that  is
                 3
     equivalent to (9.6.2)

                                                                                                    
Remark 9.6.11 One implication of (9.6.2) is that the number of edges in a
connected planar graph will never be larger than three times its number of
vertices (as long as it has at least three vertices). Since the maximum number
of edges in a graph with v vertices is a quadratic function of v, as v increases,
planar graphs are more and more sparse.

    The following theorem will be useful as we turn to graph coloring.

Theorem 9.6.12 A Vertex of Degree Five. If G is a connected planar

graph, then it has a vertex with degree 5 or less.

Proof. (by contradiction): We can assume that G has at least seven vertices,

for otherwise the degree of any vertex is at most 5. Suppose that G is a

connected planar graph and each vertex has a degree of 6 or more. Then, since

each edge contributes to the degree of two vertices, e         6v  = 3v.  However,
                                                               2
Theorem 9.6.10 states that the e  3v - 6 < 3v, which is a contradiction. 

9.6.2 Graph Coloring

Figure 9.6.13 A 3-coloring of Euler Island

    The map of Euler Island in Figure 9.6.13 shows that there are seven towns
on the island. Suppose that a cartographer must produce a colored map in
which no two towns that share a boundary have the same color. To keep costs
down, she wants to minimize the number of different colors that appear on the
map. How many colors are sufficient? For Euler Island, the answer is three.
Although it might not be obvious, this is a graph problem. We can represent
the map with a graph, where the vertices are countries and an edge between
two vertices indicates that the two corresponding countries share a boundary
of positive length. The graph corresponding to the map of Euler Island is
Figure 9.6.14.
CHAPTER 9. GRAPH THEORY                                               237

Figure 9.6.14 The graph of Euler Island

The problem of coloring Euler Island motivates a more general problem.

Definition 9.6.15 Graph Coloring. Given an undirected graph G = (V, E),

find a "coloring function" f from V into a set of colors H such that (vi, vj) 

E  f (vi) = f (vj) and H has the smallest possible cardinality. The cardinal-

ity of H is called the chromatic number of G, (G).                      

· A coloring function onto an n-element set is called an n-coloring.

· In terms of this general problem, the chromatic number of the graph of
   Euler Island is three. To see that no more than three colors are needed,
   we need only display a 3-coloring: f (1) = f (4) = f (6) = blue, f (2) = red,
   and f (3) = f (5) = f (7) = white. This coloring is not unique. The next
   smallest set of colors would be of two colors, and you should be able to
   convince yourself that no 2-coloring exists for this graph.

    In the mid-nineteenth century, it became clear that the typical planar graph
had a chromatic number of no more than 4. At that point, mathematicians
attacked the Four-Color Conjecture, which is that if G is any planar graph,
then its chromatic number is no more than 4. Although the conjecture is quite
easy to state, it took over 100 years, until 1976, to prove the conjecture in the
affirmative.

Theorem 9.6.16 The Four-Color Theorem. If G is a planar graph, then
(G)  4.

    A proof of the Four-Color Theorem is beyond the scope of this text, but
we can prove a theorem that is only 25 percent inferior.

Theorem 9.6.17 The Five-Color Theorem. If G is a planar graph, then
(G)  5.
Proof. The number 5 is not a sharp upper bound for (G) because of the
Four-Color Theorem.
This is a proof by Induction on the Number of Vertices in the Graph.
Basis: Clearly, a graph with one vertex has a chromatic number of 1.
Induction: Assume that all planar graphs with n - 1 vertices have a chromatic
number of 5 or less. Let G be a planar graph. By Theorem 9.6.12, there
exists a vertex v with deg v  5. Let G - v be the planar graph obtained by
deleting v and all edges that connect v to other vertices in G. By the induction
hypothesis, G - v has a 5-coloring. Assume that the colors used are red, white,
blue, green, and yellow.
If deg v < 5, then we can produce a 5-coloring of G by selecting a color that is
CHAPTER 9. GRAPH THEORY                         238

not used in coloring the vertices that are connected to v with an edge in G.
If deg v = 5, then we can use the same approach if the five vertices that are
adjacent to v are not all colored differently. We are now left with the possibility
that v1, v2, v3, v4, and v5 are all connected to v by an edge and they are all
colored differently. Assume that they are colored red, white blue, yellow, and
green, respectively, as in Figure 9.6.18.

Figure 9.6.18

Starting at v1 in G - v, suppose we try to construct a path v3 that passes

through only red and blue vertices. This can either be accomplished or it can't

be accomplished. If it can't be done, consider all paths that start at v1, and

go through only red and blue vertices. If we exchange the colors of the vertices

in these paths, including v1 we still have a 5-coloring of G - v. Since v1 is now

blue, we can color the central vertex, v, red.

Finally, suppose that v1 is connected to v3 using only red and blue vertices.

Then a path from v1 to v3 by using red and blue vertices followed by the edges

(v3, v) and (v, v1) completes a circuit that either encloses v2 or encloses v4 and

v5. Therefore, no path from v2 to v4 exists using only white and yellow vertices.

We can then repeat the same process as in the previous paragraph with v2 and

v4, which will allow us to color v4 white.      

Definition 9.6.19 Bipartite Graph. A bipartite graph is a graph that has

a 2-coloring. Equivalently, a graph is bipartite if its vertices can be partitioned

into two nonempty subsets so that no edge connects vertices from the same

subset.                                         

Example 9.6.20 A Few Examples.

(a) The graph of the Three Utilities Puzzle is bipartite. The vertices are
     partitioned into the utilities and the homes. A 2-coloring of the graph is
     to color the utilities red and the homes blue.

(b) For n  1, the n-cube is bipartite. A coloring would be to color all strings
     with an even number of 1's red and the strings with an odd number of
     1's blue. By the definition of the n-cube, two strings that have the same
     color couldn't be connected since they would need to differ in at least
     two positions.

(c) Let V be a set of 64 vertices, one for each square on a chess board.
CHAPTER 9. GRAPH THEORY   239

       We can index the elements of V by vij = the square on the row i,
       column j. Connect vertices in V according to whether or not you can
       move a knight from one square to another. Using our indexing of V ,

       (vij, vkl)  E if and only if |i - k| + |j - l| = 3 and |i - k| · |j - l| = 2 (V, E) is a bipartite
       graph. The usual coloring of a chessboard is valid 2-coloring.

                                                                                                    
    How can you recognize whether a graph is bipartite? There is a nice equiv-
alent condition for a graph to be bipartite.

Theorem 9.6.21 No Odd Circuits in a Bipartite Graph. An undirected
graph is bipartite if and only if it has no circuit of odd length.

Proof. () Let G = (V, E) be a bipartite graph that is partitioned into two
sets, R(ed) and B(lue) that define a 2-coloring. Consider any circuit in V . If
we specify a direction in the circuit and define f on the vertices of the circuit
by

                      f (v) = the next vertex in the circuit after v

Note that f is a bijection. Hence the number of red vertices in the circuit

equals the number of blue vertices, and so the length of the circuit must be

even.

(=) Assume that G has no circuit of odd length. For each component of

G, select any vertex w and color it red. Then for every other vertex v in the

component, find the path of shortest distance from w to v. If the length of

the path is odd, color v blue, and if it is even, color v red. We claim that this

method defines a 2-coloring of G. Suppose that it does not define a 2-coloring.

Then let va and vb be two vertices with identical colors that are connected

with an edge. By the way that we colored G, neither va nor vb could equal w.

We can now construct a circuit with an odd length in G. First, we start at w

and follow the shortest path to va . Then follow the edge (va, vb), and finally,

follow the reverse of a shortest path from w to vb. Since va and vb have the

same color, the first and third segments of this circuit have lengths that are

both odd or even, and the sum of their lengths must be even. The addition

of the single edge (va, vb) shows us that this circuit has an odd length. This

contradicts our premise.  

9.6.3 Exercises

1. Use Euler's formula to prove by contradiction that a K5 is nonplanar.
      This shows that a K4 is the largest complete graph that is planar.

2. Use Euler's formula to prove by contradiction that a K3,3 is nonplanar.
      Hint. Don't forget Theorem 9.6.21!

3. What are the chromatic numbers of the following graphs?
CHAPTER 9. GRAPH THEORY  240

      Figure 9.6.22 What are the chromatic numbers?

4. A connected planar graph has 2001 vertices and divides the plane into
      1024 regions. How many edges does it have?

5. What is  (Kn), n  1?

6. Suppose that all of the vertices of connected planar graph have degree
      3 and that there are 20 vertices. How many edges and regions does this
      graph have?

7. Complete the proof of Euler's Formula.

8. A graph is said to be a perfect graph if its chromatic number is n and it
      contains a Kn as a subgraph. For example, a cycle graph of length 5 is
      not perfect because its chromatic number is three but it has no K3 as a
      subgraph. Find a graph with chromatic number four that is not perfect.

9. Let G = (V, E) with |V |  11, and let U be the set of all undirected
      edges between distinct vertices in V . Prove that either G or G = (V, Ec)
      is nonplanar.

10. Design an algorithm to determine whether a graph is bipartite.

11. Prove that a bipartite graph with an odd number of vertices greater than
      or equal to 3 has no Hamiltonian circuit.

12. Prove that any graph with a finite number of vertices can be drawn in
      three dimensions so that no edges intersect.

13. Suppose you had to color the edges of an undirected graph so that for
      each vertex, the edges that it is connected to have different colors. How
      can this problem be transformed into a vertex coloring problem?
CHAPTER 9. GRAPH THEORY  241

14.

        (a) Suppose the edges of a K6 are colored either red or blue. Prove that
              there will be either a "red K3" (a subset of the vertex set with three
              vertices connected by red edges) or a "blue K3" or both.

        (b) Suppose six people are selected at random. Prove that either there
              exists a subset of three of them with the property that any two
              people in the subset can communicate in a common language, or
              there exist three people, no two of whom can communicate in a
              common language.

15. Let d be a positive integer, and let a1, a2, . . . ad be positive integers greater
      than or equal to two. The mesh graph M (a1, a2, . . . , ad) has vertices of
      the form x = (x1, x2, . . . , xd) where 1  xi  ai. Two vertices x and y are
      adjacent if and only if i=1 d |xi - yi| = 1. In other words, two adjacent
      vertices must differ in only one coordinate and by a difference of 1.

        (a) What is the chromatic number of M (a1, a2, . . . , ad)?

        (b) For what pairs (a1, a2) does M (a1, a2) have a Hamiltonian circuit?

         (c) For what triples (a1, a2, a3) does M (a1, a2, a3) have a Hamiltonian
              circuit?

9.6.4 Further Reading

[1] Wilson, R., Four Colors Suffice - How the Map Problem Was SolvedPrinceton,
       NJ: Princeton U. Press, 2013.
Chapter 10

Trees

In this chapter we will study the class of graphs called trees. Trees are fre-
quently used in both mathematics and the sciences. Our solution of Exam-
ple 2.1.1 is one simple instance. Since they are often used to illustrate or prove
other concepts, a poor understanding of trees can be a serious handicap. For
this reason, our ultimate goals are to: (1) define the various common types of
trees, (2) identify some basic properties of trees, and (3) discuss some of the
common applications of trees.

10.1 What Is a Tree?

10.1.1 Definition

What distinguishes trees from other types of connected graphs is the absence
of certain paths called cycles. Recall that a path is a sequence of consecutive
edges in a graph, and a circuit is a path that begins and ends at the same
vertex.

Definition 10.1.1 Cycle. A cycle is a circuit whose edge list contains no

duplicates. It is customary to use Cn to denote a cycle with n edges.  

The simplest example of a cycle in an undirected graph is a pair of vertices

with two edges connecting them. Since trees are cycle-free, we can rule out all

multigraphs having at least one pair of vertices connected with two or more

edges from consideration as trees.

Trees can either be undirected or directed graphs. We will concentrate on

the undirected variety in this chapter.

Definition 10.1.2 Tree. An undirected graph is a tree if it is connected and

contains no cycles.                                                    

Example 10.1.3 Some trees and non-trees.

                                    242
CHAPTER 10. TREES                                                     243

Figure 10.1.4 Some trees and some non-trees

  (a) Graphs i, ii and iii in Figure 10.1.4 are all trees, while graphs iv, v, and
       vi are not trees.

  (b) A K2 is a tree. However, if n  3, a Kn is not a tree.

  (c) In a loose sense, a botanical tree is a mathematical tree. There are usually
       no cycles in the branch structure of a botanical tree.

  (d) The structures of some chemical compounds are modeled by a tree. For
       example, butane Figure 10.1.5 consists of four carbon atoms and ten
       hydrogen atoms, where an edge between two atoms represents a bond be-
       tween them. A bond is a force that keeps two atoms together. The same
       set of atoms can be linked together in a different tree structure to give
       us the compound isobutane Figure 10.1.6. There are some compounds
       whose graphs are not trees. One example is benzene Figure 10.1.7.

Figure 10.1.5 Butane

                      Figure 10.1.6 Isobutane Figure 10.1.7 Benzene

                                                                                                
One type of graph that is not a tree, but is closely related, is a forest.

Definition 10.1.8 Forest. A forest is an undirected graph whose components

are all trees.                                                        

Example 10.1.9 A forest. The top half of Figure 10.1.4 can be viewed as

a forest of three trees. Graph (vi) in this figure is also a forest.  
CHAPTER 10. TREES                           244

10.1.2 Conditions for a Graph to be a Tree

We will now examine several conditions that are equivalent to the one that
defines a tree. The following theorem will be used as a tool in proving that the
conditions are equivalent.

Lemma 10.1.10 Let G = (V, E) be an undirected graph with no self-loops, and

let va, vb  V . If two different simple paths exist between va and vb, then there
exists a cycle in G.

Proof. Let p1 = (e1, e2, . . . , em) and p2 = (f1, f2, . . . , fn) be two different

simple paths from va to vb. The first step we will take is to delete from p1 and

p2 the initial edges that are identical. That is, if e1 = f1, e2 = f2, . . ., ej = fj,

and ej+1 = fj+1 delete the first j edges of both paths. Once this is done, both

paths start at the same vertex, call it vc, and both still end at vb. Now we

construct a cycle by starting at vc and following what is left of p1 until we

first meet what is left of p2. If this first meeting occurs at vertex vd, then the

remainder of the cycle is completed by following the portion of the reverse of

p2 that starts at vd and ends at vc.        

Theorem 10.1.11 Equivalent Conditions for a Graph to be a Tree.
Let G = (V, E) be an undirected graph with no self-loops and |V | = n. The
following are all equivalent:

  (1) G is a tree.

  (2) For each pair of distinct vertices in V , there exists a unique simple path
       between them.

  (3) G is connected, and if e  E, then (V, E - {e}) is disconnected.

  (4) G contains no cycles, but by adding one edge, you create a cycle.

  (5) G is connected and |E| = n - 1.
Proof. Proof Strategy. Most of this theorem can be proven by proving the
following chain of implications: (1)  (2), (2)  (3), (3)  (4), and (4)  (1).
Once these implications have been demonstrated, the transitive closure of 
on 1, 2, 3, 4 establishes the equivalence of the first four conditions. The proof
that Statement 5 is equivalent to the first four can be done by induction, which
we will leave to the reader.
(1)  (2) (Indirect). Assume that G is a tree and that there exists a pair of
vertices between which there is either no path or there are at least two distinct
paths. Both of these possibilities contradict the premise that G is a tree. If no
path exists, G is disconnected, and if two paths exist, a cycle can be obtained
by Theorem 10.1.11.
(2)  (3). We now use Statement 2 as a premise. Since each pair of vertices
in V are connected by exactly one path, G is connected. Now if we select any
edge e in E, it connects two vertices, v1 and v2. By (2), there is no simple path
connecting v1 to v2 other than e. Therefore, no path at all can exist between
v1 and v2 in (V, E - {e}). Hence (V, E - {e}) is disconnected.
(3)  (4). Now we will assume that Statement 3 is true. We must show that
G has no cycles and that adding an edge to G creates a cycle. We will use
an indirect proof for this part. Since (4) is a conjunction, by DeMorgan's Law
its negation is a disjunction and we must consider two cases. First, suppose
that G has a cycle. Then the deletion of any edge in the cycle keeps the graph
connected, which contradicts (3). The second case is that the addition of an
edge to G does not create a cycle. Then there are two distinct paths between
the vertices that the new edge connects. By Lemma 10.1.10, a cycle can then
CHAPTER 10. TREES                              245

be created, which is a contradiction.

(4)  (1) Assume that G contains no cycles and that the addition of an edge

creates a cycle. All that we need to prove to verify that G is a tree is that G

is connected. If it is not connected, then select any two vertices that are not

connected. If we add an edge to connect them, the fact that a cycle is created

implies that a second path between the two vertices can be found which is in

the original graph, which is a contradiction.  

The usual definition of a directed tree is based on whether the associated

undirected graph, which is created by "erasing" its directional arrows, is a tree.

In Section 10.3 we will introduce the rooted tree, which is a special type of

directed tree.

10.1.3 Exercises

1. Given the following vertex sets, draw all possible undirected trees that
      connect them.

        (a) Va = {right, left}

        (b) Vb = {+, -, 0}

         (c) Vc = {north, south, east, west}.
2. Are all trees planar? If they are, can you explain why? If they are not,

      you should be able to find a nonplanar tree.
3. Prove that if G is a simple undirected graph with no self-loops, then G

      is a tree if and only if G is connected and |E| = |V | - 1.
      Hint. Use induction on |E|.
4. Suppose a forest consists of m trees and v vertices. What are the possible
      values of m and how many edges does the forest have?
5.

        (a) Prove that any tree with at least two vertices has at least two vertices
              of degree 1.

        (b) Prove that if a tree has n vertices, n  4, and is not a path graph,
              Pn, then it has at least three vertices of degree 1.

6. Prove that the center of any tree can have no more than two vertices.
7. Let (d1, d2, . . . , dj, dj+1, . . . , dn) be the degree sequence of a tree with

      dj  3 and dj+1 < 3. Prove that the number of edges in the tree is

                                       j

                   2 + (dk - 2).               ()

                                       k=1

10.2 Spanning Trees

10.2.1 Motivation

The topic of spanning trees is motivated by a graph-optimization problem.
    A graph of Atlantis University (Figure 10.2.1) shows that there are four cam-

puses in the system. A new secure communications system is being installed
and the objective is to allow for communication between any two campuses;
to achieve this objective, the university must buy direct lines between certain
pairs of campuses. Let G be the graph with a vertex for each campus and
CHAPTER 10. TREES  246

an edge for each direct line. Total communication is equivalent to G being a
connected graph. This is due to the fact that two campuses can communicate
over any number of lines. To minimize costs, the university wants to buy a
minimum number of lines.

Figure 10.2.1 Atlantis University Graph

    The solutions to this problem are all trees. Any graph that satisfies the
requirements of the university must be connected, and if a cycle does exist, any
line in the cycle can be deleted, reducing the cost. Each of the sixteen trees
that can be drawn to connect the vertices North, South, East, and West (see
Exercise 10.1.3.1) solves the problem as it is stated. Note that in each case,
three direct lines must be purchased. There are two considerations that can
help reduce the number of solutions that would be considered.

   · Objective 1: Given that the cost of each line depends on certain factors,
       such as the distance between the campuses, select a tree whose cost is as
       low as possible.

   · Objective 2: Suppose that communication over multiple lines is noisier
       as the number of lines increases. Select a tree with the property that
       the maximum number of lines that any pair of campuses must use to
       communicate with is as small as possible.

    Typically, these objectives are not compatible; that is, you cannot always
simultaneously achieve these objectives. In the case of the Atlantis university
system, the solution with respect to Objective 1 is indicated with solid lines
in Figure 10.2.1. There are four solutions to the problem with respect to
Objective 2: any tree in which one campus is directly connected to the other
three. One solution with respect to Objective 2 is indicated with dotted lines
in Figure 10.2.1. After satisfying the conditions of Objective 2, it would seem
reasonable to select the cheapest of the four trees.
CHAPTER 10. TREES                                  247

10.2.2 Definition

Definition 10.2.2 Spanning Tree. Let G = (V, E) be a connected undi-

rected graph. A spanning tree for G is a spanning subgraph 9.1.17 of G that

is a tree.                                         

Note 10.2.3

(a) If (V, E) is a spanning tree, |E| = |V | - 1.

  (b) The significance of a spanning tree is that it is a minimal spanning set.
       A smaller set would not span the graph, while a larger set would have a
       cycle, which has an edge that is superfluous.

    For the remainder of this section, we will discuss two of the many topics that
relate to spanning trees. The first is the problem of finding Minimal Spanning
Trees, which addresses Objective 1 above. The second is the problem of finding
Minimum Diameter Spanning Trees, which addresses Objective 2.

Definition 10.2.4 Minimal Spanning Tree. Given a weighted connected

undirected graph G = (V, E, w), a minimal spanning tree is a spanning tree

(V, E) for which eE w(e) is as small as possible.  

10.2.3 Prim's Algorithm

Unlike many of the graph-optimization problems that we've examined, a solu-
tion to this problem can be obtained efficiently. It is a situation in which a
greedy algorithm works.

Definition 10.2.5 Bridge. Let G = (V, E) be an undirected graph and let

{L, R} be a partition of V . A bridge between L and R is an edge in E that

connects a vertex in L to a vertex in R.           

Theorem 10.2.6 Let G = (V, E, w) be a weighted connected undirected graph.

Let V be partitioned into two sets L and R. If e is a bridge of least weight

between L and R, then there exists a minimal spanning tree for G that includes

e.

Proof. Suppose that no minimal spanning tree including e exists. Let T =

(V, E) be a minimal spanning tree. If we add e to T , a cycle is created, and this

cycle must contain another bridge, e, between L and R. Since w (e)  w(e),

we can delete e and the new tree, which includes e must also be a minimal

spanning tree.                                     

Example 10.2.7 Some Bridges. The bridges between the vertex sets
{a, b, c} and {d, e} in Figure 10.2.8 are the edges {b, d} and {c, e}. According
to the theorem above, a minimal spanning tree that includes {b, d} exists. By
examination, you should be able to see that this is true. Is it true that only
the bridges of minimal weight can be part of a minimal spanning tree?
CHAPTER 10. TREES  248

Figure 10.2.8 Bridges between two sets
                                                                                                     

    Theorem 10.2.6 essentially tells us that a minimal spanning tree can be
constructed recursively by continually adding minimally weighted bridges to a
set of edges.

Algorithm 10.2.9 Prim's Algorithm. Let G = (V, E, w) be a connected,
weighted, undirected graph, and let v0 be an arbitrary vertex in V . The following
steps lead to a minimal spanning tree for G. L and R will be sets of vertices
and E is a set of edges.

  (1) (Initialize) L = V - {v0}; R = {v0}; E = .

  (2) (Build the tree) While L = :

        (1) Find e = {vL, vR}, a bridge of minimum weight between L and R.
        (2) R = R  {vL}; L = L - {vL} ; E = E  {e}

  (3) Terminate with a minimal spanning tree (V, E).

Note 10.2.10

  (a) If more than one minimal spanning tree exists, then the one that is ob-
       tained depends on v0 and the means by which e is selected in Step 2.

  (b) Warning: If two minimally weighted bridges exist between L and R, do
       not try to speed up the algorithm by adding both of them to E'.

  (c) That Algorithm 10.2.9 yields a minimal spanning tree can be proven by
       induction with the use of Theorem 10.2.6.

  (d) If it is not known whether G is connected, Algorithm 10.2.9 can be re-
       vised to handle this possibility. The key change (in Step 2.1) would be
       to determine whether any bridge at all exists between L and R. The
       condition of the while loop in Step 2 must also be changed somewhat.
CHAPTER 10. TREES                                                     249

Example 10.2.11 A Small Example. Consider the graph in Figure 10.2.12.
If we apply Prim's Algorithm starting at a, we obtain the following edge list
in the order given: {a, f }, {f, e}, {e, c}, {c, d}, {f, b}, {b, g}. The total of the
weights of these edges is 20.

Figure 10.2.12 A small weighted graph

    For small examples, the following table is a suggested way to demonstrate
an understanding of how Prim's algorithm plays out. The first line, step 0, is
the initialization of the two sets, L and R. In completing Step 3, there are two
bridges of minimal weight, {e, c} and {e, d}. We selected the former. If we had
selected the latter, the resulting spanning tree would be different, but would
have the same total weight.

Table 10.2.13 Prim's Algorithm Steps

Step  Added Bridge         L                   R                      Added Weight
      -                                                               -
0     {a, f }              {b, c, d, e, f, g}  {a}                    3
1     {e, f }              {b, c, d, e, g}     {a, f }                4
2     {e, c}               {b, c, d, g}        {a, e, f }             3
3     {c, d}               {b, d}              {a, c, e, f }          2
4     {f, b}               {b, g}              {a, c, d, e, f }       5
5     {b, g}               {g}                 {a, b, c, d, e, f }    3
6                          {}                  {a, b, c, d, e, f, g}  20
                                               Total weight

                                                                      

Definition 10.2.14 Minimum Diameter Spanning Tree. Given a con-

nected undirected graph G = (V, E), find a spanning tree T = (V, E) of G such

that the longest path in T is as short as possible. A solution to this problem

is relatively easy to obtain by combining the idea the center of a graph with

the breadth first search.                                             

Example 10.2.15 The Case for Complete Graphs. The Minimum Di-

ameter Spanning Tree Problem is trivial to solve in a Kn. Select any vertex v0
and construct the spanning tree whose edge set is the set of edges that connect

v0 to the other vertices in the Kn . Figure 10.2.16 illustrates a solution for
n = 5.
CHAPTER 10. TREES  250

Figure 10.2.16 Minimum diameter spanning tree for K5
                                                                                                     

    For incomplete graphs, a two-stage algorithm is needed. In short, the first
step is to locate a "center" of the graph. The maximum distance from a center
to any other vertex is as small as possible. Once a center is located, a breadth-
first search of the graph is used to construct the spanning tree.

10.2.4 Exercises

1. Suppose that after Atlantis University's phone system is in place, a fifth
      campus is established and that a transmission line can be bought to con-
      nect the new campus to any old campus. Is this larger system the most
      economical one possible with respect to Objective 1? Can you always
      satisfy Objective 2?

2. Construct a minimal spanning tree for the capital cities in New England
      (see Table 9.5.3).

3. Find a minimal spanning tree for the following graphs.

      Figure 10.2.17
CHAPTER 10. TREES  251

      Figure 10.2.18

      Figure 10.2.19
4. Find a minimal spanning tree for the following graph using Prim's al-

      gorithm starting at vertex 1. Your tree will not be unique. How many
      different minimal spanning trees are there?

Figure 10.2.20
CHAPTER 10. TREES  252

5. In each of the following parts justify your answer with either a proof or
      a counterexample.

        (a) Suppose a weighted undirected graph had distinct edge weights. Is it
              possible that no minimal spanning tree includes the edge of minimal
              weight?

        (b) Suppose a weighted undirected graph had distinct edge weights. Is
              it possible that every minimal spanning tree includes the edge of
              maximal weight? If true, under what conditions would it happen?

6. Show that the answer to the question posed in Example 10.2.7 is "no."
7. Find a minimum diameter spanning tree for the following graphs.

Figure 10.2.21

      Figure 10.2.22

10.3 Rooted Trees

In the next two sections, we will discuss rooted trees. Our primary foci will be
on general rooted trees and on a special case, ordered binary trees.
CHAPTER 10. TREES                  253

10.3.1 Definition and Terminology

Figure 10.3.1 A Rooted Tree

    List 10.3.2 Informal Definition and Terminology

         What differentiates rooted trees from undirected trees is that a
    rooted tree contains a distinguished vertex, called the root. Consider
    the tree in Figure 10.3.1. Vertex A has been designated the root of the
    tree. If we choose any other vertex in the tree, such as M , we know
    that there is a unique path from A to M . The vertices on this path,
    (A, D, K, M ), are described in genealogical terms:

        · M is a child of K (so is L)

        · K is M 's parent.

        · A, D, and K are M 's ancestors.

        · D, K, and M are descendants of A.

    These genealogical relationships are often easier to visualize if the tree
    is rewritten so that children are positioned below their parents, as in
    Figure 10.3.3.

         With this format, it is easy to see that each vertex in the tree can
    be thought of as the root of a tree that contains, in addition to itself,
    all of its descendants. For example, D is the root of a tree that contains
    D, K, L, and M . Furthermore, K is the root of a tree that contains
    K, L, and M . Finally, L and M are roots of trees that contain only
    themselves. From this observation, we can give a formal definition of a
    rooted tree.
CHAPTER 10. TREES                                                     254

Figure 10.3.3 A Rooted Tree, redrawn

    One can formally define the genealogical terms above. We define child here
since it's used in our formal definition of a rooted tree and leave the rest of the
definitions as an exercise.

Definition 10.3.4 Child of a Root. Given a rooted tree with root v, a

child of v is a vertex that is connected to v by an edge of the tree. We refer to

the root as the parent of each of its children.                       

Definition 10.3.5 Rooted Tree.

(a) A single vertex v with no children is a rooted tree with root v.

(b) Recursion: Let T1, T2, . . . , Tr, r  1, be disjoint rooted trees with roots v1,
     v2, . . ., vr, respectively, and let v0 be a vertex that does not belong to any
     of these trees. Then a rooted tree, rooted at v0, is obtained by making
     v0 the parent of the vertices v1, v2, . . ., and vr. We call T1, T2, . . . , Tr
     subtrees of the larger tree.

                                                                                                     
    The level of a vertex of a rooted tree is the number of edges that separate
the vertex from the root. The level of the root is zero. The depth of a tree is the
maximum level of the vertices in the tree. The depth of a tree in Figure 10.3.3
is three, which is the level of the vertices L and M . The vertices E, F , G, H,
I, J, and K have level two. B, C, and D are at level one and A has level zero.

Example 10.3.6 A Decision Tree. Figure 2.1.2 is a rooted tree with Start

as the root. It is an example of what is called a decision tree.      

Example 10.3.7 Tree Structure of Data. One of the keys to working with
large amounts of information is to organize it in a consistent, logical way. A
data structure is a scheme for organizing data. A simple example of a data
structure might be the information a college admissions department might keep
on their applicants. Items might look something like this:

ApplicantItem = (F irstN ame, M iddleInitial, LastN ame, StreetAddress,
                   City, State, Zip, HomeP hone, CellP hone, EmailAddress,
                   HighSchool, M ajor, ApplicationP aid, M athSAT, V erbalSAT,
                   Recommendation1, Recommendation2, Recommendation3)

This structure is called a "flat file".
    A spreadsheet can be used to arrange data in this way. Although a "flat

file" structure is often adequate, there are advantages to clustering some the
information. For example the applicant information might be broken into four
CHAPTER 10. TREES                              255

parts: name, contact information, high school, and application data:

 ApplicantItem = ((F irstN ame, M iddleInitial, LastN ame),

                     ((StreetAddress, City, State, Zip),

                     (HomeP hone, CellP hone), EmailAddress),

                     H ighS chool,

                     (M ajor, ApplicationP aid, (M athSAT, V erbalSAT ),

                     (Recommendation1, Recommendation2, Recommendation3))

The first item in each ApplicantItem is a list
(F irstN ame, M iddleInitial, LastN ame), with each item in that list be-
ing a single field of the original flat file. The third item is simply the single
high school item from the flat file. The application data is a list and one of its
items, is itself a list with the recommendation data for each recommendation
the applicant has.

    The organization of this data can be visualized with a rooted tree such as
the one in Figure 10.3.8.

Figure 10.3.8 Applicant Data in a Rooted Tree

In general, you can represent a data item, T , as a rooted tree with T as the

root and a subtree for each field. Those fields that are more than just one item

are roots of further subtrees, while individual items have no further children

in the tree.                                   

10.3.2 Kruskal's Algorithm

An alternate algorithm for constructing a minimal spanning tree uses a for-
est of rooted trees. First we will describe the algorithm in its simplest terms.
Afterward, we will describe how rooted trees are used to implement the al-
gorithm. Finally, we will demonstrate the SageMath implementation of the
algorithm. In all versions of this algorithm, assume that G = (V, E, w) is a
weighted undirected graph with |V | = m and |E| = n.

Algorithm 10.3.9 Kruskal's Algorithm - Informal Version.

  (1) Sort the edges of G in ascending order according to weight. That is,

                   i  j  w (ej)  w (ej) .
CHAPTER 10. TREES  256

  (2) Go down the list from Step 1 and add edges to a set (initially empty) of
       edges so that the set does not form a cycle. When an edge that would
       create a cycle is encountered, ignore it. Continue examining edges until
       either m - 1 edges have been selected or you have come to the end of the
       edge list. If m - 1 edges are selected, these edges make up a minimal
       spanning tree for G. If fewer than m - 1 edges are selected, G is not
       connected.

    Step 1 can be accomplished using one of any number of standard sorting
routines. Using the most efficient sorting routine, the time required to perform
this step is proportional to n log n. The second step of the algorithm, also of
n log n time complexity, is the one that uses a forest of rooted trees to test for
whether an edge should be added to the spanning set.

Algorithm 10.3.10 Kruskal's Algorithm.

  (1) Sort the edges of G in ascending order according to weight. That is,

                                       i  j  w (ei)  w (ej) .

  (2) (1) Initialize each vertex in V to be the root of its own rooted tree.

        (2) Go down the list of edges until either a spanning tree is completed
              or the edge list has been exhausted. For each edge e = {v1, v2}, we
             can determine whether e can be added to the spanning set without
              forming a cycle by determining whether the root of v1s tree is equal
              to the root of v2s tree. If the two roots are equal, then ignore e.
              If the roots are different, then we can add e to the spanning set.
              In addition, we merge the trees that v1 and v2 belong to. This is
              accomplished by either making v1s root the parent of v2s root or
              vice versa.

Note 10.3.11

  (a) Since we start the Kruskal's algorithm with m trees and each addition of
       an edge decreases the number of trees by one, we end the algorithm with
       one rooted tree, provided a spanning tree exists.

  (b) The rooted tree that we develop in the algorithm is not the spanning tree
       itself.

10.3.3 SageMath Note - Implementation of Kruskal's Al-
          gorithm

Kruskal's algorithm has been implemented in Sage. We illustrate how the
spanning tree for a weighted graph in can be generated. First, we create such
a graph

    We will create a graph using a list of triples of the form (vertex, vertex, label).
The weighted method tells Sage to consider the labels as weights.

 edges=[(1, 2, 4), (2, 8, 4), (3, 8, 4), (4, 7, 5), (6, 8,
        5), (1, 3, 6), (1, 7, 6), (4, 5, 6), (5, 10, 9), (2, 10,
        7), (4, 6, 7), (2, 4, 8), (1,8, 9), (1, 9, 9), (5, 6,
        9), (1, 10, 10), (2, 9, 10), (4, 9, 10), (5, 9, 10), (6,
        9, 10)]

 G=Graph(edges)
 G.weighted(True)
 G.graphplot(edge_labels=True ,save_pos=True).show()
CHAPTER 10. TREES  257

Figure 10.3.12 Weighed graph, SageMath output

    Next, we load the kruskal function and use it to generate the list of edges
in a spanning tree of G.

 from sage.graphs.spanning_tree import kruskal
 E = kruskal(G, check=True);E

  [(1, 2, 4), (1, 7, 6), (1, 9, 9), (2, 8, 4), (2, 10, 7),
        (3, 8, 4), (4, 5, 6), (4, 7, 5), (6, 8, 5)]

    To see the resulting tree with the same embedding as G, we generate a
graph from the spanning tree edges. Next, we set the positions of the vertices
to be the same as in the graph. Finally, we plot the tree.

 T=Graph(E)
 T. set_pos (G. get_pos () )
 T. graphplot ( edge_labels = True ). show ()
CHAPTER 10. TREES  258

Figure 10.3.13 Spanning tree, SageMath output

10.3.4 Exercises

1. Suppose that an undirected tree has diameter d and that you would like
      to select a vertex of the tree as a root so that the resulting rooted tree
      has the smallest depth possible. How would such a root be selected and
      what would be the depth of the tree (in terms of d)?

2. Use Kruskal's algorithm to find a minimal spanning tree for the following
      graphs. In addition to the spanning tree, find the final rooted tree in the
      algorithm. When you merge two trees in the algorithm, make the root
      with the lower number the root of the new tree.

      Figure 10.3.14
CHAPTER 10. TREES  259

      Figure 10.3.15
3. Suppose that information on buildings is arranged in records with five

      fields: the name of the building, its location, its owner, its height, and
      its floor space. The location and owner fields are records that include all
      of the information that you would expect, such as street, city, and state,
      together with the owner's name (first, middle, last) in the owner field.
      Draw a rooted tree to describe this type of record
4. Step through Kruskal's Algorithm by hand to verify that the example of
      a minimal spanning tree using Sage in Subsection 10.3.3 is correct.

10.4 Binary Trees

10.4.1 Definition of a Binary Tree

An ordered rooted tree is a rooted tree whose subtrees are put into a definite
order and are, themselves, ordered rooted trees. An empty tree and a single
vertex with no descendants (no subtrees) are ordered rooted trees.

Example 10.4.1 Distinct Ordered Rooted Trees. The trees in Fig-
ure 10.4.2 are identical rooted trees, with root 1, but as ordered trees, they are
different.
CHAPTER 10. TREES  260

Figure 10.4.2 Two different ordered rooted trees
                                                                                                     

    If a tree rooted at v has p subtrees, we would refer to them as the first,
second,..., pth subtrees. There is a subtle difference between certain ordered
trees and binary trees, which we define next.
Definition 10.4.3 Binary Tree.

  (1) A tree consisting of no vertices (the empty tree) is a binary tree
  (2) A vertex together with two subtrees that are both binary trees is a binary

       tree. The subtrees are called the left and right subtrees of the binary tree.
                                                                                                     

    The difference between binary trees and ordered trees is that every vertex
of a binary tree has exactly two subtrees (one or both of which may be empty),
while a vertex of an ordered tree may have any number of subtrees. But there
is another significant difference between the two types of structures. The two
trees in Figure 10.4.4 would be considered identical as ordered trees. However,
they are different binary trees. Tree (a) has an empty right subtree and Tree
(b) has an empty left subtree.

Figure 10.4.4 Two different binary trees

     List 10.4.5 Terminology and General Facts about Binary Trees

       (a) A vertex of a binary tree with two empty subtrees is called a leaf.
            All other vertices are called internal vertices.

       (b) The number of leaves in a binary tree can vary from one up to
            roughly half the number of vertices in the tree (see Exercise 4 of
CHAPTER 10. TREES                                                           261

     this section).

(c) The maximum number of vertices at level k of a binary tree is 2k
     , k  0 (see Exercise 6 of this section).

(d) A full binary tree is a tree for which each vertex has either zero
     or two empty subtrees. In other words, each vertex has either two
     or zero children. See Exercise 10.4.6.7 of this section for a general
     fact about full binary trees.

10.4.2 Traversals of Binary Trees

The traversal of a binary tree consists of visiting each vertex of the tree in
some prescribed order. Unlike graph traversals, the consecutive vertices that
are visited are not always connected with an edge. The most common binary
tree traversals are differentiated by the order in which the root and its subtrees
are visited. The three traversals are best described recursively and are:

Preorder    (1) Visit the root of the tree.
Traversal:  (2) Preorder traverse the left subtree.

            (3) Preorder traverse the right subtree.

   Inorder  (1) Inorder traverse the left subtree.
Traversal:  (2) Visit the root of the tree.

            (3) Inorder traverse the right subtree.

Postorder   (1) Postorder traverse the left subtree.
Traversal:  (2) Postorder traverse the right subtree.

            (3) Visit the root of the tree.

    Any traversal of an empty tree consists of doing nothing.
Example 10.4.6 Traversal Examples. For the tree in Figure 10.4.7, the
orders in which the vertices are visited are:

   · A-B-D-E-C-F-G, for the preorder traversal.

   · D-B-E-A-F-C-G, for the inorder traversal.

   · D-E-B-F-G-C-A, for the postorder traversal.
CHAPTER 10. TREES  262

Figure 10.4.7 A Complete Binary Tree to Level 2

                                                                                                    
    Binary Tree Sort. Given a collection of integers (or other objects than can
be ordered), one technique for sorting is a binary tree sort. If the integers are
a1, a2, . . ., an, n  1, we first execute the following algorithm that creates a
binary tree:

Algorithm 10.4.8 Binary Sort Tree Creation.

  (1) Insert a1 into the root of the tree.

  (2) For k := 2 to n // insert ak into the tree

        (a) r = a1
        (b) inserted = false

        (c) while not(inserted):
                 if ak < r:
                       if r has a left child:
                          r = left child of r
                        else:
                          make ak the left child of r
                          inserted = true
                    else:
                       if r has a right child:
                          r = right child of r
                        else:
                          make ak the right child of r
                          inserted = true

    If the integers to be sorted are 25, 17, 9, 20, 33, 13, and 30, then the tree
that is created is the one in Figure 10.4.9. The inorder traversal of this tree is
9, 13, 17, 20, 25, 30, 33, the integers in ascending order. In general, the inorder
traversal of the tree that is constructed in the algorithm above will produce a
sorted list. The preorder and postorder traversals of the tree have no meaning
here.
CHAPTER 10. TREES  263

Figure 10.4.9 A Binary Sorting Tree

10.4.3 Expression Trees

A convenient way to visualize an algebraic expression is by its expression tree.
Consider the expression

                                      X = a  b - c/d + e.

Since it is customary to put a precedence on multiplication/divisions, X is
evaluated as ((a  b) - (c/d)) + e. Consecutive multiplication/divisions or addi-
tion/subtractions are evaluated from left to right. We can analyze X further
by noting that it is the sum of two simpler expressions (a  b) - (c/d) and e.
The first of these expressions can be broken down further into the difference
of the expressions a  b and c/d. When we decompose any expression into
(left expression)operation(right expression), the expression tree of that expres-
sion is the binary tree whose root contains the operation and whose left and
right subtrees are the trees of the left and right expressions, respectively. Ad-
ditionally, a simple variable or a number has an expression tree that is a single
vertex containing the variable or number. The evolution of the expression tree
for expression X appears in Figure 10.4.10.
CHAPTER 10. TREES  264

Figure 10.4.10 Building an Expression Tree

Example 10.4.11 Some Expression Trees.

  (a) If we intend to apply the addition and subtraction operations in X first,
       we would parenthesize the expression to a  (b - c)/(d + e). Its expression
       tree appears in Figure 10.4.12(a).

  (b) The expression trees for a2 - b2 and for (a + b)  (a - b) appear in Fig-
       ure 10.4.12(b) and Figure 10.4.12(c).
CHAPTER 10. TREES  265

Figure 10.4.12 Expression Tree Examples

                                                                                                    
    The three traversals of an operation tree are all significant. A binary oper-
ation applied to a pair of numbers can be written in three ways. One is the
familiar infix form, such as a + b for the sum of a and b. Another form is prefix,
in which the same sum is written +ab. The final form is postfix, in which
the sum is written ab+. Algebraic expressions involving the four standard
arithmetic operations (+, -, , and/) in prefix and postfix form are defined as
follows:

    List 10.4.13 Prefix and postfix forms of an algebraic expression

 Prefix            (a) A variable or number is a prefix expression
Postfix
                   (b) Any operation followed by a pair of prefix
                        expressions is a prefix expression.

                   (a) A variable or number is a postfix expression

                   (b) Any pair of postfix expressions followed by
                        an operation is a postfix expression.

    The connection between traversals of an expression tree and these forms is
simple:

  (a) The preorder traversal of an expression tree will result in the prefix form
       of the expression.
CHAPTER 10. TREES                                    266

(b) The postorder traversal of an expression tree will result in the postfix
     form of the expression.

(c) The inorder traversal of an operation tree will not, in general, yield the
     proper infix form of the expression. If an expression requires parentheses
     in infix form, an inorder traversal of its expression tree has the effect of
     removing the parentheses.

Example 10.4.14 Traversing an Expression Tree. The preorder traversal

of the tree in Figure 10.4.10 is + - ab/cde, which is the prefix version of

expression X. The postorder traversal is ab  cd/ - e+. Note that since the

original form of X needed no parentheses, the inorder traversal, a  b - c/d + e,

is the correct infix version.                        

10.4.4 Counting Binary Trees

We close this section with a formula for the number of different binary trees
with n vertices. The formula is derived using generating functions. Although
the complete details are beyond the scope of this text, we will supply an
overview of the derivation in order to illustrate how generating functions are
used in advanced combinatorics.

    Let B(n) be the number of different binary trees of size n (n vertices),
n  0. By our definition of a binary tree, B(0) = 1. Now consider any positive
integer n + 1, n  0. A binary tree of size n + 1 has two subtrees, the sizes of
which add up to n. The possibilities can be broken down into n + 1 cases:

       Case 0: Left subtree has size 0; right subtree has size n.

       Case 1: Left subtree has size 1; right subtree has size n - 1.
             ..
             .

       Case k: Left subtree has size k; right subtree has size n - k.
             ..
             .

       Case n: Left subtree has size n; right subtree has size 0.

In the general Case k, we can count the number of possibilities by multiplying
the number of ways that the left subtree can be filled, B(k), by the number
of ways that the right subtree can be filled. B(n - k). Since the sum of these
products equals B(n + 1), we obtain the recurrence relation for n  0:

             B(n + 1) = B(0)B(n) + B(1)B(n - 1) + · · · + B(n)B(0)

                                          n

                          = B(k)B(n - k)

                                        k=0

    Now take the generating function of both sides of this recurrence relation:

                                 n

         B(n + 1)zn =               B(k)B(n - k) zn  (10.4.1)

    n=0                        n=0 k=0

or

         G(B ; z) = G(B  B; z) = G(B; z)2            (10.4.2)

    Recall that G(B ; z) = z G(B;z)-B(0) = z G(B;z)-1 If we abbreviate G(B; z)
to G, we get

                              G - 1 = G2  zG2 - G + 1 = 0
                                 z
CHAPTER 10. TREES                                                                     267

Using the quadratic equation we find two solutions:                              (10.4.3)
                                                                                 (10.4.4)

                                    G1 = 1 + 1 - 4z and
                                                  2z

                                       G2 = 1 - 1 - 4z
                                                     2z

    The gap in our derivation occurs here since we don't presume a knowledge
of calculus. If we expand G1 as an extended power series, we find

                
    G1 = 1 + 1 - 4z = 1 - 1 - z - 2z2 - 5z3 - 14z4 - 42z5 + · · ·
                2z          z                                                    (10.4.5)

    The coefficients after the first one are all negative and there is a singularity

at  0  because  of  the  1  term.  However  if  we  do  the  same  with  G2  we  get
                         z

                                                                                 (10.4.6)
       G2 = 1 - 1 - 4z = 1 + z + 2z2 + 5z3 + 14z4 + 42z5 + · · ·

                     2z

    Further analysis leads to a closed form expression for B(n), which is

                                   B(n) = 1 2n
                                              n+1 n

This sequence of numbers is often called the Catalan numbers. For more

information on the Catalan numbers, see the entry A000108 in The On-Line
Encyclopedia of Integer Sequences1.

10.4.5 SageMath Note - Power Series

It may be of interest to note how the extended power series expansions of
G1 and G2 are determined using Sage. In Sage, one has the capability of
being very specific about how algebraic expressions should be interpreted by
specifying the underlying ring. This can make working with various algebraic
expressions a bit more confusing to the beginner. Here is how to get a Laurent
expansion for G1 above.

 R.<z>= PowerSeriesRing(ZZ , ' z ' )
 G1 =(1+ sqrt (1 -4* z)) /(2* z)
 G1

 z^-1 - 1 - z - 2*z^2 - 5*z^3 - 14*z^4 - 42*z^5 - 132*z^6
   - 429*z^7 - 1430*z^8 - 4862*z^9 - 16796*z^10 - 58786*z^11
     - 208012*z^12 - 742900*z^13 - 2674440*z^14 - 9694845*z^15
       - 35357670*z^16 - 129644790*z^17 - 477638700*z^18 +
              O(z^19)

    The first Sage expression above declares a structure called a ring that
contains power series. We are not using that whole structure, just a specific
element, G1. So the important thing about this first input is that it establishes
z as being a variable associated with power series over the integers. When
the second expression defines the value of G1 in terms of z, it is automatically
converted to a power series.

    The expansion of G2 uses identical code, and its coefficients are the values
of B(n).

   1oeis.org
CHAPTER 10. TREES                                             268

R.<z>= PowerSeriesRing(ZZ , ' z ' )
G2 =(1 - sqrt (1 -4* z)) /(2* z)
G2

1 + z + 2*z^2 + 5*z^3 + 14*z^4 + 42*z^5 + 132*z^6 +  429*z^7
 + 1430*z^8 + 4862*z^9 + 16796*z^10 + 58786*z^11 +
        208012*z^12
   + 742900*z^13 + 2674440*z^14 + 9694845*z^15 +
          35357670*z^16
   + 129644790*z^17 + 477638700*z^18 + O(z^19)

    In Chapter 16 we will introduce rings and will be able to take further
advantage of Sage's capabilities in this area.

10.4.6 Exercises

1. Draw the expression trees for the following expressions:

        (a) a(b + c)

        (b) ab + c

         (c) ab + ac

        (d) bb - 4ac

         (e) ((a3x + a2) x + a1) x + a0
2. Draw the expression trees for

        (a) x2 - 1
               x-1

        (b) xy + xz + yz
3. Write out the preorder, inorder, and postorder traversals of the trees in

      Exercise 1 above.
4. Verify the formula for B(n), 0  n  3 by drawing all binary trees with

      three or fewer vertices.
5.

        (a) Draw a binary tree with seven vertices and only one leaf. Your
              answer won't be unique. How many different possible answers are
              there?

        (b) Draw a binary tree with seven vertices and as many leaves as possi-
              ble.

6. Prove that the maximum number of vertices at level k of a binary tree is
      2k and that a tree with that many vertices at level k must have 2k+1 - 1
      vertices.

7. Prove that if T is a full binary tree, then the number of leaves of T is
      one more than the number of internal vertices (non-leaves).

8.
CHAPTER 10. TREES                                           269

There is a one to one correspon-

dence between ordered rooted trees

and binary trees. If you start with

an ordered rooted tree, T , you can

build a binary tree B with an empty

right subtree by placing the the root

of T at the root of B. Then for every

vertex v from T that has been placed

in B, place it's leftmost child (if there

is one) as v's left child in B. Make

v's next sibling (if there is one) in T

the right child in B.                    Figure 10.4.15 An ordered rooted

                                         tree with root r.

Figure 10.4.16 Blue (left) and Red
(right) links added to the ordered
rooted tree with root r.

                                                Figure 10.4.17 Binary tree corre-
                                                sponding to the ordered rooted tree.

  (a) Why will B have no right children in this correspondence?

  (b) Draw the binary tree that is produced by the ordered rooted tree in
        Figure 10.4.18.

  (c) The left subtree of the binary tree in Figure 10.4.19 is one of 5
        different binary trees with three vertices. Draw each of them and
        also the ordered rooted tree that each corresponds with.

  (d) What does this correspondence tell us about how the numbers of
        different binary trees and ordered rooted trees are related?

Figure 10.4.18 What binary tree

does this correspond with?               Figure 10.4.19     What ordered
                                                            this correspond
                                         rooted tree does

                                         with?
Chapter 11

Algebraic Structures

                               Abelian Group

                          In Abelian groups, when computing,
                            With operands there's no refuting:
                                       The expression bc
                                        Is the same as cb.

                        Not en route to your job, yet commuting.

    Howard Spindel, The Omnificent English Dictionary In Limerick Form

The primary goal of this chapter is to make the reader aware of what an alge-
braic system is and how algebraic systems can be studied at different levels of
abstraction. After describing the concrete, axiomatic, and universal levels, we
will introduce one of the most important algebraic systems at the axiomatic
level, the group. In this chapter, group theory will be a vehicle for introducing
the universal concepts of isomorphism, direct product, subsystem, and generat-
ing set. These concepts can be applied to all algebraic systems. The simplicity
of group theory will help the reader obtain a good intuitive understanding of
these concepts. In Chapter 15, we will introduce some additional concepts
and applications of group theory. We will close the chapter with a discussion
of how some computer hardware and software systems use the concept of an
algebraic system.

11.1 Operations

One of the first mathematical skills that we all learn is how to add a pair of
positive integers. A young child soon recognizes that something is wrong if a
sum has two values, particularly if his or her sum is different from the teacher's.
In addition, it is unlikely that a child would consider assigning a non-positive
value to the sum of two positive integers. In other words, at an early age we
probably know that the sum of two positive integers is unique and belongs to
the set of positive integers. This is what characterizes all binary operations on
a set.

                                                 270
CHAPTER 11. ALGEBRAIC STRUCTURES                                  271

11.1.1 What is an Operation?

Definition 11.1.1 Binary Operation. Let S be a nonempty set. A binary

operation on S is a rule that assigns to each ordered pair of elements of S a

unique element of S. In other words, a binary operation is a function from

S × S into S.                                                     

Example 11.1.2 Some common binary operations. Union and intersec-

tion are both binary operations on the power set of any universe. Addition and

multiplication are binary operators on the natural numbers. Addition and mul-

tiplication are binary operations on the set of 2 by 2 real matrices, M2×2(R).
Division is a binary operation on some sets of numbers, such as the positive

reals. But on the integers (1/2 / Z) and even on the real numbers (1/0 is not
defined), division is not a binary operation.
                                                                  

Note 11.1.3

(a) We stress that the image of each ordered pair must be in S. This require-
     ment disqualifies subtraction on the natural numbers from consideration
     as a binary operation, since 1 - 2 is not a natural number. Subtraction
     is a binary operation on the integers.

 (b) On Notation. Despite the fact that a binary operation is a function,
       symbols, not letters, are used to name them. The most commonly used
       symbol for a binary operation is an asterisk, . We will also use a dia-
       mond, , when a second symbol is needed.

    If  is a binary operation on S and a, b  S, there are three common ways
of denoting the image of the pair (a, b). They are:

               ab  ab                          ab

               Prefix Form Infix Form Postfix Form

We are all familiar with infix form. For example, 2+3 is how everyone is taught
to write the sum of 2 and 3. But notice how 2 + 3 was just described in the
previous sentence! The word sum preceded 2 and 3. Orally, prefix form is quite
natural to us. The prefix and postfix forms are superior to infix form in some
respects. In Chapter 10, we saw that algebraic expressions with more than
one operation didn't need parentheses if they were in prefix or postfix form.
However, due to our familiarity with infix form, we will use it throughout most
of the remainder of this book.

    Some operations, such as negation of numbers and complementation of sets,
are not binary, but unary operators.

Definition 11.1.4 Unary Operation. Let S be a nonempty set. A unary

operator on S is a rule that assigns to each element of S a unique element of

S. In other words, a unary operator is a function from S into S.  

11.1.2 Properties of Operations

Whenever an operation on a set is encountered, there are several properties that
should immediately come to mind. To effectively make use of an operation, you
should know which of these properties it has. By now, you should be familiar
with most of these properties. We will list the most common ones here to
refresh your memory and define them for the first time in a general setting.

    First we list properties of a single binary operation.

Definition 11.1.5 Commutative Property. Let  be a binary operation
on a set S. We say that  is commutative if and only if a  b = b  a for all
CHAPTER 11. ALGEBRAIC STRUCTURES                                   272

a, b  S.                                                           

Definition 11.1.6 Associative Property. Let  be a binary operation on

a set S. We say that  is associative if and only if (a  b)  c = a  (b  c) for

all a, b, c  S.                                                    

Definition 11.1.7 Identity Property. Let  be a binary operation on a set

S. We say that  has an identity if and only if there exists an element, e, in

S such that a  e = e  a = a for all a  S.                          

The next property presumes that  has the identity property.

Definition 11.1.8 Inverse Property. Let  be a binary operation on a set

S. We say that  has the inverse property if and only if for each a  S, there

exists b  S such that a  b = b  a = e. We call b an inverse of a.  

Definition 11.1.9 Idempotent Property. Let  be a binary operation on
a set S. We say that  is idempotent if and only if a  a = a for all a  S. 

    Now we list properties that apply to two binary operations.

Definition 11.1.10 Left Distributive Property. Let  and  be binary

operations on a set S. We say that  is left distributive over  if and only if

a  (b  c) = (a  b)  (a  c) for all a, b, c  S.                     

Definition 11.1.11 Right Distributive Property. Let  and  be binary

operations on a set S. We say that  is right distributive over  if and only if

(b  c)  a = (b  a)  (c  a) for all a, b, c  S.                     

Definition 11.1.12 Distributive Property. Let  and  be binary opera-

tions on a set S. We say that  is distributive over  if and only if  is both

left and right distributive over .                                 

There is one significant property of unary operations.

Definition 11.1.13 Involution Property. Let - be a unary operation on
S. We say that - has the involution property if -(-a) = a for all a  S. 

    Finally, a property of sets, as they relate to operations.

Definition 11.1.14 Closure Property. Let T be a subset of S and let 

be a binary operation on S. We say that T is closed under  if a, b  T implies

that a  b  T .                                                     

In other words, T is closed under  if by operating on elements of T with

, you can't get new elements that are outside of T .

Example 11.1.15 Some examples of closure and non-closure.

(a) The odd integers are closed under multiplication, but not under addition.

(b) Let p be a proposition over U and let A be the set of propositions over
     U that imply p. That is; q  A if q  p. Then A is closed under both
     conjunction and disjunction.

(c) The set of positive integers that are multiples of 5 is closed under both
     addition and multiplication.

                                                                                                    
    It is important to realize that the properties listed above depend on both the
set and the operation(s). Statements such as "Multiplication is commutative."
or "The positive integers are closed." are meaningless on their own. Naturally,
if we have established a context in which the missing set or operation is clearly
implied, then they would have meaning.
CHAPTER 11. ALGEBRAIC STRUCTURES                                273

11.1.3 Operation Tables

If the set on which a binary operation is defined is small, a table is often a

good way of describing the operation. For example, we might want to define

 on {0, 1, 2} by a  b =    a+b  if a + b < 3 The table for  is
                         a+b-3  if a + b  3

                                           012
                                           0 012
                                           1 120
                                           2 201

    The top row and left column of an operation table are the column and row
headings, respectively. To determine a  b, find the entry in the row labeled a
and the column labeled b. The following operation table serves to define  on
{i, j, k}.

                                            i jk
                                           iiii
                                           jjjj
                                           kkkk

    Note that j  k = j, yet k  j = k. Thus,  is not commutative. Commuta-
tivity is easy to identify in a table: the table must be symmetric with respect
to the diagonal going from the top left to lower right.

11.1.4 Exercises

1. Determine the properties that the following operations have on the posi-
      tive integers.

        (a) addition

        (b) multiplication

         (c) M defined by aM b = larger of a and b

        (d) m defined by amb = smaller of a and b

         (e) @ defined by a@b = ab
2. Determine the properties that the following operations have on given

      sets.

        (a) Intersection on the set of subsets of {1, 2, 3, 4}.

        (b)  defined on the positive integers by ab = b.

         (c)  defined on the integers by a  b = a + b - 2

        (d)  defined on the positive real numbers by a  b = 2ab .
         (e) Concatenation on the set of all strings of zeros and ones.
3. Let  be an operation on a set S and A, B  S. Prove that if A and B
      are both closed under , then A  B is also closed under , but A  B need
      not be.
4. How can you pick out the identity of an operation from its table?
5. Define a  b by |a - b|, the absolute value of a - b. Which properties does
       have on the set of natural numbers, N?
CHAPTER 11. ALGEBRAIC STRUCTURES           274

6. Which pairs of operations in Exercise 1 are distributive over one another?

11.2 Algebraic Systems

An algebraic system is a mathematical system consisting of a set called the
domain and one or more operations on the domain. If V is the domain and
1, 2, . . . , n are the operations, [V ; 1, 2, . . . , n] denotes the mathematical
system. If the context is clear, this notation is abbreviated to V .

11.2.1 Monoids at Two Levels

Consider the following two examples of algebraic systems.

  (a) Let B be the set of all finite strings of 0's and 1's including the null (or
       empty) string, . An algebraic system is obtained by adding the opera-
       tion of concatenation. The concatenation of two strings is simply the link-
       ing of the two strings together in the order indicated. The concatenation
       of strings a with b is denoted a + b. For example, 01101 + 101 = 01101101
       and  + 100 = 100. Note that concatenation is an associative operation
       and that  is the identity for concatenation.

       A note on notation: There isn't a standard symbol for concatenation.
       We have chosen + to be consistent with the notation used in Python and
       Sage for the concatenation.

  (b) Let M be any nonempty set and let  be any operation on M that is as-
       sociative and has an identity in M . Any such system is called a monoid.
       We introduce monoids briefly here, but will discuss them further in Chap-
       ter 14

    Our second example might seem strange, but we include it to illustrate a
point. The algebraic system [B; +] is a special case of [M ; ]. Most of us
are much more comfortable with B than with M . No doubt, the reason is
that the elements in B are more concrete. We know what they look like and
exactly how they are combined. The description of M is so vague that we
don't even know what the elements are, much less how they are combined.
Why would anyone want to study M ? The reason is related to this question:
What theorems are of interest in an algebraic system? Answering this question
is one of our main objectives in this chapter. Certain properties of algebraic
systems are called algebraic properties, and any theorem that says something
about the algebraic properties of a system would be of interest. The ability to
identify what is algebraic and what isn't is one of the skills that you should
learn from this chapter.

    Now, back to the question of why we study M . Our answer is to illustrate
the usefulness of M with a theorem about M .

Theorem 11.2.1 A Monoid Theorem. If a, b are elements of M and
a  b = b  a, then (a  b)  (a  b) = (a  a)  (b  b).
Proof.

(a  b)  (a  b) = a  (b  (a  b))      Why?
                   = a  ((b  a)  b)  Why?
                   = a  ((a  b)  b)  Why?
                   = a  (a  (b  b))  Why?
                   = (a  a)  (b  b)  Why?
CHAPTER 11. ALGEBRAIC STRUCTURES                                    275

                                                                                                    
    The power of this theorem is that it can be applied to any algebraic system
that M describes. Since B is one such system, we can apply Theorem 11.2.1
to any two strings that commute. For example, 01 and 0101. Although a
special case of this theorem could have been proven for B, it would not have
been any easier to prove, and it would not have given us any insight into other
special cases of M .

Example 11.2.2 More Concrete Monoids. Consider the set of 2 × 2
real matrices, M2×2(R), with the operation of matrix multiplication. In this
context, Theorem 11.2.1 can be interpreted as saying that if AB = BA, then

(AB)2 = A2B2. One pair of matrices that this theorem applies to is  21
                                                                    12

and 3 -4 .
         -4 3

    For another pair of concrete monoids, we start with a universal set U =
{1, 2, 3, 4, 5} - although we could be a little less specific an imaging U to be any
nonempty set. The power set of U with intersection, and the power set of U
with union are both monoids. What the identities of these monoids? Are they
really the same monoid? We will answer this last question in Section 11.7. 

11.2.2 Levels of Abstraction

One of the fundamental tools in mathematics is abstraction. There are three
levels of abstraction that we will identify for algebraic systems: concrete, ax-
iomatic, and universal.

11.2.2.1 The Concrete Level

Almost all of the mathematics that you have done in the past was at the
concrete level. As a rule, if you can give examples of a few typical elements of
the domain and describe how the operations act on them, you are describing
a concrete algebraic system. Two examples of concrete systems are B and
M2×2(R). A few others are:

  (a) The integers with addition. Of course, addition isn't the only standard
       operation that we could include. Technically, if we were to add multipli-
       cation, we would have a different system.

  (b) The subsets of the natural numbers, with union, intersection, and com-
       plementation.

  (c) The complex numbers with addition and multiplication.

11.2.2.2 The Axiomatic Level

The next level of abstraction is the axiomatic level. At this level, the elements
of the domain are not specified, but certain axioms are stated about the number
of operations and their properties. The system that we called M is an axiomatic
system. Some combinations of axioms are so common that a name is given to
any algebraic system to which they apply. Any system with the properties
of M is called a monoid. The study of M would be called monoid theory.
The assumptions that we made about M , associativity and the existence of
an identity, are called the monoid axioms. One of your few brushes with
the axiomatic level may have been in your elementary algebra course. Many
algebra texts identify the properties of the real numbers with addition and
CHAPTER 11. ALGEBRAIC STRUCTURES  276

multiplication as the field axioms. As we will see in Chapter 16, "Rings and
Fields," the real numbers share these axioms with other concrete systems, all
of which are called fields.

11.2.2.3 The Universal Level

The final level of abstraction is the universal level. There are certain concepts,
called universal algebra concepts, that can be applied to the study of all al-
gebraic systems. Although a purely universal approach to algebra would be
much too abstract for our purposes, defining concepts at this level should make
it easier to organize the various algebraic theories in your own mind. In this
chapter, we will consider the concepts of isomorphism, subsystem, and direct
product.

11.2.3 Groups

To illustrate the axiomatic level and the universal concepts, we will consider
yet another kind of axiomatic system, the group. In Chapter 5 we noted that
the simplest equation in matrix algebra that we are often called upon to solve
is AX = B, where A and B are known square matrices and X is an unknown
matrix. To solve this equation, we need the associative, identity, and inverse
laws. We call the systems that have these properties groups.

Definition 11.2.3 Group. A group consists of a nonempty set G and a
binary operation  on G satisfying the properties

  (a)  is associative on G: (a  b)  c = a  (b  c) for all a, b, c  G.

  (b) There exists an identity element, e  G, such that a  e = e  a = a for
        all a  G.

  (c) For all a  G, there exists an inverse; that is, there exists b  G such
        that a  b = b  a = e.

                                                                                                     
     A group is usually denoted by its set's name, G, or occasionally by [G; ]
to emphasize the operation. At the concrete level, most sets have a standard
operation associated with them that will form a group. As we will see below,
the integers with addition is a group. Therefore, in group theory Z always
stands for [Z; +].

Note 11.2.4 Generic Symbols. At the axiomatic and universal levels,
there are often symbols that have a special meaning attached to them. In
group theory, the letter e is used to denote the identity element of whatever
group is being discussed. A little later, we will prove that the inverse of a
group element, a, is unique and its inverse is usually denoted a-1 and is read
"a inverse." When a concrete group is discussed, these symbols are dropped in
favor of concrete symbols. These concrete symbols may or may not be similar
to the generic symbols. For example, the identity element of the group of
integers is 0, and the inverse of n is denoted by -n, the additive inverse of n.

    The asterisk could also be considered a generic symbol since it is used to
denote operations on the axiomatic level.

Example 11.2.5 Some concrete groups.

  (a) The integers with addition is a group. We know that addition is associa-
        tive. Zero is the identity for addition: 0 + n = n + 0 = n for all integers
        n. The additive inverse of any integer is obtained by negating it. Thus
CHAPTER 11. ALGEBRAIC STRUCTURES               277

the inverse of n is -n.

(b) The integers with multiplication is not a group. Although multiplication

is associative and 1 is the identity for multiplication, not all integers have

a multiplicative inverse in Z. For example, the multiplicative inverse of
10  is  101 ,  but  1   is  not  an  integer.
                    10

(c) The power set of any set U with the operation of symmetric difference,

     , is a group. If A and B are sets, then A  B = (A  B) - (A  B). We
     will leave it to the reader to prove that  is associative over P(U ). The
     identity of the group is the empty set: A   = A. Every set is its own
     inverse since A  A = . Note that P(U ) is not a group with union or
     intersection.

                                               

Definition 11.2.6 Abelian Group. A group is abelian if its operation is

commutative.                                   

Abel. Most of the groups that we will discuss in this book will be abelian. The

term abelian is used to honor the Norwegian mathematician N. Abel (1802-29),

who helped develop group theory.

Figure 11.2.7 Norwegian Stamp honoring Abel

11.2.4 Exercises

1. Discuss the analogy between the terms generic and concrete for algebraic
      systems and the terms generic and trade for prescription drugs.

2. Discuss the connection between groups and monoids. Is every monoid a
      group? Is every group a monoid?

3. Which of the following are groups?

        (a) B with concatenation (see Subsection 11.2.1).

        (b) M2×3(R) with matrix addition.
         (c) M2×3(R) with matrix multiplication.
        (d) The positive real numbers, R+, with multiplication.
         (e) The nonzero real numbers, R, with multiplication.
         (f) {1, -1} with multiplication.

        (g) The positive integers with the operation M defined by aM b =
               the larger of a and b.
CHAPTER 11. ALGEBRAIC STRUCTURES                            278

4. Prove that, , defined by A  B = (A  B) - (A  B) is an associative
      operation on P(U ).

5. The following problem supplies an example of a non-abelian group.

A rook matrix is a matrix that has only 0's and 1's as entries such

that each row has exactly one 1 and each column has exactly one 1.

The term rook matrix is derived from the fact that each rook ma-

trix represents the placement of n rooks on an n × n chessboard such

that none of the rooks can attack one another. A rook in chess can

move only vertically or horizontally, but not diagonally. Let Rn be

the set of n × n rook matrices. Thereare six 3 × 3 rook matrices:
100      010                         001

I =  0 1 0  R1 =  0 0 1  R2 =  1 0 0 

0 0 1     1 0 0                       0 1 0
    100      001                         010

F1 =  0 0 1  F2 =  0 1 0  F3 =  1 0 0 

010      100                         001

        (a) List the 2 × 2 rook matrices. They form a group, R2, under matrix
              multiplication. Write out the multiplication table. Is the group
              abelian?

        (b) Write out the multiplication table for R3 . This is another group.
              Is it abelian?

         (c) How many 4 × 4 rook matrices are there? How many n × n rook
              matrices are there?

6. For each of the following sets, identify the standard operation that results
      in a group. What is the identity of each group?

        (a) The set of all 2 × 2 matrices with real entries and nonzero determi-
              nants.

        (b) The set of 2 × 3 matrices with rational entries.
7. Let V = {e, a, b, c}. Let  be defined (partially) by x  x = e for all x  V .

      Write a complete table for  so that [V ; ] is a group.
8. Consider the following set of six algebraic expressions, each defining a

      function on the set of real numbers excluding the numbers 0 and 1.

H = x, 1 - x, 1 , 1 , x - 1 , x = {y1, y2, y3, y4, y5, y6}
                    1-x x x x-1

We can operate on any two of these expressions using function composition.
For example,

         1                        1  x
(y3  y4)(x) = y3(y4(x)) = y3( x ) = 1 - x1 = x - 1 = y6(x)

Therefore, y3y4 = y6. Complete the following operation table for function
composition on H.
CHAPTER 11. ALGEBRAIC STRUCTURES                279

Table 11.2.8 Partial Operation Table for [H, ]

 y1 y2 y3 y4 y5 y6

y1 y1 y2 y3 y4 y5 y6

y2 y2 y1 y6 y5 y4

y3 y3 y4                           y6

y4  y3 y2

y5

y6

Is [H, ] a monoid? Is it a group?

11.3 Some General Properties of Groups

In this section, we will present some of the most basic theorems of group theory.
Keep in mind that each of these theorems tells us something about every group.
We will illustrate this point with concrete examples at the close of the section.

11.3.1 First Theorems

Theorem 11.3.1 Identities are Unique. The identity of a group is unique.
    One difficulty that students often encounter is how to get started in proving

a theorem like this. The difficulty is certainly not in the theorem's complexity.
It's too terse! Before actually starting the proof, we rephrase the theorem so
that the implication it states is clear.

Theorem 11.3.2 Identities are Unique - Rephrased. If G = [G; ] is a
group and e is an identity of G, then no other element of G is an identity of
G.
Proof. (Indirect): Suppose that f  G, f = e, and f is an identity of G. We
will show that f = e, which is a contradiction, completing the proof.

                             f = f  e Since e is an identity
                                = e Since f is an identity

                                                                                                     
    Next we justify the phrase "... the inverse of an element of a group."

Theorem 11.3.3 Inverses are Unique. The inverse of any element of a
group is unique.

    The same problem is encountered here as in the previous theorem. We will
leave it to the reader to rephrase this theorem. The proof is also left to the
reader to write out in detail. Here is a hint: If b and c are both inverses of a,
then you can prove that b = c. If you have difficulty with this proof, note that
we have already proven it in a concrete setting in Chapter 5.

    As mentioned above, the significance of Theorem 11.3.3 is that we can refer
to the inverse of an element without ambiguity. The notation for the inverse
of a is usually a-1 (note the exception below).

Example 11.3.4 Some Inverses.

  (a) In any group, e-1 is the inverse of the identity e, which always is e.

  (b) a-1 -1 is the inverse of a-1 , which is always equal to a (see Theo-
       rem 11.3.5 below).
CHAPTER 11. ALGEBRAIC STRUCTURES                              280

(c) (x  y  z)-1 is the inverse of x  y  z.

(d) In a concrete group with an operation that is based on addition, the

inverse of a is usually written -a. For example, the inverse of k - 3 in

the group [Z; +] is written -(k -3) = 3-k. In the group of 2×2 matrices

over the real numbers under matrix addition, the inverse of   41
                                                              1 -3

is written -  4 1 , which equals            -4 -1 .
              1 -3                          -1 3

                                                                                                    
Theorem 11.3.5 Inverse of Inverse Theorem. If a is an element of group
G, then a-1 -1 = a.

    Again, we rephrase the theorem to make it clear how to proceed.

Theorem 11.3.6 Inverse of Inverse Theorem (Rephrased). If a has
inverse b and b has inverse c, then a = c.
Proof.

a = a  e e is the identity of G
  = a  (b  c) because c is the inverse of b
  = (a  b)  c why?
  = e  c why?
  = c by the identity property

                                                                                                    
    The next theorem gives us a formula for the inverse of a  b, referred gener-
ically here as a "product." This formula should be familiar. In Chapter 5 we
saw that if A and B are invertible matrices, then (AB)-1 = B-1A-1.

Theorem 11.3.7 Inverse of a Product. If a and b are elements of group
G, then (a  b)-1 = b-1  a-1.
Proof. Let x = b-1  a-1. We will prove that x inverts a  b. Since we know
that the inverse is unique, we will have proved the theorem.

              (a  b)  x = (a  b)  b-1  a-1
                           = a  b  b-1  a-1
                           = a  b  b-1  a-1
                           = a  e  a-1
                           = a  a-1
                           =e

Similarly, x  (a  b) = e; therefore, (a  b)-1 = x = b-1  a-1        

Theorem 11.3.8 Cancellation Laws. If a, b, and c are elements of group
G, then

                       left cancellation: (a  b = a  c)  b = c
                       right cancellation: (b  a = c  a)  b = c

Proof. We will prove the left cancellation law. The right law can be proved in

exactly the same way. Starting with a  b = a  c, we can operate on both a  b
and a  c on the left with a-1:

              a-1  (a  b) = a-1  (a  c)
CHAPTER 11. ALGEBRAIC STRUCTURES                           281

Applying the associative property to both sides we get

           (a-1  a)  b = (a-1  a)  c  e  b = e  c
                                               b=c

                                                                                                     

Theorem 11.3.9 Linear Equations in a Group. If G is a group and
a, b  G, the equation a  x = b has a unique solution, x = a-1  b. In addition,
the equation x  a = b has a unique solution, x = b  a-1.
Proof. We prove the theorem only for a  x = b, since the second statement is
proven identically.

                             ax=b=eb
                                         = (a  a-1)  b
                                         = a  (a-1  b)

By the cancellation law, we can conclude that x = a-1  b.

If c and d are two solutions of the equation a  x = b, then a  c = b = a  d and,

by the cancellation law, c = d. This verifies that a-1  b is the only solution of

a  x = b.                                                  

Note 11.3.10 Our proof of Theorem 11.3.9 was analogous to solving the con-

crete equation 4x = 9 in the following way:

                                1               1
           4x = 9 = 4 · 4 9 = 4 4 9

Therefore, by cancelling 4,

                             1               9
                             x= 4 ·9= 4

11.3.2 Exponents

If a is an element of a group G, then we establish the notation that

                           a  a = a2 a  a  a = a3 etc.

In addition, we allow negative exponents and define, for example,
                                          a-2 = a2 -1

Although this should be clear, proving exponentiation properties requires a
more precise recursive definition.
Definition 11.3.11 Exponentiation in Groups. For n  0, define an
recursively by a0 = e and if n > 0, an = an-1  a. Also, if n > 1, a-n = (an)-1.

                                                                                                     
Example 11.3.12 Some concrete exponentiations.

  (a) In the group of positive real numbers with multiplication,

       53 = 52 · 5 = 51 · 5 · 5 = 50 · 5 · 5 · 5 = ((1 · 5) · 5) · 5 = 5 · 5 · 5 = 125

       and
                                         5-3 = (125)-1 = 1
                                                                125

  (b) In a group with addition, we use a different form of notation, reflecting
       the fact that in addition repeated terms are multiples, not powers. For
CHAPTER 11. ALGEBRAIC STRUCTURES                               282

example, in [Z; +], a + a is written as 2a, a + a + a is written as 3a, etc.
The inverse of a multiple of a such as -(a + a + a + a + a) = -(5a) is
written as (-5)a.

                                                                                                     
    Although we define, for example, a5 = a4  a, we need to be able to extract
the single factor on the left. The following lemma justifies doing precisely that.

Lemma 11.3.13 Let G be a group. If b  G and n  0, then bn+1 = b  bn,
and hence b  bn = bn  b.
Proof. (By induction): If n = 0,

b1 = b0  b by the definition of exponentiation
   = e  b by the basis for exponentiation
   = b  e by the identity property
   = b  b0 by the basis for exponentiation

Now assume the formula of the lemma is true for some n  0.

b(n+1)+1 = b(n+1)  b by the definition of exponentiation
           = (b  bn)  b by the induction hypothesis
           = b  (bn  b) associativity
           = b  bn+1 definition of exponentiation

                                                                                                    
    Based on the definitions for exponentiation above, there are several proper-
ties that can be proven. They are all identical to the exponentiation properties
from elementary algebra.

Theorem 11.3.14 Properties of Exponentiation. If a is an element of
a group G, and m and n are integers,

(1) a-n = a-1 n and hence (an)-1 = a-1 n

(2) an+m = an  am

(3) (an)m = anm

Proof. We will leave the proofs of these properties to the reader. All three parts

can be done by induction. For example the proof of the second part would start

by defining the proposition p(m) , m  0, to be an+m = an  am for all n. The

basis is p(0) : an+0 = an  a0.                                 

Our final theorem is the only one that contains a hypothesis about the

group in question. The theorem only applies to finite groups.

Theorem 11.3.15 If G is a finite group, |G| = n, and a is an element of G,
then there exists a positive integer m such that am = e and m  n.
Proof. Consider the list a, a2, . . . , an+1 . Since there are n + 1 elements of G
in this list, there must be some duplication. Suppose that ap = aq, with p < q.
Let m = q - p. Then

                                am = aq-p
                                    = aq  a-p
                                    = aq  (ap)-1
                                    = aq  (aq)-1
                                    =e
CHAPTER 11. ALGEBRAIC STRUCTURES                                           283

Furthermore, since 1  p < q  n + 1, m = q - p  n.                          

    Consider the concrete group [Z; +]. All of the theorems that we have stated
in this section except for the last one say something about Z. Among the facts
that we conclude from the theorems about Z are:

· Since the inverse of 5 is -5, the inverse of -5 is 5.

· The inverse of -6 + 71 is -(71) + -(-6) = -71 + 6.

· The solution of 12 + x = 22 is x = -12 + 22.

· -4(6) + 2(6) = (-4 + 2)(6) = -2(6) = -(2)(6).

· 7(4(3)) = (7 · 4)(3) = 28(3) (twenty-eight 3s).

11.3.3 Exercises

1. Let [G; ] be a group and a be an element of G. Define f : G  G by
      f (x) = a  x.

   (a) Prove that f is a bijection.

   (b) On the basis of part a, describe a set of bijections on the set of
        integers.

2. Rephrase Theorem 11.3.3 and write out a clear proof.

3. Prove by induction on n that if a1, a2, . . . , an are elements of a group G,
                             · · ·  an)-1
n       2,  then  (a1   a2                 =  a-1    ···    a2-1    a1-1.  Interpret this

result in terms of [Z; +] and [R; ·].           n

4. True or false? If a, b, c are elements of a group G, and a  b = c  a, then
      b = c. Explain your answer.

5. Prove Theorem 11.3.14.

6. Each of the following facts can be derived by identifying a certain group
      and then applying one of the theorems of this section to it. For each fact,
      list the group and the theorem that are used.

   (a)      1  5 is the only solution of 3x = 5.
            3

   (b) -(-(-18)) = -18.

   (c) If A, B, C are 3 × 3 matrices over the real numbers, with A + B =
        A + C, then B = C.

   (d) There is only one subset K of the natural numbers for which KA =
        A for every subset A of the natural numbers.

11.4 Greatest Common Divisors and the Inte-
       gers Modulo n

In this section introduce the greatest common divisor operation, and introduce
an important family of concrete groups, the integers modulo n.

11.4.1 Greatest Common Divisors

We start with a theorem about integer division that is intuitively clear. We
leave the proof as an exercise.
CHAPTER 11. ALGEBRAIC STRUCTURES                                                       284

Theorem 11.4.1 The Division Property for Integers. If m, n  Z, n > 0,
then there exist two unique integers, q (the quotient) and r (the remainder),
such that m = nq + r and 0  r < n.

Note 11.4.2 The division property says that if m is divided by n, you will

obtain a quotient and a remainder, where the remainder is less than n. This is

a fact that most elementary school students learn when they are introduced to

long division. In doing the division problem 1986 ÷ 97, you obtain a quotient

of  20  and  a  remainder  of  46.  This  result  could  either  be  written  1986  =  20 +  46
                                                                               97            97
or 1986 = 97 · 20 + 46. The latter form is how the division property is normally

expressed in higher mathematics.

    List 11.4.3

        We now remind the reader of some interchangeable terminology that
    is used when r = 0, i. e., a = bq. All of the following say the same
    thing, just from slightly different points of view.

                 divides       b divides a
                multiple       a is a multiple of b

                   factor      b is a factor of a
                  divisor      b is a divisor of a

        We use the notation b | a if b divides a.

    For example 2 | 18 and 9 | 18 , but 4  18.
    Caution: Don't confuse the "divides" symbol with the "divided by" symbol.
The former is vertical while the latter is slanted. Notice however that the
statement 2 | 18 is related to the fact that 18/2 is a whole number.

Definition 11.4.4 Greatest Common Divisor. Given two integers, a and
b, not both zero, the greatest common divisor of a and b is the positive integer
g = gcd(a, b) such that g | a, g | b, and

                                    c | a and c | b  c | g

                                                                                                     
    A little simpler way to think of gcd(a, b) is as the largest positive integer
that is a divisor of both a and b. However, our definition is easier to apply in
proving properties of greatest common divisors.
    For small numbers, a simple way to determine the greatest common divisor
is to use factorization. For example if we want the greatest common divisor of
660 and 350, you can factor the two integers: 660 = 22·3·5·11 and 350 = 2·52·7.
Single factors of 2 and 5 are the only ones that appear in both factorizations,
so the greatest common divisor is 2 · 5 = 10.
    Some pairs of integers have no common divisors other than 1. Such pairs
are called relatively prime pairs.

Definition 11.4.5 Relatively Prime. A pair of integers, a and b, are

relatively prime if gcd(a, b) = 1                                                            

    For example, 128 = 27 and 135 = 33 · 5 are relatively prime. Notice that

neither 128 nor 135 are primes. In general, a and b need not be prime in order

to be relatively prime. However, if you start with a prime, like 23, for example,

it will be relatively prime to everything but its multiples. This theorem, which

we prove later, generalizes this observation.
CHAPTER 11. ALGEBRAIC STRUCTURES               285

Theorem 11.4.6 If p is a prime and a is any integer such that p  a then
gcd(a, p) = 1

11.4.2 The Euclidean Algorithm

As early as Euclid's time it was known that factorization wasn't the best way
to compute greatest common divisors.

    The Euclidean Algorithm is based on the following properties of the greatest
common divisor.

             gcd(a, 0) = a for a = 0           (11.4.1)
gcd(a, b) = gcd(b, r) if b = 0 and a = bq + r  (11.4.2)

    To compute gcd(a, b), we divide b into a and get a remainder r such that 0 
r < |b|. By the property above, gcd(a, b) = gcd(b, r). We repeat the process
until we get zero for a remainder. The last nonzero number that is the second
entry in our pairs is the greatest common divisor. This is inevitable because
the second number in each pair is smaller than the previous one. Table 11.4.7
shows an example of how this calculation can be systematically performed.

Table 11.4.7 A Table to Compute gcd(99, 53)

                                            qa b
                                            - 99 53
                                            1 53 46
                                            1 46 7
                                            67 4
                                            14 3
                                            13 1
                                            31 0

    Here is a Sage computation to verify that gcd(99, 53) = 1. At each line,
the value of a is divided by the value of b. The quotient is placed on the next
line along with the new value of a, which is the previous b; and the remainder,
which is the new value of b. Recall that in Sage, a%b is the remainder when
dividing b into a.

 a=99
 b=53
 while b>0:

         print( ' computing gcd of '+str(a)+ ' and '+str(b))
         [a,b]=[b,a%b]
 print( ' result is '+str(a))

computing gcd of 99 and 53
computing gcd of 53 and 46
computing gcd of 46 and 7
computing gcd of 7 and 4
computing gcd of 4 and 3
computing gcd of 3 and 1
result is 1

Investigation 11.1 If you were allowed to pick two integers less than 100,
which would you pick in order to force Euclid to work hardest? Here's a hint:
The size of the quotient at each step determines how quickly the numbers
decrease.

Solution. If quotient in division is 1, then we get the slowest possible comple-
CHAPTER 11. ALGEBRAIC STRUCTURES                286

tion. If a = b + r, then working backwards, each remainder would be the sum
of the two previous remainders. This described a sequence like the Fibonacci
sequence and indeed, the greatest common divisor of two consecutive Fibonacci
numbers will take the most steps to reach a final value of 1.

    For fixed values of a and b, consider integers of the form ax + by where x
and y can be any two integers. For example if a = 36 and b = 27, some of
these results are tabulated below with x values along the left column and the
y values on top.

Figure 11.4.8 Linear combinations of 36 and 27

    Do you notice any patterns? What is the smallest positive value that you
see in this table? How is it connected to 36 and 27?

Theorem 11.4.9 Bézout's lemma. If a and b are positive integers, the

smallest positive value of ax + by is the greatest common divisor of a and b,

gcd(a, b).

Proof. If g = gcd(a, b), since g | a and g | b, we know that g | (ax + by)

for any integers x and y, so ax + by can't be less than g. To show that g is

exactly the least positive value, we show that g can be attained by extending

the Euclidean Algorithm. Performing the extended algorithm involves building

a table of numbers. The way in which it is built maintains an invariant, and

by The Invariant Relation Theorem, we can be sure that the desired values of

x and y are produced.                           

To illustrate the algorithm, Table 11.4.10 displays how to compute gcd(152, 53).

In the r column, you will find 152 and 53, and then the successive remainders

from division. So each number in r after the first two is the remainder after

dividing the number immediately above it into the next number up. To the

left of each remainder is the quotient from the division. In this case the third

row of the table tells us that 152 = 53 · 2 + 46. The last nonzero value in r is

the greatest common divisor.
CHAPTER 11. ALGEBRAIC STRUCTURES                           287

Table 11.4.10 The extended Euclidean algorithm to compute
gcd(152, 53)

                                     qr  s  t

-- 152 1 0

-- 53 0 1

                                     2 46 1 -2

                                     1 7 -1 3

                                     6 4 7 -20

                                     1 3 -8 23

                                     1 1 15 -43

                                     3 0 -53 152

    The "s" and "t" columns are new. The values of s and t in each row are
maintained so that 152s + 53t is equal to the number in the r column. Notice
that

Table 11.4.11 Invariant in computing gcd(152, 53)

                                     152 = 152 · 1 + 53 · 0
                                      53 = 152 · 0 + 53 · 1
                                    46 = 152 · 1 + 53 · (-2)

                                                   ..
                                                   .

                                   1 = 152 · 15 + 53 · (-43)
                                  0 = 152 · (-53) + 53 · 152

    The next-to-last equation is what we're looking for in the end! The main
problem is to identify how to determine these values after the first two rows.
The first two rows in these columns will always be the same. Let's look at the
general case of computing gcd(a, b). If the s and t values in rows i - 1 and i - 2
are correct, we have

                                (A)  asi-2 + bti-2 = ri-2
In addition, we know that            asi-1 + bti-1 = ri-1

                        ri-2 = ri-1qi + ri  ri = ri-2 - ri-1qi

If you substitute the expressions for ri-1 and ri-2 from (A) into this last
equation and then collect the a and b terms separately you get

                         ri = a (si-2 - qisi-1) + b (ti-2 - qiti-1)

or
                         si = si-2 - qisi-1 and ti = ti-2 - qiti-1

Look closely at the equations for ri, si, and ti. Their forms are all the same.
With a little bit of practice you should be able to compute s and t values
quickly.

11.4.3 Modular Arithmetic

We remind you of the relation on the integers that we call Congruence Modulo
n. If two integers, a and b, differ by a multiple of n, we say that they are
congruent modulo n, denoted a  b (mod n). For example, 13  38 (mod 5)
because 13 - 38 = -25, which is a multiple of 5.
CHAPTER 11. ALGEBRAIC STRUCTURES  288

Definition 11.4.12 The Integers Modulo n. If n is a positive integer
greater than one, we define the integers modulo n to be the set{0, 1, 2, ..., n-1}.

                                                                                                     
Definition 11.4.13 Modular Addition. If n is a positive integer, we define
addition modulo n (+n ) as follows. If a, b  Zn,

                 a +n b = the remainder after a + b is divided by n

                                                                                                     
Definition 11.4.14 Modular Multiplication. If n is a positive integer, we
define multiplication modulo n (×n ) as follows. If a, b  Zn,

                  a ×n b = the remainder after a · b is divided by n

                                                                                                     
Note 11.4.15

  (a) The result of doing arithmetic modulo n is always an integer between
       0 and n - 1, by the Division Property. This observation implies that
       {0, 1, . . . , n - 1} is closed under modulo n arithmetic.

  (b) It is always true that a +n b  (a + b) (mod n) and a ×n b  (a · b)
       (mod n). For example, 4 +7 5 = 2  9 (mod 7) and 4 ×7 5 = 6  20
       (mod 7).

  (c) One interpretation of Zn is that each element is a representative of its
       equivalence class with respect to congruence modulo n. For example,
       if n = 7, the number 1 in Z7 really represents all numbers in [1] =
       1 + 7k : k  Z. In doing modular arithmetic, we can temporarily replace
       elements of Zn with other elements in their equivalence class modulo n.

Example 11.4.16 Some Examples.

  (a) We are all somewhat familiar with Z12 since the hours of the day are
       counted using this group, except for the fact that 12 is used in place of 0.
       Military time uses the mod 24 system and does begin at 0. If someone
       started a four-hour trip at hour 21, the time at which she would arrive
       is 21 +24 4 = 1. If a satellite orbits the earth every four hours and starts
       its first orbit at hour 5, it would end its first orbit at time 5 +24 4 = 9.
       Its tenth orbit would end at 5 +24 10 ×24 4 = 21 hours on the clock

  (b) Virtually all computers represent unsigned integers in binary form with
       a fixed number of digits. A very small computer might reserve seven bits
       to store the value of an integer. There are only 27 different values that
       can be stored in seven bits. Since the smallest value is 0, represented
       as 0000000, the maximum value will be 27 - 1 = 127, represented as
       1111111. When a command is given to add two integer values, and the
       two values have a sum of 128 or more, overflow occurs. For example,
       if we try to add 56 and 95, the sum is an eight-digit binary integer
       10010111. One common procedure is to retain the seven lowest-ordered
       digits. The result of adding 56 and 95 would be 0010111 two = 23 
       56 + 95 (mod 128). Integer arithmetic with this computer would actually
       be modulo 128 arithmetic.

                                                                                                    
CHAPTER 11. ALGEBRAIC STRUCTURES                                   289

11.4.4 Properties of Modular Arithmetic

Theorem 11.4.17 Additive Inverses in Zn. If a  Zn, a = 0, then the
additive inverse of a is n - a.

Proof. a+(n-a) = n  0( mod n), since n = n·1+0. Therefore, a+n (n-a) =

0.                                                                 

    Addition modulo n is always commutative and associative; 0 is the identity

for +n and every element of Zn has an additive inverse. These properties can
be summarized by noting that for each n  1, [Zn; +n] is a group.

Definition 11.4.18 The Additive Group of Integers Modulo n. The

Additive Group of Integers Modulo n is the group with domain {0, 1, 2, . . . , n -

1} and with the operation of mod n addition. It is denoted as Zn.  

    Multiplication modulo n is always commutative and associative, and 1 is

the identity for ×n.

    Notice that the algebraic properties of +n and ×n on Zn are identical to
the properties of addition and multiplication on Z.

    Notice that a group cannot be formed from the whole set {0, 1, 2, . . . , n -

1} with mod n multiplication since zero never has a multiplicative inverse.

Depending on the value of n there may be other numbers that will be excluded.

Definition 11.4.19 The Multiplicative Group of Integers Modulo

n. The Multiplicative Group of Integers Modulo n is the group with domain

{k  Z|1  k  n - 1 and gcd(n, k) = 1} and with the operation of mod n
multiplication. It is denoted as Un.
                                                                   

Example 11.4.20 Some operation tables.

        Here are examples of opera-    +5 0 1 2 3 4
    tion tables for modular groups.      0 01234
    Notice that although 8 is            1 12340
    greater than 5, the two groups       2 23401
    U5 and U8 both have order 4.         3 34012
    In the case of U5, since 5 is        4 40123
    prime all of the nonzero ele-
    ments of Z5 are included. Since   Table 11.4.21 Operation Ta-
    8 isn't prime we don't include    ble for the group Z5
    integers that share a common
    factor with 8, the even integers
    in this case.

    ×5 1 2 3 4                        ×8 1 3 5 7
     1 1234                            1 1357
     2 2413                            3 3175
     3 3142                            5 5713
     4 4321                            7 7531

    Table 11.4.22 Operation ta-       Table 11.4.23 Operation ta-
    ble for the group U5              ble for the group U8

                                                                                                    
    Computing Modular Multiplicative Inverses. Unlike the nice neat formula
for additive inverses mod n, multiplicative inverses can most easily computed
by applying Bézout's lemma. If a is an element of the group Un, then by
definition gcd(n, a) = 1, and so there exist integers s and t such that 1 = ns+at.
They can be computed with the Extended Euclidean Algorithm.

    1 = ns + at  at = 1 + (-s)n  a ×n t = 1
CHAPTER 11. ALGEBRAIC STRUCTURES  290

Since t might not be in Un you might need take the remainder after dividing
it by n. Normally, that involves simply adding n to t.

    For example, in U2048, if we want the muliplicative inverse of 1001, we run
the Extended Euclidean Algorithm and find that

                   gcd(2048, 1001) = 1 = 457 · 2048 + (-935) · 1001

Thus, the multiplicative inverse of 1001 is 2048-935 = 1113. See the SageMath
Note below to see how to run the Extended Euclidean Algorithm.

11.4.5 SageMath Note - Modular Arithmetic

Sage inherits the basic integer division functions from Python that compute a
quotient and remainder in integer division. For example, here is how to divide
561 into 2017 and get the quotient and remainder.

 a=2017
 b=561
 [q,r]=[a//b,a%b]
 [q,r]

  [3, 334]

    In Sage, gcd is the greatest common divisor function. It can be used
in two ways. For the gcd of 2343 and 4319 we can evaluate the expression
gcd(2343, 4319). If we are working with a fixed modulus m that has a value es-
tablished in your Sage session, the expression m.gcd(k) to compute the greatest
common divisor of m and any integer value k. The extended Euclidean algo-
rithm can also be called upon with xgcd:

 a=2017
 b=561
 print(gcd(a,b))
 print(xgcd(a,b))

 1
  (1, -173, 622)

    Sage has some extremely powerful tool for working with groups. The inte-
gers modulo n are represented by the expression Integers(n) and the addition
and multiplications tables can be generated as follows.

 R = Integers(6)
 print(R.addition_table( ' elements '))
 print(R.multiplication_table( ' elements '))

 + 012345
   +------------

  0| 0 1 2 3 4 5
  1| 1 2 3 4 5 0
  2| 2 3 4 5 0 1
  3| 3 4 5 0 1 2
  4| 4 5 0 1 2 3
  5| 5 0 1 2 3 4

 * 012345
   +------------

  0| 0 0 0 0 0 0
  1| 0 1 2 3 4 5
CHAPTER 11. ALGEBRAIC STRUCTURES  291

  2| 0 2 4 0 2 4
  3| 0 3 0 3 0 3
  4| 0 4 2 0 4 2
  5| 0 5 4 3 2 1

    Once we have assigned R a value of Integers(6), we can do calculations by
wrapping R() around the integers 0 through 5. Here is a list containing the
mod 6 sum and product, respectively, of 5 and 4:

 [R(5)+R(4), R(5)*R(4)]

  [3, 2]

    Generating the multiplication table for the family of groups Un takes a bit
more code. Here we restrict the allowed inputs to be integers from 2 to 64.

 def U_table(n):
         if n.parent()!=2.parent() or n < 2 or n > 64:
                return "input error/out of range"
         R=Integers(n)
         els =[]
         for k in filter(lambda k:gcd(n,k)==1,range(n)):
                els = els +[ str (k)]
         return
               R.multiplication_table(elements=els ,names="elements")

 U_table (18)

   * 1 5 7 11 13 17
     +------------------

   1| 1 5 7 11 13 17
   5| 5 7 17 1 11 13
   7| 7 17 13 5 1 11
  11| 11 1 5 13 17 7
  13| 13 11 1 17 7 5
  17| 17 13 11 7 5 1

11.4.6 Exercises

1. Determine the greatest common divisors of the following pairs of integers
      without using any computational assistance.

        (a) 23 · 32 · 5 and 22 · 3 · 52 · 7
        (b) 7! and 3 · 5 · 7 · 9 · 11 · 13
         (c) 194 and 195

        (d) 12112 and 0
2. Find all possible values of the following, assuming that m is a positive

      integer.

        (a) gcd(m + 1, m)

        (b) gcd(m + 2, m)

         (c) gcd(m + 4, m)
3. Calculate:
CHAPTER 11. ALGEBRAIC STRUCTURES                                      292

(a) 7 +8 3                       (f) 6 ×8 (2 +8 5)

(b) 7 ×8 3                       (g) 3 ×5 3 ×5 3 ×5 3  34( mod5)
(c) 4 ×8 4                       (h) 2 ×11 7
(d) 10 +12 2

(e) 6 ×8 2 +8 6 ×8 5             (i) 2 ×14 7

4. List the additive inverses of the following elements:

        (a) 4, 6, 9 in Z10

        (b) 16, 25, 40 in Z50
5. In the group Z11 , what are:

        (a) 3(4)?

(b) 36(4)?

         (c) How could you efficiently compute m(4), m  Z?
6. When defining notice that we could define this operation on all integers,

      but we restricted the set to Zn to satisfy the properties of a group. Can
      you explain what goes wrong if we define +n on all of the integers?
7. A student is asked to solve the following equations under the requirement
      that all arithmetic should be done in Z2. List all solutions.

        (a) x2 + 1 = 0.

        (b) x2 + x + 1 = 0.

8. Determine the solutions of the equations in Exercise 7 but in Z5.
9.

(a) Write out the operation table for ×14 on {1, 3, 5, 9, 11, 13}, and con-
     vince your self that this is a group.

        (b) Let Un be the elements of Zn that have inverses with respect to ×n.
              Convince yourself that Un is a group under ×n.

         (c) Prove that the elements of Un are those elements a  Zn such that
              gcd(n, a) = 1. You may use Theorem 11.4.9 in this proof.

10. Prove the division property, Theorem 11.4.1.

      Hint. Prove by induction on m that you can divide any positive integer
      into m. That is, let p(m) be "For all n greater than zero, there exist
      unique integers q and r such that . . . ." In the induction step, divide n
      into m - n.
11. Suppose f : Z17  Z17 such f (i) = a ×17 i +17 b where a and b are integer
      constants. Furthermore, assume that f (1) = 11 and f (2) = 4. Find a
      formula for f (i) and also find a formula for the inverse of f .

12. Write out the operation table for mod 10 multiplication on T =
      {0, 2, 4, 6, 8}. Is [T ; ×10] a monoid? Is it a group?

13. Given that 1 = 2021 · (-169) + 450 · 759, explain why 450 is an element
      of the group U2021 and determine its inverse in that group.

14. Let n = 2021. Solve 450 ×n x = 321 for x in the group Un
15. Let p be an odd prime. Find all solutions to the equation x2 = x×n x = 1

      in the group Up.
CHAPTER 11. ALGEBRAIC STRUCTURES                                           293

16. It was observed above that in doing modular arithmetic, one can replace
      an element of Zn with any other element of its equivalence class modulo n.
      For example, if one is computing 452 ×461 7, the alternative to multiplying
      452 time 7 and then dividing by 461 to get the remainder in Z461, we can
      replace 452 with -9 and get a product of -63 which is conguent of 398.
      Use this "trick" to compute the following without the use of a calculator.

        (a) 898 ×1001 998

        (b) 7710 mod 81

         (c) The solution to 196 ×197 x = 120
17. We associate the set Zn = {0, 1, 2, ..., n - 1} with the addition modulo n,

      +n, because the pair [Zn; +n] form a group. Why must we use a matching
      modulus? Explain why by considering the following two examples.

        (a) [Z3, +2]
        (b) [Z3, +4]

11.5 Subsystems

11.5.1 Definition

The subsystem is a fundamental concept of algebra at the universal level.

Definition 11.5.1 Subsystem. If [V ; 1, . . . , n] is an algebraic system

of a certain kind and W is a subset of V , then W is a subsystem of V if

[W ; 1, . . . , n] is an algebraic system of the same kind as V . The usual notation

for "W is a subsystem of V " is W  V .                                     

Since the definition of a subsystem is at the universal level, we can cite

examples of the concept of subsystems at both the axiomatic and concrete

level.

Example 11.5.2 Examples of Subsystems.

(a) (Axiomatic) If [G; ] is a group, and H is a subset of G, then H is a
     subgroup of G if [H; ] is a group.

(b) (Concrete) U = {-1, 1} is a subgroup of [R; ·]. Take the time now to
     write out the multiplication table of U and convince yourself that [U ; ·]
     is a group.

(c) (Concrete) The even integers, 2Z = {2k : k is an integer} is a subgroup
     of [Z; +]. Convince yourself of this fact.

(d) (Concrete) The set of nonnegative integers is not a subgroup of [Z; +].
     All of the group axioms are true for this subset except one: no positive
     integer has a positive additive inverse. Therefore, the inverse property is
     not true. Note that every group axiom must be true for a subset to be a
     subgroup.

(e) (Axiomatic) If M is a monoid and P is a subset of M , then P is a
     submonoid of M if P is a monoid.

(f) (Concrete) If B is the set of strings of 0's and 1's of length zero or more
    with the operation of concatenation, then two examples of submonoids
    of B are: (i) the set of strings of even length, and (ii) the set of strings
CHAPTER 11. ALGEBRAIC STRUCTURES  294

       that contain no 0's. The set of strings of length less than 50 is not a
       submonoid because it isn't closed under concatenation. Why isn't the
       set of strings of length 50 or more a submonoid of B?

                                                                                                     

11.5.2 Subgroups

For the remainder of this section, we will concentrate on the properties of
subgroups. The first order of business is to establish a systematic way of
determining whether a subset of a group is a subgroup.

Theorem 11.5.3 Subgroup Conditions. To determine whether H, a subset
of group [G; ], is a subgroup, it is sufficient to prove:

  (a) H is closed under ; that is, a, b  H  a  b  H;

  (b) H contains the identity element for ; and

  (c) H contains the inverse of each of its elements; that is, a  H  a-1  H.
Proof. Our proof consists of verifying that if the three properties above are
true, then all the axioms of a group are true for [H; ]. By Condition (a), 
can be considered an operation on H. The associative, identity, and inverse
properties are the axioms that are needed. The identity and inverse properties
are true by conditions (b) and (c), respectively, leaving only the associative
property. Since, [G; ] is a group, a  (b  c) = (a  b)  c for all a, b, c  G.
Certainly, if this equation is true for all choices of three elements from G, it
will be true for all choices of three elements from H, since H is a subset of G.

                                                                                                     
    For every group with at least two elements, there are at least two subgroups:
they are the whole group and {e}. Since these two are automatic, they are not
considered very interesting and are called the improper subgroups of the group;
{e} is sometimes referred to as the trivial subgroup. All other subgroups, if
there are any, are called proper subgroups.
    We can apply Theorem 11.5.3 at both the concrete and axiomatic levels.

Example 11.5.4 Applying Conditions for a Subgroup.

  (a) (Concrete) We can verify that 2Z  Z, as stated in Example 11.5.2.
       Whenever you want to discuss a subset, you must find some convenient
       way of describing its elements. An element of 2Z can be described as 2
       times an integer; that is, a  2Z is equivalent to (k)Z(a = 2k). Now
       we can verify that the three conditions of Theorem 11.5.3 are true for
       2Z. First, if a, b  2Z, then there exist j, k  Z such that a = 2j and
       b = 2k. A common error is to write something like a = 2j and b = 2j.
       This would mean that a = b, which is not necessarily true. That is why
       two different variables are needed to describe a and b. Returning to our
       proof, we can add a and b: a + b = 2j + 2k = 2(j + k). Since j + k is
       an integer, a + b is an element of 2Z. Second, the identity, 0, belongs
       to 2Z (0 = 2(0)). Finally, if a  2Z and a = 2k, -a = -(2k) = 2(-k),
       and -k  Z, therefore, -a  2Z. By Theorem 11.5.3, 2Z  Z. How
       would this argument change if you were asked to prove that 3Z  Z? or
       nZ  Z, n  2?

  (b) (Concrete) We can prove that H = {0, 3, 6, 9} is a subgroup of Z12. First,
       for each ordered pair (a, b)  H × H, a +12 b is in H. This can be checked
       without too much trouble since |H × H| = 16. Thus we can conclude
       that H is closed under +12. Second, 0  H. Third, -0 = 0, -3 = 9,
CHAPTER 11. ALGEBRAIC STRUCTURES                            295

-6 = 6, and -9 = 3. Therefore, the inverse of each element of H is in
H.

  (c) (Axiomatic) If H and K are both subgroups of a group G, then H K is a
       subgroup of G. To justify this statement, we have no concrete information
       to work with, only the facts that H  G and K  G. Our proof that
       H  K  G reflects this and is an exercise in applying the definitions of
       intersection and subgroup, (i) If a and b are elements of H  K, then a
       and b both belong to H, and since H  G, a  b must be an element of H.
       Similarly, a  b  K; therefore, a  b  H  K. (ii) The identity of G must
       belong to both H and K; hence it belongs to H  K. (iii) If a  H  K,
       then a  H, and since H  G, a-1  H. Similarly, a-1  K. Hence, by
       the theorem, H  K  G. Now that this fact has been established, we
       can apply it to any pair of subgroups of any group. For example, since
       2Z and 3Z are both subgroups of [Z; +], 2Z  3Z is also a subgroup of Z.
       Note that if a  2Z  3Z, a must have a factor of 3; that is, there exists
       k  Z such that a = 3k. In addition, a must be even, therefore k must
       be even. There exists j  Z such that k = 2j, therefore a = 3(2j) = 6j.
       This shows that 2Z  3Z  6Z. The opposite containment can easily be
       established; therefore, 2Z  3Z = 6Z.

                                                                                                     
    Given a finite group, we can apply Theorem 11.3.15 to obtain a simpler
condition for a subset to be a subgroup.

Theorem 11.5.5 Condition for a Subgroup of Finite Group. Given
that [G; ] is a finite group and H is a nonempty subset of G, if H is closed
under  , then H is a subgroup of G.
Proof. In this proof, we demonstrate that Conditions (b) and (c) of Theo-
rem 11.5.3 follow from the closure of H under , which is condition (a) of the
theorem. First, select any element of H; call it . The powers of  : 1, 2,
3, . . . are all in H by the closure property. By Theorem 11.3.15, there exists
m, m  |G|, such that m = e; hence e  H. To prove that (c) is true, we let
a be any element of H. If a = e, then a-1 is in H since e-1 = e. If a = e,
aq = e for some q between 2 and |G| and

e = aq = aq-1  a

Therefore, a-1 = aq-1 , which belongs to H since q - 1  1.  

11.5.3 Sage Note - Applying the condition for a subgroup
          of a finite group

To determine whether H1 = {0, 5, 10} and H2 = {0, 4, 8, 12} are subgroups
of Z15, we need only write out the addition tables (modulo 15) for these sets.
This is easy to do with a bit of Sage code that we include below and then for
any modulus and subset, we can generate the body of an addition table. The
code is set up for H1 but can be easily adjusted for H2.

 def addition_table(n,H):
         for a in H:
                line =[]
                for b in H:
                       line +=[( a+b)%n]
                print(line)

 addition_table (15 , Set ([0 ,5 ,10]) )
CHAPTER 11. ALGEBRAIC STRUCTURES                                                                         296

  [0, 10, 5]
  [10, 5, 0]
  [5, 0, 10]

    Note that H1 is a subgroup of Z15. Since the interior of the addition table
for H2 contains elements that are outside of H2, H2 is not a subgroup of Z15.

11.5.4 Cyclic Subgroups

One kind of subgroup that merits special mention due to its simplicity is the
cyclic subgroup.

Definition 11.5.6 Cyclic Subgroup. If G is a group and a  G, the cyclic
subgroup generated by a, a, is the set of all powers of a:

                  a = {an : n  Z} .

We refer to a as a generator of subgroup a.
    A subgroup H of a group G is cyclic if there exists a  H such that H = a.
                                                                                                     

Definition 11.5.7 Cyclic Group. A group G is cyclic if there exists   G

such that  = G.                                                                                          

Note 11.5.8 If the operation on G is additive, then a = {(n)a : n  Z}.

Definition 11.5.9 Order of a Group Element. The order of an element

a of group G is the number of elements in the cyclic subgroup of G generated

by a. The order of a is denoted ord(a).                                                                  

Example 11.5.10

(a) In [R; ·], 2 = {2n : n  Z} =  .  .   .  ,  1   ,  1  ,  1  ,  1  ,  1,  2,  4,  8,  16,  .  .  .  .
                                               16     8     4     2

(b) In Z15, 6 = {0, 3, 6, 9, 12}. Here is why: If G is finite, you need list
     only the positive powers (or multiples) of a up to the first occurrence
     of the identity to obtain all of a. In Z15 , the multiples of 6 are 6,
     (2)6 = 12, (3)6 = 3, (4)6 = 9, and (5)6 = 0. Note that {0, 3, 6, 9, 12}
     is also 3,9, and 12. This shows that a cyclic subgroup can have
     different generators.

                                                                                                    
    If you want to list the cyclic subgroups of a group, the following theorem
can save you some time.

Theorem 11.5.11 If a is an element of group G, then a = a-1.
    This is an easy way of seeing, for example, that 9 in Z15 equals 6, since

-6 = 9.

11.5.5 Exercises
CHAPTER 11. ALGEBRAIC STRUCTURES  297

1. Which of the following subsets of the real numbers is a subgroup of [R; +]?
        (a) the rational numbers

        (b) the positive real numbers

         (c) {k/2 | k is an integer}
        (d) {2k | k is an integer}

         (e) {x | -100  x  100}
2. Describe in simpler terms the following subgroups of Z:

        (a) 5Z  4Z
        (b) 4Z  6Z (be careful)
         (c) the only finite subgroup of Z
3. Find at least two proper subgroups of R3 , the set of 3 × 3 rook matrices
      (see Exercise 11.2.4.5).
4. Let H and K be subgroups of G with elements a, x, y  G located in the
      following Venn diagram. Where should you place the following elements
      in Figure 11.5.12?

        (a) e

        (b) a-1

         (c) x  y

      Figure 11.5.12 Figure for exercise 4
5.

        (a) List the cyclic subgroups of Z6 and draw an ordering diagram for
              the relation "is a subset of" on these subgroups.

        (b) Do the same for Z12.

         (c) Do the same for Z8.

        (d) On the basis of your results in parts a, b, and c, what would you
              expect if you did the same with Z24?

6. Subgroups generated by subsets of a group. The concept of a cyclic
      subgroup is a special case of the concept that we will discuss here. Let
      [G; ] be a group and S a nonempty subset of G. Define the set S
      recursively by:

          · If a  S, then a  S.

          · If a, b  S, then a  b  S, and
CHAPTER 11. ALGEBRAIC STRUCTURES  298

          · If a  S, then a-1  S.

        (a) By its definition, S has all of the properties needed to be a sub-
              group of G. The only thing that isn't obvious is that the identity of
              G is in S. Prove that the identity of G is in S.

        (b) What is {9, 15} in[Z; +]?

         (c) Prove that if H  G and S  H, then S  H. This proves that
              S is contained in every subgroup of G that contains S; that is,
              S =  H.

                                S H,H G

        (d) Describe {0.5, 3} in [R+; ·] and in [R; +].

         (e) If j, k  Z, {j, k} is a cyclic subgroup of Z. In terms of j and k,
              what is a generator of {j, k}?

7. Prove that if H, K  G, and H  K = G, then H = G or K = G.
      Hint. Use an indirect argument.

8. Prove that the order of an element, a of a group is the least positive
      integer, k, such that ak is the identity of the group.

11.6 Direct Products

11.6.1 Definition

Our second universal algebraic concept lets us look in the opposite direction
from subsystems. Direct products allow us to create larger systems. In the
following definition, we avoid complicating the notation by not specifying how
many operations the systems have.

Definition 11.6.1 Direct Product. If [Vi; i, i, . . .], i = 1, 2, . . . , n are
algebraic systems of the same kind, then the direct product of these systems is
V = V1 × V2 × · · · × Vn , with operations defined below. The elements of V are
n-tuples of the form (a1, a2, . . . , an), where ak  Vk, k = 1, . . . , n. The systems
V1, V2, . . . , Vn are called the factors of V . There are as many operations on V
as there are in the factors. Each of these operations is defined componentwise:

    If (a1, a2, ..., an) , (b1, b2, ..., bn)  V ,

        (a1, a2, . . . , an)  (b1, b2, . . . , bn) = (a1 1 b1, a2 2 b2, . . . , an n bn)
        (a1, a2, . . . , an)  (b1, b2, . . . , bn) = (a1 1 b1, a2 2 b2, . . . , an n bn)

                                                 etc.

                                                                                                     
Example 11.6.2 A Direct Product of Monoids. Consider the monoids N
(the set of natural numbers with addition) and B (the set of finite strings of
0's and 1's with concatenation). The direct product of N with B is a monoid.
We illustrate its operation, which we will denote by , with examples:

                    (4, 001)  (3, 11) = (4 + 3, 001 + 11) = (7, 00111)
                              (0, 11010)  (3, 01) = (3, 1101001)

             (0, )  (129, 00011) = (0 + 129,  + 00011) = (129, 00011)
                             (2, 01)  (8, 10) = (10, 0110), and
                                 (8, 10)  (2, 01) = (10, 1001)
CHAPTER 11. ALGEBRAIC STRUCTURES         299

Note that our new monoid is not commutative. What is the identity for  ?
                                                                                                    

    The definiton of a Direct Product is quite general and may be confusing to
some. Here is the definiton of the direct product of two groups. The definition
extends easily to the direct product of three or more groups.

Definition 11.6.3 Direct Product of Two Groups. Let [G1; 1] and
[G2; 2] be two groups. Their direct product is the system [G1 × G2; ] with
domain equal to the Cartesian product of the domains of the two groups and
with the coordinatewise operation  defined by

(a1, b1)  (a2, b2) = (a1 1 a2, b1 2 b2)

for (a1, b1), (a2, b2)  G1 × G2.         

Figure 11.6.4 Concurrent calculation in a direct product

Note 11.6.5

  (a) On notation. If two or more consecutive factors in a direct product are
       identical, it is common to combine them using exponential notation. For
       example, Z × Z × R can be written Z2 × R, and R × R × R × R can be
       written R4. This is purely a notational convenience; no exponentiation
       is really taking place.

  (b) We call the operations in a direct product componentwise operations,
       and they are indeed operations on V . If two n-tuples, a and b, are selected
       from V , the first components of a and b, a1 and b1, are operated on with
       1 to obtain a1 1 b1, the first component of a  b. Note that since 1
       is an operation on V1, a1 1 b1 is an element of V1. Similarly, all other
       components of a  b, as they are defined, belong to their proper sets.

  (c) One significant fact about componentwise operations is that the compo-
       nents of the result can all be computed at the same time (concurrently).
       The time required to compute in a direct product can be reduced to a
       length of time that is not much longer than the maximum amount of
       time needed to compute in the factors.

  (d) A direct product of algebraic systems is not always an algebraic system of
       the same type as its factors. This is due to the fact that certain axioms
       that are true for the factors may not be true for the set of n-tuples.
       This situation does not occur with groups however. You will find that
       whenever a new type of algebraic system is introduced, call it type T , one
       of the first theorems that is usually proven, if possible, is that the direct
       product of two or more systems of type T is a system of type T .
CHAPTER 11. ALGEBRAIC STRUCTURES                          300

11.6.2 Direct Products of Groups

We will explore properties of direct products of groups and examine some
concrete examples

Theorem 11.6.6 The Direct Product of Groups is a Group. The direct
product of two or more groups is a group; that is, the algebraic properties of
a system obtained by taking the direct product of two or more groups includes
the group axioms.
Proof. We will only present the proof of this theorem for the direct product
of two groups. Some slight revisions can be made to produce a proof for any
number of factors.
Stating that the direct product of two groups is a group is a short way of
saying that if [G1; 1] and [G2; 2] are groups, then [G1 × G2; ] is also a group,
where  is the componentwise operation on G1 × G2. Associativity of  : If
a, b, c  G1 × G2,

a  (b  c) = (a1, a2)  ((b1, b2)  (c1, c2))
             = (a1, a2)  (b1 1 c1, b2 2 c2)
             = (a1 1 (b1 1 c1) , a2 2 (b2 2 c2))
             = ((a1 1 b1) 1 c1, (a2 2 b2) 2 c2)
             = (a1 1 b1, a2 2 b2)  (c1, c2)
             = ((a1, a2)  (b1, b2))  (c1, c2)
             = (a  b)  c

Notice how the associativity property hinges on the associativity in each factor.

An identity for : As you might expect, if e1 and e2 are identities for G1 and
G2, respectively, then e = (e1, e2) is the identity for G1 × G2. If a  G1 × G2,

                        a  e = (a1, a2)  (e1, e2)
                              = (a1 1 e1, a2 2 e2)
                              = (a1, a2) = a

Similarly, e  a = a.

Inverses in G1 × G2: The inverse of an element is determined componentwise
a-1 = (a1, a2) -1 = a1-1, a2-1 . To verify, we compute a  a-1 :

                        a  a-1 = (a1, a2)  a1-1, a2-1
                                  = a1 1 a1-1, a2 2 a2-1
                                  = (e1, e2) = e

Similarly, a-1  a = e.                                    

Example 11.6.7 Some New Groups.

(a) If n  2, Z2n , the direct product of n factors of Z2, is a group with
     2n elements. We will take a closer look at Z23 = Z2 × Z2 × Z2. The
     elements of this group are triples of zeros and ones. Since the operation
     on Z2 is +2, we will use the symbol + for the operation on Z23 . Two
     of the eight triples in the group are a = (1, 0, 1) and b = (0, 0, 1). Their
    "sum" is a + b = (1 +2 0, 0 +2 0, 1 +2 1) = (1, 0, 0). One interesting fact
     about this group is that each element is its own inverse. For example
     a + a = (1, 0, 1) + (1, 0, 1) = (0, 0, 0); therefore -a = a. We use the
     additive notation for the inverse of a because we are using a form of
CHAPTER 11. ALGEBRAIC STRUCTURES          301

     addition. Note that {(0, 0, 0), (1, 0, 1)} is a subgroup of Z23. Write out
     the "addition" table for this set and apply Theorem 11.5.5. The same
     can be said for any set consisting of (0, 0, 0) and another element of Z23.

(b) The direct product of the positive real numbers with the integers modulo
     4, R+ × Z4 is an infinite group since one of its factors is infinite. The
     operations on the factors are multiplication and modular addition, so we
     will select the neutral symbol  for the operation on R+ ×Z4. If a = (4, 3)
     and b = (0.5, 2), then

                      a  b = (4, 3)  (0.5, 2) = (4 · 0.5, 3 +4 2) = (2, 1)
                           b2 = b  b = (0.5, 2)  (0.5, 2) = (0.25, 0)
                                   a-1 = 4-1, -3 = (0.25, 1)
                                    b-1 = 0.5-1, -2 = (2, 2)

It would be incorrect to say that Z4 is a subgroup of R+ × Z4 , but
there is a subgroup of the direct product that closely resembles Z4. It is
{(1, 0), (1, 1), (1, 2), (1, 3)}. Its table is

        (1, 0)  (1, 1)  (1, 2)    (1, 3)
(1, 0)  (1, 0)  (1, 1)  (1, 2)    (1, 3)
(1, 1)  (1, 1)  (1, 2)  (1, 3)    (1, 0)
(1, 2)  (1, 2)  (1, 3)  (1, 0)    (1, 1)
(1, 3)  (1, 3)  (1, 0)  (1, 1)    (1, 2)

Imagine erasing (1, ) throughout the table and writing +4 in place of .
What would you get? We will explore this phenomenon in detail in the
next section.

The whole direct product could be visualized as four parallel half-lines
labeled 0, 1, 2, and 3 as in Figure 11.6.8. On the kth line, the point
that lies x units to the right of the zero mark would be (x, k). The set
{(2n, (n)1) | n  Z}, which is depicted on the figure is a subgroup of
R+ × Z4. What cyclic subgroup is it?

The answer: (2, 1) or (1/2, 3). There are two different generators.

Figure 11.6.8 Visualization of the group R+ × Z4
                                                                                                     

     A more conventional direct product is R2, the direct product of two factors
of [R; +]. The operation on R2 is componentwise addition; hence we will use
+ as the operation symbol for this group. You should be familiar with this
CHAPTER 11. ALGEBRAIC STRUCTURES  302

operation, since it is identical to addition of 2 × 1 matrices. The Cartesian
coordinate system can be used to visualize R2 geometrically. We plot the pair
(s, t) on the plane in the usual way: s units along the x axis and t units along
the y axis. There is a variety of different subgroups of R2 , a few of which are:

  (a) {(x, 0) | x  R}, all of the points on the x axis;

  (b) {(x, y) | 2x - y = 0}, all of the points that are on the line 2x - y = 0;

  (c) If a, b  R, {(x, y) | ax + by = 0}. The first two subgroups are special
       cases of this one, which represents any line that passes through the origin.

  (d) {(x, y) | 2x - y = k, k  Z}, a union of a set of lines that are parallel to
       2x - y = 0.

  (e) {(n, 3n) | n  Z}, which is the only countable subgroup that we have
       listed.

    We will leave it to the reader to verify that these sets are subgroups. We
will only point out how the fourth example, call it H, is closed under "addition."
If a = (p, q) and b = (s, t) and both belong to H, then 2p-q = j and 2s-t = k,
where both j and k are integers. a + b = (p, q) + (s, t) = (p + s, q + t) We can
determine whether a+b belongs to H by deciding whether or not 2(p+s)-(q+t)
is an integer:

                          2(p + s) - (q + t) = 2p + 2s - q - t
                                                 = (2p - q) + (2s - t)
                                                 =j+k

Since j and k are integers, so is j + k. This completes a proof that H is closed
under the operation of R2.

    Several useful facts can be stated in regards to the direct product of two or
more groups. We will combine them into one theorem, which we will present
with no proof. Parts a and c were derived for n = 2 in the proof of Theo-
rem 11.6.6.
Theorem 11.6.9 Properties of Direct Products of Groups. If G =
G1 × G2 × · · · × Gn is a direct product of n groups and (a1, a2, . . . , an)  G,
then:

  (a) The identity of G is (e1, e2, ..., en), where ek is the identity of Gk.

  (b) (a1, a2, ..., an) -1 = a1-1, a2-1, ..., an-1 .

  (c) (a1, a2, ..., an) m = (a1m, a2m, ..., anm) for all m  Z.

  (d) G is abelian if and only if each of the factors G1, G2, . . . , Gn is abelian.

  (e) lf H1, H2, . . . , Hn are subgroups of the corresponding factors, then H1 ×
       H2 × · · · × Hn is a subgroup of G.

    Not all subgroups of a direct product can be created using part e of The-
orem 11.6.9. For example, {(n, n) | n  Z} is a subgroup of Z2, but is not a
direct product of two subgroups of Z.
Example 11.6.10 Linked Lists using a Direct Product - XOR Linked
Lists. Using the identity (x + y) + x = y, in Z2, we can devise a scheme for
representing a symmetrically linked list using only one link field. A symmetri-
cally linked list is a list in which each node contains a pointer to its immediate
successor and its immediate predecessor (see Figure 11.6.11). If the pointers
CHAPTER 11. ALGEBRAIC STRUCTURES  303

are n-digit binary addresses, then each pointer can be taken as an element
of Z2n. Lists of this type can be accomplished using cells with only one link.
In place of a left and a right pointer, the only "link" is the value of the sum
(left link) + (right link). All standard list operations (merge, insert, delete,
traverse, and so on) are possible with this structure, provided that you know
the value of the nil pointer and the address, f , of the first (i. e., leftmost)
cell. Since first f. left is nil, we can recover f. right by adding the value of nil:
f + nil = ( nil + f.right) + nil = f.right, which is the address of the second
item. Now if we temporarily retain the address, s, of the second cell, we can
recover the address of the third item. The link field of the second item contains
the sum s. left + s. right = first + third. Therefore

                    (first + third) + first = s + s.left

                                                = (s.left + s.right) + s.left

                                                = s.right

                                                = third

    We no longer need the address of the first cell, only the second and third,
to recover the fourth address, and so forth.

Figure 11.6.11 Symmetric Linked Lists

    The following more formal algorithm uses names that reflects the timing of
the visits.

    Given a symmetric list, a traversal of the list is accomplished as follows,
where first is the address of the first cell. We presume that each item has some
information that is represented by item.info and a field called item.link that is
the sum of the left and right links.

Table 11.6.12

                    (1) yesterday =nil
                    (2) today =first
                    (3) while today = nil:

                             (3.1)Write(today.info)
                             (3.2)tomorrow = today.link + yesterday
                             (3.3)yesterday = today
                             (3.4)today = tomorrow.

    At any point in this algorithm it would be quite easy to insert a cell between
today and tomorrow. Can you describe how this would be accomplished?

    This implementation of doubly linked lists is often referred to as an XOR
linked list. For more information see the Wikipedia page en.wikipedia.org/
CHAPTER 11. ALGEBRAIC STRUCTURES  304

wiki/XOR_linked_list.             

11.6.3 Exercises

1. Write out the group table of Z2 × Z3 and find the two proper subgroups
      of this group.

2. List more examples of proper subgroups of R2 that are different from the
      ones listed in this section.

3. Algebraic properties of the n-cube.

        (a) The four elements of Z22 can be visualized geometrically as the four
              corners of the 2-cube. Algebraically describe the statements:

                (i) Corners a and b are adjacent.
               (ii) Corners a and b are diagonally opposite one another.

        (b) The eight elements of Z23 can be visualized as the eight corners
              of the 3-cube. One face contains Z2 × Z2 × {0} and the opposite
              face contains the remaining four elements so that (a, b, 1) is behind
             (a, b, 0). As in part a, describe statements i and ii algebraically.

         (c) If you could imagine a geometric figure similar to the square or
              cube in n dimensions, and its corners were labeled by elements of
              Z2n as in parts a and b, how would statements i and ii be expressed
              algebraically?

4.

        (a) Suppose that you were to be given a group [G; ] and asked to solve
              the equation x  x = e. Without knowing the group, can you antici-
              pate how many solutions there will be?

        (b) Answer the same question as part a for the equation x  x = x.
5. Which of the following sets are subgroups of Z × Z? Give a reason for

      any negative answers.

        (a) {0}

        (b) {(2j, 2k) | j, k  Z}
         (c) {(2j + 1, 2k) | j, k  Z}
        (d) {(n, n2) | n  Z}
         (e) {(j, k) | j + k is even}
6. Determine the following values in the group Z3 × R:
        (a) (2, 1)  (1, 2)

        (b) the identity element

         (c) (1, 1/2)-1

11.7 Isomorphisms

The following informal definition of isomorphic systems should be memorized.
No matter how technical a discussion about isomorphic systems becomes, keep
in mind that this is the essence of the concept.
CHAPTER 11. ALGEBRAIC STRUCTURES  305

Definition 11.7.1 Isomorphic Systems/Isomorphism - Informal Ver-

sion. Two algebraic systems are isomorphic if there exists a translation rule

between them so that any true statement in one system can be translated to a

true statement in the other.      

Example 11.7.2 How to Do Greek Arithmetic. Imagine that you are

a six-year-old child who has been reared in an English-speaking family, has

moved to Greece, and has been enrolled in a Greek school. Suppose that your

new teacher asks the class to do the following addition problem that has been

written out in Greek.

 ´   ´ o´  ____

The natural thing for you to do is to take out your Greek-English/English-
Greek dictionary and translate the Greek words to English, as outlined in
Figure 11.7.3 After you've solved the problem, you can consult the same dic-
tionary to find the proper Greek word that the teacher wants. Although this
is not the recommended method of learning a foreign language, it will surely
yield the correct answer to the problem. Mathematically, we may say that the
system of Greek integers with addition () is isomorphic to English integers
with addition (plus). The problem of translation between natural languages is
more difficult than this though, because two complete natural languages are
not isomorphic, or at least the isomorphism between them is not contained in
a simple dictionary.

Figure 11.7.3 Solution of a Greek arithmetic problem

                                                                                                    
Example 11.7.4 Software Implementation of Sets. In this example,
we will describe how set variables can be implemented on a computer. We
will describe the two systems first and then describe the isomorphism between
them.

    System 1: The power set of {1, 2, 3, 4, 5} with the operation union, . For
simplicity, we will only discuss union. However, the other operations are im-
plemented in a similar way.

    System 2: Strings of five bits of computer memory with an OR gate. In-
dividual bit values are either zero or one, so the elements of this system can
be visualized as sequences of five 0's and 1's. An OR gate, Figure 11.7.5, is a
small piece of computer hardware that accepts two bit values at any one time
and outputs either a zero or one, depending on the inputs. The output of an
OR gate is one, except when the two bit values that it accepts are both zero, in
which case the output is zero. The operation on this system actually consists
of sequentially inputting the values of two bit strings into the OR gate. The
result will be a new string of five 0's and 1's. An alternate method of operating
in this system is to use five OR gates and to input corresponding pairs of bits
from the input strings into the gates concurrently.
CHAPTER 11. ALGEBRAIC STRUCTURES  306

Figure 11.7.5 Translation between sets and strings of bits
    The Isomorphism: Since each system has only one operation, it is clear that

union and the OR gate translate into one another. The translation between
sets and bit strings is easiest to describe by showing how to construct a set
from a bit string. If a1a2a3a4a5, is a bit string in System 2, the set that it
translates to contains the number k if and only if ak equals 1. For example,
10001 is translated to the set {1, 5}, while the set {1, 2} is translated to 11000.
Now imagine that your computer is like the child who knows English and must
do a Greek problem. To execute a program that has code that includes the
set expression {1, 2}  {1, 5}, it will follow the same procedure as the child to
obtain the result, as shown in Figure 11.7.6.

Figure 11.7.6 Translation of a problem in set theory
                                                                                                     

11.7.1 Group Isomorphisms

Example 11.7.7 Multiplying without doing multiplication. This iso-
morphism is between [R+; ·] and [R; +]. Until the 1970s, when the price of
calculators dropped, multiplication and exponentiation were performed with
an isomorphism between these systems. The isomorphism (R+ to R) between
the two groups is that · is translated into + and any positive real number a is
translated to the logarithm of a. To translate back from R to R+ , you invert
the logarithm function. If base ten logarithms are used, an element of R, b,
will be translated to 10b. In pre-calculator days, the translation was done with
a table of logarithms or with a slide rule. An example of how the isomorphism
is used appears in Figure 11.7.8.

Figure 11.7.8 Multiplication using logarithms

                                                                                                    
    The following definition of an isomorphism between two groups is a more
formal one that appears in most abstract algebra texts. At first glance, it
appears different, it is really a slight variation on the informal definition. It
is the common definition because it is easy to apply; that is, given a function,
this definition tells you what to do to determine whether that function is an
isomorphism.
CHAPTER 11. ALGEBRAIC STRUCTURES                                       307

Definition 11.7.9 Group Isomorphism. If [G1; 1] and [G2; 2] are groups,
f : G1  G2 is an isomorphism from G1 into G2 if:

(1) f is a bijection, and

(2) f (a 1 b) = f (a) 2 f (b) for all a, b  G1

If such a function exists, then we say G1 is isomorphic to G2, denoted
G1 = G2.
                                                                       

We should note that "is isomorphic to" is an equivalence relation on the

set of all groups. We leave it to the reader to verify the following.

· The identity function on a group G is an isomorphism.

· Bijections have inverses, the inverse of an isomorphism is an isomorphism.

· The composition of any two isomorphisms that can be composed is an
   isomorphism.

Figure 11.7.10 Steps in proving that G1 and G2 are isomorphic

Note 11.7.11

  (a) There could be several different isomorphisms between the same pair
       of groups. Thus, if you are asked to demonstrate that two groups are
       isomorphic, your answer need not be unique.

  (b) Any application of this definition requires a procedure outlined in Fig-
       ure 11.7.10. The first condition, that an isomorphism be a bijection,
       reflects the fact that every true statement in the first group should have
       exactly one corresponding true statement in the second group. This is
       exactly why we run into difficulty in translating between two natural lan-
       guages. To see how Condition (b) of the formal definition is consistent
       with the informal definition, consider the function L : R+  R defined
       by L(x) = log10 x. The translation diagram between R+ and R for the
       multiplication problem a · b appears in Figure 11.7.12. We arrive at the
       same result by computing L-1(L(a) + L(b)) as we do by computing a · b.
       If we apply the function L to the two results, we get the same image:

          L(a · b) = L L-1(L(a) + L(b)) = L(a) + L(b)                  (11.7.1)

since L L-1(x) = x. Note that (11.7.1) is exactly Condition b of the
formal definition applied to the two groups R+ and R.
CHAPTER 11. ALGEBRAIC STRUCTURES                                     308

Figure 11.7.12 General Multiplication using logarithms

Example 11.7.13 Consider G =          1a  a  R with matrix multiplica-
                                      01

tion. The group [R; +] is isomorphic to G. Our translation rule is the function

f : R  G defined by f (a) =   1 a . Since groups have only one opera-
                              01

tion, there is no need to state explicitly that addition is translated to matrix

multiplication. That f is a bijection is clear from its definition.

    If a and b are any real numbers,

               f (a)f (b) = 1 a 1 b
                                      01  01

                             = 1 a+b
                                   01

                             = f (a + b)

    We can apply this translation rule to determine the inverse of a matrix in
G. We know that a + (-a) = 0 is a true statement in R. Using f to translate
this statement, we get

                                       f (a)f (-a) = f (0)

or

               1a             1 -a = 1 0
               01             01          01

therefore,

               1a             -1          1 -a
               01                         01
                                  =

                                                                                                     
The next theorem summarizes some of the general facts about group isomor-
phisms that are used most often in applications. We leave the proof to the
reader.

Theorem 11.7.14 Properties of Isomorphisms. If [G; ] and [H; ] are
groups with identities e and e, respectively, and T : G  H is an isomorphism
from G into H, then:

(a) T (e) = e

(b) T (a)-1 = T a-1 for all a  G, and

  (c) If K is a subgroup of G, then T (K) = {T (a) : a  K} is a subgroup of
       H and is isomorphic to K.

    "Is isomorphic to" is an equivalence relation on the set of all groups. There-
fore, the set of all groups is partitioned into equivalence classes, each equiva-
lence class containing groups that are isomorphic to one another.
CHAPTER 11. ALGEBRAIC STRUCTURES             309

11.7.2 The order sequence of a finite group

This topic is somewhat obscure. It doesn't appear in most texts, but is a nice
companion to degree sequences in graph theory. Recall that every undirected
graph has a degree sequence, and graphs with different degree sequences 9.1.31
are not isomorphic. This is a convenient way to identify non-isomorphic graphs.
We see below that order sequences play exactly the same role in identifying
whether two finite groups are isomorphic. Furthermore, identical order se-
quences of two finite groups give an excellent set of hints for constructing an
isomorphism, if one such exists. My collegue, Jim Propp, has been using this
idea for a while in his classes and I "discovered" it later. Neither of us can
claim originality. Much of the following discussion is paraphrased from Jim's
notes.

Definition 11.7.15 Order Sequence. The order sequence of a finite group

is the sequence whose terms are the respective orders of all the elements of the

group, arranged in increasing order.         

    In Z3 the element 0 has order 1, the element 1 has order 3, and the element
2 has order 3, so the order sequence of this group is 1,3,3.

    In Z4 the element 0 has order 1, the element 1 has order 4, the element 2 has
order 2, and the element 3 has order 4, so the order sequence of this group is

1,2,4,4. (Note that we have arranged the numbers 1,4,2,4 in increasing order.)

Theorem 11.7.16 If G1 and G2 are finite groups and f is an isomorphism
between them, with g  G1 and f (g)  G2, the order of g in G1 equals the order
of f (g) in G2.

    Consequently:

Corollary 11.7.17 If two groups are isomorphic, they have the same order
sequence.

    The theorem is a handy tools for proving that two particular groups are not
isomorphic. Consider the group Z2 × Z2; the element (0, 0) has order 1 while
the other elements (0, 1), (1, 0), and (1, 1) each have order 2, implying that the
order sequence is 1,2,2,2. Since this is different from the sequence 1,2,4,4, the
group Z2 × Z2 is not isomorphic to the group Z4.

    Order sequences are also useful in helping one find isomorphisms. Consider
the group U5 (the set {1, 2, 3, 4} with mod-5 multiplication). Its order sequence
is 1, 2, 4, 4, which suggests that it might be isomorphic to Z4. In fact, any
isomorphism f from Z4 to U5 must map 0 (the only element of order 1 in Z4)
to 1 (the only element of order 1 in U4) and must map 2 (the only element of
order 2 in Z4) to 4 (the only element of order 2 in U4). There are only two
bijections f from Z4 to U4 satisfying f (0) = 1 and f (2) = 4, so these are the
only two candidate isomorphisms (and both candidates turn out to be true
isomorphisms).

    The following code will compute the order sequence for the group of integers
mod n. The default value of n is 12 and you can change it in the last line of
input.

def order_sequence_Z(n):
^^IG = Integers(n)
^^Ios=[ ]
^^Ifor a in G:
^^ I ^^ Ios = os +[ a. order () ]
^^ Iprint ( sorted ( os ))

order_sequence_Z (12)
CHAPTER 11. ALGEBRAIC STRUCTURES          310

[1, 2, 3, 3, 4, 4, 6, 6, 12, 12, 12, 12]

11.7.3 Conditions for groups to not be isomorphic

How do you decide that two groups are not isomorphic to one another? The
negation of "G and H are isomorphic" is that no translation rule between G
and H exists. If G and H have different cardinalities, then no bijection from
G into H can exist. Hence they are not isomorphic. Given that |G| = |H|, it is
usually impractical to list all bijections from G into H and show that none of
them satisfy Condition b of the formal definition. The best way to prove that
two groups are not isomorphic is to find a true statement about one group that
is not true about the other group. We illustrate this method in the following
checklist that you can apply to most pairs of non-isomorphic groups in this
book.

    Assume that [G; ] and [H; ] are groups. The following are reasons for G
and H to be not isomorphic.

  (a) G and H do not have the same cardinality. For example, Z12 × Z5 can't
       be isomorphic to Z50 and [R; +] can't be isomorphic to [Q+; ·].

  (b) G is abelian and H is not abelian since a  b = b  a is always true in
       G, but T (a)  T (b) = T (b)  T (a) would not always be true. We have
       seen two groups with six elements that apply here. They are Z6 and the
       group of 3 × 3 rook matrices (see Exercise 11.2.4.5). The second group
       is non-abelian, therefore it can't be isomorphic to Z6.

  (c) G has a certain kind of subgroup that H doesn't have. Part (c) of
       Theorem 11.7.14 states that this cannot happen if G is isomorphic to
       H. [R; ·] and [R+; ·] are not isomorphic since R has a subgroup with
       two elements, {-1, 1}, while the proper subgroups of R+ are all infinite
       (convince yourself of this fact!).

  (d) The number of solutions of x  x = e in G is not equal to the number of
       solutions of y  y = e in H. Z8 is not isomorphic to Z23 since x +8 x = 0
       has two solutions, 0 and 4, while y + y = (0, 0, 0) is true for all y  Z23.
       If the operation in G is defined by a table, then the number of solutions
       of x  x = e will be the number of occurrences of e in the main diagonal
       of the table. The equations x3 = e, x4 = e, . . . can also be used in the
       same way to identify pairs of non-isomorphic groups.

  (e) One of the cyclic subgroups of G equals G (i. e., G is cyclic), while none
       of H's cyclic subgroups equals H (i. e., H is noncyclic). This is a special
       case of Condition c. Z and Z × Z are not isomorphic since Z = 1 and
       Z × Z is not cyclic.

11.7.4 Exercises

1. State whether each pair of groups below is isomorphic. For each pair that
      is, give an isomorphism; for those that are not, give your reason.

        (a) Z × R and R × Z

        (b) Z2 × Z and Z × Z

         (c) R and Q × Q

        (d) P({1, 2}) with symmetric difference and Z22
CHAPTER 11. ALGEBRAIC STRUCTURES  311

         (e) Z22 and Z4

         (f) R4 and M2×2(R) with matrix addition

        (g) R2 and R × R+

        (h) Z2 and the 2 × 2 rook matrices

         (i) Z6 and Z2 × Z3
2. If you know two natural languages, show that they are not isomorphic.
3. Prove that the relation "is isomorphic to" on groups is transitive.
4.

        (a) Write out the operation table for G = [{1, -1, i, -i}; ·] where i is
              the complex number for which i2 = -1. Show that G is isomorphic
              to [Z4; +4].

        (b) Solve x2 = -1 in G by first translating the equation to Z4 , solving
              the equation in Z4, and then translating back to G.

5. The two groups [Z4; +4] and [U5; ×5] are isomorphic. One isomorphism
      T : Z4  U5 is partially defined by T (1) = 3. Determine the values of
      T (0), T (2), and T (3).

6. Prove Theorem 11.7.14.
7. Prove that all infinite cyclic groups are isomorphic to Z.
8.

        (a) Prove that R is isomorphic to Z2 × R.

        (b) Describe how multiplication of nonzero real numbers can be accom-
              plished doing only additions and translations.

9. Prove that if G is any group and g is some fixed element of G, then the
      function g defined by g(x) = g  x  g-1 is an isomorphism from G into
      itself. An isomorphism of this type is called an inner automorphism.

10. Prove that "is isomorphic to" is an equivalence relation on the set of
      all groups by expanding on the observations made immediately after the
      definiton of an isomorphism.

11. It can be shown that there are five non-isomorphic groups of order eight.
      You should be able to describe at least three of them. Do so without use
      of tables. Be sure to explain why they are not isomorphic.

12. In Section 11.2 we posed the question of whether the two monoids
      [P(U ); ] and [P(U ); ], both monoids on the power set of some non-
      empty universal set U , are different or really the same. At the time we
      didn't have the notion of isomorphism to draw upon. Now that we do,
      determine whether they are isomorphic monoids.

13. Prove that the number of 3's in an order sequence is even.
14. Prove that the number of 5's an order sequence is a multiple of four.
Chapter 12

More Matrix Algebra

                             augmented matrix

                       There's a Gaussian technique whose intent
                          Is to solve the constraints you present
                                    As a matrix equation--
                                Once you've had the occasion

                       To write down your constants (augment).

       Steve Ngai, The Omnificent English Dictionary In Limerick Form

In Chapter 5 we studied matrix operations and the algebra of sets and logic.
We also made note of the strong resemblance of matrix algebra to elementary
algebra. The reader should briefly review this material. In this chapter we
shall look at a powerful matrix tool in the applied sciences, namely a tech-
nique for solving systems of linear equations. We will then use this process for
determining the inverse of n × n matrices, n  2, when they exist. We proceed
with a development of the diagonalization process, with a discussion of several
of its applications. Finally, we discuss the solution of linear equations over the
integers modulo 2.

12.1 Systems of Linear Equations

12.1.1 Solutions

The method of solving systems of equations by matrices that we will look
at is based on procedures involving equations that we are familiar with from
previous mathematics courses. The main idea is to reduce a given system of
equations to another simpler system that has the same solutions.

Definition 12.1.1 Solution Set. Given a system of equations involving real

variables x1, x2, . . ., xn, the solution set of the system is the set of n-tuples in

Rn, (a1, a2, . . . , an) such that the substitutions x1 = a1, x2 = a2, . . ., xn = an
make all the equations true.
                                                 

In terms of logic, a solution set is a truth set of a system of equations, which

is a proposition over n-tuples of real numbers.

In general, if the variables are from a set S, then the solution set will

be a subset of Sn. For example, in number theory mathematicians study

Diophantine equations, where the variables can only take on integer values

instead of real values.

                              312
CHAPTER 12. MORE MATRIX ALGEBRA                                 313

Definition 12.1.2 Equivalent Systems of Equations. Two systems of
linear equations are called equivalent if they have the same set of solutions. 

Example 12.1.3 Two equivalent systems. The previous definition tells
us that if we know that the system

                                 4x1 + 2x2 + x3 = 1
                                 2x1 + x2 + x3 = 4
                                 2x1 + 2x2 + x3 = 3

is equivalent to the system

                              x1 + 0x2 + 0x3 = -1
                             0x1 + x2 + 0x3 = -1
                             0x1 + 0x2 + x3 = 7

then both systems have the solution set {(-1, -1, 7)}. In other words, the

simultaneous values x1 = -1, x2 = -1, and x3 = 7 are the only values of the

variables that make all three equations in either system true.  

12.1.2 Elementary Operations on Equations

Theorem 12.1.4 Elementary Operations on Equations. If any sequence
of the following operations is performed on a system of equations, the resulting
system is equivalent to the original system:

(a) Interchange any two equations in the system.

(b) Multiply both sides of any equation by a nonzero constant.

  (c) Multiply both sides of any equation by a nonzero constant and add the
       result to a second equation in the system, with the sum replacing the latter
       equation.

    Let us now use the above theorem to work out the details of Example 12.1.3
and see how we can arrive at the simpler system.

    The original system:

                                 4x1 + 2x2 + x3 = 1             (12.1.1)
                                 2x1 + x2 + x3 = 4
                                 2x1 + 2x2 + x3 = 3

    Step 1. We will first change the coefficient of x1 in the first equation to one
and then use it as a pivot to obtain 0's for the coefficients of x1 in Equations
2 and 3.

·  Multiply  Equation  1     by  1  to  obtain
                                 4

                                     x1 + x2 2 + x3 4 = 14      (12.1.2)
                                    2x1 + x2 + x3 = 4

                                    2x1 + 2x2 + x3 = 3

· Multiply Equation 1 by -2 and add the result to Equation 2 to obtain

                                    x1 + x2 2 + x3 4 = 14
                                                 x3        7
                                    0x1 + 0x2 +  2   =     2    (12.1.3)

                                    2x1 + 2x2 + x3 = 3
CHAPTER 12. MORE MATRIX ALGEBRA                                                    314

· Multiply Equation 1 by -2 and add the result to Equation 3 to obtain

                                 x1 + x2 2 + x3 4 = 14
                                           x3           7
                              0x1 + 0x2 +  2    =       2                (12.1.4)

                                 0x1 + x2 + x3 2 = 52

    We've explicitly written terms with zero coefficients such as 0x1 to make
a point that all variables can be thought of as being involved in all equations.
After this example is complete, we will discontinue this practice in favor of the
normal practice of making these terms "disappear."

    Step 2. We would now like to proceed in a fashion analogous to Step
1; namely, multiply the coefficient of x2 in the second equation by a suitable
number so that the result is 1. Then use it as a pivot to obtain 0's as coefficients
for x2 in the first and third equations. This is clearly impossible (Why?), so
we will first interchange Equations 2 and 3 and proceed as outlined above.

· Exchange Equations 2 and 3 to obtain

                                 x1 + x2 2 + x3 4 = 14
                                 0x1 + x2 + x3 2 = 52
                                           x3           7                (12.1.5)
                              0x1 + 0x2 +  2    =       2

·  Multiply  Equation  2  by  1  and  subtract  the        result  from  Equation  1  to
                              2
   obtain

                              x1 + 0x2 + 0x3 = -1

                                 0x1 + x2 + x3 2 = 52                    (12.1.6)
                                           x3           7
                              0x1 + 0x2 +  2    =       2

    Step 3. Next, we will change the coefficient of x3 in the third equation
to one and then use it as a pivot to obtain 0's for the coefficients of x3 in
Equations 1 and 2. Notice that the coefficient of x3 is already zero in Equation
1, so we have been saved some work!

   · Multiply Equation 3 by 2 to obtain

                              x1 + 0x2 + 0x3 = -1
                               0x1 + x2 + x3 2 = 52
                               0x1 + 0x2 + x3 = 7

· Multiply Equation 3 by -1/2 and add the result to Equation 2 to obtain

                              x1 + 0x2 + 0x3 = -1                        (12.1.7)
                              0x1 + x2 + 0x3 = -1
                               0x1 + 0x2 + x3 = 7

    From the system of equations at the end of Step 3, we see that the solution
to the original system is x1 = -1, x2 = -1, and x3 = 7.
CHAPTER 12. MORE MATRIX ALGEBRA                            315

12.1.3 Transition to Matrices

In the above sequence of steps, we note that the variables serve the sole purpose
of keeping the coefficients in the appropriate location. This we can effect by
using matrices. The matrix of the original system in our example is

                             4211            

                           2 1 1 4

                             2213

where the matrix of the first three columns is called the coefficient matrix and
the complete matrix is referred to as the augmented matrix. Since we are
now using matrices to solve the system, we will translate Theorem 12.1.4 into
matrix language.

12.1.4 Elementary Row Operations

Theorem 12.1.5 Elementary Row Operations. If any sequence of the
following operations is performed on the augmented matrix of a system of equa-
tions, the resulting matrix is a system that is equivalent to the original system.
The following operations on a matrix are called elementary row operations:

(1) Exchange any two rows of the matrix.

(2) Multiply any row of the matrix by a nonzero constant.

(3) Multiply any row of the matrix by a nonzero constant and add the result
     to a second row, with the sum replacing that second row.

Definition 12.1.6 Row Equivalent Matrices. Two matrices, A and B,

are said to be row-equivalent if one can be obtained from the other by any

sequence of zero or more elementary row operations.        

If we use the notation Ri to stand for Row i of a matrix and - to stand

for row equivalence, then

                                 cRi +Rj

                             A - B

means that the matrix B is obtained from the matrix A by multiplying the
Row i of A by c and adding the result to Row j. The operation of multiplying
row i by c is indicated by

                                                                      cRi

                                             A - B

while exchanging rows i and j is denoted by

                                 Ri Rj

                             A - B.

The matrix notation for the system given in our first example, with the
CHAPTER 12. MORE MATRIX ALGEBRA                                     316

subsequent steps, is:

                            1 2 4 4 1 1 1         1 2 4 4 1 1 1 
  4 2 1 1 1R
 2 1 1 4  4-1  2 1 1 4  -2R-1+R2  0 0 1 7 2 2 

  2213                          221 3            221 3
                                  1 1 1                         1 1 1
                                  12 4 4           12 4 4
                -2R1+R3               1 7  R2R3                 1 5
                       -          00  22         - 0 1          22

                                  0 1 1 5 2 2      0 0 1 7 2 2      

                   1              1 0 0 -1         1 0 0 -1
                - 2 R2+R1             1 5  2R3 
                                                                1 5
                       -          01 2 2         - 0 1 2 2

                                  0 0 1 7 2 2      001 7

                -  1   R3  +R2    1 0 0 -1
                   2
                       -  0 1 0 -1 

                                  001 7

This again gives us the solution. This procedure is called the Gauss-Jordan
elimination method.

    It is important to remember when solving any system of equations via
this or any similar approach that at any step in the procedure we can rewrite
the matrix in "equation format" to help us to interpret the meaning of the
augmented matrix.

    In our first example we found a unique solution, only one triple, namely
(-1, -1, 7), which satisfies all three equations. For a system involving three
unknowns, are there any other possible results? To answer this question, let's
review some basic facts from analytic geometry.

    The graph of a linear equation in three-dimensional space is a plane. So
geometrically we can visualize the three linear equations as three planes in
three-space. Certainly the three planes can intersect in a unique point, as in
the first example, or two of the planes could be parallel. If two planes are
parallel, there are no common points of intersection; that is, there are no triple
of real numbers that will satisfy all three equations. Another possibility is
that the three planes could intersect along a common axis or line. In this case,
there would be an infinite number of real number triples in R3. Yet another
possibility would be if the first two planes intersect in a line, but the line is
parallel to, but not on, the third plane, giving us no solution. Finally if all
three equations describe the same plane, the solution set would be that plane.

    We can generalize these observations. In a system of n linear equations, n
unknowns, there can be

(1) a unique solution,

(2) no solution, or

(3) an infinite number of solutions.

  To illustrate these points, consider the following examples:

Example 12.1.7  A system with no solutions. Find all solutions to the
system
                            x1 + 3x2 + x3 = 2
                            x1 + x2 + 5x3 = 4
                           2x1 + 2x2 + 10x3 = 6

  The reader can verify that the augmented matrix of this system,
CHAPTER 12. MORE MATRIX ALGEBRA                   317

  13 1 2                      131 2             

 1 1 5 4 , reduces to  1 1 5 4 .

  2 2 10 6                    0 0 0 -2

  We can attempt to row-reduce this matrix further if we wish. However,

any further row-reduction will not substantially change the last row, which,

in equation form, is 0x1 + 0x2 + 0x3 = -2, or simply 0 = -2. It is clear

that we cannot find real numbers x1, x2, and x3 that will satisfy this equation.

Hence we cannot find real numbers that will satisfy all three original equations

simultaneously. When this occurs, we say that the system has no solution, or

the solution set is empty.                        

Example 12.1.8 A system with an infinite number of solutions. Next,
let's attempt to find all of the solutions to:

                             x1 + 6x2 + 2x3 = 1
                            2x1 + x2 + 3x3 = 2
                            4x1 + 2x2 + 6x3 = 4

  The augmented matrix for the system is

                              1621        

                            2 1 3 2               (12.1.8)

                              4264

which reduces to

                             1 0 11 16 1          (12.1.9)
                             0 1 111 0 

                                00 0 0

    If we apply additional elementary row operations to this matrix, it will
only become more complicated. In particular, we cannot get a one in the third
row, third column. Since the matrix is in simplest form, we will express it in
equation format to help us determine the solution set.

                            x1 + 16 11 x3 = 1     (12.1.10)
                               x2 + 111 x3 = 0
                                        0=0

Any real numbers will satisfy the last equation. However, the first equation
can be rewritten as x1 = 1 - 11 16 x3, which describes the coordinate x1 in terms
of x3 . Similarly, the second equation gives x2 in terms of x3 . A convenient
way of listing the solutions of this system is to use set notation. If we call the

solution set of the system S, then

                        S = 1 - 16 x3, - 1 x3, x3 | x3  R .
                                        11 11

    What this means is that if we wanted to list all solutions, we would replace
x3 by all possible numbers. Clearly, there is an infinite number of solutions,
two of which are (1, 0, 0) and (-15, -1, 11), when x3 takes on the values 0 and
11, respectively.

    A Word Of Caution: Frequently we may can get "different-looking" an-
swers to the same problem when a system has an infinite number of so-
lutions. Assume the solutions set in this example is reported to be A =
{(1 + 16x2, x2, -11x3) | x3  R}. Certainly the result described by S looks
CHAPTER 12. MORE MATRIX ALGEBRA                           318

different from that described by A. To see whether they indeed describe the

same set, we wish to determine whether every solution produced in S can be

generated in A. For example, the solution generated by S when x3 = 11 is

(-15, -1, 11). The same triple can be produced by A by taking x2 = -1. We

must prove that every solution described in S is described in A and, conversely,

that every solution described in A is described in S. (See Exercise 6 of this

section.)                                                 

To summarize the procedure in the Gauss-Jordan technique for solving

systems of equations, we attempt to obtain 1's along the main diagonal of

the coefficient matrix with 0's above and below the diagonal. We may find

in attempting this that this objective cannot be completed, as in the last two

examples we have seen. Depending on the way we interpret the results in

equation form, we either recognize that no solution exists, or we identify "free

variables" on which an infinite number of solutions are based. The final matrix

forms that we have produced in our examples are referred to as echelon forms.

In practice, larger systems of linear equations are solved using computers.

Generally, the Gauss-Jordan algorithm is the most useful; however, slight vari-

ations of this algorithm are also used. The different approaches share many

of the same advantages and disadvantages. The two major concerns of all

methods are:

(1) minimizing inaccuracies due to round-off errors, and

(2) minimizing computer time.

12.1.5 The Gauss-Jordan Algorithm

The accuracy of the Gauss-Jordan method can be improved by always choosing
the element with the largest absolute value as the pivot element, as in the
following algorithm.

Algorithm 12.1.9 The Gauss-Jordan Algorithm. Given a matrix equa-
tion Ax = b, where A is n × m, let C be the augmented matrix [A|b]. The
process of row-reducing to echelon form involves performing the following algo-
rithm where C[i] is the ith row of C.

  (1) i = 1

  (2) j = 1

  (3) while i <= n and j <= m):

        (a) maxi=i
         (b) for k = i+1 to n:

                 if abs(C[k,j])>abs(C[maxi,j]): then maxi=k
         (c) if C[maxi,j] != 0 then:

               (i) exchange rows i and maxi
              (ii) divide each entry in row i by C[i,j]
             (iii) for u = i+1 to n:

                       subtract C[u,j]*C[i] from C[u]
             (iv) i = i+1
        (d) j=j+1

Note 12.1.10 At the end of this algorithm, with the final form of C you can
revert back to the equation form of the system and a solution should be clear.
In general,
CHAPTER 12. MORE MATRIX ALGEBRA                                                 319

   · If any row of C is all zeros, it can be ignored.

   · If any row of C has all zero entries except for the entry in the (m + 1)st
       position, the system has no solution. Otherwise, if a column has no pivot,
       the variable corresponding to it is a free variable. Variables corresponding
       to pivots are basic variables and can be expressed in terms of the free
       variables.

Example 12.1.11 If we apply The Gauss-Jordan Algorithm to the system

                                  5x1 + x2 + 2x3 + x4 = 2

                                  3x1 + x2 - 2x3           =5

                                  x1 + x2 + 3x3 - x4 = -1

the augmented matrix is

                                                               
                                      51 2 1               2
                                                           5
                                   3 1 -2 0

                                       1 1 3 -1 -1

is reduced to                      1 0 0 21                1
                                   0 1 0 - 32
                                                           2

                                                           3

                                                           2

                                       0 0 1 0 -1

Therefore, x4 is a free variable in the solution and general solution of the system

is                                       1 1 

                                       x1         2 - 2 x4
                                        x2   3 + 3 x4 
                            x= =  2 2 
                                        x3   -1 

                                       x4                  x4

    This conclusion is easy to see if you revert back to the equations that the

final value the reduced matrix represents.                                      

12.1.6 SageMath Note - Matrix Reduction

Given an augmented matrix, C, there is a matrix method called echelon_form
that can be used to row reduce C. Here is the result for the system in Ex-
ample 12.1.11. In the assignment of a matrix value to C, notice that the first
argument is QQ, which indicates that the entries should be rational numbers.
As long as all the entries are rational, which is the case here since integers are
rational, the row-reduced matrix will be all rational.

 C = Matrix(QQ ,[[5,1,2,1,2],[3,1,-2,0,5],[1,1,3,-1,-1]])
 C. echelon_form ()

   [1 ^^I0 ^^I0 ^^I1/2 ^^I1/2]
   [0 ^^I1 ^^I0^^I-3/2 ^^I3/2]
   [0 ^^I0 ^^I1 ^^I 0^^I-1]

    If we don't specify the set from which entries are taken, it would assumed to

be the integers and we do not get a fully row-reduced matrix. This is because

the next step in working with the next output would involve multiplying row

2   by  1  and  row  3  by  19 ,  but  these  multipliers  are  not  integers.
        2

   C2 = Matrix([[5,1,2,1,2],[3,1,-2,0,5],[1,1,3,-1,-1]])
   C2 . echelon_form ()
CHAPTER 12. MORE MATRIX ALGEBRA                                  320

 [ 1 1 3 -1 -1]
 [ 0 2 2 -3 1]
 [ 0 0 9 0 -9]

    If we specifying real entries, the result isn't as nice and clean as the rational
output.

 C3 = Matrix(RR ,[[5,1,2,1,2],[3,1,-2,0,5],[1,1,3,-1,-1]])
 C3 . echelon_form ()

[  1.000000  0.0000000           0.0000000   0.5000000
                                 0.0000000    -1.500000
   0.500000000000000]                       4.934324e-17
                                  1.000000
[ 0.0000000  1.000000

   1.50000000000000]

[ 0.0000000  0.0000000

   -1.00000000000000]

    The default number of decimal places may vary from what you see here,
but it can be controlled. The single small number in row three column four
isn't exactly zero because of round-off but we could just set it to zero.

12.1.7 Exercises

1. Solve the following systems by describing the solution sets completely:

   (a) 2x1 + x2 = 3                    x1 + x2 + 2x3 = 1
         x1 - x2 = 1             (c) x1 + 2x2 - x3 = -1

   2x1 + x2 + 3x3 = 5                       x1 + 3x2 + x3 = 5

   (b) 4x1 + x2 + 2x3 = -1       (d) x1 - x2 + 3x3 = 7
          8x1 + 2x2 + 4x3 = -2          x1 + 3x2 + x3 = 4

2. Solve the following systems by describing the solution sets completely:

         2x1 + 2x2 + 4x3 = 2            6x1 + 7x2 + 2x3 = 3
   (a) 2x1 + x2 + 4x3 = 0        (d) 4x1 + 2x2 + x3 = -2

         3x1 + 5x2 + x3 = 0             6x1 + x2 + x3 = 1

          2x1 + x2 + 3x3 = 2           x1 + x2 - x3 + 2x4 = 1
   (b) 4x1 + x2 + 2x3 = -1       (e) x1 + 2x2 + 3x3 + x4 = 5

          8x1 + 2x2 + 4x3 = 4          x1 + 3x2 + 2x3 - x4 = -1

               x1 + x2 + 2x3 + x4 = 3
         (c) x1 - x2 + 3x3 - x4 = -2

               3x1 + 3x2 + 6x3 + 3x4 = 9
3. Given the final augmented matrices below from the Gauss-Jordan Algo-

      rithm, identify the solutions sets. Identify the basic and free variables,
      and describe the solution set of the original system.

     1 0 -5 0 1.2                           10 6 5  

   (a)  0 1 4 0 2.6              (c)  0 1 -2 1 

     0 0 0 1 4.5                            00 0 0

     1093                                   1 0 0 -3 1         

   (b)  0 1 0 4                  (d)  0 1 0 2 2 

     0001                                   0 0 1 -1 1
CHAPTER 12. MORE MATRIX ALGEBRA         321

4.

        (a) Write out the details of Example 12.1.7.

        (b) Write out the details of Example 12.1.8.

         (c) Write out the details of Example 12.1.11.
5. Solve the following systems using only mod 5 arithmetic. Your solutions

      should be n - tuples from Z5.

        (a) 2x1 + x2 = 3 (compare your solution to the system in 5(a))
               x1 + 4x2 = 1

               x1 + x2 + 2x3 = 1
        (b) x1 + 2x2 + 4x3 = 4

               x1 + 3x2 + 3x3 = 0
6.

        (a) Use the solution set S of Example 12.1.8 to list three different solu-
              tions to the given system. Then show that each of these solutions
              can be described by the set A in the same example.

        (b) Prove that S = A.
7. Given a system of n linear equations in n unknowns in matrix form

      AX = b, prove that if b is a matrix of all zeros, then the solution set of
      AX = b is a subgroup of Rn.

12.2 Matrix Inversion

12.2.1 Developing the Process

In Chapter 5 we defined the inverse of an n × n matrix. We noted that not
all matrices have inverses, but when the inverse of a matrix exists, it is unique.

This enables us to define the inverse of an n × n matrix A as the unique
matrix B such that AB = BA = I, where I is the n × n identity matrix. In
order to get some practical experience, we developed a formula that allowed

us to determine the inverse of invertible 2 × 2 matrices. We will now use the
Gauss-Jordan procedure for solving systems of linear equations to compute the

inverses, when they exist, of n × n matrices, n  2. The following procedure
for a 3 × 3 matrix can be generalized for n × n matrices, n  2.

                                      112
    Given the matrix A =  2 1 4 , we want to find its inverse, the matrix

        351
          x11 x12 x13

B =  x21 x22 x23 , if it exists, such that AB = I and BA = I. We will

          x31 x32 x33
concentrate on finding a matrix that satisfies the first equation and then verify

that B also satisfies the second equation.

    The equation

  112    x11 x12 x13             100  

 2 1 4   x21 x22 x23  =  0 1 0 

  351    x31 x32 x33             001
CHAPTER 12. MORE MATRIX ALGEBRA                               322

is equivalent to

  x11 + x21 + 2x31 x12 + x22 + 2x32 x13 + x23 + 2x33       100                       

 2x11 + x21 + 4x31 2x12 + x22 + 4x32 2x13 + x23 + 4x33  =  0 1 0 

  3x11 + 5x21 + x31 3x12 + 5x22 + x32 3x13 + 5x23 + x33    001

    By definition of equality of matrices, this gives us three systems of equations
to solve. The augmented matrix of one of the systems, the one equating the
first columns of the two matrices is:

                             1121         

                         2 1 4 0                           (12.2.1)

                             3510

  Using the Gauss-Jordan algorithm, we have:

  1121                       1121                          11 2 1                      

                   -2R1+R2                     -3R1+R3                                 
  2140              -        0 -1 0 -2           -         0 -1 0 -2

  3510                       3510                          0 2 -5 -3
                                        
                         11 2 1

                    -1R2          2
                    - 0 1 0

                         0 2 -5 -3                  
                                  
                                        1 0 2 -1
                    -R2+R1 and-2R2+R3 
                       -                01 0 2      

                                        0 0 -5 -7
                                                  1 0 0 - 519 
                         1 0 2 -1
                    1
                    - 5 R3   -2R3+R1  
                    - 0 1 0 2                 -     010 2

                         0 0 1 7/5                  0 0 1 75

So x11 = -19/5, x21 = 2 and x31 = 7/5, which gives us the first column of B.
    The matrix form of the system to obtain x12, x22, and x32, the second

column of B, is:

                             1120         

                         2 1 4 1                           (12.2.2)

                             3510

which reduces to

                                        9
                             100
                                        5
                          0 1 0 -1                         (12.2.3)

                             0 0 1 - 25

The critical thing to note here is that the coefficient matrix in (12.2.2) is the
same as the matrix in (12.2.1), hence the sequence of row operations that we
used in row reduction are the same in both cases.

    To determine the third column of B, we reduce

                             1120         

                         2 1 4 0

                             3511

to obtain x13 = 2/5, x23 = 0 and x33 = -1/5. Here again it is important to
note that the sequence of row operations used to solve this system is exactly
CHAPTER 12. MORE MATRIX ALGEBRA                           323

the same as those we used in the first system. Why not save ourselves a consid-
erable amount of time and effort and solve all three systems simultaneously?
This we can do this by augmenting the coefficient matrix by the identity matrix
I. We then have, by applying the same sequence of row operations as above,

           112100          1 0 0 - 5 5 19 9            2

          2 1 4 0 1 0  -  0 1 0 2 -1                   5

                                                       0

           351001         0 0 1 75 - 25 - 15

So that                        - 5 5 19 9  2
                      B =  2 -1
                                           5

                                           0

                          57 - 52 - 51

The reader should verify that BA = I so that A-1 = B.

12.2.2 The General Method for Computing Inverses

As the following theorem indicates, the verification that BA = I is not neces-
sary. The proof of the theorem is beyond the scope of this text. The interested
reader can find it in most linear algebra texts.

Theorem 12.2.1 Let A be an n × n matrix. If a matrix B can be found
such that AB = I, then BA = I, so that B = A-1. In fact, to find A-1, we
need only find a matrix B that satisfies one of the two conditions AB = I or
BA = I.

    It is clear from Chapter 5 and our discussions in this chapter that not all
n × n matrices have inverses. How do we determine whether a matrix has
an inverse using this method? The answer is quite simple: the technique we
developed to compute inverses is a matrix approach to solving several systems
of equations simultaneously.

Example 12.2.2 Recognition of a non-invertible matrix. The reader
                                         121

can verify that if A =  -1 -2 -1  then the augmented matrix

 0 5 8
     1 2 1 100

 -1 -2 -2 0 1 0  reduces to

     0 5 8 001

                        121100                

                      0 0 0 1 1 0                         (12.2.4)

                        058001

    Although this matrix can be row-reduced further, it is not necessary to do
so since, in equation form, we have:

Table 12.2.3

x11 + 2x21 + x31 = 1    x12 + 2x22 + x32 = 0    x13 + 2x23 + x33 = 0
 0=1                     0=1                     0=0
 5x21 + 8x31 = 0         5x22 + 8x32 = 0         5x23 + 8x33 = 1

    Clearly, there are no solutions to the first two systems, therefore A-1 does
not exist. From this discussion it should be obvious to the reader that the
zero row of the coefficient matrix together with the nonzero entry in the fourth
column of that row in matrix (12.2.4) tells us that A-1 does not exist. 
CHAPTER 12. MORE MATRIX ALGEBRA                                           324

12.2.3 Exercises

1. In order to develop an understanding of the technique of this section,
      work out all the details of Example 12.2.2.

2. Use the method of this section to find the inverses of the following ma-
      trices whenever possible. If an inverse does not exist, explain why.

    (a) 1 2                                                      
             -1 3                     1               2 -1

                             (d)  -2 -3 1 
             032
                                   1 4 -3
    (b)  1  -1 4       5
             001                                         
                       0           672
                          
                       1     (e)  4 2 1 

            0 1 3 -1               611

              2 -1 0               213                   

    (c)  -1 2 -1             (f)  4 2 1 

              0 -1 2               824

3. Use the method of this section to find the inverses of the following ma-

    trices whenever possible. If an inverse does not exist, explain why.

    (a)    12
           3
           15 -1

            1 0 03        

    (b)  2  -1 0 6 
             0 2 10

            0 -1 3 2

              1 -1 0      

    (c)  -1 2 -1 

              0 -1 1

                      
             10   0

    (d)  2 2 -1 

            1 -1 1

            234   

    (e)  3 4 5 

            456

         1 2 3 1 1 
    (f)  1 1 1 2 3 4 

                 111
                 345

4.

    (a) Find the inverses of the following matrices.

                200                      -1 0 0 0                  

         (i)  0 3 0              (ii)  0              5 0 0
                                           0          2            
                                           0          0 1 0
                005                                        7

                                                      0 0 34

    (b) If D is a diagonal matrix whose diagonal entries are nonzero, what
         is D-1?
CHAPTER 12. MORE MATRIX ALGEBRA                            325

5. Express each system of equations in Exercise 12.1.7.1 in the form Ax = B.
      When possible, solve each system by first finding the inverse of the matrix
      of coefficients.

12.3 An Introduction to Vector Spaces

12.3.1 Motivation for the study of vector spaces

    When we encountered various types of matrices in Chapter 5, it became
apparent that a particular kind of matrix, the diagonal matrix, was much easier

to use in computations. For example, if A =  2 1 , then A5 can be found,
                                             23

but its computation is tedious. If D = 1 0 then
                                                       04

5 1 0 5 15 0   5=                            10
D=      =
    04     04                                0 1024

Even when presented with a non-diagonal matrix, we will see that it is some-
times possible to do a bit of work to be able to work with a diagonal matrix.
This process is called diagonalization.

    In a variety of applications it is beneficial to be able to diagonalize a ma-
trix. In this section we will investigate what this means and consider a few
applications. In order to understand when the diagonalization process can
be performed, it is necessary to develop several of the underlying concepts of
linear algebra.

12.3.2 Vector Spaces

By now, you realize that mathematicians tend to generalize. Once we have
found a "good thing," something that is useful, we apply it to as many differ-
ent concepts as possible. In doing so, we frequently find that the "different
concepts" are not really different but only look different. Four sentences in
four different languages might look dissimilar, but when they are translated
into a common language, they might very well express the exact same idea.

    Early in the development of mathematics, the concept of a vector led to
a variety of applications in physics and engineering. We can certainly picture
vectors, or "arrows," in the xy - plane and even in the three-dimensional
space. Does it make sense to talk about vectors in four-dimensional space, in
ten-dimensional space, or in any other mathematical situation? If so, what is
the essence of a vector? Is it its shape or the rules it follows? The shape in
two- or three-space is just a picture, or geometric interpretation, of a vector.
The essence is the rules, or properties, we wish vectors to follow so we can
manipulate them algebraically. What follows is a definition of what is called a
vector space. It is a list of all the essential properties of vectors, and it is the
basic definition of the branch of mathematics called linear algebra.

Definition 12.3.1 Vector Space. Let V be any nonempty set of objects.
Define on V an operation, called addition, for any two elements x, y  V , and
denote this operation by x + y. Let scalar multiplication be defined for a real
number a  R and any element x  V and denote this operation by ax. The
set V together with operations of addition and scalar multiplication is called a
vector space over R if the following hold for all x, y, z  V , and a, b  R:

   · x+y=y+x
CHAPTER 12. MORE MATRIX ALGEBRA                                    326

· (x + y) + z = x + (y + z)

· There exists a vector 0  V , such that x + 0 = x for all x  V .

· For each vector x  V , there exists a unique vector -x  V , such that
   -x + x = 0.

These are the main properties associated with the operation of addition. They
can be summarized by saying that [V ; +] is an abelian group.

    The next four properties are associated with the operation of scalar multi-
plication and how it relates to vector addition.

· a (x + y) = ax + ay

· (a + b)x = ax + bx

· a (bx) = (ab)x

· 1x = x.

                                                                                                     
    In a vector space it is common to call the elements of V vectors and those

from R scalars. Vector spaces over the real numbers are also called real vector
spaces.

Example 12.3.2 A Vector Space of Matrices. Let V = M2×3(R) and let
the operations of addition and scalar multiplication be the usual operations of

addition and scalar multiplication on matrices. Then V together with these

operations is a real vector space. The reader is strongly encouraged to verify

the definition for this example before proceeding further (see Exercise 3 of this

section). Note we can call the elements of M2×3(R) vectors even though they
are not arrows.
                                                                   

Example 12.3.3 The Vector Space R2. Let R2 = {(a1, a2) | a1, a2  R}.
If we define addition and scalar multiplication the natural way, that is, as we

would on 1 × 2 matrices, then R2 is a vector space over R. See Exercise 12.3.3.4
of this section.

In this example, we have the "bonus" that we can illustrate the algebraic

concept geometrically. In mathematics, a "geometric bonus" does not always

occur and is not necessary for the development or application of the concept.

However, geometric illustrations are quite useful in helping us understand con-

cepts and should be utilized whenever available.

Figure 12.3.4 Sum of two vectors in R2

    Let's consider some illustrations of the vector space R2. Let x = (1, 4)
and y = (3, 1). We illustrate the vector (a1, a2) as a directed line segment, or
"arrow," from the point (0, 0) to the point(a1, a2). The vectors x and y are as
shown in Figure 12.3.4 together with x + y = (1, 4) + (3, 1) = (4, 5). The vector
CHAPTER 12. MORE MATRIX ALGEBRA                                        327

2x = 2(1, 4) = (2, 8) is a vector in the same direction as x, but with twice its

length.                                                                

Note 12.3.5

(1) The common convention is to use that boldface letters toward the end of
     the alphabet for vectors, while letters early in the alphabet are scalars.

(2) A common alternate notation for vectors is to place an arrow about a

                                                                                                         

     variable to indicate that it is a vector such as this: x .

(3) The vector (a1, a2, . . . , an)  Rn is referred to as an n-tuple.

  (4) For those familiar with vector calculus, we are expressing the vector x =
       a1^i + a2^j + a3k^  R3 as (a1, a2, a3). This allows us to discuss vectors in
       Rn in much simpler notation.

    In many situations a vector space V is given and we would like to describe

the whole vector space by the smallest number of essential reference vectors.
An example of this is the description of R2, the xy-plane, via the x and y axes.
Again our concepts must be algebraic in nature so we are not restricted solely

to geometric considerations.

Definition 12.3.6 Linear Combination. A vector y in vector space V (over

R) is a linear combination of the vectors x1, x2, . . ., xn if there exist scalars
a1, a2, . . . , an in R such that y = a1x1 + a2x2 + . . . + anxn
                                                                       

Example 12.3.7 A Basic Example. The vector (2, 3) in R2 is a linear
combination of the vectors (1, 0) and (0, 1) since (2, 3) = 2(1, 0) + 3(0, 1). 

Example 12.3.8 A little less obvious example. Prove that the vector
(4, 5) is a linear combination of the vectors (3, 1) and (1, 4).

    By the definition we must show that there exist scalars a1 and a2 such that:

             (4, 5) = a1(3, 1) + a2(1, 4)             3a1 + a2 = 4
                                                      a1 + 4a2 = 5

                    = (3a1 + a2, a1 + 4a2)

This system has the solution a1 = 1, a2 = 1.
    Hence, if we replace a1 and a2 both by 1, then the two vectors (3, 1) and

(1, 4) produce, or generate, the vector (4,5). Of course, if we replace a1 and
a2 by different scalars, we can generate more vectors from R2. If, for example,
a1 = 3 and a2 = -2, then

      a1(3, 1) + a2(1, 4) = 3(3, 1) + (-2)(1, 4) = (9, 3) + (-2, -8) = (7, -5)

                                                                                                     
    Will the vectors (3, 1) and (1, 4) generate any vector we choose in R2? To
see if this is so, we let (b1, b2) be an arbitrary vector in R2 and see if we can
always find scalars a1 and a2 such that a1(3, 1) + a2(1, 4) = (b1, b2). This is
equivalent to solving the following system of equations:

                                           3a1 + a2 = b1
                                           a1 + 4a2 = b2

which always has solutions for a1 and a2 , regardless of the values of the real
numbers b1 and b2. Why? We formalize this situation in a definition:

Definition 12.3.9 Generation of a Vector Space. Let {x1, x2, . . . , xn}
be a set of vectors in a vector space V over R. This set is said to generate,
CHAPTER 12. MORE MATRIX ALGEBRA                                   328

or span, V if, for any given vector y  V , we can always find scalars a1, a2, . . .,

an such that y = a1x1 + a2x2 + . . . + anxn. A set that generates a vector space

is called a generating set.                                       

We now give a geometric interpretation of the previous examples.

We know that the standard coordinate system, x axis and y axis, were

introduced in basic algebra in order to describe all points in the xy-plane

algebraically. It is also quite clear that to describe any point in the plane we

need exactly two axes.

We can set up a new coordinate system in the following way. Draw the

vector (3, 1) and an axis from the origin through (3, 1) and label it the x axis.

Also draw the vector (1, 4) and an axis from the origin through (1, 4) to be

labeled the y axis. Draw the coordinate grid for the axis, that is, lines parallel,

and let the unit lengths of this "new" plane be the lengths of the respective

vectors, (3, 1) and (1, 4), so that we obtain Figure 12.3.10.

From Example 12.3.8 and Figure 12.3.10, we see that any vector on the

plane can be described using the standard xy-axes or our new xy-axes. Hence

the position which had the name (3, 1) in reference to the standard axes has

the name (1, 0) with respect to the xy axes, or, in the phraseology of linear

algebra, the coordinates of the point (1, 4) with respect to the xy axes are

(1, 0).

Figure 12.3.10 Two sets of axes for the plane

Example 12.3.11 One point, Two position descriptions. From Exam-
ple 12.3.8 we found that if we choose a1 = 1 and a2 = 1, then the two vectors
(3, 1) and (1, 4) generate the vector (4, 5). Another geometric interpretation of
this problem is that the coordinates of the position (4, 5) with respect to the
xy axes of Figure 12.3.10 is (1, 1). In other words, a position in the plane has
the name (4, 5) in reference to the xy-axes and the same position has the name
(1, 1) in reference to the xy axes.

    From the above, it is clear that we can use different axes to describe points
or vectors in the plane. No matter what choice we use, we want to be able to de-
scribe each position in a unique manner. This is not the case in Figure 12.3.12.
Any point in the plane could be described via the xy axes, the xz axes or
the yz axes. Therefore, in this case, a single point would have three different
names, a very confusing situation.
CHAPTER 12. MORE MATRIX ALGEBRA                                        329

Figure 12.3.12 Three axes on a plane

                                                                                                    
    We formalize the our observations in the previous examples in two defini-
tions and a theorem.

Definition 12.3.13 Linear Independence/Linear Dependence. A set

of vectors {x1, x2, . . . , xn} from a real vector space V is linearly independent

if the only solution to the equation a1x1 + a2x2 + . . . + anxn = 0 is a1 = a2 =

. . . = an = 0. Otherwise the set is called a linearly dependent set.  

Definition 12.3.14 Basis. A set of vectors B = {x1, x2, . . . , xn} is a basis
for a vector space V if:

(1) B generates V , and

(2) B is linearly independent.

                                                                                                     
Theorem 12.3.15 The fundamental property of a basis. If
{x1, x2, . . . , xn} is a basis for a vector space V over R, then any vector y  V
can be uniquely expressed as a linear combination of the xi's.
Proof. Assume that {x1, x2, . . . , xn} is a basis for V over R. We must prove
two facts:

  (1) each vector y  V can be expressed as a linear combination of the xi's,
       and

  (2) each such expression is unique.

Part 1 is trivial since a basis, by its definition, must generate all of V .
The proof of part 2 is a bit more difficult. We follow the standard approach
for any uniqueness facts. Let y be any vector in V and assume that there are
two different ways of expressing y, namely

         y = a1x1 + a2x2 + . . . + anxn

and                                                             Then equating
                                y = b1x1 + b2x2 + . . . + bnxn

where at least one ai is different from the corresponding bi.
these two linear combinations we get

         a1x1 + a2x2 + . . . + anxn = b1x1 + b2x2 + . . . + bnxn

so that

         (a1 - b1) x1 + (a2 - b2) x2 + . . . + (an - bn) xn = 0
CHAPTER 12. MORE MATRIX ALGEBRA                                  330

Now a crucial observation: since the xis form a linearly independent set, the
only solution to the previous equation is that each of the coefficients must equal

zero, so ai - bi = 0 for i = 1, 2, . . . , n. Hence ai = bi, for all i. This contradicts

our assumption that at least one ai is different from the corresponding bi, so

each vector y  V can be expressed in one and only one way.       

This theorem, together with the previous examples, gives us a clear insight

into the significance of linear independence, namely uniqueness in representing

any vector.

Example 12.3.16 Another basis for R2. Prove that {(1, 1), (-1, 1)} is a
basis for R2 over R and explain what this means geometrically.

    First we show that the vectors (1, 1) and (-1, 1) generate all of R2. We
can do this by imitating Example 12.3.8 and leave it to the reader (see Exer-
cise 12.3.3.10 of this section). Secondly, we must prove that the set is linearly
independent.

    Let a1 and a2 be scalars such that a1(1, 1) + a2(-1, 1) = (0, 0). We must
prove that the only solution to the equation is that a1 and a2 must both equal
zero. The above equation becomes (a1 - a2, a1 + a2) = (0, 0) which gives us
the system

                                            a1 - a2 = 0

                                            a1 + a2 = 0

The augmented matrix of this system reduces in such way that the only solution
is the trivial one of all zeros:

             1 -1 0 - 1 0 0                   a1 = a2 = 0
             110  010

Therefore, the set is linearly independent.                      

To explain the results geometrically, note through Exercise 12, part a, that

the coordinates of each vector y  R2 can be determined uniquely using the
vectors (1,1) and (-1, 1). The concept of dimension is quite obvious for those

vector spaces that have an immediate geometric interpretation. For example,

the dimension of R2 is two and that of R3 is three. How can we define the
concept of dimension algebraically so that the resulting definition correlates

with that of R2 and R3? First we need a theorem, which we will state without
proof.

Theorem 12.3.17 Basis Size is Constant. If V is a vector space with a
basis containing n elements, then all bases of V contain n elements.

Definition 12.3.18 Dimension of a Vector Space. Let V be a vector

space over R with basis {x1, x2, . . . , xn}. Then the dimension of V is n. We
use the notation dim V = n to indicate that V is n-dimensional.
                                                                 

12.3.3 Exercises

1. If a = 2, b = -3, A = 1 0 -1 , B = 2 -2 3 , and
                  23 4                       458

C = 1 0 0 verify that all properties of the definition of a vector
          3 2 -2

space are true for M2×3(R) with these values.

2. Let a = 3, b = 4, x = (-1, 3), y = (2, 3),and z = (1, 0). Verify that
      all properties of the definition of a vector space are true for R2 for these
      values.
CHAPTER 12. MORE MATRIX ALGEBRA                               331

3.

        (a) Verify that M2×3(R) is a vector space over R. What is its dimension?

        (b) Is Mm×n(R) a vector space over R? If so, what is its dimension?
4.

        (a) Verify that R2 is a vector space over R.

        (b) Is Rn a vector space over R for every positive integer n?
5. Let P 3 = a0 + a1x + a2x2 + a3x3 | a0, a1, a2, a3  R ; that is, P 3 is the

      set of all polynomials in x having real coefficients with degree less than
      or equal to three. Verify that P 3 is a vector space over R. What is its
      dimension?
6. For each of the following, express the vector y as a linear combination of
      the vectors x1 and x2.

    (a) y = (5, 6), x1 = (1, 0), and x2 = (0, 1)

    (b) y = (2, 1), x1 = (2, 1), and x2 = (1, 1)

    (c) y = (3, 4), x1 = (1, 1), and x2 = (-1, 1)

7. Express the vector 1 2  M2×2(R), as a linear combination of
                                     -3 3

    1 1 , -1 5 , 0 1 and 0 0
    11  21  11                                    01

8. Express the vector x3 - 4x2 + 3  P 3 as a linear combination of the
      vectors 1, x, x2 , and x3.

9.

    (a) Show that the set {x1, x2} generates R2 for each of the parts in
         Exercise 6 of this section.

    (b) Show that {x1, x2, x3} generates R2 where x1 = (1, 1), x2 = (3, 4),
         and x3 = (-1, 5).

    (c) Create a set of four or more vectors that generates R2.
    (d) What is the smallest number of vectors needed to generate R2? Rn?
    (e) Show that the set

    {A1, A2, A3, A4} = { 1 0 , 0 1 , 0 0 , 0 0 }
            00  00                                    10  01

              generates M2×2(R)
         (f) Show that 1, x, x2, x3 generates P 3.
10. Complete Example 12.3.16 by showing that {(1, 1), (-1, 1)} generates R2.
11.

        (a) Prove that {(4, 1), (1, 3)} is a basis for R2 over R.
        (b) Prove that {(1, 0), (3, 4)} is a basis for R2 over R.
         (c) Prove that {(1, 0, -1), (2, 1, 1), (1, -3, -1)} is a basis for R3 over R.
CHAPTER 12. MORE MATRIX ALGEBRA                                     332

        (d) Prove that the sets in Exercise 9, parts e and f, form bases of the
              respective vector spaces.

12.

(a) Determine the coordinates of the points or vectors (3, 4), (-1, 1),
     and (1, 1) with respect to the basis {(1, 1), (-1, 1)} of R2. Interpret
     your results geometrically.

        (b) Determine the coordinates of the points or vector (3, 5, 6) with re-

              spect to the basis {(1, 0, 0), (0, 1, 0), (0, 0, 1)}. Explain why this basis
              is called the standard basis for R3.
13.

(a) Let y1 = (1, 3, 5, 9), y2 = (5, 7, 6, 3), and c = 2. Find y1 + y2 and
     cy1.

(b) Let f1(x) = 1 + 3x + 5x2 + 9x3 , f2(x) = 5 + 7x + 6x2 + 3x3 and
     c = 2. Find f1(x) + f2(x) and cf1(x).

(c) Let A =  1 3 ,B=             5 7 , and c = 2. Find A + B and
     cA.     59                  63

(d) Are the vector spaces R4 , P 3 and M2×2(R) isomorphic to each
     other? Discuss with reference to previous parts of this exercise.

12.4 The Diagonalization Process

12.4.1 Eigenvalues and Eigenvectors

We now have the background to understand the main ideas behind the diago-
nalization process.

Definition 12.4.1 Eigenvalue, Eigenvector. Let A be an n × n matrix
over R.  is an eigenvalue of A if for some nonzero column vector x  Rn we
have Ax = x. x is called an eigenvector corresponding to the eigenvalue .

                                                                                                     

Example 12.4.2 Examples of eigenvalues and eigenvectors. Find the

eigenvalues and corresponding eigenvectors of the matrix A =  21 .
                                                              23

    We want to find nonzero vectors X = x1 and real numbers  such
                                                             x2

that

AX = X  2 1                  x1 =  x1
                         23  x2      x2

 21                          x1 -  x1 = 0
       23                    x2      x2      0

 21                          x1 -  1 0       x1 = 0              (12.4.1)
       23                    x2      01      x2               0

 2 1 - 1 0                               x1 = 0
             23                  01      x2      0

 2- 1                            x1 = 0
          2 3-                   x2      0
CHAPTER 12. MORE MATRIX ALGEBRA                                      333

The last matrix equation will have nonzero solutions if and only if

         det 2 -  1 = 0
                    2 3-

or (2 - )(3 - ) - 2 = 0, which simplifies to 2 - 5 + 4 = 0. Therefore, the
solutions to this quadratic equation, 1 = 1 and 2 = 4, are the eigenvalues of
A. We now have to find eigenvectors associated with each eigenvalue.

    Case 1. For 1 = 1, (12.4.1) becomes:

2-1 1    x1 = 0      11              x1 = 0
  2 3-1  x2       0  22              x2                    0

which reduces to the single equation, x1 + x2 = 0. From this, x1 = -x2. This
means the solution set of this equation is (in column notation)

         E1 =  -c c  R
                c

So any column vector of the form -c where c is any nonzero real number
                                                 c

is an eigenvector associated with 1 = 1. The reader should verify that, for
example,

         21    1 =1 1
         23    -1                -1

so that 1 is an eigenvector associated with eigenvalue 1.
              -1

    Case 2. For 2 = 4 (12.4.1) becomes:

2-4 1    x1 = 0      -2 1                x1 = 0
  2 3-4  x2    0      2 -1               x2                   0

which reduces to the single equation -2x1 + x2 = 0, so that x2 = 2x1. The
solution set of the equation is

         E2 =  c cR
               2c

Therefore, all eigenvectors of A associated with the eigenvalue 2 = 4 are of
the form c2c , where c can be any nonzero number. 

    The following theorems summarize the most important aspects of the pre-
vious example.

Theorem 12.4.3 Characterization of Eigenvalues of a Square Matrix.
Let A be any n × n matrix over R. Then   R is an eigenvalue of A if and
only if det(A - I) = 0.

    The equation det(A - I) = 0 is called the characteristic equation, and
the left side of this equation is called the characteristic polynomial of A.

Theorem 12.4.4 Linear Independence of Eigenvectors. Nonzero eigen-
vectors corresponding to distinct eigenvalues are linearly independent.

    The solution space of (A - I)x = 0 is called the eigenspace of A corre-
sponding to . This terminology is justified by Exercise 2 of this section.
CHAPTER 12. MORE MATRIX ALGEBRA                                       334

12.4.2 Diagonalization

We now consider the main aim of this section. Given an n × n (square) matrix
A, we would like to transform A into a diagonal matrix D, perform our tasks
with the simpler matrix D, and then describe the results in terms of the given
matrix A.

Definition 12.4.5 Diagonalizable Matrix. An n × n matrix A is called
diagonalizable if there exists an invertible n × n matrix P such that P -1AP is
a diagonal matrix D. The matrix P is said to diagonalize the matrix A. 

Example 12.4.6 Diagonalization of a Matrix. We will now diagonalize
the matrix A of Example 12.4.2. We form the matrix P as follows: Let P (1)
be the first column of P . Choose for P (1) any eigenvector from E1. We may
as well choose a simple vector in E1 so P (1) = 1 is our candidate.

                                                                 -1
    Similarly, let P (2) be the second column of P , and choose for P (2) any
eigenvector from E2. The vector P (2) = 1 is a reasonable choice, thus

                                                         2

            P=   11   and P -1 = 1 2 -1 =    32 - 31
so that         -1 2                 3 11
                                             11
                                             33

P -1AP = 1            2 -1    21        1 1 = 10
              3       11      23       -1 2          04

Notice that the elements on the main diagonal of D are the eigenvalues of A,

where Dii is the eigenvalue corresponding to the eigenvector P (i) .  

Note 12.4.7

(1) The first step in the diagonalization process is the determination of the

eigenvalues. The ordering of the eigenvalues is purely arbitrary. If we

designate 1 = 4 and 2 = 1, the columns of P would be interchanged

and D would be        40      (see Exercise 3b of this section). Nonethe-
                      01

less, the final outcome of the application to which we are applying the

diagonalization process would be the same.

(2) If A is an n × n matrix with distinct eigenvalues, then P is also an n × n
     matrix whose columns P (1), P (2), . . ., P (n) are n linearly independent

     vectors.

Example 12.4.8  Diagonalization of a 3 by 3 matrix.  Diagonalize the
matrix
                                        
                              1 12 -18

                      A =  0 -11 18  .

                              0 -6 10
CHAPTER 12. MORE MATRIX ALGEBRA                              335

First, we find the eigenvalues of A.

                                   12              
                            1-  - - 11    -18
                                           18 
det(A - I) = det  0
                                         10 - 
            0                   -6

      = (1 - ) det              - - 11 18
                                   -6 10 - 

      = (1 - )((- - 11)(10 - ) + 108) = (1 - ) 2 +  - 2

Hence, the equation det(A - I) becomes

      (1 - ) 2 +  - 2 = -( - 1)2( + 2)

Therefore, our eigenvalues for A are 1 = -2 and 2 = 1. We note that we do
not have three distinct eigenvalues, but we proceed as in the previous example.

    Case 1. For 1 = -2 the equation (A - I)x = 0 becomes

                                     
        3 12 -18                         x1          0

       0 -9 18   x2  =  0 

        0 -6 12                          x3          0

                                                    10 2   

We can row reduce the matrix of coefficients to  0 1 -2 .

                                                                   00 0
    The matrix equation is then equivalent to the equations x1 =
-2x3 and x2 = 2x3. Therefore, the solution set, or eigenspace, correspond-
ing to 1 = -2 consists of vectors of the form

               -2x3                      
                                             -2

         2x3  = x3  2 

                    x3                           1

             
                 -2

Therefore  2  is an eigenvector corresponding to the eigenvalue 1 =

                       1
-2, and can be used for our first column of P :

                                  -2 ? ?         

               P = 2 ? ? 

                                  1 ??

    Before we continue we make the observation: E1 is a subspace of R3 with
basis P (1) and dim E1 = 1.

    Case 2. If 2 = 1, then the equation (A - I)x = 0 becomes

                                     
        0 12 -18                         x1             0

       0 -12 18   x2  =  0 

        0 -6 9                           x3             0

Without the aid of any computer technology, it should be clear that all three

equations that correspond to this matrix equation are equivalent to 2x2 -3x3 =

0, or x2 = 32 x3. Notice that x1 can take on any value, so any vector of the
form
                                    
        x1                            1              0

       32 x3  = x1  0  + x3  32 

        x3                            0              1
CHAPTER 12. MORE MATRIX ALGEBRA                                   336

will solve the matrix equation.

    We note that the solution set contains two independent variables, x1 and x3.
Further, note that we cannot express the eigenspace E2 as a linear combination
of a single vector as in Case 1. However, it can be written as

                                          
                           1    0         

                  E2 = x1  0  + x3  23  | x1, x3  R .
                           0    1

  We can replace any vector in a basis is with a nonzero multiple of that

vector. Simply for aesthetic reasons, we will multiply the second vector that

generates E2 by 2.Therefore, the eigenspace E2 is a subspace of R3 with basis
1              0
 0  ,  3  and so dim E2 = 2.
  0            2

  What this means with respect to the diagonalization process is that 2 = 1

gives us both Column 2 and Column 3 the diagonalizing matrix. The order is

not important so we have

                                -2 1 0  

                           P = 2 0 3 

                                1 02

  The reader can verify (see Exercise 5 of this section) that P -1 =
                                        
  0 2 -3                        -2 0 0

 1 4 -6  and P -1AP =  0 1 0                                      

  0 -1 2                        0 01

    In doing Example 12.4.8, the given 3 × 3 matrix A produced only two,
not three, distinct eigenvalues, yet we were still able to diagonalize A. The
reason we were able to do so was because we were able to find three linearly
independent eigenvectors. Again, the main idea is to produce a matrix P that
does the diagonalizing. If A is an n × n matrix, P will be an n × n matrix, and
its n columns must be linearly independent eigenvectors. The main question in
the study of diagonalizability is "When can it be done?" This is summarized
in the following theorem.

Theorem 12.4.9 A condition for diagonalizability. Let A be an n × n

matrix. Then A is diagonalizable if and only if A has n linearly independent

eigenvectors.

Proof. Outline of a proof: (=) Assume that A has linearly independent

eigenvectors, P (1), P (2), . . . , P (n), with corresponding eigenvalues 1, 2, . . . ,

n. We want to prove that A is diagonalizable. Column i of the n×n matrix AP
is AP (i) (see Exercise 7 of this section). Then, since the P (i) is an eigenvector of

A associated with the eigenvalue i we have AP (i) = iP (i) for i = 1, 2, . . . , n.

But this means that AP = P D, where D is the diagonal matrix with diagonal

entries 1, 2, . . ., n. If we multiply both sides of the equation by P -1 we get
the desired P -1AP = D.

(=) The proof in this direction involves a concept that is not covered in this

text (rank of a matrix); so we refer the interested reader to virtually any linear

algebra text for a proof.                                         

  We now give an example of a matrix that is not diagonalizable.

Example 12.4.10 A Matrix that is Not Diagonalizable. Let us attempt
CHAPTER 12. MORE MATRIX ALGEBRA                                        337

            100                                 

to diagonalize the matrix A =  0 2 1 

                                        1 -1 4
First, we determine the eigenvalues.

                                                  0             
                            1-                  2-        0
                                                          1
det(A - I) = det  0
                                                        4-
                  1 -1

          = (1 - ) det                          2- 1
                                                 -1 4 - 

          = (1 - )((2 - )(4 - ) + 1)
          = (1 - ) 2 - 6 + 9
          = (1 - )( - 3)2

Therefore there are two eigenvalues, 1 = 1 and 2 = 3. Since 1 is an
eigenvalue of degree one, it will have an eigenspace of dimension 1. Since 2
is a double root of the characteristic equation, the dimension of its eigenspace

must be 2 in order to be able to diagonalize.

    Case 1. For 1 = 1, the equation (A - I)x = 0 becomes

  000          
                  x1                                 0

 0 1 1   x2  =  0 

  1 -1 3          x3                                 0

Row reduction of this system reveals one free variable and eigenspace

                                                  
  x1        -4x3                                     -4

 x2  =  -x3  = x3  -1 

  x3        x3                                          1

          
          -4 
Hence,  -1  is a basis for the eigenspace of 1 = 1.

                 1
    Case 2. For 2 = 3, the equation (A - I)x = 0 becomes

               
  -2 0 0          x1                                    0

 0 -1 1   x2  =  0 

  1 -1 1          x3                                    0

    Once again there is only one free variable in the row reduction and so the
dimension of the eigenspace will be one:

                                                  
      x1    0                                        0

 x2  =  x3  = x3  1 

      x3    x3                                       1

          
         0
Hence,  1  is a basis for the eigenspace of 2 = 3. This means that 2 =

                1
3 produces only one column for P . Since we began with only two eigenvalues,
we had hoped that 2 = 3 would produce a vector space of dimension two, or,
in matrix terms, two linearly independent columns for P . Since A does not
have three linearly independent eigenvectors A cannot be diagonalized. 
CHAPTER 12. MORE MATRIX ALGEBRA  338

12.4.3 SageMath Note - Diagonalization

We demonstrate how diagonalization can be done in Sage. We start by defining
the matrix to be diagonalized, and also declare D and P to be variables.

 var ( ' D, P ')
 A = Matrix (QQ, [[4, 1, 0], [1, 5, 1], [0, 1, 4]]);A

  [4 1 0]
  [1 5 1]
  [0 1 4]

    We have been working with "right eigenvectors" since the x in Ax = x
is a column vector. It's not so common but still desirable in some situa-
tions to consider "left eigenvectors," so SageMath allows either one. The
right_eigenmatrix method returns a pair of matrices. The diagonal matrix,
D, with eigenvalues and the diagonalizing matrix, P , which is made up of
columns that are eigenvectors corresponding to the eigenvectors of D.

 (D ,P)=A. right_eigenmatrix () ;(D ,P)

  ([6 0 0]
  [0 4 0]
  [0 0 3],
  [ 1 1 1]
  [ 2 0 -1]
  [ 1 -1 1])

    We should note here that P is not unique because even if an eigenspace has
dimension one, any nonzero vector in that space will serve as an eigenvector.
For that reason, the P generated by Sage isn't necessarily the same as the one
computed by any other computer algebra system such as Mathematica. Here
we verify the result for our Sage calculation. Recall that an asterisk is used for
matrix multiplication in Sage.

 P. inverse () *A*P

  [6 0 0]
  [0 4 0]
  [0 0 3]

    Here is a second matrix to diagonalize.

 A2=Matrix(QQ ,[[8 ,1 ,0] ,[1 ,5,1] ,[0 ,1 ,7]]);A2

  [8 1 0]
  [1 5 1]
  [0 1 7]

    Here we've already specified that the underlying system is the rational num-
bers. Since the eigenvalues are not rational, Sage will revert to approximate
number by default. We'll just pull out the matrix of eigenvectors this time and
display rounded entries.

 P= A2 . right_eigenmatrix () [1]
 P. numerical_approx ( digits =3)
 print( ' ------------------ ')
 D =( P. inverse () * A2 *P);D. numerical_approx ( digits =3)

  [ 4.35 0.000 0.000]
  [0.000 7.27 0.000]
CHAPTER 12. MORE MATRIX ALGEBRA                                339

  [0.000 0.000 8.38]

    Finally, we examine how Sage reacts to the matrix from Example 12.4.10
that couldn't be diagonalized. Notice that the last column is a zero column,
indicating the absence of one needed eigenvector.

 A3=Matrix(QQ ,[[1, 0, 0],[0,2,1],[1,-1,4]])
 (D ,P)= A3 . right_eigenmatrix () ;(D ,P)

([1 0 0]

[0 3 0]

[0 0 3],

[1        0  0]

[ 1/4     1  0]

[ -1/4    1  0])

12.4.4 Exercises

1.

    (a) List three different eigenvectors of A =             2 1 , the matrix of
                                                             23

         Example 12.4.2, associated with each of the two eigenvalues 1 and

         4. Verify your results.

        (b) Choose one of the three eigenvectors corresponding to 1 and one of
              the three eigenvectors corresponding to 4, and show that the two
              chosen vectors are linearly independent.

2.

    (a) Verify that E1 and E2 in Example 12.4.2 are vector spaces over R.
         Since they are also subsets of R2, they are called subvector-spaces,
         or subspaces for short, of R2. Since these are subspaces consisting
         of eigenvectors, they are called eigenspaces.

        (b) Use the definition of dimension in the previous section to find dim E1
              and dim E2 . Note that dim E1 + dim E2 = dim R2. This is not a
              coincidence.

3.

    (a) Verify that P -1AP is indeed equal to                1 0 , as indicated in
         Example 12.4.6.                                     04

    (b) Choose P (1) = 1 and P (2) =                      1  and verify that the new
                                 2                       -1
                                                        0.
         value of P satisfies P -1AP = 4                1
                                                     0

    (c) Take two different (from the previous part) linearly independent
         eigenvectors of the matrix A of Example 12.4.6 and verify that
         P -1AP is a diagonal matrix.

4.                                                                  

                                                               010

    (a) Let A be the matrix in Example 12.4.8 and P =  1 0 1 .

                                                                                   102
         Without doing any actual matrix multiplications, determine the
CHAPTER 12. MORE MATRIX ALGEBRA                                      340

value of P -1AP

(b) If you choose the columns of P in the reverse order, what is P -1AP ?

5. Diagonalize the following, if possible:

(a) 1 2          (c) 3 0                        60 0                 
         32              04
                                              (e)  0 7 -4 

                                                91 3

                   1 -1 4                       1 -1 0                               

(b) -2 1         (d)  3 2 -1  (f)  -1 2 -1 
         -7 6
                   2 1 -1                       0 -1 1

6. Diagonalize the following, if possible:

(a) 0 1          (c) 2 -1                       110                  
         11              10
                                              (e)  1 0 1 

                                                011

                   136                          2 -1 0                               

(b) 2 1          (d)  -3 -5 -6  (f)  -1 2 -1 
         42
                   336                          0 -1 2

7. Let A and P be as in Example 12.4.8. Show that the columns of the

matrix AP can be found by computing AP (1), AP (2), . . . , AP (n).

8. Prove that if P is an n × n matrix and D is a diagonal matrix with
      diagonal entries d1, d2, . . . , dn, then P D is the matrix obtained from P ,
      by multiplying column i of P by di, i = 1, 2, . . . , n.

12.5 Some Applications

A large and varied number of applications involve computations of powers
of matrices. These applications can be found in science, the social sciences,
economics, engineering, and, many other areas where mathematics is used. We
will consider a few diverse examples the mathematics behind these applications
here.

12.5.1 Diagonalization

We begin by developing a helpful technique for computing Am, m > 1. If A
can be diagonalized, then there is a matrix P such that P -1AP = D, where
D is a diagonal matrix and

               Am = P DmP -1 for all m  1                            (12.5.1)

    The proof of this identity was an exercise in Section 5.4. The condition
that D be a diagonal matrix is not necessary but when it is, the calculation
on the right side is particularly easy to perform. Although the formal proof is
done by induction, the reason why it is true is easily seen by writing out an
CHAPTER 12. MORE MATRIX ALGEBRA                                          341

example such as m = 3:

A3 = P DP -1 3
    = P DP -1 P DP -1 P DP -1
    = P D P -1P D P -1P DP -1 by associativity of matrix multiplication
    = P DIDIDP -1
    = P DDDP -1
    = P D3P -1

Example 12.5.1 Application to Recursion: Matrix Computation of
the Fibonnaci Sequence. Consider the computation of terms of the Fibon-
naci Sequence. Recall that F0 = 1, F1 = 1 and Fk = Fk-1 + Fk-2 for k  2.

    In order to formulate the calculation in matrix form, we introduced the
"dummy equation" Fk-1 = Fk-1 so that now we have two equations

                                       Fk = Fk-1 + Fk-2
                                           Fk-1 = Fk-1

If A =     1 1 , these two equations can be expressed in matrix form as
           10

            Fk    = 11           Fk-1           if k  2
           Fk-1         10       Fk-2

                  =A       Fk-1
                           Fk-2

                  = A2     Fk-2              if k  3
                  etc.     Fk-3

We can use induction to prove that if k  2,

                     Fk = Ak-1 1
                     Fk-1                    1

Next, by diagonalizing A and using the fact that Am = P DmP -1. we can

show that             k                            k
                                             1- 5 
           Fk =  1  1+ 5         -
                           2                    2
                  5

  Some comments on this example:

(1) An equation of the form Fk = aFk-1 + bFk-2 , where a and b are given
     constants, is referred to as a linear homogeneous second-order difference
     equation. The conditions F0 = c0 and F1 = c1 , where c1 and c2 are
     constants, are called initial conditions. Those of you who are familiar with
     differential equations may recognize that this language parallels what is
     used in differential equations. Difference (aka recurrence) equations move
     forward discretely; that is, in a finite number of positive steps. On the
     other hand, a differential equation moves continuously; that is, takes an
     infinite number of infinitesimal steps.

(2) A recurrence relationship of the form Sk = aSk-1 + b, where a and b are
     constants, is called a first-order difference equation. In order to write out
CHAPTER 12. MORE MATRIX ALGEBRA                               342

the sequence, we need to know one initial condition. Equations of this

type can be solved similarly to the method outlined in the example by

introducing the superfluous equation 1 = 0 · Fk-1 + 1 to obtain in matrix
equation:

                                                        k
      Fk = a b  Sk-1     Fk = a b F0
      1  01       1                      1          01     1

                                                                                                     

12.5.2 Path Counting

In the next example, we apply the following theorem, which can be proven by
induction.
Theorem 12.5.2 Path Counting Theorem. If A is the adjacency matrix
of a graph with vertices {v1, v2, . . . , vn}, then the entry Ak ij is the number
of paths of length k from node vi to node vj.
Example 12.5.3 Counting Paths with Diagonalization. Consider the
graph in Figure 12.5.4.

Figure 12.5.4 Counting Numbers of Paths

 As we saw in Section 9.2, the adjacency matrix of this graph is A =
    110

 1 0 1 .

    011

    Recall that Ak is the adjacency matrix of the relation rk, where r is the
relation {(a, a), (a, b), (b, a), (b, c), (c, b), (c, c)} of the above graph. Also recall
that in computing Ak, we used Boolean arithmetic. What happens if we use

                                                                       211
"regular" arithmetic? If we square A we get A2 =  1 2 1 

                                                                       112
    How can we interpret this? We note that A33 = 2 and that there are two
paths of length two from c (the third node) to c. Also, A13 = 1, and there
is one path of length 2 from a to c. The reader should verify these claims by
examining the graph.
    How do we compute Ak for possibly large values of k? From the discussion
at the beginning of this section, we know that Ak = P DkP -1 if A is diagonal-
izable. We leave to the reader to show that  = 1, 2, and - 1 are eigenvalues
of A with eigenvectors

                                         
         1      1                             1

          0  ,  1  , and  -2 

         -1     1                                1

Then                                           
                    10                   0

         Ak = P  0 2k 0  P -1

                0 0 (-1)k
CHAPTER 12. MORE MATRIX ALGEBRA                                 343

  111                                   2  1 0 - 21 

where P =  0 1 -2  and P -1 =  13                   1       1
                                                    3
                                                            3
                                                61 - 3 6 1 1
  -1 1 1

See Exercise 12.5.5.5 of this section for the completion of this example. 

12.5.3 Matrix Calculus

Example 12.5.5 Matrix Calculus - Exponentials. Those who have stud-
ied calculus recall that the Maclaurin series is a useful way of expressing many
common functions. For example, ex = k=0 k!  xk . Indeed, calculators and com-
puters use these series for calculations. Given a polynomial f (x), we defined
the matrix-polynomial f (A) for square matrices in Chapter 5. Hence, we are
in a position to describe eA for an n × n matrix A as a limit of polynomials,
the partial sums of the series. Formally, we write

  eA = I + A + A2 + A3  + · · · = Ak
                                 2! 3!                      k!
                                                       k=0

    Again we encounter the need to compute high powers of a matrix. Let A

be an n × n diagonalizable matrix. Then there exists an invertible n × n matrix
P such that P -1AP = D, a diagonal matrix, so that

                         eA = eP DP -1

                                        P DP -1 k
                                            k!
                           =

                               k=0

                           =P            Dk     P -1
                                        k=0 k!

    The infinite sum in the middle of this final expression can be easily evaluated
if D is diagonal. All entries of powers off the diagonal are zero and the i th

entry of the diagonal is

                          Dk      Dii ii = = eDii k
                         k=0 k!              k!

                                         k=0

    For example, if A =  2 1 , the first matrix we diagonalized in Section
                         23
12.3, we found that P =
    Therefore,            11            and D =     10 .
                         -1 2                       04

  eA =                    11            e0          32 - 31
      =                  -1 2           0 e4
                                                    11
                                                    33

                           32e + 3e4    - 3e + 3e4
                         - 32e + 3 2e4  3e + 3 2e4

                         20.0116 17.2933
                         34.5866 37.3049

                                                                
CHAPTER 12. MORE MATRIX ALGEBRA                                      344

Remark 12.5.6 Many of the ideas of calculus can be developed using matrices.

For example, if A(t) =  t3 3t2 + 8t     then dt dA(t) =  3t2 6t + 8

                        et      2                        et  0

    Many of the basic formulas in calculus are true in matrix calculus. For

example,

                        d(A(t) + B(t)) dA(t) dB(t)
                                     =      +
                            dt          dt     dt

and if A is a constant matrix,

                                           deAt = AeAt
                                            dt

    Matrix calculus can be used to solve systems of differential equations in a
similar manner to the procedure used in ordinary differential equations.

12.5.4 SageMath Note - Matrix Exponential

Sage's matrix exponential method is exp.

 A=Matrix(QQ ,[[2 ,1] ,[2 ,3]])
 A. exp ()

  [1/3*e^4 + 2/3*e 1/3*e^4 - 1/3*e]
  [2/3*e^4 - 2/3*e 2/3*e^4 + 1/3*e]

12.5.5 Exercises

1.

    (a) Write out all the details of Example 12.5.1 to show that the formula
         for Fk given in the text is correct.

    (b) Use induction to prove the assertion made in the example that

          Fk = Ak-1 1
          Fk-1                  1

2.

    (a) Do Example 8.3.14 using the method outlined in Example 12.5.1.
         Note that the terminology characteristic equation, characteristic
         polynomial, and so on, introduced in Chapter 8, comes from the
         language of matrix algebra,

        (b) What is the significance of Algorithm 8.3.12, part c, with respect to
              this section?

3. Solve S(k) = 5S(k - 1) + 4, with S(0) = 0, using the method of this
      section.

4. How many paths are there of length 6 from vertex 1 to vertex 3 in
      Figure 12.5.7? How many paths from vertex 2 to vertex 2 of length 6 are
      there?
CHAPTER 12. MORE MATRIX ALGEBRA  345

      Figure 12.5.7 Graph for exercise 4

      Hint. The characteristic polynomial of the adjacency matrix is 4 - 42.
5. Regarding Example 12.5.3,

        (a) Use matrices to determine the number of paths of length 1 that exist
              from vertex a to each of the vertices in the given graph. Verify using
              the graph. Do the same for vertices b and c.

        (b) Verify all the details provided in the example.

         (c) Use matrices to determine the number of paths of length 4 there
              between each pair of nodes in the graph. Verify your results using
              the graph.

6. Let A = 2 -1
                       -1 2

        (a) Find eA

        (b) Recall that sin x = k=0 (2k+1)!  (-1)kxk and compute sin A.

         (c) Formulate a reasonable definition of the natural logarithm of a ma-
              trix and compute ln A.

7. We noted in Chapter 5 that since matrix algebra is not commutative
      under multiplication, certain difficulties arise. Let A = 1 1 and
                                                                                       00
      B= 0 0 .
                02

        (a) Compute eA, eB, and eA+B. Compare eAeB, eBeA and eA+B .

        (b) Show that if 0 is the 2 × 2 zero matrix, then e0 = I.

         (c) Prove that if A and B are two matrices that do commute, then
              eA+B = eAeB, thereby proving that eA and eB commute.

        (d) Prove that for any matrix A, eA -1 = e-A.
8. Another observation for adjacency matrices: For the matrix in Exam-

      ple 12.5.3, note that the sum of the elements in the row corresponding to
      the node a (that is, the first row) gives the outdegree of a. Similarly, the
      sum of the elements in any given column gives the indegree of the node
      corresponding to that column.
CHAPTER 12. MORE MATRIX ALGEBRA                                           346

Figure 12.5.8 Graph for exercise 8

  (a) Using the matrix A of Example 12.5.3, find the outdegree and the
       indegree of each node. Verify by the graph.

  (b) Repeat part (a) for the directed graphs in Figure 12.5.8.

12.6 Linear Equations over the Integers Mod 2

12.6.1 Row reduction mod 2

The methods we have studied for solving systems of equations up to this point
can be applied to systems in which all arithmetic is done over other algebraic
systems, including the integers modulo 2. The mod 2 case will become partic-
ularly useful in our later study of coding theory.

    When solving systems of equations with mod 2 arithmetic, the elementary
row operations are still fundamental. However, since there is only one nonzero
element, 1, you never need to multiply a row by a nonzero constant. One other
big difference is that the number of possible solutions is always finite. If you
have m linear equations in n unknowns, each unknown can only take on one of
two values, 0 or 1. Therefore there are only 2n possible n-tuples to from which
to draw a solution set. Assuming m  n, you typically (but not always) will
have m basic variables after row-reduction and n - m free variable. If this is
the case, and any solution exists, there will be 2n-m different solutions.

    Let's look at an example, which is coverted to matrix form immediately.

  x1 + x2           + x4                     =1

  x1         + x3         + x5 = 0

           x2 + x3                     + x6= 0

The augmented matrix of the system is

      1101001                                

  1 0 1 0 1 0 0

      0110010

The steps in row-reducing this matrix follow. Entries on which we "pivot" are
displayed in bold face to more easily identify the basic variables.

  1101001                              1 1 0 1 0 0 1

            add R1 to R2                           
  1010100           -                  0111101

  0110010                                 0  110010
                                       1                                
             add R2 to R1              0
                                              010100
                  -                           1 1 1 1 0 1

                                       0 11001 0
                                       1 0 1 0 1 0 0
             add R2 to R3 
                    -                  0111101     

                                       0 0 0111 1
CHAPTER 12. MORE MATRIX ALGEBRA                        347

Notice that at this point, we cannot pivot on the third row, third column

since that entry is zero. Therefore we move over to the next column, making

the x4 basic.

                          1 0 1 0 1 0 0
               add R3 to R2 
                 -               0110010             

                                 0 00111 1

    This completes the row reduction and we can now identify the solution set.
Keep in mind that since addition is subtraction, terms can be moved to either
side of an equals sign without any change in sign. The basic variables are x1,
x2, and x4, while the other three variables are free. The general solution of
the system is

                                           x1 = x3 + x5

                                           x2 = x3 + x6

                                              x3 = x3

                                        x4 = 1 + x5 + x6

                                              x5 = x5

                                              x6 = x6

    With three free variables, there are 23 = 8 solutions to this system. For
example, one of them is obtained by setting x3 = 1, x5 = 1, and x6 = 0, which
produces (x1, x2, x3, x4, x5, x6) = (0, 1, 1, 0, 1, 0).

    We can check our row reduction with SageMath:

H=Matrix(Integers(2) ,[[1,1,0,1,0,0,1],
     [1 ,0 ,1 ,0 ,1 ,0 ,0] ,[0 ,1 ,1 ,0 ,0 ,1 ,0]])

H. echelon_form ()

[1 0 1 0 1 0 0]
[0 1 1 0 0 1 0]
[0 0 0 1 1 1 1]

12.6.2 Exercises

In all of the exercises that follow, the systems of equations are over Z2, and so
mod 2 arithmetic should be used in solving them.
1. Solve the following systems, describing the solution sets completely:

(a) x1 + x2 = 0
x1               + x3= 0

x1 + x2                   =0

(b) x2 + x3 = 0
                    x3 + x4= 1

x1 + x2 + x3              =1

2. This exercise provides an example in which the number of basic variables
      is less than the number of equations. The only difference between the
      two systems below is the right hand sides. You can start with an aug-
      mented matrix having two right side columns and do row reduction for
      both systems at the same time.

x1 + x2                 + x4= 1

(a) x1           + x3 + x4= 0

               x2 + x3    =1
CHAPTER 12. MORE MATRIX ALGEBRA                                     348

x1 + x2          + x4= 1

(b) x1   + x3 + x4= 0

        x2 + x3  =0

3. This exercise motivates the concept of a coset in Chapter 15.

(a) Solve the following system and prove that the solution set is a linear

combination  of  vectors  in  Z5   and  also  a  subgroup  of  the  group  Z5

                                2                                            2
under coordinatewise mod 2 addition.

                 x1 + x2                      + x5= 0

                 x1           + x3            + x5= 0

                 x1           + x3 + x4 = 0

                              x2 + x3 + x4       =0

(b) Describe the solution set to the following system as it relates to the
     solution set to the system in the previous part of this exercise.

                 x1 + x2                      + x5= 1

                 x1           + x3            + x5= 0

                 x1           + x3 + x4 = 1

                              x2 + x3 + x4       =0
349
CHAPTER 13. BOOLEAN ALGEBRA              350

Chapter 13

Boolean Algebra

Figure 13.0.1 George Boole, 1815 - 1864
CHAPTER 13. BOOLEAN ALGEBRA                                      351

                                George Boole

                             George Boole wasn't idle a lot.
                             He churned out ideas on the spot,

                                  Making marvellous use of
                                       Inclusive/exclusive

                          Expressions like AND, OR, and NOT

   Andrew Robinson, The Omnificent English Dictionary In Limerick Form

In this chapter we will develop a type of algebraic system, Boolean algebras,
that is particularly important to computer scientists, as it is the mathematical
foundation of computer design, or switching theory. The similarities of Boolean
algebras and the algebra of sets and logic will be discussed, and we will discover
properties of finite Boolean algebras.

    In order to achieve these goals, we will recall the basic ideas of posets
introduced in Chapter 6 and develop the concept of a lattice. The reader
should view the development of the topics of this chapter as another example
of an algebraic system. Hence, we expect to define first the elements in the
system, next the operations on the elements, and then the common properties
of the operations in the system.

13.1 Posets Revisited

We recall the definition a partially ordering:

Definition 13.1.1 Partial Ordering. Let  be a relation on a set L. We say
that  is a partial ordering on L if it is reflexive, antisymmetric, and transitive.
That is:

(1)  is reflexive: a  a a  L

(2)  is antisymmetric: a  b and a = b  b  a a, b  L
(3)  is transitive: a  b and b  c  a  c a, b, c  L

The set together with the relation (L, ) is called a poset.                  

Example 13.1.2 Some posets. We recall a few examples of posets:

(a) (R, ) is a poset. Notice that our generic symbol for the partial ordering,
     , is selected to remind us that a partial ordering is similar to "less than
     or equal to."

(b) Let A = {a, b}. Then (P(A), ) is a poset.

(c) Let L = {1, 2, 3, 6}. Then (L, |) is a poset.

                                                                                                    
    The posets we will concentrate on in this chapter will be those which have
upper and lower bounds in relation to any pair of elements. Next, we define
this concept precisely.

Definition 13.1.3 Lower Bound, Upper Bound. Let (L, ) be a poset,

and a, b  L. Then c  L is a lower bound of a and b if c  a and c  b. Also,

d  L is an upper bound of a and b if a  d and b  d.                          

In most of the posets that will interest us, every pair of elements have both

upper and lower bounds, though there are posets for which this is not true.
CHAPTER 13. BOOLEAN ALGEBRA                       352

Definition 13.1.4 Greatest Lower Bound. Let (L, ) be a poset. If
a, b  L, then   L is a greatest lower bound of a and b if and only if

· a

· b

· If   L such that   a and   b, then   .

                                                                                                     
    The last condition in the definition of Greatest Lower Bound says that if
 is also a lower bound, then  is "greater" in relation to  than . The
definition of a least upper bound is a mirror image of a greatest lower bound:

Definition 13.1.5 Least Upper Bound. Let (L, ) be a poset. If a, b  L,
then u  L is a least upper bound of a and b if and only if

· au

· bu

· If u  L such that if a  u and b  u, then u  u.

                                                                                                     
    Notice that the two definitions above refer to "...a greatest lower bound"
and "a least upper bound." Any time you define an object like these you need
to have an open mind as to whether more than one such object can exist. In
fact, we now can prove that there can't be two greatest lower bounds or two
least upper bounds.

Theorem 13.1.6 Uniqueness of Least Upper and Greatest Lower
Bounds. Let (L, ) be a poset, and a, b  L. If a greatest lower bound of a
and b exists, then it is unique. The same is true of a least upper bound, if it
exists.
Proof. Let  and  be greatest lower bounds of a and b. We will prove that
 = .

(1)  a greatest lower bound of a and b   is a lower bound of a and b.

(2)  a greatest lower bound of a and b and  a lower bound of a and b
        , by the definition of greatest lower bound.

(3)  a greatest lower bound of a and b   is a lower bound of a and b.

(4)  a greatest lower bound of a and b and  a lower bound of a and b.
         by the definition of greatest lower bound.

(5)    and      =  by the antisymmetry property of a partial
     ordering.

The proof of the second statement in the theorem is almost identical to the

first and is left to the reader.                                       

Definition 13.1.7 Greatest Element, Least Element. Let (L, ) be a

poset. M  L is called the greatest (maximum) element of L if, for all a  L,

a  M . In addition, m  L is called the least (minimum) element of L if for all

a  L, m  a. The greatest and least elements, when they exist, are frequently

denoted by 1 and 0 respectively.                                       

Example 13.1.8 Bounds on the divisors of 105. Consider the partial
ordering "divides" on L = {1, 3, 5, 7, 15, 21, 35, 105}. Then (L, |) is a poset. To
CHAPTER 13. BOOLEAN ALGEBRA                        353

determine the least upper bound of 3 and 7, we look for all u  L, such that

3|u and 7|u. Certainly, both u = 21 and u = 105 satisfy these conditions and

no other element of L does. Next, since 21|105, 21 is the least upper bound

of 3 and 7. Similarly, the least upper bound of 3 and 5 is 15. The greatest

element of L is 105 since a|105 for all a  L. To find the greatest lower bound

of 15 and 35, we first consider all elements g of L such that g | 15. They are 1,

3, 5, and 15. The elements for which g | 35 are 1, 5, 7, and 35. From these two

lists, we see that  = 5 and  = 1 satisfy the required conditions. But since

1|5, the greatest lower bound is 5. The least element of L is 1 since 1|a for all

a  L.                                              

Definition 13.1.9 The Set of Divisors of an Integer. For any positive

integer n, the divisors of n is the set of integers that divide evenly into n. We

denote this set Dn.                                

For example, the set L of Example 13.1.8 is D105.

Example 13.1.10 The power set of a three element set. Consider the

poset (P(A), ), where A = {1, 2, 3}. The greatest lower bound of {1, 2} and
{1, 3} is  = {1}. For any other element  which is a subset of {1, 2} and {1, 3}
(there is only one; what is it?),   . The least element of P(A) is  and the
greatest element is A = {1, 2, 3}. The Hasse diagram of this poset is shown in
Figure 13.1.11.

Figure 13.1.11 Power Set of {1, 2, 3}

                                                                                                    
    The previous examples and definitions indicate that the least upper bound
and greatest lower bound are defined in terms of the partial ordering of the
given poset. It is not yet clear whether all posets have the property such that
every pair of elements always has both a least upper bound and greatest lower
bound. Indeed, this is not the case (see Exercise 13.1.3).

Exercises
CHAPTER 13. BOOLEAN ALGEBRA  354

1. Consider the poset (D30, |), where D30 = {1, 2, 3, 5, 6, 10, 15, 30}.
        (a) Find all lower bounds of 10 and 15.

        (b) Find the greatest lower bound of 10 and 15.

         (c) Find all upper bounds of 10 and 15.

        (d) Determine the least upper bound of 10 and 15.

         (e) Draw the Hasse diagram for D30 with respect to |. Compare this
              Hasse diagram with that of Example 13.1.10. Note that the two
              diagrams are structurally the same.

2. List the elements of the sets D8, D50, and D1001. For each set, draw the
      Hasse diagram for "divides."

3. Figure 13.1.12 contains Hasse diagrams of posets.

        (a) Determine the least upper bound and greatest lower bound of all
              pairs of elements when they exist. Indicate those pairs that do not
              have a least upper bound (or a greatest lower bound ).

        (b) Find the least and greatest elements when they exist.

      Figure 13.1.12 Figure for Exercise 3
4. For the poset (N, ), what are the greatest lower bound and least upper

      bound of two elements a and b? Are there least and/or greatest elements?
5.

        (a) Prove the second part of Theorem 13.1.6, the least upper bound of
              two elements in a poset is unique, if one exists.

        (b) Prove that if a poset L has a least element, then that element is
              unique.

6. We naturally order the numbers in Am = {1, 2, ..., m} with "less than or
      equal to," which is a partial ordering. We define an ordering,  on the
      elements of Am × An by

                               (a, b)  (a, b)  a  a and b  b

        (a) Prove that  is a partial ordering on Am × An.
CHAPTER 13. BOOLEAN ALGEBRA                                  355

        (b) Draw the ordering diagrams for  on A2 ×A2, A2 ×A3, and A3 ×A3.

         (c) In general, how does one determine the least upper bound and great-
              est lower bound of two elements of Am × An, (a, b) and (a, b)?

        (d) Are there least and/or greatest elements in Am × An?
7. Let P0 be the set of all subsets T of S = {1, 2, . . . , 9} such that the sum

      of the elements in T is even. (Note that the empty set  will be included
      as an element of P0.) For instance, {2, 3, 6, 7} is in P0 because 2 + 3 + 6 + 7
      is even, but {1, 3, 5, 6} is not in P0 because 1 + 3 + 5 + 6 is odd. Consider
      the poset (P0, ). Let A = {1, 2, 3, 6} and B = {2, 3, 6, 7} be elements of
      P0.

        (a) Explain why A  B is not element of the poset.

        (b) Use the definitions of the italicized terms and the given partial or-
              dering to complete the following statements:

                (i) R  P0 is an upper bound of A and B if
               (ii) R  P0 is the least element of P0 if

         (c) Find three different upper bounds of A and B.

        (d) Find the least upper bound of A and B. If it doesn't exist, explain
              why not.

13.2 Lattices

In this section, we restrict our discussion to lattices, those posets for which
every pair of elements has both a greatest lower bound and least upper bound.
We first introduce some notation.

Definition 13.2.1 Join, Meet. Let (L, ) be a poset, and a, b  L. We
define:

· a  b, read "a join b", as the least upper bound of a and b, if it exists.
   and

· a  b, read "a meet b", as the greatest lower bound of a and b, if it exists.

                                                                                                     
    Since the join and meet produce a unique result in all cases where they

exist, by Theorem 13.1.6, we can consider them as binary operations on a set

if they always exist. Thus the following definition:

Definition 13.2.2 Lattice. A lattice is a poset (L, ) for which every pair of

elements has a greatest lower bound and least upper bound. Since a lattice L is

an algebraic system with binary operations  and , it is denoted by [L; , ].

If we want to make it clear what partial ordering the lattice is based on, we

say it is a lattice under .                                  

Example 13.2.3 The power set of a three element set. Consider the

poset (P(A), ) we examined in Example 13.1.10. It isn't too surprising that

every pair of sets had a greatest lower bound and least upper bound. Thus, we

have a lattice in this case; and A  B = A  B and A  B = A  B. The reader

is encouraged to write out the operation tables [P(A); , ].  
CHAPTER 13. BOOLEAN ALGEBRA                                             356

    Our first concrete lattice can be generalized to the case of any set A, pro-
ducing the lattice [P(A); , ], where the join operation is the set operation of
union and the meet operation is the operation intersection; that is,  =  and
 = .

    It can be shown (see the exercises) that the commutative laws, associative
laws, idempotent laws, and absorption laws are all true for any lattice. A con-
crete example of this is clearly [P(A); , ], since these laws hold in the algebra
of sets. This lattice also has distributive property in that join is distributive
over meet and meet is distributive over join. However, this is not always the
case for lattices in general.

Definition 13.2.4 Distributive Lattice. Let L = [L; , ] be a lattice
under  . L is called a distributive lattice if and only if the distributive laws
hold; that is, for all a, b, c  L we have

a  (b  c) = (a  b)  (a  c)
                and

a  (b  c) = (a  b)  (a  c)

                                                                                                     

Example 13.2.5 A Nondistributive Lattice. We now give an example of
a lattice where the distributive laws do not hold. Let L = {0, a, b, c, 1}. We
define the partial ordering  on L by the set

{(0, 0), (0, a), (0, b), (0, c), (0, 1), (a, a), (a, 1), (b, b), (b, 1), (c, c), (c, 1), (1, 1)}

The operation tables for  and  on L are:

0 a b c1                                   0 a b c1
0 0abc1                                    0 00000
a aa111                                    a 0a00a
b b1 b11                                   b 00 b0 b
c c11c1                                    c 000 c c
1 11111                                    1 0abc1

Since every pair of elements in L has both a join and a meet, [L; , ] is a

lattice (under divides). Is this lattice distributive? We note that: a  (c  b) =

a 0 = a and (a  c)  (a  b) = 1 1 = 1. Therefore, a  (b  c) = (a  b)  (a  c)

for some values of a, b, c  L. Thus, this lattice is not distributive.                            

Our next observation uses the term "sublattice", which we have not defined

at this point, but we would hope that you could anticipate a definition, and

we will leave it as an exercise to do so.

It can be shown that a lattice is nondistributive if and only if it contains

a sublattice isomorphic to one of the lattices in Figure 13.2.6. The ordering

diagram on the right of this figure, produces the diamond lattice, which is

precisely the one that is defined in Example 13.2.5. The lattice based on the

left hand poset is called the pentagon lattice.
CHAPTER 13. BOOLEAN ALGEBRA                            357

Figure 13.2.6 Nondistributive lattices, the pentagon and diamond lattices

Exercises

1. Let L be the set of all propositions generated by p and q. What are the
      meet and join operations in this lattice under implication? What are the
      maximum and minimum elements?

2. Which of the posets in Exercise 13.1.3 are lattices? Which of the lattices
      are distributive?

3.

        (a) State the commutative laws, associative laws, idempotent laws, and
              absorption laws for lattices.

        (b) Prove laws you stated.
4. Demonstrate that the pentagon lattice is nondistributive.
5. What is a reasonable definition of the term sublattice?
6. Let [L; , ] be a lattice based on a partial ordering . Prove that if

      a, b, c  L,

        (a) a  a  b.

        (b) a  b  a.

         (c) b  a and c  a  b  c  a.

13.3 Boolean Algebras

In order to define a Boolean algebra, we need the additional concept of com-
plementation. A lattice must have both a greatest element and a least element
in order for complementation to take place. The following definition will save
us some words in the rest of this section.

Definition 13.3.1 Bounded Lattice. A bounded lattice is a lattice that

contains both a least element and a greatest element.                      

We use the symbols 0 and 1 for the least and greatest elements of a bounded

lattice in the remainder of this section.

Definition 13.3.2 The Complement of a Lattice Element. Let [L; , ]
be a bounded lattice. If a  L, then a has a complement if there exists b  L
such that

                                             ab=1

                                                 and

ab=0
CHAPTER 13. BOOLEAN ALGEBRA                                    358

                                                                                                     
    Notice that by the commutative laws for lattices, if b complements a, then

a complements b.

Definition 13.3.3 Complemented Lattice. Let L = [L; , ] be a bounded

lattice. L is a complemented lattice if every element of L has a complement in

L.                                                             

Example 13.3.4 Set Complement is a Complement. In Chapter 1, we

defined the complement of a subset of any universe. This turns out to be a

concrete example of the general concept we have just defined, but we will reason

through why this is the case here. Let L = P(A), where A = {a, b, c}. Then
[L; , ] is a bounded lattice with 0 =  and 1 = A. To find the complement,
if it exists, of B = {a, b}  L, for example, we want D such that

                            {a, b}  D = 
                                   and

                            {a, b}  D = A

It's not too difficult to see that D = {c}, since we need to include c to make
the first condition true and can't include a or b if the second condition is to be
true. Of course this is precisely how we defined Ac in Chapter 1. Since it can

be shown that each element of L has a complement (see Exercise 1), [L; , ] is
a complemented lattice. Note that if A is any set and L = P(A), then [L; , ]
is a complemented lattice where the complement of B  L is Bc = A - B. 

    In Example 13.3.4, we observed that the complement of each element of L

is unique. Is this always true in a complemented lattice? The answer is no.

Consider the following.

Example 13.3.5 A Lattice for which complements are not unique.

Let L = {1, 2, 3, 5, 30} and consider the lattice [L; , ] (under "divides"). The

least element of L is 1 and the greatest element is 30. Let us compute the

complement of the element a = 2. We want to determine a¯ such that 2  a¯ = 1

and 2  a¯ = 30. Certainly, a¯ = 3 works, but so does a¯ = 5, so the complement

of a = 2 in this lattice is not unique. However, [L; , ] is still a complemented

lattice since each element does have at least one complement.  

Definition 13.3.6 Complementation as an operation. If a complemented

lattice has the property that the complement of every element is unique, then

we consider complementation to be a unary operation. The usual notation for

the complement of a is a¯.                                     

    The following theorem gives us an insight into when uniqueness of comple-

ments occurs.

Theorem 13.3.7 One condition for unique complements. If [L; , ]
is a complemented, distributive lattice, then the complement of each element
a  L is unique.
Proof. Let a  L and assume to the contrary that a has two complements,
namely a1 and a2. Then by the definition of complement,

                            a  a1 = 0 and a  a1 = 1,

                            and                       .

                            a  a2 = 0 and a  a2 = 1,
CHAPTER 13. BOOLEAN ALGEBRA                                              359

Then

                    a1 = a1  1 = a1  (a  a2)
                       = (a1  a)  (a1  a2)
                       = 0  (a1  a2)
                       = a1  a2

On the other hand,

                    a2 = a2  1 = a2  (a  a1)
                       = (a2  a)  (a2  a1)
                       = 0  (a2  a1)
                       = a2  a1
                       = a1  a2

Hence a1 = a2, which contradicts the assumption that a has two different

complements.                                                             

Definition 13.3.8 Boolean Algebra. A Boolean algebra is a lattice that

contains a least element and a greatest element and that is both complemented

and distributive. The notation [B; , , ¯ ] is used to denote the boolean

algebra with operations join, meet and complementation.                  

Since the complement of each element in a Boolean algebra is unique (by

Theorem 13.3.7), complementation is a valid unary operation over the set under

discussion, which is why we will list it together with the other two operations

to emphasize that we are discussing a set together with three operations. Also,

to help emphasize the distinction between lattices and lattices that are Boolean

algebras, we will use the letter B as the generic symbol for the set of a Boolean

algebra; that is, [B; , , ¯ ] will stand for a general Boolean algebra.

Example 13.3.9 Boolean Algebra of Sets. Let A be any set, and let

B = P(A). Then [B; , , c] is a Boolean algebra. Here, c stands for the

complement of an element of B with respect to A, A - B.

This is a key example for us since all finite Boolean algebras and many

infinite Boolean algebras look like this example for some A. In fact, a glance

at the basic Boolean algebra laws in Table 13.3.11, in comparison with the set

laws of Chapter 4 and the basic laws of logic of Chapter 3, indicates that all

three systems behave the same; that is, they are isomorphic.             

Example 13.3.10 Divisors of 30. A somewhat less standard example of a

boolean algebra is derived from the lattice of divisors of 30 under the relation

"divides". If you examine the ordering diagram for this lattice, you see that it

is structurally the same as the boolean algebra of subsets of a three element

set. Therefore, the join, meet and complementation operations act the same

as union, intersection and set complementation. We might conjecture that the

lattice of divisors of any integer will produce a boolean algebra, but it is only

the case of certain integers. Try out a few integers to see if you can identify

what is necessary to produce a boolean algebra.                          
CHAPTER 13. BOOLEAN ALGEBRA                    360

Table 13.3.11 Basic Boolean Algebra Laws

Commutative Laws   ab=ba                       ab=ba
Associative Laws   a  (b  c) = (a  b)  c       a  (b  c) = (a  b)  c
Distributive Laws  a  (b  c) = (a  b)  (a  c)  a  (b  c) = (a  b)  (a  c)
Identity Laws      a0=0a=a                     a1=1a=a
Complement Laws    a  a¯ = 1                   a  a¯ = 0
Idempotent Laws    aa=a                        aa=a
Null Laws          a1=1                        a0=0
Absorption Laws    a  (a  b) = a               a  (a  b) = a
DeMorgan's Laws    a  b = a¯  ¯b               a  b = a¯  ¯b
Involution Law     a¯ = a

    The "pairings" of the boolean algebra laws reminds us of the principle of
duality, which we state for a Boolean algebra.

Definition 13.3.12 Principle of Duality for Boolean Algebras. Let

B = [B; , , c] be a Boolean algebra under , and let S be a true statement

for B. If S is obtained from S by replacing  with  (this is equivalent to

turning the graph upside down),  with ,  with , 0 with 1, and 1 with 0,

then S is also a true statement in B.          

Exercises

1. Determine the complement of each element B  L in Example 13.3.4. Is
      this lattice a Boolean algebra? Why?

2.

        (a) Determine the complement of each element of D6 in [D6; , ].
        (b) Repeat part a using the lattice in Example 13.2.5.

         (c) Repeat part a using the lattice in Exercise 13.1.1.

        (d) Are the lattices in parts a, b, and c Boolean algebras? Why?
3. Determine which of the lattices of Exercise 13.1.3 of Section 13.1 are

      Boolean algebras.
4. Let A = {a, b} and B = P(A).

        (a) Prove that [B; , , c] is a Boolean algebra.

        (b) Write out the operation tables for the Boolean algebra.
5. It can be shown that the following statement, S, holds for any Boolean

      algebra [B; , , -] : (a  b) = a if and only if a  b.
        (a) Write the dual, S, of the statement S.

        (b) Write the statement S and its dual, S, in the language of sets.

         (c) Are the statements in part b true for all sets?

        (d) Write the statement S and its dual, S, in the language of logic.

         (e) Are the statements in part d true for all propositions?
6. State the dual of:

        (a) a  (b  a) = a.
CHAPTER 13. BOOLEAN ALGEBRA  361

        (b) a  ¯b  a  b = 1.

         (c) a  ¯b  b = a  b.
7. Formulate a definition for isomorphic Boolean algebras.
8. For what positive integers, n, does the lattice [Dn, |] produce a boolean

      algebra?

13.4 Atoms of a Boolean Algebra

In this section we will look more closely at something we've hinted at, which
is that every finite Boolean algebra is isomorphic to an algebra of sets. We
will show that every finite Boolean algebra has 2n elements for some n with
precisely n generators, called atoms.

    Consider the Boolean algebra [B; , ,¯], whose ordering diagram is de-
picted in Figure 13.4.1

Figure 13.4.1 Illustration of the atom concept

    We note that 1 = a1  a2  a3, b1 = a1  a2, b2 = a1  a3, and b3 = a2  a3;
that is, each of the elements above level one can be described completely and
uniquely in terms of the elements on level one. The ai's have uniquely generated
the non-least elements of B much like a basis in linear algebra generates the
elements in a vector space. We also note that the ai's are the immediate
successors of the minimum element, 0. In any Boolean algebra, the immediate
successors of the minimum element are called atoms. For example, let A
be any nonempty set. In the Boolean algebra [P(A); , , c] (over ), the
singleton sets are the generators, or atoms, of the algebraic structure since
each element P(A) can be described completely and uniquely as the join, or
union, of singleton sets.
CHAPTER 13. BOOLEAN ALGEBRA                      362

Definition 13.4.2 Atom. A non-least element a in a Boolean algebra

[B; , ,¯] is called an atom if for every x  B, x  a = a or x  a = 0.

                                                                                                     
    The condition that x  a = a tells us that x is a successor of a; that is,
a  x, as depicted in Figure 13.4.3(a)
    The condition x  a = 0 is true only when x and a are "not connected."
This occurs when x is another atom or if x is a successor of atoms different

from a, as depicted in Figure 13.4.3(b).

Figure 13.4.3 Conditions for an atom

An alternate definition of an atom is based on the concept of "covering."

Definition 13.4.4 The Covering Relation. Given a Boolean algebra

[B; , ,¯], let x, z  B. We say that z covers x iff x  z and there does not

exist y  B with x  y  z.                                                   

It can be proven that the atoms of Boolean algebra are precisely those

elements that cover the zero element.

The set of atoms of the Boolean algebra [D30; , , ¯ ] is M = {2, 3, 5}.

To see that a = 2 is an atom, let x be any non-least element of D30 and note

that one of the two conditions x  2 = 2 or x  2 = 1 holds. Of course, to

apply the definition to this Boolean algebra, we must remind ourselves that in

this case the 0-element is 1, the operation  is greatest common divisor, and

the poset relation is "divides." So if x = 10, we have 10  2 = 2 (or 2 | 10), so

Condition 1 holds. If x = 15, the first condition is not true. (Why?) However,

Condition 2, 15  2 = 1, is true. The reader is encouraged to show that 3 and 5

also satisfy the definition of an atom. Next, if we should compute the join (the

least common multiple in this case) of all possible combinations of the atoms

2, 3, and 5 to generate all nonzero (non-1 in this case) elements of D30. For

example, 2  3  5 = 30 and 2  5 = 10. We state this concept formally in the

following theorem, which we give without proof.

Theorem 13.4.5 Let B = [B; , , ¯] be any finite Boolean algebra. Let A =
{a1, a2, . . . , an} be the set of all atoms of B. Then every element in B can be
expressed uniquely as the join of a subset of A.

    The least element in relation to this theorem bears noting. If we consider
the empty set of atoms, we would consider the join of elements in the empty
set to be the least element. This makes the statement of the theorem above a
bit more tidy since we don't need to qualify what elements can be generated
from atoms.

    We now ask ourselves if we can be more definitive about the structure
of different Boolean algebras of a given order. Certainly, the Boolean alge-
bras [D30; , ,  ¯ ] and [P(A); , , c] have the same graph (that of Fig-
ure 13.4.1), the same number of atoms, and, in all respects, look the same ex-
cept for the names of the elements and the operations. In fact, when we apply
CHAPTER 13. BOOLEAN ALGEBRA                                          363

corresponding operations to corresponding elements, we obtain corresponding
results. We know from Chapter 11 that this means that the two structures are
isomorphic as Boolean algebras. Furthermore, the graphs of these examples
are exactly the same as that of Figure 13.4.1, which is an arbitrary Boolean
algebra of order 8 = 23.

    In these examples of a Boolean algebra of order 8, we note that each
had 3 atoms and 23 = 8 number of elements, and all were isomorphic to
[P(A); , , c], where A = {a, b, c}. This leads us to the following questions:

· Are there any different (nonisomorphic) Boolean algebras of order 8?

· What is the relationship, if any, between finite Boolean algebras and their
   atoms?

· How many different (nonisomorphic) Boolean algebras are there of order
   2? Order 3? Order 4? etc.

    The answers to these questions are given in the following theorem and
corollaries.

Theorem 13.4.6 Let B = [B; , , -] be any finite Boolean algebra, and let A

be the set of all atoms of B. Then [P(A); , , c] is isomorphic to [B; , , -]

Proof. An isomorphism that serves to prove this theorem is T : P(A)  B

defined by T (S) = aS a, where T () is interpreted as the zero of B. We
leave it to the reader to prove that this is indeed an isomorphism.     

Corollary 13.4.7 Every finite Boolean algebra B = [B; , , ¯ ] has 2n ele-

ments for some positive integer n.

Proof. Let A be the set of all atoms of B and let |A| = n. Then there are

exactly 2n elements (subsets) in P(A),and by Theorem 13.4.6, [B; , , ¯ ] is

isomorphic to [P(A); ,  c] and must also have 2n elements.              

Corollary 13.4.8 All Boolean algebras of order 2n are isomorphic to one

another.
Proof.

Figure 13.4.9 Isomorphisms to be combined

Every Boolean algebra of order 2n is isomorphic to [P(A); , , c] when |A| = n.

Hence, if B1 and B2 each have 2n elements, they each have n atoms. Suppose

their sets of atoms are A1 and A2, respectively. We know there are isomor-

phisms T1 and T2, where Ti : Bi  P(Ai), i = 1, 2. In addition we have an

isomorphism, N from P(A1) into P(A2), which we ask you to prove in Exer-

cise 13.4.9. We can combine these isomorphisms to produce the isomorphism

T2-1  N  T1 : B1  B2, which proves the corollary.                       

The above theorem and corollaries tell us that we can only have finite

Boolean algebras of orders 21, 22, 23, .., 2n, and that all finite Boolean algebras
CHAPTER 13. BOOLEAN ALGEBRA  364

of any given order are isomorphic. These are powerful tools in determining the
structure of finite Boolean algebras. In the next section, we will discuss one of
the easiest ways of describing a Boolean algebra of any given order.

Exercises

1.

        (a) Show that a = 2 is an atom of the Boolean algebra [D30; , , -].

        (b) Repeat part a for the elements 3 and 5 of D30.

         (c) Verify Theorem 13.4.5 for the Boolean algebra [D30; , , -].
2. Let A = {a, b, c}.

        (a) Rewrite the definition of atom for [P(A); , , c]. What does a  x
              mean in this example?

        (b) Find all atoms of [P(A); , , c].

         (c) Verify Theorem 13.4.5 for [P(A); c, , ].
3. Verify Theorem 13.4.6 and its corollaries for the Boolean algebras in

      Exercises 1 and 2 of this section.
4. Give an example of a Boolean algebra of order 16 whose elements are

      certain subsets of the set {1, 2, 3, 4, 5, 6, 7}
5. Corollary 13.4.7 implies that there do not exist Boolean algebras of orders

      3, 5, 6, 7, 9, etc. (orders different from 2n). Without this corollary, directly
      show that we cannot have a Boolean algebra of order 3.
      Hint. Assume that [B; , , -] is a Boolean algebra of order 3 where
      B = {0, x, 1} and show that this cannot happen by investigating the
      possibilities for its operation tables.
6.

        (a) There are many different, yet isomorphic, Boolean algebras with two
              elements. Describe one such Boolean algebra that is derived from a
              power set, P(A), under . Describe a second that is described from
              Dn, for some n  P , under "divides."

        (b) Since the elements of a two-element Boolean algebra must be the
              greatest and least elements, 1 and 0, the tables for the operations
              on {0, 1} are determined by the Boolean algebra laws. Write out
              the operation tables for [{0, 1}; , , -].

7. Find a Boolean algebra with a countably infinite number of elements.
8. Prove that the direct product of two Boolean algebras is a Boolean alge-

      bra.
      Hint. "Copy" the corresponding proof for groups in Section 11.6.
9. Prove if two finite sets A1 and A2 both have n elements then
      [P(A1); , , c] is isomorphic to [P(A2); , , c]
10. Prove an element of a Boolean algebra is an atom if and only if it covers
      the zero element.
CHAPTER 13. BOOLEAN ALGEBRA                                                                                             365

13.5 Finite Boolean Algebras as n-tuples of 0's
       and 1's

From the previous section we know that all finite Boolean algebras are of
order 2n, where n is the number of atoms in the algebra. We can therefore
completely describe every finite Boolean algebra by the algebra of power sets.
Is there a more convenient, or at least an alternate way, of defining finite
Boolean algebras? In Chapter 11 we found that we could produce new groups
by taking Cartesian products of previously known groups. We imitate this
process for Boolean algebras.

    The simplest nontrivial Boolean algebra is the Boolean algebra on the set
B2 = {0, 1}. The ordering on B2 is the natural one, 0  0, 0  1, 1  1. If we
treat 0 and 1 as the truth values "false" and "true," respectively, we see that
the Boolean operations (join) and (meet) are nothing more than the logical
operation with the same symbols. The Boolean operation, -, (complementa-
tion) is the logical ¬ (negation). In fact, this is why these symbols were chosen
as the names of the Boolean operations. The operation tables for [B2; , , -]
are simply those of "or," "and," and "not," which we repeat here.

                               01              01                                   -
                               0 01            0 00
                               1 11            1 01                           uu
                                                                              01
                                                                              10

    By Theorem 13.4.6 and its corollaries, all Boolean algebras of order 2 are

isomorphic to this one.

    We  know  that     if  we  form  B2×B2     =       B2    we    obtain        the       set   {(0,    0),  (0,  1),  (1,  0),  (1,  1)},

                                                          2        B2

a set of order 4.      We      define  operations         on          2  the       natural          way,     namely     com-

ponentwise, so that (0, 1)  (1, 1) = (0  1, 1  1) = (1, 1), (0, 1)  (1, 1) =

(0  1, 1  1)  =  (0, 1)    and  (0, 1)  =    (¯0, ¯1)  =     (1, 0).     We      claim        that     B2     is  a  Boolean

                                                                                           2              2
                                                                                           2
algebra under the componentwise operations. Hence,                                      B     ;     ,    ,¯   is a Boolean

algebra of order 4. Since all Boolean algebras of order 4 are isomorphic to one

other, we have found a simple way of describing all Boolean algebras of order

4.

    It is quite clear that we can describe any Boolean algebra of order 8 by

considering   B2  ×    B2  ×   B2  =   B3    and,      more        generally,           any      Boolean          algebra    of

       2n        Bn                       2

order      with     2  =   B2  ×  B2   ×  ···  ×  B2      (n    factors).

Exercises

1.

       (a) Write out the operation tables for                        B   2    ;    ,    ,  -     .
                                                                         2

       (b) Draw the Hasse diagram for                     B  2  ;    ,     ,  -       and compare your results
                                                             2

           with Figure 6.3.6.

         (c) Find the atoms of this Boolean algebra.
2.

       (a) Write out the operation tables for                        B   3    ;    ,    ,  -     .
                                                                         2

       (b) Draw the Hasse diagram for                     B  3  ;    ,     ,  -
                                                             2

3.

       (a) List all atoms of B24.
CHAPTER 13. BOOLEAN ALGEBRA                                            366

        (b) Describe the atoms of B2n, n  1.

4. Theorem 13.4.6 tells us we can think of any finite Boolean algebra in
      terms of sets. In Chapter 4, we defined minsets 4.3.4 and minset normal
      form 4.3.9. Rephrase these definitions in the language of Boolean algebra.
      The generalization of minsets are called minterms.

13.6 Boolean Expressions

In this section, we will use our background from the previous sections and set
theory to develop a procedure for simplifying Boolean expressions. This proce-
dure has considerable application to the simplification of circuits in switching
theory or logical design.

Definition 13.6.1 Boolean Expression. Let [B; , , -] be any Boolean

algebra, and let x1, x2, . . . , xk be variables in B; that is, variables that can

assume values from B. A Boolean expression generated by x1, x2, . . . , xk is

any valid combination of the xi and the elements of B with the operations of

meet, join, and complementation.                                       

This definition is the analog of the definition of a proposition generated by

a set of propositions, presented in Section 3.2.

Each Boolean expression generated by k variables, e (x1, . . . , xk), defines

a function f : Bk  B where f (a1, . . . , ak) = e (a1, . . . , ak). If B is a finite

Boolean algebra, then there are a finite number of functions from Bk into B.

Those functions that are defined in terms of Boolean expressions are called

Boolean functions. As we will see, there is an infinite number of Boolean

expressions that define each Boolean function. Naturally, the "shortest" of

these expressions will be preferred. Since electronic circuits can be described

as Boolean functions with B = B2, this economization is quite useful.

In what follows, we make use of Exercise 7.1.5.5 in Section 7.1 for counting

number of functions.

Example 13.6.2 Two variables over B2. Consider any Boolean algebra

of order 2, [B; , , -]. How many functions f : B2  B are there? First,

all Boolean algebras of order 2 are isomorphic to [B2; , , -] so we want to

determine the number of functions f  :  B2        B2.  If we consider a Boolean

                                           2

function of two variables, x1 and x2, we note that each variable has two possible

values 0 and 1, so there are 22 ways of assigning these two values to the k = 2

variables. Hence, the table below has 22 = 4 rows. So far we have a table such

as this one:

                      x1 x2 f (x1, x2)

                      00                ?

                      01                ?

                      10                ?

                      11                ?

    How many possible different functions can there be? To list a

few:f1 (x1, x2) = x1, f2 (x1, x2) = x2, f3 (x1, x2) = x1  x2, f4 (x1, x2) =
(x1  x2)  x2, f5 (x1, x2) = x1  x2  x2, etc. Each of these will fill in the
question marks in the table above. The tables for f1 and f3 are

              x1 x2 f1 (x1, x2)         x1 x2 f3 (x1, x2)

              00      0                 00             0

              01      0                 01             1

              10      1                 10             1

              11      1                 11             1
CHAPTER 13. BOOLEAN ALGEBRA                                       367

Two functions are different if and only if their tables are different for at

least one row. Of course by using the basic laws of Boolean algebra we can see

that f3 = f4. Why? So if we simply list by brute force all "combinations" of

x1 and x2 we will obtain unnecessary duplication. However, we note that for

any combination of the variables x1, and x2 there are only two possible values

for f (x1, x2), namely 0 or 1. Thus, we could write 24 = 16 different functions

on 2 variables.                                                   

Now, let's count the number of different Boolean functions in a more general

setting. We will consider two cases: first, when B = B2 , and second, when B

is any finite Boolean algebra with 2n elements.

Let B = B2. Each function f : Bk  B is defined in terms of a table having

2k rows. Therefore, since there are two possible images for each element of Bk,

there are 2 raised to the 2k, or 22k different functions. We will show that every

one of these functions is a Boolean function.

Now suppose that |B| = 2n > 2. A function from Bk into B can still be

defined in terms of a table. There are |B|k rows to each table and |B| possible

images for each row. Therefore, there are 2n raised to the power 2nk different

functions. We will show that if n > 1, not every one of these functions is a

Boolean function.

Since all Boolean algebras are isomorphic to a Boolean algebra of sets, the

analogues of statements in sets are useful in Boolean algebras.

Definition 13.6.3 Minterm. A Boolean expression generated by

x1, x2, . . . , xk that has the form

                                                                      k

                                                 yi,

                                                                    i=1

where each yi may be either xi or xi is called a minterm generated by

x1, x2, . . . , xk. We use the notation M12···k for the minterm generated by

x1, x2, . . . , xk, where yi = xi if i = 1 and yi = x¯i if i = 0  

An example of the notation is that M110 = x1  x2  x¯3.

By a direct application of the Rule of Products we see that there are 2k

different minterms generated by x1, . . . , xk.

Definition 13.6.4 Minterm Normal Form. A Boolean expression gener-

ated by x1, . . . , xk is in minterm normal form if it is the join of expressions
of the form a  m, where a  B and m is a minterm generated by x1, . . . , xk.
That is, it is of the form

                     p                                            (13.6.1)

                     (aj  mj)

                   j=1

where p = 2k, and m1, m2, . . . , mp are the minterms generated by x1, . . . , xk.
                                                                                                     

Note 13.6.5

   · We seem to require every minterm generated by x1, . . . , xk, in (13.6.1),
       and we really do. However, some of the values of aj can be 0, which
       effectively makes the corresponding minterm disappear.

   · If B = B2, then each aj in a minterm normal form is either 0 or 1.
       Therefore, aj  mj is either 0 or mj.

Theorem 13.6.6 Uniqueness of Minterm Normal Form. Let
e (x1, . . . , xk) be a Boolean expression over B. There exists a unique minterm
normal form M (x1, . . . , xk) that is equivalent to e (x1, . . . , xk) in the sense that
e and M define the same function from Bk into B.
CHAPTER 13. BOOLEAN ALGEBRA                                                      368

    The uniqueness in this theorem does not include the possible ordering of
the minterms in M (commonly referred to as "uniqueness up to the order
of minterms"). The proof of this theorem would be quite lengthy, and not
very instructive, so we will leave it to the interested reader to attempt. The
implications of the theorem are very interesting, however.

    If |B| = 2n, then there are 2n raised to the 2k different minterm normal
forms. Since each different minterm normal form defines a different function,
there are a like number of Boolean functions from Bk into B. If B = B2, there
are as many Boolean functions (2 raised to the 2k) as there are functions from
Bk into B, since there are 2 raised to the 2n functions from Bk into B. The
significance of this result is that any desired function can be realized using
electronic circuits having 0 or 1 (off or on, positive or negative) values.

    More complex, multivalued circuits corresponding to boolean algebras with
more than two values would not have this flexibility because of the number of
minterm normal forms, and hence the number of boolean functions, is strictly
less than the number of functions.

    We will close this section by examining minterm normal forms for expres-
sions over B2 , since they are a starting point for circuit economization.

Example 13.6.7 Consider the Boolean expression f (x1, x2) = x1  x2. One
method of determining the minterm normal form of f is to think in terms of sets.
Consider the diagram with the usual translation of notation in Figure 13.6.8.
Then

                      f (x1, x2) = (x1  x2)  (x1  x2)  (x1  x2)

                                   = M00  M10  M11

Figure 13.6.8 Visualization of minterms for x1  x¯2

                                                                                                    
Table 13.6.9 Definition of the boolean function g

                  x1 x2 x3 g (x1, x2, x3)

                  000                            1

                  001                            0

                  010                            0

                  011                            1

                  100                            0

                  101                            0

                  110                            1

                  111                            0

Example  13.6.10  Consider  the  function  g  :  B3      B2  defined  by  Table  13.6.9.

                                                    2

The minterm normal form for g can be obtained by taking the join
CHAPTER 13. BOOLEAN ALGEBRA                                         369

of minterms that correspond to rows that have an image value of 1. If
g (a1, a2, a3) = 1, then include the minterm y1  y2  y3 where

                                    yj = xj       if aj = 1
                                             x¯j  if aj = 0

Or, to use alternate notation, include Ma1a2a3 in the expression if and only if
g (a1, a2, a3) = 1

    Therefore,

          g (x1, x2, x3) = (x1  x2  x3)  (x1  x2  x3)  (x1  x2  x3) .

                                                                                                     
    The minterm normal form is a first step in obtaining an economical way of
expressing a given Boolean function. For functions of more than three variables,
the above set theory approach tends to be awkward. Other procedures are
used to write the normal form. The most convenient is the Karnaugh map, a
discussion of which can be found in any logical design/switching theory text
(see, for example, [18]), on en.wikipedia.org/wiki/Karnaugh_map.

Exercises

1.

    (a) Write the 16 possible functions of Example 13.6.2.

    (b) Write out the tables of several of the above Boolean functions to
         show that they are indeed different.

    (c) Determine the minterm normal forms of

    (i) g1 (x1, x2) = x1  x2,

    (ii) g2 (x1, x2) = x1  x2

    (iii) g3 (x1, x2) = x1  x2

    (iv) g4 (x1, x2) = 1

2. Consider the Boolean expression f (x1, x2, x3) = (x3  x2)  (x1  x3) 

    (x2  x3) on  B  3  ;    ,    ,  -  .
                    2

    (a) Simplify this expression using basic Boolean algebra laws.

    (b) Write this expression in minterm normal form.

    (c) Write out the table for the given function defined by f and compare
         it to the tables of the functions in parts a and b.

        (d) How many possible different functions in three variables on
              [B2; , , -] are there?

3. Let [B; , , -] be a Boolean algebra of order 4, and let f be a Boolean
      function of two variables on B.

    (a) How many elements are there in the domain of f?

    (b) How many different Boolean functions are there of two, variables?
         Three variables?

    (c) Determine the minterm normal form of f (x1, x2) = x1  x2.
CHAPTER 13. BOOLEAN ALGEBRA  370

(d) If B = {0, a, b, 1}, define a function from B2 into B that is not a
     Boolean function.

13.7 A Brief Introduction to Switching Theory
       and Logic Design

 Disclaimer: I'm still looking for a good application for drawing logic gates.
The figures here are quite rough.

    Early computers relied on many switches to perform the logical operations
needed for computation. This was true as late as the 1970's when early personal
computers such as the Altair ( Figure 13.7.1) started to appear. Pioneering
computer scientists such as Claude Shannon realized that the operation of these
computers could be simplified by making use of an isomorphism between com-
puter circuits and boolean algebra. The term Switching Theory was used
at the time. Logical gates realized through increasingly smaller and smaller
integrated circuits still perform the same functions as in early computers, but
using purely electronic means. In this section, we give examples of some switch-
ing circuits. Soon afterward, we will transition to the more modern form of
circuits that are studied in Logic Design, where gates replace switches. Our
main goal is to give you an overview of how boolean functions corresponds to
any such circuit. We will introduce the common system notation used in logic
design and show how it corresponds with the mathematical notation of Boolean
algebras. Any computer scientist should be familiar with both systems.

Figure 13.7.1 The Altair Computer, an early PC, by Todd Dailey, Creative
Commons

    The simplest switching device is the on-off switch. If the switch is closed/
ON, current will pass through it; if it is open/OFF, current will not pass
through it. If we designate ON by 1, and OFF by 0, we can describe electrical
circuits containing switches by Boolean expressions with the variables repre-
senting the variable states of switches or the variable bits passing through
gates.

    The electronics involved in these switches take into account whether we are
negating a switch or not. For electromagnetic switches, a magnet is used to
control whether the switch is open or closed. The magnets themselves may be
controlled by simple ON/OFF switches. There are two types of electromagnetic
switches. One is normally open (OFF) when the magnet is not activated, but
activating the magnet will close the circuit and the switch is then ON. A
separate type of switch corresponds with a negated switch. For that type, the
switch is closed when the magnet is not activated, and when the magnet is
activated, the switch opens. We won't be overly concerned with the details
of these switches or the electronics corresponding to logical gates. We will
simply assume they are available to plug into a circuit. For simplicity, we use
CHAPTER 13. BOOLEAN ALGEBRA             371

the inversion symbol on a variable that labels a switch to indicate that it is a
switch of the second type, as in Figure 13.7.3.

 Standby power generators that many people have in their homes use a transfer
switch to connect the generator to the home power system. This switch is open
(OFF) if there is power coming from the normal municipal power supply. It
stays OFF because a magnet is keeping it open. When power is lost, the
magnet is no longer activated, and the switch closes and is ON. So the transfer
switch is a normally ON switch.

Figure 13.7.2 Representation of a nor-
mally OFF switch controlled by vari-Figure 13.7.3 Representation of a nor-
         mally ON switch controlled by variable
able x1
         x1

    The standard notation used for Boolean algebra operations in switching
theory and logic design is + for join, instead of ; and · for meet, instead of
. Complementation is the same in both notational systems, denoted with an
overline.

    The expression x1 · x2 represents the situation in which a series of two
switches appears in sequence as in Figure 13.7.4. In order for current to flow
through the circuit, both switches must be ON; that is, they must both have the
value 1. Similarly, a pair of parallel switches, as in Figure 13.7.5, is described
algebraically by x1 + x2. Here, current flows through this part of the circuit
as long as at least on of the switches is ON.

Figure 13.7.4 Two switches in AND
configuration realizing x1 · x2

                                                   Figure 13.7.5 Two switches in OR con-
                                                   figuration realizing x1 + x2
    All laws and concepts developed previously for Boolean algebras hold. The
only change is purely notational. We make the change in this section solely to
introduce the reader to another frequently used system of notation.
    Many of the laws of Boolean algebra can be visualized thought switching
theory. For example, the distributive law of meet over join is expressed as

                              x1 · (x2 + x3) = x1 · x2 + x1 · x3.

The switching circuit analogue of the above statement is that the circuits in
the two images below are equivalent. In circuit (b), the presence of two x1's
CHAPTER 13. BOOLEAN ALGEBRA                          372

might represent two electromagnetic switches controlled by the same magnet.

Figure 13.7.6 (a)         Figure 13.7.7 (b)

    The circuits in a computer are now composed of large quantities of gates,
which serve the same purpose as switches, but can be miniaturized to a great
degree. For example, the OR gate, usually drawn as in Figure 13.7.8 imple-
ments the logical OR function. This happens electronically, but is equivalent
to Figure 13.7.5. The AND gate, which is equivalent to two sequential switches
is shown in Figure 13.7.8.

Figure 13.7.8 An OR gate  Figure 13.7.9 An AND gate

    The complementation process is rep-
resented in a gate diagram by an in-
verter, as pictured in Figure 13.7.10.

                                                   Figure 13.7.10 Inverter, or NOT gate

    When drawing more complex circuits, multiple AND's or OR's are some-
times depicted using a more general gate drawing. For example if we want to
depict an OR gate with three inputs that is ON as long as at least one input
is ON, we would draw it as in Figure 13.7.11, although this would really be
two binary gates, as in Figure 13.7.12. Both diagrams are realizing the boolean
expression x1 + x2 + x3. Strictly speaking, the gates in Figure 13.7.12 represent
(x1 + x2) + x3, but the associative law for join tells us that the grouping doesn't
matter.

                                                   Figure 13.7.12 A ternary OR gate cre-
Figure 13.7.11 Simple version of aated with binary OR gates
ternary OR gate
CHAPTER 13. BOOLEAN ALGEBRA              373

    In Figure 13.7.13, we show a few
other commonly used gates, XOR,
NAND, and NOR, which correspond to
the boolean exressions x1  x2, x1 · x2,
and x1 + x2, respectively.

                                                   Figure 13.7.13 Other common gates

    Let's start with a logic circuit and see how the laws of boolean algebra can
help us simplify it.

Example 13.7.14 Simplification of a circuit. Consider the circuit in
Figure 13.7.15. As usual, we assume that three inputs enter on the left and
the output exits on the right.

Figure 13.7.15 Initial gate diagram
    If we trace the inputs through the gates we see that this circuit realizes the

boolean function

                    f (x1, x2, x3) = x1 · x2 · ((x1 + x2) + (x1 + x3)) .

    We simplify the boolean expression that defines f , simplifying the circuit
in so doing. You should be able to identify the laws of Boolean algebra that
are used in each of the steps. See Exercise 13.7.1.

    x1 · x2 · ((x1 + x2) + (x1 + x3)) = x1 · x2 · (x1 + x2 + x3)
                                              = x1 · x2 · x1 + x1 · x2 · x2 + x1 · x2 · x3
                                              = x1 · x2 + 0 · x1 + x3 · x1 · x2
                                              = x1 · x2 + x3 · x1 · x2
                                              = x1 · x2 · (1 + x3)
                                              = x1 · x2

Therefore, f (x1, x2, x3) = x1 · x2, which can be realized with the much simpler
circuit in Figure 13.7.16, without using the input x3.
CHAPTER 13. BOOLEAN ALGEBRA                                    374

Figure 13.7.16 Simplified gate diagram

                                                                                                     
    Next, we start with a table of desired outputs based on three bits of input
and design an efficient circuit to realize this output.

Example 13.7.17 Consider the following table of desired outputs for the three
input bits x1, x2, x3.

Table 13.7.18 Desired output table

x1 x2 x3 f (x1, x2, x3)

000                          0

001                          1

010                          0

011                          0

100                          1

101                          1

110                          0

111                          0

    The first step is to write the Minterm Normal Form of f . Since we are
working with the two value Boolean algebra, B2, the constants in each minterm
are either 0 or 1, and we simply list the minterms that have a 1. These
correspond with the rows of the table above that have an output of 1. We will
then attempt to simplify the expression as much as possible.

             f (x1, x2, x3) = (x1 · x2 · x3) + (x1 · x2 · x3) + (x1 · x2 · x3)
                               = x2 · ((x1 · x3) + (x1 · x3) + (x1 · x3))
                               = x2 · ((x1 · x3) + x1 · (x3 + x3))
                               = x2 · ((x1 · x3) + x1)

    Therefore we can realize our table with the boolean function f (x1, x2, x3) =
x2 · ((x1 · x3) + x1). A circuit diagram for this function is Figure 13.7.19. But
is this the simplest circuit that realizes the table? See Exercise 13.7.3.

Figure 13.7.19 A realization of the table of desired outputs.
CHAPTER 13. BOOLEAN ALGEBRA  375

                                                                                                     

Exercises

1. List the laws of boolean algebra that justify the steps in the simplification
      of the boolean function f (x1, x2, x3) in Example 13.7.14. Some steps use
      more than one law.

2. Write the following Boolean expression in the notation of logic design.

                                 (x1  x2)  (x1  x2)  (x1  x2) .
3. Find a further simplification of the boolean function in Example 13.7.17,

      and draw the corresponding gate diagram for the circuit that it realizes.

4. Consider the switching circuit in Figure 13.7.20.

      Figure 13.7.20 Can this circuit be simplifed?
        (a) Draw the corresponding gate diagram for this circuit.
        (b) Construct a table of outputs for each of the eight inputs to this
              circuit.
         (c) Determine the minterm normal of the Boolean function based on
              the table.
        (d) Simplify the circuit as much as possible.

5. Consider the circuit in Figure 13.7.21.

      Figure 13.7.21 Can this circuit be simplifed?
        (a) Trace the inputs though this circuit and determine the Boolean func-
              tion that it realizes.
        (b) Construct a table of outputs for each of the eight inputs to this
              circuit.
         (c) Find the minterm normal form of f .
        (d) Draw the circuit based on the minterm normal form.
CHAPTER 13. BOOLEAN ALGEBRA              376

    (e) Simplify the circuit algebraically and draw the resulting circuit.

6.  Consider the Boolean function f (x1, x2, x3, x4) = x1 +

    (x2 · (x1 + x4) + x3 · (x2 + x4)) .

    (a) Simplify f algebraically.

        (b) Draw the gate diagram based on the simplified version of f .

7. Draw a logic circuit using only AND, OR and NOT gates that realizes
      an XOR gate.

8. Draw a logic circuit using only AND, OR and NOT gates that realizes
      the Boolean function on three variables that returns 1 if the majority of
      inputs are 1 and 0 otherwise.
Chapter 14

Monoids and Automata

At first glance, the two topics that we will discuss in this chapter seem totally
unrelated. The first is monoid theory, which we touched upon in Chapter
11. The second is automata theory, in which computers and other machines
are described in abstract terms. After short independent discussions of these
topics, we will describe how the two are related in the sense that each monoid
can be viewed as a machine and each machine has a monoid associated with
it.

14.1 Monoids

Recall that in Section 11.2 we introduced systems called monoids. Here is the
formal definition.
Definition 14.1.1 Monoid. A monoid is a set M together with a binary
operation  with the properties

   ·  is associative: a, b, c  M , (a  b)  c = a  (b  c) and
   ·  has an identity in M : e  M such that a  M , a  e = e  a = a

                                                                                                     
Note 14.1.2 Since the requirements for a group contain the requirements for
a monoid, every group is a monoid.
Example 14.1.3 Some Monoids.

  (a) The power set of any set together with any one of the operations inter-
       section, union, or symmetric difference is a monoid.

  (b) The set of integers, Z, with multiplication, is a monoid. With addition,
       Z is also a monoid.

  (c) The set of n × n matrices over the integers, Mn(Z), n  2, with matrix
       multiplication, is a monoid. This follows from the fact that matrix mul-
       tiplication is associative and has an identity, In. This is an example of
       a noncommutative monoid since there are matrices, A and B, for which
       AB = BA.

  (d) [Zn; ×n] , n  2, is a monoid with identity 1.
  (e) Let X be a nonempty set. The set of all functions from X into X, often

       denoted XX , is a monoid over function composition. In Chapter 7, we saw

                                                 377
CHAPTER 14. MONOIDS AND AUTOMATA  378

that function composition is associative. The function i : X  X defined
by i(a) = a is the identity element for this system. If |X| is greater than 1
then it is a noncommutative monoid. If X is finite, XX = |X||X| . For
example, if B = {0, 1}, BB = 4. The functions z, u, i, and t, defined by
the graphs in Figure 14.1.4, are the elements of BB . This monoid is not
a group. Do you know why?

One reason why BB is noncommutative is that t  z = z  t because
(t  z)(0) = t(z(0)) = t(0) = 1 while (z  t)(0) = z(t(0)) = z(1) = 0.

                                                                                             

Figure 14.1.4 The functions on B2
    Virtually all of the group concepts that were discussed in Chapter 11 are

applicable to monoids. When we introduced subsystems, we saw that a sub-
monoid of monoid M is a subset of M ; that is, it is a monoid with the operation
of M . To prove that a subset is a submonoid, you can apply the following the-
orem.
Theorem 14.1.5 Submonoid Test. Assume [M ; ] is a monoid and K is
a nonempty subset of M . Then K is a submonoid of M if and only if the
following two conditions are met.

   · If a, b  K, then. a  b  K; i. e., K is closed with under .

   · The identity of M belongs to K.
    Often we will want to discuss the smallest submonoid that includes a certain
subset S of a monoid M . This submonoid can be defined recursively by the
following definition.

Definition 14.1.6 Submonoid Generated by a Set. If S is a subset of
monoid [M ; ], the submonoid generated by S, S, is defined by:.

  (a) (Basis) The identity of M belongs to S; and a  S  a  S.

  (b) (Recursion) a, b  S  a  b  S.

                                                                                                     
Note 14.1.7 If S = {a1, a2, . . . , an}, we write a1, a2, . . . , an in place of
{a1, a2, . . . , an}.

Example 14.1.8 Some Submonoids.

  (a) One example of a submonoid of [Z; +] is 2 = {0, 2, 4, 6, 8, . . .}.

  (b) The power set of Z, P(Z), over union is a monoid with identity . If
       S = {{1}, {2}, {3}}, then S is the power set of {1, 2, 3}. If S = {{n} :
CHAPTER 14. MONOIDS AND AUTOMATA                                                         379

n  Z}, then S is the set of finite subsets of the integers.

                                                                                                    
    As you might expect, two monoids are isomorphic if and only if there exists
a translation rule between them so that any true proposition in one monoid is
translated to a true proposition in the other.

Example 14.1.9 M = [P{1, 2, 3}; ] is isomorphic to M2 =            Z  3  ;  ·  ,  where  the
                                                                      2

operation in M2 is componentwise mod 2 multiplication. A translation rule is

that if A  {1, 2, 3}, then it is translated to (d1, d2, d3) where

           di = 1 if i  A
                     0 if i / A

Two cases of how this translation rule works are:

{1, 2, 3}  is the identity for M1      {1, 2}  {2, 3} = {2}
(1, 1, 1)                                          .

           is the identity for M2  (1, 1, 0) · (0, 1, 1) = (0, 1, 0)

                                                                                                     
    A more precise definition of a monoid isomorphism is identical to the defi-
nition of a group isomorphism, Definition 11.7.9.

Exercises

1. For each of the subsets of the indicated monoid, determine whether the
      subset is a submonoid.

        (a) S1 = {0, 2, 4, 6} and S2 = {1, 3, 5, 7} in [Z8; ×8].

        (b) {f  NN : f (n)  n, n  N} and f  NN : f (1) = 2 in the monoid
              [NN; ].

         (c) {A  Z | A is finite} and {A  Z | Ac is finite} in [P(Z); ].
2. For each subset, describe the submonoid that it generates.

        (a) {3} in [Z12; ×12]

        (b) {5} in [Z25; ×25]

         (c) the set of prime numbers in [P; ·]

        (d) {3, 5} in [N; +]
3. An n × n matrix of real numbers is called stochastic if and only if each

      entry is nonnegative and the sum of entries in each column is 1. Prove
      that the set of stochastic matrices is a monoid over matrix multiplication.
4. A semigroup is an algebraic system [S; ] with the only axiom that 
      be associative on S. Prove that if S is a finite set, then there must exist
      an idempotent element, that is, an a  S such that a  a = a.
5. Let B be a Boolean algebra and M the set of all Boolean functions on B.
      Let  be defined on M by (f  g)(a) = f (a)  g(a). Prove that [M ; ] is a
      monoid. Construct the operation table of [M ; ] for the case of B = B2.
CHAPTER 14. MONOIDS AND AUTOMATA                       380

14.2 Free Monoids and Languages

In this section, we will introduce the concept of a language. Languages are
subsets of a certain type of monoid, the free monoid over an alphabet. After
defining a free monoid, we will discuss languages and some of the basic problems
relating to them. We will also discuss the common ways in which languages
are defined.

    Let A be a nonempty set, which we will call an alphabet. Our primary
interest will be in the case where A is finite; however, A could be infinite for
most of the situations that we will describe. The elements of A are called letters
or symbols. Among the alphabets that we will use are B = {0, 1}, and the set
of ASCII (American Standard Code for Information Interchange) characters,
which we symbolize as ASCII.

Definition 14.2.1 Strings over an Alphabet. A string of length n, n  1
over alphabet A is a sequence of n letters from A: a1a2 . . . an. The null string,
, is defined as the string of length zero containing no letters. The set of strings

of length n over A is denoted by An. The set of all strings over A is denoted

A.                                                     

Note 14.2.2

(a) If the length of string s is n, we write |s| = n.

(b) The null string is not the same as the empty set, although they are similar
     in many ways. A0 = {}.

(c) A = A0  A1  A2  A3  · · · and if i = j, Ai  Aj = ; that is,
     {A0, A1, A2, A3, . . .} is a partition of A.

  (d) An element of A can appear any number of times in a string.

Theorem 14.2.3 If A is countable, then A is countable.

Proof. Case 1. Given the alphabet B = {0, 1}, we can define a bijection
from the positive integers into B. Each positive integer has a binary ex-
pansion dkdk-1 · · · d1d0, where each dj is 0 or 1 and dk = 1. If n has such
a binary expansion, then 2k  n  2k+1. We define f : P  B by
f (n) = f (dkdk-1 · · · d1d0) = dk-1 · · · d1d0, where f (1) = . Every one of
the 2k strings of length k are the images of exactly one of the integers between
2k and 2k+1 - 1. From its definition, f is clearly a bijection; therefore, B is
countable.
Case 2: A is Finite. We will describe how this case is handled with an example
first and then give the general proof. If A = {a, b, c, d, e}, then we can code
the letters in A into strings from B3. One of the coding schemes (there are
many) is a  000, b  001, c  010, d  011, and e  100. Now every
string in A corresponds to a different string in B; for example, ace. would
correspond with 000010100. The cardinality of A is equal to the cardinality of
the set of strings that can be obtained from this encoding system. The possible
coded strings must be countable, since they are a subset of a countable set, B.
Therefore, A is countable.
If |A| = m, then the letters in A can be coded using a set of fixed-length strings
from B. If 2k-1 < m  2k, then there are at least as many strings of length
k in Bk as there are letters in A. Now we can associate each letter in A with
with a different element of Bk. Then any string in A. corresponds to a string
in B. By the same reasoning as in the example above, A is countable.
Case 3: A is Countably Infinite. We will leave this case as an exercise. 
CHAPTER 14. MONOIDS AND AUTOMATA                                                    381

Definition 14.2.4 Concatenation. Let a = a1a2 · · · am and b = b1b2 · · · bn

be strings of length m and n, respectively. The concatenation of a with b, a + b,

is the string a1a2 · · · amb1b2 · · · bn of length m + n.                           

There are several symbols that are used for concatenation. We chose to use

the one that is also used in Python and SageMath.

' good '+ ' bye '

  ' goodbye '
    The set of strings over any alphabet is a monoid under concatenation.

Note 14.2.5

(a) The null string is the identity element of [A; +]. Henceforth, we will
     denote the monoid of strings over A by A.

(b) Concatenation is noncommutative, provided |A| > 1.

(c)  If  |A1|    =  |A2|,    then  the  monoids  A     and  A     are  isomorphic.  An

                                                    1          2

     isomorphism can be defined using any bijection f : A1  A2. If

     a = a1a2 · · · an  A1, f (a) = (f (a1)f (a2) · · · f (an)) defines a bijection
           A           A2 .
     from        into        We will leave it to the reader to prove that for all
              1
     a, b,  A1, f (a + b) = f (a) + f (b).

The languages of the world, English, German, Russian, Chinese, and so

forth, are called natural languages. In order to communicate in writing in any

one of them, you must first know the letters of the alphabet and then know how

to combine the letters in meaningful ways. A formal language is an abstraction

of this situation.

Definition 14.2.6 Formal Language. If A is an alphabet, a formal language

over A is a subset of A.                                                            

Example 14.2.7 Some Formal Languages.

(a) English can be thought of as a language over of letters A, B, · · · Z, both
     upper and lower case, and other special symbols, such as punctuation
     marks and the blank. Exactly what subset of the strings over this alpha-
     bet defines the English language is difficult to pin down exactly. This
     is a characteristic of natural languages that we try to avoid with formal
     languages.

(b) The set of all ASCII stream files can be defined in terms of a language
     over ASCII. An ASCII stream file is a sequence of zero or more lines
     followed by an end-of-file symbol. A line is defined as a sequence of
     ASCII characters that ends with the a "new line" character. The end-of-
     file symbol is system-dependent.

(c) The set of all syntactically correct expressions in any computer language
     is a language over the set of ASCII strings.

(d) A few languages over B are

         · L1 = {s  B | s has exactly as many 1's as it has 0's}
         · L2 = {1 + s + 0 | s  B}
         · L3 = 0, 01 = the submonoid of B generated by {0, 01}.

                                                                                    
CHAPTER 14. MONOIDS AND AUTOMATA                                        382

Investigation 14.1 Two Fundamental Problems: Recognition and
Generation. The generation and recognition problems are basic to computer
programming. Given a language, L, the programmer must know how to write
(or generate) a syntactically correct program that solves a problem. On the
other hand, the compiler must be written to recognize whether a program
contains any syntax errors.

Problem 14.2.8 The Recognition Problem. Given a formal language over

alphabet A, the Recognition Problem is to design an algorithm that determines

the truth of s  L in a finite number of steps for all s  A. Any such algorithm

is called a recognition algorithm.                                      

Definition 14.2.9 Recursive Language. A language is recursive if there

exists a recognition algorithm for it.                                  

Example 14.2.10 Some Recursive Languages.

(a) The language of syntactically correct propositions over set of proposi-
     tional variables expressions is recursive.

(b) The three languages in 7(d) are all recursive. Recognition algorithms for

     L1 and L2 should be easy for you to imagine. The reason a recognition
     algorithm for L3 might not be obvious is that the definition of L3 is more
     cryptic. It doesn't tell us what belongs to L3, just what can be used to
     create strings in L3. This is how many languages are defined. With a
     second description of L3, we can easily design a recognition algorithm.
     You can prove that

L3 = {s  B | s =  or s starts with a 0 and has no consecutive 1's}.

                                                                        

Problem 14.2.11 The Generation Problem. Design an algorithm that

generates or produces any string in L. Here we presume that A is either finite

or countably infinite; hence, A is countable by Theorem 14.2.3, and L  A

must be countable. Therefore, the generation of L amounts to creating a list

of strings in L. The list may be either finite or infinite, and you must be able

to show that every string in L appears somewhere in the list.           

Theorem 14.2.12 Recursive implies Generating.

(a) If A is countable, then there exists a generating algorithm for A.

(b) If L is a recursive language over a countable alphabet, then there exists

a generating algorithm for L.

Proof. Part (a) follows from the fact that A is countable; therefore, there

exists a complete list of strings in A.

To generate all strings of L, start with a list of all strings in A and an empty

list, W , of strings in L. For each string s, use a recognition algorithm (one

exists since L is recursive) to determine whether s  L. If s  L, add it to W ;

otherwise "throw it out." Then go to the next string in the list of A.  

Example 14.2.13 Since all of the languages in 7(d) are recursive, they must

have generating algorithms. The one given in the proof of Theorem 14.2.12

is not usually the most efficient. You could probably design more efficient

generating algorithms for L2 and L3; however, a better generating algorithm

for L1 is not quite so obvious.                                         

The recognition and generation problems can vary in difficulty depending

on how a language is defined and what sort of algorithms we allow ourselves
CHAPTER 14. MONOIDS AND AUTOMATA                        383

to use. This is not to say that the means by which a language is defined
determines whether it is recursive. It just means that the truth of the statement
"L is recursive" may be more difficult to determine with one definition than
with another. We will close this section with a discussion of grammars, which
are standard forms of definition for a language. When we restrict ourselves
to only certain types of algorithms, we can affect our ability to determine
whether s  L is true. In defining a recursive language, we do not restrict
ourselves in any way in regard to the type of algorithm that will be used. In
the next section, we will consider machines called finite automata, which can
only perform simple algorithms.

    One common way of defining a language is by means of a phrase structure
grammar (or grammar, for short). The set of strings that can be produced
using set of grammar rules is called a phrase structure language.

Example 14.2.14 Zeros before Ones. We can define the set of all strings

over B for which all 0's precede all 1's as follows. Define the starting symbol

S and establish rules that S can be replaced with any of the following: , 0S,

or S1. These replacement rules are usually called production rules. They are

usually written in the format S  , S  0S, and S  S1. Now define L to

be the set of all strings that can be produced by starting with S and applying

the production rules until S no longer appears. The strings in L are exactly

the ones that are described above.                      

Definition 14.2.15 Phrase Structure Grammar. A phrase structure

grammar consists of four components:

(1) A nonempty finite set of terminal characters, T . If the grammar is defin-
     ing a language over A, T is a subset of A.

(2) A finite set of nonterminal characters, N .

(3) A starting symbol, S  N .

(4) A finite set of production rules, each of the form X  Y , where X and
     Y are strings over A  N such that X = Y and X contains at least one
     nonterminal symbol.

    If G is a phrase structure grammar, L(G) is the set of strings that can be
produced by starting with S and applying the production rules a finite number
of times until no nonterminal characters remain. If a language can be defined
by a phrase structure grammar, then it is called a phrase structure language.

                                                                                                     
Example 14.2.16 Alternating bits language. The language over B con-
sisting of strings of alternating 0's and 1's is a phrase structure language. It
can be defined by the following grammar:

  (1) Terminal characters: , 0, and 1

  (2) Nonterminal characters: S, T , and U

  (3) Starting symbol: S

  (4) Production rules:

 ST                                   SU          S
  S0                                              S1
 S  0T                                           S  1U
T  10T                                           T  10
U  01U                                           U  01
CHAPTER 14. MONOIDS AND AUTOMATA             384

These rules can be visualized with a graph:

Figure 14.2.17 Production rules for the language of alternating 0's and 1's

We can verify that a string such as 10101 belongs to the language by starting

with S and producing 10101 using the production rules a finite number of times:

S  1U  101U  10101.                          

Example 14.2.18 Valid SageMath Variables. Let G be the grammar

with components:

(1) Terminal symbols = all letters of the alphabet (both upper and lower
     case), digits 0 through 9, and underscore

(2) Nonterminal symbols: {I, X},

(3) Starting symbol: I

(4) Production rules: I  , where  is any letter, I   + X for any letter
     , X  X +  for any letter, digit or underscore, , and X   for any
     letter, digit or underscore, . There are a total of 52 + 52 + 63 + 63 = 230
     production rules for this grammar. The language L(G) consists of all
     valid SageMath variable names.

                                                                                                    

Example 14.2.19 Backus-Naur Form. Backus-Naur form (BNF) is a
popular alternate form of defining the production rules in a grammar. If the
production rules A  B1, A  B2, . . . A  Bn are part of a grammar, they
would be written in BNF as A ::= B1 | B2 | · · · | Bn. The symbol | in BNF
is read as "or" while the ::= is read as "is defined as." Additional notations of
BNF are that {x}, represents zero or more repetitions of x and [y] means that
y is optional.
CHAPTER 14. MONOIDS AND AUTOMATA                                      385

A BNF version of the production rules for a SageMath variable, I, is

letter ::= a | b | c | · · · | z | A | B | · · · | Z
digit ::= 0 | 1 | · · · | 9
I ::= letter{letter | digit | _}

                                                                                                    
Example 14.2.20 The language of simple arithmetic expressions. An
arithmetic expression can be defined in BNF. For simplicity, we will consider
only expressions obtained using addition and multiplication of integers. The
terminal symbols are (,),+,*, -, and the digits 0 through 9. The nonterminal
symbols are E (for expression), T (term), F (factor), and N (number). The
starting symbol is E. Production rules are

                                        E: := E + T | T
                                         T ::= T  F | F
                                          F ::= (E) | N .
                                     N ::= [-]digit{digit}

                                                                                                    
    One particularly simple type of phrase structure grammar is the regular
grammar.

Definition 14.2.21 Regular Grammar. A regular (right-hand form) gram-

mar is a grammar whose production rules are all of the form A  t and A  tB,

where A and B are nonterminal and t is terminal. A left-hand form grammar

allows only A  t and A  Bt. A language that has a regular phrase structure

language is called a regular language.                                

Example 14.2.22

(a) The set of Sage variable names is a regular language since the grammar
     by which we defined the set is a regular grammar.

(b) The language of all strings for which all 0's precede all 1's (Exam-
     ple 14.2.14) is regular; however, the grammar by which we defined this
     set is not regular. Can you define these strings with a regular grammar?

(c) The language of arithmetic expressions is not regular.

                                                                      

Exercises

1.

        (a) If a computer is being designed to operate with a character set of
              350 symbols, how many bits must be reserved for each character?
              Assume each character will use the same number of bits.

        (b) Do the same for 3,500 symbols.
2. It was pointed out in the text that the null string and the null set are

      different. The former is a string and the latter is a set, two different kinds
      of objects. Discuss how the two are similar.
CHAPTER 14. MONOIDS AND AUTOMATA                    386

3. What sets of strings are defined by the following grammar?
        (a) Terminal symbols:  , 0 and 1
        (b) Nonterminal symbols: S and E
         (c) Starting symbol: S
        (d) Production rules: S  0S0, S  1S1, S  E, E  , E  0, E 
              1

4. What sets of strings are defined by the following grammar?
        (a) Terminal symbols: , a, b, and c
        (b) Nonterminal symbols: S, T, U and E
         (c) Starting symbol: S
        (d) Production rules:

S  aS  ST                                    T  bT
T U    U  cU                                 U E
       E

5. Define the following languages over B with phrase structure grammars.
      Which of these languages are regular?

(a) The strings with an odd number of characters.

(b) The strings of length 4 or less.

         (c) The palindromes, strings that are the same backwards as forwards.

6. Define the following languages over B with phrase structure grammars.
      Which of these languages are regular?

(a) The strings with more 0's than 1's.

(b) The strings with an even number of 1's.

         (c) The strings for which all 0's precede all 1's.

7. Prove that if a language over A is recursive, then its complement is also
      recursive.

8. Use BNF to define the grammars in Exercises 3 and 4.
9.

(a) Prove that if X1, X2, . . .is a countable sequence of countable sets,

                                                     

     the union of these sets,  Xi is countable.

                                                    i=1

(b) Using the fact that the countable union of countable sets is count-
     able, prove that if A is countable, then A is countable.

14.3 Automata, Finite-State Machines

In this section, we will introduce the concept of an abstract machine. The
machines we will examine will (in theory) be capable of performing many of
the tasks associated with digital computers. One such task is solving the recog-
nition problem for a language. We will concentrate on one class of machines,
CHAPTER 14. MONOIDS AND AUTOMATA                              387

finite-state machines (finite automata). And we will see that they are precisely
the machines that are capable of recognizing strings in a regular grammar.

    Given an alphabet X, we will imagine a string in X to be encoded on
a tape that we will call an input tape. When we refer to a tape, we might
imagine a strip of material that is divided into segments, each of which can
contain either a letter or a blank.

    The typical abstract machine includes an input device, the read head, which
is capable of reading the symbol from the segment of the input tape that
is currently in the read head. Some more advanced machines have a read/
write head that can also write symbols onto the tape. The movement of the
input tape after reading a symbol depends on the machine. With a finite-
state machine, the next segment of the input tape is always moved into the
read head after a symbol has been read. Most machines (including finite-state
machines) also have a separate output tape that is written on with a write
head. The output symbols come from an output alphabet, Z, that may or
may not be equal to the input alphabet. The most significant component of
an abstract machine is its memory structure. This structure can range from
a finite number of bits of memory (as in a finite-state machine) to an infinite
amount of memory that can be stored in the form of a tape that can be read
from and written on (as in a Turing machine).

Definition 14.3.1 Finite-State Machine. A finite-state machine is defined
by a quintet (S, X, Z, w, t) where

  (1) S = {s1, s2, . . . , sr} is the state set, a finite set that corresponds to the
       set of memory configurations that the machine can have at any time.

  (2) X = {x1, x2, . . . , xm} is the input alphabet.

  (3) Z = {z1, z2, . . . , zn} is the output alphabet.

  (4) w : X × S  Z is the output function, which specifies which output
       symbol w(x, s)  Z is written onto the output tape when the machine is
       in state s and the input symbol x is read.

  (5) t : X × S  S is the next-state (or transition) function, which specifies
       which state t(x, s)  S the machine should enter when it is in state s and
       it reads the symbol x.

                                                                                                     

Example 14.3.2 Vending Machine as a Finite-State Machine. Many
mechanical devices, such as simple vending machines, can be thought of as
finite-state machines. For simplicity, assume that a vending machine dispenses
packets of gum, spearmint (S), peppermint (P), and bubble (B), for 25 cents
each. We can define the input alphabet to be

               {deposit 25 cents, press S, press P, press B}

and the state set to be {Locked, Select}, where the deposit of a quarter unlocks

the release mechanism of the machine and allows you to select a flavor of

gum. We will leave it to the reader to imagine what the output alphabet,

output function, and next-state function would be. You are also invited to let

your imagination run wild and include such features as a coin-return lever and

change maker.                                                 

Example 14.3.3 A Parity Checking Machine. The following machine is
called a parity checker. It recognizes whether or not a string in B contains an
CHAPTER 14. MONOIDS AND AUTOMATA                                     388

even number of 1s. The memory structure of this machine reflects the fact that

in order to check the parity of a string, we need only keep track of whether an

odd or even number of 1's has been detected.

The input alphabet is B = {0, 1} and the output alphabet is also B. The

state set is {even, odd}. The following table defines the output and next-state

functions.

            x  s w(x, s) t(x, s)

            0 even                      0     even

            0  odd                      1     odd

            1 even                      1     odd

            1  odd                      0     even

Note how the value of the most recent output at any time is an indication

of the current state of the machine. Therefore, if we start in the even state

and read any finite input tape, the last output corresponds to the final state of

the parity checker and tells us the parity of the string on the input tape. For

example, if the string 11001010 is read from left to right, the output tape, also

from left to right, will be 10001100. Since the last character is a 0, we know

that the input string has even parity.                               

An alternate method for defining a finite-state machine is with a transition

diagram. A transition diagram is a directed graph that contains a node for

each state and edges that indicate the transition and output functions. An

edge (si, sj) that is labeled x/z indicates that in state si the input x results in

an output of z and the next state is sj. That is, w (x, si) = z and t (x, si) = sj.

The transition diagram for the parity checker appears in Figure 14.3.4. In later

examples, we will see that if there are different inputs, xi and xj, while in the

same state resulting in the same transitions and outputs, we label a single edge

xi, xj/ z instead of drawing two edges with labels xi/ z and xj/ z.

Figure 14.3.4 Transition Diagram for a Parity Checker

    One of the most significant features of a finite-state machine is that it
retains no information about its past states that can be accessed by the machine
itself. For example, after we input a tape encoded with the symbols 01101010
into the parity checker, the current state will be even, but we have no indication
within the machine whether or not it has always been in even state. Note how
the output tape is not considered part of the machine's memory. In this case,
the output tape does contain a "history" of the parity checker's past states.
We assume that the finite-state machine has no way of recovering the output
sequence for later use.

Example 14.3.5 A Baseball Machine. Consider the following simplified
version of the game of baseball. To be precise, this machine describes one half-
inning of a simplified baseball game. Suppose that in addition to home plate,
there is only one base instead of the usual three bases. Also, assume that there
are only two outs per inning instead of the usual three. Our input alphabet
will consist of the types of hits that the batter could have: out (O), double
play (DP), single (S), and home run (HR). The input DP is meant to represent
a batted ball that would result in a double play (two outs), if possible. The
CHAPTER 14. MONOIDS AND AUTOMATA                                    389

input DP can then occur at any time. The output alphabet is the numbers 0,
1, and 2 for the number of runs that can be scored as a result of any input.
The state set contains the current situation in the inning, the number of outs,
and whether a base runner is currently on the base. The list of possible states
is then 00 (for 0 outs and 0 runners), 01, 10, 11, and end (when the half-inning
is over). The transition diagram for this machine appears in Figure 14.3.6

Figure 14.3.6 Transition Diagram for a simplified game of baseball

Let's concentrate on one state. If the current state is 01, 0 outs and 1

runner on base, each input results in a different combination of output and

next-state. If the batter hits the ball poorly (a double play) the output is zero

runs and the inning is over (the limit of two outs has been made). A simple

out also results in an output of 0 runs and the next state is 11, one out and one

runner on base. If the batter hits a single, one run scores (output = 1) while

the state remains 01. If a home run is hit, two runs are scored (output = 2)

and the next state is 00. If we had allowed three outs per inning, this graph

would only be marginally more complicated. The usual game with three bases

would be quite a bit more complicated, however.                     

Example 14.3.7 Recognition in Regular Languages. As we mentioned
at the outset of this section, finite-state machines can recognize strings in a
regular language. Consider the language L over {a, b, c} that contains the
strings of positive length in which each a is followed by b and each b is followed
by c. One such string is bccabcbc. This language is regular. A grammar for
the language would be nonterminal symbols {A, B, C} with starting symbol C
and production rules A  bB, B  cC, C  aA, C  bB, C  cC, C  c.
A finite-state machine (Figure 14.3.8) that recognizes this language can be
constructed with one state for each nonterminal symbol and an additional
state (Reject) that is entered if any invalid production takes place. At the
end of an input tape that encodes a string in {a, b, c}, we will know when
the string belongs to L based on the final output. If the final output is 1, the
string belongs to L and if it is 0, the string does not belong to L. In addition,
recognition can be accomplished by examining the final state of the machine.
The input string belongs to the language if and only if the final state is C.
CHAPTER 14. MONOIDS AND AUTOMATA                                         390

Figure 14.3.8 Machine to recognize strings in L.

The construction of this machine is quite easy: note how each production

rule translates into an edge between states other than Reject. For example,

C  bB indicates that in State C, an input of b places the machine into State

B. Not all sets of production rules can be as easily translated to a finite-

state machine. Another set of production rules for L is A  aB, B  bC,

C  cA, C  cB, C  cC and C  c. Techniques for constructing finite-

state machines from production rules is not our objective here. Hence we will

only expect you to experiment with production rules until appropriate ones are

found.                                                                   

Example 14.3.9 A Binary Adder. A finite-state machine can be designed

to add positive integers of any size. Given two integers in binary form, a =

anan-1 · · · a1a0 and b = bnbn-1 · · · b1b0, the machine take as its input sequence
the corresponding bits of a and b reading from right to left with a "parity bit"

added

        a0b0 (a0 +2 b0) , a1b1 (a1 +2 b1) . . . , anbn (an +2 bn) , 111

    Notice the special input 111 at the end. All possible inputs except the last
one must even parity (contain an even number of ones). The output sequence
is the sum of a and b, starting with the units digit, and comes from the set
{0, 1, }. The transition diagram for this machine appears in Figure 14.3.10.

Figure 14.3.10 Transition Diagram for a binary adder
                                                                                                    
CHAPTER 14. MONOIDS AND AUTOMATA                                391

Exercises

1. Draw a transition diagram for the vending machine described in Exam-
      ple 14.3.2.

2. Construct finite-state machines that recognize the regular languages that
      you identified in Section 14.2.

3. What is the input set for the binary adding machine in Example 14.3.9?
4. What input sequence would be used to compute the sum of 1101 and

      0111 (binary integers)? What would the output sequence be?

5. The Gray Code Decoder. The finite-state machine defined by the follow-
      ing figure has an interesting connection with the Gray Code.

Figure 14.3.11 Gray Code Decoder

    Given a string x = x1x2 · · · xn  Bn, we may ask where x appears in
Gn. Starting in Copy state, the input string x will result in an output
string z  Bn, which is the binary form of the position of x in Gn. Recall
that positions are numbered from 0 to 2n - 1.

  (a) In what positions (0 - 31) do 10110, 00100, and 11111 appear in
       G5?

  (b) Prove that the Gray Code Decoder always works.

14.4 The Monoid of a Finite-State Machine

In this section, we will see how every finite-state machine has a monoid as-
sociated with it. For any finite-state machine, the elements of its associated
monoid correspond to certain input sequences. Because only a finite number
of combinations of states and inputs is possible for a finite-state machine there
is only a finite number of input sequences that summarize the machine. This
idea is illustrated best with a few examples.

    Consider the parity checker. The following table summarizes the effect on
the parity checker of strings in B1 and B2. The row labeled "Even" contains
the final state and final output as a result of each input string in B1 and B2
when the machine starts in the even state. Similarly, the row labeled "Odd"
contains the same information for input sequences when the machine starts in
the odd state.

 Input String        0           1          00          01          10                  11
      Even      ( Even, 0)  ( Odd, 1)   ( Even, 0)  ( Odd, 1)   ( Odd, 1)           ( Even, 0)
      Odd       ( Odd, 1)   ( Even, 1)  ( Odd, 1)   ( Even, 1)  ( Even, 0)          ( Odd, 1)

Same Effect as                               0           1           1                   0

    Note how, as indicated in the last row, the strings in B2 have the same
effect as certain strings in B1. For this reason, we can summarize the machine
in terms of how it is affected by strings of length 1. The actual monoid that
we will now describe consists of a set of functions, and the operation on the
functions will be based on the concatenation operation.

    Let T0 be the final effect (state and output) on the parity checker of the
input 0. Similarly, T1 is defined as the final effect on the parity checker of the
CHAPTER 14. MONOIDS AND AUTOMATA                                         392

input 1. More precisely,

                T0( even) = ( even, 0) and T0( odd) = ( odd, 1),

while

                T1( even) = ( odd, 1) and T1( odd) = ( even, 0).

In general, we define the operation on a set of such functions as follows: if s,

t are input sequences and Ts and Tt, are functions as above, then Ts  Tt = Tst,
that is, the result of the function that summarizes the effect on the machine by

the concatenation of s with t. Since, for example, 01 has the same effect on the

parity checker as 1, T0  T1 = T01 = T1. We don't stop our calculation at T01
because we want to use the shortest string of inputs to describe the final result.

                                                                  T0 T1

A complete table for the monoid of the parity checker is T0 T0 T1

                                                                         T1 T1 T0
What is the identity of this monoid? The monoid of the parity checker is

isomorphic to the monoid [Z2; +2].
    This operation may remind you of the composition operation on functions,

but there are two principal differences. The domain of Ts is not the codomain
of Tt and the functions are read from left to right unlike in composition, where
they are normally read from right to left.

You may have noticed that the output of the parity checker echoes the state

of the machine and that we could have looked only at the effect on the machine

as the final state. The following example has the same property, hence we will

only consider the final state.

Example 14.4.1 The transition diagram for the machine that recognizes
strings in B that have no consecutive 1's appears in Figure 14.4.2. Note
how it is similar to the graph in Figure 9.1.4. Only a "reject state" has been
added, for the case when an input of 1 occurs while in State a. We construct a
similar table to the one in the previous example to study the effect of certain
strings on this machine. This time, we must include strings of length 3 before
we recognize that no "new effects" can be found.

Figure 14.4.2 No Consecutive Ones Monoid

       Inputs 0 1 00 01 10 11 000 001 010 011 100 101 110 111

       s        ba b a b r b a b r b a r r

       a        br b a r r b a b r r r r r

       b        ba b a b r b a b r b a r r

       r        rr r r r r r r r r r r r r

       Same as  0               0 01 0 11 10 1 11 11

The following table summarizes how combinations of the strings
CHAPTER 14. MONOIDS AND AUTOMATA                          393

0, 1, 01, 10, and 11 affect this machine.

                               T0 T1 T01 T10 T11

                           T0  T0 T1 T01 T10 T11

                           T1  T10 T11 T1 T11 T11

                          T01  T0 T11 T01 T11 T11

                          T10  T10 T1 T1 T10 T11

                          T11  T11 T11 T11 T11 T11

    All the results in this table can be obtained using the previous table. For
example,

   T10  T01 = T1001 = T100  T1 = T10  T1 = T101 = T1
                                   and

          T01  T01 = T0101 = T010T1 = T0T1 = T01

Note that none of the elements that we have listed in this table serves as the

identity for our operation. This problem can always be remedied by including

the function that corresponds to the input of the null string, T. Since the

null string is the identity for concatenation of strings, TsT = TTs = Ts for

all input strings s.                                      

Example 14.4.3 The Unit-time Delay Machine. A finite-state machine
called the unit-time delay machine does not echo its current state, but prints its
previous state. For this reason, when we find the monoid of the unit-time delay
machine, we must consider both state and output. The transition diagram of
this machine appears in Figure 14.4.4.

Figure 14.4.4

Input                      0 1 00 01 10 11 100 or000 101 or001 110 or101                   111 or011
                                                                                            (1, 1)
0                          (0, 0) (1, 0) (0, 0) (1, 0) (0, 1) (1, 1) (0, 0) (1, 0) (0, 1)   (1, 1)

1                          (0, 1) (1, 1) (0, 0) (1, 0) (0, 1) (1, 1) (0, 0) (1, 0) (0, 1)    11

Same as                                                   00 01 10

Again, since no new outcomes were obtained from strings of length 3, only

strings of length 2 or less contribute to the monoid of the machine. The table

for the strings of positive length shows that we must add T to obtain a monoid.

                               T0 T1 T00 T01 T10 T11

                      T0       T00 T01 T00 T01 T10 T11

                      T1       T10 T11 T00 T01 T10 T11

                      T00      T00 T01 T00 T01 T10 T11 .

                      T01      T10 T11 T00 T01 T10 T11

                      T10      T00 T01 T00 T01 T10 T11

                      T11      T10 T11 T00 T01 T10 T11

                                                          
CHAPTER 14. MONOIDS AND AUTOMATA  394

Exercises

1. For each of the transition diagrams in Figure 5, write out tables for their
      associated monoids. Identify the identity in terms of a string of positive
      length, if possible.

      Figure 14.4.5 Exercise 1

      Hint. Where the output echoes the current state, the output can be
      ignored.
2. What common monoids are isomorphic to the monoids obtained in the
      previous exercise?
3. Can two finite-state machines with nonisomorphic transition diagrams
      have isomorphic monoids?

14.5 The Machine of a Monoid

Any finite monoid [M ; ] can be represented in the form of a finite-state ma-
chine with input and state sets equal to M . The output of the machine will be
ignored here, since it would echo the current state of the machine. Machines
of this type are called state machines. It can be shown that whatever can be
done with a finite-state machine can be done with a state machine; however,
there is a trade-off. Usually, state machines that perform a specific function
are more complex than general finite-state machines.
Definition 14.5.1 Machine of a Monoid. If [M ; ] is a finite monoid, then
the machine of M , denoted m(M ), is the state machine with state set M , input
set M , and next-state function t : M × M  M defined by t(s, x) = s  x. 
Example 14.5.2 We will construct the machine of the monoid [Z2; +2]. As
mentioned above, the state set and the input set are both Z2. The next state
function is defined by t(s, x) = s +2 x. The transition diagram for m (Z2)
appears in Figure 14.5.3. Note how it is identical to the transition diagram
of the parity checker, which has an associated monoid that was isomorphic to
[Z2; +2] .

Figure 14.5.3 The machine of [Z2; +2]
                                                                                                     
CHAPTER 14. MONOIDS AND AUTOMATA       395

Example 14.5.4 The transition diagram of the monoids [Z2; ×2] and [Z3; ×3]
appear in Figure 14.5.5.

Figure 14.5.5 The machines of [Z2; ×2] and [Z3; ×3]

                                                                                                    
Example 14.5.6 Let U be the monoid that we obtained from the unit-time
delay machine (Example 14.4.3). We have seen that the machine of the monoid
of the parity checker is essentially the parity checker. Will we obtain a unit-
time delay machine when we construct the machine of U ? We can't expect
to get exactly the same machine because the unit-time delay machine is not a
state machine and the machine of a monoid is a state machine. However, we
will see that our new machine is capable of telling us what input was received
in the previous time period. The operation table for the monoid serves as a
table to define the transition function for the machine. The row headings are
the state values, while the column headings are the inputs. If we were to draw a
transition diagram with all possible inputs, the diagram would be too difficult
to read. Since U is generated by the two elements, T0 and T1, we will include
only those inputs. Suppose that we wanted to read the transition function for
the input T01. Since T01 = T0T1, in any state s, t (s, T01) = t (t (s, T0) , T1) .
The transition diagram appears in Figure 14.5.7.

Figure 14.5.7 Unit time delay machine

If we start reading a string of 0's and 1's while in state T and are in state

Tab at any one time, the input from the previous time period (not the input

that sent us into Tab, the one before that) is a. In states T, T0 and T1, no

previous input exists.                 

Exercises

1. Draw the transition diagrams for the machines of the following monoids:
        (a) [Z4; +4]
        (b) The direct product of [Z2; ×2] with itself.
CHAPTER 14. MONOIDS AND AUTOMATA  396

2. Even though a monoid may be infinite, we can visualize it as an infinite-
      state machine provided that it is generated by a finite number of elements.
      For example, the monoid B is generated by 0 and 1. A section of its tran-
      sition diagram can be obtained by allowing input only from the generating
      set. The monoid of integers under addition is generated by the set {-1, 1}.
      The transition diagram for this monoid can be visualized by drawing a
      small portion of it, as in Figure 10. The same is true for the additive
      monoid of integers, as seen in Figure 11.

Figure 14.5.8 An infinite machine B

Figure 14.5.9 An infinite machine [Z; +]
  (a) Draw a transition diagram for {a, b, c}
  (b) Draw a transition diagram for [Z × Z; componentwise addition].
  (c) Draw a transition diagram for [Z; +] with generating set {5, -2}.
Chapter 15

Group Theory and Applica-
tions

                              alternating group

                              N objects are ordered, and you
                           Switch consecutive pairs two by two.

                                      All reorders you get
                                   Will comprise a new set
                 Called an alternating group when you're through.

      Chris Doyle, The Omnificent English Dictionary In Limerick Form

In Chapter 11, we introduced groups as a typical algebraic system. The associ-
ated concepts of subgroup, group isomorphism, and direct products of groups
were also introduced. Groups were chosen for that chapter because they are
among the simplest types of algebraic systems. Despite this simplicity, group
theory abounds with interesting applications. In this chapter we will introduce
some more important concepts in elementary group theory, and some of their
applications.

15.1 Cyclic Groups

Groups are classified according to their size and structure. A group's structure
is revealed by a study of its subgroups and other properties (e.g., whether it
is abelian) that might give an overview of it. Cyclic groups have the simplest
structure of all groups.

Definition 15.1.1 Cyclic Group. Group G is cyclic if there exists a  G

such that the cyclic subgroup generated by a, a, equals all of G. That is,

G = {na|n  Z}, in which case a is called a generator of G. The reader should
note that additive notation is used for G.
                                            

Example 15.1.2 A Finite Cyclic Group. Z12 = [Z12; +12], where +12 is
addition modulo 12, is a cyclic group. To verify this statement, all we need to

do is demonstrate that some element of Z12 is a generator. One such element
is 5; that is, 5 = Z12. One more obvious generator is 1. In fact, 1 is a
generator of every [Zn; +n]. The reader is asked to prove that if an element is
a generator, then its inverse is also a generator. Thus, -5 = 7 and -1 = 11
are the other generators of Z12. The remaining eight elements of the group are

                    397
CHAPTER 15. GROUP THEORY AND APPLICATIONS                   398

not generators.

Figure 15.1.3 Examples of "string art"

Figure 15.1.3(a) is an example of "string art" that illustrates how 5 gen-

erates Z12. Twelve tacks are placed evenly around a circle and numbered 0
through 11. A string is tied to tack 0, and is then looped around every fifth

tack. As a result, the numbers of the tacks that are reached are exactly the

ordered multiples of 5 modulo 12: 5, 10, 3, ... , 7, 0. Note that if every seventh

tack were used, the same artwork would be produced. If every third tack were

connected, as in Figure 15.1.3(b), the resulting loop would only use four tacks;

thus 3 does not generate Z12.                                             

Example 15.1.4 The Group of Integers is Cyclic. The additive group
of integers, [Z; +], is cyclic:

                          Z = 1 = {n · 1|n  Z}

This observation does not mean that every integer is the product of an integer
times 1. It means that

                 n terms                           n terms

Z = {0}  {1 + 1 + · · · + 1 | n  P}  {(-1) + (-1) + · · · + (-1) | n  P}

                                                                                                     

Theorem 15.1.5 Cyclic Implies Abelian. If [G; ] is cyclic, then it is
abelian.
Proof. Let a be any generator of G and let b, c  G. By the definition of
the generator of a group, there exist integers m and n such that b = ma and
c = na. Thus, using Theorem 11.3.14,

                               b  c = (ma)  (na)
                                     = (m + n)a
                                     = (n + m)a
                                     = (na)  (ma)
                                     =cb

                                                                                                    
    One of the first steps in proving a property of cyclic groups is to use the
fact that there exists a generator. Then every element of the group can be
expressed as some multiple of the generator. Take special note of how this is
used in theorems of this section.
    Up to now we have used only additive notation to discuss cyclic groups.
Theorem 15.1.5 actually justifies this practice since it is customary to use
additive notation when discussing abelian groups. Of course, some concrete
CHAPTER 15. GROUP THEORY AND APPLICATIONS                399

groups for which we employ multiplicative notation are cyclic. If one of its
elements, a, is a generator,

                        a = {an | n  Z}

Example 15.1.6 A Cyclic Multiplicative Group. The group of positive

integers modulo 11 with modulo 11 multiplication, [U11; ×11], is cyclic. One
of its generators is 6: 61 = 6, 62 = 3, 63 = 7,. . . , 69 = 2, and 610 = 1, the

identity of the group.                                   

Example 15.1.7 A Non-cyclic Group. The real numbers with addition,
[R; +] is a noncyclic group. The proof of this statement requires a bit more
generality since we are saying that for all r  R, r is a proper subset of
R. If r is nonzero, the multiples of r are distributed over the real line, as in
Figure 15.1.8. It is clear then that there are many real numbers, like r/2, that
are not in r.

Figure 15.1.8 Elements of r, r > 0

                                                                                                     
    The next two proofs make use of the Theorem 11.4.1.
    The following theorem shows that a cyclic group can never be very compli-
cated.

Theorem 15.1.9 Possible Cyclic Group Structures. If G is a cyclic
group, then G is either finite or countably infinite. If G is finite and |G| = n,
it is isomorphic to [Zn; +n]. If G is infinite, it is isomorphic to [Z; +].
Proof. Case 1: |G| < . If a is a generator of G and |G| = n, define  : Zn  G
by (k) = ka for all k  Zn.
Since a is finite, we can use the fact that the elements of a are the first n
nonnegative multiples of a. From this observation, we see that  is a surjection.
A surjection between finite sets of the same cardinality must be a bijection.
Finally, if p, q  Zn,

(p) + (q) = pa + qa            see exercise 10
               = (p + q)a
               = (p +n q)a
               = (p +n q)

Therefore  is an isomorphism.

Case 2: |G| = . We will leave this case as an exercise.  

Theorem 15.1.10 Subgroups of Cyclic Groups. Every subgroup of a
cyclic group is cyclic.

Proof. Let G be cyclic with generator a and let H  G. If H = {e}, H
has e as a generator. We may now assume that |H|  2 and a = e. Let
m be the least positive integer such that ma belongs to H. This is the key
step. It lets us get our hands on a generator of H. We will now show that
c = ma generates H. Certainly, c  H, but suppose that c = H. Then
there exists b  H such that b / c. Now, since b is in G, there exists n  Z
such that b = na. We now apply the division property and divide n by m.
b = na = (qm + r)a = (qm)a + ra, where 0  r < m. We note that r cannot
be zero for otherwise we would have b = na = q(ma) = qc  c. Therefore,
ra = na - (qm)a  H. This contradicts our choice of m because 0 < r < m.

                                                                                                    
CHAPTER 15. GROUP THEORY AND APPLICATIONS                400

Example 15.1.11 All subgroups of Z10. The only proper subgroups of
Z10 are H1 = {0, 5} and H2 = {0, 2, 4, 6, 8}. They are both cyclic: H1 = 5,
while H2 = 2 = 4 = 6 = 8. The generators of Z10 are 1, 3, 7, and 9. 

Example 15.1.12 All subgroups of Z. With the exception of {0}, all
subgroups of Z are isomorphic to Z. If H  Z, then H is the cyclic sub-
group generated by the least positive element of H. It is infinite and so by

Theorem 15.1.10 it is isomorphic to Z.                                       

We now cite a useful theorem for computing the order of cyclic subgroups

of a cyclic group:

Theorem 15.1.13 The order of elements of a finite cyclic group. If G
is a cyclic group of order n and a is a generator of G, the order of ka is n/d,
where d is the greatest common divisor of n and k.

Proof. The proof of this theorem is left to the reader.                      

Example 15.1.14 Computation of an order in a cyclic group. To

compute the order of 18 in Z30, we first observe that 1 is a generator of Z30
and 18 = 18(1). The greatest common divisor of 18 and 30 is 6. Hence, the

order of 18 is 30/6, or 5.                                                   

At this point, we will introduce the idea of a fast adder, a relatively modern

application (Winograd, 1965) of an ancient theorem, Sun Tzu's Theorem. We

will present only an overview of the theory and rely primarily on examples.

Out of necessity, integer addition with a computer is addition modulo n,

for n some larger number. Consider the case where n is small, like 64. Then

addition involves the addition of six-digit binary numbers. Consider the process

of adding 31 and 1. Assume the computer's adder takes as input two bit

strings a = {a0, a1, a2, a3, a4, a5} and b = {b0, b1, b2, b3, b4, b5} and outputs

s = {s0, s1, s2, s3, s4, s5}, the sum of a and b. Then, if a = 31 = (1, 1, 1, 1, 1, 0)

and b = 1 = (1, 0, 0, 0, 0, 0), s will be (0, 0, 0, 0, 0, 1), or 32. The output

s = 1 cannot be determined until all other outputs have been determined. If

addition is done with a finite-state machine, as in Example 14.3.9, the time

required to get s will be six time units, where one time unit is the time it takes

to get one output from the machine. In general, the time required to obtain

s will be proportional to the number of bits. Theoretically, this time can be

decreased, but the explanation would require a long digression and our relative

results would not change that much. We will use the rule that the number of

time units needed to perform addition modulo n is proportional to log2 n.

Now we will introduce a hypothetical problem that we will use to illustrate

the idea of a fast adder. Suppose that we had to add 1,000 numbers modulo

27720 = 8·9·5·7·11. By the rule above, since 214 < 27720 < 215, each addition

would take 15 time units. If the sum is initialized to zero, 1,000 additions would

be needed; thus, 15,000 time units would be needed to do the additions. We

can improve this time dramatically by applying Sun Tzu's Theorem. Recall

that k%n is the remainder upon division of k by n.

Theorem 15.1.15 Sun Tzu's Theorem. Let n1, n2, . . ., np be integers
that have no common factor greater than one between any pair of them; i. e.,

they are relatively prime. Let n = n1n2 · · · np. Define

                               : Zn  Zn1 × Zn2 × · · · × Znp

by
                   (k) = (k1, k2, . . . , kp) = (k%n1, k%n2, . . . , k%np)

where for 1  i  p, 0  ki < ni and k  ki (mod ni). Then  is an
isomorphism from Zn into Zn1 × Zn2 × · · · × Znp .
CHAPTER 15. GROUP THEORY AND APPLICATIONS  401

    Sun Tzu's Theorem can be stated in several different forms, and its proof
can be found in many abstract algebra texts. Older texts most likely will refer
to the theorem as the Chinese Remainder Theorem.

    As we saw in Chapter 11, Z6 is isomorphic to Z2 × Z3 . This is the smallest
case to which Sun Tzu's Theorem can be applied. An isomorphism between
Z6 and Z2 × Z3 is

                                 (0) = (0, 0) (3) = (1, 0)

                                 (1) = (1, 1) (4) = (0, 1)

                                 (2) = (0, 2) (5) = (1, 2)

    Let's consider a somewhat larger case. We start by selecting a modulus
that can be factored into a product of relatively prime integers: n = 21, 600 =
253352. In this case the factors are 25 = 32, 33 = 27, and 52 = 25. They need
not be powers of primes, but it is easy to break the factors into this form to
assure relatively prime numbers. To add in Zn, we need log2 n = 15 time
units. Let G = Z32 × Z27 × Z25. Sun Tzu's Theorem gives us an isomorphism
between Z21600 and G. The basic idea behind the fast adder, illustrated in
Figure 15.1.16, is to make use of this isomorphism. The notation x += a is
interpreted as the instruction to add the value of a to the variable x.

Figure 15.1.16 Fast Adder Scheme

    Assume we have several integers a1, . . . , am to be added. Here, we assume
m = 20. We compute the sum s to compare our result with this true sum.

 a =[1878 ,1384 ,84 ,2021 ,784 ,1509 ,1740 ,1201 ,2363 ,1774 ,
       1865 ,33 ,1477 ,894 ,690 ,520 ,198 ,1349 ,1278 ,650]

 s =0
 for t in a:

         s+=t
 s

  23692

    Although our sum is an integer calculation, we will put our calculation in
the context of the integers modulo 21600. The isomophism from Z21600 into
G = Z32 × Z27 × Z25 is defined in Sage as theta. In addition we demonstrate
that the operations in these groups are preserved by theta.

 G=cartesian_product([Integers (32),Integers (27),Integers (25)])
 def theta(x):

         return G((x%32,x%27,x%25))
 [ theta (1878) + theta (1384) ,theta (1878+1384) ]

  [(30, 22, 12), (30, 22, 12)]
    We initialize the sums in each factor of the range of theta to zero and

decompose each summand t into a triple (t) = (t1, t2, t3)  G.
CHAPTER 15. GROUP THEORY AND APPLICATIONS  402

 sum =G ((0 ,0 ,0) )
 for t in a:

         sum += theta (t)
 sum

  (12, 13, 17)

    Addition in G can be done in parallel so that each new subtotal in the form
of the triple (s1, s2, s3) takes only as long to compute as it takes to add in
the largest modulus, log2 32 = 5 time units, if calculations are done in parallel.
By the time rule that we have established, the addition of 20 numbers can be
done in 20 · 5 = 100 time units, as opposed to 20 · 15 = 300 time units if we do
the calculations in Z21600. However the result is a triple in G. The function
that performs the inverse of theta is built into most mathematics programs,
including Sage. In Sage the function is crt, short for Chinese Remainder
Theorem, the other common name of Sun Tzu's Theorem. We use this function
to compute the inverse of our triple, which is an element of Z21600. The result
isn't the true sum because the modulus 21600 is not large enough. However,
we verify that our result is congruent to the true sum modulo 21600.

 isum = crt ([12 ,13 ,17] ,[32 ,27 ,25])
 [isum ,(s-isum)%(21600)]

  [2092, 0]

    In order to get the true sum from our scheme, the modulus would need
to be increased by moving from 21600 to, for example, 21600  23 = 496800.
Mapping into the new group, G = Z32 × Z27 × Z25 × Z23 will take slightly
longer, as will the inversion process with crt, but adding the summands that
are in the form of quadruples can be done with no additional time.

    The computation of -1 (s1, s2, s3) that is done by the Sage function crt
can be accomplished in a variety of ways. All of them ultimately are sim-
plified by the fact that -1 is also an isomorphism. One approach is to
use the isomorphism property to realize that the value of -1 (s1, s2, s3) is
s1-1(1, 0, 0) + s2-1(0, 1, 0) + s3-1(0, 0, 1). The arithmetic in this expression
is in the domain of  and is more time consuming, but it need only be done
once. This is why the fast adder is only practical in situations where many
additions must be performed to get a single sum.

    The inverse images of the "unit vectors" can be computed ahead of time.

 u =[ crt ([1 ,0 ,0] ,[32 ,27 ,25]) ,
       crt ([0 ,1 ,0] ,[32 ,27 ,25]) ,crt ([0 ,0 ,1] ,[32 ,27 ,25]) ]

 u

  [7425, 6400, 7776]

    The result we computed earlier can be computed directly by in the larger
modulus.

 (7425*12 + 6400*13+ 7776* 17)%21600

  2092

    To further illustrate the potential of fast adders, consider increasing the
modulus to n = 2533527211 · 13 · 17 · 19 · 23 · 29 · 31 · 37 · 41 · 43 · 47  3.1 × 1021.
Each addition using the usual modulo n addition with full adders would take
72 time units. By decomposing each summand into 15-tuples according to Sun
Tzu's Theorem, the time is reduced to log2 49 = 6 time units per addition.
CHAPTER 15. GROUP THEORY AND APPLICATIONS  403

Exercises

1. What generators besides 1 does [Z; +] have?
2. Suppose [G; ] is a cyclic group with generator g. If you build a graph of

      with vertices from the elements of G and edge set E = {(a, g  a) | a  G},
      what would the graph look like? If G is a group of even order, what would
      a graph with edge set E = {(a, g2  a) | a  G} look like?
3. Prove that if |G| > 2 and G is cyclic, G has at least two generators.
4. If you wanted to list the generators of Zn you would only have to test
      the first n/2 positive integers. Why?
5. Which of the following groups are cyclic? Explain.

        (a) [Q; +]

        (b) [R+; ·]

         (c) [6Z; +] where 6Z = {6n|n  Z}

        (d) Z × Z

         (e) Z2 × Z3 × Z25
6. For each group and element, determine the order of the cyclic subgroup

      generated by the element:

        (a) Z25 , 15

        (b) Z4 × Z9 , (2, 6) (apply Exercise 8)

         (c) Z64 , 2
7. How can Theorem 15.1.13 be applied to list the generators of Zn? What

      are the generators of Z25? Of Z256?
8. Prove that if the greatest common divisor of n and m is 1, then (1, 1) is

      a generator of Zn × Zm, and hence, Zn × Zm is isomorphic to Znm.
9.

        (a) Illustrate how the fast adder can be used to add the numbers 21, 5,
              7, and 15 using the isomorphism between Z77 and Z7 × Z11.

        (b) If the same isomorphism is used to add the numbers 25, 26, and 40,
              what would the result be, why would it be incorrect, and how would
              the answer differ from the answer in part a?

10. Prove that if G is a cyclic group of order n with generator a, and p, q 
      {0, 1, . . . , n - 1}, then (p + q)a = (p +n q) a.

15.2 Cosets and Factor Groups

Consider the group [Z12; +12]. As we saw in the previous section, we can
picture its cyclic properties with the string art of Figure 15.1.3. Here we will
be interested in the non-generators, like 3. The solid lines in Figure 15.2.1
show that only one-third of the tacks have been reached by starting at zero
and jumping to every third tack. The numbers of these tacks correspond to
3 = {0, 3, 6, 9}.
CHAPTER 15. GROUP THEORY AND APPLICATIONS                           404

Figure 15.2.1 "String art" cosets

    What happens if you start at one of the unused tacks and again jump to
every third tack? The two broken paths on Figure 15.2.1 show that identical
squares are produced. The tacks are thus partitioned into very similar subsets.
The subsets of Z12 that they correspond to are {0, 3, 6, 9}, {1, 4, 7, 10}, and
{2, 5, 8, 11}. These subsets are called cosets. In particular, they are called
cosets of the subgroup {0, 3, 6, 9}. We will see that under certain conditions,
cosets of a subgroup can form a group of their own. Before pursuing this
example any further we will examine the general situation.

Definition 15.2.2 Coset. If [G; ] is a group, H  G and a  G, the left
coset of H generated by a is

a  H = {a  h|h  H}

and the right coset of H generated by a is

H  a = {h  a|h  H}.

                                                                                                     
Note 15.2.3

(a) H itself is both a left and right coset since e  H = H  e = H.

(b) If G is abelian, a  H = H  a and the left-right distinction for cosets can
     be dropped. We will normally use left coset notation in that situation.

Definition 15.2.4 Coset Representative. Any element of a coset is called

a representative of that coset.                                     

One might wonder whether a is in any way a special representative of a  H

since it seems to define the coset. It is not, as we shall see.

Remark 15.2.5 A Duality Principle. A duality principle can be formu-
lated concerning cosets because left and right cosets are defined in such similar
ways. Any theorem about left and right cosets will yield a second theorem
when "left" and "right" are exchanged for "right" and "left."
CHAPTER 15. GROUP THEORY AND APPLICATIONS                              405

Theorem 15.2.6 If b  a  H, then a  H = b  H, and if b  H  a, then
H  a = H  b.
Proof. In light of the remark above, we need only prove the first part of this

theorem. Suppose that x  a  H. We need only find a way of expressing x as
"b times an element of H." Then we will have proven that a  H  b  H. By
the definition of a  H, since b and x are in a  H, there exist h1 and h2 in H
such that b = a  h1 and x = a  h2. Given these two equations, a = bh1-1 and

             x = a  h2 = (b  h1-1)  h2 = b  (h1-1  h2)

Since h1, h2  H, h1-1  h2  H, and we are done with this part of the proof.
In order to show that b  H  a  H, one can follow essentially the same steps,

which we will let the reader fill in.                                  

Example 15.2.7 In Figure 15.2.1, you can start at either 1 or 7 and obtain

the same path by taking jumps of three tacks in each step. Thus,

             1 +12 {0, 3, 6, 9} = 7 +12 {0, 3, 6, 9} = {1, 4, 7, 10}.

                                                                                                    
    The set of left (or right) cosets of a subgroup partition a group in a special
way:

Theorem 15.2.8 Cosets Partition a Group. If [G; ] is a group and

H  G, the set of left cosets of H is a partition of G. In addition, all of the

left cosets of H have the same cardinality. The same is true for right cosets.

Proof. That every element of G belongs to a left coset is clear because a  aH

for all a  G. If aH and bH are left cosets, we will prove that they are either

equal or disjoint. If a  H and b  H are not disjoint, a  H  b  H is nonempty

and some element c  G belongs to the intersection. Then by Theorem 15.2.6,

c  a  H  a  H = c  H and c  b  H  b  H = c  H. Hence a  H = b  H.

We complete the proof by showing that each left coset has the same cardinality

as H. To do this, we simply observe that if a  G,  : H  a  H defined by

(h) = a  h is a bijection and hence |H| = |a  H|. We will leave the proof of

this statement to the reader.                                          

The function  has a nice interpretation in terms of our opening example.

If a  Z12, the graph of {0, 3, 6, 9} is rotated (30a) to coincide with one of the
three cosets of {0, 3, 6, 9}.

Corollary 15.2.9 A Coset Counting Formula. If |G| <  and H  G,

the number of distinct left cosets of H equals |H| |G| . For this reason we use G/H
to denote the set of left cosets of H in G

Proof. This follows from the partitioning of G into equal sized sets, one of

which is H.                                                            

Example 15.2.10 The set of integer multiples of four, 4Z, is a subgroup of
[Z; +]. Four distinct cosets of 4Z partition the integers. They are 4Z, 1 + 4Z,
2 + 4Z, and 3 + 4Z, where, for example, 1 + 4Z = {1 + 4k|k  Z}. 4Z can also
be written 0 + 4Z.
                                                                       

Convention 15.2.11 Distinguished Representatives. Although we have

seen that any representative can describe a coset, it is often convenient to

select a distinguished representative from each coset. The advantage to doing

this is that there is a unique name for each coset in terms of its distinguished

representative. In numeric examples such as the one above, the distinguished

representative is usually the smallest nonnegative representative. Remember,

this is purely a convenience and there is absolutely nothing wrong in writing

-203 + 4Z, 5 + 4Z, or 621 + 4Z in place of 1 + 4Z because -203, 5, 621  1 + 4Z.
CHAPTER 15. GROUP THEORY AND APPLICATIONS                           406

    Before completing the main thrust of this section, we will make note of a
significant implication of Theorem 15.2.8. Since a finite group is divided into
cosets of a common size by any subgroup, we can conclude:

Theorem 15.2.12 Lagrange's Theorem. The order of a subgroup of a
finite group must divide the order of the group.

    One immediate implication of Lagrange's Theorem is that if p is prime, Zp
has no proper subgroups.

    We will now describe the operation on cosets which will, under certain
circumstances, result in a group. For most of this section, we will assume that
G is an abelian group. This is one sufficient (but not necessary) condition that
guarantees that the set of left cosets will form a group.

Definition 15.2.13 Operation on Cosets. Let C and D be left cosets of
H, a subgroup of G with representatives c and d, respectively. Then

C  D = (c  H)  (d  H) = (c  d)  H

The operation  is called the operation induced on left cosets by .          

In Theorem 15.2.18, later in this section, we will prove that if G is an

abelian group,  is indeed an operation. In practice, if the group G is an

additive group, the symbol  is replaced by +, as in the following example.

Example 15.2.14 Computing with cosets of 4Z. Consider the cosets
described in Example 15.2.10. For brevity, we rename 0 + 4Z, 1 + 4Z, 2 + 4Z,
and 3 + 4Z with the symbols ¯0, ¯1, ¯2, and ¯3. Let's do a typical calculation,
¯1 + ¯3. We will see that the result is always going to be ¯0 , no matter what

representatives we select. For example, 9  ¯1, 7  ¯3, and 9 + 7 = 16  ¯0. Our

choice of the representatives ¯1 and ¯3 were completely arbitrary.          

In general, C  D can be computed in many ways, and so it is necessary

to show that the choice of representatives does not affect the result. When the

result we get for C  D is always independent of our choice of representatives,

we say that " is well defined." Addition of cosets is a well-defined operation

on the left cosets of 4Z and is summarized in the following table. Do you notice
anything familiar?

 ¯0 ¯1 ¯2 ¯3

¯0 ¯0 ¯1 ¯2 ¯3

¯1 ¯1 ¯2 ¯3 ¯0

¯2 ¯2 ¯3 ¯0 ¯1

¯3 ¯3 ¯0 ¯1 ¯2

Example 15.2.15 Cosets of the integers in the group of Real numbers.
Consider the group of real numbers, [R; +], and its subgroup of integers, Z.
Every element of R/Z has the same cardinality as Z. Let s, t  R. s  t + Z
if s can be written t + n for some n  Z. Hence s and t belong to the same
coset if they differ by an integer. (See Exercise 15.2.6 for a generalization of
this fact.)

    Now consider the coset 0.25+Z. Real numbers that differ by an integer from
0.25 are 1.25, 2.25, 3.25, . . . and -0.75, -1.75, -2.75, . . .. If any real number is
selected, there exists a representative of its coset that is greater than or equal
to 0 and less than 1. We will call that representative the distinguished repre-
sentative of the coset. For example, 43.125 belongs to the coset represented by
0.125; -6.382 + Z has 0.618 as its distinguished representative. The operation
on R/Z is commonly called addition modulo 1. A few typical calculations in
CHAPTER 15. GROUP THEORY AND APPLICATIONS                                      407

R/Z are

                      (0.1 + Z) + (0.48 + Z) = 0.58 + Z

                      (0.7 + Z) + (0.31 + Z) = 0.01 + Z .
                    -(0.41 + Z) = -0.41 + Z = 0.59 + Z
                  and in general, - (a + Z) = (1 - a) + Z

                                                                               

Example 15.2.16 Cosets in a Direct Product. Consider F = (Z4×Z2)/H,
where H = {(0, 0), (0, 1)}. Since Z4 × Z2 is of order 8, each element of F is a
coset containing two ordered pairs. We will leave it to the reader to verify that

the four distinct cosets are (0, 0) + H, (1, 0) + H, (2, 0) + H and (3, 0) + H.

The reader can also verify that F is isomorphic to Z4 , since F is cyclic. An
educated guess should give you a generator.
                                                                               

Example 15.2.17 Consider the group Z24 = Z2 × Z2 × Z2 × Z2 . Let H be
(1, 0, 1, 0), the cyclic subgroup of Z24 generate by (1,0,1,0). Since

(1, 0, 1, 0) + (1, 0, 1, 0) = (1 +2 1, 0 +2 0, 1 +2 1, 0 +2 0) = (0, 0, 0, 0)

                  4  4                       |Z42 |  16
the order of H is 2 and , Z2 /H has |Z2/H| = |H| = 2 = 8 elements. A
typical coset is

                  C = (0, 1, 1, 1) + H = {(0, 1, 1, 1), (1, 1, 0, 1)}

Note that since 2(0, 1, 1, 1) = (0, 0, 0, 0), 2C = C  C = H, the identity for the
operation on Z24/H. The orders of non-identity elements of this factor group
are all 2, and it can be shown that the factor group is isomorphic to Z23. 

Theorem 15.2.18 Coset operation is well-defined (Abelian Case). If
G is an abelian group, and H  G, the operation induced on cosets of H by
the operation of G is well defined.

Proof. Suppose that a, b, and a, b. are two choices for representatives of
cosets C and D. That is to say that a, a  C, b, b  D. We will show that
a  b and a  b are representatives of the same coset. Theorem 15.2.61 implies
that C = a  H and D = b  H, thus we have a  a  H and b  b  H. Then
there exists h1, h2  H such that a = a  h1 and b = b  h2 and so

                  a  b = (a  h1)  (b  h2) = (a  b)  (h1  h2)

by various group properties and the assumption that G is abelian, which lets

us reverse the order in which b and h1 appear in the chain of equalities. This

last expression for a  b implies that a  b  (a  b)  H since h1  h2  H

because H is a subgroup of G. Thus, we get the same coset for both pairs of

representatives.                                                               

Theorem 15.2.19 Let G be a group and H  G. If the operation induced on
left cosets of H by the operation of G is well defined, then the set of left cosets
forms a group under that operation.

Proof. Let C1, C2, and C3 be the left cosets with representatives r1, r2, and r3,
respectively. The values of C1  (C2  C3) and (C1  C2)  C3 are determined
by r1  (r2  r3) and (r1  r2)  r3, respectively. By the associativity of  in G,
these two group elements are equal and so the two coset expressions must be

equal. Therefore, the induced operation is associative. As for the identity and

inverse properties, there is no surprise. The identity coset is H, or e  H, the
coset that contains G's identity. If C is a coset with representative a; that is,
CHAPTER 15. GROUP THEORY AND APPLICATIONS            408

if C = a  H, then C-1 is a-1  H.

(a  H)  a-1  H = a  a-1  H = e  H = identity coset.

                                                     

Definition 15.2.20 Factor Group. Let G be a group and H  G. If the

set of left cosets of H forms a group, then that group is called the factor group

of "G modulo H." It is denoted G/H.                  

Note 15.2.21 If G is abelian, then every subgroup of G yields a factor group.
We will delay further consideration of the non-abelian case to Section 15.4.

Remark 15.2.22 On Notation. It is customary to use the same symbol
for the operation of G/H as for the operation on G. The reason we used
distinct symbols in this section was to make the distinction clear between the
two operations.

Exercises

1. Consider Z10 and the subsets of Z10, {0, 1, 2, 3, 4} and {5, 6, 7, 8, 9}. Why
      is the operation induced on these subsets by modulo 10 addition not well
      defined?

2. Can you think of a group G, with a subgroup H such that |H| = 6 and
      |G/H| = 6? Is your answer unique?

3. For each group and subgroup, what is G/H isomorphic to?

        (a) G = Z4 × Z2 and H = (2, 0). Compare to Example 15.2.16.

        (b) G = [C; +] and H = R.

         (c) G = Z20 and H = 8.
4. For each group and subgroup, what is G/H isomorphic to?

        (a) G = Z × Z and H = {(a, a)|a  Z}.

        (b) G = [R; ·] and H = {1, -1}.

         (c) G = Z25 and H = (1, 1, 1, 1, 1).
5. Assume that G is a group, H  G, and a, b  G. Prove that a  H = b  H

      if and only if b-1  a  H.
6.

        (a) Real addition modulo r, r > 0, can be described as the operation
              induced on cosets of r by ordinary addition. Describe a system of
              distinguished representatives for the elements of R/r.

        (b) Consider the trigonometric function sine. Given that sin(x + 2k) =
              sin x for all x  R and k  Z, show how the distinguished repre-
              sentatives of R/2 can be useful in developing an algorithm for
              calculating the sine of a number.

7. Complete the proof of Theorem 15.2.8 by proving that if a  G,  : H 
      a  H defined by (h) = a  h is a bijection.
CHAPTER 15. GROUP THEORY AND APPLICATIONS                                   409

15.3 Permutation Groups

15.3.1 The Symmetric Groups

At the risk of boggling the reader's mind, we will now examine groups whose
elements are functions. Recall that a permutation on a set A is a bijection from
A into A. Suppose that A = {1, 2, 3}. There are 3! = 6 different permutations
on A. We will call the set of all 6 permutations S3. They are listed in the
following table. The matrix form for describing a function on a finite set is
to list the domain across the top row and the image of each element directly
below it. For example r1(1) = 2.

Table 15.3.1 Elements of S3

i=    123  r1 =  123                 r2 =   123
f1 =  123  f2 =  231                 f3 =   312
      123        123                        123
      132        321                        213

    The operation that will give {i, r1, r2, f1, f2, f3} a group structure is func-
tion composition. Consider the "product" r1  f3:

      r1  f3(1) = r1 (f3(1)) = r1(2) = 3
      r1  f3(2) = r1 (f3(2)) = r1(1) = 2 .

      r1  f3(3) = r1 (f3(3)) = r1(3) = 1

    The images of 1, 2, and 3 under r1  f3 and f2 are identical. Thus, by the
definition of equality for functions, we can say r1  f3 = f2 . The complete
table for the operation of function composition is given in Table 15.3.2.

Table 15.3.2 Operation Table for S3

            i r1 r2 f1 f2 f3
           i i r1 r2 f1 f2 f3
           r1 r1 r2 i f3 f1 f2
           r2 r2 i r1 f2 f3 f1
           f1 f1 f2 f3 i r1 r2
           f2 f2 f3 f1 r2 i r1
           f3 f3 f1 f2 r1 r2 i

List 15.3.3

    We don't even need the table to verify that we have a group. Based
on the following observations, the set of all permutations on any finite
set will be a group.

  (1) Function composition is always associative.

  (2) The identity for the group is i. If g is any one of the permutations
       on A and x  A,

            (g  i)(x) = g(i(x)) = g(x) (i  g)(x) = i(g(x)) = g(x)

     Therefore g  i = i  g = g.

(3) A permutation, by definition, is a bijection. In Chapter 7 we
     proved that this implies that it must have an inverse and the
     inverse itself is a bijection and hence a permutation. Hence all
CHAPTER 15. GROUP THEORY AND APPLICATIONS  410

elements of S3 have an inverse in S3. If a permutation is displayed
in matrix form, its inverse can be obtained by exchanging the two
rows and rearranging the columns so that the top row is in order.
The first step is actually sufficient to obtain the inverse, but the
sorting of the top row makes it easier to recognize the inverse.

For example, let's consider a typical permutation on {1, 2, 3, 4, 5},
f= 1 2 3 4 5 .

         53214

f -1 = 5 3 2 1 4 = 1 2 3 4 5 .
12345  43251

Note 15.3.4 From Table 15.3.2, we can see that S3 is non-abelian. Remember,
non-abelian is the negation of abelian. The existence of two elements that don't
commute is sufficient to make a group non-abelian. In this group, r1 and f3 is
one such pair: r1  f3 = f2 while f3  r1 = f1, so r1  f3 = f3  r1. Caution:
Don't take this to mean that every pair of elements has to have this property.
There are several pairs of elements in S3 that do commute. In fact, the identity,
i, must commute with everything. Also every element must commute with its
inverse.

Definition 15.3.5 Symmetric Group. Let A be a nonempty set. The set
of all permutations on A with the operation of function composition is called
the symmetric group on A, denoted SA.

    The cardinality of a finite set A is more significant than the elements, and
we will denote by Sn the symmetric group on any set of cardinality n, n  1.

                                                                                                     

Example 15.3.6 The significance of S3. Our opening example, S3, is the
smallest non-abelian group. For that reason, all of its proper subgroups are
abelian: in fact, they are all cyclic. Figure 15.3.7 shows the Hasse diagram for
the subgroups of S3.

Figure 15.3.7 Lattice diagram of subgroups of S3

                                                                                                    
Example 15.3.8 Smallest Symmetric Groups. The only abelian symmet-
ric groups are S1 and S2 , with 1 and 2 elements, respectively. The elements
of S2 are i = 1 2 1 2 and  = 1 2 2 1 . S2 is isomorphic to Z2. 
CHAPTER 15. GROUP THEORY AND APPLICATIONS                            411

Theorem 15.3.9 For n  1, |Sn| = n! and for n  3, Sn is non-abelian.

Proof. The first part of the theorem follows from the extended rule of products

(see Chapter 2). We leave the details of proof of the second part to the reader

after the following hint. Consider f in Sn where f (1) = 2, f (2) = 3, f (3) = 1,

and f (j) = j for 3 < j  n. Therefore the cycle representation of f is (1, 2, 3).

Now define g in a similar manner so that when you compare f (g(1)) and g(f (1))

you get different results.                                           

15.3.2 Cycle Notation

A second way of describing a permutation is by means of cycles, which we
will introduce first with an example. Consider f  S8 defined using the now-
familiar matrix notation:

                            f= 1 2 3 4 5 6 7 8
                                     82765413

Consider the images of 1 when f is applied repeatedly. The images f (1),
f (f (1)), f (f (f (1))), . . . are 8, 3, 7, 1, 8, 3, 7, . . .. In Figure 15.3.10(a), this situa-
tion is represented by a graph with vertices 1, 8, 3, and 7 and shows that the
values that you get by repeatedly applying f cycle through those values. This
is why we refer to this part of f as a cycle of length 4. Of course starting at 8,
3, or 7 also produces the same cycle with only the starting value changing.

Figure 15.3.10 Representations of a cycle of length 4

    Figure 15.3.10(a) illustrates how the cycle can be represented in a visual
manner, but it is a bit awkward to write. Part (b) of the figure presents a more
universally recognized way to write a cycle. In (b), a cycle is represented by a
list where the image of any number in the list is its successor. In addition, the
last number in the list has as its image the first number.

    The other elements of the domain of f are never reached if you start in
the cycle (1, 8, 3, 7), and so looking at the images of these other numbers will
produce numbers that are disjoint from the set {1, 8, 3, 7}. The other disjoint
cycles of f are (2), (4, 6), and (5). We can express f as a product of disjoint
cycles: f = (1, 8, 3, 7)(2)(4, 6)(5) or f = (1, 8, 3, 7)(4, 6), where the absence of
2 and 5 implies that f (2) = 2 and f (5) = 5.

Note 15.3.11 Disjoint Cycles. We say that two cycles are disjoint if no
number appears in both cycles, as is the case in our expressions for f above.
Disjoint cycles can be written in any order. Thus, we could also say that
f = (4, 6)(1, 8, 3, 7).
CHAPTER 15. GROUP THEORY AND APPLICATIONS               412

Note 15.3.12 Composition of Permutations. We will now consider the
composition of permutations written in cyclic form by an example. Suppose
that f = (1, 8, 3, 7)(4, 6) and g = (1, 5, 6)(8, 3, 7, 4) are elements of S8. To
calculate f  g, we start with simple concatenation:

f  g = (1, 8, 3, 7)(4, 6)(1, 5, 6)(8, 3, 7, 4)          (15.3.1)

Although this is a valid expression for f  g, our goal is to express the compo-
sition as a product of disjoint cycles as f and g were individually written. We
will start by determining the cycle that contains 1. When combining any num-
ber of cycles, they are always read from right to left, as with all functions. The
first cycle in (15.3.1) does not contain 1; thus we move on to the second. The
image of 1 under that cycle is 5. Now we move on to the next cycle, looking
for 5, which doesn't appear. The fourth cycle does not contain a 5 either; so
f  g(1) = 5.

    At this point, we would have written "f  g = (1, 5" on paper. We repeat
the steps to determine f  g(5). This time the second cycle of (15.3.1) moves 5
to 6 and then the third cycle moves 6 to 4. Therefore, f g(5) = 4. We continue
until the cycle (1, 5, 4, 3) is completed by determining that f  g(3) = 1. The
process is then repeated starting with any number that does not appear in the
cycle(s) that have already been completed.

    The final result for our example is f  g = (1, 5, 4, 3)(6, 8, 7). Since f (2) = 2
and g(2) = 2, f  g(2) = 2 and we need not include the one-cycle (2) in the
final result, although it can be included.

Example 15.3.13 Some Compositions.

  (a) (1, 2, 3, 4)(1, 2, 3, 4) = (1, 3)(2, 4)

  (b) (1, 4)(1, 3)(1, 2) = (1, 2, 3, 4).

Notice that cyclic notation does not indicate the set which is being permuted.
The examples above could be in S5, where the image of 5 is 5. This ambiguity
is usually overcome by making the context clear at the start of a discussion.

                                                                                                     
Definition 15.3.14 Transposition. A transposition is a cycle of length 2.

                                                                                                     

Observation 15.3.15 About transpositions. f = (1, 4) and g = (4, 5) are
transpositions in S5. However, f  g = (1, 4, 5) and g  f = (1, 5, 4) are not
transpositions; thus, the set of transpositions is not closed under composition.
Since f 2 = f  f and g2 = g  g are both equal to the identity permutation, f
and g are their own inverses. In fact, every transposition is its own inverse.

Theorem 15.3.16 Decomposition into Cycles. Every cycle of length
greater than 2 can be expressed as a product of transpositions.
Proof. We need only indicate how the product of transpositions can be ob-
tained. It is easy to verify that a cycle of length k, (a1, a2, a3, . . . , ak), is equal
to the following product of k - 1 transpositions:

(a1, ak) · · · (a1, a3) (a1, a2)

                                                                                                    
    Of course, a product of cycles can be written as a product of transpositions
just as easily by applying the rule above to each cycle. For example,

(1, 3, 5, 7)(2, 4, 6) = (1, 7)(1, 5)(1, 3)(2, 6)(2, 4)
CHAPTER 15. GROUP THEORY AND APPLICATIONS     413

Unlike the situation with disjoint cycles, we are not free to change the order
of these transpositions.

15.3.3 Parity of Permutations and the Alternating Group

A decomposition of permutations into transpositions makes it possible to clas-
sify them and identify an important family of groups.

    The proofs of the following theorem appears in many abstract algebra texts.

Theorem 15.3.17 Every permutation on a finite set can be expressed as the

product of an even number of transpositions or an odd number of transpositions,

but not both.
    Theorem 15.3.17 suggests that Sn can be partitioned into its "even" and

"odd" elements. For example, the even permutations of S3 are i, r1 = (1, 2, 3) =
(1, 3)(1, 2) and r2 = (1, 3, 2) = (1, 2)(1, 3). They form a subgroup, {i, r1, r2} of
S3.

    In general:

Definition 15.3.18 The Alternating Group. Let n  2. The set of even

permutations in Sn is a proper subgroup of Sn called the alternating group on

{1, 2, . . . , n}, denoted An.                

We justify our statement that An is a group:

Theorem 15.3.19 Let n  2. The alternating group is indeed a group and
has order 2n! .
Proof. In this proof, the symbols si and ti stand for transpositions and p, q are
even nonnegative integers. If f, g  An, we can write the two permutations as
products of even numbers of transpositions, f = s1s2 · · · sp and g = t1t2 · · · tq.
Then

                                  f  g = s1s2 · · · spt1t2 · · · tq

Since p + q is even, f  g  An, and An is closed with respect to function
composition. With this, we have proven that An is a subgroup of Sn by Theo-
rem 11.5.5.

To prove the final assertion, let Bn be the set of odd permutations and let
 = (1, 2). Define  : An  Bn by (f ) = f   . Suppose that (f ) = (g).
Then f   = g   and by the right cancellation law, f = g. Hence,  is an
injection. Next we show that  is also a surjection. If h  Bn, h is the image
of an element of An. Specifically, h is the image of h   .

(h   ) = (h   )  
          = h  (   ) Why?
          = h  i Why?
          =h

Since  is a bijection, |An| = |Bn| = 2n! .    

Example 15.3.20 The Sliding Tile Puzzle. Consider the sliding-tile
puzzles pictured in Figure 15.3.21. Each numbered square is a tile and the
dark square is a gap. Any tile that is adjacent to the gap can slide into the gap.
In most versions of this puzzle, the tiles are locked into a frame so that they
can be moved only in the manner described above. The object of the puzzle
is to arrange the tiles as they appear in Configuration (a). Configurations (b)
and (c) are typical starting points. We propose to show why the puzzle can be
solved starting with (b), but not with (c).
CHAPTER 15. GROUP THEORY AND APPLICATIONS           414

Figure 15.3.21 Configurations of the sliding tile puzzle

    We will associate a change in the configuration of the puzzle with an element
of S16. Imagine that a tile numbered 16 fills in the gap. For any configuration
of the puzzle, the identity i, is the function that leave the configurate "as is."
In general, if f  S16, and 1  k  16, f (k) is the position to which the tile
in position k is moved by f that appears in the position of k in configuration
(a). If we call the functions that, starting with configuration (a), result in
configurations (b) and (c) by the names f1 and f2, respectively,

                 f1 = (1, 5, 3, 7)(2, 6, 4, 8)(9, 10)(11, 14, 13, 12)(15)(16)

and
                 f2 = (1, 5, 3, 7, 15)(2, 6, 4, 8)(9, 10)(11, 14, 13, 12)(16).

    How can we interpret the movement of one tile as a permutation? Con-
sider what happens when the 12 tile of i slides into the gap. The result
is a configuration that we would interpret as (12, 16), a single transposition.
Now if we slide the 8 tile into the 12 position, the result is or (8, 16, 12).
Hence, by "exchanging" the tiles 8 and 16, we have implemented the function
(8, 12)(12, 16) = (8, 12, 16).

Figure 15.3.22 The configuration (8, 12, 16)

Every time you slide a tile into the gap, the new permutation is a trans-

position composed with the old permutation. Now observe that to start with

initial configuration and terminate after a finite number of moves with the gap

in its original position, you must make an even number of moves. Thus, config-

uration corresponding any permutation that leaves 16 fixed cannot be solved

if the permutation is odd. Note that f2 is an odd permutation; thus, Puzzle

(c) can't be solved. The proof that all even permutations, such as f1, can be

solved is left to the interested reader to pursue.  
CHAPTER 15. GROUP THEORY AND APPLICATIONS  415

15.3.4 Dihedral Groups

Observation 15.3.23 Realizations of Groups. By now we've seen several
instances where a group can appear through an isomorphic copy of itself in
various settings. The simplest such example is the cyclic group of order 2.
When this group is mentioned, we might naturally think of the group [Z2; +2],
but the groups [{-1, 1}; ·] and [S2; ] are isomorphic to it. None of these groups
are necessarily more natural or important than the others. Which one you use
depends on the situation you are in and all are referred to as realizations
of the cyclic group of order 2. The next family of groups we will study, the
dihedral groups, has two natural realizations, first as permutations and second
as geometric symmetries.

    The family of dihedral groups is indexed by the positive integers greater
than or equal to 3. For k  3, Dk will have 2k elements. We first describe the
elements and the operation on them using geometry.

    We can describe Dn in terms of symmetries of a regular n-gon (n = 3:
equilateral triangle, n = 4: square, n = 5: regular pentagon,. . .). Here we
will only concentrate on the case of D4. If a square is fixed in space, there are
several motions of the square that will, at the end of the motion, not change
the apparent position of the square. The actual changes in position can be seen
if the corners of the square are labeled. In Figure 15.3.24, the initial labeling
scheme is shown, along with the four axes of symmetry of the square.

Figure 15.3.24 Axes of symmetry of the square

    It might be worthwhile making a square like this with a sheet of paper. Be
careful to label the back so that the numbers match the front. Two motions of
the square will be considered equivalent if the square is in the same position
after performing either motion. There are eight distinct motions. The first
four are 0, 90, 180, and 270 clockwise rotations of the square, and the
other four are the 180 flips along the axes l1, l2, l3, and l4. We will call
the rotations i, r1, r2, and r3, respectively, and the flips f1, f2, f3, and f4,
respectively. Figure 15.3.25 illustrates r1 and f1. For future reference, we also
include the permutations to which they correspond.
CHAPTER 15. GROUP THEORY AND APPLICATIONS  416

Figure 15.3.25 Two elements of D4

    What is the operation on this set of symmetries? We will call the operation
"followed by" and use the symbol  to represent it. The operation will be to
combine motions, applying motions from right to left, as with functions. We
will illustrate how  is computed by finding r1  f1. Starting with the initial
configuration, if you perform the f1 motion, and then immediately perform r1
on the result, we get the same configuration as if we just performed f4, which
is to flip the square along the line l4. Therefore, r1  f1 = f4. An important
observation is that f1  r1 = f4, meaning that this group is nonabelian. The
reader is encouraged to verify this on their own.

    We can also realize the dihedral groups as permutations. For any symmetric
motion of the square we can associate with it a permutation. In the case of D4,
the images of each of the numbers 1 through 4 are the positions on the square
that each of the corners 1 through 4 are moved to. For example, since corner 4
moves to position 1 when you perform r1, the corresponding function will map
4 to 1. In addition, 1 gets mapped to 2, 2 to 3 and 3 to 4. Therefore, r1 is the
cycle (1, 2, 3, 4) . The flip f1 transposes two pairs of corners and corresponds
to (1, 4)(2, 3). If we want to combine these two permutations, using the same
names as with motions, we get

                r1  f1 = (1, 2, 3, 4)  (1, 4)(2, 3) = (1)(2, 4)(3) = (2, 4)

Notice that this permutation corresponds with the flip f4.
    Although D4 isn't cyclic (since it isn't abelian), it can be generated from

the two elements r1 and f1:

             D4 = r1, f1 = i, r1, r12, r13, f1, r1  f1, r12  f1, r13  f1

    It is quite easy to describe any of the dihedral groups in a similar fashion.
Here is the formal definition
CHAPTER 15. GROUP THEORY AND APPLICATIONS                                    417

Definition 15.3.26 Dihedral Group. Let n be a positive integer greater
than or equal to 3. If r = (1, 2, . . . , n), an n-cycle, and f = (1, n)(2, n - 1) . . .
Then

       Dn = r, f  = i, r, r2, . . . , rn-1, f, r  f, r2  f, . . . , rn-1  f

is the nth dihedral group.                                                   

Note 15.3.27 Caution. You might notice that we use a script D, D, for the
dihedral groups. Occasionally you might see an ordinary D in other sources
for the dihedral groups. Don't confuse it with the set of divisors of n, which
we denote by Dn. Normally the context of the discussion should make the
meaning of Dn clear.

Example 15.3.28 A Letter-facing Machine. An application of D4 is in
the design of a letter-facing machine. Imagine letters entering a conveyor belt
to be postmarked. They are placed on the conveyor belt at random so that
two sides are parallel to the belt. Suppose that a postmarker can recognize
a stamp in the top right corner of the envelope, on the side facing up. In
Figure 15.3.29, a sequence of machines is shown that will recognize a stamp
on any letter, no matter what position in which the letter starts. The letter P
stands for a postmarker. The letters R and F stand for rotating and flipping
machines that perform the motions of r1 and f1.

Figure 15.3.29 A letter facer

The arrows pointing up indicate that if a letter is postmarked, it is taken

off the conveyor belt for delivery. If a letter reaches the end, it must not

have a stamp. Letter-facing machines like this have been designed (see [16]).

One economic consideration is that R-machines tend to cost more than F -

machines. R-machines also tend to damage more letters. Taking these facts

into consideration, the reader is invited to design a better letter-facing machine.

Assume that R-machines cost $800 and F -machines cost $500. Be sure that

all corners of incoming letters will be examined as they go down the conveyor

belt.                                                                        

15.3.5 Exercises

1. Given f = 1 2 3 4 , g = 1 2 3 4 , and h =
                      2143                     2341

       1 2 3 4 , compute
       3241

       (a) f  g                                (e) h-1

       (b) g  h                                (f) h-1  g  h
       (c) (f  g)  h

       (d) f  (g  h)           (g) f -1

2. Write f , g, and h from Exercise 1 as products of disjoint cycles and

       determine whether each is odd or even.
CHAPTER 15. GROUP THEORY AND APPLICATIONS  418

3. Do the left cosets of A3 = {i, r1, r2} over S3 form a group under the
      induced operation on left cosets of A3? What about the left cosets of
      f1?

4. In its realization as permutations, the dihedral group D3 is equal to S3.
      Can you give a geometric explanation why? Why isn't D4 equal to S4?

5.

        (a) Complete the list of elements of D4 and write out a table for the
              group in its realization as symmetries.

        (b) List the subgroups of D4 in a lattice diagram. Are they all cyclic?
              To what simpler groups are the subgroups of D4 isomorphic?

6. Design a better letter-facing machine (see Example 15.3.28). How can
      you verify that a letter-facing machine does indeed check every corner of a
      letter? Can it be done on paper without actually sending letters through
      it?

7. Prove by induction that if r  1 and each ti, is a transposition, then
      (t1  t2  · · ·  tr) -1 = tr  · · ·  t2  t1

8. How many elements are there in D5 ? Describe them geometrically.
9. Complete the proof of Theorem 15.3.9.
10. How many left cosets does An, n  2 have?
11. Prove that f  r = rn-1  f in Dn.
12.

        (a) Prove that the tile puzzles corresponding to A16 
              { f  S16| f (16) = 16} are solvable.

        (b) If f (16) = 16, how can you determine whether f 's puzzle is solvable?
13.

        (a) Prove that S3 is isomorphic to R3, the group of 3 × 3 rook matrices
             (see Section 11.2 exercises).

        (b) Prove that for each n  2, Rn is isomorphic to Sn.

15.4 Normal Subgroups and Group Homomor-
       phisms

Our goal in this section is to answer an open question from earlier in this
chapter and introduce a related concept. The question is: When are left cosets
of a subgroup a group under the induced operation? This question is open for
non-abelian groups. Now that we have some examples to work with, we can
try a few experiments.

15.4.1 Normal Subgroups

Example 15.4.1 Cosets of A3. We have seen that A3 = {i, r1, r2} is a
subgroup of S3, and its left cosets are A3 itself and B3 = {f1, f2, f3}. Whether
{A3, B3} is a group boils down to determining whether the induced operation
is well defined. Consider the operation table for S3 in Figure 15.4.2.
CHAPTER 15. GROUP THEORY AND APPLICATIONS        419

Figure 15.4.2 Operation table for S3

    We have shaded in all occurrences of the elements of B3 in gray. We will
call these elements the gray elements and the elements of A3 the white ones.

    Now consider the process of computing the coset product A3  B3. The
"product" is obtained by selecting one white element and one gray element.

Note that white "times" gray is always gray. Thus, A3  B3 is well defined.
Similarly, the other three possible products are well defined. The table for the

factor group S3/A3 is

                                          A3 B3

                       A3 A3 B3
                       B3 B3 A3

Clearly, S3/A3 is isomorphic to Z2. Notice that A3 and B3 are also the
right cosets of A3. This is significant.
                                                 

Example 15.4.3 Cosets of another subgroup of S3. Now let's try the
left cosets of f1 in S3. There are three of them. Will we get a complicated
version of Z3? The left cosets are C0 = f1, C1 = r1 f1 = {r1, f3}, and
C2 = r2 f1 = {r2, f2}.

    The reader might be expecting something to go wrong eventually, and here

it is. To determine C1  C2 we can choose from four pairs of representatives:

 r1  C1, r2  C2 - r1  r2 = i  C0
r1  C1, f2  C2 - r1  f2 = f  C0
f3  C1, r2  C2 - f3  r2 = f2  C2
f3  C1, f2  C2 - f3  f2 = r2  C2

This time, we don't get the same coset for each pair of representatives. There-
fore, the induced operation is not well defined and no factor group is produced.

                                                                                                    
Observation 15.4.4 This last example changes our course of action. If we
had gotten a factor group from {C0, C1, C2}, we might have hoped to prove
that every collection of left cosets forms a group. Now our question is: How
can we determine whether we will get a factor group? Of course, this question
is equivalent to: When is the induced operation well defined? There was only
CHAPTER 15. GROUP THEORY AND APPLICATIONS                         420

one step in the proof of Theorem 15.2.18, where we used the fact that G was
abelian. We repeat the equations here:

                   a  b = (a  h1)  (b  h2) = (a  b)  (h1  h2)

since G was abelian.

    The last step was made possible by the fact that h1 b = bh1. As the proof
continued, we used the fact that h1  h2 was in H and so a  b is (a  b)  h
for some h in H. All that we really needed in the "abelian step" was that

h1  b = b  (something in H) = b  h3. Then, since H is closed under G's
operation, h3  h2 is an element of H. The consequence of this observation is
that we define a certain kind of subgroup that guarantees that the inducted

operation is well-defined.

Definition 15.4.5 Normal Subgroup. If G is a group, H  G, then H is

a normal subgroup of G, denoted H  G, if and only if every left coset of H is

a right coset of H; i. e. a  H = H  a a  G                        

Theorem 15.4.6 If H  G, then the operation induced on left cosets of H
by the operation of G is well defined if and only if any one of the following
conditions is true:

(a) H is a normal subgroup of G.

(b) If h  H, a  G, then there exists h  H such that h  a = a  h.

(c) If h  H, a  G, then a-1  h  a  H.

Proof. We leave the proof of this theorem to the reader.          

Be careful, the following corollary is not an "...if and only if..." statement.

Corollary 15.4.7 If H  G, then the operation induced on left cosets of H
by the operation of G is well defined if either of the following two conditions is
true.

(a) G is abelian.

(b) |H| = 2 |G| .

Example 15.4.8 A non-normal subgroup. The right cosets of f1  S3
are {i, f1}, {r1f2}, and {r2, f3}. These are not the same as the left cosets of
f1. In addition, f2-1f1f2 = f2f1f2 = f3 / f1. Thus, f1 is not normal.

                                                                                                    
    The improper subgroups {e} and G of any group G are normal subgroups.
G/{e} is isomorphic to G. All other normal subgroups of a group, if they exist,
are called proper normal subgroups.

Example 15.4.9 By Condition b of Corollary 15.4.7, An is a normal subgroup

of Sn and Sn/An is isomorphic to Z2.                              

Example 15.4.10 Subgroups of A5. A5, a group in its own right with
60 elements, has many proper subgroups, but none are normal. Although this

could be done by brute force, the number of elements in the group would make

the process tedious. A far more elegant way to approach the verification of this

statement is to use the following fact about the cycle structure of permutations.

If f  Sn is a permutation with a certain cycle structure, 12 · · · k, where the
length of i is i, then for any g  Sn, g-1  f  g, which is the conjugate of f by
g, will have a cycle structure with exactly the same cycle lengths. For example
CHAPTER 15. GROUP THEORY AND APPLICATIONS                              421

if we take f = (1, 2, 3, 4)(5, 6)(7, 8, 9)  S9 and conjugate by g = (1, 3, 5, 7, 9),

          g-1  f  g = (1, 9, 7, 5, 3)  (1, 2, 3, 4)(5, 6)(7, 8, 9)  (1, 3, 5, 7, 9)
                        = (1, 4, 9, 2)(3, 6)(5, 8, 7)

Notice that the condition for normality of a subgroup H of G is that the

conjugate of any element of H by an element of G must be remain in H.

To verify that A5 has no proper normal subgroups, you can start by cata-

loging the different cycle structures that occur in A5 and how many elements

have those structures. Then consider what happens when you conjugate these

different cycle structures with elements of A5. An outline of the process is in

the exercises.                                                         

Example 15.4.11 Let G be the set of two by two invertible matrices of real

numbers. That is,

                G = a b | a, b, c, d  R, ad - bc = 0
                            cd

We saw in Chapter 11 that G is a group with matrix multiplication.

This group has many subgroups, but consider just two: H1 =

a0              a = 0 and H2 =  a0           ad = 0 . It is fairly simple to
0a                              0d

apply one of the conditions we have observed for normallity that H1 a normal

subgroup of G, while H2 is not normal in G.                            

15.4.2 Homomorphisms

Think of the word isomorphism. Chances are, one of the first images that
comes to mind is an equation something like

                   (x  y) = (x)  (y)

An isomorphism must be a bijection, but the equation above is the algebraic
property of an isomorphism. Here we will examine functions that satisfy equa-
tions of this type.

Definition 15.4.12 Homomorphism. Let [G; ] and [G; ] be groups.
 : G  G is a homomorphism if (x  y) = (x)  (y) for all x, y  G. 

    Many homomorphisms are useful since they point out similarities between
the two groups (or, on the universal level, two algebraic systems) involved.

Example 15.4.13 Decreasing modularity. Define  : Z6  Z3 by (n) =
n mod 3. Therefore, (0) = 0, (1) = 1, (2) = 2, (3) = 1 + 1 + 1 = 0,
(4) = 1, and (5) = 2. If n, m  Z6. We could actually show that  is a
homomorphism by checking all 62 = 36 different cases for the formula

                   (n +6 m) = (n) +3 (m)                            (15.4.1)

but we will use a line of reasoning that generalizes. We have already encoun-
tered Sun Tzu's Theorem, which implies that the function  : Z6  Z3 × Z2
defined by (n) = (n mod 3, n mod 2). We need only observe that equating
the first coordinates of both sides of the equation

                                  (n +6 m) = (n) + (m)              (15.4.2)
gives us precisely the homomorphism property.                              
CHAPTER 15. GROUP THEORY AND APPLICATIONS                  422

Theorem 15.4.14 Group Homomorphism Properties. If  : G  G is
a homomorphism, then:

(a) (e) = (the identity of G) = the identity of G = e.

  (b)  a-1 = (a)-1 for all a  G.

  (c) If H  G, then (H) = {(h)|h  H}  G.
Proof.

(a) Let a be any element of G. Then (a)  G.

(a)  e = (a) by the definition of e
           = (a  e) by the definition of e
           = (a)  (e) by the fact that  is a homomorphism

By cancellation, e = (e).

(b) Again, let a  G. e = (e) =  a  a-1 = (a)   a-1 . Hence, by the
     uniqueness of inverses, (a)-1 =  a-1 .

(c) Let b1, b2  (H). Then there exists a1, a2  H such that  (a1) = b1,
      (a2) = b2. Recall that a compact necessary and sufficient condition for
     H  G is that x  y-1  H for all x, y  H. Now we apply the same
     condition in G:

                               b1  b2-1 =  (a1)   (a2) -1

                                           =  (a1)   a2-1

                                           =  a1  a2-1  (H)

since a1  a2-1  H, and so we can conclude that (H)  G.

                                                                                                     
Corollary 15.4.15 Since a homomorphism need not be a surjection and part
(c) of Theorem 15.4.14 is true for the case of H = G, the range of , (G), is
a subgroup of G

Example 15.4.16 If we define  : Z  Z/4Z by (n) = n + 4Z, then  is a
homomorphism. The image of the subgroup 4Z is the single coset 0 + 4Z, the
identity of the factor group. Homomorphisms of this type are called natural
homomorphisms. The following theorems will verify that  is a homomorphism
and also show the connection between homomorphisms and normal subgroups.
The reader can find more detail and proofs in most abstract algebra texts. 

Theorem 15.4.17 If H  G, then the function  : G  G/H defined by
(a) = aH is a homomorphism.

Proof. We leave the proof of this theorem to the reader.   

Definition 15.4.18 Natural Homomorphism. If H  G, then the function
 : G  G/H defined by (a) = aH is called the natural homomorphism. 

    Based on Theorem 15.4.17, every normal subgroup gives us a homomor-
phism. Next, we see that the converse is true.

Definition 15.4.19 Kernel of a homomorphism. Let  : G  G be a

homomorphism, and let e and e be the identities of G and G, respectively.

The kernel of  is the set ker  = {a  G | (a) = e}          
CHAPTER 15. GROUP THEORY AND APPLICATIONS                                 423

Theorem 15.4.20 Let  : G  G be a homomorphism from G into G . The
kernel of  is a normal subgroup of G.

Proof. Let K = ker . We can see that K is a subgroup of G by letting
a, b  K and verify that a  b-1  K by computing (a  b-1) = (a)  (b)-1 =
e  e-1 = e. To prove normality, we let g be any element of G and k  K.
We compute (g  k  g-1) to verify that g  k  g-1  K.

     (g  k  g-1) = (g)  (k)  (g-1)
                       = (g)  (k)  (g)-1
                       = (g)  e  (g)-1
                       = (g)  (g)-1
                       = e

                                                                                                    
    Based on this most recent theorem, every homomorphism gives us a normal
subgroup.

Theorem 15.4.21 Fundamental Theorem of Group Homomorphisms.
Let  : G  G be a homomorphism. Then (G) is isomorphic to G/ ker .

Example 15.4.22 Define  : Z  Z10 by (n) = n mod 10. The three
previous theorems imply the following:

   ·  : Z  Z/10Z defined by (n) = n + 10Z is a homomorphism.

   · {n  Z|(n) = 0} = {10n | n  Z} = 10Z  Z.

   · Z/10Z is isomorphic to Z10.

                                                                                                    
Example 15.4.23 Let G be the same group of two by two invertible real
matrices as in Example 15.4.11. Define  : G  G by (A) =  A . We

                                                                                                                               |det A|

will let the reader verify that  is a homomorphism. The theorems above imply
the following.

· ker  = {A  G|(A) = I} =  a0                 | a  R, a = 0  G. This
                           0a

verifies our statement in Example 15.4.11. As in that example, let ker  =

H1.

· G /H1 is isomorphic to {A  G | det A = 1}.

·  : G  G /H1 defined, naturally, by (A) = AH1 is a homomorphism.

                                                                                                    
    For the remainder of this section, we will be examining certain kinds of
homomorphisms that will play a part in our major application to homomor-
phisms, coding theory.

Example 15.4.24 Consider  : Z22  Z23 defined by (a, b) = (a, b, a +2 b).
If (a1, b1) , (a2, b2)  Z22,

 ((a1, b1) + (a2, b2)) =  (a1 +2 a2, b1 +2 b2)
                            = (a1 +2 a2, b1 +2 b2, a1 +2 a2 +2 b1 +2 b2)
                            = (a1, b1, a1 +2 b1) + (a2, b2, a2 +2 b2)
                            =  (a1, b1) +  (a2, b2)
CHAPTER 15. GROUP THEORY AND APPLICATIONS                        424

Since (a, b)=(0, 0, 0) implies that a = 0 and b = 0, the kernel of  is

{(0, 0)}. By previous theorems,  Z22 = {(0, 0, 0), (1, 0, 1), (0, 1, 1), (1, 1, 0)}
is isomorphic to Z22.
                                                                 

We can generalize the previous example as follows: If n, m  1 and A is an

m × n matrix of 0's and 1's (elements of Z2), then  : Z2m  Z2n defined by

                        (a1, a2, ..., am) = (a1, a2, ..., am) A

is a homomorphism. This is true because matrix multiplication is distributive

over addition. The only new idea here is that computation is done in Z2. If
a = (a1, a2, ..., am) and b = (b1, b2, ..., bm), (a + b)A = aA + bA is true by basic
matrix laws. Therefore, (a + b) = (a) + (b).

15.4.3 Exercises

1. Which of the following functions are homomorphisms? What are the
      kernels of those functions that are homomorphisms?

(a) 1 : R  R+ defined by 1(a) = |a|.

(b) 2 : Z5  Z2 where 2(n) =  0 if n is even .
                             1 if n is odd

         (c) 3 : R × R  R, where 3(a, b) = a + b.

        (d) 4 : S4  S4 defined by 4(f ) = f  f = f 2.
2. Which of the following functions are homomorphisms? What are the

      kernels of those functions that are homomorphisms?

        (a) 1 : M2×2(R)  R, defined by 1(A) = A11A22 + A12A21.

        (b) 2 : (R)2  R defined by 2(a, b) = ab.

         (c) 3 : { A  M2×2(R)| det A = 0}  R, where 3(A) = det A.

        (d) 4 : S4  S4 defined by 4(f ) = f -1.
3. Show that D4 has one proper normal subgroup, but that (1, 4)(2, 3) is

      not normal.
4. Prove that the function  in Example 15.4.23 is a homomorphism.

5. Define the two functions  : Z23  Z24 and  : Z24  Z2 by
       (a1, a2, a3) = (a1, a2, a3, a1 +2 a2 +2 a3), and  (b1, b2, b3, b4) = b1 + b2 +
      b3 + b4 Describe the function   . Is it a homomorphism?

6. Express  in Example 15.4.23 in matrix form.

7. Prove that if G is an abelian group, then q(x) = x2 defines a homomor-
      phism from G into G. Is q ever an isomorphism?

8. Prove that if  : G  G is a homomorphism, and H G, then (H)(G).
      Is it also true that (H)  G?

9. Prove that if  : G  G is a homomorphism, and H  (G), then
      -1(H) = {a  G|(a)  H}  G.

10. Following up on Example 15.4.10, prove that A5 is a simple group; i. e.,
      it has no proper normal subgroups.

(a) Make a list of the different cycle structures that occur in A5 and
     how many elements have those structures.

(b) Within each set of permutations with different cycle structures, iden-
CHAPTER 15. GROUP THEORY AND APPLICATIONS  425

     tify which subsets are closed with respect to the conjugation opera-
     tion. With this you will have a partition of A5 into conjugate classes
     where for each class, C, f, g  C if and only if   A5 such that
     -1  f   = g.

(c) Use the fact that a normal subgroup of A5 needs to be a union of
     conjugate classes and verify that no such union exists.

15.5 Coding Theory, Linear Codes

A Transmission Problem. In this section, we will introduce the basic ideas
involved in coding theory and consider solutions of a coding problem by means
of linear codes.

    Imagine a situation in which information is being transmitted between two
points. The information takes the form of high and low pulses (for example,
radio waves or electric currents), which we will label 1 and 0, respectively.
As these pulses are sent and received, they are grouped together in blocks of
fixed length. The length determines how much information can be contained
in one block. If the length is r, there are 2r different values that a block
can have. If the information being sent takes the form of text, each block
might be a character. In that case, the length of a block may be seven, so
that 27 = 128 block values can represent letters (both upper and lower case),
digits, punctuation, and so on. During the transmission of data, noise can
alter the signal so that what is received differs from what is sent. Figure 15.5.1
illustrates the problem that can be encountered if information is transmitted
between two points.

Figure 15.5.1 A noisy transmission

    Noise is a fact of life for anyone who tries to transmit information. For-
tunately, in most situations we could expect a high percentage of the pulses
that are sent to be received properly. However, when large numbers of pulses
are transmitted, there are usually some errors due to noise. For the remainder
of the discussion, we will make assumptions about the nature of the noise and
the message that we want to send. Henceforth, we will refer to the pulses as
bits.

    We will assume that our information is being sent along a binary sym-
metric channel. By this, we mean that any single bit that is transmitted will
be received improperly with a certain fixed probability, p, independent of the
bit value. The magnitude of p is usually quite small. To illustrate the process,
we will assume that p = 0.001, which, in the real world, would be considered
somewhat large. Since 1 - p = 0.999, we can expect 99.9% of all bits to be
properly received.

    In addition to assuming p = 0.001 throughout, we will also suppose that our
message consists of 3,000 bits of information. Two factors will be considered
in evaluating a method of transmission. The first is the probability that the
message is received with no errors. The second is the number of bits that will
be transmitted in order to send the message. This quantity is called the rate
of transmission:

Rate =  Message length

        Number of bits transmitted
CHAPTER 15. GROUP THEORY AND APPLICATIONS                                               426

As you might expect, as we devise methods to improve the probability of

success, the rate will decrease.

Suppose that we ignore the noise and transmit the message without any

coding. The probability of success is 0.9993000 = 0.0497124. Therefore we only

successfully receive the message in a totally correct form less than 5% of the

time.  The  rate  of  3000  =  1  certainly  doesn't  offset  this  poor  probability.
                      3000
Our strategy for improving our chances of success will be to send an encoded

message. The encoding will be done in such a way that small errors can be

identified and corrected. This idea is illustrated in Figure 15.5.2.

Figure 15.5.2 The Coding Process

    In all of our examples, the functions that will correspond to our encoding
devices will involve multiplication of messages by matrices using mod 2 arith-
metic. First we will introduce some geometric ideas to make the process more
intuitive.

15.5.1 Introduction

Although we'll be using algebra to help improve communications, the basic
solution can be imagined from a geometric point of view. For any positive
integer n, we define a distance function on the elements of the group Z2n.
This distance is called the Hamming Distance.

Definition 15.5.3 Hamming Distance. Given two elements of Z2n, a and
b, the Hamming Distance, dH (a, b) between them is the number of positions in

which they differ.                                                                      

    For example, dH ((1, 1, 0, 0), (1, 1, 0, 1)) = 1 since these two elements of Z24
differ in just the last position; and dH ((1, 1, 0, 0), (1, 1, 0, 0)) = 0. Notice that

we can compute the distance between two bit strings by adding them coordi-

natewise in the Cartesian product and counting the number 1's that appear in

the sum. For example (1, 1, 0, 0) + (1, 0, 0, 1) = (0, 1, 0, 1). The sum has two 1's,

so the distance between (1, 1, 0, 0) and (1, 0, 0, 1) is 2. In addition, the location

of the 1's in the sum tell us where the two bit strings differ.

    When we look at groups like Z24 from a point of view, we refer to these
sets as metric spaces or simply spaces. In the case of Z24, there are just
24 = 16 points in the space and the maximum distance between the points

is 4. More generally Z2n has 2n points and the maximum distance between
points in that space is n. Looking at the group Z2n from this geometric point
of view is essentially the same as the n-cube 9.4.17 we considered in discussing

Hamiltonian graphs. In this section we will use n-tuples such as (1, 1, 0, 1)

interchangeably with strings of bits such as 1101.
CHAPTER 15. GROUP THEORY AND APPLICATIONS  427

    For any distance r in a space, the ball of radius r centered at a point a,
denoted Br(a), is the set of all points whose distance from a is r or less. For
example, in the space Z24,

    B1((1, 1, 0, 0)) = {(1, 1, 0, 0), (0, 1, 0, 0), (1, 0, 0, 0), (1, 1, 1, 0), (1, 1, 0, 1)}.

    The ultimate goal of our encoding will be to take a set of possible messages,
the message space, and distribute them in a larger space, the code space, in
such a way that the encoded message, called a code word is at least a certain
distance away from any other code word. The minimum distance between the
code words will determine whether we can correct errors or just detect them.
Now let's turn to some examples.

15.5.2 Error Detection

Suppose that each block of three bits a = (a1, a2, a3) is encoded with the
function e : Z23  Z24, where

                              e(a) = (a1, a2, a3, a1 +2 a2 +2 a3)

The fourth bit of e(a) is called the parity-check bit. When the encoded
block is received, the four bits will probably all be correct (they are cor-
rect approximately 99.6% of the time under our assumed parameters), but
the added bit that is sent will make it possible to detect single bit errors in
the block. Note that when e(a) is transmitted, the sum of its components is
a1 +2 a2 +2 a3 +2 (a1 +2 a2 +2 a3) = 0, since ai + ai = 0 in Z2.

    If any single bit is garbled by noise, the sum of the received bits will be 1.
A parity error occurs if the sum of the received bits is 1. Since more than
one error is unlikely when p is small, a high percentage of all errors can be
detected.

    At the receiving end, the decoding function acts on the four-bit block b =
(b1, b2, b3, b4) with the function d : Z24  Z42, where

                           d(b) = (b1, b2, b3, b1 +2 b2 +2 b3 +2 b4)

Notice that the fourth bit of d(b) is an indicator of whether there is a parity
error - 0 if no error, and 1 if an error. If no parity error occurs, the first
three bits are recorded as part of the message. If a parity error occurs, we
will assume that a retransmission of that block can be requested. This request
can take the form of automatically having the parity-check bit of d(b) sent
back to the source. If 1 is received, the previous block is retransmitted; if 0 is
received, the next block is sent. This assumption of two-way communication
is significant, but it is desirable to make this coding system useful. For our
calculations, it is reasonable to expect that the probability of a transmission
error in the opposite direction is also 0.001. Without going into the details, we
will report that the probability of success in sending 3000 bits is approximately
0.990 and the rate is approximately 3/5. The rate includes the transmission of
the parity-check bit to the source and is only approximate because the resent
blocks will decrease the rate below 3/5 somewhat.
CHAPTER 15. GROUP THEORY AND APPLICATIONS  428

Figure 15.5.4 The 4-cube with code words displayed as larger vertices
    Let's consider the geometry of this code. If we examine the 4-cube in

Figure 15.5.4, the code words are the strings of four bits with an even number
of ones. These vertices are the larger ones. Notice that the ball of radius
1 centered around any of the code words consists of that code word and the
smaller vertices that are connected to the code word with an edge of the 4-cube.
Since there are no other code-words in the ball, a single bit error produces a
non-code word and so an error can be detected.

15.5.3 Error Correction

Next, we will consider coding functions that allow us to correct errors at the
receiving end so that only one-way communication is needed. Before we begin,
recall that every element of Z2n, n  1, is its own inverse; that is, -b = b.
Therefore, a - b = a + b.
Example 15.5.5 The Triple Repetition Code. Suppose we take each
individual bit in our message and encode it by repeating it three times. In
other words, if a is a single bit, e(a) = (a, a, a). The code words for this code
are (0, 0, 0) and (1, 1, 1). Let's look at the geometry behind this code. The
message space has just two points, but the code space is Z23, which has 8
points, the vertices of the 3-cube, which appears in Figure 15.5.6.

Figure 15.5.6 The 3-cube with code words displayed as circular vertices
CHAPTER 15. GROUP THEORY AND APPLICATIONS                     429

    In the figure for this code, the code words are circular vertices. If we
identify the balls of radius 1 centered around the two code words, you might
notice that the two balls do not intersect. Each has a different vertex with
triangular, square and pentagonal shapes. From a geometric point of view,
this is why we can correct a single bit error. If any string of three bits in the
code space is received it is in one of the two balls and the code word in that
ball had to have been the one that was transmitted.

    Regarding the actual correction process, the shapes have a meaning, as
outlined in the following list.

· Circle: No correction needed

· Pentagon: Correct the first bit

· Square: Correct the second bit

· Triangle: Correct the third bit

Of course, once the correction is made, only the first bit is extracted from

the code word since all bits will be equal. The simplicity of the final result

masks an important property of all error correcting codes we consider. All of

the possible points in the code space can be partitioned in such a way that

each block in the partition corresponds with a specific correction that we can

make to recover the correct code word.

If you have read about cosets, you will see that the partition we refer to is

the set of left cosets of the set of code words.              

Triple repetition is effective, but not very efficient since its rate is quite

low, 1/3. Next we consider a slightly more efficient error correcting code based

on matrix multiplication. Any such code that is computed with a matrix

multiplication is called a linear code. We should point out that both the

parity check code and the triple repetition code are linear codes. For the

parity check code, the encoding function can be thought of as acting on a 1 × 3
row vector a = (a1, a2, a3) by multiplying times a 3 × 4 matrix:

       1001                             

e(a) = (a1, a2, a3)  0 1 0 1  = (a1, a2, a3, a1 +2 a2 +2 a3)

       0011

For triple repetition, the encoding function can be thought of as acting on a
1 × 1 matrix a by multiplying times a 1 × 3 matrix:

     e(a) = (a) 1 1 1 = a a a

Example 15.5.7 A Somewhat More Efficient Linear Code. The en-

coding that we will consider here takes a block a = (a1, a2, a3) and produces

a code word of length 6. As in the triple repetition code, each code word will

differ from each other code word by at least three bits. As a result, any single

error will not push a code word close enough to another code word to cause

confusion. Now for the details.

Let                                               

                                 100110

     G =  0 1 0 1 0 1 .

                                 001011

We call G the generator matrix for the code, and let a = (a1, a2, a3) be our
message. Define e : Z23  Z26 by

     e(a) = aG = (a1, a2, a3, a4, a5, a6)
CHAPTER 15. GROUP THEORY AND APPLICATIONS                             430

where

                          a4=a1 +2 a2

                          a5=a1        +2 a3

                          a6=    a2 +2 a3

    Notice that since matrix multiplication is distributive over addition, we
have

                     e(a + b) = (a + b)G = aG + bG = e(a) + e(b)

for all a, b  Z23. This equality, may look familiar from the definition of an
isomorphism, but in this case the function e is not onto. If you've read about
homomorphisms, this is indeed an example of one.

    One way to see that any two distinct code words have a distance from one
another of at least 3 is to consider the images of any two distinct messages. If
a and b are distinct elements of Z23, then c = a + b has at least one coordinate
equal to 1. Now consider the difference between e(a) and e(b):

                                     e(a) + e(b) = e(a + b)

                                                    = e(c)

Whether c has 1, 2, or 3 ones, e(c) must have at least three ones. This can be
seen by considering the three cases separately. For example, if c has a single
one, two of the parity bits are also 1. Therefore, e(a) and e(b) differ in at least
three bits. By the same logic as with triple repetition, a single bit error in any
code word produces an element of the code space that is contained in on of the
balls of radius 1 centered about a code word.

    Now consider the problem of decoding received transmissions. Imagine that
a code word, e(a), is transmitted, and b = (b1, b2, b3, b4, b5, b6) is received. At
the receiving end, we know the formula for e(a), and if no error has occurred
in transmission,

                 b1 = a1

                 b2 = a2 b1+2b2 +2b4 = 0
                 b3 = a3  b1 +2b3 +2b5 = 0
       b4 = a1 +2 a2
                                 b2+2b3       +2b6= 0
       b5 = a1 +2 a3

       b6 = a2 +2 a3

The three equations on the right are called parity-check equations.   If any of
                                                                      described
them are not true, an error has occurred. This error checking can be

in matrix form.

Let                                      

                                 110
                                1 0 1 
                               0 1 1
                          H =            
                               1 0 0
                                         
                               0 1 0

                                 001

    The matrix H is called the parity-check matrix for this code. Now define
p : Z26  Z23 by p(b) = bH. We call p(b) the syndrome of the received block.
For example, p(0, 1, 0, 1, 0, 1) = (0, 0, 0) and p(1, 1, 1, 1, 0, 0) = (1, 0, 0)

    Note that p has a similar property as e, that p(b1 + b2) = p(b1) + p(b2). If
the syndrome of a block is (0, 0, 0), we can be almost certain that the message
block is (b1, b2, b3).
CHAPTER 15. GROUP THEORY AND APPLICATIONS                                                 431

    Next we turn to the method of correcting errors. Despite the fact that there
are only eight code words, one for each three-bit block value, the set of possible
received blocks is Z26, with 64 elements. Suppose that b is not a code word,
but that it differs from a code word by exactly one bit. In other words, it is the
result of a single error in transmission. Suppose that w is the code word that
b is closest to and that they differ in the first bit. Then b + w = (1, 0, 0, 0, 0, 0)
and

                    p(b) = p(b) + p(w) since p(w) = (0, 0, 0)

                          = bH + wH
                          = (b + w)H by the distributive property

                          = p(b + w)

                          = p(1, 0, 0, 0, 0, 0)

                          = (1, 1, 0)

This is the first row of H!

Note that we haven't specified b or w, only that they differ in the first

bit. Therefore, if b is received, there was probably an error in the first bit and

p(b) = (1, 1, 0), the transmitted code word was probably b + (1, 0, 0, 0, 0, 0) and

the message block was (b1 +2 1, b2, b3). The same analysis can be done if b and

w differ in any of the other five bits.

In general, if the syndrome of a received string of bits is the kth row of the

parity check matrix, the error has occurred in the kth bit.                               

Probability Epilog. For the two error correction examples we've looked

at, we can compare their probabilities of successfully receiving all 3000 bits

correctly over a binary symmetric channel with p = 0.001.

For the triple repetition code, the probability is

                          0.9993 + 3 · 0.9992 · 0.001 3000 = 0.991,

and  the  rate  of  this  code  is  1  which  means  we  need  to  transmit  9000  bits.
                                    3
For the second code, the probability of success is

                          0.9996 + 6 · 0.9995 · 0.001 1000 = 0.985,

and rate for this code is 12 , which means we need to transmit 6000 bits.
    Clearly, there is a trade-off between accuracy and speed.

Example 15.5.8            Another Linear Code. Consider the linear code with
generator matrix
                                                         
                                         11010

                                G =  0 1 1 0 0 .

                                         00011

Since G is 3 × 5, this code encodes three bits into five bits. The natural
question to ask is what detection or correction does it afford? We can answer
this question by constructing the parity check matrix. We observe that if
a = (a1, a2, a3) the encoding function is

                    e(a) = aG = (a1, a1 + a2, a2, a1 + a3, a3)

where addition is mod 2 addition. If we receive five bits (c1, c2, c3, c4, c5) and
no error has occurred, the following two equations would be true.

                                       c1 + c2 + c3 = 0                            (15.5.1)
                                       c1 + c4 + c5 = 0                            (15.5.2)
CHAPTER 15. GROUP THEORY AND APPLICATIONS                          432

Notice that in general, the number of parity check equations is equal to the
number of extra bits that are added by the encoding function. These equations
are equivalent to the single matrix equation (c1, c2, c3, c4, c5)H = 0, where

      1 1

      1 0
              
H  =    1  0  
              
      0 1

        01

    At a glance, we can see that this code will not correct most single bit errors.
Suppose an error e = (e1, e2, e3, e4, e5) is added in the transmission of the
five bits. Specifically, suppose that 1 is added (mod 2) in position j, where
1  j  5 and the other coordinates of e are 0. Then when we compute the
syndrome of our received transmission, we see that

cH = (aG + e)H = (aG)H + eH = eH.

But eH is the jth row of H. If the syndrome is (1, 1) we know that the error

occurred in position 1 and we can correct it. However, if the error is in any

other position we can't pinpoint its location. If the syndrome is (1, 0), then

the error could have occurred in either position 2 or position 3. This code does

detect all single bit errors but only corrects one fifth of them.  

15.5.4 Exercises

1. If the error-detecting code is being used, how would you act on the
      following received blocks?

        (a) (1, 0, 1, 1)

        (b) (1, 1, 1, 1)

         (c) (0, 0, 0, 0)
2. Determine the parity check matrix for the triple repetition code.
3. If the error-correcting code from this section is being used, how would

      you decode the following blocks? Expect an error that cannot be fixed
      with one of these.

        (a) (1, 0, 0, 0, 1, 1)

        (b) (1, 0, 1, 0, 1, 1)

         (c) (0, 1, 1, 1, 1, 0)

        (d) (0, 0, 0, 1, 1, 0)

         (e) (1, 0, 0, 0, 0, 1)

         (f) (1, 0, 0, 1, 0, 0)
4. Suppose that the code words of a coding function have the property that

      any two of them have a Hamming distance of at least 5. How many bit
      errors could be corrected with such a code?
5. Consider the linear code defined by the generator matrix

                                        G= 1 0 1 0
                                                  0111
CHAPTER 15. GROUP THEORY AND APPLICATIONS    433

        (a) What size blocks does this code encode and what is the length of
              the code words?

        (b) What are the code words for this code?

         (c) With this code, can you detect single bit errors? Can you correct
              all, some, or no single bit errors?

6. Rectangular codes. To build a rectangular code, you partition your
      message into blocks of length m and then factor m into k1 · k2 and arrange
      the bits in a k1 × k2 rectangular array as in the figure below. Then you
      add parity bits along the right side and bottom of the rows and columns.
      The code word is then read row by row.

   ···  

   ···                = message bit
.. .. ..      .. ..   = parity bit
...           ..

   ···  
   ··· 

    For example, if m is 4, then our only choice is a 2 by 2 array. The
message 1101 would be encoded as

                                          110
                                          011
                                          10

and the code word is the string 11001110.

  (a) Suppose that you were sent four bit messages using this code and you
       received the following strings. What were the messages, assuming
       no more than one error in the transmission of coded data?

(i) 11011000  (ii) 01110010  (iii) 10001111

        (b) If you encoded n2 bits in this manner, what would be the rate of
              the code?

         (c) Rectangular codes are linear codes. For the 2 by 2 rectangular code,
              what are the generator and parity check matrices?

7. Suppose that the code in Example 15.5.8 is expanded to add the column
                                                  
                                                      0
                                                  1
                                                      1

      to the generator matrix G, can all single bit errors be corrected? Explain
      your answer.
CHAPTER 15. GROUP THEORY AND APPLICATIONS                              434

8. Suppose that a linear code has parity check matrix

                                          111          

                                          1  1      0  
                                                       
                                        1 0 1 
                          H= 0 1 1 
                                                       
                                       1 0 0
                                                       
                                       0 1 0

                                          001

     Determine the generator matrix, G, and in so doing, identify the number
     of bits in each message block and the number of parity bits.

     Hint. There is a parity check equation for each parity bit.

9. A code with minimum distance d is called perfect if every string of bits

     is  within  Hamming  distance  r  =  d-1   of  some  code  word.  For such a
                                            2
     code, the spheres of radius r around the code words partition the set of

     all strings. This is analogous to packing objects into a box with no wasted

     space. Using just the number of bit strings of length n and the number of

     strings in a sphere of radius 1, for what values of n is it possible to find a

     perfect code of distance 3? You don't have to actually find the codes.

10.

         (a) Prove that the code words of a linear code are a subgroup of the
              code space.

     (b) Prove that if C is a left coset of the set of code words, then all
          elements of C will have the same syndrome.
Chapter 16

An Introduction to Rings and
Fields

                                field extension

                         Field extensions are simple. Let's say
                               That field L is a subfield of K,
                               Then it goes without mention,
                                    Field K's an extension
                                Of L -- like a shell, in a way.

           zqms, The Omnificent English Dictionary In Limerick Form
In our early elementary school days we began the study of mathematics by
learning addition and multiplication on the set of positive integers. We then
extended this to operations on the set of all integers. Subtraction and division
are defined in terms of addition and multiplication. Later we investigated the
set of real numbers under the operations of addition and multiplication. Hence,
it is quite natural to investigate those structures on which we can define these
two fundamental operations, or operations similar to them. The structures
similar to the set of integers are called rings, and those similar to the set of
real numbers are called fields.

    In coding theory, highly structured codes are needed for speed and accuracy.
The theory of finite fields is essential in the development of many structured
codes. We will discuss basic facts about finite fields and introduce the reader
to polynomial algebra.

16.1 Rings, Basic Definitions and Concepts

16.1.1 Basic Definitions

We would like to investigate algebraic systems whose structure imitates that
of the integers.
Definition 16.1.1 Ring. A ring is a set R together with two binary opera-
tions, addition and multiplication, denoted by the symbols + and · such that
the following axioms are satisfied:

  (1) [R; +] is an abelian group.

  (2) Multiplication is associative on R.

                                                 435
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS                436

(3) Multiplication is distributive over addition; that is, for all a, b, c  R, the
     left distributive law, a · (b + c) = a · b + a · c, and the right distributive
     law, (b + c) · a = b · a + c · a.

                                                                                                     
Note 16.1.2

(1) A ring is denoted [R; +, ·] or as just plain R if the operations are under-
     stood.

(2) The symbols + and · stand for arbitrary operations, not just "regular"
     addition and multiplication. These symbols are referred to by the usual
     names. For simplicity, we may write ab instead of a · b if it is not ambigu-
     ous.

  (3) For the abelian group [R; +], we use additive notation. In particular,
       the group identity is designated by 0 rather than by e and is customarily
       called the "zero" of the ring. The group inverse is also written in additive
       notation: -a rather than a-1.

    We now look at some examples of rings. Certainly all the additive abelian
groups of Chapter 11 are likely candidates for rings.

Example 16.1.3 The ring of integers. [Z; +, ·] is a ring, where + and
· stand for regular addition and multiplication on Z. From Chapter 11, we
already know that [Z; +] is an abelian group, so we need only check parts 2
and 3 of the definition of a ring. From elementary algebra, we know that the

associative law under multiplication and the distributive laws are true for Z.
This is our main example of an infinite ring.
                                                               

Example 16.1.4 The ring of integers modulo n. [Zn; +n, ×n] is a ring.
The properties of modular arithmetic on Zn were described in Section 11.4, and
they give us the information we need to convince ourselves that [Zn; +n, ×n]
is a ring. This example is our main example of finite rings of different orders.

                                                               

Definition 16.1.5 Commutative Ring. A ring in which multiplication is

a commutative operation is called a commutative ring.          

It is common practice to use the word "abelian" when referring to the

commutative law under addition and the word "commutative" when referring

to the commutative law under the operation of multiplication.

Definition 16.1.6 Unity of a Ring. A ring [R; +, ·] that has a multiplicative
identity is called a ring with unity. The multiplicative identity itself is called
the unity of the ring. More formally, if there exists an element 1  R, such
that for all x  R, x · 1 = 1 · x = x, then R is called a ring with unity. 

Example 16.1.7 The rings in our first two examples were commutative rings

with unity, the unity in both cases being the number 1. The ring [M2×2(R); +, ·]
is a noncommutative ring with unity, the unity being the two by two identity

matrix.

An example of a ring that is not a ring with unity is the ring of even integers,

[2Z; +, ·].                                                    

16.1.2 Direct Products of Rings

Products of rings are analogous to products of groups or products of Boolean
algebras.
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS                          437

                                                                                                 n

    Let [Ri; +i, ·i], i = 1, 2, . . . , n be rings. Let P = × Ri and a = (a1, a2, . . . , an), b =

                                                                                               i=1

(b1, b2, . . . , bn)  P .
    From Chapter 11 we know that P is an abelian group under the operation

of componentwise addition:

                         a + b = (a1 +1 b1, a2 +2 b2, ..., an +n bn)
We also define multiplication on P componentwise:

                            a · b = (a1 ·1 b1, a2 ·2 b2, ..., an ·n bn)

    To show that P is a ring under the above operations, we need only show
that the (multiplicative) associative law and the distributive laws hold. This is
indeed the case, and we leave it as an exercise. If each of the Ri is commutative,
then P is commutative, and if each contains a unity, then P is a ring with unity,
which is the n-tuple consisting of the unities of each of the Ri's.

Example 16.1.8 Since [Z4; +4, ×4] and [Z3; +3, ×3] are rings, then Z4 × Z3 is
a ring, where, for example,

                   (2, 1) + (2, 2) = (2 +4 2, 1 +3 2) = (0, 0)

                             and                                      .

                   (3, 2) · (2, 2) = (3 ×4 2, 2 ×3 2) = (2, 1)

    To determine the unity in the ring Z4 × Z3, we look for the element (m, n)
such that for all elements (a, b)  Z4 × Z3, (a, b) = (a, b) · (m, n) = (m, n) · (a, b),
or, equivalently,

                       (a ×4 m, b ×3 n) = (m ×4 a, n ×3 b) = (a, b)
So we want m such that a ×4 m = m ×4 a = a in the ring Z4. The only element
m in Z4 that satisfies this equation is m = 1. Similarly, we obtain value of 1
for n. So the unity of Z4 × Z3, which is unique by Exercise 15 of this section,
is (1, 1). We leave to the reader to verify that this ring is commutative. 

16.1.3 Multiplicative Inverses in Rings

We now consider the extremely important concept of multiplicative inverses.
Certainly many basic equations in elementary algebra (e.g., 2x = 3) are solved
with this concept.

Example 16.1.9 The equation 2x = 3 has a solution in the ring [Q; +, ·] but
does not have a solution in [Z; +, ·] since, to solve this equation, we multiply
both sides of the equation 2x = 3 by the multiplicative inverse of 2. This

number, 2-1 exists in Q but does not exist in Z. We formalize this important
idea in a definition which by now should be quite familiar to you.
                                                                         

Definition 16.1.10 Multiplicative Inverses. Let [R; +, ·] be a ring with

unity, 1. If u  R and there exists an element v  R such that u · v = v · u = 1,

then u is said to have a multiplicative inverse, v. A ring element that possesses

a multiplicative inverse is a unit of the ring. The set of all units of a ring R is

denoted by U (R).                                                        

By Theorem 11.3.3, the multiplicative inverse of a ring element is unique,

if it exists. For this reason, we can use the notation u-1 for the multiplicative

inverse of u, if it exists.
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS  438

Example 16.1.11 In the rings [R; +, ·] and [Q; +, ·] every nonzero element has
a multiplicative inverse. The only elements in [Z; +, ·] that have multiplicative
inverses are -1 and 1. That is, U (R) = R, U (Q) = Q, and U (Z) = {-1, 1}.

                                                                                                    

Example 16.1.12 Let us find the multiplicative inverses, when they exist, of
each element of the ring [Z6; +6, ×6]. If u = 3, we want an element v such that
u×6v = 1. We do not have to check whether v×6u = 1 since Z6 is commutative.
If we try each of the six elements, 0, 1, 2, 3, 4, and 5, of Z6, we find that none
of them satisfies the above equation, so 3 does not have a multiplicative inverse
in Z6. However, since 5 ×6 5 = 1, 5 does have a multiplicative inverse in Z6,
namely itself: 5-1 = 5. The following table summarizes all results for Z6.

                         u  u-1

                         0 does not exist

                         1  1

                         2 does not exist

                         3 does not exist

                         4 does not exist

                         5  5

It shouldn't be a surprise that the zero of a ring is never going to have a

multiplicative inverse.                          

16.1.4 More universal concepts, isomorphisms and subrings

Isomorphism is a universal concept that is important in every algebraic struc-
ture. Two rings are isomorphic as rings if and only if they have the same
cardinality and if they behave exactly the same under corresponding opera-
tions. They are essentially the same ring. For this to be true, they must
behave the same as groups (under + ) and they must behave the same under
the operation of multiplication.

Definition 16.1.13 Ring Isomorphism. Let [R; +, ·] and [R; +, ·] be rings.
Then R is isomorphic to R if and only if there exists a function, f : R  R,
called a ring isomorphism, such that

  (1) f is a bijection

  (2) f (a + b) = f (a) + f (b) for all a, b  R

  (3) f (a · b) = f (a) · f (b) for all a, b  R.

                                                                                                     
    Conditions 1 and 2 tell us that f is a group isomorphism.
    This leads us to the problem of how to show that two rings are not iso-
morphic. This is a universal concept. It is true for any algebraic structure
and was discussed in Chapter 11. To show that two rings are not isomorphic,
we must demonstrate that they behave differently under one of the operations.
We illustrate through several examples.

Example 16.1.14 Consider the rings [Z; +, ·] and [2Z; +, ·]. In Chapter 11 we
showed that as groups, the two sets Z and 2Z with addition were isomorphic.
The group isomorphism that proved this was the function f : Z  2Z, defined
by f (n) = 2n. Is f a ring isomorphism? We need only check whether f (m·n) =
f (m) · f (n) for all m, n  Z. In fact, this condition is not satisfied:

           f (m · n) = 2 · m · n and f (m) · f (n) = 2m · 2n = 4 · m · n
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS                       439

Therefore, f is not a ring isomorphism. This does not necessarily mean that
the two rings Z and 2Z are not isomorphic, but simply that f doesn't satisfy
the conditions. We could imagine that some other function does. We could try
to find another function that is a ring isomorphism, or we could try to show
that Z and 2Z are not isomorphic as rings. To do the latter, we must find
something different about the ring structure of Z and 2Z.

    We already know that they behave identically under addition, so if they are
different as rings, it must have something to do with how they behave under
the operation of multiplication. Let's begin to develop a checklist of how the
two rings could differ:

(1) Do they have the same cardinality? Yes, they are both countable.

(2) Are they both commutative? Yes.

(3) Are they both rings with unity? No.

Z is a ring with unity, namely the number 1. 2Z is not a ring with unity, 1 / 2Z.
Hence, they are not isomorphic as rings.
                                                                      

Example 16.1.15 Next consider whether [2Z; +, ·] and [3Z; +, ·] are isomor-
phic. Because of the previous example, we might guess that they are not.

However, checklist items 1 through 3 above do not help us. Why? We add

another checklist item:

4. Find an equation that makes sense in both rings, which is solvable in

one and not the other.

The equation x + x = x · x, or 2x = x2, makes sense in both rings. However,

this equation has a nonzero solution, x = 2, in 2Z, but does not have a nonzero
solution in 3Z. Thus we have an equation solvable in one ring that cannot be
solved in the other, so they cannot be isomorphic.
                                                                      

Another universal concept that applies to the theory of rings is that of a

subsystem. A subring of a ring [R; +, ·] is any nonempty subset S of R that

is a ring under the operations of R. First, for S to be a subring of the ring

R, S must be a subgroup of the group [R; +]. Also, S must be closed under ·,

satisfy the associative law under ·, and satisfy the distributive laws. But since

R is a ring, the associative and distributive laws are true for every element in

R, and, in particular, for all elements in S, since S  R. We have just proven

the following theorem:

Theorem 16.1.16 A nonempty subset S of a ring [R; +, ·] is a subring of R
if and only if:

(1) [S; +] is a subgroup of the group [R; +]

  (2) S is closed under multiplication: if a, b  S, then a · b  S.
Example 16.1.17 The set of even integers, 2Z, is a subring of the ring [Z; +, ·]
since [2Z; +] is a subgroup of the group [Z; +] and since it is also closed with
respect to multiplication:

                     2m, 2n  2Z  (2m) · (2n) = 2(2 · m · n)  2Z

                                                                                                    
    Several of the basic facts that we are familiar with are true for any ring.
The following theorem lists a few of the elementary properties of rings.

Theorem 16.1.18 Some Basic Properties. Let [R; +, ·] be a ring, with
a, b  R. Then
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS                        440

  (1) a · 0 = 0 · a = 0

  (2) a · (-b) = (-a) · b = -(a · b)

  (3) (-a) · (-b) = a · b
Proof.

  (1) a·0 = a·(0+0) = a·0+a·0, the last equality valid by the left distributive
       axiom. Hence if we add -(a · 0) to both sides of the equality above, we
       obtain a · 0 = 0. Similarly, we can prove that 0 · a = 0.

  (2) Before we begin the proof of this part, recall that the inverse of each
       element of the group [R; +] is unique. Hence the inverse of the element
       a·b is unique and it is denoted -(a·b). Therefore, to prove that a·(-b) =
       -(a · b), we need only show that a · (-b) inverts a · b.

a · (-b) + a · b = a · (-b + b) by the left distributive axiom

=a·0  since - b inverts b

=0    by part 1 of this theorem

     Similarly, it can be shown that(-a) · b = -(a · b).
(3) We leave the proof of part 3 to the reader as an exercise.

                                                                       

Example 16.1.19 We will compute 2·(-2) in the ring [Z6; +6, ×6]. 2×6(-2) =
- (2 ×6 2) = -4 = 2, since the additive inverse of 4 (mod 6) is 2. Of course,

we could have done the calculation directly as 2 ×6 (-2) = 2 ×6 4 = 2  

16.1.5 Integral Domains and Zero Divisors

As the example above illustrates, Theorem 16.1.18 is a modest beginning in the
study of which algebraic manipulations are possible when working with rings.
A fact in elementary algebra that is used frequently in problem solving is the
cancellation law. We know that the cancellation laws are true under addition
for any ring, based on group theory. Are the cancellation laws true under
multiplication, where the group axioms can't be counted on? More specifically,
let [R; +, ·] be a ring and let a, b, c  R with a = 0. When can we cancel the a's
in the equation a · b = a · c? We can do so if a-1 exists, but we cannot assume
that a has a multiplicative inverse. The answer to this question is found with
the following definition and the theorem that follows.

Definition 16.1.20 Zero Divisor. Let [R; +, ·] be a ring. If a and b are two
nonzero elements of R such that a · b = 0, then a and b are called zero divisors.

                                                                                                     

Example 16.1.21

(a) In the ring [Z8; +8, ×8], the numbers 4 and 2 are zero divisors since
     4 ×8 2 = 0. In addition, 6 is a zero divisor because 6 ×8 4 = 0.

(b) In the ring [M2×2(R); +, ·] the matrices A =  00            and B =
         0 1 are zero divisors since AB = 0.      01
         00

(c) [Z; +, ·] has no zero divisors.
                                                                                                  
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS                   441

    Now, here is why zero divisors are related to cancellation.

Theorem 16.1.22 Multiplicative Cancellation. The multiplicative can-
cellation laws hold in a ring [R; +, ·] if and only if R has no zero divisors.
Proof. We prove the theorem using the left cancellation axiom, namely that if
a = 0 and a · b = a · c, then b = c for all a, b, c  R. The proof using the right
cancellation axiom is its mirror image.

() Assume the left cancellation law holds in R and assume that a and b
are two elements in R such that a · b = 0. We must show that either a = 0 or
b = 0. To do this, assume that a = 0 and show that b must be 0.

                    a·b=0a·b=a·0 .
                                b = 0 by the left cancellation law

() Conversely, assume that R has no zero divisors and we will prove that
the left cancellation law must hold. To do this, assume that a, b, c  R, a = 0,
such that a · b = a · c and show that b = c.

a·b=a·ca·b-a·c=0
                a · (b - c) = 0
                b - c = 0 since there are no zero divisors
               b=c

                                                                                                    
    Hence, the only time that the cancellation laws hold in a ring is when
there are no zero divisors. The commutative rings with unity in which the two
conditions are true are given a special name.

Definition 16.1.23 Integral Domain. A commutative ring with unity

containing no zero divisors is called an integral domain.         

In this chapter, Integral domains will be denoted generically by the letter

D. We state the following two useful facts without proof.

Theorem 16.1.24 If m  Zn, m = 0, then m is a zero divisor if and only if
m and n are not relatively prime; i.e., gcd(m, n) > 1.

Corollary 16.1.25 If p is a prime, then Zp has no zero divisors.

Example 16.1.26 [Z; +, ·], [Zp; +p, ×p] with p a prime, [Q; +, ·], [R; +, ·], and
[C; +, ·] are all integral domains. The key example of an infinite integral domain
is [Z; +, ·]. In fact, it is from Z that the term integral domain is derived. Our
main example of a finite integral domain is [Zp; +p, ×p], when p is prime. 

    We close this section with the verification of an observation that was made
in Chapter 11, namely that the product of two algebraic systems may not be
an algebraic system of the same type.

Example 16.1.27 Both [Z2; +2, ×2] and [Z3; +3, ×3] are integral domains.
Consider the direct product Z2 × Z3. It's true that Z2 × Z3 is a commutative
ring with unity (see Exercise 13). However, (1, 0) · (0, 2) = (0, 0), so Z2 × Z3
has zero divisors and is therefore not an integral domain.
                                                                  
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS                442

16.1.6 Exercises

1. Review the definition of rings to show that the following are rings. The
      operations involved are the usual operations defined on the sets. Which of
      these rings are commutative? Which are rings with unity? For the rings
      with unity, determine the unity and all units.

        (a) [Z; +, ·]

        (b) [C; +, ·]

         (c) [Q; +, ·]

        (d) [M2×2(R); +, ·]

         (e) [Z2; +2, ×2]
2. Follow the instructions for Exercise 1 and the following rings:

(a) [Z6; +6, ×6]                            (d) [Z8; +8, ×8]

(b) [Z5; +5, ×5]                            (e) [Z × Z; +, ·]

(c) Z23; +, ·                               (f) R2; +, ·

3. Show that the following pairs of rings are not isomorphic:

        (a) [Z; +, ·] and [M2×2(Z); +, ·]

        (b) [3Z; +, ·] and [4Z; +, ·].
4. Show that the following pairs of rings are not isomorphic:

        (a) [R; +, ·] and [Q; +, ·].

        (b) [Z2 × Z2; +, ·]and [Z4; +, ·].
5.

        (a) Show that 3Z is a subring of the ring [Z; +, ·]

        (b) Find all subrings of Z8.

         (c) Find all subrings of Z2 × Z2.
6. Verify the validity of Theorem 16.1.22 by finding examples of elements a,

      b, and c, a = 0 in the following rings, where a · b = a · c and yet b = c:

        (a) Z8

        (b) M2×2(R)
         (c) Z22
7.

        (a) Determine all solutions of the equation x2 - 5x + 6 = 0 in Z. Can
              there be any more than two solutions to this equation (or any qua-
              dratic equation) in Z?

        (b) Find all solutions of the equation in part a in Z12. Why are there
              more than two solutions?

8. Solve the equation x2 + 4x + 4 = 0 in the following rings. Interpret 4 as
      1 + 1 + 1 + 1, where 1 is the unity of the ring.
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS  443

        (a) in Z8

        (b) in M2×2(R)

         (c) in Z

        (d) in Z3
9. The relation "is isomorphic to" on rings is an equivalence relation. Ex-

      plain the meaning of this statement.
10.

        (a) Let R1, R2, . . ., Rn be rings. Prove the multiplicative, associative,
              and distributive laws for the ring

                                                                                     n

                                                    R = × Ri

                                                                                   i=1

        (b) If each of the Ri is commutative, is R commutative?

         (c) Under what conditions will R be a ring with unity?

        (d) What will the units of R be when it has a unity?
11.

        (a) Prove that the ring Z2 × Z3 is commutative and has unity.

        (b) Determine all zero divisors for the ring Z2 × Z3.

         (c) Give another example illustrating the fact that the product of two
              integral domains may not be an integral domain. Is there an example
              where the product is an integral domain?

12. Boolean Rings. Let U be a nonempty set.

        (a) Verify that [P(U ); , ] is a commutative ring with unity.

        (b) What are the units of this ring?
13.

        (a) For any ring [R; +, ·], expand (a + b)(c + d) for a, b, c, d  R.

        (b) If R is commutative, prove that (a + b)2 = a2 + 2ab + b2 for all
              a, b  R.

14.

        (a) Let R be a commutative ring with unity. Prove by induction that
              for n  1, (a + b)n = k=0 k n n akbn-k

        (b) Simplify (a + b)5 in Z5 .
         (c) Simplify (a + b)10 in Z10.
15. Prove part 3 of Theorem 16.1.18.
16. Let U be a finite set. Prove that the Boolean ring [P(U ); , ] is isomor-
      phic to the ring [Z2n; +, ·]. where n = |U |.
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS                       444

16.2 Fields

Although the algebraic structures of rings and integral domains are widely used
and play an important part in the applications of mathematics, we still cannot
solve the simple equation ax = b, a = 0 in all rings or all integral domains,
for that matter. Yet this is one of the first equations we learn to solve in
elementary algebra and its solubility is basic to innumerable questions. If we
wish to solve a wide range of problems in a system we need at least all of the
laws true for rings and the cancellation laws together with the ability to solve
the equation ax = b, a = 0. We summarize the above in a definition and list
theorems that will place this concept in the context of the previous section.

Definition 16.2.1 Field. A field is a commutative ring with unity such that

each nonzero element has a multiplicative inverse.                    

In this chapter, we denote a field generically by the letter F . The letters k,

K and L are also conventionally used for fields.

Example 16.2.2 Some common fields. The most common infinite fields

are [Q; +, ·], [R; +, ·], and [C; +, ·].                              

Remark 16.2.3 Since every field is a ring, all facts and concepts that are true
for rings are true for any field.

Theorem 16.2.4 Field  Integral Domain. Every field is an integral

domain.

Proof. The proof is fairly easy and a good exercise, so we provide a hint.

Starting with the assumption that a · b = 0 if we assume that a = 0 then the

existence of a-1 makes it possible to infer that b = 0.               

    Of course the converse of Theorem 16.2.4 is not true. Consider [Z; +, ·].
However, the next theorem proves the converse in finite fields.

Theorem 16.2.5 Finite Integral Domain  Field. Every finite integral

domain is a field.

Proof. We leave the details to the reader, but observe that if D is a finite

integral domain, we can list all elements as a1, a2, . . . , an, where a1 = 1. Now,

to show that any ai has a multiplicative inverse, consider the n products ai ·

a1, ai · a2, . . . , ai · an. What can you say about these products?  

If p is a prime, p | (a · b)  p | a or p | b. An immediate implication of this

fact is the following corollary.

Corollary 16.2.6 If p is a prime, then Zp is a field.

Example 16.2.7 A field of order 4. Corollary 16.2.6 gives us a large
number of finite fields, but we must be cautious. This does not tell us that all
finite fields are of the form Zp , p a prime. To see this, let's try to construct a
field of order 4.

    First the field must contain the additive and multiplicative identities, 0 and
1, so, without loss of generality, we can assume that the field we are looking
for is of the form F = {0, 1, a, b}. Since there are only two nonisomorphic
groups of order 4, we have only two choices for the group table for [F ; +]. If
the additive group is isomorphic to Z4 then two of the nonzero elements of F
would not be their own additive inverse (as are 1 and 3 in Z4). Let's assume
  F is one of those elements and  +  =  = 0. An isomorphism between
the additive groups F and Z4 would require that  in F correspond with 2 in
Z4. We could continue our argument and infer that  ·  = 0, producing a zero
divisor, which we need to avoid if F is to be a field. We leave the remainder of
the argument to the reader. We can thus complete the addition table so that
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS                        445

[F ; +] is isomorphic to Z22:

                               +01ab
                               0 01ab
                               1 10ba
                               a ab01
                               b ba10

    Next, since 1 is the unity of F , the partial multiplication table must look
like:

                                         · 01 a b

                                        000 0 0

                                        101 a b

                                        a0a--

                                         b 0 b --

    Hence, to complete the table, we have only four entries to find, and, since
F must be commutative, this reduces our task to filling in three entries. Next,
each nonzero element of F must have a unique multiplicative inverse. The
inverse of a must be either a itself or b. If a-1 = a, then b-1 = b. (Why?) But
a-1 = a  a · a = 1. And if a · a = 1, then a · b is equal to a or b. In either
case, by the cancellation law, we obtain a = 1 or b = 1, which is impossible.
Therefore we are forced to conclude that a-1 = b and b-1 = a. To determine
the final two products of the table, simply note that, a · a = a because the
equation x2 = x has only two solutions, 0 and 1 in any field. We also know
that a · a cannot be 1 because a doesn't invert itself and cannot be 0 because
a can't be a zero divisor. This leaves us with one possible conclusion, that
a · a = b and similarly b · b = a. Hence, our multiplication table for F is:

                               · 01ab
                               00000
                               101ab
                               a0ab1
                               b 0b 1a

We leave it to the reader to verify that [F ; +, ·], as described above, is a

field. Hence, we have produced a field of order 4. This construction would be

difficult to repeat for larger fields. In section 16.4 we will introduce a different

approach to constructing fields that will be far more efficient.       

    Even though not all finite fields are isomorphic to Zp for some prime p, it
can be shown that every field F must have either:

· a subfield isomorphic to Zp for some prime p, or

· a subfield isomorphic to Q.
One can think of all fields as being constructed from either Zp or Q.

Example 16.2.8 [R; +, ·] is a field, and it contains a subfield isomorphic to
[Q; +, ·], namely Q itself.
                                                                       

Example 16.2.9 The field F that we constructed in Example 16.2.7 has a

subfield isomorphic to Zp for some prime p. From the tables, we note that the
subset {0, 1} of {0, 1, a, b} under the given operations of F behaves exactly like

[Z2; +2, ×2]. Hence, F has a subfield isomorphic to Z2.                

We close this section with a brief discussion of isomorphic fields. Again,

since a field is a ring, the definition of isomorphism of fields is the same as that
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS  446

of rings. It can be shown that if f is a field isomorphism, then f a-1 = f (a)-1;
that is, inverses are mapped onto inverses under any field isomorphism. A
major question to try to solve is: How many different non-isomorphic finite
fields are there of any given order? If p is a prime, it seems clear from our
discussions that all fields of order p are isomorphic to Zp. But how many
nonisomorphic fields are there, if any, of order 4, 6, 8, 9, etc? The answer is
given in the following theorem, whose proof is beyond the scope of this text.

Theorem 16.2.10

  (1) Any finite field F has order pn for a prime p and a positive integer n.

  (2) For any prime p and any positive integer n there is a field of order pn .

  (3) Any two fields of order pn are isomorphic.

Galois. The field of order pn is frequently referred to as the Galois field of
order pn and it is denoted by GF (pn). Evariste Galois (1811-32) was a pioneer
in the field of abstract algebra.

Figure 16.2.11 French stamp honoring Evariste Galois
    This theorem tells us that there is a field of order 22 = 4, and there is

only one such field up to isomorphism. That is, all such fields of order 4 are
isomorphic to F , which we constructed in the example above.

Exercises

1. Write out the addition, multiplication, and "inverse" tables for each of
      the following fields'.

        (a) [Z2; +2, ×2]

        (b) [Z3; +3, ×3]

         (c) [Z5; +5, ×5]
2. Show that the set of units of the fields in Exercise 1 form a group under

      the operation of the multiplication of the given field. Recall that a unit is
      an element which has a multiplicative inverse.
3. Complete the proof of Theorem 16.2.5 that every finite integral domain
      is a field.
4. Write out the operation tables for Z22. Is Z22 a ring? An integral domain?
      A field? Explain.
5. Determine all values x from the given field that satisfy the given equation:

        (a) x + 1 = -1 in Z2 , Z3 and Z5
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS                                        447

        (b) 2x + 1 = 2 in Z3 and Z5

         (c) 3x + 1 = 2 in Z5
6.

        (a) Prove that if p and q are prime, then Zp × Zq is never a field.

        (b) Can Zpn be a field for any prime p and any positive integer n  2?
7. Determine all solutions to the following equations over Z2. That is, find

      all elements of Z2 that satisfy the equations.

(a) x2 + x = 0                                  (c) x3 + x2 + x + 1 = 0

(b) x2 + 1 = 0                                  (d) x3 + x + 1 = 0

8. Determine the number of different fields, if any, of all orders 2 through

15. Wherever possible, describe these fields via a known field.
                           
9. Let Q 2 = a + b 2 a, b  Q .

                          
(a) Prove that Q 2 ; +, · is a field.

                                                                                   
(b) Show that Q is a subfield of Q 2 . For this reason, Q 2 is
          called an extension field of Q.

(c)       Show  that  all  the  roots  of  the  equation  x2 - 4x +  7  =  0  lie  in  the
                                                                     2

          extension field Q 2 .

(d) Do the roots of the equation x2 -4x+3 = 0 lie in this field? Explain.

16.3 Polynomial Rings

In the previous sections we examined the solutions of a few equations over
different rings and fields. To solve the equation x2 - 2 = 0 over the field of
the real numbers means to find all solutions of this equation that are in this
particular field R. This statement can be replaced as follows: Determine all
a  R such that the polynomial f (x) = x2 - 2 is equal to zero when evaluated
at x = a. In this section, we will concentrate on the theory of polynomials. We
will develop concepts using the general setting of polynomials over rings since
results proven over rings are true for fields (and integral domains). The reader
should keep in mind that in most cases we are just formalizing concepts that
he or she learned in high school algebra over the field of reals.

Definition 16.3.1 Polynomial over a Ring. Let [R; +, ·] be a ring. A
polynomial, f (x), over R is an expression of the form

                             n

             f (x) = aixi = a0 + a1x + a2x2 + · · · + anxn

                           i=0

where n  0, and a0, a1, a2, . . . , an  R. If an = 0, then the degree of f (x) is

n. If f (x) = 0, then the degree of f (x) is undefined, but for convenience we

say that deg 0 = -. If the degree of f (x) is n, we write deg f (x) = n. The

set of all polynomials in the indeterminate x with coefficients in R is denoted

by R[x].                                                                               

Note 16.3.2

· The symbol x is an object called an indeterminate, which is not an
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS                    448

       element of the ring R.

   · Note that R  R[x]. The elements of R are called constant polynomials,
       with the nonzero elements of R being the polynomials of degree 0.

   · R is called the ground, or base, ring for R[x].

   · In the definition above, we have written the terms in increasing degree
       starting with the constant. The ordering of terms can be reversed without
       changing the polynomial. For example, 1 + 2x - 3x4 and -3x4 + 2x + 1
       are the same polynomial.

   · A term of the form xk in a polynomial is understood to be 1xk.

   · It is understood that if deg f (x) = n, then coefficients of powers of x
       higher than n are equal to the zero of the base ring.

Definition 16.3.3 Polynomial Addition. Let f (x) = a0 + a1x + a2x2 +
· · · + amxm and g(x) = b0 + b1x + b2x2 + · · · + bnxn be elements in R[x] so
that ai  R and bi  R for all i. Let k be the maximum of m and n. Then
f (x)+g(x) = c0 +c1x+c2x2 +· · ·+ckxk, where ci = ai +bi for i = 0, 1, 2, . . . , k.

                                                                                                     
Definition 16.3.4 Polynomial Multiplication. Let f (x) = a0 + a1x +
a2x2 + · · · + amxm and g(x) = b0 + b1x + b2x2 + · · · + bnxn. Then

      f (x) · g(x) = d0 + d1x + d2x2 + · · · + dpxp where p = m + n and
        ds = i=0 s aibs-i = a0bs + a1bs-1 + a2bs-2 + · · · + as-1b1 + asb0
                                           for 0  s  p

                                                                                                     
    The important fact to keep in mind is that addition and multiplication
in R[x] depends on addition and multiplication in R. The powers of x merely
serve the purpose of "place holders." All computations involving coefficients are
done over the given ring. Powers of the indeterminate are computed formally
applying the rule of adding exponents when multiplying powers.

Example 16.3.5 f (x) = 3, g(x) = 2 - 4x + 7x2 , and h(x) = 2 + x4 are all

polynomials in Z[x]. Their degrees are 0, 2, and 4, respectively.  

Addition and multiplication of polynomials are performed as in high school

algebra. However, we must do our computations in the ground ring of the

polynomials.

Example 16.3.6 In Z3[x], if f (x) = 1 + x and g(x) = 2 + x, then

              f (x) + g(x) = (1 + x) + (2 + x)
                              = (1 +3 2) + (1 +3 1) x
                              = 0 + 2x
                              = 2x

and

     f (x)g(x) = (1 + x) · (2 + x)
                 = 1 ×3 2 + (1 ×3 1 +3 1 ×3 2)x + (1 ×3 1)x2
                 = 2 + 0x + x2
                 = 2 + x2
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS  449

However, for the same polynomials as above, f (x) and g(x) in the more familiar
setting of Z[x], we have

           f (x) + g(x) = (1 + x) + (2 + x) = (1 + 2) + (1 + 1)x = 3 + 2x

and

           f (x)g(x) = (1 + x) · (2 + x)
                                                = 1 · 2 + (1 · 1 + 1 · 2)x + (1 · 1)x2
                                                = 2 + 3x + x2

                                                                                                     
Example 16.3.7 Let f (x) = 2 + x2 and g(x) = -1 + 4x + 3x2. We will
compute f (x) · g(x) in Z[x]. Of course this product can be obtained by the
usual methods of high school algebra. We will, for illustrative purposes, use
the above definition. Using the notation of the above definition, a0 = 2, a1 = 0,
a2 = 1, b0 = -1, b1 = 4, and b2 = 3. We want to compute the coefficients d0,
d1, d2, d3, and d4 . We will compute d3 , the coefficient of the x3 term of the
product, and leave the remainder to the reader (see Exercise 2 of this section).
Since the degrees of both factors is 2, ai = bi = 0 for i  3. The coefficient of
x3 is

        d3 = a0b3 + a1b2 + a2b1 + a3b0 = 2 · 0 + 0 · 3 + 1 · 4 + 0 · (-1) = 4

                                                                                                     
     The proofs of the following theorem are not difficult but rather long, so we
omit them.
Theorem 16.3.8 Properties of Polynomial Rings. Let [R; +, ·] be a ring.
Then:

  (1) R[x] is a ring under the operations of polynomial addition and multipli-
       cation.

  (2) If R is a commutative ring, then R[x] is a commutative ring.

  (3) If R is a ring with unity, 1, then R[x] is a ring with unity (the unity in
        R[x] is 1 + 0x + 0x2 + · · ·).

  (4) If R is an integral domain, then R[x] is an integral domain.

  (5) If F is a field, then F [x] is not a field. However, F [x] is an integral
       domain.

     Next we turn to division of polynomials, which is not an operation since the
result is a pair of polynomials, not a single one. From high school algebra we
all learned the standard procedure for dividing a polynomial f (x) by a second
polynomial g(x). This process of polynomial long division is referred to as the
division property for polynomials. Under this scheme we continue to divide
until the result is a quotient q(x) and a remainder r(x) whose degree is strictly
less than that of the divisor g(x). This property is valid over any field. Before
giving a formal description, we consider some examples.

Example 16.3.9 Polynomial Division. Let f (x) = 1 + x + x3 and g(x) =
1 + x be two polynomials in Z2[x]. Let us divide f (x) by g(x). Keep in mind
that we are in Z2[x] and that, in particular, -1 = 1 in Z2 . This is a case
where reordering the terms in decreasing degree is preferred.
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS                                      450

Figure 16.3.10

    Therefore,           x3 + x + 1 = x2 + x + 1
or equivalently,                x+1                       x+1

                         x3 + x + 2 = x2 + x · (x + 1) + 1

That is, f (x) = g(x) · q(x) + r(x) where q(x) = x2 + x and r(x) = 1. Notice

that deg(r(x)) = 0, which is strictly less than deg(g(x)) = 1.                       

Example 16.3.11 Let f (x) = 1 + x4 and g(x) = 1 + x be polynomials in Z2[x].
Let us divide f (x) by g(x):

Figure 16.3.12

Thus x4 + 1 = x3 + x2 + x + 1 (x + 1). Since we have 0 as a remainder,

x + 1 must be a factor of x4 + 1. Also, since x + 1 is a factor of x4 + 1, 1 is a

zero (or root) of x4 + 1. Of course we could have determined that 1 is a root

of f (x) simply by computing f (1) = 14 +2 1 = 1 +2 1 = 0.                           

Before we summarize the main results suggested by the previous examples,

we should probably consider what could have happened if we had attempted to

perform divisions of polynomials in the ring Z[x] rather than in the polynomials
over the field Z2. For example, f (x) = x2 - 1 and g(x) = 2x - 1 are both
elements  of  the  ring  Z[x],  yet  x2 - 1     ( 12 x +  1                  3  The  quotient
                                             =            2  )(2x  -  1)  -  4

and remainder are not a polynomials over Z but polynomials over the field of
rational numbers. For this reason it would be wise to describe all results over

a field F rather than over an arbitrary ring R so that we don't have to expand

our possible set of coefficients.

Theorem 16.3.13 Division Property for Polynomials. Let [F ; +, ·] be a
field and let f (x) and g(x) be two elements of F [x] with g(x) = 0. Then there
exist unique polynomials q(x) and r(x) in F [x] such that f (x) = g(x)q(x)+r(x),
where deg r(x) < deg g(x).
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS                             451

Proof. This theorem can be proven by induction on deg f (x).                

Theorem 16.3.14 The Factor Theorem. Let [F ; +, ·] be a field. An
element a  F is a zero of f (x)  F [x] if and only if x - a is a factor of f (x)
in F [x].

Proof.

() Assume that a  F is a zero of f (x)  F [x]. We wish to show that x - a
is a factor of f (x). To do so, apply the division property to f (x) and g(x) =
x - a. Hence, there exist unique polynomials q(x) and r(x) from F [x] such that
f (x) = (x - a) · q(x) + r(x) and the deg r(x) < deg(x - a) = 1, so r(x) = c  F ,
that is, r(x) is a constant. Also, the fact that a is a zero of f (x) means that
f (a) = 0. So f (x) = (x - a) · q(x) + c becomes 0 = f (a) = (a - a)q(a) + c.
Hence c = 0, so f (x) = (x - a) · q(x), and x - a is a factor of f (x). The reader
should note that a critical point of the proof of this half of the theorem was
the part of the division property that stated that deg r(x) < deg g(x).

() We leave this half to the reader as an exercise.                         

Theorem 16.3.15 A nonzero polynomial f (x)  F [x] of degree n can have at
most n zeros.
Proof. Let a  F be a zero of f (x). Then f (x) = (x-a)·q1(x), q1(x)  F [x], by
the Factor Theorem. If b  F is a zero of q1(x), then again by Factor Theorem,
f (x) = (x - a)(x - b)q2(x), q2(x)  F [x]. Continue this process, which must
terminate in at most n steps since the degree of qk(x) would be n - k. 

    From The Factor Theorem, we can get yet another insight into the problems

associated with solving polynomial equations; that is, finding the zeros of a

polynomial. The initial important idea here is that the zero a is from the

ground field F . Second, a is a zero only if (x - a) is a factor of f (x) in F [x];
that is, only when f (x) can be factored (or reduced) to the product of (x - a)
times some other polynomial in F [x].

Example 16.3.16 Consider the polynomial f (x) = x2 - 2 taken as being in

Q[x]. From high school algebra we know that f (x) has two zeros (or roots),
namely ± 2, and x2 - 2 can be factored as x - 2 x + 2 . However, we

are working in Q[x], these twofactors are not in the set of polynomials over
the rational numbers, Q since 2 / Q . Therefore, x2 - 2 does not have a zero
in Q since it cannot be factored over Q. When this happens, we say that the
polynomial is irreducible over Q.
                                                                            

The problem of factoring polynomials is tied hand-in-hand with that of the

reducibility of polynomials. We give a precise definition of this concept.

Definition 16.3.17 Reducibility over a Field. Let [F ; +, ·] be a field and

let f (x)  F [x] be a nonconstant polynomial. f (x) is reducible over F if and

only if it can be factored as a product of two nonconstant polynomials in F [x].

A polynomial is irreducible over F if it is not reducible over F .          

Example 16.3.18 The polynomial f (x) = x4 + 1 is reducible over Z2 since
x4 + 1 = (x + 1) x3 + x2 + x - 1 .
                                                                            

Example 16.3.19 Is the polynomial f (x) = x3 + x + 1 reducible over Z2?
Since a factorization of a cubic polynomial can only be as a product of linear
and quadratic factors, or as a product of three linear factors, f (x) is reducible
if and only if it has at least one linear factor. From the Factor Theorem, x - a
is a factor of x3 + x + 1 over Z2 if and only if a  Z2 is a zero of x3 + x + 1. So
x3 + x + 1 is reducible over Z2 if and only if it has a zero in Z2 . Since Z2 has
only two elements, 0 and 1, this is easy enough to check. f (0) = 03 +2 0+2 1 = 1
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS    452

and f (1) = 13 +2 1 +2 1 = 1, so neither 0 nor 1 is a zero of f (x) over Z2. Hence,
x3 + x + 1 is irreducible over Z2.
                                                   

From high school algebra we know that x3 + x + 1 has three zeros from

some field. Can we find this field? To be more precise, can we construct the

field that contains Z2 and all zeros of x3 + x + 1? We will consider this task in
the next section.

We close this section with a final analogy. Prime numbers play an important

role in mathematics. The concept of irreducible polynomials (over a field) is

analogous to that of a prime number. Just think of the definition of a prime

number. A useful fact concerning primes is: If p is a prime and if p | ab, then

p | a or p | b. We leave it to the reader to think about the veracity of the

following: If p(x) is an irreducible polynomial over F , a(x), b(x)  F [x] and

p(x) | a(x)b(x), then p(x) | a(x) or p(x) | b(x).

Exercises

1. Let f (x) = 1 + x and g(x) = 1 + x + x2. Compute the following sums
      and products in the indicated rings.

        (a) f (x) + g(x) and f (x) · g(x) in Z[x]
        (b) f (x) + g(x) and f (x) · g(x) in Z2[x]
         (c) (f (x) · g(x)) · f (x) in Q[x]
        (d) (f (x) · g(x)) · f (x) in Z2[x]
         (e) f (x) · f (x) + f (x) · g(x) in Z2[x]
2. Complete the calculations started in Example 16.3.7.
3. Prove that:

        (a) The ring R is a subring of the ring R[x].
        (b) The ring Z[x] is a subring of the Q[x].
         (c) The ring Q[x] is a subring of the ring R[x].
4.

        (a) Find all zeros of x4 + 1 in Z3.
        (b) Find all zeros of x5 + 1 in Z5.
5. Determine which of the following are reducible over Z2. Explain.
        (a) f (x) = x3 + 1

        (b) g(x) = x3 + x2 + x.

         (c) h(x) = x3 + x2 + 1.

        (d) k(x) = x4 + x2 + 1. (Be careful.)
6. Prove the second half of The Factor Theorem.
7. Give an example of the contention made in the last paragraph of this

      section.
8. Determine all zeros of x4 + 3x3 + 2x + 4 in Z5[x].
9. Show that x2 - 3 is irreducible over Q but reducible over the field of real

      numbers.
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS                                     453

10. The definition of a vector space given in Chapter 13 holds over any field
      F , not just over the field of real numbers, where the elements of F are
      called scalars.

        (a) Show that F [x] is a vector space over F .

        (b) Find a basis for F [x] over F .

         (c) What is the dimension of F [x] over F ?
11. Prove Theorem 16.3.13, the Division Property for Polynomials
12.

        (a) Show that the field R of real numbers is a vector space over R. Find
              a basis for this vector space. What is dim R over R?

        (b) Repeat part a for an arbitrary field F.

         (c) Show that R is a vector space over Q.

16.4 Field Extensions

From high school algebra we realize that to solve a polynomial equation means
to find its roots (or, equivalently, to find the zeros of the polynomials). From
Example 16.3.16 and Example 16.3.19 we know that the zeros may not lie
in the given ground field. Hence, to solve a polynomial really involves two
steps: first, find the zeros, and second, find the field in which the zeros lie. For
economy's sake we would like this field to be the smallest field that contains all
the zeros of the given polynomial. To illustrate this concept, let us reconsider
the examples from the previous section..

Example 16.4.1 Extending the Rational Numbers. Let f (x) = x2 -2 
Q[x]. It is important to remember that we are considering x2 - 2 over Q, no
other field. We would like to find all zeros of f (x) andthe smallest field, call
it S for now, that contains them. The zeros are x = ± 2, neither of which is
an element of Q. The set S we are looking for must satisfy the conditions:

  (1) S must be a field.

(2) S must contain Q as a subfield,

(3) S must contain all zeros of f (x) = x2 - 2

                              
By the last condition 2 must be an element of S, and, if S is to be a

field, the sum, product, difference, and quotient of elements in S must be in
                                                                  2  3 
S. So operations involving this number, such as 2, 2 , 2 , 2 + 2,

2-  2,  and  1    must  all  be  elements  of  S.  Further,  since  S  contains  Q  as  a
             
               2                           

subset, any element of Q combined with 2 under any field operation must be
an element of S. Hence, every element of the form a + b 2, where a and b can

be any elements in Q, is an element of S. We leave to the reader to show that
S = {a + b 2 | a, b  Q} is a field (seeExercise 1 of this section). We note that
the second zero of x2 - 2, namely - 2, is an element of this set. To see this,
simply take a = 0 and b = -1. The field S is frequently denoted as Q 2 ,
and it is referred to asan extension field of Q. Note that the polynomial
x2 - 2 = x - 2 x + 2 factors into linear factors, or splits, in Q 2 [x];

                                                                                       
that is, all coefficients of both factors are elements of the field Q 2 . 
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS  454

Example 16.4.2 Extending Z2. Consider the polynomial g(x) = x2+x+1 
Z2[x]. Let's repeat the steps from the previous example to factor g(x). First,
g(0) = 1 and g(1) = 1, so none of the elements of Z2 are zeros of g(x). Hence,
the zeros of g(x) must lie in an extension field of Z2. By Theorem 16.3.15,
g(x) = x2 + x + 1 can have at most two zeros. Let a be a zero of g(x). Then
the extension field S of Z2 must contain, besides a, a · a = a2, a3, a + a,
a + 1, and so on. But, since g(a) = 0, we have a2 + a + 1 = 0, or equivalently,
a2 = -(a+1) = a+1 (remember, we are working in an extension of Z2). We can
use this recurrence relation to reduce powers of a. So far our extension field, S,
of Z2 must contain the set {0, 1, a, a + 1}, and we claim that this the complete
extension. For S to be a field, all possible sums, products, and differences of
elements in S must be in S. Let's try a few: a + a = a (1 +2 1) = a · 0 = 0  S
Since a + a = 0, -a = a, which is in S. Adding three a's together doesn't give
us anything new: a + a + a = a  S In fact, na is in S for all possible positive
integers n. Next,

                              a3 = a2 · a
                                 = (a + 1) · a
                                 = a2 + a
                                 = (a + 1) + a
                                 =1

Therefore, a-1 = a + 1 = a2 and (a + 1)-1 = a.
    It is not difficult to see that an is in S for all positive n. Does S contain

all zeros of x2 + x + 1? Remember, g(x) can have at most two distinct zeros
and we called one of them a, so if there is a second, it must be a + 1. To see if
a + 1 is indeed a zero of g(x), simply compute f (a + 1):

f (a + 1) = (a + 1)2 + (a + 1) + 1
           = a2 + 1 + a + 1 + 1
           = a2 + a + 1
           =0

Therefore, a + 1 is also a zero of x2 + x + 1. Hence, S = {0, 1, a, a + 1} is

the smallest field that contains Z2 = {0, 1} as a subfield and contains all zeros
of x2 + x + 1. This extension field is denoted by Z2(a). Note that x2 + x + 1
splits in Z2(a); that is, it factors into linear factors in Z2(a). We also observe
that Z2(a) is a field containing exactly four elements. By Theorem 16.2.10,
we expected that Z2(a) would be of order p2 for some prime p and positive
integer n. Also recall that all fields of order pn are isomorphic. Hence, we have

described all fields of order 22 = 4 by finding the extension field of a polynomial

that is irreducible over Z2.                     

The reader might feel somewhat uncomfortable with the results obtained

in Example 16.4.2. In particular, what is a? Can we describe it through a

known quantity? All we know about a is that it is a zero of g(x) and that

a2 = a + 1. We could also say that a(a + 1) = 1, but we really expected more.
However, should we expect more? In Example 16.4.1, 2 is a number we are
more comfortable with, but all we really know about it is that  = 2 is the

number such that 2 = 2. Similarly, the zero that the reader will obtain in

Exercise 2 of this section is the imaginary number i. Here again, this is simply

a symbol, and all we know about it is that i2 = -1. Hence, the result obtained

in Example 16.4.2 is not really that strange.
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS                       455

    The reader should be aware that we have just scratched the surface in the
development of topics in polynomial rings. One area of significant applications
is in coding theory.

Example 16.4.3 An Error Correcting Polynomial Code. An important
observation regarding the previous example is that the nonzero elements of
GF (4) can be represented two ways. First as a linear combination of 1 and
a. There are four such linear combinations, one of which is zero. Second, as
powers of a. There are three distinct powers and the each match up with a
nonzero linear combination:

                                        a0 = 1 · 1 + 0 · a
                                        a1 = 0 · 1 + 1 · a
                                        a2 = 1 · 1 + 1 · a

    Next, we briefly describe the field GF (8) and how an error correcting code

can be build on a the same observation about that field.
    First, we start with the irreducible polynomial p(x) = x3 + x + 1 over Z2.

There is another such cubic polynomial, but its choice produces essentially the

same result. Just as we did in the previous example, we assume we have a zero
of p(x) and call it . Since we have assumed that p() = 3 +  + 1 = 0, we
get the recurrence relation for powers 3 =  + 1 that lets us reduce the seven
powers k, 0  k  6, to linear combinations of 1, , and 2. Higher powers
will reduce to these seven, which make up the elements of a field with 23 = 8

elements when we add zero to the set. We leave as an exercise for you to set

up a table relating powers of  with the linear combinations.

    With this information we are now in a position to take blocks of four bits and

encode them with three parity bits to create an error correcting code. If the bits
are b3b4b5b6, then we reduce the expression Bm = b3 ·3 +b4 ·4 +b5 ·5 +b6 ·6
using the recurrence relation to an expression Bp = b0 · 1 + b1 ·  + b2 · 2. Since
we are equating equals within GF (8), we have Bp = Bm, or Bp + Bm = 0. The
encoded message is b0b1b2b3b4b5b6, which is a representation of 0 in GF (8).
If the transmitted sequence of bits is received as c0c1c2c3c4c5c6 we reduce
C = c0 · 1 + c1 ·  + c2 · 2 + c3 · 3 + c4 · 4 + c5 · 5 + c6 · 6 using the recurrence.
If there was no transmission error, the result is zero. If the reduced result is

zero it is most likely that the original message was c3c4c5c6. If bit k is switched
in the transmission, then

                 C = Bp + Bm + k = k

Therefore if we reduce C with the recurrence, we get the linear combination of

1, , and 2 that is equal to k and so we can identify the location of the error

and correct it.                                                       

Exercises

1.

                                                                   
    (a) Use the definition of a field to show that Q( 2) is a field.

                                                                              
    (b) Use the definition of vector space to show that Q 2 is a vector

         space over Q.

                                                         
    (c) Prove that 1, 2 is a basis for the vector space Q 2 over Q,
                   
    and, therefore, the dimension of Q( 2) over Q is 2.
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS  456

2.

        (a) Determine the splitting field of f (x) = x2 + 1 over R. This means
              consider the polynomial f (x) = x2 + 1  R[x] and find the smallest
              field that contains R and all the zeros of f (x). Denote this field by
              R(i).

        (b) R(i) is more commonly referred to by a different name. What is it?
         (c) Show that {1, i} is a basis for the vector space R(i) over R. What

              is the dimension of this vector space (over R)?
3. Determine the splitting field of x4 - 5x2 + 6 over Q.
4.

        (a) Factor x2 + x + 1 into linear factors in Z2(a).
        (b) Write out the field tables for the field Z2(a) and compare the results

              to the tables of Example 16.2.7.

         (c) Cite a theorem and use it to show why the results of part b were to
              be expected.

5.

        (a) Show that x3 + x + 1 is irreducible over Z2.
        (b) Determine the splitting field of x3 + x + 1 over Z2.
         (c) By Theorem 16.2.10, you have described all fields of order 23.
6.

        (a) List all polynomials of degree 1, 2, 3, and 4 over Z2 = GF (2).
        (b) From your list in part a, identify all irreducible polynomials of degree

              1, 2, 3, and 4.

         (c) Determine the splitting fields of each of the polynomials in part b.

        (d) What is the order of each of the splitting fields obtained in part c?
              Explain your results using Theorem 16.2.10.

7. Is the polynomial code described in this section a linear code?

16.5 Power Series

16.5.1 Definition

Earlier in this chapter, we found that a polynomial of degree n over a ring R
is an expression of the form

                                             n

                    f (x) = aixi = a0 + a1x + a2x2 + · · · + anxn

                                           i=0

where n  0, each of the ai are elements of R and an = 0. In Section 8.5 we
defined a generating function of a sequence s with terms s0, s1, s2, . . . as the
infinite sum

                                                      

                        G(s, z) = sizi = s0 + s1z + s2z2 + · · ·

                                                     i=0
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS                                                   457

    The main difference between these two expressions, disregarding notation,
is that the latter is an infinite expression and the former is a finite expression.
In this section we will extend the algebra of polynomials to the algebra of
infinite expressions like G(s, z), which are called power series.

Definition 16.5.1 Power Series. Let [R; +, ·] be a ring. A power series
over R is an expression of the form

                                  

                   f (x) = aixi = a0 + a1x + a2x2 + · · ·

                                 i=0

where a1, a2, a3, . . .  R. The set of all such expressions is denoted by R[[x]].
                                                                                                     

    Our first observation in our comparison of R[x] and R[[x]] is that every
polynomial is a power series and so R[x]  R[[x]]. This is true because a
polynomial a0 + a1x + a2x2 + · · · + anxn of degree n in R[x], can be thought of
as an infinite expression where ai = 0 for i > n. In addition, we will see that
R[[x]] is a ring with subring R[x].

    R[[x]] is given a ring structure by defining addition and multiplication on
power series as we did in R[x], with the modification that, since we are dealing
with infinite expressions, the sums and products will remain infinite expressions
that we can determine term by term, as was done in with polynomials.

Definition 16.5.2 Power Series Addition. Given power series

                  f (x) = i=0  aixi = a0 + a1x + a2x2 + · · · and
                                
                   g(x) =       i=0  bixi  =     b0  +   b1x  +   b2x2  +     ·  ·  ·

their sum is

                   

f (x) + g(x) = (ai + bi) xi                                                                    .

                   i=0

                  = (a0 + b0) + (a1 + b1)x + (a2 + b2)x2 + (a3 + b3)x3 + · · ·

                                                                                                     
Definition 16.5.3 Power Series Multiplication. Given power series

                  f (x) = i=0  aixi = a0 + a1x + a2x2 + · · · and
                                
                   g(x) =       i=0  bixi  =     b0  +   b1x  +   b2x2  +     ·  ·  ·

their product is

                                              i

f (x) · g(x) = dixi where di = ajbi-j                                                             .

              i=0                          j=0

= (a0 · b0) + (a0 · b1 + a1 · b0)x + (a0 · b2 + a1 · b1 + a2 · b0)x2 + · · ·

                                                                                                     
Example 16.5.4 Some Power Series Calcuations. Let

              f (x) =           ixi  =  0  +     1x  +  2x2  +  3x3  +  ·  ·  ·           and
                           i=0
                           
                   g(x) =  i=0  2ixi       =  1  +   2x  +   4x2  +  8x3   +        ·  ·  ·

be elements in Z[[x]]. Let us compute f (x) + g(x) and f (x) · g(x). First the
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS                          458

sum:

                                     

                f (x) + g(x) = ixi + 2ixi

                              i=0             i=0
                               
                                     i + 2i xi
                          =

                               i=0

                          = 1 + 3x + 6x2 + 11x3 + · · ·

The product is a bit more involved:

f (x) · g(x) =            

                   ixi ·     2ixi

                i=0       i=0

         = 0 + 1x + 2x2 + 3x3 + · · · · 1 + 2x + 4x2 + 8x3 + · · ·

         = 0 · 1 + (0 · 2 + 1 · 1)x + (0 · 4 + 1 · 2 + 2 · 1)x2 + · · ·

         = x + 4x2 + 11x3 + · · ·

                                                  i

         = dixi           where di = j2i-j

                i=0                  j=0

We can compute any value of di, with the amount of time/work required in-
creasing as i increases.

def d(i):
       s=0
       for j in range(1,i+1):
              s+=j*2^(i-j)
       return s

d(20)

2097130

A closed-form expression for di would be desirable. Using techniques from

Chapter 8, the formula is di = 2i+1 - i - 2, which we leave it to the reader to
derive. Hence, f (x) · g(x) =  i=0(2i+1 - i - 2)xi
                                                                         

16.5.2 Properties, Units

We have seen that addition and multiplication in R[[x]] is virtually identical
to that in R[x]. The following theorem parallels Theorem 16.3.8, establishing
the ring properties of R[[x]].

Theorem 16.5.5 Properties of Power Series. Let [R; +, ·] be a ring.
Then:

  (1) R[[x]] is a ring under the operations of power series addition and multi-
        plication, which depend on the operations in R.

  (2) If R is a commutative ring, then R[[x]] is a commutative ring.

  (3) If R is a ring with unity, 1, then R[[x]] is a ring with unity (the unity in
       R[x] is 1 + 0x + 0x2 + · · ·).

  (4) If R is an integral domain, then R[[x]] is an integral domain.

  (5) If F is a field, then F [[x]] is not a field. However, F [[x]] is an integral
       domain.
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS                           459

    We are most interested in the situation when the set of coefficients is a
field. The theorem above indicates that when F is a field, F [[x]] is an integral
domain. A reason that F [[x]] is not a field is the same as one that we can cite
for F [x], namely that x does not have multiplicative inverse in F [[x]].

    With all of these similarities, one might wonder if the rings of polynomials
and power series over a field are isomorphic. It turns out that they are not.
The difference between F [x] and F [[x]] becomes apparent when one studies
which elements are units in each. First we prove that the only units in F [x]
are the nonzero constants; that is, the nonzero elements of F .

Theorem 16.5.6 Polynomial Units. Let [F ; +, ·] be a field. Polynomial
f (x) is a unit in F [x] if and only if it is a nonzero constant polynomial.

Proof.

() Let f (x) be a unit in F [x]. Then f (x) has a multiplicative inverse, call
it g(x), such that f (x) · g(x) = 1. Hence, the deg(f (x) · g(x)) = deg(1) = 0.
But deg(f (x) · g(x)) = deg f (x) + deg g(x). So deg f (x) + deg g(x) = 0, and
since the degree of a polynomial is always nonnegative, this can only happen
when the deg f (x) = deg g(x) = 0. Hence, f (x) is a constant, an element of F ,
which is a unit if and only if it is nonzero.

() If f (x) is a nonzero element of F , then it is a unit since F is a field.
Thus it has an inverse, which is also in F [x] and so f (x) is a unit of F [x]. 

    Before we proceed to categorize the units in F [[x]], we remind the reader
that two power series a0 + a1x + a2x2 + · · · and b0 + b1x + b2x2 + · · · are equal
if and only if corresponding coefficients are equal, ai = bi for all i  0.

Theorem 16.5.7 Power Series Units. Let [F ; +, ·] be a field. Then f (x) =
   i=0  aixi is a unit of F [[x]] if and only if a0 = 0.

Proof.

() If f (x) is a unit of F [[x]], then there exists g(x) =  i=0  bixi in F [[x]]
such that

     f (x) · g(x) = a0 + a1x + a2x2 + · · · · b0 + b1x + b2x2 + · · ·

                  =1                                                   .

                  = 1 + 0x + 0x2 + · · ·

Since corresponding coefficients in the equation above must be equal, a0 ·b0 = 1,
which implies that a0 = 0.

() Assume that a0 = 0. To prove that f (x) is a unit of F [[x]] we need to
find g(x) = i=0  bixi in F [[x]] such that f (x) · g(x) = i=0  dixi = 1. If we
use the formula for the coefficients f (x) · g(x) and equate coefficients, we get

d0 = a0 · b0 = 1                           b0 = a0-1

d1 = a0 · b1 + a1 · b0 = 0                 b1 = -a0-1 · (a1 · b0)

d2 = a0b2 + a1b1 + a2b0 = 0                b2 = -a0-1 · (a1 · b1 + a2 · b0)                             .
 ..                                       .. ..
.                                         ..

ds = a0 · bs + a1 · bs-1 + · · · + as · b0 = 0  bs = -a0-1 · (a1 · bs-1 + a2 · bs-2 + · · · + as · b0)

Therefore the powers series i=0  bixi is an expression whose coefficients lie
in F and that satisfies the statement f (x) · g(x) = 1. Hence, g(x) is the

multiplicative inverse of f (x) and f (x) is a unit.                      
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS                                                 460

Example 16.5.8 Let f (x) = 1 + 2x + 3x2 + 4x3 + · · · = i=0  (i + 1)xi be
an element of Q[[x]]. Then, by Theorem 16.5.7, since a0 = 1 = 0, f (x) is a
unit and has an inverse, call it g(x). To compute g(x), we follow the procedure
outlined in the above theorem. Using the formulas for the bis, we obtain

                                               b0 = 1
                                      b1 = -1(2 · 1) = -2
                                b2 = -1(2 · (-2) + 3 · 1) = 1
                            b3 = -1(2 · 1 + 3 · (-2) + 4 · 1) = 0
                        b4 = -1(2 · 0 + 3 · 1 + 4 · (-2) + 5 · 1) = 0
                  b5 = -1(2 · 0 + 3 · 0 + 4 · (1) + 5 · (-2) + 6 · 1) = 0

                                                   ..
                                                   .

For s  3, we have

bs = -1(2 · 0 + 3 · 0 + · · · (s - 2) · 0 + (s - 1) · 1 + s · (-2) + (s + 1) · 1) = 0

Hence, g(x) = 1 - 2x + x2 is the multiplicative inverse of f (x).                                     

Certainly F [[x]] contains a wider variety of units than F [x]. Yet F [[x]] is

not a field, since x  F [[x]] is not a unit. So concerning the algebraic structure

of F [[x]], we know that it is an integral domain that contains F [x]. If we allow

our power series to take on negative exponents; that is, consider expressions

of the form f (x) =       aixi         where  all  but   a   finite  number    of  terms        with  a
                     i=-
negative index equal zero. These expressions are called extended power series.

The set of all such expressions is a field, call it E. This set does contain, for

example, the inverse of x, which is x-1. It can be shown that each nonzero

element of E is a unit.

16.5.3 Exercises

1. Let f (x) = i=0  aixi and g(x) = i=0  bixi be elements of
      R[[x]]. Let f (x) · g(x) = i=0  dixi = 1. Apply basic algebra to
        a0 + a1x + a2x2 + · · · · b0 + b1x + b2x2 + · · · to derive the formula
      ds = i=0 s aibs-i for the coefficients of f (x) · g(x). Hence, to show that
      f (x) · g(x) = s=0  ( i=0 s aibs-i) xs

2.

(a) Prove that for any integral domain D, the following can be proven:

f (x) =                   aixi  is  a  unit  of  D[[x]]  if  and     only  if  a0  is  a  unit  in  D.
                     i=0

(b) Compare the statement in part a to that in Theorem 16.5.7.

         (c) Give an example of the statement in part a in Z[[x]].
3. Use the formula for the product to verify that the expression g(x) of

      Example 16.5.8 is indeed the inverse of f (x).

4.

(a) Determine the inverse of f (x) = 1 + x + x2 + · · · =                                 xiin  Q[[x]].
                                                                                   i=0

(b) Repeat part a with f (x) taken in Z2[[x]].

(c) Use the method outlined in Chapter 8 to show that the power series
     f (x) = i=0  xi is the rational generating function 1-x 1 . What is the
     inverse of this function? Compare your results with those in part a.
CHAPTER 16. AN INTRODUCTION TO RINGS AND FIELDS                          461

5.

    (a) Determine the inverse of h(x) =            2ixi  in  Q[[x]].
                                              i=0

    (b) Use the procedures in Chapter 8 to find a rational generating func-

    tion for h(x) in part a. Find the multiplicative inverse of this func-

    tion.

6.  Let a(x) = 1 + 3x + 9x2 + 27x3 + · · · =       3ixi  and  b(x)    =  1 + x + x2  +
                                              i=0
    x3 + · · · =       xi  both  in  R[[x]].
                  i=0

    (a) What are the first four terms (counting the constant term as the
         0 th term) of a(x) + b(x)?

    (b) Find a closed form expression for a(x).

         (c) What are the first four terms of a(x)b(x)?
7. Write as an extended power series:

    (a) x4 - x5 -1

        (b) x2 - 2x3 + x4 -1

8. Derive the closed form expression di = 2i+1 - i - 2 for the coefficients of
      the product f (x) · g(x) in Example 16.5.4.
Appendix A

Algorithms

                                   algorithm

Using step-by-step math operations,
It performs with exact calculations.
An algorithm's job
Is to work out a "prob"
With repeated precise computations.

Jesse Frankovich, The Omnificent English Dictionary In Limerick Form

Computer programs, bicycle assembly instructions, knitting instructions, and
recipes all have several things in common. They all tell us how to do something;
and the usual format is as a list of steps or instructions. In addition, they are
usually prefaced with a description of the raw materials that are needed (the
input) to produce the end result (the output). We use the term algorithm to
describe such lists of instructions. We assume that the reader may be unfamil-
iar with algorithms, so the first section of this appendix will introduce some
of the components of the algorithms that appear in this book. Since we would
like our algorithms to become computer programs in many cases, the notation
will resemble a computer language such as Python or Sage; but our notation
will be slightly less formal. In some cases we will also translate the pseudocode
to Sage. Our goal will be to give mathematically correct descriptions of how
to accomplish certain tasks. To this end, the second section of this appendix
is an introduction to the Invariant Relation Theorem, which is a mechanism
for algorithm verification that is related to Mathematical Induction

A.1 An Introduction to Algorithms

Most of the algorithms in this book will contain a combination of three kinds
of steps: the assignment step, the conditional step, and the loop.

A.1.1 Assignments

In order to assign a value to a variable, we use an assignment step, which takes
the form:

                         Variable = Expression to be computed
The equals sign in most languages is used for assignment but some languages
may use variations such as := or a left pointing arrow. Logical equality, which

                                                 462
APPENDIX A. ALGORITHMS  463

produces a boolean result and would be used in conditional or looping steps,
is most commonly expressed with a double-equals, ==.

    An example of an assignment is k = n - 1 which tells us to subtract 1 from
the value of n and assign that value to variable k. During the execution of an
algorithm, a variable may take on only one value at a time. Another example
of an assignment is k = k - 1. This is an instruction to subtract one from the
value of k and then reassign that value to k.

A.1.2 Conditional steps

Frequently there are steps that must be performed in an algorithm if and only
if a certain condition is met. The conditional or "if ... then" step is then
employed. For example, suppose that in step 2 of an algorithm we want to
assure that the values of variables x and y satisfy the condition x <= y. The
following step would accomplish this objective.

    2. If x > y:
    ^^I2.1 t = x
    ^^I2.2 x = y
    ^^I2.3 y = t

Listing A.1.1 Code to be sure that x is not greater than y

    Steps 2.1 through 2.3 would be bypassed if the condition x > y were false
before step 2.

    One slight variation is the "if ... then ... else" step, which allows us to
prescribe a step to be taken if the condition is false. For example, if you
wanted to exercise today, you might look out the window and execute the
following algorithm.

    1. If it is cold or raining:
    ^^I^^Iexercise indoors
    ^^ Ielse :
    ^^I^^Igo outside and run
    2. Rest

Listing A.1.2 A plan for exercising

A.1.3 Loops

The conditional step tells us to do something once if a logical condition is true.
A loop tells us to repeat one or more steps, called the body of the loop, while
the logical condition is true. Before every execution of the body, the condition
is tested. The following flow diagram serves to illustrate the steps in a While
loop.
APPENDIX A. ALGORITHMS                                          464

Figure A.1.3 Flow diagram for a while loop

    Suppose you wanted to solve the equation f (x) = 0. The following initial
assignment and loop could be employed.

1. c = your first guess
2. While f(c) != 0:
^^I^^Ic = another guess

Listing A.1.4

    Caution: One must always guard against the possibility that the condition
of a While loop will never become false. Such "infinite loops" are the bane of
beginning programmers. The loop above could very well be such a situation,
particularly if the equation has no solution, or if the variable takes on real
values

    In cases where consecutive integer values are to be assigned to a variable, a
different loop construction, a For loop, is often employed. For example, suppose
we wanted to assign variable k each of the integer values from m to n and for
each of these values perform some undefined steps. We could accomplish this
with a While loop:

1. k := m            steps
2. While k <= n:
^^I2.1 execute some
^^I2.2 k = k + l

Listing A.1.5
    Alternatively, we can perform these steps with a For loop.

For k = m to n:
^^Iexecute some steps

Listing A.1.6
APPENDIX A. ALGORITHMS                                                         465

    For loops such as this one have the advantage of being shorter than the
equivalent While loop. The While loop construction has the advantage of
being able to handle more different situations than the For loop.

A.1.4 Exercises

1. What are the inputs and outputs of the algorithms listed in the first
      sentence of this section?

2. What is wrong with this algorithm?

            Input: a and b, integers
            Output: the value of c will be a - b
            (1) c = 0
            (2) While a > b:
            ^^I^^I(2.1) a := a - l
            ^^I^^I(2.2) c := c + l

      Listing A.1.7
3. Describe, in words, what the following algorithm does:

            Input: k, a positive integer
            Output: s = ?
            (1) s = 0
            (2) While k > 0:

                   (2.1) s = s + k
                   (2.2) k = k - 1

      Listing A.1.8
4. Write While loops to replace the For loops in the following partial algo-

      rithms:

(a) (1) S = 0
      (2) for k = 1 to 5: S = S + k^2

(b) The floor of a number is the greatest integer less than or equal to
     that number.

               (1) m = a positive integer greater than 1
               (2) B = floor(sqrt(m))
               (3) for i = 2 to B: if i divides evenly into m, jump to step 5
               (4) print "m is a prime" and exit
               (5) print "m is composite" and exit
5. Describe in words what the following algorithm does:

Input: n, a positive    integer
Output: k?
(1) f= 0
(2) k=n
(3) While k is even:
^^I(3.1) f = f+ 1
^^I(3.2) k = k div 2

      Listing A.1.9
6. Fix the algorithm in Exercise 2.
APPENDIX A. ALGORITHMS                                              466

A.2 The Invariant Relation Theorem

A.2.1 Two Exponentiation Algorithms

Consider the following algorithm implemented in Sage to compute ammod n,
given an arbitrary integer a, non-negative exponent m, and a modulus n, n  0.
The default sample evaluation computes 25 mod 7 = 32 mod 7 = 4, but you can
edit the final line for other inputs.

 def slow_exp(a,m,n):
         b=1
         k=m
         while k>0:
                b=(b*a)%n # % is integer remainder (mod) operation
                k-=1
         return b

 slow_exp (2 ,5 ,7)

 4

    It should be fairly clear that this algorithm will successfully compute am(mod n)
since it mimics the basic definition of exponentiation. However, this algorithm
is highly inefficient. The algorithm that is most commonly used for the task
of exponentiation is the following one, also implemented in Sage.

def fast_exp(a,m,n):                           quotient  operation
       t=a
       b=1
       k=m
       while k>0:
              if k%2==1: b=(b*t)%n
              t=(t^2)%n
              k=k//2 # // is the integer
       return b

fast_exp (2 ,5 ,7)

    The only difficulty with the "fast algorithm" is that it might not be so
obvious that it always works. When implemented, it can be verified by example,
but an even more rigorous verification can be done using the Invariant Relation
Theorem. Before stating the theorem, we define some terminology.

A.2.2 Proving the correctness of the fast algorithm

Definition A.2.1 Pre and Post Values. Given a variable x, the pre value

of x, denoted x`, is the value before an iteration of a loop. The post value,

denoted x´, is the value after the iteration.                       

Example A.2.2 Pre and post values in the fast exponentiation al-
gorithm. In the fast exponentiation algorithm, the relationships between the
pre and post values of the three variables are as follows.

´b  `bt`k`mod 2(mod n)

t´  t`2(mod n)
   k´ = k`//2
                                                          
APPENDIX A. ALGORITHMS                                       467

Definition A.2.3 Invariant Relation. Given an algorithm's inputs and a

set of variables that are used in the algorithm, an invariant relation is a set of

one or more equations that are true prior to entering a loop and remain true

in every iteration of the loop.                              

Example A.2.4 Invariant Relation for Fast Exponentiation. We claim

that the invariant relation in the fast algorithm is btk = am(mod n). We will

prove that this is indeed true below.                        

Theorem A.2.5 The Invariant Relation Theorem. Given a loop within
an algorithm, if R is a relation with the properties

(a) R is true before entering the loop

(b) the truth of R is maintained in any iteration of the loop

(c) the condition for exiting the loop will always be reached in a finite number
     of iterations.

then R will be true upon exiting the loop.

Proof. The condition that the loop ends in a finite number of iterations lets us

apply mathematical induction with the induction variable being the number of

iterations. We leave the details to the reader.              

We can verify the correctness of the fast exponentiation algorithm using

the Invariant Relation Theorem. First we note that prior to entering the loop,

btk = 1am = am(mod n). Assuming the relation is true at the start of any

iteration, that is `bt`k` = am(mod n), then

´bt´k´  (`bt`k` mod 2)(t`2)k`//2(mod n)

  ``2(k`//2)+k`                              mod  2(mod  n)
  bt

 `bt`k`(mod n)

 am(mod n)

Finally, the value of k will decrease to zero in a finite number of steps because
the number of binary digits of k decreases by one with each iteration. At the
end of the loop,

                                 b = bt0 = btk  am(mod n)

which verifies the correctness of the algorithm.

A.2.3 Exercises

1. How are the pre and post values in the slow exponentiation algorithm
      related? What is the invariant relation between the variables in the slow
      algorithm?

2. Verify the correctness of the following algorithm to compute the greatest
      common divisor of two integers that are not both zero.
APPENDIX A. ALGORITHMS  468

         def gcd(a,b):
                r0=a
                r1=b
                while r1 !=0:
                       t= r0 % r1
                       r0=r1
                       r1=t
                return r0

         gcd(1001,154) #test

         77

      Hint. The invariant of this algorithm is gcd(r0, r1) = gcd(a, b).

3. Verify the correctness of the Binary Conversion Algorithm in Chapter 1.

4. A dragon has 100 heads. A knight can cut off 15, 17, 20, or 5 heads,
      respectively, with one blow of his sword. In each of these cases 24, 2, 14,
      or 17 new heads grow on its shoulders, respectively. If all heads are blown
      off, the dragon dies. Can the dragon ever die? (problem attributed to
      Biswaroop Roy)
Appendix B

Python and SageMath

SageMath (originally Sage) is a computer algebra system that is built on top
of Python, which is a popular general-purpose programming language. In this
appendix we highlight a few features of Python through a series of SageMath
cells. Pure Python code can generally be evaluated in these cells and most of
what you see here is just Python. There are exceptions. For example, Sage-
Math has enhanced capabilities to work with sets. In Python, the expression
set([0,1,2,3]) is a set of four integers, and certain basic set operations can
be performed on these types of expressions. This is a valid expression in Sage-
Math too, but a different SageMath expression, Set([0,1,2,3]), with a capital
S, has enhanced properties. For example, we can create the power set of the
SageMath expression, which we do in the discussion of iterators.

B.1 Python Iterators

All programming languages allow for looping. A common form of loop is one
in which a series of instructions are executed for each value of some index
variable, commonly for values between two integers. Python allows a bit more
generality by having structures called "iterators" over which looping can be
done. An iterator can be as simple as a list, such as [0,1,2,3], but also can
be a power set of a finite set, as we see below, or the keys in a dictionary, which
is described in the next section.

B.1.1 Counting Subsets

Suppose we want to count the number of subsets of {0, 1, 2, ..., 9} that contain
no adjacent elements. First, we will define our universe and its power set. The
plan will be to define a function that determines whether a subset is "valid" in
the sense that it contains no adjacent elements. Then we will iterate over the
subsets, counting the valid ones. We know that the number of all subsets will
be 2 raised to the number of elements in U , which would be 210 = 1024, but
let's check.
 U= Set ( range (10) )

 power_set =U. subsets ()
 len(power_set)

  1024

                                                 469
APPENDIX B. PYTHON AND SAGEMATH  470

    The validity check in this case is very simple. For each element, k, of a
set, B, we ask whether its successor, k + 1, is also in the set. If we never get
an answer of "True" then we consider the set valid. This function could be
edited to define validity in other ways to answer different counting questions.
It's always a good idea to test your functions, so we try two tests, one with a
valid set and one with an invalid one.

 def valid(B):
         v=true
         for k in B:
                if k+1 in B:
                       v=false
                       break
         return v

 [ valid ( Set ([1 ,3 ,5 ,9]) ) , valid ( Set ([1 ,2 ,4 ,9]) )]

  [True , False]

    Finally we do the counting over our power set, incrementing the count
variable with each valid set.

 count =0
 for B in power_set:

         if valid(B):
                count +=1

 count

  144

B.2 Dictionaries

B.2.1 Colors of Fruits

In Python and SageMath, a dictionary is a convenient data structure for estab-
lishing a relationship between sets of data. From the point of view of this text,
we can think of a dictionary as a concrete realization of a relation between two
sets or on a single set. A dictionary resembles a function in that there is a set
of data values called the keys, and for each key, there is a value. The value
associated with a key can be almost anything, but it is most commonly a list.

    To illustrate the use of dictionaries, we will define a relationship between
colors and fruits. The keys will be a set of colors and values associated with each
color will be a list of fruits that can take on that color. We will demonstrate
how to initialize the dictionary and how to add to it. The following series of
assignments have no output, so we add a print statement to verify that this
cell is completely evaluated.

 fruit_color ={}
 fruit_color[ ' Red ' ]=[ ' apple ', ' pomegranate ', ' blood orange ']
 fruit_color[ ' Yellow ' ]=[ ' banana ', ' apple ', ' lemon ']
 fruit_color[ ' Green ' ]=[ ' apple ', ' pear ', ' grape ', ' lime ']
 fruit_color[ ' Purple ' ]=[ ' plum ', ' grape ']
 fruit_color[ ' Orange ' ]=[ ' orange ', ' pineapple ']
 print( ' done ')

  done

    We distinguish a color from a fruit by capitalizing colors but not fruit. The
keys of this dictionary are the colors. The keys() method returns an interator;
APPENDIX B. PYTHON AND SAGEMATH  471

so to get a list of keys we wrap the result with list().

 list ( fruit_color . keys () )

 [ ' Purple ', ' Orange ', ' Green ', ' Yellow ', ' Red ']

    As an afterthought, we might add the information that a raspberry is red
as follows. You have to be careful in that if 'Red' isn't already in the dictionary,
it doesn't have a value. This is why we need an if statement.

 if ' Red ' in fruit_color:
         fruit_color[ ' Red ' ]=fruit_color[ ' Red ' ]+[ ' raspberry ']

 else:
         fruit_color[ ' Red ' ]=[ ' raspberry ']

 fruit_color[ ' Red ']

 [ ' apple ', ' pomegranate ', ' blood orange ', ' raspberry ']

    A dictionary is iterable, with an iterator taking on values that are the keys.
Here we iterate over our dictionary to output lists consisting of a color followed
by a list of fruits that come in that color.

 for color in fruit_color:
         print([color ,fruit_color[color]])

 [ ' Purple ' , [ ' plum ' , ' grape ' ]]
 [ ' Orange ' , [ ' orange ' , ' pineapple ' ]]
 [ ' Green ' , [ ' apple ' , ' pear ' , ' grape ' , ' lime ' ]]
 [ ' Yellow ' , [ ' banana ' , ' apple ' , ' lemon ' ]]
 [ ' Red ', [ ' apple ', ' pomegranate ', ' blood

        orange ' , ' raspberry ' ]]

    We can view a graph of this relation between colors and fruits, but the
default view is a bit unconventional.

 DiGraph ( fruit_color ). plot ()

    With a some additional coding we can line up the colors and fruits in
their own column. First we set the positions of colors on the left with all
x-coordinates equal to -5 using another dictionary called vertex_pos.

 vertex_pos ={}
 k=0
 for c in fruit_color.keys():

         vertex_pos [c ]=( -5 , k)
         k+=1
 vertex_pos

  { ' Purple ': (-5, 0), ' Orange ': (-5, 1), ' Green ': (-5, 2),
         ' Red ': (-5, 4), ' Yellow ': (-5, 3)}

    Next, we place the fruit vertices in another column with x-coordinates all
equal to 5. In order to do this, we first collect all the fruit values into one set
we call fruits.

 fruits=Set([ ])
 for v in fruit_color.values():

          fruits=fruits.union(Set(v))
 k=0
 for f in fruits:

         vertex_pos [f ]=(5 , k)
         k+=1
APPENDIX B. PYTHON AND SAGEMATH  472

 vertex_pos

 { ' blood orange ': (5, 0), ' grape ': (5, 1), ' apple ': (5, 2),
         ' Purple ': (-5, 0), ' plum ': (5, 10), ' pomegranate ': (5,
        3), ' pear ': (5, 4), ' Yellow ': (-5, 3), ' orange ': (5, 7),
         ' Green ': (-5, 2), ' pineapple ': (5, 6), ' Orange ': (-5,
        1), ' lemon ': (5, 8), ' raspberry ': (5, 9), ' banana ': (5,
        5), ' Red ': (-5, 4), ' lime ': (5, 11)}

    Now the graph looks like a conventional graph for a relation between two
different sets. Notice that it's not a function.

 DiGraph(fruit_color).plot(pos=vertex_pos ,vertex_size=1)

  Graphics object consisting of 33 graphics primitives
Appendix C

Determinants

In Chapter 5 we defined the determinant of a 2 × 2 matrix for the sole purpose
of providing some hands-on experience in the computation of inverses of 2 × 2
matrices. In this appendix we will define the determinant of any square matrix,
and summarize the main properties of determinants.

C.1 Definition

Associated with every square matrix is a number called its determinant. The
most important information it provides us with is whether the matrix is in-
vertible. A matrix has an inverse if and only if its determinant is nonzero. If
A is a square matrix, then the determinant of A is commonly denoted either
det(A) or |A|. Strictly speaking, we only need to define the determinant of a
1 × 1 matrix here and then define the higher ordered ones recursively, but for
convenience we also recall the definition of the determinant of a 2 × 2 matrix.

Definition C.1.1 Determinant of 1 × 1 and a 2 × 2 matrices.

· If A is a 1 × 1 matrix, then |A| = A1,1

· If A is a 2 × 2 matrix, then |A| = A1,1A2,2 - A1,2A2,1

                                                                                                     
    We now proceed to define the determinant of an n × n matrix where n >
2. This definition requires two preliminary definitions those of minors and

cofactors.

Definition C.1.2 Matrix Minor. Let A be an n × n matrix, n  2. The

determinant of the (n - 1) × (n - 1) matrix formed by removing the ith row

and jth column of A is the minor denoted by M (A)i,j.           

                341                

Example C.1.3 Let A = 1 3 4 then A has nine minors, one of which

                                      413
is

                            M (A)1,1 = 3 4 = 3 · 3 - 4 · 1 = 5
                                            13

For our purposes in computing |A|, we only need minors corresponding

to any one row or column. Completing the minors in the first row we have

M (A)1,2 = -13 and M (A)1,3 = -11                               

                                   473
APPENDIX C. DETERMINANTS                                             474

Definition C.1.4 Cofactor. Let A be an n × n matrix, n  2. The ith row,
jth column cofactor of A, denoted C(A)i,j, is defined by

                                  C(A)i,j = (-1)i+j M (A)i,j

                                                                      

Example C.1.5 Using the values of minors computed in Example 3, we have

C(A)1,1 = (-1)2M (A)1,1 = 5, C(A)1,2 = (-1)3M (A)1,2 = 13, and C(A)1,3 =

(-1)4M (A)1,3 = -11.                                                  

Finally, we will define the determinant of a square matrix. Our definition

is practical in that you can apply it easily to any matrix. It isn't the most

general, nor is it the best definiton for the purposes of proving properties of

determinants. The more general definition is beyond our current scope, but

can be easily stated with background in permutation groups.

Definition C.1.6 Determinant of a Square Matrix. Let A be an n × n
matrix, n  2. The determinant of A is equal to

                                 n

                                    A1,j · C(A)1,j

                                j=1

                                                                      

Our definition of a determinant involves what is called expansion along

the first row of the matrix A. It is certainly not obvious, but it is true, that

the determinant of a matrix can be found by expanding along any row or any

column.

                                                                 341 

Example C.1.7 We have computed the cofactors for row 1 of A = 1 3 4

                                                                 413

above and so the determinant is only a few operations away.

         |A| = A1,1 · C(A)1,1 + A1,2 · C(A)1,2 + A1,3 · C(A)1,3
             = 3 · 5 + 4 · 13 + 1 · (-11)
             = 56

                                                                                                    
Example C.1.8 Associated with any square matrix, A, is a characteristic
polynomial which is defined to be the |A-I|. The roots of this polynomial are
the eigenvalues ofthe matrix. Here, we compute the characteristic polynomial

            341
of A = 1 3 4.

            413
    To compute the determinant we expand along the first row.

                     3-      4    1
det (A - I) = 1            3-     4
                                3-
                        4    1

         = (3 - ) · 3 -  4 + 4 · (-1) · 1 4 + 1 · 1 3 - 
                           1 3-                     4 3-         41

         = (3 - )((3 - )2 - 4) - 4((3 - ) - 16) + (1 - 4(3 - ))

         = -3 + 92 - 15 + 56

                                                                      
APPENDIX C. DETERMINANTS                                                    475

C.2 Computation

Our definition of determinant can be applied to estimate the worst case for
the time to evaluate an n × n determinant. Let M (n) be the number of mul-
tiplications to evaluate an n × n determinant. Then we have M (2) = 2. To
determine the value of M (3) we observe that this requires the computation
of three minors, each a two by two matrix, and then a multiplication of each
of them by the entries in row 1. Therefore, M (3) = 3M (2) + 3 = 9. Using
the same logic in general, we have M (n) = nM (n - 1) + n. The formula
can be derived to be M (n) = n! k=1 k! n 1 . For large n this is approximately
e · n!. Fortunately, there are ways to reduce the number of multiplications
using properties of determinants, which we list here without proof.

Theorem C.2.1 Properties of Determinants. Let A and B be n × n
matrices, where n  2.

1. |A| can be found by expanding along any row or any column.

2. If two rows (or columns) of A are interchanged, |A| changes sign.

3. The value of a determinant is unchanged if a multiple of one row (or
   column) of A is added to another row (or column) of A .

4. If one row (or column) of a matrix A is multiplied by a constant c, then
   the value of |A| is multiplied by c.

5. |AB| = |A| · |B|.

   6. |I| = 1 where I is the n × n identity matrix.
    Based on these properties, here are a few corollaries.

Corollary C.2.2 Further Properties. Let A and B be n × n matrices,
where n  2.

1. If a row (or column) of A consists entirely of zeros, then |A| = 0.

2. If a matrix A has two equal rows (or columns) then |A| = 0.

3. If any row (or column) of A is a scalar multiple of any other row (or
   column) of A, then |A| = 0.

4.  |A-1| =   1   ,  if  A-1  exists.
             |A|

Example C.2.3 Computatation of a determinant by row reduction.

We will apply some of these properties, most notably the first and third of

Theorem 1, to compute a four by four determinant without doing as many

multiplications as expected. We will use SageMath to do the calculations for

us. In SageMath, as in Python, numbering starts at zero, so we will describe
                                             
                                       1347

the process using that numbering system. Let A = 1 3 4 4  
                                                                      6678

                                                                       3375
    Our strategy will be to create a column that is mostly zero so that we
can expand along that column and only need to compute one cofactor. That
will be the 0th column. To do that we do the following row operations. We
subtract row 0 from row 1, replacing row 1 with that result. Then we subtract
six time row 0 from row 2, producing a new row 2. Finally, three times row
0 is subtracted from row 3 to produce a new row 3. The SageMath code
APPENDIX C. DETERMINANTS  476

below accomplishes this and produces a new matrix, B, which has the same
determinant.

 A= matrix ([[1 ,3 ,4 ,7] ,[2 ,3 ,4 ,4] ,[5 ,6 ,7 ,4] ,[3 ,3 ,7 ,5]])
 B= matrix ([ A [0] , A [1] -2* A [0] , A [2] -5* A [0] , A [3] -3* A [0]]) ;B

 [ 1 3 4 7]
 [ 0 -3 -4 -10]
 [ 0 -9 -13 -31]
 [ 0 -6 -5 -16]

    Expanding this matrix along the column zero, we need only compute a single
three by three cofactor. We will go one step further and do row operations to
get a matrix with zeros in rows 2 and 3 of column 1. The SageMath code below
tells what we are doing.

 C= matrix ([ B [0] , B [1] , B [2] -3* B [1] , B [3] -2* B [1]]) ;C

 [ 1 3 4 7]
 [ 0 -3 -4 -10]
 [ 0 0 -1 -1]
 [ 0 0 3 4]

    We are at a point where we can do the final calculation very easily.

                      |A| = |C| = 1 · (-3 · (-1 · 4 - 3 · (-1))) = 3

SageMath has a determinant function, det, that we can use to verify this
calculation:

 A= matrix ([[1 ,3 ,4 ,7] ,[2 ,3 ,4 ,4] ,[5 ,6 ,7 ,4] ,[3 ,3 ,7 ,5]])
 det(A)

3
                                                                                                   
Appendix D

Notation

The following table defines the notation used in this book. Page numbers or
references refer to the first appearance of each symbol.

Symbol      Description                                                      Page

xA          x is an element of A                                                  1
x / A       x is not an element of A                                              2
|A|         The number of elements in a finite set A.                             3
AB          A is a subset of B.                                                   3
            the empty set                                                         3
{}          the empty set                                                         3
AB          The intersection of A and B.                                          5
AB          The union of A and B.                                                 5
B-A         The complement of A relative to B.                                    7
Ac          The complement of set A relative to the uni-                          7
            verse.
AB          The symmetric difference of A and B.                                  8
A×B         The cartesian product of A with B.                                   11
P (A)       The power set of A, the set of all subsets of A.                     11
n!          n factorial, the product of the first n positive                     25
            integers
 n          n choose k, the number of k element subsets of                       33
  k         an n element set.
            the conjunction, p and q                                             41
pq          the disjunction, p or q                                              42
pq          the negation of p, "not p"                                           42
¬p          The conditional proposition If p then q.                             42
pq          The biconditional proposition p if and only if q                     43
pq          symbol for a tautology                                               48
1           symbol for a contradiction                                           48
0           r is logically equivalent to s                                       48
r  s        r implies s                                                          49
rs          the Sheffer Stroke of p and q                                        50
p|q         Symbol that denotes the end of a proof. Can                          55
            be replaced with QED
            the truth set of p                                                   59
Tp                                                                           page)
                                                  (Continued on next

            477
APPENDIX D. NOTATION                      478

Symbol                       Description                                               Page

(n)U (p(n))                  The statement that p(n) is true for at least one              67
                             value of n
(n)U (p(n))                  The statement that p(n) is always true.                       68
0m×n                         the m by n zero matrix                                        92
In                           The n × n identity matrix                                     95
A-1                          A inverse, the multiplicative inverse of A                    95
det A or |A|                 The determinant of A, 2 by 2 case                             96
a|b                          a divides b, or a divides evenly into b                     103
xsy                          x is related to y through the relation s                    104
rs                           the composition of relation r with relation s               104
[a]                          The equivalence class of a                                  112
A/r                          Partition of A with respect to an equivalence               112
                             relation r
a n b                        a is congruent to b modulo n                                113
a  b(mod n)                  a is congruent to b modulo n                                113
r+                           The transitive closure of r                                 121
f :AB                        A function, f , from A into B                               126
BA                           The set of all functions from A into B                      127
f (a)                        The image of a under f                                      127
f (X)                        Range of function f : X  Y                                  127
S                            Characteristic function of the set S                        130
|A| = n                      A has cardinality n                                         131
(g  f )(x) = g(f (x))        The composition of g with f                                 135
f  f = f2                    the "square" of a function.                                 136
i or iA                      The identity function (on a set A)                          137
f -1                         The inverse of function f read "f inverse"                  137
logba                        Logarithm, base b of a                                      165
                                                                                         170
S                            S pop                                                       173
S                            S push                                                      173
ST                           Convolution of sequences S and T                            173
Sp                           Multiple pop operation on S                                 175
Sp                           Multiple push operation on S                                175
Kn                           A complete undirected graph with n vertices.                186
deg(v), indeg(v), outdeg(v)  degree, indegree and outdegree of vertex v                  192
e(v)                         The eccentricity of a vertex                                205
d(G)                         The diameter of graphG                                      205
r(G)                         The radius of graph G                                       205
C (G)                        The center of graph G                                       205
Qn                           The n-cube                                                  213
V (f )                       The value of flow f                                         226
Pn                           A path graph of length n                                    232
(G)                          the chromatic number of G                                   236
Cn                           A cycle with n edges.                                       241
                             generic symbol for a binary operation                       270
string1 + string2            The concatenation of string1 and string2                    273
[G; ]                        a group with elements G and binary operation                275
                             
                                                                                       page)
                                                                   (Continued on next
APPENDIX D. NOTATION               479

Symbol                Description                                               Page

gcd(a, b)             the greatest common divisor of a and b                      283
Zn                    the integers modulo n                                       287
a +n b                the mod n sum of a and b                                    287
a ×n b                the mod n product of a and b                                287
Zn                    The Additive Group of Integer Modulo n                      288
Un                    The Multiplicative Group of Integer Modulo n                288
W V                   W is a subsystem of V                                       292
a                     the cyclic subgroup generated by a                          295
ord(a)                Order of a                                                  295
V1 × V2 × · · · × Vn  The direct product of algebraic structures                  297
                      V1, V2, . . . , Vn
G1 × G2               The direct product of groups G1 and G2                      298
G1 = G2               G1 is isomorphic to G2                                      306
dim(V )               The dimension of vector space V                             329
0                     least element in a poset                                    351
1                     greatest element in a poset                                 351
Dn                    the set of divisors of integer n                            352
ab                    the join, or least upper bound of a and b                   354
ab                    the meet, or greatest lower bound of a and b                354
[L; , ]               A lattice with domain having meet and join op-              354
                      erations
a¯                    The complement of lattice element a                         357
[B; , , ¯ ]           a boolean algebra with operations join, meet                358
                      and complementation
M1 2 ···k                                                                         359
                      the minterm generated by x1, x2, . . . , xk, where          366
A                     yi = xi if i = 1 and yi = x¯i if i = 0
An                    The set of all strings over an alphabet A                   379
                      The set of all strings of length n over an alpha-           379
                      bet A
s1 + s2               The empty string                                            379
L(G)                  The concatenation of strings s1 and s2                      380
                      Language created by phrase structure grammar                382
(S, X, Z, w, t)       G
                      A finite-state machine with states S, input al-             386
m(M )                 phabet X, output alphabet X, and output func-
                      tion w and next-state function t                            393
a  H, H  a            The machine of monoid M                                     396
G/H                                                                               403
SA                    the left and right cosets generated by a                    407
Sn                    The factor group G mod H.                                   409
                      The group of permutations of the set A                      409
An                    The group of permutations on a set with n ele-
Dn                    ments                                                       412
H G                   The Alternating Group                                       416
ker                   The nth dihedral group                                      419
                      H is a normal subgroup of G                                 421
                      the kernel of homomorphism                                page)

                                                            (Continued on next
APPENDIX D. NOTATION  480

Symbol                Description                                  Page

dH (a, b)             Hamming distance between a and b               425
[R; +, ·]             a ring with domain R and operations + and ·    434
U (R)                 the set of units of a ring R                   436
                                                                     437
D                     a generic integral domain                      439
deg f (x)             the degree of polynomial f (x)                 440
R[x]                  the set of all polynomials in x over R         446
R[[x]]                the set of all powers series in R              446
x`, x´                pre and post values of a variable x            456
M (A)i,j              The i, j minor of A                            465
C (A)i,j              The i, j cofactor of A                         472
det(A)or|A|           The determinant of A                           473
                                                                     473
Appendix E

An Informal Glossary of Terms

Glossary

Many of the words in this glossary are not formally defined in the book either
because they are viewed as prerequisites to a course in discrete mathematics
or are terms in computer science that some students may be unfamiliar with.

An. When referring to "an entity" we mean that the object can be any of the
elements is some set. For example, if you say that n is an integer, it could be
any integer.
Bit. The smallest unit of computer memory, normally represented as a 0 or 1.
Byte. A basic unit of computer memory containing eight Bits, normally mod-
eled as a sequence of eight 0's and 1's.
Complex Number. A number of the form a + bi, where a and b are real
numbers and i2 = -1.
Composite Integer. A positive integer is composite if it is greater than one
and is the product of two positive integers greater than one. For example, 10
(equal to 2 · 5) is composite. Any positive integer greater than one that is not
composite is Prime.
Constant. A numerical value that is unchanging . The value might be un-
known and it still may be represented with a symbol. For example if we are
discussing the process of sorting a file of N numbers, N is considered a constant
with respect to the sorting algorithm. Constants can become variables though.
If we have designed a sorting algorithm, and want to analyze its efficiency, we
would consider N to be a variable.
Creative Commons. An organization which has created several open licenses
for creative works such as Applied Discrete Structures.
Data Structure. A format for organizing, processing, retrieving and storing
data.
Distinct. Two entities are distinct if they are not the same. For example, any
two student ID numbers at a school should be distinct. If not, confusion could
ensue. See also Unique.
Even Integer. Any Integer that is equal to two times an integer. That
includes 0, since 0 = 2 · 0.
Factor. If an algebraic expression is the product of several expressions, each
of those expressions is a factor.
Iff. Shorthand for "if and only if"

                                                 481
APPENDIX E. AN INFORMAL GLOSSARY OF TERMS  482

Integer. Whole number, whether positive, negative or zero.

Into. When defining a function we use into as a connector between the domain
and codomian. Occasionally further abbeviated to to

                                                                                          
Irrational Number. A number that is not equal to any fraction. 2 is one
we prove to be irrational in the book.

LaTeX. A markup language used for books and papers with lots of mathe-
matics, which is built on TEX. PreTeXt uses LATEX as an intermediate format
to produce pdf and print output.

Multiples. Multiples of a number c are . . . , -3c, --2c, -c, 0, c, 2c, 3c, . . .

Natural Numbers. In this book, its the numbers 0,1,2,3,4,... . There isn't
100% agreement here. Some people say its the numbers 1,2,3,4, ... . We call
those numbers the positive integers. The symbol we use of the natural numbers
is N. There is no consistent definition of positive complex numbers.
Nonnegative Number. A number that is either positive or zero.

Odd Integer. An integer n is odd if there exists an integer k so that n = 2k+1.
Any integer that is not even is odd.

Positive Number. A positive number is a number that is greater than zero.
Normally visualized as being to the right of zero on a conventional number line.
The set of positive integers is denoted P. The sets of positive rational and real
numbers are denoted Q+ and R?+, respectively
Powers. Powers of a nonzero number c are . . . , c-3, c-2, c-1, 1, c1, c2, c3, . . ..
Recall that c0 = 1.
PreTeXt. An authoring and publishing system for authors of textbooks,
research articles, and monographs, especially in STEM disciplines. Applied
Discrete Structures is produced using PreTeXt.

Prime. A positive integer that is divisible by exactly two positive integers,
itself and 1. One is not prime, but 2 is the oddest prime because it's even. See
also Composite Integer.

Queue. A conventional waiting line, with the first come-first serve service rule.
A queue is a common Data Structure in computer science. See also Stack.

Rational Number. Any real number that is equal to a quotient two integers,
a/b, with b = 0.

Real Number. For the purposes of this book, think of the numbers on a
standard number line. All of the points make up the set of real numbers.

SageMath. An open source computer algebra system for a wide range of
symbolic and numerical mathematical computations. Originally named simply
Sage.

Stack. A Data Structure similar to a queue, but where the last come-first
serve service rule is used. This wouldn't be a fair waiting line rule, but it is a
very useful data structure. See also Queue

Subtraction. Subtraction is really addition of the negation of a number:
a - b = a + (-b).

Term. If an algebraic expression is the sum of several expressions, each of
those expressions is a term. For example there are three terms in the expression
2y + x - (w + 1)/2. Note that subtraction is considered the same as addition
here.
To. See Into.
Unique. We say a mathematical entity is unique when there's nothing else
like it. For example, the solution, x = 3 to the equation 2x + 1 = 7 is unique.
APPENDIX E. AN INFORMAL GLOSSARY OF TERMS  483

No other number solves the equation. See also Distinct.

Variable. A quantity whose value that can vary within a specified set. Nor-
mally represented by an algebraic symbol. For discrete variables it is customary
to use the letters in the range from i to n, but this isn't a rigid rule. Letters
at the end of the alphabet are traditionally used for continuous variables.
Appendix F

Hints and Solutions to Se-
lected Exercises

For the most part, solutions are provided here for odd-numbered exercises.

1 · Set Theory
1.1 · Set Notation and Relations
1.1.3 · Exercises for Section 1.1

1.1.3.1. Answer. These answers are not unique.

  (a) 8, 15, 22, 29                   (d) -8, -6, -4, -2
  (b) apple, pear, peach, plum        (e) 6, 10, 15, 21
  (c) 1/2, 1/3, 1/4, 1/5
1.1.3.3. Answer.

  (a) {2k + 1 | k  Z, 2  k  39}
  (b) {x  Q | -1 < x < 1}
  (c) {2n | n  Z}
  (d) {9n | n  Z, -2  n}
1.1.3.5. Answer.

(a) True   (d) True                   (g) False

(b) False  (e) False

(c) True   (f) True                   (h) True

1.1.3.7. Answer. {} is not the empty set - it contains something which
happens to be the empty set.

1.2 · Basic Set Operations
1.2.4 · Exercises

1.2.4.1. Answer.

                                 484
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES485

(a) {2, 3}                (e) {0}                    (i) 

(b) {0, 2, 3}             (f)                        (j) {0}
(c) {0, 2, 3}             (g) {1, 4, 5, 6, 7, 8, 9}

(d) {0, 1, 2, 3, 5, 9}    (h) {0, 2, 3, 4, 6, 7, 8}

1.2.4.3. Answer. These are all true for any sets A, B, and C.

1.2.4.5. Answer.

(a) {1, 4}  A  {1, 2, 3, 4}

(b) {2}  A  {1, 2, 4, 5}

  (c) A = {2, 4, 5}
1.2.4.7. Answer.

Figure F.0.1

1.3 · Cartesian Products and Power Sets
1.3.4 · Exercises

1.3.4.1. Answer.
  (a) {(0, 2), (0, 3), (2, 2), (2, 3), (3, 2), (3, 3)}

  (b) {(2, 0), (2, 2), (2, 3), (3, 0), (3, 2), (3, 3)}

  (c) {(0, 2, 1), (0, 2, 4), (0, 3, 1), (0, 3, 4), (2, 2, 1), (2, 2, 4),
       (2, 3, 1), (2, 3, 4), (3, 2, 1), (3, 2, 4), (3, 3, 1), (3, 3, 4)}
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES486

  (d) 
  (e) {(0, 1), (0, 4), (2, 1), (2, 4), (3, 1), (3, 4)}
  (f) {(2, 2), (2, 3), (3, 2), (3, 3)}
  (g) {(2, 2, 2), (2, 2, 3), (2, 3, 2), (2, 3, 3), (3, 2, 2), (3, 2, 3), (3, 3, 2), (3, 3, 3)}
  (h) {(2, ), (2, {2}), (2, {3}), (2, {2, 3}), (3, ), (3, {2}), (3, {3}), (3, {2, 3})}
1.3.4.3. Answer. {a, b}, {a, c}, {a, d}, {b, c}, {b, d} and {c, d}
1.3.4.5. Answer. There are n singleton subsets, one for each element.
1.3.4.7. Answer.
  (a) {+00, +01, +10, +11, -00, -01, -10, -11}
  (b) 16 and 512
1.3.4.9. Answer. They are equal when A = B.

1.4 · Binary Representation of Positive Integers
1.4.3 · Exercises

1.4.3.1. Answer.

  (a) 11111                 (c) 1010
                            (d) 1100100
  (b) 100000
1.4.3.3. Answer.

(a) 18                      (c) 42

(b) 19                      (d) 1264

1.4.3.5. Answer. There is a bit for each power of 2 up to the largest one
needed to represent an integer, and you start counting with the zeroth power.
For example, 2017 is between 210 = 1024 and 211 = 2048, and so the largest
power needed is 210. Therefore there are 11 bits in binary 2017.

(a) 11                      (c) 13

(b) 12                      (d) 51

1.4.3.7. Answer. A number must be a multiple of four if its binary rep-
resentation ends in two zeros. If it ends in k zeros, it must be a multiple of
2k .

1.5 · Summation Notation and Generalizations
1.5.3 · Exercises

1.5.3.1. Answer.

(a) 24                      (c) 3, 7, 15, 31

(b) 6                       (d) 1, 4, 9, 16

1.5.3.3. Answer.

(a) 1 + 1 + 1 + · · · + 1 = n
1(1 + 1) 2(2 + 1) 3(3 + 1)  n(n + 1) n + 1

(b) 1 + 1 + 1 = 1 + 1 + 1 = 3 = 3
     1(2) 2(3) 3(4) 2 6 12 4 3 + 1
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES487

(c) 1 + 23 + 33 + · · · + n3 =  1  n2(n + 1)2  1 + 8 + 27 = 36 =     1   (3)2(3 + 1)2
                                4                                    4

1.5.3.5. Answer.   (x + y)3 =      3  x3 +  3  x2y  +  (3  xy2 +  3  y3
                                   0        1                     3
                                                        2

1.5.3.7. Answer.

  (a) {x  Q | 0 < x  5}                     (c) 
                                            (d) {x  Q | -1 < x < 1} = B1
  (b) {x  Q | -5 < x < 5} = B5
1.5.3.9. Answer.

(a) 36                                      (b) 105

2 · Combinatorics
2.1 · Basic Counting Techniques - The Rule of
Products
2.1.3 · Exercises

2.1.3.1. Answer. If there are m horses in race 1 and n horses in race 2 then
there are m · n possible daily doubles.

2.1.3.3. Answer. 72 = 4 · 6 · 3

2.1.3.5. Answer. 720 = 6 · 5 · 4 · 3 · 2 · 1

2.1.3.7. Answer. If we always include the blazer in the outfit we would
have 6 outfits. If we consider the blazer optional then there would be 12
outfits. When we add a sweater we have the same type of choice. Considering
the sweater optional produces 24 outfits.

2.1.3.9. Answer.

(a) 28 = 256

(b) 24 = 16. Here we are concerned only with the first four bits, since the
     last four are a mirror image of the first four.

(c) 27 = 128, you have no choice in the last bit.

2.1.3.11. Answer.

(a) 16                                      (b) 31

    In the second part we can arrive at the answer by counting all subsets and
subtracting one since one of the sets (the whole set) is an improper subsets.

2.1.3.13. Answer.

  (a) 3                                     (b) 6
2.1.3.15. Answer. 18
2.1.3.17. Answer.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES488

Figure F.0.2 Solution to 17(a)
  (a) See Figure F.0.2
  (b) 56

2.1.3.19. Answer. 2n-1 - 1 and 2n - 2

2.2 · Permutations
2.2.2 · Exercises

2.2.2.1. Answer. P (1000, 3)
2.2.2.3. Answer. With repetition: 268  2.0883 × 1011

    Without repetition: P (26, 8)  6.2991 1010
2.2.2.5. Answer. 15!
2.2.2.7. Answer.

  (a) P (15, 5) = 360360
  (b) 2 · 14 · 13 · 12 · 11 = 48048
2.2.2.9. Answer. If the president is sitting at 12 o'clock on the table, then
the two members from her major need to sit at 4 and 8 o'clock. There are two
ways to arrange them. The other majors sit at 2, 6, and 10 o'clock and can be
placed P (3, 3) = 6 ways, so the final answer is 2 × 6 = 12
2.2.2.11. Answer.
  (a) P (4, 2) = 12
  (b) P (n; 2) = n(n - 1)
  (c) Case 1: m > n. Since the coordinates must be different, this case is

       impossible.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES489

       Case 2: m  n.P (n; m).

2.3 · Partitions of Sets and the Law of Addition
2.3.3 · Exercises

2.3.3.1. Answer. {{a}, {b}, {c}}, {{a, b}, {c}}, {{a, c}, {b}}, {{a}, {b, c}}, {{a, b, c}}

2.3.3.3. Answer. No. By this definition it is possible that an element of A
might belong to two of the subsets.

2.3.3.5. Answer. The first subset is all the even integers and the second is
all the odd integers. These two sets do not intersect and they cover the integers
completely.

2.3.3.7. Answer. Since 17 participated in both activities, 30 of the tennis
players only played tennis and 25 of the swimmers only swam. Therefore,
17 + 30 + 25 = 72 of those who were surveyed participated in an activity and
so 18 did not.

2.3.3.9. Solution. We assume that |A1  A2| = |A1| + |A2| - |A1  A2|.

|A1  A2  A3| = |(A1  A2)  A3| W hy?                                   W hy?
                    = |A1  A2| + |A3| - |(A1  A2)  A3| W hy?
                    = |(A1  A2| + |A3| - |(A1  A3)  (A2  A3)| W hy?
                    = |A1| + |A2| - |A1  A2| + |A3|
                       - (|A1  A3| + |A2  A3| - |(A1  A3)  (A2  A3)|
                    = |A1| + |A2| + |A3| - |A1  A2| - |A1  A3|
                       - |A2  A3| + |A1  A2  A3| W hy?

The law for four sets is

|A1  A2  A3  A4| = |A1| + |A2| + |A3| + |A4|
                              - |A1  A2| - |A1  A3| - |A1  A4|
                                 - |A2  A3| - |A2  A4| - |A3  A4|
                              + |A1  A2  A3| + |A1  A2  A4|
                                 + |A1  A3  A4| + |A2  A3  A4|
                              - |A1  A2  A3  A4|

Derivation:

|A1  A2  A3  A4| = |(A1  A2  A3)  A4|
                           = |(A1  A2  A3| + |A4| - |(A1  A2  A3)  A4|
                           = |(A1  A2  A3| + |A4|
                              - |(A1  A4)  (A2  A4)  (A3  A4)|
                           = |A1| + |A2| + |A3| - |A1  A2| - |A1  A3|
                              - |A2  A3| + |A1  A2  A3| + |A4| - |A1  A4|
                              + |A2  A4| + |A3  A4| - |(A1  A4)  (A2  A4)|
                              - |(A1  A4)  (A3  A4)| - |(A2  A4)  (A3  A4)|
                              + |(A1  A4)  (A2  A4)  (A3  A4)|
                           = |A1| + |A2| + |A3| + |A4| - |A1  A2| - |A1  A3|
                              - |A2  A3| - |A1  A4| - |A2  A4| - |A3  A4|
                              + |A1  A2  A3| + |A1  A2  A4|
                              + |A1  A3  A4| + |A2  A3  A4|
                              - |A1  A2  A3  A4|
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES490

2.3.3.11. Answer. Partition the set of fractions into blocks, where each
block contains fractions that are numerically equivalent. Describe how you
would determine whether two fractions belong to the same block. Redefine
the rational numbers to be this partition. Each rational number is a set of
fractions.

2.4 · Combinations and the Binomial Theorem
2.4.4 · Exercises

2.4.4.1. Answer. 103 · 254 = 1, 518, 000

2.4.4.2. Hint. Think of the set of positions that contain a 1 to turn this is
into a question about sets.

2.4.4.3. Answer. 710 + 810 + 910 + 10 10 = 120 + 45 + 10 + 1 = 176

2.4.4.5. Hint. Think of each path as a sequence of instructions to go right
(R) and up (U).

Answer. Each path can be described as a sequence or R's and U's with

exactly six of each. The six positions in which R's could be placed can be

selected from the twelve positions in the sequence  12   = 924 ways. We can
                                                    6
                                               m+n
generalize this logic and see that there are     m  paths from (0, 0) to (m, n).

2.4.4.7. Answer.

(a) C(52, 5) = 2, 598, 960

(b) 52 · 47 · 42 · 37
5         5        5         5

2.4.4.9. Answer.   4  ·  48  = 6 · 17296 = 103776
2.4.4.11. Answer.  2     3
2.4.4.13. Answer.
                      312 · 49 · 55
  (a) 10 = 45
          2

(b) 10 = 120
        3

2.4.4.15. Answer. Assume |A| = n. If we let x = y = 1 in the Binomial

Theorem, we obtain 2n =  n   +  n  +· · ·+  n  , with the right side of the equality
                         0      1           n

counting all subsets of A containing 0, 1, 2, . . . , n elements. Hence |P (A)| = 2|A|

2.4.4.17. Hint. 9998 = 10000 - 2
Answer. 100003 - 3 · 2 · 100002 + 3 · 22 · 10000 - 23 = 999, 400, 119, 992.

3 · Logic
3.1 · Propositions and Logical Operators
3.1.3 · Exercises

3.1.3.1. Answer.

(a) d  c                                    (c) ¬(d  s)

  (b) s  ¬c                                 (d) ¬s  ¬c
3.1.3.3. Answer.

(a) 2 > 5 and 8 is an even integer. False.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES491

  (b) If 2  5 then 8 is an even integer. True.
  (c) If 2  5 and 8 is an even integer then 11 is a prime number. True.
  (d) If 2  5 then either 8 is an even integer or 11 is not a prime number.

       True.

  (e) If 2  5 then either 8 is an odd integer or 11 is not a prime number.
       False.

  (f) If 8 is not an even integer then 2 > 5. True.

3.1.3.5. Answer. Only the converse of d is true. The converse of (a) is "It
it necessary for an integer to be a even that it be a multiple of four." This is
false because 6 is even and it isn't a multiple of four.

3.2 · Truth Tables and Propositions Generated
by a Set
3.2.4 · Exercises

3.2.4.1. Answer.

         p pp
  (a) 0 0

         11

p ¬p p  (¬p)

(b) 0 1           0

10                0

p ¬p p  (¬p)

(c) 0 1           1

10                1

       p pp
(d) 0 0

       11

3.2.4.3. Answer.

(a) ¬(p  r)  s

(b) (p  q)  (r  q)

3.2.4.5. Answer. 24 = 16 rows.

3.3 · Equivalence and Implication
3.3.5 · Exercises

3.3.5.1. Answer. a  e, d  f, g  h

3.3.5.3. Solution. No. In symbolic form the question is: Is (p  q)  (q 

p q p  q q  p (p  q)  (q  p)

00 1                 1          1

p)? 0 1 1            0          0

10 0                 1          0

11 1                 1          1

This table indicates that an implication is not always equivalent to its

converse.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES492

3.3.5.5. Solution. Let x be any proposition generated by p and q. The
truth table for x has 4 rows and there are 2 choices for a truth value for x for
each row, so there are 2 · 2 · 2 · 2 = 24 possible propositions.

3.3.5.7. Answer. 0  p and p  1 are tautologies.

3.3.5.9. Solution. Yes. In symbolic form the question is whether, if we have
a conditional proposition p  q, is (q  p)  (¬p  ¬q)?

p q q  p ¬p  ¬q (q  p)  (¬p  ¬q)

     00 1           1            1

     01 0           0            1

     10 1           1            1

     11 1           1            1

This table indicates that an converse is always equivalent to the inverse.

3.4 · The Laws of Logic
3.4.2 · Exercises

3.4.2.1. Answer. Let s = I will study,t = I will learn. The argument is:
((s  t)  (¬t))  (¬s), call the argument a.

                   s t s  t (s  t)  (¬t) a

                   00 1             1            1

                   01 1             0            1.

                   10 0             0            1

                   11 1             0            1

    Since a is a tautology, the argument is valid.

3.4.2.3. Answer. In any true statement S, replace;  with ,  with ,
0 with 1, 1 with 0,  with , and  with . Leave all other connectives
unchanged.

3.5 · Mathematical Systems and Proofs
3.5.4 · Exercises

3.5.4.1. Answer.

(a)

                    p q (p  q)  ¬q ((p  q)  ¬q)  p

                    00     0           1

                    01     0           1

                    10     1           1

                    11     0           1

(b)

           p q (p  q)  ¬q ¬p ((p  q)  (¬q))  ¬p

           00           1     1                  1

           01           0     1                  1

           10           0     0                  1

           11           0     0                  1

3.5.4.3. Answer.

(a) Direct proof:

     (1) d  (a  c)
     (2) d
     (3) a  c
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES493

        (4) a  b
        (5) ¬a  b
        (6) c  b
        (7) ¬c  b
        (8) (¬a  b)  (¬c  b)
        (9) (¬a  ¬c)  b
       (10) ¬(a  c)  b
       (11) b 
       Indirect proof:

        (1) ¬b Negated conclusion
        (2) a  b Premise
        (3) ¬a Indirect Reasoning (1), (2)
        (4) c  b Premise
        (5) ¬c Indirect Reasoning (1), (4)
        (6) (¬a  ¬c) Conjunctive (3), (5)
        (7) ¬(a  c) DeMorgan's law (6)
        (8) d  (a  c) Premise
        (9) ¬d Indirect Reasoning (7), (8)
       (10) d Premise
       (11)  (9), (10) 

 (b) Direct proof:

        (1) (p  q)  (r  s)
        (2) p  q
        (3) (p  t)  (s  u)
        (4) q  t
        (5) p  t
        (6) r  s
        (7) s  u
        (8) r  u
        (9) p  r
       (10) p  u
       (11) p  (t  u) Use (x  y)  (x  z)  x  (y  z)
       (12) ¬(t  u)  ¬p
       (13) ¬(t  u)
       (14) ¬p 

       Indirect proof:

        (1) p
        (2) p  q
        (3) q
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES494

        (4) q  t
        (5) t
        (6) ¬(t  u)
        (7) ¬t  ¬u
        (8) ¬u
        (9) s  u
       (10) ¬s
       (11) r  s
       (12) ¬r
       (13) p  r
       (14) r
       (15) 0 

  (c) Direct proof:

        (1) ¬s  p Premise
        (2) s Added premise (conditional conclusion)
        (3) ¬(¬s) Involution (2)
        (4) p Disjunctive simplification (1), (3)
        (5) p  (q  r) Premise
        (6) q  r Detachment (4), (5)
        (7) q Premise
        (8) r Detachment (6), (7) 

       Indirect proof:

        (1) ¬(s  r) Negated conclusion
        (2) ¬(¬s  r) Conditional equivalence (1)
        (3) s  ¬r DeMorgan (2)
        (4) s Conjunctive simplification (3)
        (5) ¬s  p Premise
        (6) s  p Conditional equivalence (5)
        (7) p Detachment (4), (6)
        (8) p  (q  r) Premise
        (9) q  r Detachment (7), (8)
       (10) q Premise
       (11) r Detachment (9), (10)
       (12) ¬r Conjunctive simplification (3)
       (13) 0 Conjunction (11), (12) 

 (d) Direct proof:

        (1) p  q
        (2) q  r
        (3) p  r
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES495

 (4) p  r
 (5) ¬p  r
 (6) (p  r)  (¬p  r)
 (7) (p  ¬p)  r
 (8) 0  r
 (9) r

Indirect proof:

        (1) ¬r Negated conclusion
        (2) p  r Premise
        (3) p (1), (2)
        (4) p  q Premise
        (5) q Detachment (3), (4)
        (6) q  r Premise
        (7) r Detachment (5), (6)
        (8) 0 (1), (7) 
3.5.4.5. Answer.

(a) Let W stand for "Wages will increase," I stand for "there will be in-
     flation," and C stand for "cost of living will increase." Therefore the
     argument is: W  I, ¬I  ¬C, W  C. The argument is invalid.
     The easiest way to see this is through a truth table, which has one case,
     the seventh, that this false. Let x be the conjunction of all premises.

W I C ¬I ¬C W  I ¬I  ¬C x x  C

0 00 1 1              1            1     01

0 01 1 0              1            0     01

0 10 0 1              1            1     01

0 11 0 0              1            1     01

1 00 1 1              0            1     01

1 01 1 0              0            0     01

1 10 0 1              1            1     10

1 11 0 0              1            1     11

(b) Let r stand for "the races are fixed," c stand for "casinos are crooked," t
     stand for "the tourist trade will decline," and p stand for "the police will
     be happy." Therefore, the argument is:

          (r  c)  t, t  p, ¬p  ¬r.

The argument is valid. Proof:

(1) t  p Premise
(2) ¬p Premise
(3) ¬t Indirect Reasoning (1), (2)
(4) (r  c)  t Premise
(5) ¬(r  c) Indirect Reasoning (3), (4)
(6) (¬r)  (¬c) DeMorgan (5)
(7) ¬r Conjunction simplification (6) 
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES496

3.5.4.7. Answer. p1  pk and pk  pk+1 implies p1  pk+1. It takes two
steps to get to p1  pk+1 from p1  pk This means it takes 2(100 - 1) steps to
get to p1  p100 (subtract 1 because p1  p2 is stated as a premise). A final
step is needed to apply detachment to imply p100

3.6 · Propositions over a Universe
3.6.3 · Exercises

3.6.3.1. Answer.

  (a) {{1}, {3}, {1, 3}, }

  (b) {{3}, {3, 4}, {3, 2}, {2, 3, 4}}

  (c) {{1}, {1, 2}, {1, 3}, {1, 4}, {1, 2, 3}, {1, 2, 4}, {1, 3, 4}, {1, 2, 3, 4}}

  (d) {, {2}, {3}, {4}, {2, 3}, {2, 4}, {3, 4}}

  (e) {A  U : |A| = 2}

3.6.3.3. Answer. There are 23 = 8 subsets of U , allowing for the possibility
of 28 nonequivalent propositions over U .

3.6.3.5. Answer. Two possible answers: s is odd and (s - 1)(s - 3)(s -
5)(s - 7) = 0

3.6.3.7. Solution. b and c

3.7 · Mathematical Induction
3.7.4 · Exercises

3.7.4.1. Answer. We wish to prove that P (n) : 1+3+5+· · ·+(2n-1) = n2
is true for n  1. Recall that the nth odd positive integer is 2n - 1.

    Basis: for n = 1, P (n) is 1 = 12, which is true
    Induction: Assume that for some n  1, P (n) is true. Then we infer that
P (n + 1) follows:

   1 + 3 + · · · + (2(n + 1) - 1) = (1 + 3 + · · · + (2n - 1)) + (2(n + 1) - 1)
                                        = n2 + (2n + 1) by P (n) and basic algebra
                                        = (n + 1)2 

3.7.4.3. Answer. Proof:

· Basis: We note that the proposition is true when n = 1:  k=1 1 k2 = 1 =
    6 1(2)(3) .

· Induction: Assume that the proposition is true for some n  1. This is
   the induction hypothesis.

n+1  n

     k2 = k2 + (n + 1)2

k=1  k=1

     = n(n + 1)(2n + 1) + (n + 1)2  by the induction hypothesis
                  6

        (n + 1)(2n2 + 7n + 6)
     =

                      6
     = (n + 1)(n + 2)(2n + 3) 

                      6

Therefore, the truth of the proposition for n implies the truth of the
proposition for n + 1.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES497

3.7.4.5. Solution.         Basis:  For  n  =  1,  we    observe   that    1    =        1
                                                                        (1·2)        (1+1)

Induction: Assume that for some n  1, the formula is true.
Then:

1                       1               1                  n                   1
(1 · 2) + · · · + n(n + 1) + (n + 1)(n + 2) = n + 1 + (n + 1)(n + 2)

                                                      =    (n + 2)n      +                  1

                                                         (n + 1)(n + 2) (n + 1)(n + 2)

                                                             (n + 1)2
                                                      =

                                                         (n + 1)(n + 2)

                                                      = n+1 
                                                         n+2

3.7.4.7. Answer. Let An be the set of strings of zeros and ones of length

n (we assume that |An| = 2n is known). Let En be the set of the "even"

strings,  and  Ec    =  the  odd   strings.   The problem is to prove that for n  1,

                  n
|En| = 2n-1. Clearly, |E1| = 1, and, if for some n  1, |En| = 2n-1, it follows
that |En+1| = 2n by the following reasoning.

We        partition  En+1    according  to   the  first  bit:  En+1  =  {1s       |  s    Ec    }    {0s  |

                                                                                             n

s  En}

Since {1s | s  Enc } and {0s | s  En} are disjoint, we can apply the

addition law. Therefore,

                           |En+1| = |Enc | + |En|
                                    = 2n-1 + (2n - 2n-1) = 2n. 

3.7.4.9. Solution. Assume that for n persons (n  1), 2 (n-1)n handshakes
take place. If one more person enters the room, he or she will shake hands with
n people,

                        (n - 1)n   +n=       n2 - n + 2n

                             2                       2

                                        =    n2 + n n(n + 1)
                                                        =
                                                  2            2

                                        = ((n + 1) - 1)(n + 1) 2 

Also, for n = 1, there are no handshakes, which matches the conjectured

formula:                           (1 - 1)(1) 2 = 0 .

3.7.4.11. Solution. Let p(n) be "a1 + a2 + · · · + an has the same value no
matter how it is evaluated."

    Basis: a1 + a2 + a3 may be evaluated only two ways. Since + is associative,
(a1 + a2) + a3 = a1 + (a2 + a3). Hence, p(3) is true.

    Induction: Assume that for some n  3, p(3), p(4), . . . , p(n) are all true.
Now consider the sum a1 + a2 + · · · + an + an+1. Any of the n additions in
this expression can be applied last. If the jth addition is applied last, we have

cj = (a1 + a2 + · · · + aj) + (aj+1 + · · · + an+1). No matter how the expression
to the left and right of the jth addition are evaluated, the result will always be

the same by the induction hypothesis, specifically p(j) and p(n + 1 - j). We
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES498

now can prove that c1 = c2 = · · · = cn. If i < j,

       ci = (a1 + a2 + · · · + ai) + (ai+1 + · · · + an+1)
          = (a1 + a2 + · · · + ai) + (ai+1 + · · · + aj) + (aj+1 + · · · + an+1)
          = ((a1 + a2 + · · · + ai) + (ai+1 + · · · + aj)) + (aj+1 + · · · + an+1)
          = (a1 + a2 + · · · + aj) + (aj+1 + · · · + an+1)
          = cj 

3.7.4.12. Hint. The number of times the rules are applied should be the
integer that you do the induction on.
3.7.4.13. Hint. Let p(m) be the proposition that xm+n = xmxn for all
n  1.
Solution. For m  1, let p(m) be xn+m = xnxm for all n  1. The basis for
this proof follows directly from the basis for the definition of exponentiation.

    Induction: Assume that for some m  1, p(m) is true. Then

             xn+(m+1) = x(n+m)+1 by associativity of integer addition
                          = xn+mx1 by recursive definition
                          = xnxmx1 induction hypothesis
                          = xnxm+1 recursive definition 

3.8 · Quantifiers
3.8.5 · Exercises

3.8.5.1. Answer.

  (a) (x)(F (x)  C(x))

  (b) There are objects in the sea which are not fish.

  (c) Every fish lives in the sea.
3.8.5.3. Answer.

  (a) There is a book with a cover that is not blue.

  (b) Every mathematics book that is published in the United States has a
       blue cover.

  (c) There exists a mathematics book with a cover that is not blue.

  (d) There exists a book that appears in the bibliography of every mathemat-
       ics book.

  (e) (x)(B(x)  M (x))

   (f) (x)(M (x)  ¬U (x))

  (g) (x)((y)(¬R(x, y))
3.8.5.5. Answer. The equation 4u2 - 9 = 0 has a solution in the integers.
(False)
3.8.5.7. Answer.

  (a) Every subset of U has a cardinality different from its complement. (True)

  (b) There is a pair of disjoint subsets of U both having cardinality 5. (False)
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES499

  (c) A - B = Bc - Ac is a tautology. (True)
3.8.5.9. Answer. (a)Q(b)Q(a + b is a rational number.)
3.8.5.10. Hint. You will need three quantifiers.
3.8.5.11. Answer. Let I = {1, 2, 3, . . . , n}

  (a) (x)I (x  Ai)

  (b) (x)I (x  Ai)

3.9 · A Review of Methods of Proof
3.9.3 · Exercises

3.9.3.1. Answer. The given statement can be written in if . . . , then . . .
format as: If x and y are two odd positive integers, then x + y is an even
integer.

    Proof: Assume x and y are two positive odd integers. It can be shown that
x + y = 2 · (some positive integer).

    x odd and positive  x = 2m + 1 for some m  0,
    y odd and positive  y = 2n + 1 for some n  0.
    Then,

   x + y = (2m + 1) + (2n + 1) = 2((m + n) + 1) = 2 · (some positive integer)

Therefore, x + y is an even positive integer.                                              

3.9.3.3. Answer. Proof: (Indirect) Assume to the contrary,that 2 is a
rational      number.  Then    there      exists   p, q     Z, (q  =  0)  where  p  =  2 and where
                                                                                 q
p
q  is  in  lowest      terms,  that  is,  p  and   q  have  no  common    factor    other  than  1.

                       p  p2
                       q = 2  q2 = 2

                                  p2 = 2q2
                                  p2 is an even integer
                                  p is an even integer (see Exercise 2)
                                  4 is a factor of p2
                                  q2 is even
                                  q is even

    Hence both p and q have a common factor, namely 2, which is a contradic-
tion. 

3.9.3.5. Answer. Proof: (Indirect) Assume x, y  R and x + y  1. Assume
to the contrary that x  12 or y  12 is false, which is equivalent to x >
1  and           12 .  Hence              1     1     1.  This  contradicts  the    assumption   that
2          y  >                x+y   >    2  +  2  =

x + y  1. 

4 · More on Sets
4.1 · Methods of Proof for Sets
4.1.5 · Exercises

4.1.5.1. Answer.

   (a) Assume that x  A (condition of the conditional conclusion A  C).
        Since A  B, x  B by the definition of . B  C and x  B implies
        that x  C. Therefore, if x  A, then x  C. 
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES500

  (b) (Proof that A - B  A  Bc) Let x be in A - B. Therefore, x is in A,
       but it is not in B; that is, x  A and x  Bc  x  A  Bc. 

  (c) ()Assume that A  B and A  C. Let x  A. By the two premises,x 
       B and x  C. Therefore, by the definition of intersection, x  B  C. 

  (d) ()(Indirect) Assume that Bc is not a subset of Ac . Therefore, there
       exists x  Bc that does not belong to Ac. x / Ac  x  A. Therefore,
       x  A and x / B, a contradiction to the assumption that A  B. 

  (e) There are two cases to consider. The first is when C is empty. Then the
       conclusion follows since both Cartesian products are empty.
       If C isn't empty, we have two subcases, if A is empty, A × C = , which
       is a subset of every set. Finally, the interesting subcase is when A is not
       empty. Now we pick any pair (a, c)  A × C. This means that a is in A
       and c is in C. Since A is a subset of B, a is in B and so (a, c)  B × C.
       Therefore A × C  B × C. 

4.1.5.3. Answer.

  (a) If A = Z and B = , A - B = Z, while B - A = .

  (b) If A = {0} and B = {1}, (0, 1)  A × B, but (0, 1) is not in B × A.

  (c) Let A = , B = {0}, and C = {1}.

  (d) If A = {1}, B = {1}, and C = , then the left hand side of the identity
       is {1} while the right hand side is the empty set. Another example is
       A = {1, 2}, B = {1}, and C = {2}.

4.1.5.5. Solution. Proof: Let p(n) be

        A  (B1  B2  · · ·  Bn) = (A  B1)  (A  B2)  · · ·  (A  Bn).

    Basis: We must show that p(2) : A  (B1  B2) = (A  B1)  (A  B2) is
true. This was done by several methods in section 4.1.

    Induction: Assume for some n  2 that p(n) is true. Then

A  (B1  B2  · · ·  Bn+1) = A  ((B1  B2  · · ·  Bn)  Bn+1)
                                    = (A  (B1  B2  · · ·  Bn))  (A  Bn+1) by p(2)
                                    = ((A  B1)  · · ·  (A  Bn))  (A  Bn+1) by the induction hypothesis
                                    = (A  B1)  · · ·  (A  Bn)  (A  Bn+1) 

4.1.5.6. Answer. The statement is false. The sets A = {1, 2}, B = {2, 3}
and C = {3, 4} provide a counterexample. Looking ahead to Chapter 6, we
would say that the relation of being non-disjoint is not transitive 6.3.3

4.2 · Laws of Set Theory
4.2.4 · Exercises

4.2.4.1. Answer.

  (a)
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES501

(b)

                 A B Ac Bc A  B (A  B)c Ac  Bc

                 00 1 1 0                 1    1

                 01 1 0 1                 0    0

                 10 0 1 1                 0    0

                 11 0 0 1                 0    0

     The last two columns are the same so the two sets must be equal.

(c)

     x  A  A  (x  A)  (x  A) by the definition of 
                    x  A by the idempotent law of logic

     Therefore, A  A  A.

     x  A  (x  A)  (x  A)  by conjunctive addition
             xAA

       Therefore, A  A  A and so we have A  A = A.

4.2.4.3. Answer. For all parts of this exercise, a reason should be supplied
for each step. We have supplied reasons only for part a and left them out of
the other parts to give you further practice.

  (a)

                A  (B - A) = A  (B  Ac) by Exercise 1 of Section 4.1
                                 = (A  B)  (A  Ac) by the distributive law.
                                 = (A  B)  U by the null law
                                 = (A  B) by the identity law 

  (b)

                                         A - B = A  Bc
                                                  = Bc  A .
                                                  = Bc  (Ac)c
                                                  = Bc - Ac

(c) Select any element, x  A  C. One such element exists since A  C is
     not empty.

                 xAC      xAxC
                           x  B  x  C.
                          xBC
                           B  C =  

     Therefore,

(d)

                 A  (B - C) = A  (B  Cc)

                          = (A  B  Ac)  (A  B  Cc)

                          = (A  B)  (Ac  Cc)        .

                          = (A  B)  (A  C)c

                          = (A - B)  (A - C) 
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES502

  (e)

                             A - (B  C) = A  (B  C)c
                                               = A  (Bc  Cc) .
                                               = (A  Bc)  (A  Cc)
                                               = (A - B)  (A - C) 

4.2.4.5. Hierarchy of Set Operations.
Answer.

(a) A  ((Bc)  C)              (b) (A  B)  (C  B)         (c) (A  B)  (Cc)

4.3 · Minsets
4.3.3 · Exercises

4.3.3.1. Answer.

(a) {1}, {2, 3, 4, 5}, {6}, {7, 8}, {9, 10}

(b) 25 , as compared with 210. {1, 2} is one of the 992 sets that can't be
     generated.

4.3.3.3. Answer. B1 = {00, 01, 10, 11} and B2 = {0, 00, 01} generate min-
sets {00, 01}, {0}, {10, 11}, and {, 1}. Note:  is the null string, which has
length zero.

4.3.3.5. Answer.

(a)  B1  B2  = ,  B1    Bc    = {0, 2, 4},   Bc      B2  = {1, 5},  Bc      Bc    = {3}

                           2                    1                      1       2

(b) 23, since there are 3 nonempty minsets.

4.3.3.7. Answer. Let a  A. For each i, a  Bi, or a  Bic, since Bi Bic =
A by the complement law. Let Di = Bi if a  Bi, and Di = Bic otherwise.
Since a is in each Di, it must be in the minset D1  D2 · · ·  Dn. Now consider
two different minsets M1 = D1 D2 · · ·Dn, and M2 = G1 G2 · · ·Gn, where
each Di and Gi is either Bi or Bic. Since these minsets are not equal, Di = Gi,
for some i. Therefore, M1  M2 = D1  D2 · · ·  Dn  G1  G2 · · ·  Gn = ,
since two of the sets in the intersection are disjoint. Since every element of A
is in a minset and the minsets are disjoint, the nonempty minsets must form a
partition of A. 

4.4 · The Duality Principle
4.4.2 · Exercises

4.4.2.1. Answer.

  (a) A  (B  A) = A
  (b) A  ((Bc  A)  B)c = 
  (c) (A  Bc)c  B = Ac  B
4.4.2.3. Answer.

(a) p  ¬((¬q  p)  q)  0

  (b) (¬(p  (¬q))  q)  ((¬p)  q)
4.4.2.5. Answer. The maxsets are:

· B1  B2 = {1, 2, 3, 5}
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES503

   · B1  B2c = {1, 3, 4, 5, 6}

   · B1c  B2 = {1, 2, 3, 4, 6}

   · B1c  B2c = {2, 4, 5, 6}

    They do not form a partition of A since it is not true that the intersection
of any two of them is empty. A set is said to be in maxset normal form
when it is expressed as the intersection of distinct nonempty maxsets or it is
the universal set U .

5 · Introduction to Matrix Algebra
5.1 · Basic Definitions and Operations
5.1.4 · Exercises

5.1.4.1. Answer. For parts c, d and i of this exercise, only a verification
is needed. Here, we supply the result that will appear on both sides of the
equality.

(a) AB =       -3 6     BA =          23
                9 -13                -7 -18

(b) 1 0
         5 -2

(c) 3 0
        15 -6

(d) 18 -15 15
         -39 35 -35

(e) -12 7 -7
          21 -6 6

(f) B + 0 = B
(g) 0 0

         00

(h) 0 0
         00

(i) 5 -5
        10 15

5.1.4.3. Answer.     1/2 0       0             1     0                
5.1.4.5. Answer.       0 1/3                      32768       0
                                 0  A15 =  0                  0
                                                     0
                             10  27            0         14348907

                  A3 =  0 8
                             00

5.1.4.7. Answer.

(a) Ax = 2x1 + 1x2 equals 3 if and only if both of the equalities
             1x1 - 1x2           1

2x1 + x2 = 3 and x1 - x2 = 1 are true.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES504

(b) (i) A = 2 -1 x = x1 B = 4
             11                  x2              0

                           
           11 2                  x1                    1

(c) A =  1 2 -1  x =  x2  B =  -1 

           13 1                  x3                    5

                       
           110                   x1              3

(d) A =  0 1 0  x =  x2  B =  5 

           103                   x3              6

5.2 · Special Types of Matrices
5.2.3 · Exercises

5.2.3.1. Answer.

(a) -1/5 3/5                            (d) A-1 = A
          2/5 -1/5

(b) No inverse exists.                                                        
(c) 1 3                                          1/3 0                   0
                                                                         0
         01                             (e)  0 2

                                                       0 0 -1/5

5.2.3.3. Solution. Let A and B be n by n invertible matrices.

The object here is to prove a formula for the inverse of AB, which is denoted

(AB)( - 1). If A( - 1)B( - 1) inverts AB (which it does) then the formula is

proven.

             B-1A-1     (AB) = B-1 A-1(AB)
                               = B-1 A-1A B
                               = ( B-1 IB)
                               = B-1(B)
                               =I

    Similarly, (AB) B-1A-1 = I.
    By Theorem 5.2.6, B-1A-1 is the only inverse of AB. If we tried to invert
AB with A-1B-1, we would be unsuccessful since we cannot rearrange the
order of the matrices.

5.2.3.5. Linearity of Determinants.

Solution.

(a) Let A =  ab         and B =         xy .
             cd                         zw

         det(AB) = det  ax + bz ay + bw
                        cx + dz cy + dw

             = adwx - adyz - bcwx + bcyz                     four terms cancel
                                                                                   .
             = (ad - bc)xw - (ad - bc)yz

             = (ad - bc)(xw - yz)
             = (det A)(det B)

(b) 1 = det I = det AA-1 = det A det A-1. Now solve for det A-1.

(c)  det A = 1 · 1 - 3 · 2 = -5  while  det A-1  =  1  ·  1  -  3  ·  2  = - 15 .
                                                    5     5     5     5
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES505

5.2.3.7. Answer. Basis: (n = 1) : det A1 = det A = (det A)1
    Induction: Assume det(An) = (det A)n for some n  1.

            det An+1 = det (AnA) by the definition of exponents
                         = det (An) det(A) by exercise 5
                         = (detA)n(det A) by the induction hypothesis
                         = (det A)n+1

5.2.3.9. Answer.
  (a) Assume A = BDB-1
       Basis: (m = 1): A1 = A = BD1B-1 is given.
       Induction: Assume that for some positive integer m, Am = BDmB-1

Am+1 = AmA
        = (BDmB-1)(BDB-1) by the induction hypothesis
        = (BDm(B-1B)(DB-1) by associativity
        = BDmDB-1 by the definition of inverse
        = BDm+1B-1 

(b) A10 = BD10B-1 =  -9206 15345
                     -6138 10231

5.3 · Laws of Matrix Algebra
5.3.3 · Exercises

5.3.3.1. Answer.

(a) Let A and B be m by n matrices. Then A + B = B + A,

(b) Let A, B, and C be m by n matrices. Then A + (B + C) = (A + B) + C.

(c) Let A and B be m by n matrices, and let c  R. Then c(A+B) = cA+cB,
(d) Let A be an m by n matrix, and let c1, c2  R. Then (c1 + c2) A =

     c1A + c2A.

(e) Let A be an m by n matrix, and let c1, c2  R. Then c1 (c2A) = (c1c2) A

(f) Let 0 be the zero matrix, of size m by n, and let A be a matrix of size
     n by r. Then 0A = 0 = the m by r zero matrix.

(g) Let A be an m by n matrix, and 0 = the number zero. Then 0A = 0 =
      the m by n zero matrix.

(h) Let A be an m by n matrix, and let 0 be the m by n zero matrix. Then
     A + 0 = A.

(i) Let A be an m by n matrix. Then A + (-1)A = 0, where 0 is the m by n
    zero matrix.

(j) Let A, B, and C be m by n, n by r, and n by r matrices respectively.
    Then A(B + C) = AB + AC.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES506

(k) Let A, B, and C be m by n, r by m, and r by m matrices respectively.
     Then (B + C)A = BA + CA.

(l) Let A, B, and C be m by n, n by r, and r by p matrices respectively.
    Then A(BC) = (AB)C.

(m) Let A be an m by n matrix, Im the m by m identity matrix, and In the
      n by n identity matrix. Then ImA = AIn = A

(n) Let A be an n by n matrix. Then if A-1 exists, A-1 -1 = A.

  (o) Let A and B be n by n matrices. Then if A-1 and B-1 exist, (AB)-1 =
       B-1A-1.

5.3.3.3. Answer.

(a) AB + AC =            21 5 22
                         -9 0 -6

(b) A-1 = 1 2 = A
                  0 -1

(c) A(B + C) = AB + BC, which is given in part (a).
(d) A2 -1 = (AA)-1 = (A-1A) = I-1 = I by part c

5.4 · Matrix Oddities
5.4.2 · Exercises

5.4.2.1. Answer. In elementary algebra (the algebra of real numbers), each
of the given oddities does not exist.

  (a) AB may be different from BA. Not so in elementary algebra, since
       ab = ba by the commutative law of multiplication.

  (b) There exist matrices A and B such that AB = 0, yet A = 0and B = 0. In
       elementary algebra, the only way ab = 0 is if either a or b is zero. There
       are no exceptions.

  (c) There exist matrices A, A = 0, yet A2 = 0. In elementary algebra,
       a2 = 0  a = 0.

  (d) There exist matrices A2 = A. where A = 0 and A = I. In elementary
       algebra, a2 = a  a = 0 or 1.

  (e) There exist matrices A where A2 = I but A = I and A = -I. In
       elementary algebra, a2 = 1  a = 1 or - 1.

5.4.2.3. Answer.

  (a) det A = 0  A-1 exists, and if you multiply the equation A2 = A on
       both sides by A-1 , you obtain A = I.

(b) Counterexample: A =         10
                                0 -1
5.4.2.5. Answer.          1/3
  (a) A-1 = 1/3          -2/3  x1 = 4/3, and x2 = 1/3
                    1/3
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES507

(b) A-1 =  1 -1             x1 = 4, and x2 = 4
           1 -2

(c) A-1 =  1/3 1/3          x1 = 2/3, and x2 = -1/3
           1/3 -2/3

(d) A-1 =  1/3 1/3          x1 = 0, and x2 = 1
           1/3 -2/3

(e) The matrix of coefficients for this system has a zero determinant; there-
     fore, it has no inverse. The system cannot be solved by this method. In
     fact, the system has no solution.

6 · Relations
6.1 · Basic Definitions
6.1.4 · Exercises

6.1.4.1. Answer.

(a) (2, 4), (2, 8)

(b) (2, 3), (2, 4), (5, 8)

(c) (1, 1), (2, 4)

6.1.4.3. Answer.

(a) r = {(1, 2), (2, 3), (3, 4), (4, 5)}

(b) r2 = {(1, 3), (2, 4), (3, 5)} = {(x, y) : y = x + 2, x, y  A}

  (c) r3 = {(1, 4), (2, 5)} = {(x, y) : y = x + 3, x, y  A}
6.1.4.5. Answer.

(a) When n = 3, there are 27 pairs in the relation.

(b) Imagine building a pair of disjoint subsets of S. For each element of S
     there are three places that it can go: into the first set of the ordered pair,
     into the second set, or into neither set. Therefore the number of pairs in
     the relation is 3n, by the product rule.

6.1.4.7. Solution. Assume (x, y)  r1r3. This implies that there exist z  A
such that (x, z)  r1 and (z, y)  r3. We are given that r1  r2, which implies
that (x, z)  r2. Combining this with (z, y)  r3 implies that (x, y)  r2r3,
which proves that r1r3  r2r3.

6.2 · Graphs of Relations on a Set
6.2.2 · Exercises

6.2.2.1. Answer.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES508

Figure F.0.3 Digraph for exercise 1
6.2.2.3. Answer. See Figure F.0.4

Figure F.0.4 Digraph of the relation t

6.3 · Properties of Relations
6.3.3 · Equivalence Relations

Checkpoint 6.3.16 Solution.
                      a n b  n | (a - b)  a - b = nq1, q1  Z
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES509

            b n c  n | (b - c)  b - c = nq2, q2  Z

Therefore

            a - c = (a - b) + (b - c) = n(q1 + q2)  a n c

6.3.4 · Exercises

6.3.4.1. Answer.

(a) "Divides" is reflexive because, if i is any positive integer, i · 1 = i and so
     i|i

(b) "Divides" is antisymmetric. Suppose i and j are two distinct positive

integers. One of them has to be less than the other, so we will assume

i < j. If i | j, then for some positive integer k, where k  1 we have

i · k = j.  But      this  means  that  j  ·  1  = i and since  1  is not a positive
                                              k                 k
integer, j  i.

  (c) "Divides" is transitive. If h, i and j are positive integers such that h | i
       and i | j, there must be two positive integers k1 and k2 such that h·k1 = i
       and i · k2 = j. Combining these equalities we get h · (k1 · k2) = j and so
       h | j.

6.3.4.3. Answer.

Table F.0.5 Properties of relations defined by digraphs

Part        reflexive?     symmetric?         antisymmetric?    transitive?
i           yes            no                 no                yes
ii          yes            no                 yes               yes
iii         no             no                 no                no
iv          no             yes                yes               yes
v           yes            yes                no                yes
vi          yes            no                 yes               yes
vii         no             no                 no                no

(i) See Table F.0.5

  (ii) Graphs ii and vi show partial ordering relations. Graph v is of an equiv-
       alence relation.

6.3.4.5. Answer.

(a) No, since | 1 - 1 |= 0 = 2, for example
(b) Yes, because | i - j |=| j - i |.
(c) No, since | 2 - 4 |= 2 and | 4 - 6 |= 2, but | 2 - 6 |= 4 = 2, for example.
(d) See Figure F.0.6

Figure F.0.6

6.3.4.7. Answer. Let a be any element of A. a  [a] since r is reflexive,
so each element of A is in some equivalence class. Therefore, the union of all
equivalence classes equals A. Next we show that any two equivalence classes are
either identical or disjoint and we are done. Let [a] and [b] be two equivalence
classes, and assume that [a]  [b] = . We want to show that [a] = [b]. To show
that [a]  [b], let x  [a]. x  [a]  arx. Also, there exists an element, y, of A
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES510
that is in the intersection of [a] and [b] by our assumption. Therefore,

                         ary  bry  ary  yrb r is symmetric
                                        arb transitivity of r

    Next,
                                    arx  arb  xra  arb
                                                   xrb
                                                   brx
                                                   x  [b]

    Similarly, [b]  [a]. 
6.3.4.9. Answer.

  (a) Equivalence Relation, [0] = {0}, [1] = {1}, [2] = {2, 3} = [3], [4] =
       {4, 5} = [5], and [6] = {6, 7} = [7]

  (b) Not an Equivalence Relation.
  (c) Equivalence Relation, [0] = {0, 2, 4, 6} = [2] = [4] = [6] and [1] =

       {1, 3, 5, 7} = [3] = [5] = [7]
6.3.4.11. Answer.

  (a) The proof follows from the biconditional equivalence in Table 3.4.4.
  (b) Apply the chain rule.
  (c) See Figure F.0.7.

Figure F.0.7

6.4 · Matrices of Relations
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES511

6.4.3 · Exercises

6.4.3.1. Answer.

     1  4 5 6                         6 7 8
          000
(a) 2  1 0 0  and 4                      000

     3    010                      5 1 0 0
                        
                                   6     010
     4    001

(b) r1r2 = {(3, 6), (4, 7)}

        6 7 8
     1    000

(c)  2    0       0  0  
                        
     3 1 0 0

     4    010

6.4.3.3. Answer.

Table F.0.8

                           R : xry if and only if |x - y| = 1
                           S : xsy if and only if x is less than y.

6.4.3.5. Hint. Consider the possible matrices.
Answer. The graph of a relation on three elements has nine entries. The
three entries in the diagonal must be 1 in order for the relation to be reflexive.
In addition, to make the relation symmetric, the off-diaginal entries can be
paired up so that they are equal. For example if the entry in row 1 column 2 is
equal to 1, the entry in row 2 column 1 must also be 1. This means that three
entries, the ones above the diagonal determine the whole matrix, so there are
23 = 8 different reflexive, symmetric relations on a three element set.

6.4.3.7. Answer.

     1  1 2 3 4                          1 2 3 4
          0100                        1     1010

(a)  2    1       0  1  0       and   2     0  1  0     1  
                                                           
     3 0 1 0 1                        3 1 0 1 0

     4    0010                        4     0101

          1       1 2 3 4                         1 2 3 4
                     0101                   1        1010

(b) P Q = 2          1  0    1  0     P2 =  2        0     1  0  1  = Q2
                                                                    
          3 0 1 0 1                         3 1 0 1 0

          4          1010                   4        0101

6.4.3.9. Answer.

(a) Reflexive: Rij = Rij for all i, j, therefore Rij  Rij

     Antisymmetric: Assume Rij  Sij and Sij  Rij for all 1  i, j  n.
     Therefore, Rij = Sij for all 1  i, j  n and so R = S

     Transitive: Assume R, S, and T are matrices where Rij  Sij and Sij 
     Tij, for all 1  i, j  n. Then Rij  Tij for all 1  i, j  n, and so
     R  T.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES512

  (b)

                            R2 ij = Ri1R1j + Ri2R2j + · · · + RinRnj
                                     Si1S1j + Si2S2j + · · · + SinSnj .
                                    = S2 ij  R2  S2

       To verify that the converse is not true we need only one example. For
       n = 2, let R12 = 1 and all other entries equal 0, and let S be the zero
       matrix. Since R2 and S2 are both the zero matrix, R2  S2, but since
       R12 > S12, R  S is false.

  (c) The matrices are defined on the same set A = {a1, a2, . . . , an}. Let
       c (ai) , i = 1, 2, . . . , n be the equivalence classes defined by R and let
       d (ai) be those defined by S. Claim: c (ai)  d (ai).

                                  aj  c (ai)  airaj
                                                 Rij = 1  Sij = 1
                                                 aisaj
                                                 aj  d (ai)

6.5 · Closure Operations on Relations
6.5.3 · Exercises

6.5.3.3. Answer.

  (a) See graphs below.

  (b) For example, 0s+4 and using S one can go from 0 to 4 using a path of
       length 3.

Figure F.0.9 Digraph of S  Figure F.0.10 Digraph of S2
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES513

Figure F.0.11 Digraph of S3        Figure F.0.12 Digraph of S+

6.5.3.5. Answer. Definition: Reflexive Closure. Let r be a relation on A.
The reflexive closure of r is the smallest reflexive relation that contains r.

    Theorem: The reflexive closure of r is the union of r with {(x, x) : x  A}

6.5.3.7. Answer.

(a) By the definition of transitive closure, r+ is the smallest relation which
     contains r; therefore, it is transitive. The transitive closure of r+, (r+)+ ,
     is the smallest transitive relation that contains r+. Since r+ is transitive,
     (r+)+ = r+.

  (b) The transitive closure of a symmetric relation is symmetric, but it may
       not be reflexive. If one element is not related to any elements, then the
       transitive closure will not relate that element to others.

7 · Functions
7.1 · Definition and Notation
7.1.5 · Exercises

7.1.5.1. Answer.

(a) Yes                   (c) No           (e) Yes

  (b) Yes                 (d) No
7.1.5.3. Answer.

(a) Range of f = f (A) = {a, b, c, d} = B

(b) Range of g = g(A) = {a, b, d}

(c) h is not a function.

(d) k is not a function.

(e) Range of L = L(A) = {1}

7.1.5.5. Answer. For each of the |A| elements of A, there are |B| possible
images, so there are |B| · |B| · . . . · |B| = B||A| functions from A into B.

7.2 · Properties of Functions
7.2.3 · Exercises

7.2.3.1. Answer. The only one-to-one function and the only onto function
is f .
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES514

7.2.3.3. Answer.

  (a) f1 is onto but not one-to-one: f1(0) = f1(1).

  (b) f2 is one-to-one and onto.

  (c) f3 is one-to-one but not onto.

  (d) f4 is onto but not one-to-one.

  (e) f5 is one-to-one but not onto.

  (f) f6 is one-to-one but not onto.
7.2.3.5. Answer. Let X = {socks selected} and Y = {pairs of socks} and
define f : X  Y where f (x) =the pair of socks that x belongs to . By the
Pigeonhole principle, there exist two socks that were selected from the same
pair.
7.2.3.7. Answer.

  (a) f (n) = n, for example

  (b) f (n) = 1, for example

  (c) None exist.

  (d) None exist.
7.2.3.9. Answer.

  (a) Use s : N  P defined by s(x) = x + 1.
  (b) Use the functionf : N  Z defined by f (x0 = x/2 if x is even and

       f (x) = -(x + 1)/2 if x is odd.

  (c) The proof is due to Georg Cantor (1845-1918), and involves listing the
       rationals through a definite procedure so that none are omitted and du-
       plications are avoided. In the first row list all nonnegative rationals with
       denominator 1, in the second all nonnegative rationals with denomina-
       tor 2, etc. In this listing, of course, there are duplications, for example,
       0/1 = 0/2 = 0, 1/1 = 3/3 = 1, 6/4 = 9/6 = 3/2, etc. To obtain a list
       without duplications follow the arrows in Figure F.0.13, listing only the
       circled numbers.
       We obtain: 0, 1, 1/2, 2, 3, 1/3, 1/4, 2/3, 3/2, 4/1, . . . Each nonnegative ra-
       tional appears in this list exactly once. We now must insert in this list
       the negative rationals, and follow the same scheme to obtain:

                         0, 1, -1, 1/2, -1/2, 2, -2, 3, -3, 1/3, -1/3, . . .

       which can be paired off with the elements of N.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES515

Figure F.0.13 Enumeration of the rational numbers.

7.2.3.11. Answer. Let f be any function from A into B. By the Pigeonhole
principle with n = 1, there exists an element of B that is the image of at least
two elements of A. Therefore, f is not an injection.

7.2.3.13. Answer. The proof is indirect and follows a technique called the
Cantor diagonal process. Assume to the contrary that the set is countable, then
the elements can be listed: n1, n2, n3, . . . where each ni is an infinite sequence
of 0s and 1s. Consider the array:

n1 = n11n12n13 · · ·
n2 = n21n22n23 · · ·
n3 = n31n32n33 · · ·

             ..
             .

We assume that this array contains all infinite sequences of 0s and 1s. Con-

sider the sequence s defined by si = 0                if nii = 1
                                                   1  if nii = 0

Notice that s differs from each ni in the ith position and so cannot be in

the list. This is a contradiction, which completes our proof.

7.3 · Function Composition
7.3.4 · Exercises

7.3.4.1. Answer.

(a) g  f : A  C is defined by (g  f )(k) = +                      if k = 1 or k = 5
                                                             -    otherwise

(b) No, since the domain of f is not equal to the codomain of g.

(c) No, since f is not surjective.

(d) No, since g is not injective.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES516

7.3.4.3. Answer.

  (a) The permutations of A are i, r1, r2, f1, f2, and f3, defined in Table 15.3.1.

  (b)
                                               g g-1 g2
                                               iii
                                               r1 r2 r2
                                               r2 r1 r1
                                               f1 f1 i
                                               f2 f2 i
                                               f3 f3 i

  (c) If f and g are permutations of A, then they are both injections and their
       composition, f  g, is a injection, by Theorem 7.3.6. By Theorem 7.3.7,
       f g is also a surjection; therefore, f g is a bijection on A, a permutation.

  (d) Proof by induction: Basis: (n = 1). The number of permutations of A is
       one, the identity function, and 1! = 1.

       Induction: Assume that the number of permutations on a set with n
       elements, n  1, is n!. Furthermore, assume that |A| = n + 1 and that
       A contains an element called . Let A = A - {}. We can reduce the
       definition of a permutation, f , on A to two steps. First, we select any one
       of the n! permutations on A. (Note the use of the induction hypothesis.)
       Call it g. This permutation almost completely defines a permutation on
       A that we will call f . For all a in A, we start by defining f (a) to be
       g(a). We may be making some adjustments, but define it that way for
       now. Next, we select the image of , which can be done n + 1 different
       ways, allowing for any value in A. To keep our function bijective, we
       must adjust f as follows: If we select f () = y = , then we must find
       the element, z, of A such that g(z) = y, and redefine the image of z
       to f (z) = . If we had selected f () = , then there is no adjustment
       needed. By the rule of products, the number of ways that we can define
       f is n!(n + 1) = (n + 1)! 
7.3.4.5. Answer.

  (a) f1 has an inverse. f1-1 = f13.

  (b) f2 has an inverse. f2-1 = f2.

  (c) f3 does not have an inverse. One way to verify this is to note that f3 is
       not one-to-one because f3(0000) = 0000 = f3(1111).

  (d) f4 has an inverse. f4-1 = f43.

7.3.4.7. Answer.

  (a) f  g(n) = n + 3

  (b) f 3(n) = n + 15

  (c) f  h(n) = n2 + 5

7.3.4.9. Hint. You have seen a similar proof in matrix algebra.

7.3.4.11. Answer. If f : A  B and f has an inverse, then that inverse is
unique.

    Proof: Suppose that g and h are both inverses of f , both having domain B
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES517

and codomain A.

                                     g = g  iB
                                        = g  (f  h)
                                        = (g  f )  h
                                        = iA  h
                                        =h g=h 

7.3.4.12. Hint. See Exercise 3 of Section 5.4.
7.3.4.13. Answer. Let x, x be elements of A such that g  f (x) = g  f (x);
that is, g(f (x)) = g(f (x)). Since g is injective, f (x) = f (x) and since f is
injective, x = x. 

    Let x be an element of C. We must show that there exists an element of A
whose image under g  f is x. Since g is surjective, there exists an element of
B, y, such that g(y) = x. Also, since f is a surjection, there exists an element
of A, z, such that f (z) = y, g  f (z) = g(f (z)) = g(y) = x.
7.3.4.15. Answer. Basis: (n = 2): (f1  f2) -1 = f2-1  f1-2 by Exer-
cise 7.3.4.12.

    Induction: Assume n  2 and

                    (f1  f2  · · ·  fn) -1 = fn-1  · · ·  f2-1  f1-1

and consider (f1  f2  · · ·  fn+1)-1.

           (f1  f2  · · ·  fn+1) -1 = ((f1  f2  · · ·  fn)  fn+1) -1
                                          = fn+1-1  (f1  f2  · · ·  fn) -1
                                                   by the basis
                                          = fn+1-1  fn-1  · · ·  f2-1  f1-1
                                                   by the induction hypothesis
                                          = fn+1-1  · · ·  f2-1  f1-1 .

8 · Recursion and Recurrence Relations
8.1 · The Many Faces of Recursion
8.1.8 · Exercises
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES518

8.1.8.1. Answer.

                  7  6        6
                     =+
                  2  2        1

                     5        5     5     5
                     =+++
                     2        1     1     0

                     5        5
                     = +2 +1
                     2        1

                     4        4        4     4
                     = + + 2( + ) + 1
                     2        1        1     0

                     4        4
                     = +3 +3
                     2        1

                     3        3        3     3
                     = + + 3( + ) + 3
                     2        1        1     0

                     3        3
                     = +4 +6
                     2        1

                     2        2        2     2
                     = + + 4( + ) + 6
                     2        1        1     0

                           2
                     = 5 + 11

                           1

                           1     1
                     = 5( + ) + 11
                           1     0

                     = 21

8.1.8.3. Answer.

(a) p(x) in telescoping form: ((((x + 3)x - 15)x + 0)x + 1)x - 10

  (b) p(3) = ((((3 + 3)3 - 15)3 - 0)3 + 1)3 - 10 = 74

8.1.8.5. Answer. The basis is not reached in a finite number of steps if you
try to compute f (x) for a nonzero value of x.

8.2 · Sequences
8.2.3 · Exercises

8.2.3.1. Answer. Basis: B(0) = 3 · 0 + 2 = 2, as defined.
    Induction: Assume: B(k) = 3k + 2 for some k  0.

B(k + 1) = B(k) + 3               by the induction hypothesis
            = (3k + 2) + 3       as desired
            = (3k + 3) + 2
            = 3(k + 1) + 2

8.2.3.3. Answer. Imagine drawing line k in one of the infinite regions that it
passes through. That infinite region is divided into two infinite regions by line
k. As line k is drawn through every one of the k - 1 previous lines, you enter
another region that line k divides. Therefore k regions are divided and the
number of regions is increased by k. From this observation we get P (5) = 16.

8.2.3.5. Answer. For n greater than zero, M (n) = M (n - 1) + 1, and
M (0) = 0.

8.3 · Recurrence Relations
8.3.5 · Exercises
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES519

8.3.5.1. Answer. S(k) = 2 + 9k

8.3.5.3. Answer. S(k) = 6(1/4)k

8.3.5.5. Answer. S(k) = k2 - 10k + 25

8.3.5.7. Answer. S(k) = (3 + k)5k

8.3.5.9. Answer. S(k) = (12 + 3k) + k2 + 7k - 22 2k-1

     8.3.5.11. Answer. S(k) = 4(-3)k + 2k - 5k+1
8.3.5.13. Answer.

(a) The characteristic equationis a2 - a - 1 = 0, which has solutions  =
       1 + 5 2 and  = 1 - 5 2, It is useful to point out that + = 1
                       kk

     and  -  = 5. The general solution is F (k) = b1 + b2 . Using the
     initial conditions, we obtain the system: b1 + b2 = 1 and b1 + b2 = 1.
     The solution to this system is b1 = /( - ) = 5 + 5 2 5 and

                                    
     b2 = /( - ) = 5 - 5 2 5

     Therefore the final solution is

F (n) =   n+1 - n+1              n+1 -            2 n+1
       =      -                            1- 5
                                        5

             1+ 5 2

  (b) Cr = F (r + 1)
8.3.5.15. Answer.

  (a) For each two-block partition of {1, 2, . . . , n - 1}, there are two partitions
       we can create when we add n, but there is one additional two-block
       partition to count for which one block is {n}. Therefore, D(n) = 2D(n -
       1) + 1 for n  2 and D(1) = 0.

  (b) D(n) = 2n-1 - 1

8.4 · Some Common Recurrence Relations
8.4.5 · Exercises

8.4.5.1. Answer.

  (a) S(n) = 1/n!

  (b) U (k) = 1/k, an improvement.

  (c) T (k) = (-3)kk!, no improvement.
8.4.5.3. Answer.

  (a) T (n) = 3 (log2 n + 1)
  (b) T (n) = 2

  (c) V (n) = log8 n + 1
8.4.5.4. Hint. Prove by induction on r.
8.4.5.5. Answer. The indicated substitution yields S(n) = S(n + 1). Since
S(0) = T (1)/T (0) = 6, S(n) = 6 for all n. Therefore T (n + 1) = 6T (n) 
T (n) = 6n.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES520

8.4.5.7. Answer.

(a) A good approximation to the solution of this recurrence relation is based

     on the following observation: n is a power of a power of two; that is,

     n is 2m, where m = 2k , then Q(n) = 1 + Q 2m/2 . By applying this

     recurrence relation k times we obtain Q(n) = k. Going back to the

     original form of n, log2 n = 2k or log2 (log2 n) = k. We would expect
     that in general, Q(n) is log2 (log2 n). We do not see any elementary
     method for arriving at an exact solution.

(b) Suppose that n is a positive integer with 2k-1  n < 2k. Then n can
     be written in binary form, (ak-1ak-2 · · · a2a1a0)two with ak-1 = 1 and

                                                      k-1

     R(n) is equal to the sum  (ak-1ak-2 · · · ai)two. If 2k-1  n < 2k, then

                                                       i=0

     we can estimate this sum to be between 2n - 1 and 2n + 1. Therefore,
     R(n)  2n.

8.5 · Generating Functions
8.5.7 · Exercises

8.5.7.1. Answer.

(a) 1, 0, 0, 0, 0, . . .

(b) 5(1/2)k

(c) 1, 1, 0, 0, 0, . . .

  (d) 3(-2)k + 3 · 3k
8.5.7.3. Answer.

(a) 1/(1 - 9z)
(b) (2 - 10z) 1 - 6z + 5z2

(c) 1 1 - z - z2

8.5.7.5. Answer.

  (a) 3/(1 - 2z) + 2/(1 + 2z), 3 · 2k + 2(-2)k
  (b) 10/(1 - z) + 12/(2 - z), 10 + 6(1/2)k
  (c) -1/(1 - 5z) + 7/(1 - 6z), 7 · 6k - 5k
8.5.7.7. Answer.

(a) 11k

(b) (5/3)k(k + 1)(k + 2)

k                           k  k
(c)  (j)(10(k - j)) = 10k  j - 10  j2 = (5/3)(k - 1)k(k + 1)
j=0                       j=0  j=0

(d) k(k + 1)(k + 3)/6

8.5.7.9. Answer. Coefficients of z0 through z5 in (1+5z)(2+4z)(3+3z)(4+
2z)(5 + z)
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES521

k Number of ways of getting a score of k

0                 120

1                 1044

2                 2724

3                 2724

4                 1044

5                 120

9 · Graph Theory
9.1 · Graphs - General Introduction
9.1.5 · Exercises

9.1.5.1. Answer. In Figure 9.1.8, computer b can communicate with all
other computers. In Figure 9.1.9, there are direct roads to and from city b to
all other cities.

9.1.5.3. Answer.

Figure F.0.14 Solution to exercise 3 of Section 9.1

9.1.5.5. Answer.  The maximum number of edges would be         28 = 2 (7)(8) =
28.

9.1.5.7. Answer.

(a) n = (n - 1)n
   2  2

  (b) n - 1, each vertex except the champion vertex has an indegree of 1 and
       the champion vertex has an indegree of zero.

9.1.5.9. Answer.

(a) Not graphic - if the degree of a graph with seven vertices is 6, it is
     connected to all other vertices and so there cannot be a vertex with
     degree zero.

(b) Graphic. One graph with this degree sequence is a cycle of length 6.

(c) Not Graphic. The number of vertices with odd degree is odd, which is
     impossible.

(d) Graphic. A "wheel graph" with one vertex connected to all other and
     the others connected to one another in a cycle has this degree sequence.

(e) Graphic. Pairs of vertices connected only to one another.

(f) Not Graphic. With two vertices having maximal degree, 5, every vertex
    would need to have a degree of 2 or more, so the 1 in this sequence makes
    it non-graphic.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES522

9.2 · Data Structures for Graphs
9.2.3 · Exercises

9.2.3.1. Answer.

(a) A rough estimate of the number of vertices in the "world airline graph"

would be the number of cities with population greater than or equal to

100,000. This is estimated to be around 4,100. There are many smaller

cities that have airports, but some of the metropolitan areas with clusters

of large cities are served by only a few airports. 4,000-5,000 is probably

a good guess. As for edges, that's a bit more difficult to estimate. It's

certainly not a complete graph. Looking at some medium sized airports

such as Manchester, NH, the average number of cities that you can go

to directly is in the 50-100 range. So a very rough estimate would be

75·4500  =  168, 750.  This  is  far  less  than  4, 5002,  so  an  edge  list  or  dictio-
    2
nary of some kind would be more efficient.

(b) The number of ASCII characters is 128. Each character would be con-

nected to   8  = 28 others and so there are       128·28        = 3, 584 edges.     Com-
            2                                        2
paring this to the 1282 = 16, 384, an array is probably the best choice.

  (c) The Oxford English Dictionary as approximately a half-million words,
       although many are obsolete. The number of edges is probably of the
       same order of magnitude as the number of words, so an edge list or
       dictionary is probably the best choice.

9.2.3.3. Answer. Each graph is isomorphic to itself. In addition, G2 and G4
are isomorphic; and G3, G5, and G6 are isomorphic to one another.

9.3 · Connectivity
9.3.6 · Exercises

9.3.6.1. Answer.

                       k         123456

               V [k].found T T T F F T

               V [k].from 2 5 6   5

               DepthSet 2 1 2   1

    (* = undefined)

9.3.6.3. Answer. If the number of vertices is n, there can be 2 (n-1)(n-2)
vertices with one vertex not connected to any of the others. One more edge
and connectivity is assured.
9.3.6.5. Answer.

(a) The eccentricity of each vertex is 2; and the diameter and radius are both
     2 as well. All vertices are part of the center.

(b) The corners (1,3,10 and 10) have eccentricities 5. The two central vertices,
     5 and 8, which are in the center of the graph have eccentricity 3. All other
     vertices have eccentricity 4. The diameter is 5. The radius is 3.

(c) Vertices 1, 2 and 5 have eccentricity 2 and make up the center of this
     graph. Verticies 7 and 8 have eccentricity 4, and all other vertices have
     eccentricity 3. The diameter is 4. The radius is 2.

(d) The eccentricity of each vertex is 4; and the diameter and radius are both
     4 as well. All vertices are part of the center.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES523

9.3.6.7. Answer. Basis: (k = 1) Is the relation r1, defined by vr1w if there
is a path of length 1 from v to w? Yes, since vrw if and only if an edge, which
is a path of length 1, connects v to w.

    Induction: Assume that vrkw if and only if there is a path of length k from
v to w. We must show that vrk+1w if and only if there is a path of length k + 1
from v to w.

                       vrk+1w  vrky and yrw for some vertex y

    By the induction hypothesis, there is a path of length k from v to y. And
by the basis, there is a path of length one from y to w. If we combine these
two paths, we obtain a path of length k + 1 from v to w. Of course, if we
start with a path of length k + 1 from v to w, we have a path of length k
from v to some vertex y and a path of length 1 from y to w. Therefore,
vrky and yrw  vrk+1w.

9.4 · Traversals: Eulerian and Hamiltonian Graphs
9.4.3 · Exercises

9.4.3.1. Answer. Using a recent road map, it appears that an Eulerian
circuit exists in New York City, not including the small islands that belong to
the city. Lowell, Massachusetts, is located at the confluence of the Merrimack
and Concord rivers and has several canals flowing through it. No Eulerian path
exists for Lowell.

9.4.3.3. Answer. Gray Code for the 4-cube:

  0000  

  0001  
        
        
  0011  
 0010 
 0110 
        
 0111 
        
  0101  
        
G  4 =  0100 
 1100 
        
  1101  
 1111 
 1110 
        
 1010 
        
  1011  
        
 1001 

  1000

9.4.3.5. Answer. Any bridge between two land masses will be sufficient. To
get an Eulerian circuit, you must add a second bridge that connects the two
land masses that were not connected by the first bridge.

9.4.3.7. Answer. Let G = (V, E) be a directed graph. G has an Eulerian

circuit if and only if G is connected and indeg(v) = outdeg(v) for all v  V .
There exists an Eulerian path from v1 to v2 if and only if G is connected,
indeg(v1) = outdeg(v1) - 1, indeg(v2) = outdeg(v2) + 1, and for all other
vertices in V the indegree and outdegree are equal.

9.4.3.8. Hint. You could prove this by induction on the number of edges,
but an easier way would be to consider the degree sequence and use something
you know about the sum of the entries.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES524

9.4.3.9. Answer. A round-robin tournament graph is rarely Eulerian. It
will be Eulerian if it has an odd number of vertices and each vertex (team)
wins exactly as many times as it loses. Every round-robin tournament graph
has a Hamiltonian path. This can be proven by induction on the number of
vertices.

9.4.3.11. Solution. No, such a line does not exist. The dominoes with two
different numbers correspond with edges in a K6. See corresponding dominos
and edges in Figure F.0.15. Dominos with two equal numbers could be held
back and inserted into the line created with the other dominoes if such a line
exists. For example, if (2, 5), (5, 4) were part of the line, (5, 5) could be inserted
between those two dominoes. The line we want exists if and only if there exists
an Eulerian path in a K6. Since all six vertices of a K6 have odd degree no
such path exists.

Figure F.0.15 Correspondence between a line of dominos and a path in a K6

9.5 · Graph Optimization
9.5.5 · Exercises

9.5.5.1. Answer. The circuit would be Boston, Providence, Hartford, Con-
cord, Montpelier, Augusta, Boston. It does matter where you start. If you
start in Concord, for example, your mileage will be higher.

9.5.5.3. Answer.
                              

  (a) Optimal cost = 2 2  2.82843, which is attained with the nearest neigh-
       bor algorithm. Strip algorithm phase 1 cost = 3.39411. Strip algorithm
       phase 2 cost = 3.67696.

(b) Optimal cost = 2.62266, which is attained with the nearest neighbor
     algorithm. Strip algorithm phase 1 cost is = 3.00007. Strip algorithm
     phase 2 cost 3.07119.

(c) A = (0.0, 0.5), B = (0.5, 0.0), C = (0.5, 1.0), D = (1.0, 0.5)

There are 4 points; so we will divide the unit square into two strips.

· Optimal Path: (B, A, C, D)                      
· Phase I Path: (B, A, C, D)    Distance = 2 2
· Phase II Path: (A, C, B, D)
                                                
                               Distance = 2 2

                                                     
                                Distance = 2 + 2

(d) A = (0, 0), B = (0.2, 0.6), C = (0.4, 0.1), D = (0.6, 0.8), E = (0.7, 0.5)
     There are 5 points; so we will divide the unit square into three strips.

· Optimal Path: (A, B, D, E, C) Distance = 2.30821
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES525

       · Phase I Path: (A, C, B, C, E)   Distance = 2.5745
       · Phase II Path: (A, B, D, E, C)   Distance = 2.30821

9.5.5.5. Answer.

(a) f (c, d) = 2, f (b, d) = 2, f (d, k) = 5, f (a, g) = 1, and f (g, k) = 1.

(b) There are three possible flow-augmenting paths. s, b, d, k with flow in-
     crease of 1. s, a, d, k with flow increase of 1, and s, a, g, k with flow in-
     crease of 2.

  (c) The new flow is never maximal, since another flow-augmenting path will
       always exist. For example, if s, b, d, k is used above, the new flow can be
       augmented by 2 units with s, a, g, k.

9.5.5.7. Answer.

(a) Value of maximal flow = 31.

(b) Value of maximal flow = 14.

  (c) Value of maximal flow = 14. See Table F.0.16 for one way to got this
       flow.

Table F.0.16

       Step Flow-augmenting path Flow added

       1          Source, A, Sink            2

       2          Source, C, B, Sink         3

       3          Source, E, D, Sink         4

       4          Source, A, B, Sink         1

       5          Source, C, D, Sink         2

       6 Source, A, B, C, D, Sink            2

9.5.5.9. Hint. Count the number of comparisons of distances that must be
done.

Answer. To locate the closest neighbor among the list of k other points on
the unit square requires a time proportional to k. Therefore the time required
for the closest-neighbor algorithm with n points is proportional to (n - 1) +
(n - 2) + · · · + 2 + 1, which is proportional to n2. Since the strip algorithm
takes a time proportional to n(log n), it is much faster for large values of n.

9.6 · Planarity and Colorings
9.6.3 · Exercises

9.6.3.1. Answer. A K5 has 10 edges. If a K5 is planar, the number of regions
into which the plane is divided must be 7, by Euler's formala (5 + 7 - 10 = 2).
If we re-count the edges of the graph by counting the number edges bordering
the regions we get a count of at least 7 × 3 = 21. But we've counted each edge
twice this way and the count must be even. This implies that the number of
edges is at least 11, which a contradiction.

9.6.3.2. Hint. Don't forget Theorem 9.6.21!
9.6.3.3. Answer.

(a) 4             (c) 3                      (e) 2
(b) 3             (d) 3                      (f) 4
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES526

9.6.3.5. Answer. The chromatic number is n since every vertex is connected
to every other vertex.

9.6.3.7. Answer. Suppose that G is not connected. Then G is made up of
2 components that are planar graphs with less than k edges, G1 and G2. For
i = 1, 2 let vi, ri, andei be the number of vertices, regions and edges in Gi. By
the induction hypothesis, vi + ri - ei = 2 for i = 1, 2.

    One of the regions, the infinite one, is common to both graphs. Therefore,
when we add edge e back to the graph, we have r = r1 + r2 - 1, v = v1 + v2,
and e = e1 + e2 + 1.

                 v + r - e = (v1 + v2) + (r1 + r2 - 1) - (e1 + e2 + 1)

                              = (v1 + r1 - e1) + (v2 + r2 - e2) - 2

                              =2+2-2

                              =2

9.6.3.9. Answer. Since |E| + |Ec| = 2 n(n-1) , either E or Ec has at least
4 n(n-1) elements. Assume that it is E that is larger. Since 4 n(n-1) is greater
than 3n - 6 for n  11, G would be nonplanar. Of course, if Ec is larger, then
G would be nonplanar by the same reasoning. Can you find a graph with ten
vertices such that it is planar and its complement is also planar?

9.6.3.11. Answer. Suppose that (V, E) is bipartite (with colors red and
blue), |E| is odd, and (v1, v2, . . . , v2n+1, v1) is a Hamiltonian circuit. If v1 is
red, then v2n+1 would also be red. But then {v2n+1, v1} would not be in E, a
contradiction.

9.6.3.13. Answer. Draw a graph with one vertex for each edge, If two edges
in the original graph meet at the same vertex, then draw an edge connecting
the corresponding vertices in the new graph.

9.6.3.15. Solution.

  (a) The chromatic number will always be two. One coloring of any of these
       graphs would be to color all vertices whose coordinate add up to an even
       integer one color and the other vertices whose coordinates have an odd
       sum some other color. This works because for any vertex, if the sum of
       coordinate is even, the adjacent vertices differ in exactly one coordinate
       by ±1 and so they have a coordinate sum that is odd.

  (b) If both a1 and a2 are odd, then M (a1, a2) does not have a Hamiltonian
       circuit. To see why, we can color vertices with an even coordinate sum
       white and the ones with a odd sum black. If a1 = 2k1 + 1 and a2 =
       2k2 + 1, then there are N = 4k1k2 + 2k1 + 2k2 + 1 vertices. There will be
       k1k2 +k1 +k2 +1 white vertices and one fewer black one. Any circuit that
       starts and ends at any vertex must have an even number of vertices if we
       count the beginning/ending vertex once. This implies that a Hamiltonian
       circuit that includes all vertices cannot exist.

       If either of the ai are even, M (a1, a2) does have a Hamiltonian circuit.
       There are many different possible circuits, but one of them, assuming a1
       is even, would be to start at (1, 1), traverse the left border, the top border
       and the right border, leaving you at (a1, 1). then you can zig-zag back
       to (1, 1) visiting all of the vertices in the interior of the graph and the
       bottom border. This is is illustrated in the following graph of M (4, 3)
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES527

  (c) As in the two diminsional case there will be a Hamiltonian circuit if at
       least one of the ai are even.

10 · Trees
10.1 · What Is a Tree?
10.1.3 · Exercises

10.1.3.1. Answer. The number of trees are: (a) 1, (b) 3, and (c) 16. The
trees that connect Vc are:

Figure F.0.17
10.1.3.3. Hint. Use induction on |E|.
10.1.3.5. Solution.

  (a) Assume that (V, E) is a tree with |V |  2, and all but possibly one vertex
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES528

       in V has degree two or more.

                     2|E| = deg(v)  2|V | - 1  |E|  |V | - 1
                                                                                2

                                           vV

                                                             |E|  |V |
                                                             (V, E) is not a tree.

  (b) The proof of this part is similar to part (a). If we assume that there are
       less than three vertices of degree three, we can still infer 2|E|  2|V | - 1
       using the fact that a non-chain tree has at least one vertex of degree three
       or more.

10.1.3.7. Solution. We can prove this by induction for trees with n vertices,
n  2. The basis is clearly true since the only tree with two vertices is a K2.
Now assume that () is true for some n greater than or equal to two and
consider a tree T with n + 1 vertices. We proceed by removing a leaf from T .
If there exists a leaf connected to a vertex of degree two, we select one such
leaf. The resulting tree satisfies () for the number of leaves; and adding the
removed leaf neither changes the number of leaves nor the value of (). If all
interior vertices have degree three or more remove any leaf from T . Again, the
number of leaves in the resulting tree is (), but this time when we put the
removed leaf back on the tree the number of leaves will increase by one, but
the value of () will increase by one to match it

10.2 · Spanning Trees
10.2.4 · Exercises

10.2.4.1. Answer. It might not be most economical with respect to Objec-
tive 1. You should be able to find an example to illustrate this claim. The new
system can always be made most economical with respect to Objective 2 if the
old system were designed with that objective in mind.

10.2.4.3. Solution.

  (a) There are three minimal spanning tree, with edges {0, 5}, {0, 3}, {4, 5}
       and any two of the following edges {0, 1}, {0, 2}, {1, 2}.

  (b) There is only one minimal spanning tree. If we start with
       BOS as the "right set", the edges in the following set are or-
       dered according to how they are added in Prim's Algorithm:
       {{BOS, N Y }, {N Y, P HI}, {P HI, DC}, {DC, AT L},
       {P HI, KC}, {KC, CHI}, {KC, LA}, {LA, SF }}.

  (c) There is only one minimal spanning tree, which has edges
       {{1, 8}, {2, 8}, {2, 7}, {3, 7}, {3, 6}, {4, 6}, {4, 5}}

10.2.4.5. Solution.

  (a) No, every minimal spanning tree will include the edge of minimal weight?
       At some point, the edge of minimal weight will be part of a bridge between
       two sets and will be included in the spanning tree.

  (b) Yes, this will happen if the edge of maximal weight is the only bridge
       between two sets.

10.2.4.7. Solution.

  (a) Edges in one solution are: {8, 7}, {8, 9}, {8, 13}, {7, 6}, {9, 4}, {13, 12},
       {13, 14}, {6, 11}, {6, 1}, {1, 2}, {4, 3}, {4, 5}, {14, 15}, and {5, 10}
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES529
  (b) Vertices 8 and 9 are centers of the graph. Starting from vertex 8, a
       minimum diameter spanning tree is
       {{8, 3}, {8, 7}, {8, 13}, {8, 14}, {8, 9}, {3, 2}, {3, 4}, {7, 6},
       {13, 12}, {13, 19}, {14, 15}, {9, 16}, {9, 10}, {6, 1}, {12, 18},
       {16, 20}, {16, 17}, {10, 11}, {20, 21}, {11, 5}}.
       The diameter of the tree is 7.

10.3 · Rooted Trees
10.3.4 · Exercises

10.3.4.1. Answer. Locate any simple path of length d and locate the vertex
in position d/2 on the path. The tree rooted at that vertex will have a depth
of d/2, which is minimal.
10.3.4.3. Answer.

Figure F.0.18

10.4 · Binary Trees
10.4.6 · Exercises

10.4.6.1. Answer.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES530

Figure F.0.19

Figure F.0.20
10.4.6.3. Answer.

                                 Preorder Inorder Postorder
                         (a) ·a + bc a · b + c abc + ·
                         (b) + · abc a · b + c ab · c+
                         (c) + · ab · ac a · b + a · c ab · ac · +
10.4.6.5. Answer. There are 26 = 64 different possible answers to part (a).
The answer to (b) is unique.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES531

Figure F.0.21
10.4.6.7. Answer. Solution 1:

    Basis: A binary tree consisting of a single vertex, which is a leaf, satisfies
the equation leaves = internal vertices + 1

    Induction:Assume that for some k  1, all full binary trees with k or fewer
vertices have one more leaf than internal vertices. Now consider any full binary
tree with k + 1 vertices. Let TA and TB be the left and right subtrees of the
tree which, by the definition of a full binary tree, must both be full. If iA and
iB are the numbers of internal vertices in TA and TB, and jA and jB are the
numbers of leaves, then jA = iA + 1 and jB = iB + 1. Therefore, in the whole
tree,

              the number of leaves = jA + jB
                                          = (iA + 1) + (iB + 1)
                                          = (iA + iB + 1) + 1
                                          = (number of internal vertices) + 1

    Solution 2:
    Imagine building a full binary tree starting with a single vertex. By con-
tinuing to add leaves in pairs so that the tree stays full, we can build any full
binary tree. Our starting tree satisfies the condition that the number of leaves
is one more than the number of internal vertices . By adding a pair of leaves to
a full binary tree, an old leaf becomes an internal vertex, increasing the num-
ber of internal vertices by one. Although we lose a leaf, the two added leaves
create a net increase of one leaf. Therefore, the desired equality is maintained.
10.4.6.8. Solution.
  (a) The root of B is the root of the corresponding ordered rooted tree, which

       as no siblings.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES532

(b) Figure F.0.22

(c) Figure F.0.23

(d) The number of ordered rooted trees with n vertices is equal to the number

of binary trees with n - 1 vertices,  1  2(n-1)
                                      n    n-1

11 · Algebraic Structures
11.1 · Operations
11.1.4 · Exercises

11.1.4.1. Answer.

(a) Commutative, and associative. Notice that zero is the identity for addi-
     tion, but it is not a positive integer.

(b) Commutative, associative, and has an identity (1)

(c) Commutative, associative, has an identity (1), and is idempotent

(d) Commutative, associative, and idempotent

  (e) None. Notice that 2@(3@3) = 134217728, while (2@3)@3 = 512; and
       a@1 = a, while 1@a = 1.

11.1.4.3. Answer.

a, b  A  B  a, b  A by the definition of intersection
                 a  b  A by the closure of A with respect to 

Similarly, a, b  A  B  a  b  B. Therefore, a  b  A  B. The set of
positive integers is closed under addition, and so is the set of negative integers,
but 1 + -1 = 0. Therefore, their union, the nonzero integers, is not closed
under addition.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES533

11.1.4.5. Answer.

(a)  is commutative since |a - b| = |b - a| for all a, b  N

(b)  is not associative. Take a = 1, b = 2, and c = 3, then (a  b)  c =
     ||1 - 2| - 3| = 2 , and a  (b  c) = |1 - |2 - 3|| = 0.

(c) Zero is the identity for  on N, since a  0 = |a - 0| = a = |0 - a| = 0  a.
(d) Each element of N inverts itself since a  a = |a - a| = 0.
(e)  is not idempotent, since, for a = 0, a  a = 0 = a.

11.2 · Algebraic Systems
11.2.4 · Exercises

11.2.4.1. Answer. The terms "generic" and "trade" for prescription drugs
are analogous to "generic" and "concrete" algebraic systems. Generic aspirin,
for example, has no name, whereas Bayer, Tylenol, Bufferin, and Anacin are all
trade or specific types of aspirins. The same can be said of a generic group [G; ]
where G is a nonempty set and  is a binary operation on G, When examples of
typical domain elements can be given along with descriptions of how operations
act on them, such as Q or M2×2(R), then the system is concrete (has a
specific name, as with the aspirin). Generic is a way to describe a general
algebraic system, whereas a concrete system has a name or symbols making it
distinguishable from other systems.

11.2.4.3. Answer. The systems in parts b, d, e, and f are groups.

11.2.4.5. Answer.

(a) Elements are I =      10   , and T =  0 1 , the group is abelian.
     Operation table is   01              10
                         ·I   T
                         II   T
                         TT   I

(b)

                              I R1 R2 F1 F2 F3

                         I    I R1 R2 F1 F2 F3

                         R1 R1 R2 I F2 F3 F1

                         R2 R2 I R1 F3 F1 F2

                         F1  F1 F3 F2 I R2 R1

                         F2  F2 F1 F3 R1 I R2

                         F3  F3 F2 F1 R2 R1 I

     This group is non-abelian since, for example, F1F2 = R2 and F2F1 = R1.

(c) 4! = 24, n!.

11.2.4.7. Answer. The identity is e. a  b = c, a  c = b, b  c = a, and [V ; ]
is abelian. (This group is commonly called the Klein-4 group.)

11.3 · Some General Properties of Groups
11.3.3 · Exercises

11.3.3.1. Answer.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES534

(a) f is injective:
                         f (x) = f (y)  a  x = a  y .
                                           x = y by left cancellation

        f is surjective: For all b  G, f (x) = b has the solution a-1  b.

  (b) Functions of the form f (x) = a + x, where a is any integer, are bijections

11.3.3.3. Answer. Basis: (n = 2) (a1  a2)-1 = a2-1  a1-1 by Theo-
rem 11.3.7.

    Induction: Assume that for some n  2,

                       (a1  a2  · · ·  an)-1 = an-1  · · ·  a2-1  a1-1

We must show that

              (a1  a2  · · ·  an  an+1)-1 = an+1 -1  an-1  · · ·  a2-1  a1-1

    This can be accomplished as follows:

(a1  a2  · · ·  an  an+1)-1 = ((a1  a2  · · ·  an)  an+1)-1 by the associative law
                                     = an+1 -1  (a1  a2  · · ·  an)-1 by the basis
                                     = an+1 -1  an-1  · · ·  a2-1  a1-1 by the induction hypothesis
                                     = an+1 -1  an-1  · · ·  a2-1  a1-1 by the associative law

11.3.3.5. Answer. In this answer, we will refer to Lemma 11.3.13 simply as
"the lemma."

  (a) Let p(n) be a-n = a-1 n, where a is any element of group [G; ]. First
       we will prove that p(n) is true for all n  0.
        Basis: If n = 0, Using the definition of the zero exponent, a0 -1 =
        e-1 = e, while a-1 0 = e. Therefore, p(0) is true.
        Induction: Assume that for some n  0, p(n) is true.

                  an+1 -1 = (an  a)-1 by the definition of exponentiation
                              = a-1  (an)-1 by the lemma
                              = a-1  a-1 n by the induction hypothesis
                              = a-1 n+1 by the lemma

If n is negative, then -n is positive and

a-n =  a-1 -1 -n

= a-1 -(-n) since the property is true for positive numbers
= a-1 n

(b) For m > 1, let p(m) be an+m = an  am for all n  1. The basis for this
     proof follows directly from the basis for the definition of exponentiation.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES535

       Induction: Assume that for some m > 1, p(m) is true. Then

               an+(m+1) = a(n+m)+1 by the associativity of integer addition
                            = an+m  a1 by the definition of exponentiation
                            = (an  am)  a1 by the induction hypothesis
                            = an  am  a1 by associativity
                            = an  am+1 by the definition of exponentiation

       To complete the proof, you need to consider the cases where m and/or n
       are negative.

  (c) Let p(m)be (an)m = anm for all integers n.
       Basis: (am)0 = e and am·0 = a0 = e therefore, p(0) is true.
       Induction; Assume that p(m) is true for some m >0,

                 (an)m+1 = (an)m  an by the definition of exponentiation
                             = anm  an by the induction hypothesis
                             = anm+n by part (b) of this proof
                             = an(m+1)

       Finally, if m is negative, we can verify that (an)m = anm using many of
       the same steps as the positive case.

11.4 · Greatest Common Divisors and the Inte-
gers Modulo n
11.4.2 · The Euclidean Algorithm

Investigation 11.1 Solution. If quotient in division is 1, then we get the
slowest possible completion. If a = b + r, then working backwards, each re-
mainder would be the sum of the two previous remainders. This described a
sequence like the Fibonacci sequence and indeed, the greatest common divisor
of two consecutive Fibonacci numbers will take the most steps to reach a final
value of 1.

11.4.6 · Exercises

11.4.6.1. Answer.

  (a) 22 · 3 · 5

  (b) 32 · 5 · 7

  (c) 194

  (d) 12112

11.4.6.3. Answer.

(a) 2              (d) 0  (g) 1
                          (h) 3
(b) 5              (e) 2  (i) 0

(c) 0              (f) 2

11.4.6.5. Answer.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES536

(a) 1                 (c) m(4) = r(4), where m = 11q + r,
(b) 1                      0  r < 11

11.4.6.7. Answer. Since the solutions, if they exist, must come from Z2,
substitution is the easiest approach.

(a) 1 is the only solution, since 12 +2 1 = 0 and 02 +2 1 = 1

  (b) No solutions, since 02 +2 0 +2 1 = 1, and 12 +2 1 +2 1 = 1
11.4.6.9. Solution.

(a) The operation table can be created with SageMath:

       def U_table(n):
              if n.parent()!=2.parent() or n < 2 or n > 64:
                     return "input error/out of range"
              R=Integers(n)
              els =[]
              for k in filter(lambda k:gcd(n,k)==1,range(n)):
                     els = els +[ str (k)]
              return
                    R.multiplication_table(elements=els ,names="elements")

       U_table (14)

   * 1 3 5 9 11 13
     +------------------

    1| 1 3 5 9 11 13
    3| 3 9 1 13 5 11
    5| 5 1 11 3 13 9
    9| 9 13 3 11 1 5
  11| 11 5 13 1 9 3
  13| 13 11 9 5 3 1

We know that multiplication mod 14 is associative, 1 is the identity and
from the table we see that each element has an inverse in this system.

(b) We know that multiplication mod n is associative, 1 is the identity and
     we are assuming that all element are invertible. In the next part we see
     that the invertable elements are exactly the set Un.

(c) Let a be an element of Zn such that gcd(n, a) = 1. By Theorem 11.4.9
     there exist integers s and t such that ns+at = 1. By the division property,
     we can divide n into t to get t = nq + r where r  Zn.

       ns + at = 1  ar = n(-(aq + s)) + 1  a ×n r = 1

       Therefore, a has an inverse, and that inverse is in Un.

11.4.6.10. Hint. Prove by induction on m that you can divide any positive
integer into m. That is, let p(m) be "For all n greater than zero, there exist
unique integers q and r such that . . . ." In the induction step, divide n into
m - n.

11.4.6.11. Solution.  The given conditions can be converted to a system of
linear equations:
                        f (1) = 11  a +17 b = 11
                      f (2) = 4  2 ×17 a +17 b = 4

If we subtract the first equation from the second, we get a = 4 +17 (-11) =
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES537

4 +17 6 = 10. This implies that b = 1, and f (i) = 10 × +17i + 1. To get a
formula for the inverse of f we solve f (j) = i for j, using the fact that the
multiplicative inverse of 10 (mod 17) is 12.

                              f (j) = i  10 × +17j + 1 = i
                                          10 × +17j = i +17 16
                                          j = 12 ×17 (i +17 16)

Therefore f -1(i) = 12 ×17 (i +17 16) = 12 ×17 i +17 5.
11.4.6.13. Solution. By Bézout's lemma, 450 is an element of U2021. It's
inverse in the group is 759 because

                 450 · 759 = 2021 · 169 + 1  450 ×2021 759 = 1.
11.4.6.15. Solution. There will always to two solutions, 1 and n - 1. We
can prove this as follows:

                             x2 = 1  x1 - 1 p 0
                                       p | (x2 - 1)
                                       p | (x - 1)(x + 1)
                                       p | (x - 1) or p | (x + 1)
                                       x p 1 or x p -1
                                       x = 1 or x = p - 1

The fourth step applies a theorem that follows from Bézout's lemma that states
that if a prime divides evenly into a product, then it must divide into one of
the factors.

11.5 · Subsystems
11.5.5 · Exercises

11.5.5.1. Answer. Only a and c are subgroups.

11.5.5.3. Answer. {I, R1, R2}, {I, F1}, {I, F2}, and {I, F3} are all the
proper subgroups of R3.
11.5.5.5. Answer.

  (a) 1 = 5 = Z6, 2 = 4 = {2, 4, 0}, 3 = {3, 0}, 0 = {0}

  (b) 1 = 5 = 7 = 11 = Z12, 2 = 10 = {2, 4, 6, 8, 10, 0}, 3 = 9 =
       {3, 6, 9, 0}, 4 = 8 = {4, 8, 0}, 6 = {6, 0}, 0 = {0}

  (c) 1 = 3 = 5 = 7 = Z8, 2 = 6 = {2, 4, 6, 0}, 4 = {4, 0},
       0 = {0}

  (d) Based on the ordering diagrams for parts a through c in Figure F.0.24,
       we would expect to see an ordering diagram similar to the one for divides
       on {1, 2, 3, 4, 6, 8, 12, 24} (the divisors of 24) if we were to examine the
       subgroups of Z24. This is indeed the case.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES538

Figure F.0.24 Figure for exercise 5

11.5.5.7. Hint. Use an indirect argument.

Answer. Assume that H and K are subgroups of group G, and that, as in
Figure 11.5.12, there are elements x  H - K and y  K - H. Consider the
product x  y. Where could it be placed in the Venn diagram? If we can prove
that it must lie in the outer region, Hc  Kc = (H  K)c, then we have proven
that H  K is not closed under  and cannot be a subgroup of G, Assume that
x  y  H. Since x is in H, x-1 is in H and so by closure x-1  (x  y) = y  H
which is a contradiction. Similarly, x  y / K.

    One way to interpret this theorem is that no group is the union of two
groups.

11.6 · Direct Products
11.6.3 · Exercises

11.6.3.1. Answer. Table of Z2 × Z3:

  +     (0, 0)  (0, 1)  (0, 2)  (1, 0)  (1, 1)  (1, 2)
(0, 0)  (0, 0)  (0, 1)  (0, 2)  (1, 0)  (1, 1)  (1, 2)
(0, 1)  (0, 1)  (0, 2)  (0, 0)  (1, 1)  (1, 2)  (1, 0)
(0, 2)  (0, 2)  (0, 0)  (0, 1)  (1, 2)  (1, 0)  (1, 1)
(1, 0)  (1, 0)  (1, 1)  (1, 2)  (0, 0)  (0, 1)  (0, 2)
(1, 1)  (1, 1)  (1, 2)  (1, 0)  (0, 1)  (0, 2)  (0, 0)
(1, 2)  (1, 2)  (1, 0)  (1, 1)  (0, 2)  (0, 0)  (0, 1)

The only two proper subgroups are {(0, 0), (1, 0)} and {(0, 0), (0, 1), (0, 2)}
11.6.3.3. Algebraic properties of the n-cube.
Answer.

  (a) (i) a + b could be (1, 0) or (0, 1). (ii) a + b = (1, 1).
  (b) (i) a + b could be(1, 0, 0), (0, 1, 0), or (0, 0, 1). (ii) a + b = (1, 1, 1).
  (c) (i) a + b has exactly one 1. (ii) a + b has all 1s.
11.6.3.5. Answer.
  (a) No, 0 is not an element of Z × Z.
  (b) Yes.
  (c) No, (0, 0) is not an element of this set.
  (d) No, the set is not closed: (1, 1) + (2, 4) = (3, 5) and (3, 5) is not in the

       set.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES539

  (e) Yes.

11.7 · Isomorphisms
11.7.4 · Exercises

11.7.4.1. Answer.

(a) Yes, f (n, x) = (x, n) for (n, x)  Z × R is an isomorphism.
(b) No, Z2 × Z has a two element subgroup while Z × Z does not.
(c) No. Q × Q is countable and R is not. Therefore, no bijection can exist

     between them.

(d) Yes.

(e) No.

(f) Yes, one isomorphism is defined by f (a1, a2, a3, a4) =  a1 a2 .
                                                             a3 a4

(g) Yes, one isomorphism is defined by f (a1, a2) = (a1, 10a2 ).

(h) Yes.

  (i) Yes f (k) = k(1, 1).

11.7.4.3. Answer. Consider three groups G1, G2, and G3 with operations
, , and , respectively. We want to show that if G1 is isomorphic to G2, and
if G2 is isomorphic to G3 , then G1 is isomorphic to G3.

G1 isomorphic to G2  there exists an isomorphism f : G1  G2

       G2 isomorphic to G3  there exists an isomorphism g : G2  G3

If we compose g with f , we get the function g  f : G1  G3, By Theorem 7.3.6
and Theorem 7.3.7, g  f is a bijection, and if a, b  G1,

(g  f )(a  b) = g(f (a  b))
                 = g(f (a)  f (b)) since f is an isomorphism
                 = g(f (a))  g(f (b)) since g is an isomorphism
                 = (g  f )(a)  (g  f )(b)

Therefore, g f is an isomorphism from G1 into G3, proving that "is isomorphic
to" is transitive.

11.7.4.5. Answer. By Theorem 11.7.14(a), T (0) must be 1. T (2) = T (1 +4
1) = T (1) ×5 T (1) = 3 ×5 3 = 4. Since T is a bijection, T (3) = 2.

11.7.4.7. Answer. Let G be an infinite cyclic group generated by a. Then,
using multiplicative notation, G = { an| n  Z}. The map T : G  Z defined
by T (an) = n is an isomorphism. This is indeed a function, since an = am
implies n = m. Otherwise, a would have a finite order and would not generate
G.

(a) T is one-to-one, since T (an) = T (am) implies n = m, so an = am.
(b) T is onto, since for any n  Z, T (an) = n.
(c) T (an  am) = T an+m = n + m = T (an) + T (am)
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES540

11.7.4.11. Answer. Z8, Z2 × Z4 , and Z32. One other is the fourth dihedral
group, introduced in Section 15.3.

11.7.4.13. Answer. Each 3 is the order of an element whose inverse is it's
square; i. e., if a has order 3, a2 = a-1 is distinct from a and also has order 3
and contributes a second matching 3.

12 · More Matrix Algebra
12.1 · Systems of Linear Equations
12.1.7 · Exercises

12.1.7.1. Answer.

(a) {(4/3, 1/3)}

(b) {( 1 x3 - 3, -4x3 + 11, x3) | x3  R}
        2

(c) {(-5, 14/5, 8/5)}

  (d) {(6.25 - 2.5x3, -0.75 + 0.5x3, x3) | x3  R}
12.1.7.3. Answer.

(a) Basic variables: x1, x2 and x4. Free variable: x3. Solution set: {(1.2 +
     5x3, 2.6 - 4x3, 4.5) | x3  R}

(b) Basic variables: x1 and x2. Free variable: x3. The solution set is empty
     because the last row of the matrix converts to the inconsistent equation
     0 = 1.

  (c) Basic variables: x1 and x2. Free variable: x3.      Solution set:
       {(-6x3 + 5, 2x3 + 1, x3) | x3  R}                  Solution set:

  (d) Basic variables: x1, x2 and x3. Free variable: x4.
       {(3x4 + 1, -2x4 + 2, x4 + 1, x4) | x4  R}

12.1.7.5. Answer.

(a) {(3, 0)}

(b) {(3, 0, 4)}

12.1.7.7. Answer. Proof: Since b is the n × 1 matrix of 0{'}s, let's call it 0.
Let S be the set of solutions to AX = 0. If X1 and X2 be in S. Then

                    A (X1 + X2) = AX1 + AX2 = 0 + 0 = 0

so X1 + X2  S; or in other words, S is closed under addition in Rn.
    The identity of Rn is 0, which is in S. Finally, let X be inS. Then

                         A(-X) = -(AX) = -0 = 0

and so -X is also in S.

12.2 · Matrix Inversion
12.2.3 · Exercises

12.2.3.3. Answer.

15 30

(a) 11 11
311 - 11         5
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES541

      -20 221 29 - 23 
(b)  2  -1 0                  
                           0  

       -4 2 1 0               

       7 - 72 - 3 1 2 2

(c) The inverse does not exist. When the augmented matrix is row-reduced

     (see below), the last row of the first half cannot be manipulated to match

     the identity matrix.

       1 00    

(d)  -3 1 1 

       -4 1 2

(e) The inverse does not exist.

       9 -36 30               

(f)  -36 192 -180 

       30 -180 180

12.2.3.5. Answer. The solutions are in the solution section of Section 12.1,
exercise 1, We illustrate with the outline of the solution to part (c). The matrix
version of the system is

                     11 2           
                                     x1          1

                    1 2 -1   x2  =  -1 

                     13 1            x3          5

We compute the inverse of the matrix of coefficients and get

                     11 2        -1           5 5 -5          

       A-1 =  1 2 -1  = 1  -2 -1 3 
                                         5 1 -2 1
                     13 1

and                                   

                     x1              1        -5

                    x2  = A-1  -1  =  145 
                                     5 85
                     x3

12.3 · An Introduction to Vector Spaces
12.3.3 · Exercises

12.3.3.3. Answer. The dimension of M2×3(R) is 6 and yes, Mm×n(R) is
also a vector space of dimension m · n. One basis for Mm×n(R) is {Aij | 1 
i  m, 1  j  n} where Aij is the m × n matrix with entries all equal to zero
except for in row i, column j where the entry is 1.

12.3.3.7. Answer. If the matrices are named B, A1, A2 , A3, and A4 , then

                   B = 8 A1 + 5 A2 + -5 A3 + 23 A4
                           3     3       3    3

12.3.3.9. Answer.

(a) If x1 = (1, 0), x2 = (0, 1), and y = (b1, b2), then y = b1x1 + b2x2. If
     x1 = (3, 2), x2 = (2, 1), and y = (b1, b2), then y = (-b1 + 2b2) x1 +
     (2b1 - 3b2) x2.

(b) If y = (b1, b2) is any vector in R2 , then y = (-3b1 + 4b2) x1 +
     (-b1 + b2) x2 + (0)x3
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES542

(c) One solution is to add any vector(s) to x1, x2, and x3 of part b.
(d) 2, n

(e) x y = xA1 + yA2 + zA3 + wA4
         zw

  (f) a0 + a1x + a2x2 + a3x3 = a0(1) + a1(x) + a2 x2 + a3 x3 .
12.3.3.11. Answer.

(a) The set is linearly independent: let a and b be scalars such that a(4, 1) +

     b(1, 3) = (0, 0), then 4a + b = 0 and a + 3b = 0 which has a = b = 0 as

     its only solutions. The set generates all of R2: let (a, b) be an arbitrary
     vector in R2 . We want to show that we can always find scalars 1 and 2
     such that 1(4, 1) + 2(1, 3) = (a, b). This is equivalent to finding scalars
     such that 41 + 2 = a and 1 + 32 = b. This system has a unique
     solution 1 = 11 3a-b , and 2 = 11 4b-a . Therefore, the set generates R2.

12.3.3.13. Answer. The answer to the last part is that the three vector

spaces are all isomorphic to one another. Once you have completed part (a) of

this exercise, the following translation rules will give you the answer to parts

(b) and (c),

              (a, b, c, d)   ab   a + bx + cx2 + dx2
                             cd

12.4 · The Diagonalization Process
12.4.4 · Exercises

12.4.4.1. Answer.

(a) Any nonzero multiple of 1 is an eigenvector associated with  = 1.
                                         -1

(b) Any nonzero multiple of 1 is an eigenvector associated with  = 4.
                                          2

(c) Let x1 = a and x2 = b . You can verify that c1x1 +
                -a               2b

c2x2 = 0           if and only if c1 = c2 = 0. Therefore, {x1, x2} is linearly
             0

independent.

12.4.4.3. Answer. Part c: You should obtain 4 0 or 1 0 , de-
                                           01                   04

pending on how you order the eigenvalues.

12.4.4.5. Answer.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES543

                 2 1 , then                            -2 0 0  
                 3 -1
(a) If P =     40 .                          P -1AP =  0 1 0 .
     P -1AP =  0 -1
                                                       0 00

(b) If P =                1 1 , then      (e) A is not diagonalizable. Five is a
                          71                   double root of the characteristic
                                               equation, but has an eigenspace
P -1AP =       50 .                            with dimension only 1.
               0 -1

(c) If P =                1 0 , then                           
                          01                        1  11
     P -1AP = 3
                       0  0.              (f) If P =  -2 0 1 , then
                          4
                                               1 -1 1       
                     1             
                          -1 1                         300
(d) If P =  -1             4 2 , then
                                             P -1AP =  0 1 0 .

               -1 1 1                                  000

12.4.4.7. Answer. This is a direct application of the definition of matrix
multiplication. Let A(i) be the ith row of A, and let P (j) be the jth column of
P . Then the jth column of the product AP is

                                 A(1)P (j) 
                                 A(2)P (j) 
                                             
                                .
                                 .. 

                                  A(n)P (j)

    Hence, (AP )(j) = A P (j) for j = 1, 2, . . . , n. Thus, each column of AP
depends on A and the j th column of P .

12.5 · Some Applications
12.5.5 · Exercises

12.5.5.4. Hint. The characteristic polynomial of the adjacency matrix is
4 - 42.

12.5.5.5. Answer.

                            110   

(a) Since A = A1 =  1 0 1 , there are 0 paths of length 1 from: node

                          011
c to node a, node b to node b, and node a to node c; and there is 1 path
of length 1 for every other pair of nodes.

                                                                1-c 1 0
(b) The characteristic polynomial is |A- cI| = 1 -c 1 = -c3 +

                                                                   0 1 1-c
     2c2 + c - 2

Solving the characteristic equation -c3 + 2c2 + c - 2 = 0 we find solutions
1, 2, and -1.

If c= 1, we find theassociated eigenvector by finding a nonzero solution
010                         x1         0

to  1 -1 1   x2  =  0  One of these, which will be the

010                         x3         0
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES544

                           
                                1

first column of P , is  0 

                               -1          
                                     0  x1                                   0

                               -1 1  1   x2  =  0  yields eigen-

If c = 2, the system  1 -2

                           0 1 -1       x3                                   0
                   
                       1

vectors, including  1 , which will be the second column of P .

                       1

If c = -1, then the system determining the eigenvectors is
210                x1           0                                               1

 1 1 1   x2  =  0  and we can select  -2 , although

012                x3           0                                               1

any nonzero multiple of this vector could be the third column of P .

                                                                                         
                                                                          1     11
                                                                                1 -2  .
(c) Assembling the results of part (b) we have P =  0

                                                   -1 1 1

                     14 0                                                          
          A4 = P  0 24          0           10                                  0
                                                                                0  P -1
                                0  P -1 = P  0 16
                                                                                1
                   0 0 (-1)4                       00
           1 16 1 2   1 0 - 21 
          =  0 16 -2   1 1 3 3          1

                                        3
                                     61 - 3 6 1 1
                   -1 16 1
                           
                   655

          = 5 6 5 

                   556

Hence there are five different paths of length 4 between distinct vertices,
and six different paths that start and end at the same vertex. The reader
can verify these facts from Figure 12.5.4

12.5.5.7. Answer.

(a) eA =  ee       , eB =  00        , and eA+B =  e e2 - e
          00               0 e2                    0 e2

                             0          02 03
(b) Let 0 be the zero matrix, e = I + 0 + 2 + 6 + . . . = I .

(c) Assume that A and B commute. We will examine the first few terms
     in the product eAeB. The pattern that is established does continue in
     general. In what follows, it is important that AB = BA. For example, in
     the last step, (A+B)2 expands to A2 +AB +BA+B2, not A2 +2AB +B2,
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES545

if we can't assume commutativity.

eAeB =       Ak                 Bk
            k=0 k!             k=0 k!

                        A2 A3                          B2 B3
       = I +A+ 2 + 6 +···                   I +B + 2 + 6 +···

                               A2           B2 A3 A2B AB2 B3
       = I + A + B + 2 + AB + 2 + 6 + 2 + 2 + 6 + · · ·

       = I + (A + B) + 1 A2 + 2AB + B2 + 1 A3 + 3A2B + 3AB2 + B3                             +···
                               2                               6

       = I + (A + B) + 1 (A + B)2 + 1 (A + B)3 + · · ·
                               2            6

       = eA+B

(d) Since A and -A commute, we can apply part d;

                                     eAe-A = eA+(-A) = e0 = I

12.6 · Linear Equations over the Integers Mod
2
12.6.2 · Exercises

12.6.2.1. Answer.

(a) {(0, 0, 0), (1, 1, 1)}

(b) {(1, 1, 1, 0)}

12.6.2.2. Answer. As suggested here is the augmented matrix with both
right sides, and its row reduction:

        110111                              1 0 1 1 0 0

 1 0 1 1 0 0  -  0 1 1 0 1 0 

        011010                                 0 0 00 01

There are only two basic variables here because the left side of the last equation
is the sum of the left sides of the first two equations.

  (a) Ignoring the last column of both matrices, we see that the last equation
       of the first system reduces to 0 = 0, which is always true, and the first
       two equations yield two free variables, x3 and x4. The general solution
       is the set of quadruples {(x3 +2 x4, x3 +2 1, x3, x4) | x3, x4  Z2}. The
       cardinality of the solution set is 4.

  (b) If we replace the fifth column with the sixth one, the last row indicates
       that 0 = 1, which means that the solution set is empty.

12.6.2.3. Answer.

  (a) Row reduction produces a solution with one free variable, x3.

                            (x1, x2, x3, x4, x5) = (x3, x3, x3, 0, 0)
                                                    = x3(1, 1, 1, 0, 0)

The solution set has only two elements. It is {(0, 0, 0, 0, 0), (1, 1, 1, 0, 0)}.

Since  Z5   is      a  finite  group,  the  solution  set  is  a  subgroup  because  it  is

         2
closed with respect to coordinatewise mod 2 addition.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES546

(b) The row-reduced augmented matrix of coefficients provides the solution

                     (x1, x2, x3, x4, x5) = (x3, 1 + x3, x3, 1, 0)
                                             = (0, 1, 0, 1, 0) + x3(1, 1, 1, 0, 0)

        Therefore, the solution to this system is a shift of the solution
        set to the homogeneous system by the vector (0, 1, 0, 1, 0), which is
        {(0, 1, 0, 1, 0), (1, 0, 1, 1, 0)}

13 · Boolean Algebra
13.1 · Posets Revisited

· Exercises

 13.1.1. Answer.

(a) 1, 5                              (d) 30
(b) 5
(c) 30                                (e) See the Sage cell below with the
                                           default input displaying a Hasse
                                           diagram for D12.

Posets.DivisorLattice (12).show()

13.1.3. Answer.
   · Solution for Hasse diagram (b):

      

           a1 a2 a3 a4 a5              a1 a2 a3 a4 a5
          a1 a1 a2 a3 a4 a5           a1 a1 a1 a1 a1 a1
          a2 a2 a2 a4 a4 a5           a2 a1 a2 a1 a2 a2
          a3 a3 a4 a3 a4 a5           a3 a1 a1 a3 a3 a3
          a4 a4 a4 a4 a4 a5           a4 a1 a2 a3 a4 a4
          a5 a5 a5 a5 a5 a5           a5 a1 a2 a3 a4 a5

              a1 is the least element and a5 is the greatest element.
   · Partial solution for Hasse diagram (f):

            lub (a2, a3) and lub (a4, a5) do not exist.
            No greatest element exists, but a1 is the least element.
13.1.5. Answer. If 0 and 0 are distinct least elements, then

0  0      since 0 is a least element   0 = 0 by antisymmetry, a contradiction
0  0      since 0 is a least element

13.1.7. Answer.

(a) The sum of elements in A  B = {2, 3, 6} is odd and disqualifies the set
     from being an element of the poset.

(b) The following correctly complete the statements in this part.

(i) . . . A  R and B  R
(ii) . . . for all A  P0, R  A
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES547

(c) Any set that contains the union of AB = {1, 2, 3, 6, 7} but also contains
     3 or 5, but not both will be an upper bound. You can create several by
     including on not including 4 or 8.

   (d) The least upper bound doesn't exist. Notice that the union of A and
        B isn't in P0. One of the two sets {1, 2, 3, 5, 6, 7} and {1, 2, 3, 6, 7, 9} is
        contained within every upper bound of A and B but neither is contained
        within the other.

13.2 · Lattices

· Exercises

 13.2.5. Answer. One reasonable definition would be this: Let [L; , ] be
 a lattice and let K be a nonempty subset of L. Then K is a sublattice of L if
 and only if K is closed under both  and 

13.3 · Boolean Algebras

· Exercises

                       B            Complement of B

                                    A

                       {a}          {b, c}

                               {b}  {a, c}
13.3.1. Answer. {c}                 {a, b}

                       {a, b}       {c}

                       {a, c}       {b}

                       {b, c}       {a}

                       A            

This lattice is a Boolean algebra since it is a distributive complemented

lattice.

13.3.3. Answer. a and g.

13.3.5. Answer.

(a) S : a  b = a if a  b

(b) The dual of S : A  B = A if A  B is S : A  B = A if A  B

(c) Yes

(d) The dual of S : p  q  p if p  q is S : p  q  p if q  p

(e) Yes

13.3.7. Answer. [B; , , -] is isomorphic to [B; , ,~] if and only if there
exists a function T : B  B such that

(a) T is a bijection;

(b) T (a  b) = T (a)  T (b) for all a, b  B

(c) T (a  b) = T (a)  T (b) for all a, b  B

(d) T (a¯) = T (~a) for all a  B.

13.4 · Atoms of a Boolean Algebra

· Exercises
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES548

13.4.1. Answer.

(a) For a = 3 we must show that for each x  D30 one of the following is
     true: x  3 = 3 or x  3 = 1. We do this through the following table:

                 x verification

                 1          13=1

                 2          23=1

                 3          33=3

                 5          53=1

                 6          63=3

                 10 20  3 = 1

                 15 15  3 = 3

                 30 30  3 = 3

For a = 5, a similar verification can be performed.

(b) 6 = 2  3, 10 = 2  5, 15 = 3  5, and 30 = 2  3  5.

13.4.3.  Answer. If B = D30       30 then A = {2, 3, 5} and

                                  1                    5  {5}

D30 is isomorphic to P(A), where  2  {2}               10  {2, 5} and
                                  3  {3}               15  {3, 5}

                                  6  {2, 3} 30  {2, 3, 5}

            Join  Union
        Meet  Intersection
Complement  Set Complement

13.4.5. Hint. Assume that [B; , , -] is a Boolean algebra of order 3 where
B = {0, x, 1} and show that this cannot happen by investigating the possibili-
ties for its operation tables.

Answer. Assume that x = 0 or 1 is the third element of a Boolean algebra.
Then there is only one possible set of tables for join and meet, all following
from required properties of the Boolean algebra.

                  0x1              0x1
                 0 0x1            0 000
                 x xx1            x 0xx
                 1 111            1 0x1

Next, to find the complement of x we want y such that x  y = 0 and x  y = 1.
No element satisfies both conditions; hence the lattice is not complemented
and cannot be a Boolean algebra. The lack of a complement can also be seen
from the ordering diagram from which  and  must be derived.

13.4.7. Answer. Let X be any countably infinite set, such as the integers.
A subset of X is cofinite if it is finite or its complement is finite. The set of
all cofinite subsets of X is:

(a) Countably infinite - this might not be obvious, but here is a hint. Assume
     X = {x0, x1, x2, . . .}. For each finite subset A of X, map that set to the
     integer i=0  A (xi) 2i You can do a similar thing to sets that have a
     finite complement, but map them to negative integers. Only one minor
     adjustment needs to be made to accommodate both the empty set and
     X.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES549

(b) Closed under union

(c) Closed under intersection, and

(d) Closed under complementation.

Therefore, if B = {A  X : A is cofinite}, then B is a countable Boolean
algebra under the usual set operations.

13.4.8. Hint. "Copy" the corresponding proof for groups in Section 11.6.

13.5 · Finite Boolean Algebras as n-tuples of 0's
and 1's

· Exercises

 13.5.1. Answer.

(a)

      (0, 0) (0, 1) (1, 0) (1, 1)

     (0, 0) (0, 0) (0, 1) (1, 0) (1, 1)

     (0, 1) (0, 1) (0, 1) (1, 1) (1, 1)

     (1, 0) (1, 0) (1, 1) (1, 0) (1, 1)

     (1, 1) (1, 1) (1, 1) (1, 1) (1, 1)     _

      (0, 0) (0, 1) (1, 0) (1, 1)        u  u

     (0, 0) (0, 0) (0, 0) (0, 0) (0, 0) (0, 0) (1, 1)

     (0, 1) (0, 0) (0, 1) (0, 0) (0, 1) (0, 1) (1, 0)

     (1, 0) (0, 0) (0, 0) (1, 0) (1, 0) (1, 0) (0, 1)

     (1, 1) (0, 0) (0, 1) (1, 0) (1, 1) (1, 1) (0, 0)

   (b) The graphs are isomorphic.
   (c) (0, 1) and (1,0)
 13.5.3. Answer.
   (a) (1, 0, 0, 0), (0, 1, 0, 0), (0, 0, 1, 0), and (0, 0, 0, 1) are the atoms.
   (b) The n-tuples of bits with exactly one 1.

13.6 · Boolean Expressions

· Exercises

 13.6.1. Answer.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES550

         f1 (x1, x2) = 0
         f2 (x1, x2) = (x1  x2)
         f3 (x1, x2) = (x1  x2)
         f4 (x1, x2) = (x1  x2)
         f5 (x1, x2) = (x1  x2)
         f6 (x1, x2) = ((x1  x2)  (x1  x2)) = x1
         f7 (x1, x2) = ((x1  x2)  (x1  x2)) = x2
  (a) f8 (x1, x2) = ((x1  x2)  (x1  x2)) = ((x1  x2)  (x1  x2))
         f9 (x1, x2) = ((x1  x2)  (x1  x2)) = ((x1  x2)  (x1  x2))
         f10 (x1, x2) = ((x1  x2)  (x1  x2)) = x2
         f11 (x1, x2) = ((x1  x2)  (x1  x2)) = x1
         f12 (x1, x2) = ((x1  x2)  (x1  x2)  (x1  x2)) = (x1  x2)
         f13 (x1, x2) = ((x1  x2)  (x1  x2)  (x1  x2)) = (x1  x2)
         f14 (x1, x2) = ((x1  x2)  (x1  x2)  (x1  x2)) = (x1  x2)
         f15 (x1, x2) = ((x1  x2)  (x1  x2)  (x1  x2)) = (x1  x2)
         f16 (x1, x2) = ((x1  x2)  (x1  x2)  (x1  x2)  (x1  x2)) = 1

  (b) The truth table for the functions in part (a) are

                           x1 x2 f1 f2 f3 f4 f5 f6 f7 f8
                           0 0 01000111
                           0 1 00100100
                           1 0 00010010
                           1 1 00001001

                       x1 x2 f9 f10 f11 f12 f13 f14 f15 f16
                       0000 0 1 1 1 0 1
                       0111 0 1 1 0 1 1
                       1010 1 1 0 1 1 1
                       1101 1 0 1 1 1 1

  (c) (i) g1 (x1, x2) = f15 (x1, x2)
        (ii) g2 (x1, x2) = f12 (x1, x2)
       (iii) g3 (x1, x2) = f12 (x1, x2)
       (iv) g4 (x1, x2) = f16 (x1, x2)

13.6.3. Answer.

  (a) The number of elements in the domain of f is 16 = 42 = |B|2

  (b) With two variables, there are 43 = 256 different Boolean functions. With
       three variables, there are 48 = 65536 different Boolean functions.

  (c) f (x1, x2) = (1  x1  x2)  (1  x1  x2)  (1  x1  x2)  (0  x1  x2)

  (d) Consider f : B2  B, defined by f (0, 0) = 0, f (0, 1) = 1, f (1, 0) = a,
       f (1, 1) = a, and f (0, a) = b, with the images of all other pairs in B2 de-
       fined arbitrarily. This function is not a Boolean function. If we assume
       that it is Boolean function then f can be computed with a Boolean expres-
       sion M (x1, x2). This expression can be put into minterm normal form:
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES551

M (x1, x2) = (c1  x1  x2)(c2  x1  x2)(c3  x1  x2)(c4  x1  x2)

                       f (0, 0) = 0  M (0, 0) = 0  c1 = 0
                       f (0, 1) = 1  M (0, 0) = 1  c2 = 1
                       f (1, 0) = a  M (0, 0) = a  c3 = a
                       f (1, 1) = a  M (0, 0) = a  c4 = a

        Therefore, M (x1, x2) = (x1  x2)  (a  x1  x2)  (a  x1  x2) and so,
        using this formula, M (0, a) = (¯0  a)  (a  0  a¯)  (a  0  a) = a This
        contradicts f (0, a) = b, and so f is not a Boolean function.

13.7 · A Brief Introduction to Switching Theory
and Logic Design

· Exercises

 13.7.1. Answer.

(1) Associative, commutative, and idempotent laws.

(2) Distributive law.

(3) Idempotent and complement laws.

(4) Null and identity laws

(5) Distributive law.

(6) Null and identity laws.

13.7.2. Answer.

                       (x1 · x2) + (x1 · x2) + (x1 · x2).

13.7.3. Answer. A simpler boolean expression for the function is x2 · (x1 +
x3).

 Figure F.0.25 An even simpler circuit

14 · Monoids and Automata
14.1 · Monoids

· Exercises

 14.1.1. Answer.

   (a) S1 is not a submonoid since the identity of [Z8; ×8], which is 1, is not in
        S1. S2 is a submonoid since 1  S2 and S2 is closed under multiplication;
        that is, for all a, b  S2, a ×8 b is in S2.

   (b) The identity of NN is the identity function i : N  N defined by i(a) = a,
        a  N. If a  N, i(a) = a  a, thus the identity of NN is in S1. However,
        the image of 1 under any function in S2 is 2, and thus the identity of
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES552

NN is not in S2, so S2 is not a submonoid. The composition of any two
functions in S1, f and g, will be a function in S1:

     (f  g)(n) = f (g(n))  g(n) since f is in S1
                   n since g is in S1  f  g  S1

       and the two conditions of a submonoid are satisfied and S1 is a submonoid
       of NN.

  (c) The first set is a submonoid, but the second is not since the null set has
       a non-finite complement.

14.1.3. Answer. The set of n × n real matrices is a monoid under matrix
multiplication. This follows from the laws of matrix algebra in Chapter 5. To
prove that the set of stochastic matrices is a monoid over matrix multiplication,
we need only show that the identity matrix is stochastic (this is obvious) and
that the set of stochastic matrices is closed under matrix multiplication. Let
A and B be n × n stochastic matrices.

                                                                            n

                                      (AB)ij = aikbkj

                                                                          k=1

    The sum of the jth column is

n    n    n                                 n

     (AB)ij = a1kbkj + a1kbkj + · · · + ankbkj

j=1  k=1  k=1                               k=1

     n

     = (a1kbkj + a1kbkj + · · · + ankbkj )

     k=1

     n

     = bkj (a1k + a1k + · · · + ank)

     k=1

     n

     = bkj since A is stochastic

     k=1

     = 1 since B is stochastic

14.1.5. Answer. Let f, g, h  M , and a  B.

     ((f  g)  h)(a) = (f  g)(a)  h(a)
                         = (f (a)  g(a))  h(a)
                         = f (a)  (g(a)  h(a))
                         = f (a)  (g  h)(a)
                         = (f  (g  h))(a)

Therefore (f  g)  h = f  (g  h) and  is associative.
    The identity for  is the function u  M where u(a) = 1 = the "one" of

B. If a  B, (f  u)(a) = f (a)  u(a) = f (a)  1 = f (a). Therefore f  u = f .
Similarly, u  f = f .

    There are 22 = 4 functions in M for B = B2. These four functions are
 APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES553

 named in the text. See Figure 14.1.4. The table for  is

                                          z i tu
                                          z zzzz
                                          i z iz i
                                          t zzt t
                                          uzi tu

14.2 · Free Monoids and Languages

· Exercises

 14.2.1. Answer.
   (a) For a character set of 350 symbols, the number of bits needed for each
        character is the smallest n such that 2n is greater than or equal to 350.
        Since 29 = 512 > 350 > 28, 9 bits are needed,
   (b) 212 = 4096 > 3500 > 211; therefore, 12 bits are needed.

 14.2.3. Answer. This grammar defines the set of all strings over B for which
 each string is a palindrome (same string if read forward or backward).
 14.2.5. Answer.

   (a) Terminal symbols: The null string, 0, and 1. Nonterminal symbols: S,
        E. Starting symbol: S. Production rules: S  00S, S  01S, S  10S,
        S  11S, S  E, E  0, E  1 This is a regular grammar.

   (b) Terminal symbols: The null string, 0, and 1. Nonterminal symbols: S,
        A, B, C Starting symbol: S Production rules: S  0A, S  1A, S  
        , A  0B, A  1B, A  , B  0C, B  1C, B  A, C  0, C  1,
        C   This is a regular grammar.

   (c) See Exercise 3. This language is not regular.
 14.2.7. Answer. If s is in A and L is recursive, we can answer the question
"Is s in Lc?" by negating the answer to "Is s in L?"
 14.2.9. Answer.

   (a) List the elements of each set Xi in a sequence xi1, xi2, xi3 . . . . Then
        draw arrows as shown below and list the elements of the union in order
        established by this pattern: x11, x21, x12, x13, x22, x31, x41, x32, x23,
        x14, x15 . . .,

   (b) Each of the sets A1 , A2 , A3, . . ., are countable and A is the union of
        these sets; hence A is countable.

 Figure F.0.26 Exercise 9
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES554

14.3 · Automata, Finite-State Machines

· Exercises

 14.3.1. Answer.

            x                   s      Z(x, s)   t(x, s)
      Deposit25 c            Locked    Nothing   Select
      Deposit25 c            Select  Return25 c  Select
                             Locked    Nothing   Locked
         PressS              Select  DispenseS   Locked
         PressS              Locked    Nothing   Locked
         PressP              Select  DispenseP   Locked
         PressP              Locked    Nothing   Locked
         PressB              Select  DispenseB   Locked
         PressB

Figure F.0.27 Vending Machine Transitions
14.3.3. Answer. {000, 011, 101, 110, 111}
14.3.5. Answer.

(a) · Input: 10110, Output: 11011  10110 is in position 27
        · Input: 00100, Output: 00111  00100 is in position 7
        · Input:11111, Output: 10101  11111 is in position 21

(b) Let x = x1x2 . . . xn and recall that for n  1, Gn+1 = r 0Gn , where
                                                          1Gn
Gr    is the reverse of Gn.  To prove that the Gray Code Decoder always

   n

works, let p(n) be the proposition "Starting in Copy state, x's output is

the position of x in Gn; and starting in Complement state, x's output

is the position of x in Grn." That p(1) is true is easy to verify for both

possible values of x, 0 and 1. Now assume that for some n  1, p(n) is

true and consider x = x1x2 . . . xnxn+1.

If x1 = 0, x's output is a zero followed by the output for (x2 . . . xnxn+1)
starting in Copy state. By the induction hypothesis, this is zero followed
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES555

     by the position of (x2 . . . xnxn+1) in Gn, which is the position of x in
     Gn+1, by the definition of G.

     If x1 = 1, x's output is a one followed by the output for (x2 . . . xnxn+1)
     starting in Complement state. By the induction hypothesis, this is one
     followed by the position of (x2 . . . xnxn+1) in Grn, which is the position
     of x in Gn+1, by the definition of G. 

14.4 · The Monoid of a Finite-State Machine

· Exercises

 14.4.1. Hint. Where the output echoes the current state, the output can be
 ignored.

 Answer.

     Input String a       b         c aa ab ac

(a) 1 (a, 1) (a, 2) (c, 3) (a, 1) (a, 2) (c, 3)
     2  (a, 2) (a, 1) (c, 3) (a, 2) (a, 1) (c, 3)

     3  (c, 3) (c, 3) (c, 3) (c, 3) (c, 3) (c, 3)

     Input String ba bb bc ca cb cc

     1  (a, 2) (a, 1) (c, 3) (c, 3) (c, 3) (c, 3)

     2  (a, 1) (a, 2) (c, 3) (c, 3) (c, 3) (c, 3)

     3  (c, 3) (c, 3) (c, 3) (c, 3) (c, 3) (c, 3)

     We can see that TaTa = T aa = Ta, TaTb = T ab = Tb, etc. Therefore, we
     have the following monoid:

                                    Ta Tb Tb

                          Ta Ta Tb Tc

                          Tb        Tb Ta Tc

                          Tc        Tc Tc Tc

     Notice that Ta is the identity of this monoid.

     Input String 1 2 11 12 21 22

     A  CB A DD A

(b)  B  DAB C C B

     C  ADC B B C

     D  BCD A AD

     Input String 111 112 121 122 211 212 221 222

     A  CBBCBCCB

     B  D A AD ADD A

     C  BCCBCBBC

     D  BCCBCBBC

     We have the following monoid:

                                    T1 T2 T11 T12

                     T1       T11 T12 T1 T2

                     T2       Tb T11 T2 T1

                     T11      T1 T2 T11 T12

                     T12      T2 T1 T12 T11

     Notice that T11 is the identity of this monoid.
 APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES556
 14.4.3. Answer. Yes, just consider the unit time delay machine of Fig-
 ure 14.4.4. Its monoid is described by the table at the end of Section 14.4
 where the T row and T column are omitted. Next consider the machine in
 Figure 14.5.7. The monoid of this machine is:

                                T T0 T1 T00 T01 T10 T11
                         T T T0 T1 T00 T01 T10 T11
                         T0 T0 T00 T01 T00 T01 T10 T11
                         T1 T1 T10 T11 T00 T01 T10 T11
                        T00 T00 T00 T01 T00 T01 T10 T11
                        T01 T01 T10 T11 T00 T01 T10 T11
                        T10 T10 T00 T01 T00 T01 T10 T11
                        T11 T11 T10 T11 T00 T01 T10 T11
     Hence both of these machines have the same monoid, however, their transi-
 tion diagrams are nonisomorphic since the first has two vertices and the second
 has seven.

14.5 · The Machine of a Monoid

· Exercises

 14.5.1. Answer.

 Figure F.0.28 (a)
 APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES557

 Figure F.0.29 (b)

15 · Group Theory and Applications
15.1 · Cyclic Groups

· Exercises

 15.1.1. Answer. The only other generator is -1.
 15.1.3. Answer. If |G| = m, m > 2, and G = a, then a, a2, . . ., am-1
 , am = e are distinct elements of G. Furthermore, a-1 = am-1 = a, If
 1  k  m, a-1 generates ak:

                                   a-1 m-k = am-1 m-k
                                               = am2-m-mk+k
                                               = (am)m-k-1  ak
                                               = e  ak = ak

     Similarly, if G is infinite and G = a, then a-1 generates G.
 15.1.5. Answer.

   (a) No. Assume that q  Q generates Q. Then q = {nq : n  Z}. But this
        gives us at most integer multiples of q, not every element in Q.

   (b) No. Similar reasoning to part a.
   (c) Yes. 6 is a generator of 6Z.
   (d) No.
   (e) Yes, (1, 1, 1) is a generator of the group.
 15.1.7. Answer. Theorem 15.1.13 implies that a generates Zn if and only
 if the greatest common divisor of n and a is 1. Therefore the list of generators
 of Zn are the integers in Zn that are relatively prime to n. The generators of
 Z25 are all of the nonzero elements except 5, 10, 15, and 20. The generators of
 Z256 are the odd integers in Z256 since 256 is 28.
 15.1.9. Answer.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES558

(a)  : Z77  Z7 × Z11 maps the given integers as follows:

21                                (0, 10)

5                                      (5, 5)

7                                      (0, 7)

15                                     (1, 4)

sum = 48  (6, 4) = sum

The final sum, 48, is obtained by using the facts that -1(1, 0) = 22 and
-1(0, 1) = 56

-1(6, 4) = 6 ×77 -1(1, 0) + 4 ×77 -1(0, 1)
                                                          = 6 ×77 22 +77 4 ×77 56.
                                                          = 55 +77 70
                                                          = 48

(b) Using the same isomorphism:

25                                   (4, 3)
26                                   (5, 4)
40                                   (5, 7)
                                 sum = (0, 3)

theta-1(0, 3) = 3 ×77 -1(0, 1)

                                 = 3 ×77 56    .

                                 = 14

        The actual sum is 91. Our result is incorrect, since 91 is not in Z77.
        Notice that 91 and 14 differ by 77. Any error that we get using this
        technique will be a multiple of 77.

15.2 · Cosets and Factor Groups

· Exercises

 15.2.1. Answer. An example of a valid correct answer: Call the subsets A
 and B respectively. If we choose 0  A and 5  B we get 0 +10 5 = 5  B.
 On the other hand, if we choose 3  A and 8  B, we get 3 +10 8 = 1  A.
 Therefore, the induced operation is not well defined on {A, B}.

 15.2.3. Answer.

   (a) The four distinct cosets in G/H are H = {(0, 0), (2, 0)}, (1, 0) + H =
        {(1, 0), (3, 0)}, (0, 1)+H = {(0, 1), (2, 1)}, and (1, 1)+H = {(1, 1), (3, 1)}.
        None of these cosets generates G/H; therefore G/H is not cyclic. Hence
        G/H must be isomorphic to Z2 × Z2.

   (b) The factor group is isomorphic to [R; +]. Each coset of R is a line in
        the complex plane that is parallel to the x-axis:  : C/R  R, where
        T ({a + bi | a  R}) = b is an isomorphism.

   (c) 8 = {0, 4, 8, 12, 16} |Z20/8| = 4. The four cosets are: ¯0, ¯1, ¯2, and
        ¯3. 1 generates all four cosets. The factor group is isomorphic to [Z4; +4]
        because ¯1 is a generator.
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES559

15.2.5. Answer.

                      a  H = b  H  a  bH
                                          a = b  h for some h  H
                                          b-1  a = h for some h  H
                                          b-1  a  H

15.3 · Permutation Groups
15.3.5 · Exercises

15.3.5.1. Answer.

(a) 1 2 3 4                            (e) 1 2 3 4
         1432                                  4213

(b) 1 2 3 4                            (f) 1 2 3 4
         4312                                  3142

(c) 1 2 3 4
         3421

(d) 1 2 3 4                            (g) 1 2 3 4
         3421                                   2143

15.3.5.3. Answer. S3/A3 is a group of order two. The operation on left
cosets of H = f1 is not well defined and so a group cannot be formed from
left cosets of H.

15.3.5.5. Answer. D4 =  i, r, r2, r3, f1, f2, f3, f4  Where i is the identity
                        , and
function, r =  1234
               2341

               f1 =  1234              f2 =  1234
               f3 =  4321              f4 =  2143
                     1234                    1234
                     3214                    1432

The operation table for the group is

                     i r r2 r3 f1 f2 f3 f4

               i     i r r2 r3 f1 f2 f3 f4

               r     r r2 r3 i f4 f3 f1 f2

               r2 r2 r3 i r f2 f1 f4 f3

               r3 r3 i r r2 f3 f4 f2 f1

               f1 f1 f3 f2 f4 i r2 r r3

               f2 f2 f4 f1 f3 r2 i r3 r

               f3 f3 f2 f4 f1 r3 r i r2

               f4 f4 f1 f3 f2 r r3 r2 i

A lattice diagram of its subgroups is
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES560

Figure F.0.30 Subgroups of D4
    All proper subgroups are cyclic except i, r2, f1, f2 and i, r2, f3, f4 .

Each 2-element subgroup is isomorphic to Z2 ; i, r, r2, r3 is isomorphic to Z4
; and i, r2, f1, f2 and i, r2, f3, f4 are isomorphic to Z2 × Z2.
15.3.5.7. Answer. One solution is to cite Exercise 3 at the end of Section
11.3. It can be directly applied to this problem. An induction proof of the
problem at hand would be almost identical to the proof of the more general
statement. (t1t2 · · · tr) -1 = tr-1 · · · t2-1t1-1 by Exercise 3 of Section 11.3
= tr · · · t2t1 since each transposition inverts itself. 
15.3.5.9. Answer. Part I: That |Sk| = k! follows from the Rule of Products.

    Part II: Let f be the function defined on {1, 2, ..., n} by f (1) = 2, f (2) = 3,
f (3) = 1, and f (j) = j for 4  j  n; and let g be defined by g(1) = 1, g(2) = 3,
g(3) = 2, and g(j) = j for 4  j  n. Note that f and g are elements of Sn.
Next, (f  g)(1) = f (g(1)) = f (1) = 2, while (g  f )(1) = g(f (1)) = g(2) = 3,
hence f  g = g  f and Sn is non-abelian for any n  3.
15.3.5.13. Answer.

  (a) Both groups are non-abelian and of order 6; so they must be isomorphic,
       since only one such group exists up to isomorphism. The function  :
                                      (i) = I  (f1) = F1
       S3  R3 defined by  (r1) = R1  (f2) = F2 is an isomorphism,
                                     (r2) = R2  (f3) = F3

  (b) Recall that since every function is a relation, it is natural to translate
       functions to Boolean matrices. Suppose that f  Sn. We will define its
       image, (f ), by
                                       (f )kj = 1  f (j) = k
       That  is a bijection follows from the existence of -1. If A is a rook
       matrix,
                -1(A)(j) = k  The 1 in column j of A appears in row k
                                    Akj = 1
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES561

For f, g  Sn,

(f  g)kj = 1  (f  g)(j) = k
                    l such that g(j) = l and f (l) = k
                    l such that (g)lj = 1 and (f )kl = 1
                    ((f )(g))kj = 1

       Therefore,  is an isomorphism.

15.4 · Normal Subgroups and Group Homomor-
phisms
15.4.3 · Exercises

15.4.3.1. Answer.

(a) Yes, the kernel is {1, -1}

(b) No, since 2 (2 +5 4) = 2(1) = 1, but 2(2) +2 2(4) = 0 +2 0 = 0
     A follow-up might be to ask what happens if 5 is replaced with some
     other positive integer in this part.

  (c) Yes, the kernel is {(a, -a)|a  R}

  (d) No. A counterexample, among many, would be to consider the two trans-
       positions t1 = (1, 3) and t2 = (1, 2). Compare 4(t1 t2) and 4(t1)4(t2).

15.4.3.3. Answer. r = i, r, r2, r3 is a normal subgroup of D4. To see
you could use the table given in the solution of Exercise 15.3.5.5 of Section
15.3 and verify that a-1ha  r for all a  D4 and h  r. A more efficient
approach is to prove the general theorem that if H is a subgroup G with exactly
two distinct left cosets, than H is normal. f1 is not a normal subgroup of
D4. f1 = {i, f1} and if we choose a = r and h = f1 then a-1ha = r3f1r =
f2 / f1

15.4.3.5. Answer. (  ) (a1, a2, a3) = 0 and so    is the trivial homo-
morphism, but a homomorphism nevertheless.

15.4.3.7. Answer. Let x, y  G.

q(x  y) = (x  y)2       since G is abelian
          =xyxy
          =xxyy
          = x2  y2
          = q(x)  q(y)

Hence, q is a homomorphism. In order for q to be an isomorphism, it must be
the case that no element other than the identity is its own inverse.

                                    x  Ker(q)  q(x) = e

                                                   xx=e
                                                    x-1 = x

15.4.3.9. Answer. Proof: Recall that the inverse image of H under  is
-1(H) = {g  G|(g)  H}.

    Closure: Let g1, g2  -1(H), then  (g1) ,  (g2)  H. Since H is a
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES562

subgroup of G,

                  (g1)   (g2) =  (g1  g2)  H  g1  g2  -1(H)

    Identity: By Theorem 15.4.14(a), e  -1(H).
    Inverse: Let a  -1(H) . Then (a)  H and by Theorem 15.4.14(b),
(a)-1 =  a-1  H and so a-1  -1(H).

15.5 · Coding Theory, Linear Codes
15.5.4 · Exercises

15.5.4.1. Answer.

  (a) Error detected, since an odd number of 1's was received; ask for retrans-
       mission.

  (b) No error detected; accept this block.

  (c) No error detected; accept this block.
15.5.4.3. Answer.

  (a) Syndrome = (1, 0, 1). Corrected coded message is (1, 1, 0, 0, 1, 1) and
       original message was (1, 1, 0).

  (b) Syndrome = (1, 1, 0). Corrected coded message is (0, 0, 1, 0, 1, 1) and
       original message was (0, 0, 1).

  (c) Syndrome = (0, 0, 0). No error, coded message is (0, 1, 1, 1, 1, 0) and orig-
       inal message was (0, 1, 1).

  (d) Syndrome = (1, 1, 0). Corrected coded message is (1, 0, 0, 1, 1, 0) and
       original message was (1, 0, 0).

  (e) Syndrome = (1, 1, 1). This syndrome occurs only if two bits have been
       switched. No reliable correction is possible.

  (f) Syndrome = (0, 1, 0). Corrected coded message is (1, 0, 0, 1, 1, 0) and
       original message was (1, 0, 0).

15.5.4.5. Answer.
  (a) Blocks of two bits are encoded into code words of length 4.

  (b) The code words are 0000, 1010, 0111 and 1101.

  (c) Since the first two code words have a Hamming distance of 2, not all
       single bit errors can be corrected. For example, if 0000 is transmitted
       and the first bit is switch, then 1000 is received and we can't tell for
       sure whether this came from 0000 or 1010. To see what can be corrected,
       we note that a1a2 is encoded to a1a2(a1 +2 a2)a2 and so if b1b2b3b4 is
       recieved and no error has occurred,

                                           b1 +2 b2 +2 b3 = 0
                                               b2 +2 b4 = 0

       We can extract the parity check matrix from this set of equations. It is
                                                 
                                                    10
                                                 1 1
                                                 1 0
                                                    01
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES563

The rows of this matrix correspond with the syndromes for errors in bits
1 through 4, which are all nonzero, so we can detect any single bit error.
Notice that the syndromes for bits 1 and 3 are identical. This reflects the
fact that errors in these bits can't be corrected. However, the syndromes
for bits 2 and 4 are unique and so we can correct them. Therefore the
second bit of the original message can be sent with more confidence than
the first.

15.5.4.7. Solution. Yes, you can correct all single bit errors because the
parity check matrix for the expanded code is

                                      110  

                                     1 0 0 
                                    1 0 1
                   H =                     .
                                    0 1 0
                                           
                                    0 1 1

                                      001

Since each possible syndrome of single bit errors is unique we can correct any
error.

15.5.4.8. Hint. There is a parity check equation for each parity bit.

16 · An Introduction to Rings and Fields
16.1 · Rings, Basic Definitions and Concepts
16.1.6 · Exercises

16.1.6.1. Answer. All but ring d are commutative. All of the rings have a
unity element. The number 1 is the unity for all of the rings except d. The
unity for M2×2(R) is the two by two identity matrix. The units are as follows:

  (a) {1, -1}                         (d) {A |A11A22 - A12A21 = 0 }
                                      (e) {1}
  (b) C
  (c) Q
16.1.6.3. Answer.

(a) Consider commutativity

  (b) Solve x2 = 3x in both rings.
16.1.6.5. Answer.

(a) We already know that 3Z is a subgroup of the group Z. We need only
     show that 3Z is closed with respect to multiplication. Let 3m, 3n  3Z.
     (3m)(3n) = 3(3mn)  3Z, since 3mn  Z.

(b) The proper subrings are {0, 2, 4, 6} and {0, 4}; while {0} and Z8 are
     improper subrings.

  (c) The proper subrings are {00, 01}, {00, 10}, and {00, 11}: while {00} and
       Z2 × Z2 are improper subrings.

16.1.6.7. Answer.

(a) The left-hand side of the equation factors into the product (x - 2)(x - 3).
     Since Z is an integral domain, x = 2 and x = 3 are the only possible
     solutions.

(b) Over Z12, 2, 3, 6, and 11 are solutions. Although the equation factors
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES564

       into (x - 2)(x - 3), this product can be zero without making x either 2
       or 3. For example. If x = 6 we get (6 - 2) ×12 (6 - 3) = 4 ×12 3 = 0.
       Notice that 4 and 3 are zero divisors.

16.1.6.9. Answer. Let R1, R2, and R3 be any rings, then

  (a) R1 is isomorphic to R1 and so "is isomorphic to" is a reflexive relation
       on rings.

(b) R1 is isomorphic to R2  R2 is isomorphic to R1, and so "is isomorphic
     to" is a symmetric relation on rings,

(c) R1 is isomorphic to R2, and R2 is isomorphic to R3 implies that R1 is
     isomorphic to R3, and so "is isomorphic to" is a transitive relation on
     rings.

We haven't proven these properties here, just stated them. The combination
of these observations implies that "is isomorphic to" is an equivalence relation
on rings.

16.1.6.11. Answer.

  (a) Commutativity is clear from examination of a multiplication table for
       Z2×Z3. More generally, we could prove a theorem that the direct product
       of two or more commutative rings is commutative. (1, 1) is the unity of
       Z2 × Z3.

  (b) {(m, n)|m = 0 or n = 0, (m, n) = (0, 0)}

  (c) Another example is Z × Z. You never get an integral domain in this
       situation. By the definition an integral domain D must contain a "zero"
       so we always have (1, 0) · (0, 1) = (0, 0) in D × D.

16.1.6.13. Answer.

(a) (a + b)(c + d) = (a + b)c + (a + b)d = ac + bc + ad + bd

(b)

     (a + b)(a + b) = aa + ba + ab + bb     by part a
                       = aa + ab + ab + bb  since R is commutative.
                       = a2 + 2ab + b2

16.2 · Fields

· Exercises

 16.2.5. Answer.

  (a) 0 in Z2, 1 in Z3, 3 in Z5
  (b) 2 in Z3, 3 in Z5
  (c) 2 in Z5
16.2.7. Answer.

(a) 0 and 1       (b) 1          (c) 1                        (d) none

16.3 · Polynomial Rings

· Exercises
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES565

16.3.1. Answer.

  (a) f (x) + g(x) = 2 + 2x + x2 , f (x) · g(x) = 1 + 2x + 2x2 + x3
  (b) f (x) + g(x) = x2, f (x) · g(x) = 1 + x3
  (c) 1 + 3x + 4x2 + 3x3 + x4
  (d) 1 + x + x3 + x4
  (e) x2 + x3
16.3.3. Answer.

  (a) If a, b  R, a - b and ab are in R since R is a ring in its own right.
       Therefore, R is a subring of R[x]. The proofs of parts b and c are similar.

16.3.5. Answer.

(a) Reducible, (x + 1) x2 + x + 1

(b) Reducible, x x2 + x + 1

(c) Irreducible. If you could factor this polynomial, one factor would be
     either x or x + 1, which would give you a root of 0 or 1, respectively. By
     substitution of 0 and 1 into this polynomial, it clearly has no roots.

(d) Reducible, (x + 1)4

16.3.7. Answer. We illustrate this property of polynomials by showing that
it is not true for a nonprime polynomial in Z2[x]. Suppose that p(x) = x2 + 1,
which can be reduced to (x + 1)2 , a(x) = x2 + x, and b(x) = x3 + x2. Since
a(x)b(x) = x5 + x3 = x3 x2 + 1 , p(x)|a(x)b(x). However, p(x) is not a factor
of either a(x) or b(x).

16.3.9. Answer. The only possible proper factors of x2 - 3 are x - 3
            

and x + 3 , which are not in Q[x] but are in R[x].

16.3.11. Answer. For n  0, let S(n) be the proposition: For all g(x) = 0
and f (x) with deg f (x) = n, there exist unique polynomials q(x) and r(x) such

that f (x) = g(x)q(x) + r(x), and either r(x) = 0 or deg r(x) < deg g(x).

Basis: S(0) is true, for if f (x) has degree 0, it is a nonzero constant, f (x) =

c = 0, and so either f (x) = g(x) · 0 + c if g(x) is not a constant, or f (x) =
g(x)g(x)-1 + 0 if g(x) is also a constant.

    Induction: Assume that for some n  0, S(k) is true for all k  n, If f (x)
has degree n + 1, then there are two cases to consider. If deg g(x) > n + 1,

f (x) = g(x) · 0 + f (x), and we are done. Otherwise, if deg g(x) = m  n + 1, we
perform long division as follows, where LDT's stand for terms of lower degree

than n + 1.

                 gmxm + LDTs       fn+1 · gm-1xn+1-m

                                   )fn+1xn+1 + LDTs
                                    fn+1xn+1 + LDTs

                                   h(x)

Therefore,

h(x) = f (x)- fn+1 · gm-1xn+1-m g(x)  f (x) = fn+1 · gm-1xn+1-m g(x)+h(x)

Since deg h(x) is less than n+1, we can apply the induction hypothesis: h(x) =
g(x)q(x) + r(x) with deg r(x) < deg g(x).
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES566

    Therefore,

                    f (x) = g(x) fn+1 · gm-1xn+1-m + q(x) + r(x)

with deg r(x) < deg g(x). This establishes the existence of a quotient and
remainder. The uniqueness of q(x) and r(x) as stated in the theorem is proven
as follows: if f (x) is also equal to g(x)q¯(x) + r¯(x) with deg r¯(x) < deg g(x),
then

     g(x)q(x) + r(x) = g(x)q¯(x) + r(x)  g(x) (q¯(x) - q(x)) = r(x) - r¯(x)

Since deg r(x) - r¯(x) < deg g(x), the degree of both sides of the last equation
is less than deg g(x). Therefore, it must be that q¯(x) - q(x) = 0, or q(x) = q¯(x)
And so r(x) = r¯(x).

16.4 · Field Extensions

· Exercises                           
                   If a0 + a1 2  Q 2 is nonzero, then it has a multiplica-
 16.4.1. Answer.
 tive inverse:

                     1 =                                 
                                    1  a0 - a12
                   a0 + a1 2 a0 + a12 a0 - a1 2
                                    a0 - a1 2
                                = a02 - 2a12
                                                         a1 
                                =2  a0       2- 2              22

                                    a0 - 2a1 a0 - 2a1

The  denominator,  a02 - 2a12,  is  nonzero  since       is  irrational.  Since       a0
                                                      2                          a0 2 -2a1 2
                                                    
and a02-2a12 -a1 are both rational numbers, a0 + a1 2 is a unit of Q 2 . The
                                                                          
field containing Q 2 is denoted Q 2 and so Q 2 = Q 2

16.4.3. Answer. x4 - 5x2 + 6 = (x2 - 2)(x2 - 3) has zeros ±2 and ±3.
  Q( 2) = {a + b 2 | a, b  Q} contains the zeros ± 2 but does not contain

± 3, since neither are expressible in the form a + b 2. If we consider the set
{c + d 3 | c, d Q( 2)}, thenthis field contains ± 3 as well as ± 2, and is
denoted Q( 2)( 3) = Q( 2, 3). Taking into account the form of c and d in
the description above, we can expand to

                                                         
     Q( 2, 3) = {b0 + b1 2 + b2 3 + b3 6 | bi  Q}

16.4.5. Answer.

(a) f (x) = x3 + x + 1 is reducible if and only if it has a factor of the form
     x - a. By Theorem 16.3.14, x - a is a factor if and only if a is a zero.
     Neither 0 nor 1 is a zero of f (x) over Z2.

(b) Since f (x) is irreducible over Z2, all zeros of f (x) must lie in an extension
     field of Z2 . Let c be a zero of f (x). Z2(c) can be described several
     different ways. One way is to note that since c  Z2(c), cn  Z2(c) for all
     n. Therefore, Z2(c) includes 0, c, c2, c3, . . .. But c3 = c + 1 since f (c) = 0.
     Furthermore, c4 = c2 + c, c5 = c2 + c + 1, c6 = c2 + 1, and c7 = 1. Higher
     powers of c repeat preceding powers. Therefore,

     Z2(c) = 0, 1, c, c2, c + 1, c2 + 1, c2 + c + 1, c2 + c
            = a0 + a1c + a2c2 | ai  Z2
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES567

     The three zeros of f (x) are c, c2 and c2 + c.
                             f (x) = (x + c) x + c2 x + c2 + c

(c) Cite Theorem Theorem 16.2.10, part 3.

16.5 · Power Series
16.5.3 · Exercises

16.5.3.5. Answer.

(a)
                                                 b0 = 1

                                      b1 = (-1)(2 · 1) = -2
                                 b2 = (-1)(2 · (-2) + 4 · 1) = 0
                            b3 = (-1)(2 · 0 + 4 · (-2) + 8 · 1) = 0

     All other terms are zero. Hence, f (x)-1 = 1 - 2x

(b)

                           f (x) = 1 + 2x + 22x2 + 23x3 + · · ·
                                  = (2x)0 + (2x)1 + (2x)2 + (2x)3 + · · ·
                                         1
                                  =
                                     1 - 2x

       The last step follows from the formula for the sum of a geometric series.
16.5.3.7. Answer.

(a)

     x4 - x5 -1 = (x4(1 - x))-1

                     = x-4 1
                             1-x

                     = x-4                 

                                              xk .

                                           k=0

                        

                     =                     xk

                        k=-4

(b)

     x4 - 2x3 + x2 -1 = x2 x2 - 2x + 1 -1

                     = x-2 1 - 2x + x2 -1

                     = x-2                 

                                              (k + 1)xk .

                                    k=0
                            

                     = (k + 2)xk

                        k=-2
References

Many of the references listed here were used in preparing the original 1980's
version of this book. In most cases, the mathematics that they contain is still
worth reading for further background. Many can be found online, in university
libraries or used bookstores. A few more current references have been added.

[1] Allenby, R.B.J.T, Rings, Fields and Groups, Edward Arnold, 1983.
[2] Appel, K., and W. Haken, Every Planar Map Is 4-colorable, Bull, Am.

       Math. Soc. no. 82 (1976): 711-12.
       This has historical significance in that it announced the first correct proof
       of the Four Color Theorem
[3] Austin, A. Keith, An Elementary Approach to NP-Completeness Ameri-
       can Math. Monthly 90 (1983): 398-99.
[4] Beardwood, J., J. H. Halton, and J. M. Hammersley, The Shortest Path
       Through Many Points Proc. Cambridge Phil. Soc. no. 55 (1959): 299-
       327.
[5] Ben-Ari, M, Principles of Concurrent Programming, Englewood Cliffs,
       NJ: Prentice-Hall, 1982.
[6] Berge, C, The Theory of Graphs and Its Applications, New York: Wiley,
       1962.
[7] Bogart, Kenneth P, Combinatorics Through Guided Discovery, 2005.
       This book may be freely downloaded and redistributed at http://www.math.dartmouth.edu/
       news-resources/electronic/kpbogart/ under the terms of the GNU Free
       Documentation License (FDL), as published by the Free Software Foun-
       dation.
[8] Busacker, Robert G., and Thomas L. Saaty, Finite Graphs and Networks,
       New York: McGraw-Hill, 1965.
[9] Connell, Ian, Modern Algebra, A Constructive Introduction, New York:
       North-Holland, 1982.
[10] Denning, Peter J., Jack B. Dennis, and Joseph L. Qualitz, Machines,
       Languages, and Computation, Englewood Cliffs, NJ: Prentice-Hall, 1978.
[11] Denning, Peter J, Multigrids and Hypercubes. American Scientist 75
       (1987): 234-238.
[12] Dornhoff, L. L., and F. E. Hohn, Applied Modern Algebra, New York:
       Macmillan, 1978.
[13] Ford, L. R., Jr., and D. R. Fulkerson, Flows in Networks, Princeton, NJ:
       Princeton Univesity Press, 1962.
[14] Fraleigh, John B, A First Course in Abstract Algebra, 3rd ed. Reading,

                                                 568
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES569

       MA: Addison-Wesley, 1982.

[15] Gallian, Joseph A, Contemporary Abstract Algebra, D.C. Heath, 1986.

[16] Gallian, Joseph A, Group Theory and the Design of a Letter-Facing Ma-
       chine, American Math. Monthly 84 (1977): 285-287.

[17] Hamming, R. W, Coding and Information Theory, Englewood Cliffs, NJ:
       Prentice-Hall, 1980.

[18] Hill, F. J., and G. R. Peterson, Switching Theory and Logical Design,
       2nd ed. New York: Wiley, 1974.

[19] Hofstadter, D. R, Godel, Escher, Bach: An Eternal Golden Braid, New
       York: Basic Books, 1979.

[20] Hohn, F. E, Applied Boolean Algebra, 2nd ed. New York: Macmillan,
       1966.

[21] Hopcroft, J. E., and J. D. Ullman, Formal Languages and Their Relation
       to Automata, Reading, MA: Addison-Wesley, 1969.

[22] Hu, T. C, Combinatorial Algorithms, Reading, MA: Addison-Wesley,
       1982.

[23] Knuth, D. E, The Art of Computer Programming. Vol. 1, Fundamental
       Algorithms, 2nd ed. Reading, MA: Addison-Wesley, 1973.

[24] Knuth, D. E, The Art of Computer Programming. Vol. 2, Seminumerical
       Algorithms, 2nd ed., Reading, MA: Addison-Wesley, 1981.

[25] Knuth, D. E, The Art of Computer Programming. Vol. 3, Sorting and
       Searching, Reading, MA: Addison-Wesley, 1973.

[26] Knuth, D. E, The Art of Computer Programming. Vol. 4A, Combinator-
       ial Algorithms, Part 1, Upper Saddle River, New Jersey: Addison-Wesley,
       2011.
       https://www-cs-faculty.stanford.edu/~knuth/taocp.html

[27] Kulisch, U. W., and Miranker, W. L, Computer Arithmetic in Theory
       and Practice, New York: Academic Press, 1981.

[28] Levin, Oscar, Discrete Mathematics: An Open Introduction, http://
       discrete.openmathbooks.org.

[29] Lipson, J. D, Elements of Algebra and Algebraic Computing, Reading,
       MA: Addison-Wesley, 1981.

[30] Liu, C. L, Elements of Discrete Mathematics, New York: McGraw-Hill,
       1977.

[31] O'Donnell, Analysis of Boolean Functions.
       A book about Fourier analysis of boolean functions that is being devel-
       oped online in a blog.

[32] The Omnificent English Dictionary In Limerick Form .
       The source of all limericks that appear at the beginning of most chapters.
       https://www.oedilf.com/

[33] Ore, O, Graphs and Their Uses, New York: Random House, 1963.

[34] Parry, R. T., and H. Pferrer, The Infamous Traveling-Salesman Problem:
       A Practical Approach Byte 6 (July 1981): 252-90.

[35] Pless, V, Introduction to the Theory of Error-Correcting Codes, New
       York: Wiley-Interscience, 1982.

[36] Purdom, P. W., and C. A. Brown, The Analysis of Algorithms, Holt,
APPENDIX F. HINTS AND SOLUTIONS TO SELECTED EXERCISES570

       Rinehart, and Winston, 1985.

[37] Quine, W. V, The Ways of Paradox and Other Essays, New York: Ran-
       dom House, 1966.

[38] Ralston, A, The First Course in Computer Science Needs a Mathematics
       Corequisite, Communications of the ACM 27-10 (1984): 1002-1005.

[39] Solow, Daniel, How to Read and Do Proofs, New York: Wiley, 1982.

[40] Supowit, K. J., E. M. Reingold, and D. A. Plaisted The Traveling Sales-
       man Problem and Minimum Matching in the Unit Square.SIAM J. Com-
       puting, 1983,12, 144-56.

[41] Standish, T. A, Data Structure Techniques, Reading, MA: Addison-Wesley,
       1980.

[42] Stoll, Robert R, Sets, Logic and Axiomatic Theories, San Francisco: W.
       H. Freeman, 1961.

[43] Strang, G, Linear Algebra and Its Applications, 2nd ed. New York: Aca-
       demic Press, 1980.

[44] Tucker, Alan C, Applied Combinatorics, 2nd ed. New York: John Wiley
       and Sons, 1984.

[45] Wand, Mitchell, Induction, Recursion, and Programming, New York:
       North-Holland, 1980.

[46] Warshall, S, A Theorem on Boolean Matrices Journal of the Association
       of Computing Machinery, 1962, 11-12.

[47] Weisstein, Eric W. Strassen Formulas, MathWorld--A Wolfram Web Re-
       source, http://mathworld.wolfram.com/StrassenFormulas.html.

[48] Wilf, Herbert S, Some Examples of Combinatorial Averaging, American
       Math. Monthly 92 (1985).

[49] Wilf, Herbert S. generatingfunctionology, A K Peters/CRC Press, 2005
       The 1990 edition of this book is available at https://www.math.upenn.edu/
       ~wilf/DownldGF.html

[50] Winograd, S, On the Time Required to Perform Addition, J. Assoc.
       Comp. Mach. 12 (1965): 277-85.

[51] Wilson, R., Four Colors Suffice - How the Map Problem Was SolvedPrinceton,
       NJ: Princeton U. Press, 2013.
Index

(0, 1)-matrix, see relation matrix       Bipartite Graph., 238
                                         Bipartitie
Abelian Group, 277
      a Limerick, 270                          a Limerick, 184
                                         Bit, 481
adjacency matrix, 117, 196               Boolean Algebra, 359
      a Limerick, 102                    Boolean Algebras, 357
                                         Boolean Arithmetic, 118
Adjacency Matrix Method, 200             Boolean Expression, 366
Algebraic Systems, 274                   Boolean Expressions, 366
algorithm                                Boolean matrix, see relation

      a Limerick, 462                                matrix
Alternating Group, 413                   Bounded Lattice, 357
Alternating group                        Breadth-First Search, 200
                                         Breadth-first Search, 202
      a Limerick, 397                    Bridge, 247
An, 481                                  Bubble Sort, 166
Analog-to-digital Conversion, 214        Byte, 481
Antisymmetric Relation, 109              Bézout's lemma, 286
Associative Property, 272
Atom of a Boolean Algebra, 362           Cancellation in Groups, 280
augmented matrix                         Cardinality., 131
                                         Cartesian Product, 11
      a Limerick, 312                    Center of a Graph, 230
Automata, 386                            Center of a graph, 205
Automorphism                             Characteristic Equation, 154
                                         Characteristic function, 130
      Inner, 311                         Characteristic Polynomial, 474
                                         Characteristic Roots, 154
Basic Law Of Addition:, 30               Child
Basic Set Operations, 5
Basis, 329                                     of a Root, 254
Biconditional Proposition, 43            Chinese Remainder Theorem, 400
Bijection, 131                           Chromatic Number, 237
Binary Conversion Algorithm, 14          Circuit, in a graph, 188
binary matrix, see relation matrix       Closed Form Expression., 147
Binary Operation., 271                   Closest Neighbor Algorithm, 221
Binary Representation, 13                Closure Property, 272
Binary Search, 143                       Code
Binary Tree, 260
Binary Trees, 259                              Polynomial, 455
Binomial Coefficient                     Codes

      Recursive Definition, 141                Linear, 425
binomial coefficient, 33                 Coding Theory, 425
Binomial Coefficient Formula, 34
Binomial Theorem, The, 36

                                    571
INDEX                                                                        572

Cofactor, 474                       dihedral Group, 415
combinations, 33                    dimension of a Vector Space, 330
Commutative Property, 271           Direct Product
Compact Minset Notation, 85
Complement of a Lattice Element,          of Two Groups, 299
                                    direct Product, 298
            357                     direct Products, 298
      as an operation, 358          direct proof, 55
Complement of a set, 7              directed Graph, 184
Complemented Lattice, 358           directed graph, 106
Complete Undirected Graph., 186     disjoint Cycles, 411
Complex Number, 481                 disjoint Sets, 5
Composite Integer, 481              disjunction, Logical, 42
Composition of Functions, 135       distinct, 481
Composition of Relations, 104       distributive Lattice, 356
Concatenation, 381                  distributive Property, 272
Conditional Statement, 42           divides, 103
Congruence Modulo n, 113            division Property for Integers, 284
conjunction, Logical, 41            division Property for Polynomials,
Connected Component, 189
Connectivity in Graphs, 199                     450
Constant, 481                       divisors of an Integer, 353
Contradiction, 48                   doyle, Chris, 126, 397
Contrapositive, 43                  duality for Boolean Algebras, 360
Converse, 43
Coset, 404                          Eccentricity of a vertex, 205
Coset Counting Formula, 405         Edges
Coset Representative, 404
Cosets                                    of a directed graph, 184
      Operation on, 406                   of an undirected graph, 185
Cosets and Factor Groups, 403       Egg, Bob, 88
Countable Set, 132                  Eigenvalue, 332
Counting Binary Trees, 266          Eigenvector, 332
covering relation, 362              Elementary Operations on
Creative Commons, 481
Cycle, 242                                      Equations, 313
Cycle Notation, 411                 Elementary Row Operations, 315
Cyclic Group, 296, 397              Embedding of a graph, 106
Cyclic Subgroup, 296                Empty Graph, 185
                                    Empty set, 3
data Structure, 481                 empty set
degree, 192
degree Sequence of a Graph, 192           a Limerick, 1
derangement, 167                    Enumeration, 2
detachment, 52                      Equivalence, 48
Determinant, 474                    Equivalence Classes, 112
                                    Equivalence Relation, 112
      1 × 1 and a 2 × 2 cases, 473  Equivalence Relations, 112
diagonal matrix                     Euclidean Algorithm, The, 285
                                    Euler's Formula, 234
      a Limerick, 88                Euler's Theorem, 211
diagonalizable Matrix, 334
diagonalization Process, The, 332         Koenigsberg Case, 210
diameter of a Graph, 205            Eulerian Paths, Circuits, Graphs,
digraph, 106
Dihedral Group                                  210
                                    Even Integer, 481
      Definition, 417               Existential Quantifier, 67
                                    Exponentiation in Groups, 281
                                    Expression Tree, 263
INDEX                                                                        573

Extended Rule Of Products, The,     Goldie, 40, 141
            22                      Graph

Factor, 481                               Data Structures, 195
Factor Group, 408                         Multigraph, 186
Factor Theorem, 451                       Simple Directed, 184
Factorial, 25                             Simple Undirected, 185
Fibonacci Sequence, 145             Graph Coloring, 237
                                    Graph Optimization, 220
      Matrix Representation, 341    Graphic Sequence, 192
Fibonacci sequence                  Gray Code, 214
                                    Gray Code Decoder, 391
      a Limerick, 141               Greatest Common Divisor (gcd),
Field, 444
field extension                                 284
                                    Greatest Element, 352
      a Limerick, 435               Greatest Lower Bound, 352
Finite-State Machine, 387           Group, 276
Finite-State Machines, 386
Five-Color Theorem, 237             Hamiltonian Paths, Circuits, and
Flow Augmenting Path, 227                       Graphs, 213
Forest., 243
Formal Language, 381                Hamming Distance, 426
formal logic                        Hasse Diagram, 110
                                    Homogeneous Recurrence
      a Limerick, 40
Four-Color Theorem, 237                         Relation., 153
Frankovich, Jesse, 462              Homomorphism, 421
Free Monoids and Languages, 380
Full binary tree, 260, 261                Group, 418
Function, 126                       Howlett,Chris, 184

      Bijective, 131                Idempotent Property, 272
      Composition, 135              Identity Function, 137
      Equality, 135                 Identity Matrix, 95
      Injective, 131                Identity Property, 272
      One-to-one, 131               Iff, 481
      Onto, 131                     Image of an Element., 127
      Surjective, 131               Implication, 49
Functions                           Improper subset, 4
      Of two Variables, 128         Inclusion-Exclusion, Laws of, 31
Functions Between Two Sets          Indirect proof, 56
      Set of, 127                   Indirect Reasoning, 52
Fundamental Theorem of Group        Induced Subgraph, 188
                                    Induction and Recursion, 146
            Homomorphisms, 423      Injection, 131
                                    Integer, 482
Gauss-Jordan Algorithm, 318         Integers Modulo n
genealogical terms, 253
Generalized Set Operations, 18            Additive Group, 289
Generate, 327                             Multiplicative Group, 289
Generating Function, 170            Integral Domain, 441
Generating Functions, 169           Intersection, 5
                                    Into, 482
      Closed form expressions for,  Inverse
            177                           Logical, 43
                                          Matrix, 95
      Operations on, 175            Inverse Function
Generator, 296                            of a function on a set, 137
George Boole                        Inverse Property, 272

      a Limerick, 351
Glossary, 481
INDEX                                                                         574

Involution Property, 272             Meet, 355
Irrational Number, 482               Merge Sort, 166
Irreducibility of a Polynomial, 451  Mesh Graph, 241
Isomorphic Graphs, 191               Minimal Spanning Tree, 247
Isomorphism                          Minimum Diameter Spanning

      Group, 307                                 Tree, 249
Isomorphisms, 304                    Minor, 473
                                     Minset, 84
Join, 355                            Minset Normal Form, 85
                                     Minterm, 367
Karnaugh map, 369                    Minterm Normal Form, 367
Kernel, 422                          Modular Addition, 288
kernel of a function, 130            Modular Arithmetic, 287
Kruskal's Algorithm, 256
                                           Properties, 289
Lagrange's Theorem, 406              Modular Multiplication, 288
LaTeX, 482                           Modus Ponens
Lattice, 355
Lattice Paths, 37                          see Detachment, 52
Lattices, 355                        Modus Tollens
Laws of Matrix Algebra, 98
Leaf of a binary tree, 260                 see Indirect Reasoning, 52
Leaf, of a binary tree, 260          Monoid, 377
Least Element, 352
Least Upper Bound, 352                     of a Finite-State Machine, 391
Left Distributive Property, 272      Monoids, 377
Level of a vertex, 254               Multigraph, 186
Levels of Abstraction, 275           Multiple Pop and Push, 175
Limerick                             Multiples, 482
                                     Multiplicative Inverses, 437
      countably infinite, 126
      Enumerative Combinatorics,     N-cube, 214
                                     Natural Homomorphism, 422
            20                       Natural Numbers, 482
Linear Code, 429                     Negation, Logical, 42
Linear Combination., 327             Network, 225
Linear Dependence, 329               Networks, 225
Linear Equations                     Ngai, Steve, 312
                                     Nim, 105
      over the Integers Mod 2, 346   Nonhomogeneous of Finite Order
Linear Equations in a Group, 281
Linear Independence, 329                         Linear Relations
Logarithm                                  Solution, 156
                                     Nonnegative Number, 482
      General Base, 165              Normal Subgroup., 420
Logarithm, base 2, 164               Normal Subgroups, 418
Logarithms, 164
                                     Odd Integer, 482
      Properties, 164                Operation Tables, 273
Logic Design, 370                    Operations, 270
logical matrix, see relation matrix  Order
Lower Bound, 351
                                           of elements of a finite cyclic
Machine of a Monoid, 394                         group, 400
Many Faces of Recursion, The, 141
Matrix Addition, 90                  Order of a Group Element, 296
Matrix Inversion, 321                Order of a Recurrence Relation,
Matrix Multiplication, 90
Matrix Oddities, 99                              152
Maximal flow, 227                    Order Sequence, 309
                                     Ordering Diagram, 110
                                     Oslan, Steven, vii
INDEX                                                                       575

Parent of a vertex, 254            Properties of Operations, 271
Partial Ordering, 109, 351         proposition, 40
Partially ordered set, 109         Propp, Jim, 309
Partition                          psheil, 102

      of a group by cosets, 405    Quantifiers, 67
partition, 29                            Multiple, 69
Path Graph, 233                          Negation, 68
Path, in a graph, 188
Perfect Codes, 434                 Queue, 482
Perfect Graph, 240
Permutation, 26, 138               Radius of a graph, 205
Permutation Counting Formula,      Range of a Function., 127
                                   Rational Number, 482
            26                     Real Number, 482
Permutation Groups, 409            Rectangular codes, 433
Permutations                       Recurrence Relation, 151
                                   Recurrence Relations
      Composition, 412
Phrase Structure Grammar, 383            Solving, 151
Pigeonhole Principle, 133          Recurrence Relations Obtained
Planar Embedding of a Graph, 233
Planar Graph, 233                              from "Solutions", 152
Plane Graph, 233                   Recursive Language, 382
Polynomial                         Recursive Searching, 143
                                   Reducible Polynomial, 451
      Irreducible, 451             References, 568
Polynomial Addition, 448           Reflexive Relation, 109
Polynomial Code, 455               Regions of a Planar Graph, 234
Polynomial Expression              Regular Grammar, 385
                                   Relation, 102
      Non-recursive)., 142         relation matrix, 117
      Recursive definition, 143    Relation Notation, 104
Polynomial Multiplication, 448     Relation on a Set, 103
Polynomial over a Ring, 447        Relatively Prime, 284
Polynomial Units, 459              Right Distributive Property, 272
Polynomials, 142                   Ring, 435
Polynomials and their evaluation,
                                         Commutative, 436
            141                    Ring Isomorphism., 438
Poset, 109                         Ring with unity, 436
Posets Revisited, 351              Robinson, Andrew, 351
Positive Number, 482               Rooted Tree, 254
Power Series, 457                  Rooted Trees, 252
Power Series Units, 459            Row Equivalent Matrices, 315
Power Set, 11                      Rule Of Products, The, 21
Power Set Cardinality Theorem,
                                   SageMath, 482
            22                     SageMath Note
Powers, 482
Powers of Functions, 136                 bridge hands, 36
Predicate, 58                            Cartesian Products and
PreTeXt, 482
Prim's Algorithm, 248                          Power Sets, 11
Prime, 482                               Functions, 129
Prime number, 65                         Graphs, 197
Products                                 Kruskal's Algorithm, 256
                                         Matrix Diagonalization, 338
      Extended Rule of, 22               Matrix Exponential, 344
      Rule of, 21                        Matrix Reduction, 319
Proper subset, 4                         Modular Arithmetic, 290
Properties of Functions, 130
INDEX                                                                     576

      Power Series, 267          Systems of Linear Equations, 312
      Search in a Graph, 206
      Sets, 8                    Tautology, 48
Scalar Multiplication, 90        Term, 482
Sequence, 148                    The Integers Modulo n, 288
Sequences, 148                   Three Utilities Puzzle, 234
      Operations on, 173         To, 482
      Recursively Defined, 144   Tournament Graph, 190
Set of Functions Between Two     Transitive Closure, 121
                                 Transitive Relation, 109
            Sets, 127            Transposition, 412
Set-Builder Notation, 2          Traveling Salesman Problem, The,
Sheffer Stroke, 50
SheilaB, 1                                   221
Simple Undirected Graph, 185     Traversals of Binary Trees, 261
Solution Set, 312                Traversals of Graphs, 210
Some General Properties of       Tree, 242
                                 Truth Set, 59
            Groups, 279
Span, 327                        Unary Operation., 271
Spanning Subgraph, 188           Union, 5
Spanning Tree, 247               Unique, 482
Spanning Trees, 245              Units
Spindel, Howard, 270
Stack, 482                             of a ring, 437
Strings over an Alphabet, 380          of Polynomial Rings, 459
STT, see Sun Tzu's Theorem             of Power Series Rings, 459
Subgraph, 188                    Unity of a Ring, 436
Subgroup, 293                    Universal Quantifier, 68
                                 Universe, 6
      Conditions, 294            Upper Bound, 351
Submonoid
                                 Value of a Flow, 227
      Generated by a Set, 378    Variable, 483
Subsystem, 293                   Vector Space, 325
Subsystems, 293                  Vector Spaces, 325
Subtraction, 482
Summation Notation and           Weighted Graph, 220
                                 What Is a Tree?, 242
            Generalizations, 16
Sun Tzu's Theorem, 400           XOR linked list, 302
Surjection, 131
Switching Theory, 370            Zero Divisor, 440
Symmetric Difference, 8          zqms, 435
Symmetric Group, 410
Symmetric Relation, 112
Syndrome, 430
