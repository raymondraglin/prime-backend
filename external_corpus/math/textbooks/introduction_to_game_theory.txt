Introduction to Game Theory

            a Discovery Approach
Introduction to Game Theory

            a Discovery Approach

             Jennifer Firkins Nordstrom
                   Linfield University
                    McMinnville, OR

                    January 12, 2026
Website: Website: Jennifer Nordstrom Open Math Textbooks1
©2017-2025 Jennifer Firkins Nordstrom
This work is licensed under a Creative Commons Attribution-ShareAlike 4.0
International License2.

   1nordstrommath.com/
   2creativecommons.org/licenses/by-sa/4.0/
Preface

Many colleges and universities are offering courses in quantitative reasoning
for all students. One model for a quantitative reasoning course is to provide
students with a single cohesive topic. Ideally, such a topic can pique the curios-
ity of students with wide ranging academic interests and limited mathematical
background. This text is intended for use in such a course. Game theory is an
excellent topic for a non-majors quantitative course as it develops mathemat-
ical models to understand human behavior in social, political, and economic
settings. The variety of applications can appeal to a broad range of students.
Additionally, students can learn mathematics through playing games, some-
thing many choose to do in their spare time!

    This text particularly explores the ideas of game theory through the rich
context of popular culture. At the end of each chapter is a section on appli-
cations of the concepts to popular culture. It suggests films, television shows,
and novels with themes from game theory. The questions in each of these
sections are intended to serve as essay prompts for writing assignments.

Course Goals.

   · Introduce students to the mathematics of game theory.

   · Teach students how to use mathematical models to solve problems in
       social and economic situations.

   · Build students' quantitative intuition.

   · Introduce students to the power of mathematics to frame human behav-
       ior.

   · Provide students an opportunity to use algebraic techniques, such as
       linear models and systems of equations, in game theoretic applications.

   · Provide students an opportunity to use basic ideas of probability, such
       as expected value, in game theoretic applications.

Course Format. The material is presented in a discovery format, requiring
students to make conjectures frequently. Each section is structured as a class
activity. Any introduction material can be read by the students, and the num-
bered problems or questions are to be out in class and as homework, depending
on how far a particular student progresses through the section. Most sections
require students to attempt to solve the problem before they have been pro-
vided much framework. The sections then build the necessary tools to solve
the problem or understand the key ideas. Being able to compare their original
solutions and ideas to the more sophisticated mathematical ones helps build

                                                  v
vi

their mathematical intuition and helps them to understand the power of using
mathematics in situations where their intuition falls short.

Suggestions for Use. This text is primarily for use in a college-level quan-
titative reasoning course. It can also be used for an introductory course in
game theory for the social sciences. It approaches the subject matter through
an inquiry-based format. Most of the topics can be introduced by providing
the students with the activity to work through during class, followed by a dis-
cussion. Almost all of the activities are intended to work through the concepts
without additional lecture or introduction. Students with even a rudimentary
background in algebra will find the material accessible. Any necessary mathe-
matical background can be introduced as needed.
Contents

Preface                               v

1 What is Game Theory?                1

1.1 Players and Strategies . . . . . . . . . . . . . . . . 1
1.2 Game Matrices and Payoff Vectors . . . . . . . . . . . 5

2 Two-Person Zero-Sum Games           9

2.1 Introduction to Two-Person Zero-Sum Games . . . . . . . 9
2.2 Finding Strategies . . . . . . . . . . . . . . . . . 15
2.3 Probability and Expected Value . . . . . . . . . . . . 25
2.4 A Game of Chance . . . . . . . . . . . . . . . . . 29
2.5 Equilibrium Points . . . . . . . . . . . . . . . . . 32
2.6 Strategies for Zero-Sum Games and Equilibrium Points . . . . 35
2.7 Popular Culture: Rationality and Perfect Information . . . . 36

3 Repeated Two-Person Zero-sum Games  39

3.1 Introduction to Repeated Games . . . . . . . . . . . . 39
3.2 Mixed Strategies: Graphical Solution. . . . . . . . . . . 43
3.3 Using Sage to Graph Lines and Solve Equations. . . . . . . 53
3.4 Mixed Strategies: Expected Value Solution . . . . . . . . 59
3.5 Liar's Poker . . . . . . . . . . . . . . . . . . . . 64
3.6 Solving Systems of Equations Using Matrices. . . . . . . . 67
3.7 Undercut . . . . . . . . . . . . . . . . . . . . . 73

4 Non-Zero-Sum Games                  77

4.1 Introduction to Two-Player Non-Zero-Sum Games . . . . . . 77
4.2 Prisoner's Dilemma and Chicken . . . . . . . . . . . . 82
4.3 A Class-Wide Experiment. . . . . . . . . . . . . . . 86
4.4 What Makes a Prisoner's Dilemma? . . . . . . . . . . . 90
4.5 Another Multiplayer Experiment . . . . . . . . . . . . 94
4.6 Volunteer's Dilemma . . . . . . . . . . . . . . . . 98
4.7 Repeated Prisoner's Dilemma . . . . . . . . . . . . . 101
4.8 Popular Culture: Prisoner's Dilemma and Chicken . . . . . . 105

                        vii
viii         CONTENTS

Back Matter              109
                         111
References
Index
Chapter 1

What is Game Theory?

    "Game Theory is not about 'playing games.' It is about conflict resolution
among rational but distrustful beings." Poundstone, Prisoner's Dilemma, p.
39.

    Although we will play many games throughout this book, our goal is to
understand how rational, distrustful players would play the game. These games
are meant to serve as models for situations of conflict. We will explore how
to "solve" games under certain assumptions about our players. As with any
mathematical model, we will need to make assumptions about how our players
will behave, what information they have, and the constraints of the game. For
example, we will assume that our players will use all information available to
them and that players will follow the rules of the game.

    Games can provide hours of recreational enjoyment and are worth studying
for this alone. However, even simple games can be used to model political,
social, and economic interactions. Understanding some foundations of game
theory can help us interpret, predict, and respond in competitive situations.

1.1 Players and Strategies

In this book most of the games will be played by two players. Each player
must decide how he or she will play the game. In order to study games math-
ematically, we need to make some assumptions about how the players should
play the game. This allows us to be able to better predict what our players
should do.

1.1.1 Assumptions: Cake Division

We begin with an example of cutting a cake to illustrate some of the assump-
tions we will make about our players. How can two children fairly divide a

                                                  1
2                       CHAPTER 1. WHAT IS GAME THEORY?

cake? One classic solution is to have one child cut the cake and have the other
child choose a piece.

    Before examining this solution, try to answer the following questions:

   · Why does this work? In other words, why should both children feel they
       received a fair share of the cake?

   · What are the underlying assumptions that make this process work? What
       do we need to assume about each player?

    The goal of each player is to get the largest piece. We can think of this as
each player acting in his or her self-interest. Furthermore, both players know
that the other player has the same goal and will act to further this goal. Thus,
we know that each player is rational. Even more, each player knows the other
player is rational.

    We need both players to be self-interested and rational to reach the solution
that the cake is divided evenly, and both children receive equal sized pieces.
For example, if a player doesn't like cake, then they may cut themselves a small
piece, and give the other player a large piece. This could lead to both children
being happy and feeling that the cake was fairly divided, but it does not give
us an evenly divided cake. The idea that each player knows the other player
is rational is important as well. If the cake cutter does not think the chooser
will take the largest piece, then we also may not get an evenly divided cake.

    The idea that players are self-interested is crucial to game theory. There are
lots of other ways to play games, and those might be worth exploring. But to
get started with game theory, we must make specific assumptions and develop
the mathematical context from these assumptions.

                                     Basic Assumptions.

       Players are      The goal is to win the most or lose the least.
   self-interested.
                        A player will always take into account all available
       Players are      information and make the decision which maxi-
           perfectly    mizes his payoff. This includes knowing that his
              logical.  opponent is also making the best decision for her-
                        self.

    As an example of how a player must assume that his opponent is also
making the best decision for herself, in the cake cutting game a player wouldn't
cut one large piece hoping that his opponent will by chance pick the smaller
piece. A player must assume that her opponent will always choose the larger
piece.

    What does it mean to win? A player's payoff is the amount (points, money,
or anything a player values) a player receives for a particular outcome of a game.
We say that the player's goal is to maximize his or her payoff. We should note
that the maximum payoff for a player might even be negative, in which case
the player wants the least negative (or closest to 0) payoff.

    It is important to recognize the difference between having the goal of max-
imizing the payoff and having the goal of simply winning. Here are some
examples.

   1. If two players were racing, a player wouldn't just want to finish first, she
       would want to finish by as large a margin as possible.
1.1. PLAYERS AND STRATEGIES  3

   2. If two teams were playing basketball, the team wouldn't want to just
       have the higher score, they would want to win by the largest number of
       points. In other words, a team would prefer to win by 10 points rather
       than by 1 point.

   3. In an election poll, a candidate doesn't just want to be ahead of her
       opponent, she wants lead by as large a margin as possible, (especially if
       she needs to account for error in the polls).

    Keep in mind the the goal of each player is to win the most or lose the
least. It will be tempting to look for strategies which simply assure a player of
a positive payoff, but we need to make sure a player can't do even better with
a different strategy.

    Now you may be wondering what these assumptions have to do with reality.
After all, no one's perfect. But we often study ideal situations (especially in
math). For example, you've all studied geometry. Can anyone here draw a
perfectly straight line or a perfectly round circle? Yet, you've all studied such
objects.

    Our Goal: Develop strategies for our perfectly logical, self-interested play-
ers.

1.1.2 Developing Strategies: Tic Tac Toe

Now that we know what our players' goals are, we want to develop a strategy
to achieve them. We start with the familiar game of Tic Tac Toe.

Activity 1.1.1 Play Tic Tac Toe. Play several games of Tic TacToe
with an opponent. Make sure you take turns being the first player and the
second player. Develop a strategy for winning Tic Tac Toe. You may have a
different strategy for the first player and for the second player. Be as specific
as possible. You may need to consider several possibilities which depend on
what your opponent does.

 (a) Who wins? Player 1 or Player 2?

 (b) What must each player do in order to have the best possible outcome?

 (c) How did you develop your strategy?

 (d) How do you know it will always work?
    Let us note some characteristics of Tic Tac Toe.

   · There are two players.

   · Players have perfect information. This means each player knows what
       all of his or her own options are, what all of his or her opponent's options
       are, and both players know what the outcome of each option is. Addi-
       tionally, players know that both players have all of this information.

   · This game has a solution. A solution for a game consists of a strategy
       for each player and the outcome of the game when each player plays his
       or her strategy. In Tic Tac Toe, if both players play their best, the game
       will always end in a tie.

   · The game is finite. This means the game must end after a finite number
       of moves or turns. In other words, the game cannot go on forever. A
       game that is not finite is called infinite. Note, an infinite game may end
       after a finite number of turns, but there is no maximum number of turns
4                            CHAPTER 1. WHAT IS GAME THEORY?

   or process to ensure the game ends. In Tic Tac Toe, the game must end
   after 9 or fewer turns.

Activity 1.1.2 Perfect information, more examples. Can you think of
another example of a game with perfect information? What is an example of
a game that does not have perfect information?

Activity 1.1.3 Finite and infinite, more examples. Give some examples
of finite games and infinite games.

Definition 1.1.1 A strategy for a player is a complete way to play the game

regardless of what the other player does.                     

The choice of what a player does may depend on the opponent, but that choice

is predetermined before game play. For example, in the cake cutting game, it

doesn't matter which piece the "chooser" will pick, the "cutter" will always cut

evenly. Similarly, it doesn't matter how the cutter cuts, the chooser will always

pick the largest piece. In Tic Tac Toe, Player 2's strategy should determine

his first move no matter what Player 1 plays first. For example, if Player 1

plays the center square, where should Player 2 play? If Player 1 plays a corner,

where should Player 2 play?

Activity 1.1.4 Describe your favorite game. What is your favorite game?

   (a) Give a brief description of the game, including what it means to "win" or
        "lose" the game.

(b) How many players do you need?

   (c) Do the players have perfect information for the game?

(d) Is the game finite or can it go on forever?

 (e) Give some possible strategies for the player(s). Note, depending on the
       game, these strategies may not always result in a definite win, but they
       should suggest a way to increase a player's chances of winning (or not
       losing).

    We have established a few assumptions and looked at how to describe strate-
gies in some familiar games. Not all games easily fit into the context we will be
using throughout this text. But you might keep in mind some of your favorite
games and see how well the strategies and solutions can be applied to them.
In the next section we develop some useful notation for describing most of the
games we will study.

1.1.3 Check Your Understanding

1. True or False?
           True or False: If a player has perfect information, then they know

      exacty how their opponent will play the game.

2. True or False?
           True or False: The game of chess has perfect information.

3. True or False?
           True or False: The game of poker has perfect information

4. True or False?
           True or False: A rational player always wants to score as many points

      as possible.

5. True or False?
           True or False: A payoff for a player can have a negative value.
1.2. GAME MATRICES AND PAYOFF VECTORS                                5

1.2 Game Matrices and Payoff Vectors

We need a way to describe the possible choices for the players and the outcomes
of those choices. For now, we will stick with games that have only two players.
We will call them Player 1 and Player 2.

1.2.1 Setting up a Payoff Matrix

We begin with an example of the game of Matching Pennies, Suppose each
player has two choices: Heads (H) or Tails (T). If they choose the same side
of the coin, then Player 1 wins $1 from Player 2. If they don't match, then
Player 1 loses $1 to Player 2.

    We can represent all the possible outcomes of the game with a matrix.
Player 1's options will always correspond to the rows of the matrix, and Player
2's options will correspond to the columns. See Table 1.2.1, p. 5.

Table 1.2.1 A game matrix showing the strategies for each player

                                Player 2
                              Head Tail

              Player 1  Head
                        Tail

Definition 1.2.2 A payoff is the amount a player receives for a given outcome

of the game.                                                         

Now we can fill in the matrix with each player's payoff. Since the payoffs

to each player are different, we will use ordered pairs where the first number

is Player 1's payoff and the second number is Player 2's payoff. The ordered

pair is called the payoff vector. For example, if both players choose H, then

Player 1's payoff is $1 and Player 2's payoff is -$1 (since he loses to Player 1).

Thus the payoff vector associated with the outcome H, H is (1, -1).

We fill in the matrix with the appropriate payoff vectors in Table 1.2.3, p. 5

Table 1.2.3 A game matrix showing the payoff vectors

                              Player 2

                              H   T

              Player 1 H (1, -1) (-1, 1)

                        T (-1, 1) (1, -1)

    It is useful to think about different ways to quantify winning and losing.
What are some possible measures of value? For example, we could use money,
chips, counters, votes, points, amount of cake, etc.

    Remember, a player always prefers to win the MOST points (money, chips,
votes, cake), not just more than her opponent. If you want to study a game
where players simply win or lose (such as Tic Tac Toe), we could just use "1"
for a win and "-1" for a loss.

1.2.2 Revisiting the Assumptions

Recall that we said there are two Basic Assumptions, p. 2 we must make about
our players:

   · Our players are self-interested. This means they will always prefer the
       largest possible payoff. They will choose a strategy which maximizes
       their payoff.
6                    CHAPTER 1. WHAT IS GAME THEORY?

   · Our players are perfectly logical. This means they will use all the infor-
      mation available and make the choice that results in the largest payoff
      for themselves.

    It is important to note that each player also knows that his or her opponent
is also self-interested and perfectly logical!

Activity 1.2.1 Preferred payoffs. Determine best payoff in each of the
following.

   (a) Which payoff does a player prefer: 0, 2, or -2?

(b) Which payoff does a player prefer: -2, -5, or -10?

  (c) Which payoff does a player prefer: -1, -3, or 0?
    It may be strightforward to decide the best payoff for a player out of a list of

values, and it would be great if a player could just determine the biggest value
in the table and choose that strategy. However, when there are two players a
player may have to choose a strategy more carefully, since Player 1 can only
choose the row, and Player 2 can only choose the column. Thus, the outcome
of the game depends on BOTH players.

Example 1.2.4 A 2 × 2 Game. Suppose two players are playing a game
in which they can choose A or B with the payoffs given in the game matrix in
Table 1.2.5, p. 6.

Table 1.2.5 Payoff matrix for Activity 1.2.2

                        Player 2

                     A                                  B

                  Player 1 A (100, -100) (-10, 10)

                  B  (0, 0)  (-1, 1)

     In the following activity, we will try to determine what each player should

do.                                                             

Activity 1.2.2 Finding strategies. Use the game matrix given in Ta-

ble 1.2.5, p. 6.

   (a) Just by quickly looking at the matrix, which player appears to be able
        to win more than the other player? Does one player seem to have an
        advantage? Explain.

(b) Determine what each player should do. Explain your answer.

   (c) Compare your answer in (b) to your answer in (a). Did the player you
        suggested in (a) actually win more than the other player?

(d) According to your answer in (b), does Player 1 end up with the largest
      possible payoff (for Player 1) in the matrix?

   (e) According to your answer in (b), does Player 2 end up with the largest
        possible payoff (for Player 2) in the matrix?

  (f) Do you still think a player has an advantage in this game? Is it the same
       answer as in (a)?

Example 1.2.6 A 3 × 3 Game. Suppose there are two players with the
game matrix given in Table 1.2.7, p. 7.
1.2. GAME MATRICES AND PAYOFF VECTORS                           7

Table 1.2.7 Payoff matrix for Activity 1.2.3

                                Player 2

                             X  Y                      Z

     A (1000, -1000) (-5, 5) (-15, 15)

     Player 1 B (200, -200)     (0, 0)                 (-5, 5)

     C (500, -500) (20, -20) (-25, 25)

     In the following activity, we will try to determine what each player should

do.                                                             

Activity 1.2.3 More practice finding strategies. Use the game matrix

given in Table 1.2.7, p. 7.

(a) Just by quickly looking at the matrix, which player appears to be able
     to win more than the other player? Does one player seem to have an
     advantage? Explain.

(b) Determine what each player should do. Explain your answer.

(c) Compare your answer in (b) to your answer in (a). Did the player you
     suggested in (a) actually win more than the other player?

(d) According to your answer in (b), does Player 1 end up with the largest
      possible payoff (for Player 1) in the matrix?

(e) According to your answer in (b), does Player 2 end up with the largest
     possible payoff (for Player 2) in the matrix?

  (f) Do you still think a player has an advantage in this game? Is it the same
       answer as in (a)?

    This chapter has introduced you to who the players are and how to organize
strategies and payoffs into a matrix. In the next chapter we will study some
methods for how a player can determine his or her best strategy.

1.2.3 Check Your Understanding

1. Which payoff does a player prefer: 3, 1, or -5?

         A. 3
         B. 1
         C. -5
2. Which payoff does a player prefer: -5, -1, or -10?

         A. -1
         B. -5
         C. -10
3. Which payoff does a player prefer: 1/2, 0, or 5/6?

         A. 5/6
         B. 0
         C. 1/2
8               CHAPTER 1. WHAT IS GAME THEORY?

4. In the game matrix, Player 1 will always choose

         A. the row.

         B. the column
5. For the payoff vector (5, -5), Player 1's payoff is

   A. 5

         B. -5
6. Consider the following game matrix.

   Table 1.2.8

                                        Player 2

                                        C           D

                Player 1 A (5, -5) (-1, 1)

                B (2, -2) (-3, 3)

   What column should Player 2 choose?

         A. C

         B. D
7. Using the game matrix Table 1.2.8, p. 8.

           What row should Player 1 choose?

         A. A

         B. B
8. Using the game matrix Table 1.2.8, p. 8.

           Which player has the advantage in this game?

   A. Player 1
   B. Player 2
Chapter 2

Two-Person Zero-Sum Games

    In this chapter we will look at a specific type of two-player game. These are
often the first games studied in game theory as they can be straightforward to
analyze. All of our games in this chapter will have only two players. We will
also focus on games in which one player's win is the other player's loss.

2.1 Introduction to Two-Person Zero-Sum Games

In the examples from the last section, whatever amount one player won, the
other player lost.

Definition 2.1.1 A two player game is called a zero-sum game if the sum

of the payoffs to each player is constant for all possible outcomes of the game.

More specifically, the coordinates in each payoff vector must add up to the same

value for each payoff vector. Such games are sometimes called constant-sum

games instead.                                                   

We can always think of zero-sum games as being games in which one player's

win is the other player's loss.

Example 2.1.2 Zero-sum in Poker. Consider a poker game in which each

player comes to the game with $100. If there are five players, then the sum of

money for all five players is always $500. At any given time during the game,

a particular player may have more than $100, but then another player must

have less than $100. One player's win is another player's loss.  

Example 2.1.3 Zero-sum in Cake Division. Consider the cake division
game. We want to find the payoff matrix for this game. It is important to
determine what each player's options are first. How can the "cutter" cut the
cake? How can the "chooser" pick her piece? The payoff matrix is given in
Table 2.1.4, p. 10.

                                 9
10                      CHAPTER 2. TWO-PERSON ZERO-SUM GAMES

Table 2.1.4 Payoff matrix for Cake Cutting game.

                                                   Chooser

                        Larger Piece               Smaller Piece

Cutter     Cut Evenly            (half, half)               (half, half)
           Cut Unvenly
                        (small piece, large piece) (large piece, small piece)

    In order to better see that this game is zero-sum (or constant-sum), we
could give values for the amount of cake each player gets. For example, half
the cake would be 50%, a small piece might be 40%. Then we can rewrite the
matrix with the percentage values in Table 2.1.5, p. 10

Table 2.1.5 Payoff matrix, in percent of cake, for the Cake Cutting
game.

                                                  Chooser

                                        Larger Piece Smaller Piece

           Cutter  Cut Evenly           (50, 50)   (50, 50)
                   Cut Unvenly
                                        (40, 60)   (60, 40)

    In each outcome, the payoffs to each player add up to 100 (or 100%). In

more mathematical terms, the coordinates of each payoff vector add up to 100.

Thus the sum is the same, or constant, for each outcome.                  

    We can see from the matrix in Table 2.1.5, p. 10 that Player 2 will always

choose the larger piece, thus Player 1 does best to cut the cake evenly. The

outcome of the game is the strategy pair denoted [Cut Evenly, Larger Piece],

with resulting payoff vector (50, 50).

    But why are we going to call these games "zero-sum" rather than "constant-

sum"? We can convert any zero-sum game to a game where the payoffs actually

sum to zero.

Example 2.1.6 Poker Payoffs Revisited. Consider the above poker game

where each player begins the game with $100. Suppose at some point in the

game the five players have the following amounts of money: $50, $200, $140,

$100, $10. Then we could think of their gain as -$50, $100, $40, $0, -$90. What

do these five numbers add up to?                                          

Example 2.1.7 Convert the cake division payoffs so that the payoff vectors
sum to zero (rather than 100).

    The solution is given in Table 2.1.8, p. 10.

Table 2.1.8 Zero-sum payoff matrix for Cake Cutting game.

                                                  Chooser

                                        Larger Piece Smaller Piece

           Cutter  Cut Evenly           (0, 0)              (0, 0)
                   Cut Unvenly
                                        (-10, 10)  (10, -10)

    But let's make sure we understand what these numbers mean. For example,

a payoff of (0, 0) does not mean each player gets no cake, it means they don't

get any more cake than the other player. In this example, each player gets half

the cake (50%) plus the payoff.                                           

    When the game matrix is in the form of Example 2.1.7, p. 10, it is easy to

recognize a zero-sum game since each payoff vector has the form (a, -a) (or

(-a, a)).
2.1. INTRODUCTION TO TWO-PERSON ZERO-SUM GAMES                     11

2.1.1 An Election Campaign Game

Two candidates, Arnold and Bainbridge, are facing each other in a state elec-
tion. They have three choices regarding the issue of the speed limit on I-5:
they can support raising the speed limit to 70 MPH, they can support keeping
the current speed limit, or they can dodge the issue entirely. The next three
examples present three different payoff matrices for Arnold and Bainbridge.

Example 2.1.9 The Speed Limit Issue. The candidates have the infor-
mation given in Table 2.1.10, p. 11 about how they would likely fare in the
election based on how they stand on the speed limit.

Table 2.1.10 Percentage of the vote for Example 2.1.9.

                               Bainbridge

                     Raise Limit Keep Limit              Dodge
                                                         (40, 60)
        Raise Limit  (45, 55)    (50, 50)                (50, 50)
        Keep Limit                                       (40, 60)
Arnold  Dodge        (60, 40)    (55, 45)

                     (45, 55)    (55, 45)

                                                                                                    
Activity 2.1.1 Analysis of the election game. For the following questions,
assume Arnold and Bainbridge have the payoff matrix given in Example 2.1.9,
p. 11.

(a) Explain why Table 2.1.10, p. 11 is a zero-sum game.

(b) What should Arnold choose to do? What should Bainbridge choose to
      do? Be sure to explain each candidate's choice. And remember, a player
      doesn't just want to win, he wants to get THE MOST votes. For exam-
      ple, you could assume these are polling numbers and that there is some
      margin of error, thus a candidate prefers to have a larger margin over his
      opponent.

(c) What is the outcome of the election? What percentage of the vote does
     each candidate get?

 (d) Does Arnold need to consider Bainbridge's strategies in order to decide on
       his own strategy? Does Bainbridge need to consider Arnold's strategies
       in order to decide on his own strategy? Explain your answer.

Example 2.1.11 A New Scenario. Bainbridge's mother is injured in
a highway accident caused by speeding. The new payoff matrix is given in
Table 2.1.12, p. 11.

Table 2.1.12 Percentage of the vote for Example 2.1.11.

                               Bainbridge

                     Raise Limit Keep Limit              Dodge
                                                         (40, 60)
        Raise Limit  (45, 55)    (10, 90)                (50, 50)
        Keep Limit                                       (40, 60)
Arnold  Dodge        (60, 40)    (55, 45)

                     (45, 55)    (10, 90)

                                                                                                    
Activity 2.1.2 Analysis of the second scenario. For the following ques-
tions, assume Arnold and Bainbridge have the payoff matrix given in Exam-
ple 2.1.11, p. 11.

(a) Explain why Table 2.1.12, p. 11 is a zero-sum game.
12             CHAPTER 2. TWO-PERSON ZERO-SUM GAMES

(b) What should Arnold choose to do? What should Bainbridge choose to
      do? Be sure to explain each candidate's choice.

(c) What is the outcome of the election?

 (d) Does Arnold need to consider Bainbridge's strategies in order to decide on
       his own strategy? Does Bainbridge need to consider Arnold's strategies
       in order to decide on his own strategy? Explain your answer.

Example 2.1.13 A Third Scenario. Bainbridge begins giving election
speeches at college campuses and monster truck rallies. The new payoff matrix
is given in Table 2.1.14, p. 12.

Table 2.1.14 Percentage of the vote for Example 2.1.13.

                                            Bainbridge

                                  Raise Limit Keep Limit  Dodge
                                                          (60, 40)
               Raise Limit        (35, 65)  (10, 90)      (50, 50)
               Keep Limit                                 (65, 35)
       Arnold  Dodge              (45, 55)  (55, 45)

                                  (40, 60)  (10, 90)

                                                                                                    
Activity 2.1.3 Analysis of the third scenario. For the following questions,
assume Arnold and Bainbridge have the payoff matrix given in Example 2.1.13,
p. 12.

(a) Explain why Table 2.1.14, p. 12 is a zero-sum game.

(b) What should Arnold choose to do? What should Bainbridge choose to
      do? Be sure to explain each candidate's choice.

(c) What is the outcome of the election?

 (d) Does Arnold need to consider Bainbridge's strategies in order to decide on
       his own strategy? Does Bainbridge need to consider Arnold's strategies
       in order to decide on his own strategy? Explain your answer.

Activity 2.1.4 Changing the strategy. In each of the above scenarios, is
there any reason for Arnold or Bainbridge to change his strategy? If there is,
explain under what circumstances it makes sense to change strategy. If not,
explain why it never makes sense to change strategy.

2.1.2 Equilibrium Pairs

Chances are, in each of the exercises above, you were able to determine what
each player should do. In particular, if both players play your suggested strate-
gies, there is no reason for either player to change to a different strategy.

Definition 2.1.15 A pair of strategies is an equilibrium pair if neither player

gains by changing strategies.                                       

    For example, consider the game matrix from Example 1.2.4, p. 6, Table 1.2.5,

p. 6.

Table 2.1.16 Payoff matrix for Example 1.2.4.

                                            Player 2

                                  A                   B

               Player 1 A (100, -100) (-10, 10)

                               B  (0, 0)    (-1, 1)
2.1. INTRODUCTION TO TWO-PERSON ZERO-SUM GAMES  13

    You determined that Player 2 should choose to play B, and thus, Player 1
should play B (i.e., we have the strategy pair [B, B]). Why is this an equilibrium
pair? If Player 2 plays B, does Player 1 have any reason to change to strategy
A? No, she would lose 10 instead of 1. If Player 1 plays B, does Player 2
have any reason to change to strategy A? No, she would gain 0 instead of 1.
Thus neither player benefits from changing strategy, and so we say [B, B] is an
equilibrium pair.

    For now, we can use a "guess and check" method for finding equilibrium
pairs. Take each outcome and decide whether either player would prefer to
switch. Remember, Player 1 can only choose a different row, and Player 2 can
only choose a different column. In our above example there are four outcomes
to check: [A, A], [A, B], [B, A], and [B, B]. We already know [B, B] is an
equilibrium pair, but let's check the rest. Suppose the players play [A, A].
Does Player 1 want to switch to B? No, she'd rather get 100 than 0. Does
Player 2 want to switch to B? Yes! She'd rather get 10 than -100. So [A, A]
is NOT an equilibrium pair since a player wants to switch. Now check that for
[A, B] Player 1 would want to switch, and for [B, A] both players would want
to switch. Thus [A, B] and [B, A] are NOT equilibrium pairs. Now you can
try to find equilibrium pairs in any matrix game by just checking each payoff
vector to see if one of the players would have wanted to switch to a different
strategy.

    Generally, when we define a game matrix for a game, our rows and columns
will be named with the strategy choices for the players. However, mathemat-
ically, we can just think of the matrix of payoff vectors without the row and
column labels. In this case, we often identify the payoff vector itself as an
equilibrium or equilibrium point. In Table 1.2.5, p. 6, for example, we
would say the payoff vector (-1, 1) is an equilibrium point.

Activity 2.1.5 Checking equilibrium pairs. Are the strategy pairs you
determined in the three election scenarios, Table 2.1.10, p. 11, Table 2.1.12,
p. 11, and Table 2.1.14, p. 12, equilibrium pairs? In other words, would either
player prefer to change strategies? (You don't need to check whether any other
strategies are equilibrium pairs.)

Activity 2.1.6 Using "guess and check". Use the "guess and check"
method to determine any equilibrium points for the following payoff matri-
ces. It can also be helpful to identify the associated row and column for the
equilibrium pair.

(a)  [                   ]

        (2, -2) (2, -2)

        (1, -1) (3, -3)

(b)  [                   ]

        (3, -3) (1, -1)

        (2, -2) (4, -4)

(c)  [                           ]

        (4, -4) (5, -5) (4, -4)

        (3, -3) (0, 0) (1, -1)

    After trying the above examples, do you think every game has an equilib-
rium pair? Can games have multiple equilibrium pairs?

Activity 2.1.7 Existence of equilibrium pairs. Do all games have equi-
librium pairs?
14          CHAPTER 2. TWO-PERSON ZERO-SUM GAMES

Activity 2.1.8 Multiple equilibrium pairs. Can a game have more than
one equilibrium pair?

    The next three activities give you a few more games to practice finding
equilibrium pairs.

Activity 2.1.9 Rock, paper, scissors. Consider the game ROCK, PA-
PER, SCISSORS (Rock beats Scissors, Scissors beat Paper, Paper beats Rock).
Construct the payoff matrix for this game. Does it have an equilibrium pair?
Explain your answer.

Activity 2.1.10 Battle of the networks. Two television networks are
battling for viewers for 7 pm Monday night. They each need to decide if they
are going to show a sitcom or a sporting event. Table 2.1.17, p. 14 gives the
payoffs as percent of viewers.

Table 2.1.17 Payoff matrix for Battle of the Networks.

            Network 1  Sitcom      Network 2
                       Sports  Sitcom Sports
                               (55, 45) (52, 48)
                               (50, 50) (45, 55)

(a) Explain why this is a zero-sum game.

(b) Does this game have an equilibrium pair? If so, find it and explain what
      each network should do.

  (c) Convert this game to one in which the payoffs actually sum to zero.If
       a network wins 60% of the viewers, how much more than 50% of the
       viewers does it have?

Activity 2.1.11 Competitive advantage. This game is an example of
what economists call Competitive Advantage. Two competing firms need
to decide whether or not to adopt a new type of technology. The payoff matrix
is in Table 2.1.18, p. 14. The variable a is a positive number representing the
economic advantage a firm will gain if it is the first to adopt the new technology.

Table 2.1.18 Payoff matrix for Competitive Advantage.

    Firm B  Adopt New Tech                  Firm A  Stay Put
            Stay Put           Adopt New Tech        (a, -a)
                                                      (0, 0)
                                      (0, 0)
                                     (-a, a)

(a) Explain the payoff vector for each strategy pair. For example, why should
      the pair [Adopt New Tech, Stay Put] have the payoff (a, -a)?

(b) Explain what each firm should do.

 (c) Give a real life example of Competitive Advantage.

    We've seen how to describe a zero-sum game and how to find equilibrium
pairs. We've tried to decide what each player's strategy should be. Each player
may need to consider the strategy of the other player in order to determine
his or her best strategy. But we need to be careful, although our intuition can
be useful in deciding the best strategy, we'd like to be able to be more precise
about finding strategies for each player. We'll learn some of these tools in the
next section.
2.2. FINDING STRATEGIES                                                  15

2.1.3 Check Your Understanding

1. True or False?
           True or False: The following game matrix is a zero-sum game.

            [                        ]
              (10, 20)   (-10, 40)
             (-20, 50)
                          (0, 30)

2. True or False?
           True or False: The following game matrix is a zero-sum game.

            [                        ]
              (10, 20)   (-20, 10)
             (-10, 20)    (20, 10)

3. Determine which payoff vector is an equilbrium point for the following

matrix.     [                   ]

               (1, -1) (0, 0)

               (3, -3) (2, -2)

A. (2, -2)
B. (1, -1)
C. (0, 0)

         D. (3, -3)

4. True or False?
           True or False: A zero-sum game must have an equilibrium pair (or

      point).

5. True or False?
           True or False: A zero-sum game can have more than one equilibrium

      pair (or point).

6. True or False?
           True or False: The game of Rock-Paper-Scissors has an equilibrium

      pair.

2.2 Finding Strategies

Recall that in a zero-sum game, we know that one player's win is the other
player's loss. Furthermore, we know we can rewrite any zero-sum game so
that the player's payoffs are in the form (a, -a). Note, this works even if a is
negative; in which case, -a is positive.

2.2.1 Simplifying a Zero-Sum Game Matrix

Example 2.2.1 A Simpler Payoff Matrix. Consider the zero-sum game
with payoff matrix in Table 2.2.2, p. 15. For simplicity our payoff matrix con-
tains only the payoffs and not the strategy names; but Player 1 still chooses a
row and Player 2 still chooses a column.

Table 2.2.2 The payoff matrix for Example 2.2.1.

            Player 1          Player 2
                         (1, -1) (-0, 0)
                         (-1, 1) (-2, 2)
16  CHAPTER 2. TWO-PERSON ZERO-SUM GAMES

    If we know we are playing a zero-sum game, then the use of ordered pairs
seems somewhat redundant: if Player 1 wins 1, then we know that Player 2
must lose 1 (win -1). Thus, if we KNOW we are playing a zero-sum game, we
can simplify our notation by just using Player 1's payoffs. The above matrix
in Table 2.2.2, p. 15 can be simplified as in Table 2.2.3, p. 16.

Table 2.2.3 The payoff matrix for Example 2.2.1 using only Player
1's payoffs.

    Player 1                Player 2
                             10
                            -1 -2

                                                                                                    
    When simplifying, keep a few things in mind:

    1. You MUST know that the game is zero-sum.

    2. If it is not otherwise specified, the payoffs represent Player 1's payoffs.

    3. You can always give a similar matrix representing Player 2's payoffs.
       However, due to (2), you should indicate that the matrix is for Player
       2. For example, Player 2's payoff matrix would be given by Table 2.2.4,
       p. 16.

       Table 2.2.4 The payoff matrix for Example 2.2.1 using only
       Player 2's payoffs.

    Player 1                Player 2
                            -1 0
                             12

    4. Both players can make strategy decisions by considering only Player 1's
       payoff matrix. (Why?) Just to test this out, by looking only at the
       matrix in Table 2.2.3, p. 16 determine which strategy each player should
       choose.

    In this last example, it should be clear that Player 1 is looking for rows
which give her the largest payoff. This is nothing new. However, Player 2 is now
looking for columns which give Player 1 the SMALLEST payoff. (Why?)

2.2.2 Dominated Strategies

Now that we have simplified our notation for zero-sum games, let's try to find
a way to determine the best strategy for each player.

Example 2.2.5 A 2 × 3 Game. Consider the zero-sum game given in
Table 2.2.6, p. 16.

Table 2.2.6 Payoff matrix for Example 2.2.5.

    Player 1                  Player 2
                             1 02
                            -1 -2 2

    Determine which row Player 1 should choose. Is there any situation in

which Player 1 would choose the other row?       

Example 2.2.7 Another 2 × 3 Game. Consider the zero-sum game given
in Table 2.2.8, p. 17.
2.2. FINDING STRATEGIES                                               17

Table 2.2.8 Payoff matrix for Example 2.2.7.

                      Player 1    Player 2
                                 1 02
                                -1 -2 3

Determine which row Player 1 should choose. Is there any situation in

which Player 1 would choose the other row?                            

In Example 2.2.5, p. 16, no matter what Player 2 does, Player 1 would

always choose Row 1, since every payoff in Row 1 is greater than or equal to

the corresponding payoff in Row 2 (1  -1, 0  -2, 2  2). In Example 2.2.7,

p. 16, this is not the case: if Player 2 were to choose Column 3, then Player

1 would prefer Row 2. In Example 2.2.5, p. 16 we would say that Row 1

dominates Row 2.

Definition 2.2.9 A strategy X dominates a strategy Y if every entry for X

is greater than or equal to the corresponding entry for Y . In this case, we say

Y is dominated by X.

If strategy X dominates stratgy Y , we can write X  Y .               

In mathematical notation, let aik be the value in the ith row and kth column.

Similarly, ajk is the value in the jth row and kth column. The ith row dominates

the jth row if aik  ajk for all k, and aik > ajk for at least one k.

This definition can also be used for Player 2: we consider columns instead

of rows. If we are looking at Player 1's payoffs, then Player 2 prefers smaller

payoffs. Thus one column X dominates another column Y if all the entries in

X are smaller than or equal to the corresponding entries in Y .

Here is the great thing: we can always eliminate dominated strategies!

(Why?) Thus, in Example 2.2.5, p. 16, we can eliminate Row 2, as in Fig-

ure 2.2.10, p. 17.

                                Player 2

                                      102
                      Player 1

                                      -1 -2 2

Figure 2.2.10 Row 2 is dominated by Row 1.

    Now it is easy to see what Player 2 should do, as we can ignore the crossed
out row.

    In Example 2.2.7, p. 16, we cannot eliminate Row 2 since it is not dominated
by Row 1. However, it should be clear that Column 2 dominates Column 3
(remember, Player 2 prefers SMALLER values). Thus we can eliminate Column
3 as in Figure 2.2.11, p. 17.

                                                                    Player 2

                                                                102
                                               Player 1

                                                                -1 -2 3

Figure 2.2.11 Column 3 is dominated by Column 2.                 Now, in Fig-

    AFTER eliminating Column 3, Row 1 dominates Row 2.
ure 2.2.12, p. 18 we can eliminate Row 2.
18  CHAPTER 2. TWO-PERSON ZERO-SUM GAMES

    Player 1      Player 2
              102
              -1 -2 3

Figure 2.2.12 After eliminating Column 3, Row 2 is dominated by Row 1.
    Again, in the reduced game it is easy to determine what each player should

do.
Activity 2.2.1 Check equilibrium pairs. Check that the strategy pairs
we determined in Example 2.2.5, p. 16 and Example 2.2.7, p. 16 are, in fact,
equilibrium pairs.

                         Eliminating Dominated Strategies.

         Given a zero-sum game matrix with Player 1's payoffs. We find
    a dominated strategy with the following process. Note, you can
    compare either rows or columns first.

        1. Choose two rows.

        2. Compare the corresponding values in the two rows.

        3. If in each comparison, one row has values less than or equal to
            the values in the other row, eliminate the row with the smaller
            values.

        1. Choose two columns.

        2. Compare the corresponding values in the two columns.

        3. If in each comparison, one column has values greater than or equal
            to the values in the other column, eliminate the column with the
            larger values.

         Once you have eliminated a row or column, you can repeat the
    process with the remaining rows or columns, ignoring any eliminated
    values. The process of elimininating dominated strategies is helpful for
    simplifying the game.

    Now, look back at the election examples from Subsection 2.1.1, p. 11 and
apply the process of eliminating dominated strategies.

Activity 2.2.2 Eliminating dominated strategies. Use the idea of elim-
inating dominated strategies to determine what each player should do in the
Arnold/ Bainbridge examples in Table 2.1.10, p. 11, Table 2.1.12, p. 11, and
Table 2.1.14, p. 12. Do you get the same strategy pairs as you determined in
the related activities (Activity 2.1.1, p. 11, Activity 2.1.2, p. 11, Activity 2.1.3,
p. 12)?

    The next three activities provide more practice in using dominated strate-
gies to find equilibrium pairs.

Activity 2.2.3 More practice with dominated strategies. Use the idea
of eliminating dominated strategies to determine any equilibrium pairs in the
zero-sum game given in Table 2.2.13, p. 19. Note, since it is a zero-sum game
we need only show Player 1's payoffs. Explain all the steps in your solution. If
you are unable to find an equilibrium pair, explain what goes wrong.
2.2. FINDING STRATEGIES  19

Table 2.2.13 Payoff matrix for Activity 2.2.3.

                                                        Player 2
                                                  WX Y Z
                                           A 1 0 0 10
                             Player 1 B -1 0 -2 9
                                           C111 8
                                           D -2 0 0 7

Activity 2.2.4 Determine equilibrium pairs. Determine any equilibrium
pairs in the zero-sum game given in Table 2.2.14, p. 19. Explain all the steps
in your solution. If you are unable to find an equilibrium pair, explain what
goes wrong.

Table 2.2.14 Payoff matrix for Activity 2.2.4.

                                                        Player 2
                                                  W X YZ
                                           A1 2 34
                             Player 1 B 0 -1 0 5
                                           C -1 3 2 4
                                           D 0 1 -1 1

Activity 2.2.5 Practice finding equilibrium pairs. Determine any equi-
librium pairs in the zero-sum game given in Table 2.2.15, p. 19. Explain all the
steps in your solution. If you are unable to find an equilibrium pair, explain
what goes wrong.

Table 2.2.15 Payoff matrix for Activity 2.2.5.

                                                        Player 2
                                                W X YZ
                                          A -2 0 3 20
                           Player 1 B 1 -2 -3 0
                                          C 10 -10 -1 1
                                          D 0 0 10 15

Activity 2.2.6 A more challenging example. Determine any equilibrium
pairs in the zero-sum game given in Table 2.2.16, p. 19. Explain all the steps
in your solution. If you are unable to find an equilibrium pair, explain what
goes wrong.

Table 2.2.16 Payoff matrix for Activity 2.2.6.

                                                        Player 2
                                                WX YZ
                                         A -2 0 3 20
                           Player 1 B 1 -2 -5 -3
                                         C 10 -10 -1 1
                                         D 0 0 10 8

    Chances are you had trouble determining an equilibrium pair for the game
in Activity 2.2.6, p. 19. Does this mean there isn't an equilibrium pair? Not
necessarily, but we are stuck if we try to use only the idea of eliminating
dominated strategies. So we need a new method.
20  CHAPTER 2. TWO-PERSON ZERO-SUM GAMES

2.2.3 Maximin and Minimax Strategies

We might think of our next method as the "worst case scenario," or "extremely
defensive play." The idea is that we want to assume our opponent is the best
player to ever live. In fact, we might assume our opponent is telepathic. So
no matter what we do, our opponent will always guess what we are going to
choose.

Example 2.2.17 Playing Against the Best. Assume you are Player 1,

and you are playing against this "infinitely smart" Player 2. Consider the game

in Table 2.2.13, p. 19. If you pick row A, what will Player 2 do? Player 2 will

pick column X or Y. Try this for each of the rows. Which row is your best

choice? If you pick A, you will get 0; if you pick B, you will get -2; if you pick

C, you will get 1; and if you pick D you will get -2. Thus, your best choice is

to choose C and get 1. Now assume you are Player 2, and Player 1 is "infinitely

smart." Which column is your best choice? If you pick W, Player 1 will get 1

(you will get -1); if you pick X, Player 1 will get 1; if you pick Y, Player 1 will

get 1; and if you pick Z, Player 1 will get 10. Thus, you can choose W, X, or

Y (since you want Player 1 to win the least) and get -1.                   

Activity 2.2.7 A new method. Using the method described in Exam-
ple 2.2.17, p. 20, determine what each player should do in the game in Ta-
ble 2.2.14, p. 19.

Activity 2.2.8 More practice with the new method. Using the method
described in Example 2.2.17, p. 20, determine what each player should do in
the game in Table 2.2.15, p. 19.

    After working through a few examples can you describe more generally the
process used in Example 2.2.17, p. 20? What is Player 1 looking for in each
row? Then how does she choose which row to play? What is Player 2 looking
for in each column? How does he choose which column to play?

Activity 2.2.9 Generalizing the new method. Generalize the method
described in Example 2.2.17, p. 20. In other words, give a general rule for how
Player 1 should determine his or her best move. Do the same for Player 2.

Activity 2.2.10 The new method and equlibrium points. What do you
notice about using this method on the games in Table 2.2.13, p. 19, Table 2.2.14,
p. 19, and Table 2.2.15, p. 19? Is the solution an equilibrium pair?

Activity 2.2.11 The new method on the challenging example. Now try
this method on the elusive payoff matrix in Table 2.2.16, p. 19. What should
each player do? Do you think we get an equilibrium pair? Explain.

    The strategies we found using the above method have a more official name.
Player 1's strategy is called the maximin strategy. Player 1 is maximizing
the minimum values from each row. Player 2's strategy is called the minimax
strategy. Player 2 is minimizing the maximum values from each column. No-
tice, we can find the maximin and minimax strategies for any zero-sum game.
But do our players always want to use these strategies? Will they always result
in an equilibrium pair? The next five activities explore these questions.

    Finding the Maximin and Minimax Strategies.

        Given a zero-sum game matrix with Player 1's payoffs. We find the
    maximin strategy with the following process.

    1. Find the smallest value in each row.
2.2. FINDING STRATEGIES  21

        2. From the smallest values you found in step (1), choose the largest.

        3. Player 1 chooses the row corresponding to the value found in (2).

         Given a zero-sum game matrix with Player 1's payoffs. We find the
     minimax strategy with the following process.

        1. Find the largest value in each column.

        2. From the largest values you found in step (1), choose the smallest.

        3. Player 2 chooses the column corresponding to the value found in
            (2).

         Since we often will look for the maximin strategy for Player 1 and
     the minimax strategy for Player 2 in a game, this strategy pair will be
     referred to as the maximin/minimax strategy (or strategy pair).

Activity 2.2.12 Look for dominated strategies. Let's consider another
game matrix, given in Table 2.2.18, p. 21. Explain why you cannot use domi-
nated strategies to find an equilibrium pair. Do you think there is an equilib-
rium pair for this game (why or why not)?

Table 2.2.18 Payoff matrix for Activity 2.2.12.

                                                        Player 2
                                                W X YZ
                                          A -2 0 3 20
                           Player 1 B 1 2 -3 0
                                          C 10 -10 -1 1
                                          D 0 0 10 15

Activity 2.2.13 Find the maximin/minimax strategy. If both play-
ers use the maximin/ minimax strategy, what is the outcome of the game in
Table 2.2.18, p. 21?

Activity 2.2.14 Predicting a maximin strategy. In the game in Ta-
ble 2.2.18, p. 21, if Player 1's opponent can guess that Player 1 will choose to
use a maximin strategy, is Player 1 better off not using the maximin strategy?

Activity 2.2.15 Deviating from the maximin/minimax strategy. Sup-
pose both players initially decide to use the maximin/minimax strategy in the
game in Table 2.2.18, p. 21. Is Player 1 better off choosing a different strat-
egy? If Player 2 guesses a change, is Player 2 better off changing strategies?
Continue this line of reasoning for several iterations. What strategies do each
of the players choose? Is at least one player always better off switching strate-
gies? Can we conclude that the maximin/ minimax strategy does not lead to
an equilibrium pair?

Activity 2.2.16 Comparing examples. Compare the game in Activ-
ity 2.2.12, p. 21 to what happens in Activity 2.2.3, p. 18, Activity 2.2.4, p. 19,
and Activity 2.2.5, p. 19. Can you identify any key differences between the
games in Activity 2.2.12, p. 21 and Activity 2.2.3, p. 18, Activity 2.2.4, p. 19,
and Activity 2.2.5, p. 19?

    Given a zero-sum matrix game, we can find equilibruim pairs (if they exist)
by the "guess and check" method, by eliminating dominated strategies, and by
looking for the minimax/maximin strategies. You should be able to apply all
22                CHAPTER 2. TWO-PERSON ZERO-SUM GAMES

three methods and think about which method might be the most appropriate
for a given matrix game. For example, although "guess and check" should
always find an equilibrium point if it exists, it may be very tedious to apply to
a really large matrix. The maximin/minimax method might be much faster.

2.2.4 Check Your Understanding

1. Suppose we are looking for dominated strategies in the following matrix.

    Table 2.2.19

                  Player 1         Player 2
                                 -1 0 2
                                  5 -2 1
                                  0 14

    Which row can we eliminate?

    A. Row 1

    B. Row 2

    C. Row 3

         D. We can't eliminate any rows.

2. Suppose we are looking for dominated strategies in the matrix Table 2.2.19,
      p. 22.
           Which column can we eliminate?

    A. Column 1

    B. Column 2

    C. Column 3

         D. We can't eliminate any columns.
3. Suppose we are looking for dominated strategies in the following matrix.

    Table 2.2.20

                  Player 1           Player 2
                                 -2 -1 0
                                  0 2 -1
                                  1 3 -4

    Which row or column can we eliminate?

    A. Row 1

    B. Row 2

    C. Row 3

    D. Column 1

    E. Column 2

    F. Column 3

    G. We can't eliminate any rows or columns.
2.2. FINDING STRATEGIES                                   23

4. Suppose we are looking for dominated strategies in the following matrix.

Table 2.2.21

                         Player 1   Player 2
                                   3 0 -1
                                   1 2 -3
                                   10 3

Which row or column can we eliminate?

A. Row 1
B. Row 2

C. Row 3
D. Column 1
E. Column 2
F. Column 3

         G. We can't eliminate any rows or columns.
5. This exercise finds Player 1's maximin strategy.

(a) Click on or circle the smallest value in each row.

Table 2.2.22

                         Player 1   Player 2
                                   3 0 -1
                                   1 2 -3
                                   10 3

(b) If Player 1 wants to play the maximin stategy, she should play the
      row with the largest of the values from (a). Thus, she should play

                A. Row 1.
                B. Row 2.
                C. Row 3.
6. This exercise finds Player 2's minimax strategy.

(a) Click on or circle the largest value in each column.

Table 2.2.23

                         Player 1   Player 2
                                   3 0 -1
                                   1 2 -3
                                   10 3

(b) If Player 2 wants to play the minimax stategy, she should play the
      column with the smallest of the values from (a). Thus, she should
      play

A. Column 1.
B. Column 2.
C. Column 3.
24                CHAPTER 2. TWO-PERSON ZERO-SUM GAMES

7. Looking at the game Table 2.2.21, p. 23, the value of the maximin strategy
      for Player 1 is .
           The value of the minimax strategy for Player 2 is .
           These two values are equal ("yes" or "no") .

8. True or False?
           True or False: The game Table 2.2.21, p. 23, has an equilibrium pair.

      Hint. Try using what you know about the maximin and minimax strate-
      gies.

9. This exercise finds Player 1's maximin strategy.

    (a) Click on or circle the smallest value in each row.

    Table 2.2.24

                  Player 1      Player 2
                            -4 -2 5
                             213
                             5 -3 -4

    (b) If Player 1 wants to play the maximin stategy, she should play the
          row with the largest of the values from (a). Thus, she should play

                A. Row 1.
                B. Row 2.
                C. Row 3.
10. This exercise finds Player 2's minimax strategy.

    (a) Click on or circle the largest value in each column.

    Table 2.2.25

                  Player 1                    Player 2
                                           -4 -2 5
                                            2 13
                                            5 -3 -4

    (b) If Player 2 wants to play the minimax stategy, she should play the
          column with the smallest of the values from (a). Thus, she should
          play

    A. Column 1.

    B. Column 2.

                C. Column 3.
11. Consider the game given in the table.

    Table 2.2.26

                  Player 1      Player 2
                            -4 -2 5
                             213
                             5 -3 -4

    The value of the maximin strategy for Player 1 is .
    The value of the minimax strategy for Player 2 is .
    These two values are equal ("yes" or "no") .
2.3. PROBABILITY AND EXPECTED VALUE                        25

12. True or False?
           True or False: The game Table 2.2.26, p. 24, has an equilibrium pair.

      Hint. Try using what you know about the maximin and minimax strate-
      gies.

2.3 Probability and Expected Value

Many games have an element of chance. In order to model such games and de-
termine strategies, we should understand how mathematicians use probability
to represent chance.

2.3.1 Some Basic Probability

You are probably a little bit familiar with the idea of probability. People
often talk about the chance of some event happening. For example, a weather
forecast might say there is a 20% chance of rain. Determining the chance of
rain can be difficult, so we will stick with some easier examples.

    Consider a standard deck of 52 playing cards. What is the chance of drawing
a red card? What is the probability of drawing a red card? Is there a difference
between chance and probability? Yes! The probability of an event has a very
specific meaning in mathematics.

Definition 2.3.1 The probability of an event E is the number of different
outcomes resulting in E divided by the total number of equally likely outcomes.
In mathematical symbols,

              number of different outcomes resulting in E
   P (E) = total number of equally likely outcomes .

                                                                                                     
    Notice that the probability of E will always be a number between 0 and 1.

An impossible event will have probability 0; an event that always occurs will

have probability 1.

    Returning to our standard deck of 52 playing cards, the probability of
drawing a red card is 12 , not 50%. Although we can convert between probability
and percent (since 0.5 converted to percent is 50%), it is important to answer

a question about probability with a probability, not a percent.

Example 2.3.2 Drawing a Particular Suit. Given a standard deck of
playing cards, what is the probability of drawing a heart?

Answer. You might say since there are four suits, and one of the suits is

hearts, you have a probability of 14 . You'd be correct, but be careful with this
reasoning. This works because each suit has the same number of cards, so each

suit is equally likely. Another way the calculate the probability is to count

the number of hearts (13) divided by the number of cards (52). Thus, we get

a  probability  of  13  =  1  =  0.25.                     
                    52     4

Example 2.3.3 A Card is Missing. Now suppose the ace of spades is
missing from the deck. What is the probability of drawing a heart?

Answer. As before, there are still four suits in the deck, so it might be
tempting to say the probability is still 14 . But we'd be wrong! Each suit is no
longer equally likely since, it is slightly less likely that we draw a spade. Each
26  CHAPTER 2. TWO-PERSON ZERO-SUM GAMES

individual card is still equally likely, though. So now

    P (drawing a heart) = number of hearts = 13 = 0.255.
                                  number of cards 51

    As you can see, it is now slightly more likely that we draw a heart if the

ace of spades is removed from the deck.                                     

    Now try to compute some probabilities on your own.

Activity 2.3.1 Probability with a single die. Consider rolling a single die.
List the possible outcomes. Assuming that it is a fair die, are all the outcomes
equally likely? What is the probability of rolling a 2? What is the probability
of rolling an even number?

Activity 2.3.2 Probability with red and green dice. Now consider
rolling two fair dice, say a red die and a green die.

(a) How many equally likely outcomes are there? List them.

(b) What is the probability that you get a two on the red die and a four on
      the green die?

(c) What is the probability that you roll a three on the red die?

(d) What is the probability that you roll a two and a four?

(e) What is the probability that you roll a three on at least one of the dice?

  (f) Compare your answers in (b) and (c) with your answers in (d) and (e).
       Are they the same or different? Explain.

Activity 2.3.3 Probability with two of the same dice. Again consider
rolling two fair dice, but now we don't care what color they are.

(a) Does this change the number of equally likely outcomes from Activ-
     ity 2.3.2, p. 26? Why or why not? It may be helpful to list the possible
     outcomes.

(b) What is the probability that you get snake eyes (two ones)?

(c) What is the probability that you roll a two and a four?

(d) What is the probability that you roll a three on at least one of the dice?

 (e) What is the probability that you roll a two OR a four?
Activity 2.3.4 Sums of dice. Suppose we roll two dice and add them.

(a) List the possible sums.

(b) What is the probability that you get a total of seven on the two dice?

(c) What is the probability that you get a total of four when you roll two
     dice?

 (d) Are the events of getting a total of seven and getting a total of four
       equally likely? Explain.

    It is important to note that just because you can list all of the possible
outcomes, they may not be equally likely. As we see from Activity 2.3.4, p. 26,
although there are 11 possible sums, the probability of getting any particular
sum (such as seven) is not 111 .
2.3. PROBABILITY AND EXPECTED VALUE                                27

2.3.2 Expected Value

Now that we have defined the probability for an outcome, we need a way to
calculate payoffs for games of chance.

Definition 2.3.4 The expected value of a game of chance is the average net

gain or loss that we would expect per game if we played the game many times.

We compute the expected value by multiplying the value of each outcome by

its probability of occurring and then add up all of the products.  

For example, suppose you toss a fair coin. If it lands on Heads, you win 25

cents. If it lands on Tails, you lose 25 cents. The probability of getting Heads

is 1/2, as is the probability of getting Tails. The expected value of the game is

                (       1  )(  1  )

                        2 × .25 + 2 × (-.25) = 0.

    Thus, you would expect an average payoff of $0, if you were to play the
game several times. Note, the expected value is not necessarily the actual value
of playing the game.

Activity 2.3.5 Expected value and a two-coin game. Consider a game
where you toss two coins. If you get two Heads, you win $2. If you get a Head
and a Tail, you win $1, if you get two Tails, you lose $4. Find the expected
value of the game.

Hint. First you need to find the probability of each event. Think about
equally likely events.

Activity 2.3.6 Play the two-coin game. Now play the game in Activ-
ity 2.3.5, p. 27 the indicated number of times. Give your actual payoff and
compare it to the expected value.

(a) One time.

(b) Ten times.

(c) Twenty-five times.

    Is there a single possible outcome where you would actually win or lose the
exact amount computed for the expected value? If not, why do we call it the
expected value?

Activity 2.3.7 Expected value of roulette. A standard roulette wheel
has 38 numbered slots for a small ball to land in: 36 are marked from 1 to 36,
with half of those black and half red; two green slots are numbered 0 and 00.
An allowable bet is to bet on either red of black. This bet is an even money
bet, which means if you win you receive twice what you bet. Many people
think that betting black or red is a fair game. What is the expected value of
betting $1000 on red? Is this a fair game? Explain.

Activity 2.3.8 Another roulette example. Considering again the roulette
wheel, if you bet $100 on a particular number and the ball lands on that number,
you win $3600. What is the expected value of betting $100 on Red 4?

    After finding the expected value of the games in the above activities, what
do you think the expected value can tell us about a game? Can you use it
to decide whether you should play that game of chance or not? When will a
game be advantageous for the player? We often care whether a game is fair.
Can the expected value help you determine if a game is fair?
28                   CHAPTER 2. TWO-PERSON ZERO-SUM GAMES

Activity 2.3.9 Expected value and fairness. Use the idea of expected
value to explain fairness in a game of chance.

    The next activity is a good challenge for exploring expected value.

Activity 2.3.10 A betting game with two dice. You place a bet and roll
two fair dice. If you roll a 7 or an 11, you receive your bet back (you break
even). If you roll a 2, a 3, or a 12, then you lose your bet. If you roll anything
else, you receive half of the sum you rolled in dollars. How much should you
bet to make this a fair game?

Hint. It might be helpful to begin with a table showing the possible sums,
their probability, and the payoff for each.

    In the next section we use the ideas of probability and expected value to
understand how set up a payoff matrix for a game of chance.

2.3.3 Check Your Understanding

1. In a standard deck of cards, find the probability of randomly drawing an

    Ace. Give your answer to at least 3 decimal places.

    The probability is          .

2. In a standard deck of cards, find the probability of randomly drawing a

    face card (Jack, Queen, King). Give your answer to at least 3 decimal

    places.

    The probability is          .

3. In a standard deck of cards, find the probability of randomly drawing an

    even numbered card. Give your answer to at least 3 decimal places.

    The probability is          .

4. An urn contains 3 red balls, 2 green balls, 4 multicolored balls. Find the

    probability of drawing a green ball. Give your answer to at least 3 decimal

    places.

    The probability is          .

5. An urn contains 3 red balls, 2 green balls, 4 multicolored balls. Find the

    probability of drawing a solid colored ball. Give your answer to at least 3

    decimal places.

    The probability is          .

6. An urn contains 3 red balls, 2 green balls, 4 multicolored balls. Suppose

    you win $1 if you draw a multicolored ball, but lose $1 if you draw a red

    or green ball. Find the expected value of the game. Give your answer to

    at least 3 decimal places.

    The expected value is          .

7. An urn contains 3 red balls, 2 green balls, 4 multicolored balls. Suppose

    you win $2 if you draw a green ball, you lose $1 if you draw a multicolored

    ball, and you win $0 if you draw a red ball. Find the expected value of

    the game.

    The expected value is          .

8. A game of chance is fair if the expected value is

    A. 0.

    B. positive.

    C. negative.
2.4. A GAME OF CHANCE                29

2.4 A Game of Chance

Now that we have worked with expected value, we can begin to analyze some
simple games that involve an element of chance.

Example 2.4.1 One-Card Stud Poker. We begin with a deck of cards in

which 50% are Aces (you can use Red cards for Aces) and 50% are Kings (you

can use Black cards for Kings). There are two players and one dealer. The

play begins by each player putting in the ante (1 chip). Each player is dealt

one card face down. WITHOUT LOOKING AT THEIR CARD, the players

decide to Bet (say, 1 chip) or Fold. Players secretly show the dealer their choice

of Bet or Fold. If one player Bets and the other Folds, then the player who

Bet wins. If both Bet or both Fold, then Ace beats King (or Red beats Black);

winner takes the pot (all the chips from the ante and any bets). If there is a

tie, they split the pot.             

Activity 2.4.1 Play One-Card Stud Poker. Play the game several times
with two other people (so you have two players and a dealer). Keep track of
the strategy choices of the players and the resulting payoffs.

Activity 2.4.2 Guess a strategy. Based on playing the game, determine a
possible winning strategy.

Activity 2.4.3  Check if zero-sum.   Is this a zero-sum game? Why or why
not?            Effect of the deal.  Does the actual deal affect the choice

Activity 2.4.4
of strategy?

Activity 2.4.5 Strategy choices. On any given deal, what strategy choices
does a player have?

    Before moving on, you should attempt to determine the payoff matrix.
The remainder of this section will be more meaningful if you have given some
thought to what the payoff matrix should be. It is OK to be wrong at this
point, it is not OK to not try.

Activity 2.4.6 Determine a possible payoff matrix. Write down a
possible payoff matrix for this game.

    Now let's work through creating the payoff matrix for One-Card Stud Poker.

Activity 2.4.7 Payoff for [Bet, Fold]. If Player 1 Bets and Player 2 Folds,
does it matter which cards were dealt? How much does Player 1 win? How
much does Player 2 lose? What is the payoff vector for [Bet, Fold]? (Keep in
mind your answer to Activity 2.4.3, p. 29.)

Activity 2.4.8 Payoff for [Fold, Bet]. If Player 1 Folds and Player 2 Bets,
does it matter which cards were dealt? What is the payoff vector for [Fold,
Bet]?

Activity 2.4.9 Payoff and the actual deal. If both players Bet, does the
payoff depend on which cards were dealt?

    To determine the payoff vector for [Bet, Bet] and [Fold, Fold] we will need
to consider which cards were dealt. We can use some probability to determine
the remaining payoff vectors.

Activity 2.4.10 Probability of each deal. There are four possible out-
comes of the deal (what cards could have been dealt to each player?). List
them. What is the probability that each occurs? Remember, the probability
of an event is a number between 0 and 1.
30  CHAPTER 2. TWO-PERSON ZERO-SUM GAMES

Activity 2.4.11 Payoff for each deal with [Bet, Bet]. Consider the pair
of strategies [Bet, Bet]. For each possible deal, determine the payoff vector.
For example, if the players are each dealt an Ace (Red), how much does each
player win? Again, keep in mind your answer to Activity 2.4.3, p. 29.

    In order to calculate the payoff for [Bet, Bet], we need to take a weighted
average of the possible payoff vectors in Activity 2.4.11, p. 30. In particular,
we will "weight" a payoff by the probability that it occurs. Recall that this is
the expected value, Definition 2.3.4, p. 27. We will calculate the expected
value separately for each player.

Activity 2.4.12 Player 1's expected value for [Bet, Bet]. Find the
expected value for [Bet, Bet] for Player 1.

Activity 2.4.13 Player 2's expected value for [Bet, Bet]. Find the
expected value for [Bet, Bet] for Player 2.

    The pair of expected values from Activity 2.4.12, p. 30 and Activity 2.4.13,
p. 30 is the payoff vector for [Bet, Bet].

Activity 2.4.14 Justify using expected value as the payoff. Explain
why it should make sense to use the expected values for the payoffs in the
matrix for the strategy pair [Bet, Bet].

Hint. Think about what a player needs to know to choose a strategy in a
game of chance.

    We can use a similar process to find the payoff vector for [Fold, Fold].

Activity 2.4.15 Repeat for [Fold, Fold]. Repeat Activity 2.4.11, p. 30,
Activity 2.4.12, p. 30, and Activity 2.4.13, p. 30 for the pair of strategies [Fold,
Fold].

Activity 2.4.16 Complete payoff matrix. Summarize the above work by
giving the completed payoff matrix for One-Card Stud Poker.

    Now that you have done all the hard work of finding the payoff matrix
for One-Card Stud Poker, we can analyze our two-player zero-sum game using
the techniques we learned in the previous sections. It is also important to
see how the mathematical solution compares to our conjectured solution from
Activity 2.4.2, p. 29.

Activity 2.4.17 Best strategy for One-Card Stud. Use the payoff matrix
to determine the best strategy for each player. If each player uses their best
strategy, what will be the outcome of the game?

Activity 2.4.18 Compare strategies. Compare the strategy you found in
Activity 2.4.17, p. 30 to your suggested strategy in Activity 2.4.2, p. 29. In par-
ticular, discuss how knowing the payoff matrix might have changed your strat-
egy. Also compare the payoff that results from the strategy in Activity 2.4.17,
p. 30 to the payoff that results from your original strategy in Activity 2.4.2,
p. 29.

    Since One-Card Stud Poker has an element of chance, we should see what
happens if we play the game several times using the strategy from Activ-
ity 2.4.17, p. 30.

Activity 2.4.19 Payoff for repeated One-Card Stud. Use the payoff
matrix to predict what the payoff to each player would be if the game is played
ten times.

Activity 2.4.20 Play repeated One-Card Stud. Play the game ten
times using the best strategy. How much has each player won or lost after ten
hands of One-Card Stud Poker? Compare your answer to your prediction in
2.4. A GAME OF CHANCE                                                 31

Activity 2.4.19, p. 30. Does the actual payoff differ from the theoretical payoff?
If so, why do you think this might be?

Activity 2.4.21 Fair game. Explain why this game is considered fair.

Example 2.4.2 Generalized One-Card Stud Poker. In One-Card Stud

Poker we anted one chip and bet one chip. Now, suppose we let players ante

a different amount and bet a different amount (although players will still ante

and bet the same amount as each other). Suppose a player antes a and bets b.

How might this change the game?                                       

Activity 2.4.22 Payoff matrix for Generalized One-Card Stud. Use
the method outlined for One-Card Stud Poker to determine the payoff matrix
for Generalized One-Card Stud Poker.

Activity 2.4.23 Strategy for Generalized One-Card Stud. Does the
strategy change for the generalized version of the game? Explain.

    For more of a challenge with probability, you can think about what happens
if we change the number of Kings in the deck.

Activity 2.4.24 One-Card Stud with more Kings. Suppose you are
playing the regular version of One-Card Stud Poker from Example 2.4.1, p. 29,
but now the deck contains 25% Aces and 75% Kings.

(a) Do you think having fewer Aces would change your strategy? Why or
     why not?

(b) Does the number of Kings in the deck change the the payoff vector for
      [Bet, Fold] and [Fold, Bet]?

(c) Calculate the expected value for the [Bet, Bet] and [Fold, Fold] strategy
     pairs.To make this a little easier, assume the deck has infinitely many
     cards, so that the probability of a player being dealt an Ace doesn't
     change if the other player was dealt an Ace. In other words, each player
     has a probability of .25 of being dealt an Ace. Now the probability of the
     deal Ace, Ace is .25 × .25.

(d) Give the payoff matrix for the game. How does it compare to the standard
      version of the game?

 (e) Does the strategy for the game change if the percentage of Kings changes?

    Now that we have analyzed several zero-sum games, we can see how im-
portant it is to find any equilibrium pairs. In the next section we explore
equilibrium strategies in more detail.

Check Your Understanding

1. True or False?
           True or False: Neither player has an advantage in One-Card Stud

      Poker.
2. True or False?

           True or False: One-Card Stud Poker has an equilibrium pair.
3. In One-Card Stud Poker, Player 1 wants to play Bet

         A. always.

         B. never.

         C. more often than Fold.
32                           CHAPTER 2. TWO-PERSON ZERO-SUM GAMES

         D. less often than Fold.
4. The expected payoff to a player in One-Card Stud Poker over the long

      run is .

5. True or False?
           True or False: The actual payoff to a player in One-Card Stud Poker

      is the same as the expected payoff.

2.5 Equilibrium Points

In this section, we will try to gain a greater understanding of equilibrium
strategies in a game. In general, we call the pair of equilibrium strategies an
equilibrium pair, while we call the specific payoff vector associated with an
equilibrium pair an equilibrium point.

Activity 2.5.1 Find equilibrium         points.  Determine the equilibrium
point(s) for the following games.

     [                    ]
(a) (2, -2)      (-1, 1)
                 (-1, 1)
       (2, -2)

                 (-1, 1)              
         (0, 0)   (0, 0)      (0, 0)
                             (-1, 1)
(b) (-1, 1)

    (0, 0) (1, -1) (0, 0)

Activity 2.5.2 An observation about equilibrium points. What do you
notice about the values of the equilibrium points of the games in Activity 2.5.1,
p. 32?

    We now get to the main question in this section.

Question 2.5.1 Can two equilibrium points for a two-player zero-sum game

have different values?                           

    By experimenting with some examples, try to create an example of a game

with two equilibrium points where those points have different values for one

of the players. If you can successfully create such an example, you will have

answered the question. But just because you can't find an example, that

doesn't mean one doesn't exist!

Activity 2.5.3 Experimenting with different values. Let's see if we can
create a 2 × 2 matrix for a zero-sum game that has two equilibrium points with
different values. Let's assume the two equilbrium are (1, -1) and (2, -2).

(a) Create a matrix with (1, -1) and (2, -2) in the same row. Can they both
     be equilibria, or does one player want to switch?

(b) Create a matrix with (1, -1) and (2, -2) in the same column. Can they
      both be equilibria, or does one player want to switch?

(c) Now place (1, -1) and (2, -2) diagonally in the matrix (different rows
     and columns). Try to fill in values for the other two places in the matrix
     so that (1, -1) is an equilibrium. Is (2, -2) an equilibrium in any of your
     examples?Remember, if (1, -1) is an equilibrium, then 1 must be the
     biggest value for Player 1 in the column and 1 is the smallest in the row,
     so that -1 is the biggest for Player 2 in the row.

(d) Do you think it is possible to have both (1, -1) and (2, -2) be equilibrium
      points in a 2 × 2 matrix? Explain your answer based on your examples.
2.5. EQUILIBRIUM POINTS             33

    After trying several examples, you might be beginning to believe that the
answer to Question 2.5.1, p. 32 is "no." Now you are ready to try to prove the
following theorem.

Theorem 2.5.2 Solution Theorem for Zero-Sum Games. Every equi-
librium point of a two-person zero-sum game has the same value.

    Let's start with the 2 × 2 case. We will use a proof by contradiction. We
will assume the theorem is false and show that we get a logical contradiction.
Once we reach a logical contradiction (a statement that is both true and false),
we can conclude we were wrong to assume the theorem was false; hence, the
theorem must be true. Make sure you are comfortable with the logic of this
before moving on.

    Since we want to assume the theorem is false, we assume we have a two-
player zero-sum game with two different equilibrium values. Since we don't
have a specific example of such a game, we want to represent the game in a
general form. In particular, we can represent the general game

[                                ]
 (a, -a)                 (c, -c) .
 (d, -d)                 (b, -b)

    Note that if a is negative, then -a is positive; thus, every possible set of
values is represented by this matrix. We want to look at the possible cases for
equilibria.

Activity 2.5.4 Equilibria in Column 1. Explain what goes wrong if
(a, -a) and (d, -d) are equilibria with a = d.

Hint. Think about the different cases, such as a < d, a > d. Can you show
that in each case either (a, -a) or (d, -d) is NOT an equilibrium?

Activity 2.5.5 Equilibria in the same column/row. Generalize your
answer to Activity 2.5.4, p. 33 to explain what goes wrong if the two equilibria
with different values are in the same column. Similarly, explain what happens
if the two equilibria are in the same row.

Activity 2.5.6 Diagonal equilibria. Does the same explanation hold if the
two equilibria are diagonal from each other? (Explain your answer!)

    From your last answer, you should see that we need to do more work to
figure out what happens if the equilibria are diagonal. So let's assume that the
two equilibria are (a, -a) and (b, -b) with a = b. It might be helpful to draw
the payoff matrix and circle the equilibria.

Activity 2.5.7 A player prefers the value of an equilibrium. Construct
a system of inequalities using the fact that a player prefers an equilibrium point
to another choice. For example, Player 1 prefers a to d. Thus, a > d. List
all four inequalities you can get using this fact. You should get two for each
player. Remember that Player 1 can only compare values in the same column
since he has no ability to switch columns. If necessary, convert all inequalities
to ones without negatives. (Algebra review: -5 < -2 means 5 > 2.)

Activity 2.5.8 Create strings of inequalities. Now string your inequali-
ties together. For example, if a < b and b < c then we can write a < b < c. Be
careful, the inequalities must face the same way; we cannot write a > b < c.

Activity 2.5.9 You now have a contradiction. Explain why you now
have a contradiction (a statement that must be false). We can now conclude
our assumption that a = b was wrong.
34                 CHAPTER 2. TWO-PERSON ZERO-SUM GAMES

Activity 2.5.10 Diagonal case for c and d. Repeat the above argument
(Activity 2.5.7, p. 33, Activity 2.5.8, p. 33, and Activity 2.5.9, p. 33) for the case
that the two equilibria are (d, -d) and (c, -c) with d = c.

Activity 2.5.11 Summarize conclusion. Explain why you can conclude
that all equilibria in a 2 × 2 two-player zero-sum game have the same value.

    We just worked through the proof, step-by-step, but now you need to put
all the ideas together for yourself.

Activity 2.5.12 The complete proof. Write up the complete proof for the
2 × 2 case in your own words.

Activity 2.5.13 Generalizing to a larger game. Can you see how you
might generalize to a larger game matrix? You do not need to write up a proof
of the general case, just explain how the key ideas from the 2 × 2 case would
apply to a bigger game matrix.

Hint. Think about equilibria in (a) the same row, (b) in the same column,
or (c) in a different row and column.

    We've seen that any two equlibrium points must have the same value. How-
ever, it is important to note that just because an outcome has the same value
as an equilibrium point, that does not mean it is also an equilibrium point.

Activity 2.5.14 Equal values may not be equilibria. Give a specific
example of a game matrix with two payoff vectors that are (0, 0), where one is
an equilibrium point and the other is not.

    Working through the steps of a mathematical proof can be challenging. As
you think about what we did in this section, first make sure you understand
the argument for each step. Then work on understanding how the steps fit
together to create the larger argument.

    The next section summarizes all our work with finding equilibrium points
for zero-sum games.

Check Your Understanding

1. True or False?
           True or False: If a < b < c < d then a < d.

2. True or False?
           True or False: If a < b then -a < -d.

3. True or False?
           True or False: If a < b < c < d < a then we have a contradiction.

4. True or False?
           True or False: If (a, -a) and (b, -b) are two equilibria in a zero-sum

      game, then a = b.

5. True or False?
           True or False: If (3, -3) is an equilibrium in a zero-sum game, then

      every equilibrium in the game has payoff vector (3, -3).

6. True or False?

    True or False: In the matrix

                   [  (-2, 2) (-1, 1)             ]

                      (-1, 1) (2, -2)

      both (-1, 1) payoff vectors are equilibria.

7. True or False?
           True or False: If (3, -3) is an equilibrium in a zero-sum game, then
2.6. STRATEGIES FOR ZERO-SUM GAMES AND EQUILIBRIUM POINTS35

      every payoff vector (3, -3) is a equilibrium.

2.6 Strategies for Zero-Sum Games and Equilib-
     rium Points

Throughout this chapter, we have been trying to find solutions for two player
zero-sum games by deciding what two rational players should do. In this
section, we will try to understand where we are with solving two-player zero-
sum games. The activities in this section are intended to review the concepts of
dominated strategies, equilibrium points, and the maximin/minimax strategies.
By working through your own examples, we hope to tie these concepts together
and ask some bigger questions about equilibrium points. For example, should
a player always play an equilibrium strategy? Will the maximin/minimax
strategy always find an equilibrium point if one exists? What should a player
do if no equlibrium exists? Although the formal answers to some of these
questions are outside the scope of this book, you should be able to make some
good conjectures about equilibrium points and rational solutions to two-player
zero-sum games.

Activity 2.6.1 Random 2 × 2 matrix. Write down a random payoff (zero-
sum) matrix with two strategy choices for each player.

Activity 2.6.2 Random 3 × 3 matrix. Write down a random payoff (zero-
sum) matrix with three strategy choices for each player.

Activity 2.6.3 Random 4 × 4 matrix. Write down a random payoff (zero-
sum) matrix with four strategy choices for each player.

Activity 2.6.4 Analyze several examples. Exchange your list of matrices
with another student in the class. For each matrix you have been given

  (a) try to determine any dominated strategies, if they exist.

  (b) try to determine any equilibrium points, if they exist.

  (c) determine the maximin and minimax strategies for Player 1 and Player
       2, respectively. Can you always find these?

Activity 2.6.5 Classify examples. Now combine all the examples of payoff
matrices in a group of 3 or 4 students. Make a list of the examples with
equilibrium points and a list of examples without equilibrium points. If you
have only one list, try creating examples for the other list. Based on your lists,
do you think random payoff matrices are likely to have equilibrium points?

    We want to use lists of matrices as experimental examples to try to answer
some of the remaining questions we have about finding rational solutions for
games and equilibrium points. If you don't feel you have enough examples,
you are welcome to create more or gather more from your classmates.

Activity 2.6.6 Playing an equilibrium strategy. If a matrix has an equi-
librium point, can a player ever do better to not play an equilibrium strategy?
Explain.

Activity 2.6.7 Equilibia and maximin/minimax. If a matrix has an
equilibrium point, does the maximin/minimax strategy always find it? Explain.

Activity 2.6.8 No equilibria and maximin/minimax. If a matrix does
NOT have an equilibrium point, should a player always play the maximin/
minimax strategy? Explain.
36  CHAPTER 2. TWO-PERSON ZERO-SUM GAMES

Activity 2.6.9 Strategy and games with no equilibria. If a matrix
does NOT have an equilibrium point is there an ideal strategy for each player?
Explain.

Activity 2.6.10 Summarize the connections. Write a brief summary of
the connections you have observed between finding a rational solution for a
game and equilibrium points.

    Now you should have an understanding of how to find equilibrium strategies
in two-player zero-sum games. The main advantage of equilibrium strategies
is that if both players play them, neither player would have gained by playing
a different strategy. Thus, we can think of the equilibrium strategies as the
solution to the game for two rational players. But what should our players do
if the game has no equilibrium point? We will look more closely at games with
no equilibrium point in the next chapter.

Check Your Understanding

1. True or False?
           True or False: Every zero-sum game has at least one equilibrium.

2. True or False?
           True or False: Every zero-sum game has a maximin/minimax strategy.

3. True or False?
           True or False: If a zero-sum game has an equilibrium, then the players

      should play the corresponding strategies.

4. True or False?
           True or False: In a zero-sum game if Player 1 plays an equilibrium

      strategy, then Player 2 does best to play the equilibrium strategy.

5. True or False?
           True or False: In a zero-sum game with an equilibrium, if Player 1

      does not play an equilibrium strategy, then Player 2 does best to play the
      equilibrium strategy.

6. True or False?
           True or False: In a zero-sum game with an equilibrium, Player 1's max-

      imin strategy is an equilibrium strategy and Player 2's minimax strategy
      is an equilibrium strategy.

7. True or False?
           True or False: In a zero-sum game without an equilibrium, players still

      do best to play the maximin/minimax strategies.

2.7 Popular Culture: Rationality and Perfect In-
     formation

In this section, we will look at applications of rationality and perfect informa-
tion in popular culture. We present films with connections to game theory and
suggest some related questions for essays or class discussion.

    The movie Dr. Strangelove or: How I Learned to Stop Worrying and Love
the Bomb (1964) depicts the cold war era with the USA and the Soviet Union
on the brink of atomic war.

Question 2.7.1 Society would generally consider General Jack Ripper to be

irrational. What is his goal or his optimal payoff? Give evidence that he is, in

fact, acting rationally in light of his goal.  
2.7. POPULAR CULTURE: RATIONALITY AND PERFECT INFORMATION37

Question 2.7.2 Explain how the Soviet's Doomsday Machine is supposed

to be the ultimate deterrent to nuclear war. How does the lack of perfect

information impact the effectiveness of the Doomsday Machine?          

In the movie The Princess Bride (1987) the Dread Pirate Roberts and

kidnapper Vizzini engage in a battle of wits in which Vizzini is to deduce

which goblet contain a lethal poison.

Question 2.7.3 In your own words describe how the poison scene demonstrates

that knowing that both players have the same knowledge can help one deduce

additional information. In other words, just knowing that one player has all the

information is not enough; that player, must also know that the other player

has the same knowledge.                                                

Question 2.7.4 Of course, in the poison scene, both players break the rules.

How does this impact the players' ability to use perfect information?  

Now try to apply the ideas of rationality and perfect information to your

own popular culture examples.

Question 2.7.5 Consider a game-theoretic scenario in a novel or film of your

choice. Are the players rational? What are the players' goals, and are they

making choices which will maximize their payoff? Explain.              

Question 2.7.6 Consider the statement "One of the main differences between

horror films and suspense films is that in horror films characters behave ir-

rationally while in suspense films they behave rationally." Do you agree or

disagree with this statement? Give an example of a suspense film and a horror

film with evidence from the films that supports your position.         

Question 2.7.7 Think of other films where two characters engage in a "game."

What are the assumptions of the players? Do they have perfect information?

Does the amount of information a player has give him or her an advantage?

Explain.                                                               

Question 2.7.8 Give an example from a film, current events, or your own life

where if one player "breaks the rules," while the other player assumes perfect

knowledge (both players know the possible strategies and outcomes), it will

change the outcome of the "game."                                      

Question 2.7.9 Find a news article that describes a political or economic

situation a being a zero-sum game. Do you agree that the situation is a zero-

sum game? Discuss how viewing the situation as a zero-sum game affects the

behavior of the "players."                                             
Chapter 3

Repeated Two-Person Zero-
sum Games

    If we are presented with a two-person zero-sum game we know that our
first step is to look for an equilibrium point. If a game has an equilibrium
point, then we know that our players should play the corresponding strategy
pair. In this case the equilibrium pair and its payoff vector is the solution to
the game. In this chapter we will explore games that do not necessarily have
an equilibrium point. We will also try to determine what a player should do if
they play the game repeatedly.

3.1 Introduction to Repeated Games

Now that we are experts at finding equilibrium pairs, what happens when a
game doesn't have any equilibrium pairs? What should our players do? As we
saw in Section 2.6, p. 35, if there is no equilibrium point then no matter which
strategies are played, at least one player wants to switch.

Activity 3.1.1  A 2 × 2 repeated game. Consider the following zero-sum
game
                [        ]
                   1 0.
                   -1 2

(a) Does this game have an equilibrium pair?

(b) Play this game with an opponent 10 times. Tally your wins and losses.

(c) Describe how you chose which strategy to play. Describe how your op-
     ponent chose which strategy to play.

(d) When playing the game several times, does it make sense for either player

                   39
40  CHAPTER 3. REPEATED TWO-PERSON ZERO-SUM GAMES

       to play the same strategy all the time? Why or why not?

    Up until this point we have used the term "strategy" to mean which row
or column a player chooses to play. Now we want to refer to how a player
plays a repeated game as the player's strategy. In order to avoid confusion,
in repeated games we will define some specific strategies.

Definition 3.1.1 In a repeated game, if a player always plays the same row

or column, we say that she is playing a pure strategy.                 

    For example, if Player 1 always plays Row A, we say she is playing pure

strategy A.

Definition 3.1.2 If a player varies which row or column he plays, then we say

he is playing a mixed strategy.                                        

    For example, if a player plays Row A 40% of the time and Row B 60% of

the time, we will say he is playing a (.4, .6) strategy, as we generally use the

probability rather than the percent. The probabilities of each strategy will be

listed in the same order as the strategies in the matrix.

    It is not enough just to determine how often to play a strategy. Suppose

Player 1 just alternates rows in Activity 3.1.1, p. 39. Can Player 2 "out-guess"

Player 1? What might be a better way for Player 1 to play?

    We'd really like to find a way to determine the best mixed strategy for each

player in a repeated game. Let's start with what we already know: games

with equilibrium points. If a game has an equilibrium pair of strategies, would

a player want to play a mixed strategy? Recall that a strategy pair is an

equilibrium pair if neither player gains by switching strategy.

Example 3.1.3 Repeating a Game with an Equilibrium. Consider the

following zero-sum game          [      ]

                                    -1 1 .
                                    02

    This game has an equilibrium pair. Convince yourself that if this game is

played repeatedly, each player should choose to play a pure strategy.  

    Thus, if the game has an equilibrium we know that players will play the pure

strategies determined by the equilibrium pairs. So let's get back to thinking

about games without equilibrium pairs. If we play such a game once, can we

predict the outcome? What about if we repeat the game several times, can

we predict the outcome? Think about tossing a coin. If you toss it once,

can you predict the outcome? What if you toss it 100 times, can you predict

the outcome? Not exactly, but we can say what we expect: if we toss a coin

100 times we expect to have half of the coins turn up heads and half turn up

tails. This may not be the actual outcome, but it is a reasonable prediction.

Now is a good time to remind yourself about finding the expected value,

Definition 2.3.4, p. 27.

    Recall the familiar game of Rock-Paper-Scissors: Rock beats Scissors, Scis-

sors beat Paper, and Paper beats Rock. Using the payoff matrix and experi-

mentation, we will try to determine the best strategy for this game.

Activity 3.1.2 RPS payoff matrix. Construct a game matrix for Rock-
Paper-Scissors.

Activity 3.1.3 RPS and equilibrium points. Is Rock-Paper-Scissors a
zero-sum game? Does it have an equilibrium point? Explain.

Activity 3.1.4 Play RPS. We want to look at what happens if we repeat
Rock-Paper-Scissors.

(a) Play the game ten times with an opponent. Record the results (list
3.1. INTRODUCTION TO REPEATED GAMES  41

       strategy pairs and payoffs for each player).

 (b) Describe any strategy you used to play Rock-Paper-Scissors.

 (c) Reflect on your chosen strategy. Does it guarantee you a win? What
       should it mean to win in a repeated game? What are the strengths and
       weaknesses of your strategy?

 (d) Discuss your strategy with your opponent. After sharing your ideas for
       a strategy, can you improve your previous strategy?

    Although you may have come up with a good strategy, let's see if we can't
decide what the "best" strategy should be for Rock-Paper-Scissors.

Activity 3.1.5 Exploring some strategies. Let's assume we are playing
Rock-Paper-Scissors against the smartest player to ever live. We will call such
an opponent the "perfect" player. You can think of this player as one who can
figure out your strategy easily.

 (a) Explain why it is not a good idea to play a pure strategy; i.e., to play
       only Rock, only Paper, or only Scissors.

 (b) Does it make sense to play one option more often than another (for
       example, Rock more often than Paper)? Explain.

 (c) How often should you play each option?

 (d) Do you want to play in a predictable pattern or randomly? What are
       some advantages and disadvantages of a pattern? What are some advan-
       tages and disadvantages of a random strategy?

    Hopefully, you concluded that the best strategy against our perfect player
would be to play Rock, Paper, Scissors 1/3 of the time each, and to play
randomly. We can say that our strategy is to play each option randomly with
a probability of 1/3, and call this the Random(1/3, 1/3, 1/3) strategy.

Activity 3.1.6 Testing the random strategy. Let's try out the Random(1/
3, 1/3, 1/3) strategy

 (a) Using this strategy, what do you predict the long term payoff will be for
       Player 1? For Player 2?

 (b) Let's check our prediction. Using a die, let 1 and 2 represent Rock, 3
       and 4 represent Paper, and 5 and 6 represent Scissors. Play the game
       20 times with someone in class where each player rolls to determine the
       choice of Rock, Paper, or Scissors. Keep track of the strategy pairs and
       payoffs. What was the total payoff for each player? At this point, if you
       still feel that you have a better strategy, try your strategy against the
       random one to see what happens!

 (c) How did the actual outcome compare to your predicted outcome? What
       do you expect would happen if you play the game 100 times? (Or more?)

    Using ideas about probability and expected value we can more precisely
predict the long term payoff for each player when playing a random mixed
strategy.

Activity 3.1.7 Expected payoff when both players play the random
strategy. Assume both players are using the Random(1/3, 1/3, 1/3) strategy.

 (a) List all the possible outcomes for a single game. An outcome is a strategy
       pair and the corresponding payoff, for example [R, P], (-1, 1).
42  CHAPTER 3. REPEATED TWO-PERSON ZERO-SUM GAMES

(b) What is the probability that any particular pair of strategies will be
      played? Are the strategy pairs equally likely?

(c) Using these probabilities and payoffs, calculate the expected value of the
     game for each player.

Activity 3.1.8 Strategy for the repeated 2 × 2 game. Now consider the
matrix from Activity 3.1.1, p. 39:

                             [        ]
                                      1 0.
                                -1 2

     See if you can determine how often Player 1 should play each row, and how
often Player 2 should play each column. Try testing your proposed strategy
(you may be able to use a variation on the dice as we saw in Activity 3.1.6, p. 41).
Write up any conjectured strategies and the results from playing the game with
your strategy. Do you think you have come up with the best strategy? Explain.

     You may have had an idea about the best way to play Rock-Paper-Scissors
before working through this section, but how can we find solutions to other
games, such as the one in Activity 3.1.8, p. 42? We don't want to just use a
"guess and check" method. Especially since there are infinitely many possible
mixed strategies to try! The rest of the chapter will develop mathematical
methods for solving repeated games with no equilibrium point.

Check Your Understanding

1. True or False?
           True or False: In Rock-Paper-Scissors, the best strategy is to always

      play Rock.

2. True or False?
           True or False: In Rock-Paper-Scissors, the best strategy is to play

      Rock more often than Paper or Scissors.

3. True or False?
           True or False: In Rock-Paper-Scissors, the best strategy is to play

      Rock, then Paper, then Scissors.

4. True or False?
           True or False: The following game has an equilibruim.

                          [                       ]
                           (10, -10)  (-10, 10)
                           (-20, 20)
                                        (0, 0)

5. Suppose the following game is played repeatedly.

                          [                       ]
                           (10, -10)  (-10, 10)
                           (-20, 20)
                                        (0, 0)

    Player 1 should play

    A. Pure strategy Row 1.

    B. Pure strategy Row 2.

    C. A mixed strategy, varying Row 1 and Row 2.
3.2. MIXED STRATEGIES: GRAPHICAL SOLUTION                         43

6. Suppose the following game is played repeatedly.

                      [  (10, -10) (-10, 10)  ]

                         (-20, 20) (0, 0)

Player 2 should play

A. Pure strategy Column 1.
B. Pure strategy Column 2.

C. A mixed strategy, varying Column 1 and Column 2.

7. True or False?
           True or False: The following game has an equilibruim.

                      [                    ]
                       (10, -10)   (0, 0)
                       (-20, 20)  (-1, 1)

8. Suppose the following game is played repeatedly.

                      [                    ]
                       (10, -10)   (0, 0)
                       (-20, 20)  (-1, 1)

Player 1 should play

A. Pure strategy Row 1.

B. Pure strategy Row 2.

C. A mixed strategy, varying Row 1 and Row 2.

9. Suppose the following game is played repeatedly.

                      [  (10, -10) (0, 0)   ]

                         (-20, 20) (-1, 1)

Player 2 should play

         A. Pure strategy Column 1.

         B. Pure strategy Column 2.

         C. A mixed strategy, varying Column 1 and Column 2.
10. True or False?

           True or False: If a repeated game has an equilibrium, then the players
      should play a pure strategy.
11. True or False?

           True or False: In a repeated game with no equilibrium, it is better to
      play a mixed strategy with a predictable pattern.

3.2 Mixed Strategies: Graphical Solution

We know for games with an equilibrium, the maximin/minimax strategies will
find an equilibrium solution. In this section we will learn a method for finding
the maximin/minimax mixed strategies for a repeated game. This method
will use graphs of lines and their intersection point to find the probability with
which a player should play each row or column.
44  CHAPTER 3. REPEATED TWO-PERSON ZERO-SUM GAMES

    Let's continue to consider the game given in Activity 3.1.1, p. 39 by

    [        ]
       1 0.
       -1 2

    In order to make our analysis easier, let's name the row and column strate-
gies as in Table 3.2.1, p. 44.

Table 3.2.1 Example matrix with named strategies

                                                  CD
                                           A1 0
                                           B -1 2

    We want to determine how often Player 1 should play A and how often she
should play B.

Activity 3.2.1 Conjecture a strategy. First it is good to test your instinct.
Do you think she should play one of the strategies more often than the other?
If so, which strategy should she play the most?

    What we are really trying to find is the probability with which Player 1
plays A (or B). Since we know that the probabilities sum to one, if we can find
one probability, then we know the other.

    Here is one way to do this. Let p be the probability that Player 1 plays B.
Let m be the payoff to Player 1. Since we are trying to find a mixed strategy
for Player 1, we will pick a strategy for Player 2 and try to determine the
possible payoffs for Player 1.

    Let us determine some pairs (p, m) for Table 3.2.1, p. 44.

    · Step 1. Assume Player 2 plays pure strategy C.

     Step 1a. Assume Player 1 plays pure strategy A.
       Find the probability, p, and payoff, m, if Player 1 always plays A.

       If Player 1 plays pure strategy A, then she never plays B. Thus the
       probability she plays B is 0. Hence,

       p = 0.

    In the case where Player 1 plays A and Player 2 plays C, what is
    the payoff to Player 1? This is m, so

       m = 1.

      Thus, for the strategy pair [A, C] we get (p, m) = (0, 1).

       It is important to note that (0, 1) is not a payoff vector. This is
       common notation for any ordered pair. With payoff vectors, the
       ordered pair represents the payoff to each player. Here the ordered
       pair represents a probability of playing B and the payoff to Player
      1.

     Step 1b. Assume Player 1 plays pure strategy B.
       Find the probability (p) and payoff (m) if Player 1 always plays B.

       If Player 1 plays pure strategy B, then what is the probability that
       she plays B? Since she always plays B,

       p = 1.
3.2. MIXED STRATEGIES: GRAPHICAL SOLUTION  45

   In the case where Player 1 plays B and Player 2 plays C, what is
   the payoff to Player 1?

                                         m = -1.

  Thus, for the strategy pair [B, C] we get (p, m) = (1, -1).

 Step 1c. Player 1 varies her strategy.
   Now we want to know what Player 1's payoff will be as she varies
   the probability, p, with which she plays B. We can draw a graph
  where the x-axis represents to probability with which she plays B (p)
   and the y-axis represents the expected payoff (m). See Figure 3.2.2,
   p. 45.

                                     1

        A                               B

  Figure 3.2.2 Labeled axes.

  Thus, when Player 1 plays only A, she is playing B with probability
   0; when Player 1 plays only B, she is playing B with probability
  1. It might be easier to remember if you label your graph as in
   Figure 3.2.2, p. 45.

 Step 1d. Plot points.
   Now we can plot the points we determined in Step 1a and Step
  1b. We will connect them with a line representing Player 2's pure
   strategy C. See Figure 3.2.3, p. 45.

    2

(0, 1)
    1

-1                    1
      A    C

                        (1, -1)

                        B

Figure 3.2.3 Player 2's strategy C.

    Before moving on, let's make sure we understand what this line represents.
Any point on it represents the expected payoff to Player 1 as she varies her
strategy, assuming Player 2 only plays C. In this case, we can see that as she
plays B more often, her expected payoff goes down.

    Now let's do the same thing, assuming Player 2 plays only D.
46  CHAPTER 3. REPEATED TWO-PERSON ZERO-SUM GAMES

    · Step 2. Assume Player 2 plays pure strategy D.

            Step 2a. Assume Player 1 plays pure strategy A.
              Find the probability, p, and payoff, m, if Player 1 always plays A.
              If Player 1 plays pure strategy A, then what is the probability that
              she plays B?
                                                      p = 0.

              What is the payoff to Player 1?

                                                      m = 0.

              Thus, for the strategy pair [A, D] we get (p, m) = (0, 0).
            Step 2b. Assume Player 1 plays pure strategy B.

              Find the probability, p, and payoff, m, if Player 1 always plays B.
              If Player 1 plays pure strategy B, then what is the probability that
              she plays B?

                                                      p = 1.

              What is the payoff to Player 1?

                                                      m = 2.

              Thus, for the strategy pair [B, D] we get (p, m) = (1, 2).
            Step 2c. Player 1 varies her strategy.

              Now, on our same graph from Step 1, we can plot the points we
              determined in Step 2a and Step 2b. We will connect them with a
              line representing Player 2's pure strategy D. See Figure 3.2.4, p. 46.

                                                                            (1, 2)
                                        2

    (0, 1)   D

    1

    (0, 0)

    -1                     1
          A     C

                             (1, -1)

                             B

    Figure 3.2.4 Player 2's strategy D.

    Now we can see that if Player 2 plays only D, then Player 1 does
    best by playing only B.

Now we have this nice graph, but what does it really tell us? Although we
drew lines representing each of Player 2's pure strategies, Player 1 doesn't know
what Player 2 will do. Suppose Player 1 only played A, while Player 2 plays
an unknown mixed strategy. Then the possible payoffs for Player 1 are 1 or
0. The more often Player 2 plays C, the more often Player 1 gets 1. So the
expected payoff per game for a repeated game varies between 0 and 1. We can
see the possible expected values as the red line on the graph in Figure 3.2.5,
p. 47.
3.2. MIXED STRATEGIES: GRAPHICAL SOLUTION  47

                                   (1, 2)
2

(0, 1)   D

1

(0, 0)

-1                     1
      A     C

                         (1, -1)

                         B

Figure 3.2.5 Figure 3.2.5, p. 47 of the expected payoffs for Player 1 playing
only A.

    Since we want to understand mixed strategies for Player 1, what would
happen if Player 1 played A half the time and B half the time? In other words,
what happens if p = 1/2? Although we may not easily be able to see the
exact values, we can represent the possible expected values on the graph in
Figure 3.2.6, p. 47.

                                   (1, 2)
2

(0, 1)   D

1

(0, 0)

-1                     1
      A     C

                         (1, -1)

                         B

Figure 3.2.6 The expected payoffs for Player 1 playing B half the time.

    Hopefully, you've begun to see that for each choice of p, the top line repre-
sents the highest expected value for Player 1; the bottom line represents the
lowest expected value for Player 1; the area between the lines represents the
possible expected values for Player 1. As we did with non-repeated games, let's
look at the "worst case scenario" for Player 1. In other words, let's assume
that Player 2 can figure out Player 1's strategy. Then Player 1 would want
to maximize the minimum expected value. Aha! This is just looking for the
maximin strategy!

    Now the minimum expected value for each choice of p is given by the bottom
lines on the graph, shown in red in Figure 3.2.7, p. 48.
48  CHAPTER 3. REPEATED TWO-PERSON ZERO-SUM GAMES

                                       (1, 2)
    2

    (0, 1)                       D

    1

    (0, 0)

    -1                                              1
          A                              C

                                                      (1, -1)

                                                      B

Figure 3.2.7 The minimum expected payoffs for Player 1.

    It should be easy to see that the maximum of the minimum expected payoffs
occurs at the intersection of the two lines.

    · Step 3. Find the intersection of the two lines.

     Step 3a. Find the equation for Line C.

      This is the line passing through the points (0, 1) and (1, -1). It has
       slope -2 and y-intercept 1. Thus, it has equation

                                          y = -2x + 1.

       [Although the x-axis represents probability p and the y-axis repre-
       sents expected payoff m, you are probably more comfortable solving
       equations-at least for the moment-in x and y.]

     Step 3b. Find the equation for Line D.
      This is the line passing through the points (0, 0) and (1, 2). It has
       slope 2 and y-intercept 0. Thus, it has equation

                                     y = 2x.

     Step 3c. Use substitution to find the point of intersection.

                        2x =                           -2x + 1
                        4x =                                    1
                                                               1
                         x=                                    4

    Substituting  x  =  1  back  in  to  either  original  equation,  say  y  =  2x,
                        4
    gives us y = 12 . Thus, the point of intersection is (1/4, 1/2).

    · Step 4. Determine Player 1's maximin mixed strategy.

       Recalling that the first coordinate is p, the probability that Player 1 plays
       B, we know that Player 1 will play B with probability 1/4, and thus, play
       A with probability 3/4, since 1 - (1/4) = 3/4. The expected payoff for
       Player 1 is 1/2. It is important to check back to your original intuition
       about the game from Activity 3.2.1, p. 44. Did it seem as though Player
       1 should play A more often than B?
3.2. MIXED STRATEGIES: GRAPHICAL SOLUTION                             49

Let's make a few important observations. First, it should be clear from the

graph that Player 1 expects a payoff of 1/2 NO MATTER WHAT PLAYER 2

DOES. Second, since this is a zero-sum game, we know that Player 2's expected

payoff is -1/2. It is important to note that this graph does not give us any

information about an optimal strategy for Player 2. We will see how to find

a strategy for Player 2 in the following activities. Can you think of how you

might do this?

We can use the graphical method to find the maximin and minimax mixed

strategies for repeated two-person zero-sum games.

Using the same game matrix as above:

                [        ]
                   1 0,
                   -1 2

we will continue to label Player 1's strategies by A and B, and Player 2's
strategies by C and D. We now want to determine the minimax strategy for
Player 2. Keep in mind the payoffs are still the payoffs to Player 1, so Player
2 wants the payoff to be as small as possible.

Activity 3.2.2 The minimax strategy. We can use the graph to see the
payoff for Player 2's minimax strategy.

(a) Sketch the graph for Player 1 that we drew above. Be sure to label the
      endpoints of each line. Also label each line according to which strategy
      they represent.

(b) Describe the minimax strategy and show it on the graph. (You do not
      need to find the actual mixed strategy for Player 2.)

 (c) Are the payoff vectors for the maximin and minimax strategies the same?

    For non-repeated games we have seen that if the maximin value is the same
as the minimax value, then the game has a pure strategy equilibrium. The
same idea applies to mixed strategy games. If the value of the maximin strat-
egy is the same as the value of the minimax strategy, then the corresponding
mixed strategies will be a mixed strategy equilibrium point. Thus, your
answer to Activity 3.2.2, p. 49 should tell you this game has a mixed strategy
equilibrium point consisting of the maximin/ minimax strategy.

    Before looking for the mixed strategy for Player 2, we summarize the graph-
ical process for finding the mixed strategy for Player 1.

                Finding a Mixed Strategy Graphically.

    The graph represents the probability that Player 1 plays B along
the x-axis and the payoff along the y-axis.

1. Assume Player 2 plays C.

     (a) Assume Player 1 plays A.
          Then p = 0 and m = the payoff for [A, C].
          Plot (p, m).

    (b) Assume Player 1 plays B.
          Then p = 1 and m = the payoff for [B, C].
          Plot (p, m).

     (c) Draw the line connecting the two points.
          This represents Player 2's pure strategy C.
50  CHAPTER 3. REPEATED TWO-PERSON ZERO-SUM GAMES

        2. Assume Player 2 plays D.

             (a) Assume Player 1 plays A.
                   Then p = 0 and m = the payoff for [A, D].
                   Plot (p, m).

             (b) Assume Player 1 plays B.
                   Then p = 1 and m = the payoff for [B, D].
                   Plot (p, m).

             (c) Draw the line connecting the two points.
                   This represents Player 2's pure strategy D.

        3. Find the mixed strategy.

             (a) Find the equations of the two lines.
             (b) Find the intersection, (x, y), of the two lines.

         Recalling that x is the probability that Player 1 plays B, the mixed
    strategy will be (1 - x, x) with an expected payoff to Player 1 of y.

    We now know that Player 2 wants to play the minimax strategy in response
to Player 1's maximin strategy, so we need to find the actual mixed strategy
for Player 2 to employ. Since we are minimizing Player 1's maximum expected
payoff, we will continue to use the matrix representing Player 1's payoff. We
will repeat the process we used for Player 1, except the x-axis now represents
the probability that Player 2 will play D, and the lines will represent Player
1's strategies A and B. The y-axis continues to represent Player 1's payoff.

Activity 3.2.3 Draw the axes for Player 2's strategy. First sketch the
axes. Recall, the x-axis only goes from 0 to 1.

Activity 3.2.4 Player 1 plays A. Assume Player 1 only plays A.

 (a) If Player 2 only plays C, what is the payoff to Player 1? Recall we called
       this m. What is the probability that Player 2 plays D? Recall we called
       this p. On your graph, plot the point (p, m).

 (b) If Player 2 plays only D, find m and p. Plot (p, m) on the graph.

 (c) Now sketch the line through your two points. This line represents Player
       1's pure strategy A and the expected payoff (to Player 1) for Player 2's
       mixed strategies. Label it A.

Activity 3.2.5 Player 1 plays B. Now assume Player 1 plays only B.
Repeat the steps in Activity 3.2.4, p. 50, using B instead of A, to find the line
representing Player 1's pure strategy B. (Label it!)

Activity 3.2.6 The graph for Player 2. It is important to keep in mind
that although the x-axis refers to how often Player 2 will play C and D, the
y-axis represents the payoff to Player 1.

 (a) Explain why we are looking for the minimax strategy for Player 2.

 (b) Show on the graph the maximum payoff that Player 1 can expect for each
       of Player 2's possible mixed strategies.

 (c) Show the point on the graph that represents the minimax strategy.
3.2. MIXED STRATEGIES: GRAPHICAL SOLUTION                               51

Activity 3.2.7 Equations for the lines. Find the equations of the lines
you drew in Activity 3.2.4, p. 50 and Activity 3.2.5, p. 50.

Activity 3.2.8 The point of intersection. Using the equations from
Activity 3.2.7, p. 51, find the point of intersection of the two lines.

Activity 3.2.9 Player 2's mixed strategy. How often should Player 2 play
C? How often should he play D? What is Player 1's expected payoff? And
hence, what is Player 2's expected payoff?

Activity 3.2.10 Equilibrium strategies. Explain why each player should
play the maximin/ minimax mixed strategy. In other words, explain why
neither player benefits by changing their strategy.

Hint. Think about playing defensively and assuming the other player is the
"perfect" player.

     Now it may have occurred to you that since this is a zero-sum game, we
could have just converted our matrix to the payoff matrix for Player 2 and
found Player 2's maximin strategy. But it is important to understand the
relationship between the maximin and the minimax strategies. So for the sake
of practice and a little more insight, find Player 2's maximin strategy by writing
the payoff matrix for Player 2 and repeating the process that we did for Player
1. Keep in mind that Player 2 is finding the probability of playing C and D
rather than A and B.

Activity 3.2.11 Finding the maximin using Player 2's payoffs. Convert
the payoff matrix above into the payoff matrix for Player 2. Find the maximin
strategy for Player 2 using the graphical method. Be sure to include a sketch
of the graph (labeled!!), the equations for the lines, the probability that Player
2 will play C and D, and the expected payoff for Player 2.

Activity 3.2.12 Compare the solutions. Compare your answer in Activ-
ity 3.2.11, p. 51 to your answer in Activity 3.2.9, p. 51.

Activity 3.2.13 Fairness. Is this game fair? Explain.

Activity 3.2.14 Expected payoff. We saw above that the expected payoff
for Player 1 was 1/2. Explain what this means for a repeated game.

Hint. Is it actually possible for a player to win 1/2 in a given game?

Before trying to solve more games, work through the following interactive

activity using the same game matrix as above:

[        ]
   1 0.
   -1 2

You can then use this same activity to help you solve other 2 × 2 games. Make
sure you check for a pure strategy equilibria before trying to find mixed strate-
gies!

Interactive Activity: Finding the mixed strategy graphically. The
interactive activity is available in the online version of the text at nordstrommath.
com/IntroGameTheory2e/S_MixStratGraph.html#W_graphicalmethod or on Doenet at
https://tinyurl.com/doenetmixstrat.

    Now you are ready to try to analyze some more games!

Activity 3[.2.15 P]ractice finding mixed strategies. Consider the zero-
sum game -4 4 .

                 2 -2

 (a) Does this game have a pure strategy equilibrium?
52  CHAPTER 3. REPEATED TWO-PERSON ZERO-SUM GAMES

 (b) Just by looking at the matrix, do you think this game will be fair? (Would
       you rather be Player 1 or Player 2?)

 (c) Sketch (and label!) the appropriate graph for this game.

 (d) Use you graph to determine if there is a mixed strategy equilibrium point.
       If there is, how often should Player 1 play each strategy? What is the
       expected payoff to each player?

 (e) Is this game fair? Explain. Compare your answer to (b).

Activity 3.2.16[ More]practice finding mixed strategies. Consider the
zero-sum game 0 1 .

                      1 -10

 (a) Does this game have a pure strategy equilibrium?

 (b) Just by looking at the matrix, do you think this game will be fair? (Would
       you rather be Player 1 or Player 2?)

 (c) Sketch (and label!) the appropriate graph for this game.

 (d) Use you graph to determine if there is a mixed strategy equilibrium point.
       If there is, how often should Player 1 play each strategy? What is the
       expected payoff to each player?

 (e) Is this game fair? Explain. Compare your answer to (b).
    Although it is worth working through examples by hand in order to under-

stand the algebraic process, in the next section we will see how technology can
help us solve systems of equations.

Check Your Understanding

The following exercises will work through the steps of finding the mixed strat-
egy for Player 1.

1. True or False?
           True or False: The following zero-sum game

    Table 3.2.8

                       CD
                 A 2 -1
                 B -3 4

           has a pure strategy equilibrium.

2. Consider the zero-sum game given by Table 3.2.8, p. 52. Let p be the
      probability that Player 1 plays B and m be the payoff to Player 1.
           If Player 1 plays A and Player 2 plays C then p = and m = .
           If Player 1 plays B and Player 2 plays C then p = and m = .

3. Consider the zero-sum game given by Table 3.2.8, p. 52. Let p be the
      probability that Player 1 plays B and m be the payoff to Player 1.
           If Player 1 plays A and Player 2 plays D then p = and m = .
           If Player 1 plays B and Player 2 plays D then p = and m = .

4. The line between to points (0, 2) and (1, -3) has slope  and y intercept
           .

5. The line between to points (0, -1) and (1, 4) has slope  and y intercept
           .
3.3. USING SAGE TO GRAPH LINES AND SOLVE EQUATIONS  53

6. Find the intersection of the lines y = -5x + 2 and y = 5x - 1
           x = and y = . Give your answer in decimal form.

7. Consider the zero-sum game given by Table 3.2.8, p. 52. Player 1 should
      play the mixed strategy

         A. (0.3, 0.7)

         B. (0.7, 0.3)

         C. (0.5, 0.5)

         D. (0.3, 0.5)

      Hint. The work in the previous exercises will help answer this question.
8. Consider the repeated zero-sum game given by Table 3.2.8, p. 52. If Player

      1 plays the maximin mixed strategy, her expected payoff is

         A. 0.3

         B. 0.5

         C. It depends on what Player 2 plays.

      Hint. The work in the previous exercises will help answer this question.
9. Is the game in Table 3.2.8, p. 52 fair?

         A. Yes.
         B. No, Player 1 has an advantage.
         C. No, Player 2 has an advantage.

3.3 Using Sage to Graph Lines and Solve Equa-
     tions

In this section we will use technology to graph lines and solve for the intersec-
tion point. In particular, we will use an open online resource called Sage.

    Let's continue to consider the game from Section 3.2, p. 43 given by

Table 3.3.1 Small Repeated Game.

                                                  CD
                                           A1 0
                                           B -1 2

    Recall, our goal is to determine how often Player 1 should play A and how
often she should play B.

    We will follow the same steps as in Section 3.2, p. 43. Let p be the prob-
ability that Player 1 plays B. Let m be the payoff to Player 1. Since we are
trying to find a mixed strategy for Player 1, we will pick a strategy for Player
2 and try to determine the possible payoffs for Player 1.

    Let us determine some pairs (p, m).

   · Step 1. Assume Player 2 plays pure strategy C.

            Step 1a. Assume Player 1 plays pure strategy A.
54  CHAPTER 3. REPEATED TWO-PERSON ZERO-SUM GAMES

       If Player 1 always plays A, then we are considering the strategy pair
       [A, C]. Since Player 1 never plays B, p = 0. The payoff to Player
      1 for [A, C] is m = 1. Thus, for the strategy pair [A, C] we get
      (p, m) = (0, 1).

     Step 1b. Assume Player 1 plays pure strategy B.
       If Player 1 always plays B, then we are considering the strategy pair
       [B, C]. Since Player 1 always plays B, p = 1. The payoff to Player
      1 for [A, C] is m = -1. Thus, for the strategy pair [B, C] we get
      (p, m) = (1, -1).

     Step 1c. Player 1 varies her strategy.
       Now we want to know what Player 1's payoff will be as she varies
       the probability, p, with which she plays B. We can draw a graph
      where the x-axis represents to probability with which she plays B
      (p) and the y-axis represents the expected payoff (m). Thus, when
       Player 1 plays only A, she is playing B with probability 0; when
       Player 1 plays only B, she is playing B with probability 1. It might
       be easier to remember if you label your graph as in Figure 3.2.2,
       p. 45.

     Step 1d. Plot points.
       Now we can use Sage to plot the points we determined in Step 1a
       and Step 1b and the line between them. This line represents Player
      2's pure strategy C. See Figure 3.2.3, p. 45. Click on the "Evaluate
      (Sage)" button to plot the line between the points (0, 1) and (1, -1).

         AC =(0 ,1) ;
         BC =(1 , -1) ;
         show(line([AC, BC], thickness=2,

               color=( ' blue ' ))+point(AC, color=( ' blue ' ),
               pointsize =70)+point(BC, color=( ' blue ' ),
               pointsize=70), figsize=4)

    Before moving on, let's again, make sure we understand what this line
represents. Any point on it represents the expected payoff to Player 1 as she
varies her strategy, assuming Player 2 only plays C. In this case, we can see
that as she plays B more often, her expected payoff goes down. You can now
use this Sage cell to plot any line for Player 2's pure strategy C. Just edit the
values for the points u and v. Go ahead and try it! (Don't worry the original
values will reset when you refresh the page.)

    Now let's do the same thing, assuming Player 2 plays only D.

   · Step 2. Assume Player 2 plays pure strategy D.

            Step 2a. Assume Player 1 plays pure strategy A.
              If Player 1 always plays A, then we are considering the strategy pair
              [A, D]. Since Player 1 never plays B, p = 0. The payoff to Player
              1 for [A, D] is m = 0. Thus, for the strategy pair [A, D] we get
             (p, m) = (0, 0).

            Step 2b. Assume Player 1 plays pure strategy B.
              If Player 1 always plays B, then we are considering the strategy pair
              [B, D]. Since Player 1 always plays B, p = 1. The payoff to Player
              1 for [B, D] is m = 2. Thus, for the strategy pair [B, D] we get
             (p, m) = (1, 2).
3.3. USING SAGE TO GRAPH LINES AND SOLVE EQUATIONS  55

 Step 2c. Player 1 varies her strategy.
   Now, on our same graph from Step 1, we can plot the points we
   determined in Step 2a and Step 2b. We will connect them with a
   line representing Player 2's pure strategy D. See Figure 3.2.4, p. 46.

     AC =(0 ,1) ;
     BC =(1 , -1) ;
     AD =(0 ,0) ;
     BD=(1, 2);
     show(line([AC , BC], thickness=2,

           color=( ' blue ' ))+point(AC , color =( ' blue ' ),
           pointsize =70)
        +point(BC, color=( ' blue ' ), pointsize =70)
        +line([AD , BD], thickness=2, color =( ' red ' ))
        +point(AD, color=( ' red ' ), pointsize =70)+point(BD,

               color=( ' red '), pointsize =70), figsize=4)

              Now we can see that if Player 2 plays only D, then Player 1 does
              best by playing only B. Again, you can use this Sage cell to plot
              both Player 2's pure strategies. Points AC and BC are for strategy
              C, while points AD and BD are for strategy D.

    As we saw in Section 3.2, p. 43, for each choice of p, the top line represents
the highest expected value for Player 1; the bottom line represents the lowest
expected value for Player 1; the area between the lines represents the possible
expected values for Player 1. Thus, Player 1 wants to maximize the minimum
expected value, which means she wants to find the maximin strategy. And, as
we saw in Section 3.2, p. 43, the maximin strategy occurs at the intersection
of the two lines.

   · Step 3. Find the intersection of the two lines.

            Step 3a. Find the equation for Line C.
              This is the line passing through the points (0, 1) and (1, -1). It has
              slope -2 and y-intercept 1. Thus, it has equation m = -2p + 1.
             (Recall the x-axis represents probability p and the y-axis represents
              expected payoff m.)

            Step 3b. Find the equation for Line D.
              This is the line passing through the points (0, 0) and (1, 2). It has
              slope 2 and y-intercept 0. Thus, it has equation m = 2p.

            Step 3c. Use technology to find the point of intersection.

                 p, m = var( 'p, m ')
                 solve([m==-2*p+1, m==2*p], p, m)[0]

                 [p == (1/4), m == (1/2)]

              The solution for Player 1 is (p, m). Where p is the probability Player
              1 plays B, and m is the expected payoff to Player 1.
              We can use this Sage cell to solve for p and m for any 2 × 2 game
              by editing the equations m == -2  p + 1, m == 2  p.

   · Step 4. Determine Player 1's maximin mixed strategy.

       Determine Player 1's maximin mixed strategy. Recalling that p is the
       probability that Player 1 plays B, we know that Player 1 will play B with
56  CHAPTER 3. REPEATED TWO-PERSON ZERO-SUM GAMES

    probability 1/4, and thus, play A with probability 3/4. The expected pay-
    off for Player 1, m, is 1/2. It is important to check the algebraic solution
    with where the intersection point appears on the graph. Although we are
    using technology to help us graph and solve for the intersection point,
    we need to be able to catch any errors we make entering the information
    into Sage.

    We have seen that we can use the same matrix with Player 1's payoffs to

find the strategy for Player 2. Using the same game matrix as above:

    [        ]
       1 0,
       -1 2

and continuing to label Player 1's strategies by A and B, and Player 2's strate-
gies by C and D, we can graph lines for Player 1's pure strategies A and B.
We now let the x-axis represent the probability that Player 2 plays D. In the
Sage applet below, for AC and AD enter the coordinates of two points that
determine the line for when Player 1 plays A, then the two points for BC and
BD that determine the line for when Player 1 plays B. We will then have Sage
graph the lines. You can enter new values for AC, AD, BC, and BD if you
would like to draw the graph for a different matrix.

@interact(layout=dict(top=[[ ' AC ' , ' AD ' ],[ ' BC ' , ' BD ' ]]))
def endpoints(AC=vector((0,1.0)), AD=vector((1,0.0)),

      BC=vector((0,-1.0)), BD=vector((1, 2.0))):
   L1 = line([AC , AD], thickness =2, color =( ' blue ' ))
   L2 = line([BC , BD], thickness =2, color =( ' red ' ))
   P1 = point(AC, color=( ' blue ' ), pointsize =70)
   P2 = point(AD, color=( ' blue ' ), pointsize =70)
   P3 = point(BC, color=( ' red ' ), pointsize =70)
   P4 = point(BD, color=( ' red ' ), pointsize =70)
   pretty_print(html("Enter the coordinates of the endpoints

          for the two lines you 'd like to graph. Note that AC
          and AD are for one line , BC and BD for the other."))
   show(L1+L2+P1+P2+P3+P4 , figsize =4)

    Now determine and enter the equations of the two lines and have Sage solve
for the intersection point.

 p, m = var( 'p, m ')
 @interact
 def

        intersection ( Slope1 = -1 , Intercept1 =1 , Slope2 =3 , Intercept2 = -1) :
     Eq1 = m==Slope1*p+Intercept1
     Eq2 = m==Slope2*p+Intercept2
     S = solve([Eq1 , Eq2], p, m)[0]
     pretty_print(html("The intersection point is $%s$,

            $% s$ ." %( latex (S [0]) , latex (S [1]) )))

    You can now use these last two Sage cells to solve any 2 × 2 game with a
mixed strategy equilibrium. You can also take some time to experiment with
what happens if the game has a pure strategy equilibrium.

    Sage is a powerful tool that we can use to solve many different computa-
tional problems. It is nice because it is free and open to use. But feel free to
use other available graphing and solving tools, such as Desmos1.

   1https://www.desmos.com/
3.3. USING SAGE TO GRAPH LINES AND SOLVE EQUATIONS                             57

    We can also use a simplified version of the interactive activity from Sec-
tion 3.2, p. 43.

Interactive Activity: Graphical Method. The interactive activity is
available in the online version of the text at nordstrommath.com/IntroGameTheory2e/
S_SolvingEq.html#W_graphicalmethodtool or on Doenet at https://tinyurl.com/
doenetmixstratfinder.

    Now use the Sage cells or the interactive activity to help you analyze some
more games!
Activity 3.3.1 Use techno[logy to ]find a mixed strategy equilibrium.
Consider the zero-sum game -4 4 .

                                         2 -2

 (a) Does this game have a pure strategy equilibrium?

 (b) Just by looking at the matrix, do you think this game will be fair? (Would
       you rather be Player 1 or Player 2?)

 (c) Use the Sage applet or the interactive activity to draw the graph for this
       game. Label each of your lines with the appropriate pure strategy.

 (d) Use your graph to determine if there is a mixed strategy equilibrium
       point. If there is, use technology to determine how often Player 1 should
       play each strategy. What is the expected payoff to each player?

 (e) Is this game fair? Explain. Compare your answer to (b).

Activ[ity 3.3.2] More practice with technology. Consider the zero-sum
game 0 1 .

         1 -10

 (a) Does this game have a pure strategy equilibrium?

 (b) Just by looking at the matrix, do you think this game will be fair? (Would
       you rather be Player 1 or Player 2?)

 (c) Use the Sage applet or the interactive activity to draw the graph for this
       game. Label each of your lines with the appropriate pure strategy.

 (d) Use your graph to determine if there is a mixed strategy equilibrium point.
       If there is, determine how often Player 1 should play each strategy. What
       is the expected payoff to each player?

 (e) Is this game fair? Explain. Compare your answer to (b).

Check Your Understanding

Use one of the tools in this section to find the mixed strategy for Player 1.
1. True or False?

           True or False: The following zero-sum game

      Table 3.3.2

                                                     CD
                                               A 5 -2
                                               B1 3

           has a pure strategy equilibrium.
58  CHAPTER 3. REPEATED TWO-PERSON ZERO-SUM GAMES

2. Consider the zero-sum game given by Table 3.3.2, p. 57. If we are finding
      Player 1's mixed strategy, which two points are on the line for Player 2's
      pure strategy C?

         A. (0, 5)

         B. (1, 1)

         C. (0, -2)
         D. (1, 3)

         E. (1, 5)

         F. (0, 1)

         G. (1, -2)
         H. (0, 3)
3. Consider the zero-sum game given by Table 3.3.2, p. 57. If we are finding
      Player 1's mixed strategy, which two points are on the line for Player 2's
      pure strategy D?

    A. (0, 5)
    B. (1, 1)

    C. (0, -2)
    D. (1, 3)
    E. (1, 5)

    F. (0, 1)

    G. (1, -2)

    H. (0, 3)

4. The line between the points (0, 5) and (1, 1) has slope   and y intercept
           .

5. The line between the points (0, -2) and (1, 3) has slope  and y intercept
           .

6. True or False?
           True or False: When finding the mixed strategy, it is possible that p

      is negative.

7. True or False?
           True or False: When finding the mixed strategy, it is possible that p

      is greater than 1.

8. Consider the zero-sum game given by Table 3.3.2, p. 57. Find the mixed
      strategy for Player 1.

    A. (7/9, 2/9)
    B. (2/9, 7/9)

    C. (2/9, 17/9)
3.4. MIXED STRATEGIES: EXPECTED VALUE SOLUTION  59

9. Consider the repeated zero-sum game given by Table 3.3.2, p. 57. If Player
      1 plays the maximin mixed strategy, her expected payoff is

         A. 7/9

         B. 17/9

         C. It depends on what Player 2 plays.
10. Is the game in Table 3.3.2, p. 57 fair?

         A. Yes.

         B. No, Player 1 has an advantage.

         C. No, Player 2 has an advantage.
11. Find the mixed strategy for Player 1 for the following game.

      Table 3.3.3
                                                     CD

                                              A -2 1
                                              B 1 -2
           Player 1 should play A with a probability of and B with a probabilty
      of . The expected payoff to Player 1 is .
12. Find the mixed strategy for Player 2 for the game in Table 3.3.2, p. 57.
           Player 2 should play C with a probability of and D with a probabilty
      of . The expected payoff to Player 2 is . (Use 3 decimal places if
      necessary)
13. If we use the graph to try to find Player 1's mixed strategy, which of the
      following can we determine with just the graph, without solving for the
      intersection point?

         A. Whether Player 1 should play A more often than B.

         B. Whether Player 1's expected payoff is positive or negative.

         C. Whether Player 2's expected payoff is positive or negative.

         D. Whether Player 2 should play C more often than D.

         E. Whether Player 1 will win or lose if the game is played once.

         F. Whether Player 1 will win or lose if the game is played 10 times.

3.4 Mixed Strategies: Expected Value Solution

In this section, we will use the idea of expected value to find the equilibrium
mixed strategies for repeated two-person zero-sum games.

    One of the significant drawbacks of the graphical solution from the previous
sections is that it can only solve 2×2 matrix games. If each player has 3 options,
we would need to graph in three dimensions. Technically this is possible, but
rather complicated. If each player has more than 3 options, since we can't
graph in four or more dimensions, we are at a complete loss. So we need to
think about an alternate way to solve for the mixed strategies. Although we
will begin with 2 × 2 games, this method will easily generalize to larger games.
60  CHAPTER 3. REPEATED TWO-PERSON ZERO-SUM GAMES

Example 3.4.1 Matching Pennies Game. Consider the game in which

each player can choose HEADS (H) or TAILS (T); if the two players match,

Player 1 wins; if the two players differ, Player 2 wins. What strategy should

each player play?                                          

Activity 3.4.1 Payoff matrix. Determine the payoff matrix for the Match-
ing Pennies game.

Activity 3.4.2 Pure strategy equilibria. Explain why the Matching
Pennies game has no pure strategy equilibrium point.

Activity 3.4.3 Conjecture a mixed strategy. Since we know that there
is no pure strategy equilibrium point, we need to look for a mixed strategy
equilibrium point.

(a) Just by looking at the payoff matrix for Matching Pennies, what do you
     think an ideal strategy for each player would be? Explain your choice.

 (b) Suppose both players play your ideal strategy in the Matching Pennies
       game, what should the expected value of the game be?

    We could use our previous graphical method to determine the expected
value of the game (you might quickly try this just to verify your prediction).
However, as we have noted, a major drawback of the graphical solution is that
if our players have 3 or more options, then we would need to graph an equation
in 3 or more variables; which, I hope you agree, we don't want to do. Although
we will continue to focus on 2 × 2 games, we will develop a new method which
can more easily be used to solve larger games.

    We will some new notation. Let

    P1(H) =        the probability that Player 1 plays H;
    P1(T ) =       the probability that Player 1 plays T;
    P2(H) =        the probability that Player 2 plays H;
    P2(T ) =       the probability that Player 2 plays T.

Also, we will let E1(H) be the expected value for Player 1 playing pure strategy
H against a given strategy for Player 2. Similarly, E2(H) will be Player 2's
expected value for playing pure strategy H.

Activity 3.4.4 The (60, 40) strategy for Player 2. In the Matching
Pennies game, suppose Player 2 plays H 60% of the time and T 40% of the
time.

(a) What are P2(H) and P2(T )?

(b) What do you think Player 1 should do? Does this differ from your ideal
      mixed strategy in Activity 3.4.3, p. 60? Explain.

(c) We can use expected value to compute what Player 1 should do in re-
     sponse to Player 2's 60/40 strategy. First, consider a pure strategy for
     Player 1. Compute the expected value for Player 1 if she only plays H
     while Player 2 plays H with probability .6 and T with probability .4. This
     expected value is E1(H), above.

(d) Similarly, compute the expected value for Player 1 if she plays only T.
      Call it E1(T ).

(e) Which pure strategy has a higher expected value for Player 1? If Player
     1 plays this pure strategy, will she do better than your predicted value of
     the game?
3.4. MIXED STRATEGIES: EXPECTED VALUE SOLUTION  61

Activity 3.4.5 The (60, 40) strategy is not ideal for Player 2. Hopefully,
you concluded that in Activity 3.4.4, p. 60 a pure strategy is good for Player 1.
Explain why this means the 60/40 strategy is bad for Player 2.

Activity 3.4.6 When to play H, when to play T. For any particular
mixed (or pure) strategy of Player 2, we could find E1(T ) and E1(H).

 (a) Explain why if E1(H) > E1(T ), Player 1 should always play H.

 (b) Similarly, explain why if E1(H) < E1(T ), Player 1 should always play T.

Activity 3.4.7 Player 2 is unhappy when Player 1's expected values
are unequal. Explain why the situations in Activity 3.4.6, p. 61 are bad for
Player 2.

Activity 3.4.8 Equal expected values are better. Use your answers from
Activity 3.4.6, p. 61 and Activity 3.4.7, p. 61 to explain why the situation in
which E1(H) = E1(T ) is the best for Player 2.

    From Activity 3.4.8, p. 61 we now know that Player 2 wants E1(H) = E1(T ),
we can use a little algebra to compute the best defensive strategy for Player 2.
Remember, we want to assume that Player 1 will always be able to chose the
strategy that will be best for her, and thus Player 2 wants to protect himself.
Let's find the probabilities with which Player 2 should play H and T.

Activity 3.4.9 Equations for Player 1's expected values. Let P2(H)
and P2(T ) be the probabilities that Player 2 plays H and T respectively.

 (a) Find equations for E1(H) and E1(T ) in terms of P2(H) and P2(T ) for
       the game of Matching Pennies.The expected value, E1(H), is (Player 1's
       payoff for [H, H]× the probability Player 2 plays H)+ (Player 1's payoff
       for [H, T]× the probability Player 2 plays T).

 (b) Since we want E1(H) = E1(T ), set your two equations equal to each
       other. This gives you one equation in terms of P2(H) and P2(T ).

 (c) Explain why we must also have the equation P2(H) + P2(T ) = 1.
    In general, to solve for Player 2's strategy, we want to write an equation

for each of Player 1's pure strategy expected values in terms of Player 2's
probabilities. For example, E1(H) and E1(T ) in terms of variables P2(H) and
P2(T ). We then set the expected values equal to each other. We now have an
equation just in terms of Player 2's probabilities.

    In order to solve for the probabilities, we also need to use the fact that
Player 2's probabilities sum to 1. For example, P2(H) + P2(T ) = 1. For a 2 × 2
game, you now have 2 equations with 2 unknowns (P2(H) and P2(T )). Use
an algebraic method such as substitution or elimination to solve the system of
equations.

Activity 3.4.10 Solve for Player 2's probabilities. Using the equations
from Activity 3.4.9, p. 61 solve for P2(H) and P2(T ). You now have the equi-
librium mixed strategy for Player 2. Does this match the mixed strategy you
determined in Activity 3.4.3, p. 60?

    Now can you use a similar process to find Player 1's strategy? Whose
expected values should you use? Whose probabliities?

Activity 3.4.11 Find Player 1's probabilities. Set up and solve the
analogous equations from Activity 3.4.9, p. 61 for Player 1. Does this match
the mixed strategy from Activity 3.4.3, p. 60?

Hint. We should have an equation for E2(H) and one for E2(T ). Since we
62  CHAPTER 3. REPEATED TWO-PERSON ZERO-SUM GAMES

are looking for the probabilities of each of Player 1's options, the equations
should involve P1(H) and P1(T ).

    We now have a new method for finding the best mixed strategies for Players
1 and 2, assuming that each player is playing defensively against an ideal player.
But how can we find the value of the game? For Player 2, we assumed E1(H) =
E1(T ). In other words, we found the situation in which Player 1's expected
value is the same no matter which pure strategy she plays. Thus, Player 1 is
indifferent to which pure strategy she plays. If she were not indifferent, then
she would play the strategy with a higher expected value. But, as we saw, this
would be bad for Player 2. So Player 1 can assume that Player 2 will play the
equilibrium mixed strategy. Thus, as long as Player 1 plays a mixed strategy,
it doesn't matter whether at any given time, she plays H or T (this is the idea
that she is indifferent to them). Hence, the expected value of the game for
Player 1 is the same as E1(H), which is the same as E1(T ). Similarly, we find
that the expected value of the game for Player 2 is E2(H) (or E2(T )). This is
a pretty complicated idea. You may need to think about it for a while. In the
meantime, use the probabilities you found for each player and the equations
for E1(H) and E2(H) to find the value of the game for each player.

Activity 3.4.12 Find Player 1's expected value of the game. Use the
probabilities you calculated in Activity 3.4.10, p. 61 to find E1(H), and hence
the expected value of the game for Player 1. How does this compare to your
prediction for the value of the game that you gave in Activity 3.4.3, p. 60?

Activity 3.4.13 Find Player 2's expected value of the game. Use the
probabilities you calculated in Activity 3.4.11, p. 61 to find E2(H), and hence
the expected value of the game for Player 2. How does this compare to your
prediction for the value of the game that you gave in Activity 3.4.3, p. 60?

    Keep practicing with the expected value method on some other games.

Activity 3.4.14 Solve a 2 × 2 repeated game using expected values.
Apply this method of using expected value to Activity 3.1.1, p. 39, which we
solved using the graphical method in Section 3.2, p. 43 to find the equilibrium
mixed strategies for each player and the value of the game for each player:

    [        ]
       1 0.
       -1 2

Activity 3.4.15 Expected value solution for Rock-Paper-Scissors. As
we noted in this section, this method can be used to solve bigger games. We just
have more equations. Use the expected value method to find the equilibrium
mixed strategy for Rock-Paper-Scissors for Player 2.

Hint. You will need to set E1(R) = E1(P ) and E1(P ) = E1(S); solve for
P2(R), P2(P ), P2(S); etc. It should be very similar to what you did for Match-
ing Pennies, but there will be three equations and three unknowns.

    If you found this last activity to be algebraically challenging, don't worry,
we will be able to use technology to help us solve equations with several vari-
ables.

Check Your Understanding

1. True or False?
           True or False: The following zero-sum game
3.4. MIXED STRATEGIES: EXPECTED VALUE SOLUTION          63

      Table 3.4.2

                                                     CD
                                              A 1 -3
                                              B -4 2

           has a pure strategy equilibrium.

2. Consider the zero-sum game given by Table 3.4.2, p. 63. Suppose Player
      2 plays the C 50% of the time and D 50% of the time. We can call this
      the (50, 50) or (1/2, 1/2) strategy. What is E1(A)?

3. Consider the zero-sum game given by Table 3.4.2, p. 63. Suppose Player
      2 plays the C 50% of the time and D 50% of the time. We can call this
      the (50, 50) or (1/2, 1/2) strategy. What is E1(B)?

4. Suppose Player 2 plays the (1/2, 1/2) strategy in Table 3.4.2, p. 63, then
      which pure strategy does Player 1 prefer?

         A. Playing A

         B. Playing B

         C. Neither, Player 1 is indifferent to playing A or B.
5. Consider the zero-sum game given by Table 3.4.2, p. 63. Suppose Player

      2 plays the C 25% of the time and D 75% of the time. We can call this
      the (25, 75) or (1/4, 3/4) strategy. What is E1(A)?

6. Consider the zero-sum game given by Table 3.4.2, p. 63. Suppose Player
      2 plays the C 25% of the time and D 75% of the time. We can call this
      the (25, 75) or (1/4, 3/4) strategy. What is E1(B)?
           Reminder, if your answer is not a whole number, use decimals.

7. If Player 2 plays the (1/4, 3/4) strategy in Table 3.4.2, p. 63, then which
      pure strategy does Player 1 prefer?

         A. Playing A

         B. Playing B

         C. Neither, Player 1 is indifferent to playing A or B.
8. Consider the zero-sum game given by Table 3.4.2, p. 63. Suppose Player

      2 plays (3/4, 1/4) strategy.
           What is E1(A)?
           What is E1(B)?
           Reminder, if your answer is not a whole number, use decimals.

9. If Player 2 plays the (3/4, 1/4) strategy in Table 3.4.2, p. 63, then which
      pure strategy does Player 1 prefer?

A. Playing A

B. Playing B

C. Neither, Player 1 is indifferent to playing A or B.

10. To find Player 1's equilibrium mixed strategy we use the expected values

for           and the probabilities for  .

A. Player 1; Player 1
B. Player 2; Player 2
64  CHAPTER 3. REPEATED TWO-PERSON ZERO-SUM GAMES

         C. Player 1; Player 2

         D. Player 2; Player 1
11. Which two equations should you use to find Player 1's equilibrium mixed

      strategy in the following game?
      Table 3.4.3

                                                     CD
                                               A 5 -2
                                               B1 3

         A. -5P1(A) + (-1)P1(B) = 2P1(A) - 3P1(B)

         B. 5P2(C) + (-2)P2(D) = 1P2(C) + 3P2(D)

         C. P1(A) + P1(B) = 1

         D. P2(C) + P2(D) = 1
12. Which two equations should you use to find Player 2's equilibrium mixed

      strategy in the game Table 3.4.3, p. 64?

         A. -5P1(A) + (-1)P1(B) = 2P1(A) - 3P1(B)

         B. 5P2(C) + (-2)P2(D) = 1P2(C) + 3P2(D)

         C. P1(A) + P1(B) = 1

         D. P2(C) + P2(D) = 1

3.5 Liar's Poker

In this section, we will continue to explore the ideas of a mixed strategy equi-
librium. We have seen several examples of finding an equilibrium. We began
with games which had a pure strategy equilibrium and then moved to games
with a mixed strategy equilibrium. We saw two different methods for finding
an equilibrium. The first employed graphs in order to understand and find the
maximin and minimax strategies, and hence the equilibrium mixed strategy.
The second method employed the ideas of expected value to find the equilib-
rium strategy. We will continue to solidify these ideas with another game, a
simplified variation of poker.

Example 3.5.1 Liar's Poker. We begin with a deck of cards which has 50%

Aces (A) and 50% Kings (K) and two players. Aces rank higher than Kings.

    Player 1 is dealt one card, face down. Player 1 can look at the card, but does

not show the card to Player 2. Player 1 then says "Ace" or "King" depending

on what his card is. Player 1 can either tell the truth and say what the card is

(T), or he can bluff and say that he has a higher ranking card (B). Note that

if Player 1 has an Ace, he must tell the truth since there are no higher ranking

cards. However, if he is dealt a King, he can bluff by saying he has an Ace.

    If Player 1 says "King" the game ends and both players break even. If

Player 1 says "Ace" then Player 2 can either call (C) or fold (F). If Player 2

folds, then Player 1 wins $0.50. If Player 2 calls and Player 1 does not have

an Ace, then Player 2 wins $1. If Player 2 calls and Player 1 does have an Ace,

then Player 1 wins $1.                                                        
3.5. LIAR'S POKER  65

Activity 3.5.1 Play Liar's Poker. Choose an opponent and play Liar's
Poker several times. Be sure to play the game as Player 1 and as Player 2.
This is important for understanding the game. Keep track of the outcomes.

Activity 3.5.2 Conjecture a strategy. Just from playing Liar's Poker
several times, can you suggest a strategy for Player 1? What about for Player
2? Does this game seem fair, or does one of the players seem to have an
advantage? Explain your answers.

Activity 3.5.3 Try to find the payoff matrix. In order to formally analyze
Liar's Poker, we should find the payoff matrix. Do your best to find the payoff
matrix. In a single hand of Liar's Poker, what are the possible strategies for
Player 1? What are the possible strategies for Player 2? Determine any payoffs
that you can.

    Finding the payoff matrix in Activity 3.5.3, p. 65 is probably more challeng-
ing than it appears. Eventually we want to employ the same method for finding
the payoff matrix that we used in One-Card Stud Poker from Example 2.4.1,
p. 29 in Chapter 2, but first we need to understand each player's strategies and
the resulting payoffs. We begin with the fact that Player 1 can be dealt an
Ace or a King.

Activity 3.5.4 Player 1 has an Ace. Assume Player 1 is dealt an Ace.
What can Player 1 do? What can Player 2 do? What is the payoff for each
situation?

Activity 3.5.5 Player 1 has a King. Assume Player 1 is dealt a King.
What can Player 1 do? What can Player 2 do? What is the payoff for each
situation?

    Since Player 1 must say "Ace" when dealt an Ace, he only has a choice of
strategy when dealt a King. So we can define his strategy independent of the
deal. One strategy is to say "Ace" when dealt an Ace and say "Ace" when
dealt a King; call this the bluffing strategy, (B). The other strategy is to
say "Ace" when dealt an Ace and say "King" when dealt a King; call this the
truth strategy, (T). The only time Player 2 has a choice is when Player 1
says "Ace." In this case Player 2 can call, (C) or fold, (F). Since we need
to determine the payoff matrix, we first need to determine the payoffs for pure
strategies. This is similar to what we did for the One-Card Stud game.

Activity 3.5.6 Expected value of [B, C]. Consider Player 1's pure strategy
of always bluffing when dealt a King (B) and Player 2's pure strategy of always
calling (C). Determine the expected value for Player 1. What is Player 2's
expected value?

Hint. You need to consider each possible deal.

Activity 3.5.7 Expected value of [B, F]. Similarly, determine the expected
value for Player 1 for the pure strategy pair [B, F]. What is Player 2's expected
value?

Activity 3.5.8 Expected value of [T, C]. Determine the expected value for
Player 1 for the pure strategy pair [T, C]. What is Player 2's expected value?

Activity 3.5.9 Expected value of [T, F]. Determine the expected value for
Player 1 for the pure strategy pair [T, F]. What is Player 2's expected value?

Activity 3.5.10 Payoff matrix for Liar's Poker. Using the expected
values you calculated in Activity 3.5.6, p. 65, Activity 3.5.7, p. 65, Activity 3.5.8,
p. 65, and Activity 3.5.9, p. 65, set up the 2 × 2 payoff matrix for Liar's Poker.

    Once you have determined the payoff matrix for Liar's Poker, you can
use either the graphical method or expected value method to solve the game.
66  CHAPTER 3. REPEATED TWO-PERSON ZERO-SUM GAMES

But before using either of these methods always check for a pure strategy
equilibrium!

Activity 3.5.11 Pure strategy equilibrium. Using the payoff matrix
you found in Activity 3.5.10, p. 65, does Liar's Poker have a pure strategy
equilibrium? Explain.

Activity 3.5.12 Mixed strategy equilibrium. Use any method you have
learned to find a mixed strategy equilibrium for Liar's Poker. Give the mixed
strategy for Player 1 and the mixed strategy for Player 2.

Activity 3.5.13 Compare strategies. Compare your solution from Activ-
ity 3.5.12, p. 66 to your conjectured strategy from Activity 3.5.2, p. 65.

Activity 3.5.14 Expected value of the game. What is the expected value
of the game for each player? How much would Player 1 expect to win if she
played 15 games using the equilibrium mixed strategy?

Activity 3.5.15 Fairness. Is this game fair? Explain. Again, compare your
answer to your conjecture in Activity 3.5.2, p. 65.

    Congratulations! You can now set up matrices for simple games of chance
and solve for a mixed strategy equilibrium. Before solving a more complicated
game, let's get the help of technology for solving larger matrix games.

Check Your Understanding

1. Match each payoff vector to the corresponding strategy pair for Liar's
      Poker, Example 3.5.1, p. 64.

                 [T, F]                     (0, 0)
                 [B, C]                     (1/2, -1/2)
                 [B, F]                     (1/4, -1/4)

2. In Liar's Poker, the payoff vector for [T, C] is

    A. (0, 0)

         B. (1/2, -1/2).
         C. (-1/2, 1/2).
         D. (-1/4, 1/4).
         E. (1/4, -1/4).
3. In Liar's Poker, it is preferable to be

    A. Player 1

    B. Player 2

         C. Neither, the game looks the same to both players.

4. True or False?
           True or False: In the game of Liar's Poker, Player 1 should always

      bluff (B).

5. True or False?
           True or False: In the game of Liar's Poker, Player 2 should always call

      (C).
3.6. SOLVING SYSTEMS OF EQUATIONS USING MATRICES  67

6. True or False?
           True or False: In the game of Liar's Poker, Player 1 should tell the

      truth (T) more often than bluff (B).

7. True or False?
           True or False: In the game of Liar's Poker, Player 2 should fold (F)

      more often than call (C).

8. True or False?
           True or False: Liar's Poker is a fair game.

9. In Liar's Poker, suppose Player 2 calls (C) 50% of the time and folds (F)
      50% of the time.
           What is the expected payoff to Player 1 for bluffing, E1(B)?
           What is the expected payoff to Player 1 for telling the truth, E1(T )?

           Reminder, if your answer is not a whole number, use decimals.
10. If Player 2 plays the (1/2, 1/2) mixed strategy in Liar's Poker, then which

      pure strategy does Player 1 prefer?

         A. Bluffing (B)

         B. Telling the truth (T)

         C. Neither, Player 1 is indifferent to playing B or T.
11. True or False?

           True or False: If Liar's Poker is played once (not repeated), Player 1
      will win.
12. True or False?

           True or False: If Liar's Poker is played 10 times with Player 1 playing
      the mixed strategy equilibrium, then Player 1 expects to have a positive
      payoff.

3.6 Solving Systems of Equations Using Matrices

In this section, we will see how to use matrices to solve systems of equations.
In both the graphical method and the expected value method, you have had
to solve a system of equations. In the graphical method you had systems
consisting of two lines such as Example 3.6.1, p. 67.
Example 3.6.1 Two Equations. An example of a system of two lines:

                                                 31
                                           y = 5x - 5
                                           y = -x + 3.

                                                                                                    
    In the expected value method we had systems of three equations such as
Example 3.6.2, p. 67.
Example 3.6.2 Three Equations. An example of a system of three equa-
tions where the variables are E1(A), E1(B), P2(C), P2(D):

                                   E1(A) = P2(C) - P2(D)
                                  E1(B) = 2P2(D)

                                         1 = P2(C) + P2(D).

                                                                                                    
68  CHAPTER 3. REPEATED TWO-PERSON ZERO-SUM GAMES

    In Example 3.6.2, p. 67, even after setting E1(A) = E1(B) so that there
were only 2 variables, the algebra began to get cumbersome. What if we wanted
to solve a much larger game, such as a 5 X 5 game?

    We've used matrices to represent our games, but now we want to use them
as a mathematical tool to help us solve systems of equations. In order to use
matrices to solve our systems of equations, we want to write all our equations
in the same form: we will have all the variable terms on the left of the equals
sign and all constants on the right.

Example 3.6.3 Turning a System of Equations into a Matrix. The
equations in Example 3.6.1, p. 67 we can be rewritten as

               3                            1
               5x - y = 5

                  x + y = 3.

    In fact, we can simplify the first equation by multiplying both sides by 5:

               3x - 5y = 1
                  x + y = 3.

    We can use the coefficients and constants to create a matrix:

               [                            ]
                  3 -5 1 .
                  113

In this matrix you have a column for the coefficients of each variable. So the

coefficients of x are in the first column, the coefficients of y are in the second.

The constant terms are always in the last column. Each row corresponds to

one equation.                                                          

    The matrix in Example 3.6.3, p. 68 is called an augmented matrix. It is

really just a matrix, but we call it augmented if we include information from

both sides of the equation (the coefficients and the constants).

    The algebraic method for solving the system of equations (finding the x and

y values that satisfy both equations) is called row reduction. It is based on

the elimination method that you may have seen in a precalculus or college

algebra course. We won't go through the algebra here, as we really don't need

it. Since our goal is to be able to easily solve larger systems of equations, we

will rely on technology to do the algebra.

    Computer algebra systems such as Sage, Mathematica, and Maple, as well

as graphing calculators, can easily do the row reduction for us. In this section

we will use the Desmos matrix calculator first, then show how to use Sage.

Note that any graphing claculator will work similarly to Desmos.

Example 3.6.4 Using the Desmos Matrix Calculator. On Desmos, use
the Matrix Calculator under Math Tools: Desmos Matrix Calculator1. Use the

New Matrix button to enter the matrix. If we want to enter the matrix

               [  3 -5 1                    ]

                  113

we will need a matrix with 2 rows and 3 columns. Enter the values in the
matrix. You can either Tab to each entry or use the arrow buttons. Once
you have entered the values in the matrix, use the blue Enter button (the blue
arrow in the bottom right corner. Then use the "rref" button (this stands for
"reduced row echelon form") and the matrix name, probably A . The result will
3.6. SOLVING SYSTEMS OF EQUATIONS USING MATRICES  69

be the following matrix:  [             ]

                             1 0 2.
                             011

This is the matrix we will use to determine the solution for the system of

equations. We'll get to how we do that shortly.   

Example 3.6.5 Using Sage. We can also find the reduced row echolon form
of a matrix using Sage, as in the following Sage Cell.

A= matrix ([[3 , -5 ,1] ,[1 ,1 ,3]]) ;
show (A. rref () )

matrix([[1, 0, 2],[0,1,1]])

                                                                                                
Recall that when we set up the original matrix, the first column is for x

and the second is for y. Each row represents an equation. We can take the

matrix                    [             ]

                             1 0 2.
                             011

and translate each row back to equations. This gives us the following system
of equations:

                          x + 0y = 2
                          0x + y = 1

which simplifies to

                             x=2
                             y = 1.

    By plugging these values back into the original equations, you can verify
that this is in fact the solution to the system of equations in Example 3.6.3,
p. 68.

    Since the technology does all the algebra for us, our job is to translate the
equations into an appropriate matrix and then translate the final matrix back
into the solution to the system of equations. Remember, when using a matrix
to solve a game, the matrix is only a tool, it is not the solution to the game.

    Now, let's try the equations for the expected value method in Example 3.6.2,
p. 67. As presented, how many variables does the system have?

                                   E1(A) = P2(C) - P2(D)
                                   E1(B) = 2P2(D)

                                          1 = P2(C) + P2(D)

    It has 4: E1(A), E1(B), P2(C) and P2(D). But when we solved these equa-
tions, we set the expected values equal to each other. This gives us the two
equations

                             P2(C) - P2(D) = 2P2(D)
                                               1 = P2(C) + P2(D).

    Now if we put these into the equation form with all variables on the left
and constants on the right, we get

                          P2(C) - 3P2(D) = 0

1www.desmos.com/matrix
70  CHAPTER 3. REPEATED TWO-PERSON ZERO-SUM GAMES

                      P2(C) + P2(D) = 1.

    Putting these equations into an augmented matrix, gives us

                                 [       ]
                                    1 -3 0 ,
                                    111

where the first column corresponds to P2(C) and the second column corre-
sponds to P2(D). We can do the row reduction using either Desmos or the
Sage cell below.

A= matrix ([[1 , -3 ,0] ,[1 ,1 ,1]]) ;
show (A. rref () )

matrix([[1, 0, 3/4],[0,1,1/4]])

    Using row reduction, we get

                                 [           ]
                                    1 0 3/4 .
                                    0 1 1/4

    Thus, recalling Column 1 is for P2(C) and Column 2 is for P2(D), our
solution is P2(C) = 3/4, and P2(D) = 1/4.

    Here are some more systems of equations to practice solving using aug-
mented matrices. If you want to use the above Sage cells just edit the values
for each row in the cell.

Activity 3.6.1 Solve a system of 2 equations. Solve the system of
equations.

                                          2x - 2y = 6
                                           x + 3y = 7

Activity 3.6.2 Solve another system of 2 equations. Solve the system
of equations.

                                         4p1 - 2p2 = 0
                                           p1 + p2 = 1

    For larger matrices, you can edit the Sage cell by adding additional terms in
each row, and adding more rows. For example, you can replace [3, -5, 1], [1, 1, 3]
with [4, 8, -4, 4], [3, 8, 5, -11], [-2, 1, 12, -17].

Activity 3.6.3  Solve a system of 3 equations.       Consider the system of
equations

                       4x + 8y - 4z            =4
                       3x + 8y + 5z          = -11
                      -2x + y + 12z          = -17.

(a) Set up the augmented matrix for this system.

(b) Use row reduction to find the solution.

Activity 3.6.4 Solve  another system of 3            equations.  Consider the
system of equations

                      2x + y - 4z       = 10
                        3x + 5z         = -5
                         y + 2z         = 7.

(a) Set up the augmented matrix for this system.
3.6. SOLVING SYSTEMS OF EQUATIONS USING MATRICES              71

(b) Use row reduction to find the solution.

Activity   3.6.5 Even  more practice with 3    equations.  Consider the
system of  equations
                              a + b - 5c = 0
                            -4a - b + 6c = 0

                               a + b + c = 1.

(a) Set up the augmented matrix for this system.

(b) Use row reduction to find the solution.

Activity 3.6.6  Now, a system with 5 equations. Consider the system
of equations
                             3x + 2y - w - v = 0
                         2x - y + 3z + w + 5v = 0

                             x + 2y + 6z - w = 0
                            -y + z - 3w + v = 0
                            x + y + z + w + v = 1.

(a) Set up the augmented matrix for this system.

 (b) Use row reduction to find the solution.

    Now we are ready to apply everything we have learned about solving re-
peated zero-sum games to a much more challenging game in the next section.

Check Your Understanding

1. Suppose we have the system of equations

                          3x - 4   =y
                          z + 2x   =5
                          x - 2y  = 3z.

Which is the corresponding augmented matrix for this system?

             3 -4 1

A. 1 2 5

             1 -2 3

             3 -1 4

B. 2 1 5

             1 -2 3

             3 -1 0 4   

C. 2 0 1 5

             1 -2 -3 0

             3 1 0 -4   

D. 2 0 1 5 

             1 -2 3 0

2. Suppose after doing row reduction on a system of equations with variables
72  CHAPTER 3. REPEATED TWO-PERSON ZERO-SUM GAMES

    x, y, z, we have the following matrix         
                                                3
                                                2 .
                                          100
                                               -1
                                        0 1 0
                                          001

      Then the solution to the system of equations is
           x=
           y=
           z=

3. Use row reduction to solve the following system of equations.

                            2x - 3y + z         =7
                           -x + 2y - 2z        = -7
                                               = 2.
                             x+y+z

    Then the solution to the system of equations is
        x=
        y=
        z=

4. Suppose we finding the mixed strategy equilibrium for a 2 × 2 game using
      row reduction. After row reducing we have the following matrix where
      the first column represents P (A) and the second represents P (B).

                              [                ]
                                 1 0 -1 .
                                 01 2

    What can we conclude?

    A. P (A) = -1, P (B) = 2
    B. P (A) = 1, P (B) = 2

    C. P (A) = -1/3, P (B) = 2/3

    D. P (A) = -1/3, P (B) = 2/3

    E. We must have made a mistake since P (A)+P (B) = 1 in this context.

    F. We must have made a mistake since P (A) and P (B) must be be-
        tween 0 and 1 in this context.

5. Suppose we finding the mixed strategy equilibrium for a 2 × 2 game using
      row reduction. After row reducing we have the following matrix where
      the first column represents P (A) and the second represents P (B).

                              [                ]
                                 1 0 1/3 .
                                 0 1 1/3

    What can we conclude?

    A. P (A) = 1/3, P (B) = 1/3
    B. P (A) = 1/3, P (B) = 2/3
    C. We must have made a mistake since P (A)+P (B) = 1 in this context.
    D. We must have made a mistake since P (A) and P (B) must be be-

        tween 0 and 1 in this context.
3.7. UNDERCUT                            73

6. Suppose we finding the mixed strategy equilibrium for a 2 × 2 game using
      row reduction. After row reducing we have the following matrix where
      the first column represents P (A) and the second represents P (B).

                       [              ]
                             1 0 1/3 .
                             0 1 2/3

What can we conclude?

A. P (A) = 2/3, P (B) = 1/3
B. P (A) = 1/3, P (B) = 2/3

C. We must have made a mistake since P (A)+P (B) = 1 in this context.

D. We must have made a mistake since P (A) and P (B) must be be-
    tween 0 and 1 in this context.

3.7 Undercut

This section requires you to be able to solve "large" systems of equations. You
will be using the matrix techniques from Section 3.6, p. 67. You are encouraged
to use technology such as a Desmos or Sage.

    As we saw in Section 3.5, p. 64, an important part of game theory is the
process of translating a game to a form that we can analyze.

Example 3.7.1 Undercut. Each player chooses a number 1 through 5. If
the two numbers don't differ by 1, then each player adds their own number
to their score. If the two numbers differ by 1, then the player with the lower
number adds both numbers to their score; the player with the higher number
gets nothing. This game is from Douglas Hofstadter's Metamagical Themas.

    For example, suppose in round one Player 1 chooses 4, and Player 2 chooses
4. Each player keeps their own number. The score is now 4-4. In the next
round, Player 1 chooses 2, and Player 2 chooses 5. The score would now be 6-9.
In the third round Player 1 chooses 4, and Player 2 chooses 5. Now Player 1
gets both numbers, while Player 2 gets nothing, making the score 15-9. 

Activity 3.7.1 Play Undercut. Choose an opponent and play Undercut
several times. Keep track of the outcomes.

    After playing Undercut with an opponent, try to devise a good strategy.

Activity 3.7.2 Conjecture a strategy. Just from playing Undercut several
times, can you suggest a strategy for Player 1? What about for Player 2? For
example, what number(s) should you play most often/ least often, or does it
matter? Are there numbers you should never play? Does this game seem fair,
or does one of the players seem to have an advantage? Explain your answers.

    As we've seen before, a payoff matrix can help with analyzing a game.

Activity 3.7.3 Payoff matrix. Create a payoff matrix for Undercut. Note
that your payoffs should have a score for each player.

Activity 3.7.4 Zero-sum. Is this a zero-sum game? Explain.

Activity 3.7.5 Pure strategy equilibrium. Does there appear to be a
pure strategy equilibrium for this game (a strategy pair where neither player
wants to switch)? Explain.

    Let's assume we are going to play Undercut repeatedly. By the time you
and your opponent are done playing, what should it mean to win the game?
74  CHAPTER 3. REPEATED TWO-PERSON ZERO-SUM GAMES

Activity 3.7.6 Long-run winner. How might we determine a "winner" for
Undercut after playing several times?

    Most likely, you said that someone will win the game if they have the most
points. In fact, we probably don't care if the final score is 10-12 or 110-112. In
either case, Player 2 wins. Since we will play this game several times, we do
care about the point difference. For example, a score of 5-1 would be better
for Player 1 than 5-3. So let's think about the game in terms of the point
difference between the players in a given game. This is called the net gain.
For example, with score of 5-1, Player 1 would have a net gain of 4.

Activity 3.7.7 Net gain. Calculate the net gain for Player 1 for each of
the three example rounds described in Example 3.7.1, p. 73 at the beginning
of this section.

Activity 3.7.8 Net gain payoff matrix. Create a new payoff matrix for
Undercut which uses the players' net gain for the payoff vectors.

Activity 3.7.9 Zero-sum. Is this now a zero-sum game? Explain.
    The method of using net gain to describe the payoffs to each player should

be familiar from some of the really early examples where we turned constant-
sum payoff vectors into zero-sum vectors. But note that the original form of
this game wasn't even a constant-sum game! What we are really doing here
is thinking about our payoffs not as points, but a win or loss relative to our
opponent. Now that we have reframed Undercut as a zero-sum game, we can
apply our methods for solving the game that we have seen in this chapter.

Activity 3.7.10 Pure strategy equilibrium. Is there a pure strategy
equilibrium for this game? Explain.

Hint. Rather than looking at each option, you could compare the values for
the pure maximin/ minimax strategies.

    This game has one additional property that will help simplify our analysis.
This game is symmetric, meaning the game looks the same to Players 1 and
2.

Activity 3.7.11 Symmetric games. Give an example of another game
which is symmetric. Give an example of a game which is not symmetric.

Activity 3.7.12 Expected payoff for a symmetric game. What is the
expected payoff for a symmetric game? Explain your answer.

Hint. You might think about whether it is possible for a player to have an
advantage in a symmetric game.

    Hopefully, you determined that there is not a pure strategy equilibrium for
Undercut. Thus, we would like to find a mixed strategy equilibrium. Since
this is a 5 × 5 game, we cannot use our graphical method. We will need to
rely on our expected value method. We want to decide with what probability
we should play each number. Let a, b, c, d, e be the probabilities with which
Player 2 plays 1-5, respectively. For example, if Player 1 plays a pure strategy
of 2, then the expected value for Player 1, E1(2), is -3a + 0b + 5c - 2d - 3e.

Activity 3.7.13 Equations for Player 1's expected value. Write down
the five equations that give Player 1's expected value for each of Player 1's
pure strategies.

Hint. Find equations for E1(1), E1(2), E1(3), E1(4), E1(5) in terms of Player
2's probabilities, a, b, c, d, e.

Activity 3.7.14 Expected value of a symmetric game. In Activity 3.7.12,
p. 74, you should have determined that since this is a symmetric game, the
3.7. UNDERCUT  75

expected value for each Player should be 0. Modify your equations from Activ-
ity 3.7.13, p. 74 to include this piece of information. It is important to recognize
that this step greatly simplifies our work for the expected value method since
we don't need to set the expected values equal to each other. However, we can
ONLY do this since we know the game is symmetric!

    If we use that the game is symmetric, and hence the expected value of the
game for each player must be 0 since neither player can have an advantage over
the other, we do not need to set the equations equal to each other. We could
not use this method earlier since we had no way of knowing the expected value
of a general game.

    We now have five equations and five unknowns. There is a sixth equation:
we know that the probabilities must add up to 1. We can now solve for the
equilibrium strategy.

Activity 3.7.15 Solve the system of equations. Use an augmented
matrix and row reduction to solve the resulting system of six equations. Give
the mixed strategy equilibrium for Player 2. What is the mixed strategy for
Player 1?

Hint. Should the strategy for Player 1 be different than the strategy for
Player 2?

Activity 3.7.16 Summary. Based on your answer to Activity 3.7.15, p. 75,
which number(s) should you play the most often? Which should you play
the least? Are there any numbers that you should never play? Compare the
mathematical solution to your conjectured solution for Activity 3.7.2, p. 73. Is
there an advantage to knowing the mathematical solution?

    You have now solved a rather complex two-person game. Try playing it
with your friends and family. It may be difficult (or even impossible) to play
randomly with the exact probabilties. It is also unlikely that your opponent
will also be playing the equilibrium strategy, but can you use the solution to
assure you have an advantage, or at least assure that your opponent doensn't
have an advantage? Can you see the difference between an exact theoretical
solution to a game and a practical strategy for playing the game? In the next
chapter we will see even more differences between theoretical and practical
solutions to a game.

Check Your Understanding

1. In Undercut, Example 3.7.1, p. 73, if Player 1 plays 5 and Player 2 plays
      1, Player 2's net gain is .

2. In Undercut, Example 3.7.1, p. 73, if Player 1 plays 3 and Player 2 plays
      4, Player 1's net gain is .

3. In Undercut, it is preferable to be

         A. Player 1

         B. Player 2

         C. Neither, the game looks the same to both players.
4. True or False?

           True or False: The following zero-sum game is symmetric:
                                                 []
                                                   3 1.
                                                   13
76  CHAPTER 3. REPEATED TWO-PERSON ZERO-SUM GAMES

5. True or False?
           True or False: The following zero-sum game is symmetric:

    [      ]
       0 -3 .
       30

6. True or False?
           True or False: The following zero-sum game is symmetric:

    [      ]
       2 -1 .
       12

7. True or False?
           True or False: The following zero-sum game is symmetric:

    [      ]
       0 -1 .
       12

8. True or False?
           True or False: In a zero-sum symmetric game played only once, the

      expected payoff to each player is 0.

9. True or False?
           True or False: In a repeated zero-sum symmetric game the expected

      payoff to a player playing the mixed strategy equilibrium is 0.

10. True or False?
           True or False: In Undercut, a player should always play 5.

11. True or False?
           True or False: In Undercut, a player should never play 5.

12. True or False?
           True or False: In Undercut, a player should always play 1.

13. True or False?
           True or False: In Undercut, a player should never play 1.

14. True or False?
           True or False: In Undercut, a player should play each number 1-5

      equally.

15. True or False?
           True or False: In Undercut, If Player 1 is playing the mixed strategy

      equilibrium, then Player should play the mixed strategy equilibrium.
Chapter 4

Non-Zero-Sum Games

    In the previous chapters we concentrated on zero-sum games. We know
how to solve any zero-sum game. If it has a pure strategy equilibrium, then
we know the players should play the equilibrium strategies. If it doesn't have
an equilibrium point, then we have seen methods for finding a mixed strategy
equilibrium. Assuming both players are our model rational players, then we
know they should always play an equilibrium strategy.

    In this chapter we turn our attention to non-zero-sum games.

4.1 Introduction to Two-Player Non-Zero-Sum
     Games

In this section we introduce non-zero-sum games. In a non-zero-sum game
the players' payoffs no longer need to sum to a constant value. Now it is
possible for both players to gain or both players to lose.
Activity 4.1.1 Compare properties. What are some properties of a zero-
sum game that may no longer hold for a non-zero-sum game? For example,
in a zero-sum game is it ever advantageous to inform your opponent of your
strategy? Is it advantageous to communicate prior to game play and determine
a joint plan of action? Would you still want to minimize your opponents payoff?

    Let's build an understanding of non-zero-sum games by looking at an ex-
ample.
Example 4.1.1 Battle of the Movies. Alice and Bob want to go out to a
movie. Bob wants to see an action movie, Alice wants to see a comedy. Both
prefer to go to a movie together rather than to go alone. We can represent the
situation with the payoff matrix in Table 4.1.2, p. 78:

                                                  77
78  CHAPTER 4. NON-ZERO-SUM GAMES

Table 4.1.2 Battle of the Movies

                                                            Alice
                                                   Action Comedy
                          Bob Action (2, 1) (-1, -1)
                                   Comedy (-1, -1) (1, 2)

                                                                                                     
Activity 4.1.2 Not zero-sum. Explain why this is not a zero-sum game.

    In zero-sum games it is never advantageous to let your opponent know you
strategy. Does that property still apply for games like Battle of the Movies?

Activity 4.1.3 Announcing a strategy. Could it be advantageous for a
player to announce his or her strategy? Could it be harmful to announce his or
her strategy? If possible, describe a scenario in which it would be advantageous
to announce a strategy. If possible, describe a scenario in which it would be
harmful to announce a strategy.

    We might first try to analyze Battle of the Movies using the same techniques
as we used for zero-sum games. For example, we might start as we would in
zero-sum games by looking for any equilibrium points.

Activity 4.1.4 Equilibrium points. Since our main goal in analyzing
games has been to find equilibrium points, let's find any equilibrium points for
Battle of the Movies.

 (a) Are there any strategy pairs where players would not want to
       switch?There are two!

 (b) Are the equilibrium points the same (in other words, does each player
       get the same payoff at each equilibrium point)? Compare this to what
       must happen for zero-sum games.

    Now that we know Battle of the Movies has two equilibrium points, we
should try to find actual strategies for Alice and Bob. Is there a good strategy
for each if they play the game only once? What if they repeat the game? Recall
that with zero-sum games, if there was an equilibrium, rational players always
want to play it, even if the game is repeated. Does that still seem to work here?
Also, how might the ability to communicate change what the players do?

Activity 4.1.5 Repeating the game. Suppose the game is played repeat-
edly. For example, Alice and Bob have movie night once a month.

 (a) Suggest a strategy for Alice and for Bob.

 (b) Play the game with someone from class without communicating about
       your strategy before each game.

  (c) How could communication affect the choice of strategy? Now play several
       times where you are allowed to communicate about your strategy. Does
       this change your strategy?

 (d) In either case, communicating and not communicating, do you think your
       strategies for Alice and Bob represent a mixed strategy equilibrium?

Activity 4.1.6 Compare to zero-sum. In a zero-sum game, if there is
a pure strategy equilibrium, then what happens when you repeat a game? If
you repeat Battle of the Movies, does the game always result in an equilibrium
pair?

    Hopefully, you are beginning to see some of the challenges for analyzing non-
4.1. INTRODUCTION TO TWO-PLAYER NON-ZERO-SUM GAMES 79

zero-sum games. We know there are equilibrium points in Battle of the Movies,
but even rational play may not result in an equilibrium. For the remainder of
this section, let's assume that players are not allowed to communicate about
strategy prior to play. Such games are called non-cooperative games. Before
moving on, let's try to find the maximin strategies for our players using the
graphical method, as we did with zero-sum games.

Activity 4.1.7 Bob's payoff matrix. Consider Battle of the Movies from
Bob's point of view. We know that Bob wants to maximize his payoff (that
has not changed). So Bob doesn't care what Alice's payoff's are. Write down
Bob's payoff matrix without including Alice's payoffs.

Activity 4.1.8 Graphical method on Bob's matrix. Recall that the
graphical method represents Bob's expected payoff depending on how often
he plays each of his options. Sketch the graph associated with Bob's payoff
matrix.

Activity 4.1.9 Bob's maximin mixed strategy. The area between the
two lines still represents the possible expected values for Bob, depending on
how often Alice plays each of her strategies. So as before, the bottom lines
represent the least Bob can expect as he varies his strategy. Thus, the point
of intersection will represent the biggest of these smallest values (the maximin
strategy). Find this point of intersection. How often should Bob play each
option? What is his expected payoff?

    So no matter what Alice does, Bob can expect that over the long run he wins
at least the value you found in Activity 4.1.9, p. 79. Make sure you understand
this before moving on.

Activity 4.1.10 Alice's maximin mixed strategy. Consider Battle of
the Movies from Alice's point of view. Write down her payoff matrix and use
the graphical method to find the probability with which she should play each
option and her expected payoff.

    Now, from Activity 4.1.9, p. 79 and Activity 4.1.10, p. 79 you have the
minimum payoff each player should expect. Note that since this is not a zero-
sum game, both players can expect a positive payoff. But now we want to see
how this pair of mixed strategies really works for the players.

Activity 4.1.11 Alice's expected value when Bob plays his maximin
strategy. Assume Bob plays the mixed strategy from Activity 4.1.9, p. 79.

 (a) Calculate Alice's expected value for each of her pure strategies
       (E2(Comedy) and E2(Action)).

 (b) Are Alice's expected values equal? If not, which strategy does she prefer
       when Bob plays the mixed strategy from Activity 4.1.9, p. 79? Does Alice
       want to deviate from her mixed strategy?

Activity 4.1.12 Mixed strategy equilibrium. If Alice plays a pure strat-
egy, does Bob want to change his strategy? Is the mixed strategy pair for Bob
and Alice from Activity 4.1.9, p. 79 and Activity 4.1.10, p. 79 an equilibrium?
In fact, if Bob changes his strategy, how does his expected value compare to
the expected value for his mixed strategy?

Activity 4.1.13 Downside of the graphical method. What goes wrong
with the graphical method in the case of a non-zero-sum game?

Hint. Is it important for Alice to consider the minimax strategy? Does Alice
have any reason to minimize Bob's payoff?
80               CHAPTER 4. NON-ZERO-SUM GAMES

    As we can see by the above activities, the methods used to analyze zero-sum
games may not be too helpful for non-zero-sum games. Part of the problem
is that in solving zero-sum games we take into consideration that one player
wants to minimize the payoff to the other player. This is no longer the case.
Changing strategies may allow BOTH players to do better. A player no longer
has any reason to prevent the other player from doing better.

Activity 4.1.14 Response to the mixed strategy. We know the mixed
strategy won't give us an equilibrium. But suppose we start there. In other
words, suppose Bob plans to play the mixed strategy from Activity 4.1.9, p. 79.
Which pure strategy should Alice play? In response, which pure strategy should
Bob play? What is the outcome? Do you end up at an equilibrium?

Activity 4.1.15 Bob's expected value when Alice plays her maximin
strategy. Suppose Alice plans to play the mixed strategy from Activity 4.1.10,
p. 79. Calculate the expected value for Bob for each of his pure strategies.
Which pure strategy does Bob prefer to play? How will Alice respond to Bob's
pure strategy? What is the outcome? Do you end up at an equilibrium?

Activity 4.1.16 Out-guessing the mixed strategy. Suppose Bob thinks
Alice will try the mixed strategy and Alice thinks Bob will try the mixed
strategy. Which pure strategy will each play? What is the outcome? Do you
end up at an equilibrium?

Activity 4.1.17 Playing the maximin mixed strategy. Considering
Activity 4.1.14, p. 80, Activity 4.1.15, p. 80, and Activity 4.1.16, p. 80, is it
in a player's best interest to even consider playing the mixed strategy from
Activity 4.1.9, p. 79 or Activity 4.1.10, p. 79?

    We've seen the limitations of the graphical method, but what about the
expected value method?

Activity 4.1.18 Expected value solution. Try applying the expected value
method to Battle of the Movies. What mixed strategies do you get? Explain
why this method will also not result in an equilibrium. You might want to
consider whether it is important for one player to minimize the expected value
for the other player.

    Now that we have seen how the methods that allowed us to solve zero-sum
games don't work for non-zero-sum games, we will need to find new ways to
approach non-zero-sum games.

Check Your Understanding

1. True or False?
           True or False: The following game

    Table 4.1.3

                          C                   D

                 A (2, 2) (1, 0)

                 B (0, 1) (-1, -1)

           is a zero-sum game.

2. The following game has at least one pure strategy equilibrium, click on or
      circle the equilibrium point(s).
4.1. INTRODUCTION TO TWO-PLAYER NON-ZERO-SUM GAMES 81

Table 4.1.4

                     C  D

                     A (2, 2) (1, 0)

                     B (0, 1) (-1, -1)

3. In the game in Table 4.1.3, p. 80, Player 1 should play

A. Pure strategy A.

         B. Pure strategy B.
         C. A mixed strategy with A more often than B.
         D. A mixed strategy with B more often than A.
4. In the game in Table 4.1.3, p. 80, Player 2 should play

A. Pure strategy C.

B. Pure strategy D.

C. A mixed strategy with C more often than D.

         D. A mixed strategy with D more often than C.

5. True or False?
           True or False: The following game

Table 4.1.5

                     C  D

                     A (2, 3) (1, -4)

                     B (-4, 1) (3, 2)

           is a zero-sum game.

6. The following game has at least one pure strategy equilibrium, click on or
      circle the equilibrium point(s).

Table 4.1.6

                     C  D

                     A (2, 3) (1, -4)

                     B (-4, 1) (3, 2)

7. True or False?
           True or False: In the game in Table 4.1.5, p. 81, if the players play

      once, and each player chooses the strategy with their preferred equilibrium,
      them the game will result in an equilibrium.

8. In the game in Table 4.1.5, p. 81, suppose Player 1 only considers her
      payoff matrix and finds the mixed strategy as we did for zero-sum games.
      Then Player 1 would play

A. Pure strategy A.

         B. Pure strategy B.

         C. A mixed strategy with A more often than B.

         D. A mixed strategy with B more often than A.
9. In the game in Table 4.1.5, p. 81, suppose Player 1 plays the zero-sum

      mixed strategy. Then Player 2 prefers to play
82  CHAPTER 4. NON-ZERO-SUM GAMES

         A. Pure strategy C.

         B. Pure strategy D.

         C. A mixed strategy with C more often than D.

         D. A mixed strategy with D more often than C.
10. In the game in Table 4.1.5, p. 81, suppose Player 2 announces he will play

      C. What should Player 1 play?

         A. Pure strategy A.

         B. Pure strategy B.

         C. A mixed strategy with A more often than B.

         D. A mixed strategy with B more often than A.
11. Going back to Battle of the Movies, suppose Alice still prefers Comedy

      to Action, but also prefers to go to the movie with Bob than to go alone.
      However, now Bob hates Comedy, so he would prefer to see the action
      movie alone rather than go to the Comedy movie.

           We can adjust the payoff as in the following matrix. Click or circle
      any equilibruim points.

      Table 4.1.7

                                                               Alice
                                                       Action Comedy
                              Bob Action (2, 1) (1, -1)
                                       Comedy (-3, -1) (-2, 2)
12. True or False?
           True or False: In a zero-sum game, it can be a benefit to a player to
      announce their strategy.
13. True or False?
           True or False: In a non-zero-sum game, it can be a benefit to a player
      to announce their strategy.
14. True or False?
           True or False: In a zero-sum game, a player wants to minimize their
      opponent's payoff.
15. True or False?
           True or False: In a non-zero-sum game, a player wants to minimize
      their opponent's payoff.

4.2 Prisoner's Dilemma and Chicken

Before getting any further into non-zero-sum games, let's recall some key ideas
about zero-sum games.

   · If a zero-sum game has an equilibrium point, then repeating the game
       does not affect how the players will play.

   · If a zero-sum game has more that one equilibrium point then the values
       of the equilibrium points are the same.

   · In a zero-sum game, we can find mixed strategy equilibrium points using
       the graphical method or the expected value method.
4.2. PRISONER'S DILEMMA AND CHICKEN  83

· In a zero-sum game, a player never benefits from communicating her
   strategy to her opponent.

    In the last section we saw that non-zero-sum games can differ on all of the
above!

Example 4.2.1 A 2 × 2 Non-Zero Sum Game. Let's consider the game
given in the following matrix.

Table 4.2.2 A non-zero sum example

C  D

A (0, 0) (10, 5)

B (5, 10) (0, 0)

                                                                                                    
Activity 4.2.1 Not zero-sum. Check that this is not a zero-sum game.

    Even with non-zero-sum games, it is helpful to start by finding any equilib-
rium points.

Activity 4.2.2 Equilibrium points. Using the "guess and check" method
for finding equilibria, you should be able to determine that Table 4.2.2, p. 83
has two equilibrium points. What are they?

Activity 4.2.3 Preference between equilibria. As we saw in Section 4.1,
p. 77, the equilibrium points in non-zero-sum games need not have the same
values. Does Player 1 prefer one of the equilibria from Activity 4.2.2, p. 83 over
the other?

    Since it is now possible for both players to benefit at the same time, it might
be a good idea for players to communicate with each other. For example, if
Player 1 says that she will choose A no matter what, then it is in Player 2's
best interest to choose D. If communication is allowed in the game, then we
say the non-zero-sum game is cooperative. If no communication is allowed,
we say it is non-cooperative.

    We saw in Section 4.1, p. 77, that our methods for analyzing zero-sum games
do not work very well on non-zero-sum games. Let's look a little closer at this.

    If we apply the graphical method for Player 1 to the game in Table 4.2.2,
p. 83, we get that Player 1 should play a (1/3, 2/3) mixed strategy for an
expected payoff of 10/3. Similarly we can determine that Player 2 should play
a (2/3, 1/3) mixed strategy for an expected payoff of 10/3. Recall we developed
this strategy as a "super defensive" strategy. But are our players motivated to
play as defensively in a non-zero-sum game? Not necessarily! It is no longer
true that Player 2 needs to keep Player 1 from gaining.

    Now suppose, Player 1 plays the (1/3, 2/3) strategy. Then the expected
payoff to Player 2 for playing pure strategy C, E2(C), is 20/3; and the expected
payoff to Player 2 for playing pure strategy D, E2(D), is 5/3. Thus Player 2
prefers C over D. But if Player 2 plays only C, then Player 1 should abandon
her (1/3, 2/3) strategy and just play B. This results in the payoff vector (5,
10). Notice, that now the expected value for Player 1 is 5, which is better than
10/3! Again, since Player 2 is not trying to keep Player 1 from gaining, there
is no reason to apply the maximin strategy to non-zero-sum games. Similarly,
we don't want to apply the expected value solution since Player 1 does not
care if Player 2's expected values are equal. Each player only cares about his
or her own payoff, not the payoff of the other player. It is also useful to note
that the mixed strategy is not an equilibrium strategy since at least one player
wants to change strategy.

    OK, so now, how do we analyze these games?
84              CHAPTER 4. NON-ZERO-SUM GAMES

Activity 4.2.4 Conjecture a strategy. What are some possible strategies
for each player in Table 4.2.2, p. 83? Might some strategies depend on com-
municating with the other player? Might some strategies depend on what a
player knows about her opponent, especially if communication is not allowed?

    Can you see that some of the analysis might be better understood with
psychology than with mathematics?

    In order to better understand non-zero-sum games we look at two classic
games.

Example 4.2.3 Prisoner's Dilemma. Two partners in crime are arrested
for burglary and sent to separate rooms. They are each offered a deal: if they
confess and rat on their partner, they will receive a reduced sentence. So if
one confesses and the other doesn't, the confessor only gets 3 months in prison,
while the partner serves 10 years. If both confess, then they each get 8 years.
However, if neither confess, there isn't enough evidence, and each gets just one
year. We can represent the situation with the following matrix.

Table 4.2.4 The Prisoner's Dilemma (years in prison).

                                       Prisoner 2

                               Confess Don't Confess

    Prisoner 1  Confess        (8, 8)      (0.25, 10)
                Don't Confess
                               (10, 0.25)  (1, 1)

                                                                                                     
    Since this game, as presented, is probably only playerd once, we can begin
by looking for dominated strategies and equilibrium points.

Activity 4.2.5 Dominated strategies. Does the matrix in Table 4.2.4,
p. 84 have any dominated strategies for Player 1? Does it have any dominated
strategies for Player 2? Keep in mind that a prisoner prefers smaller numbers
since prison time is bad.

    If you were to be one of the prisoners, what would you do? Do you think
everyone would do that, too? What would our perfectly rational player do?
Would your strategy change if you are allowed to communicate? We examine
some of these questions in the next few activities.

Activity 4.2.6 A prisoner's strategy. Suppose you are Prisoner 1. What
should you do? Why? Suppose you are Prisoner 2. What should you do?
Why? Does your choice of strategies result in an equilibrium pair?

Activity 4.2.7 The best outcome. Looking at the game as an outsider,
what strategy pair is the best option for both prisoners.

Activity 4.2.8 Two rational prisoners. Now suppose both prisoners are
perfectly rational, so that any decision Prisoner 1 makes would also be the
decision Prisoner 2 makes. Further, suppose both prisoners know that their
opponent is perfectly rational. What should each prisoner do?

Activity 4.2.9 An unpredictable prisoner. Suppose Prisoner 2 is unpre-
dictable and is likely to confess with 50/50 chance. What should Prisoner 1
do? Does it change if Prisoner 2 confesses with a 75% chance? What if he
confesses with a 25% chance.

Activity 4.2.10 Communication between prisoners. Suppose the pris-
oners are able to communicate about their strategy. How might this affect
what they choose to do?
4.2. PRISONER'S DILEMMA AND CHICKEN            85

Activity 4.2.11 The dilemma. Explain why Prisoner's Dilemma is a
"dilemma" for the prisoners. Is it likely they will choose a strategy which
leads to the best outcome for both? You might want to consider whether there
are dominated strategies.

     You should now have some idea about why we call this game a dilemma,
since the players may in fact have difficulty deciding on whether to confess or
not. Even two perfectly rational players may not be able to get the best payoff.

     We now turn to another classic example. We can ask similar qustions about
Chicken that we ask about Prisoner's Dilemma.

Example 4.2.5 Chicken. Two drivers drive towards each other. If one
driver swerves, he is considered a "chicken." If a driver doesn't swerve (drives
straight), he is considered the winner. Of course if neither swerves, they crash
and neither wins. A possible payoff matrix for this game is given in the following
matrix.

Table 4.2.6 The game of Chicken.

                            Driver 2

                    Swerve           Straight

Driver 1  Swerve    (0, 0)           (-1, 10)
          Straight
                    (10, -1) (-100, -100)

                                                                                                     
    Again, since this game as presented is probably only played once, we can
begin by looking for dominated strategies and equilibrium points.

Activity 4.2.12 Dominated strategies. Does the Chicken game in Ta-
ble 4.2.6, p. 85 have any dominated strategies?

Activity 4.2.13 The best outcome. What strategy results in the best
outcome for Driver 1? What strategy results in the best outcome for Driver 2?
What happens if they both choose that strategy?

Activity 4.2.14 Equilibrium points. Consider the strategy pair with
outcome (-1, 10). Does Driver 1 have any regrets about his choice? What
about Driver 2? Is this an equilibrium point? Are there any other points in
which neither driver would regret his or her choice?

    If you were to be one of the drivers, what would you do? Do you think
everyone would do that, too? What would our perfectly rational player do?
Would your strategy change if you are allowed to communicate? We examine
some of these questions in the next few activities.

Activity 4.2.15 A driver's strategy. Can you determine what each driver
should do in Chicken? If so, does this result in an equilibrium pair?

Activity 4.2.16 Two rational drivers. Now suppose both drivers in the
game of Chicken are perfectly rational, so that any decision Driver 1 makes
would also be the decision Driver 2 makes. Further, suppose both drivers know
that their opponent is perfectly rational. What should each driver do?

Activity 4.2.17 A random self-driving car. Suppose Driver 2 is poorly
programmed self-driving car that will swerve or drive straight with a 50/50
chance. What should Driver 1 do? Does it change if the self-driving car
swerves with 75% chance?

Activity 4.2.18 Communication between drivers. Can it benefit drivers
in the game of Chicken to communicate about their strategy? Explain.
86  CHAPTER 4. NON-ZERO-SUM GAMES

Activity 4.2.19 Compare games. Compare Prisoner's Dilemma and
Chicken. Are there dominated strategies in both games? Are there equilib-
rium pairs? Are players likely to reach the optimal payoff for one player, both
players, or neither player? Does a player's choice depend on what he knows
about his opponent (perfectly rational or perfectly random)?

    Both Prisoner's Dilemma and Chicken are models of games where we de-
scribe the choice of strategy as Cooperate and Defect. In Prisoner's Dilemma,
we think of cooperating as cooperating with the other player, and defecting
as turning against the other player. So if both players cooperate (with each
other, not the law), they will get the higher payoff of only one year in prison.
They defect by ratting on each other. In Chicken, players cooperate by swerv-
ing and defect by driving straight. Using the examples of Prisoner's Dilemma
and Chicken, think about how these games can model other everyday interac-
tions where you could describe your choices as cooperating and defecting. The
remainder of the chapter looks more closely at situations where players can
cooperate or defect.

Check Your Understanding

1. True or False?
           True or False: In the game of Chicken, the player who swerves is

      cooperating.

2. True or False?
           True or False: In the Prisoner's Dilemma, the player who confesses is

      cooperating.

3. True or False?
           True or False: In the Prisoner's Dilemma, the strategy pair [Don't

      Confess, Don't Confess] is an equilibrium.

4. True or False?
           True or False: In the game of Chicken, the strategy pair [Swerve,

      Swerve] is an equilibrium.

5. True or False?
           True or False: In the game of Chicken, the equilibria have the same

      payoff vectors.

6. True or False?
           True or False: In the game of Chicken, communication can be benefi-

      cial for players.

7. True or False?
           True or False: In Prisoner's Dilemma, communication can be beneficial

      for players.

4.3 A Class-Wide Experiment

We are going to look at a class-wide game.
    Each member of the class secretly chooses a single letter: "C" or "D,"

standing for "cooperate" or "defect." This will be used as your strategy choice
in the following game with each of the other players in the class. Here is how
it works for each pair of players: if they both cooperate, they get each get 3
points. If they both defect, they each get 1 point. If one cooperates and one
defects, the cooperator gets nothing, but the defector gets 5 points. Your one
choice of "C" or "D" will be used to play the game with all the other players
in the class.
4.3. A CLASS-WIDE EXPERIMENT  87

     Thus, if everyone chooses "C," everyone will get 3 points per person (not
counting yourself). If everyone chooses "D," everyone will get 1 point per
person (not counting yourself). You can't lose! And of course, anyone chooses
"D" will get at least as much as everyone else will. If, for example in a class
of 20 poeple, 11 people choose "C" and 9 choose "D," then the 11 C-ers will
get 3 points apiece from the other C-ers (making 30 points), and zero from
the D-ers. So C-ers will get 30 points each. The D-ers, by contrast, will pick
up 5 points apiece from each of the C-ers, making 55 points, and 1 point from
each of the other D-ers, making 8 points, for a grand total of 63 points. No
matter what the distribution is, D-ers always do better than C-ers. Of course,
the more C-ers there are, the better everyone will do!

     By the way, I should make it clear that in making your choice, you should
not aim to be the winner, but simply to get as many points for yourself as
possible. Thus you should be happier to get 30 points (as a result of saying
"C" along with 10 others, even though the 9 D-sayers get more than you) than
to get 19 points (by saying "D" along with everybody else, so nobody "beats"
you).

     Of course, your hope is to be the only defector, thus really cleaning up:
with 19 C-ers, you'll get 95 points, and they'll each get 18 times 3, namely
54 points! But why am I doing the multiplication or any of this figuring for
you? You've been studying game theory. So have all of you! You are all
equally versed in game theory and understand about making rational choices.
Therefore, I hardly need to tell you that you are to make what you consider
to be your maximally rational choice. In particular, feelings of morality, guilt,
apathy, and so on, are to be disregarded. Reasoning alone (of course including
reasoning about others' reasoning) should be the basis of your decision.

     So all you need to do is make your choice. Write it down.
     It is to be understood (it almost goes without saying, but not quite) that
you are not to discuss your answer with anyone else from the class. The purpose
is to see what people do on their own, in isolation. Along with your answer you
should include a short explanation for why you made your particular choice.
     Adapted from Douglas Hofstadter, Metamagical Themas, p. 740.
     ---------------------
     Once everyone in class has made their choice, share your answers with the
class. Then answer the following questions about the class's responses.

Activity 4.3.1 Summary of responses. Create a summary of the responses
from the class-wide experiment.

  (a) How many C's were there?

  (b) How many D's were there?

  (c) What was the payoff to each C?

  (d) What was the payoff to each D?

Activity 4.3.2 Payoff matrix. Determine the payoff matrix for class-wide
Prisoner's Dilemma.

Hint. Although you played this game with each other person in the class,
this is still a 2 person game!

Activity 4.3.3 Reasons for choice. What are some reasons people chose
C? What are some reasons people chose D?

     Although we can now see what everyone chose, we might not agree that
everyone made the most rational choice. How might perfectly rational players
88  CHAPTER 4. NON-ZERO-SUM GAMES

play the game?

Activity 4.3.4 The rational choice. What appears to be the most rational
choice, C or D? If everyone is equally rational, then what would everyone do?
If everyone is equally rational, should everyone choose the same thing?

Activity 4.3.5 Everyone is rational. Now suppose everyone is equally
(and perfectly) rational. AND everyone knows that everyone else is equally
(and perfectly) rational. What should everyone choose?

Hint. If everyone knows that everyone will choose the same answer, what
should everyone choose to do?

    The next two exercises look at two more examples of games where players
can "Cooperate" or "Defect". How does changing the payoffs change the players'
incentive to cooperate or defect?

Activity 4.3.6 A game of cooperation and defection. Consider the
following game where C stands for Cooperate, and D stands for Defect.

Table 4.3.1 A Cooperate-Defect game

    C  D

    C (3, 3) (0, 50)

    D (50, 0) (.01, .01)

    What would you do? Why? What seems to be the most rational thing to
do? Why?

Activity 4.3.7 Another game of cooperation and defection. Consider
the following game where C stands for Cooperate, and D stands for Defect.

Table 4.3.2 Matrix for another Cooperate-Defect game

    C     D

    C (1000, 1000) (0, 100)

    D (100, 0) (100, 100)

    What would you do? Why? What seems to be the most rational thing to
do? Why?

Activity 4.3.8 Motivation to cooperate or defect. Looking at all three
of the above games (the Class-Wide experiment, Table 4.3.1, p. 88, and Ta-
ble 4.3.2, p. 88), can you think of what sort of payoffs you would need in order
to cooperate (C)? What about to defect (D)?

    Not every game where player's cooperate or defect is a Prisoner's Dilemma,
or even a dilemma. You can certainly change the payoffs in the above matrices
so that it is very clear what each player should do. But as you've seen with this
section's experiment, there is something special about the Prisoner's Dilemma.
Everyone does better if they all cooperate, but any one player does better to
defect. The next section will look more specifically at what makes a game a
Prisoner's Dilemma.

Check Your Understanding

1. Consider the Class-Wide Prisoner's Dilemma described at the beginning
      of this section. What is the payoff vector if Player 1 cooperates and Player
      2 defects?

         A. (3, 3)

         B. (0, 5)
4.3. A CLASS-WIDE EXPERIMENT              89

C. (5, 0)
D. (1, 1)
E. (3, 5)

         F. (3, 1)

2. In Class-Wide Prisoner's Dilemma every player was playing a two-person
      Prisoner's Dilemma with every other player. If you think most of the class
      will defect, then you should

         A. Cooperate

         B. Defect
3. In Class-Wide Prisoner's Dilemma every player was playing a two-person

      Prisoner's Dilemma with every other player. If you think most of the class
      will cooperate, then you should

A. Cooperate

         B. Defect
4. Consider the following Cooperate-Defect game where we can vary the

      value for a.

      Table 4.3.3

                              C        D

              C (a, a) (0, 5)

              D (5, 0) (1, 1)

    If we increase the value of a, we     the likelihood players will
choose to cooperate.

A. increase

B. decrease

         C. don't change
5. Consider the following Cooperate-Defect game where we can vary the

      value for a.

      Table 4.3.4

                              C        D

              C (3, 3) (0, a)

              D (a, 0) (1, 1)

    If we increase the value of a, we     the likelihood players will
choose to cooperate.

A. increase

         B. decrease

         C. don't change
6. Consider the following Cooperate-Defect game where we can vary the

      value for a.
90                             CHAPTER 4. NON-ZERO-SUM GAMES

    Table 4.3.5                                      D
                                                C  (a, 0)
                                                   (1, 1)
                                        C (3, 3)
                                        D (0, a)           the likelihood players will
        If we decrease the value of a, we
    choose to cooperate.

       A. increase

       B. decrease

       C. don't change

4.4 What Makes a Prisoner's Dilemma?

In this section we give a mathematical description of Prisoner's Dilemma and
compare it to some similar games.

    The Class-wide Prisoner's Dilemma game we played in Section 4.3, p. 86
has the payoff matrix given in Table 4.4.1, p. 90 for each pair of players.

Table 4.4.1 A Class-wide Prisoner's Dilemma.

                                                   Player 2

                                        Cooperate Defect

    Player 1  Cooperate                            (3, 3)  (0, 5)
              Defect
                                                   (5, 0)  (1, 1)

    We can classify each of the values for the payoffs as follows:

    · Reward for Mutual Cooperation: R = 3.

    · Punishment for Defecting: P = 1.

    · Temptation to Defect: T = 5.

    · Sucker's Payoff: S = 0.

                      Conditions for a Prisoner's Dilemma.
        In order for a game to be a variation of Prisoner's Dilemma it must
    satisfy two conditions:

      (1) T > R > P > S

      (2) (T + S)/2 < R

Let's apply this description of Prisoner's Dilemma to a few games we've seen.
We can use Conditions for a Prisoner's Dilemma, p. 90 to check if a game is
really a Prisoner's Dilemma.

Activity 4.4.1 Description of conditions. Describe conditions (1) and (2)
in Conditions for a Prisoner's Dilemma, p. 90 in words.

Hint. (T + S)/2 is the average of T and S.

Activity 4.4.2 The conditions for Classwide Prisoner's Dilemma.
Show the Conditions for a Prisoner's Dilemma, p. 90 hold for the Class-wide
Prisoner's Dilemma in Table 4.4.1, p. 90.
4.4. WHAT MAKES A PRISONER'S DILEMMA?                       91

Activity 4.4.3 The conditions for Prisoner's Dilemma.       Recall the
matrix for Prisoner's Dilemma from Example 4.2.3, p. 84.

Table 4.4.2 Prisoner's Dilemma (again).

                                      Prisoner 2

                              Confess Don't Confess

Prisoner 1  Confess           (8, 8)            (0.25, 10)
            Don't Confess
                              (10, 0.25)        (1, 1)

    Determine R, P, T, and S for this game. Be careful, think about what
cooperating versus defecting should mean. Show the Conditions for a Prisoner's
Dilemma, p. 90 are satisfied.

Hint. Time in jail is bad, so the bigger the number, the worse you do; thus,
it might be helpful to think of the payoffs as negatives.

Activity 4.4.4 The conditions for Chicken. Recall the matrix for Chicken
from Example 4.2.5, p. 85.

Table 4.4.3 Chicken (again).

                                      Driver 2

                              Swerve        Straight

Driver 1    Swerve            (0, 0)        (-1, 10)
            Straight
                              (10, -1) (-100, -100)

    Determine R, P, T, and S for this game. Again, think about what coop-
erating and defecting mean in this game. Determine if the Conditions for a
Prisoner's Dilemma, p. 90 are satisfied. If not, which condition(s) fail?

Activity 4.4.5 The conditions on another game. Consider the cooperate-
defect game where the first row/column is C and the second row/column is D:

            [                            ]
              (3, 3)           (0, 50) .
             (50, 0)          (.01, .01)

    Determine R, P, T, and S for this game. Determine if the Conditions for a
Prisoner's Dilemma, p. 90 are satisfied. If not, which condition(s) fail?

Activity 4.4.6 A little more practice. Consider the cooperate-defect game
where the first row/column is C and the second row/column is D:

            [                             ]
             (1000, 1000)      (0, 100) .
                (100, 0)      (100, 100)

    Determine R, P, T, and S for this game. Determine if Conditions for a
Prisoner's Dilemma, p. 90 are satisfied. If not, which condition(s) fail?

Activity 4.4.7 Compare the games. The games in Activity 4.4.4, p. 91,
Activity 4.4.5, p. 91, and Activity 4.4.6, p. 91 are not true Prisoner's Dilemmas.
For each game, how do the changes in payoffs affect how you play? In particular,
in Prisoner's Dilemma, a player will generally choose to defect. This results in
a non-optimal payoff for each player. Is this still true in Activity 4.4.4, p. 91,
Activity 4.4.5, p. 91, and Activity 4.4.6, p. 91? If possible, use canges in the
Conditions for a Prisoner's Dilemma, p. 90 to help explain any differences in
how one should play.

    We can now define defection as the idea that if everyone did it, things
would be worse for everyone. Yet, if only one (or a small) number did it, life
would be sweeter for that individual. We can define cooperation as the act
92                                  CHAPTER 4. NON-ZERO-SUM GAMES

of resisting temptation for the betterment of all players.

Activity 4.4.8 Example from real life. Give an example of defection and
cooperation from real life. Explain how your example of defection make things
worse for everyone if everyone did it, but would benefit the defector. Explain
how cooperation is improves things for all, even if the payoff is smaller for the
individual.

Check Your Understanding

1. Consider the cooperate-defect game

    [                                             ]
       (5, 5)                           (15, -1) .
                                        (10, 10)
     (-1, 15)

        Match the reward for mutual cooeration (R), the punishment for de-
    fecting (P), the temptation to defect (T), and the sucker's payoff (S) with
    their corresponding payoffs.

                                    -1  R

                                    15  S

                                    10  P

                                    5   T

2. True or False?
           True or False: the game

    [                                             ]
       (5, 5)                           (15, -1)
                                        (10, 10)
     (-1, 15)

    satisfies the Conditions for a Prisoner's Dilemma, p. 90.

3. Consider the cooperate-defect game

    [                                            ]
     (10, 10)                           (-1, 5) .
     (5, -1)                             (2, 2)

        Match the reward for mutual cooeration (R), the punishment for de-
    fecting (P), the temptation to defect (T), and the sucker's payoff (S) with
    their corresponding payoffs.

                                    5   R

                                    10  S

                                    -1  P

                                    2   T

4. True or False?
           True or False: the game

    [                                            ]
     (10, 10)                           (-1, 5)
     (5, -1)                             (2, 2)

    satisfies the Conditions for a Prisoner's Dilemma, p. 90.

5. Consider the cooperate-defect game

    [                                              ]
      (2, 2)                             (-5, 5) .
     (5, -5)                            (-2, -2)
4.4. WHAT MAKES A PRISONER'S DILEMMA?                      93

    Match the reward for mutual cooeration (R), the punishment for de-
fecting (P), the temptation to defect (T), and the sucker's payoff (S) with
their corresponding payoffs.

                                    -5  R

                                    -2  S

                                    5   P

                                    2   T

6. True or False?
           True or False: the game

                       [                           ]
                         (2, 2)          (-5, 5)
                        (5, -5)         (-2, -2)

satisfies the Conditions for a Prisoner's Dilemma, p. 90.

7. The game given in   [                          ]
                         (2, 2)         (-5, 5)

                                    (5, -5) (-2, -2)

has   equilibrium point(s).

A. 0

B. 1

C. 2

D. 3

8. Consider the cooperate-defect game

                       [                      ]
                        (-2, -2)        (5, 0) .
                          (0, 5)        (2, 2)

    Match the reward for mutual cooeration (R), the punishment for de-
fecting (P), the temptation to defect (T), and the sucker's payoff (S) with
their corresponding payoffs.

                                    -2  R

                                    5   S

                                    2   P

                                    0   T

9. True or False?
           True or False: the game

                       [                      ]
                        (-2, -2)        (5, 0)
                          (0, 5)        (2, 2)

satisfies the Conditions for a Prisoner's Dilemma, p. 90.

10. The game given in  [                             ]

                                    (-2, -2) (5, 0)

                                    (0, 5) (2, 2)

has   equilibrium point(s).

A. 0

B. 1
94                     CHAPTER 4. NON-ZERO-SUM GAMES

    C. 2

    D. 3

11. Consider the cooperate-defect game

                       [                                          ]
                           (0, 0)                    (-15, 20) .
                                                    (-10, -10)
                        (20, -15)

        Match the reward for mutual cooeration (R), the punishment for de-
    fecting (P), the temptation to defect (T), and the sucker's payoff (S) with
    their corresponding payoffs.

                                               20       R
                                               -10      S
                                               -15      P
                                               0        T

12. True or False?                                                ]
           True or False: the game                   (-15, 20)
                                                    (-10, -10)
                                      [
                                          (0, 0)

                                        (20, -15)

    satisfies the Conditions for a Prisoner's Dilemma, p. 90.

13. The game given in  [                                         ]
                           (0, 0)                   (-15, 20)

                       (20, -15) (-10, -10)

    has   equilibrium point(s).

    A. 0
    B. 1
    C. 2
    D. 3

4.5 Another Multiplayer Experiment

This activity needs to be played as a class. All players need to be able to
respond without being able to see the responses of others. Answers may be
revealed before moving on to the next question.
Activity 4.5.1 Without sharing your answers with others, select your answer
to the following questions. Try to be as honest about your answer as possible.
Make sure you have a reason for each answer.
Question 4.5.1 The lights go out in the neighborhood. Someone needs to call
the power company. If someone calls, everyone's lights go on.

 (A) Call

 (B) Don't call

                                                                                                     
4.5. ANOTHER MULTIPLAYER EXPERIMENT  95

Question 4.5.2 The same as in Question 4.5.1, p. 94, but now you have to
wait on hold for 5 minutes.

 (A) Call

 (B) Don't call

                                                                                                     
Question 4.5.3 The same as in Question 4.5.1, p. 94, but now you have to
wait on hold for 30 minutes.

 (A) Call

 (B) Don't call

                                                                                                     
Question 4.5.4 The same as in Question 4.5.1, p. 94, but now you have to
pay a $.50 service fee.

 (A) Call

 (B) Don't call

                                                                                                     
Question 4.5.5 The same as in Question 4.5.1, p. 94, but now you have to
pay a $2.50 service fee.

 (A) Call

 (B) Don't call

                                                                                                     
Question 4.5.6 The power lines go down in your small mountain community.
You have to hike 3 miles in the snow to notify the power company.

 (A) Hike to notify the power company

 (B) Stay home and let someone else do the hiking

                                                                                                     
Question 4.5.7 Everyone in your class cheats on an exam. The professor says
if someone confesses they receive an F. If no one confesses, everyone fails.

 (A) Confess

 (B) Don't confess

                                                                                                     
Question 4.5.8 Evil Dr. No captures the class and puts you in all in a shark
tank separated so you can't communicate. If one person volunteers to be eaten
then the rest go free. If no one volunteers after 10 minutes all get eaten by
sharks.

 (A) Volunteer

 (B) Don't volunteer

                                                                                                     
96  CHAPTER 4. NON-ZERO-SUM GAMES

Question 4.5.9 Evil Dr. No captures you and the five most important people
in your life and puts you in all in a shark tank separated so you can't commu-
nicate. If one person volunteers to be eaten then the rest go free. If no one
volunteers after 10 minutes all get eaten by sharks.

 (A) Volunteer

 (B) Don't volunteer

                                                                                                     
Question 4.5.10 For any "Big Brother" fans: choose to eat all your favorite
foods for a week or nasty "slop" for a week. If at least three people say slop,
everyone gets what they asked for. Otherwise, everyone is on slop.

 (A) Favorite foods

 (B) Slop

                                                                                                     
Question 4.5.11 OK, now let's get serious about this. Answer 5 points or 1
point. If at least one person says 1 point, everyone gets the number of points
they chose. Otherwise, everyone gets 0 points.

 (A) 5 points

 (B) 1 point

                                                                                                     
Question 4.5.12 Answer 20 points or 1 point. If at least one person says 1
point, everyone gets the number of points they chose. Otherwise, everyone gets
0 points.

 (A) 20 points

 (B) 1 point

                                                                                                     
Question 4.5.13 Answer 6 points or 5 points. If at least one person says 5
points, everyone gets the number of points they chose. Otherwise, everyone
gets 0 points.

 (A) 6 points

 (B) 5 points

                                                                                                     
Question 4.5.14 Answer 20 points or 1 point. If at least five people say 1
point, everyone gets the number of points they chose. Otherwise, everyone gets
0 points.

 (A) 20 points

 (B) 1 point

                                                                                                     
    After answering the above questions and seeing the responses from your
classmates, think about how you responded. Did this differ from how your
classmates responded? Try to give reasons for how you chose your responses
to the above questions. Ask classmates for their reasons for responding as they
4.5. ANOTHER MULTIPLAYER EXPERIMENT                         97

did. It can be particularly useful to share your answers with someone who
chose a different response from you. You can summarize the various reasons
for volunteering and not volunteering in the activities below.

Activity 4.5.2 Volunteer or not. After answering the questions in Ac-
tivity 4.5.1, p. 94, were you likely to volunteer or unlikely to volunteer? For
example, were you likely to be the one to call the power company or get eaten
by sharks, or were you generally hoping someone else would do it? If it de-
pended on the situation, explain under what circumstances you were likely to
volunteer.

Activity 4.5.3 Always a volunteer. After sharing your answers as a class,
did each situation have a volunteer? In other words, was there always someone
willing to call the power company or take fewer points? If there was a question
with no volunteer, can you suggest why?

Activity 4.5.4 Unlikely to volunteer. For which questions in Activ-
ity 4.5.1, p. 94 was it unlikely that there would be very many volunteers? Did
you take that into consideration when deciding if you were going to volunteer?

Activity 4.5.5 Reasons to volunteer. What are some reasons for volun-
teering? What are some reasons for not volunteering?

Check Your Understanding

The following questions are to help you reflect on the experiment from this
section. Although each question will indicate a "correct" answer, there is room
for discussion and disagreement about each of these questions.

1. As the cost of volunteering goes up, it becomes          likely that
      someone volunteers.

A. more

         B. less                                            likely that

2. As the reward for the group goes up, it becomes
      someone volunteers.

A. more

         B. less                                            likely

3. As the cost of having no volunteers goes up, it becomes
      that someone volunteers.

A. more

B. less

4. Although our experiment did not change the number of participants, think

about what you predict would happen if we now played this experiment

with the entire school or community. As the number of participants goes

up, it becomes  likely that there is a volunteer.

A. more

         B. less

5. Although our experiment did not change the number of participants, think
      about what you predict would happen if we now played this experiment
      with the entire school or community. As the number of participants goes
98                  CHAPTER 4. NON-ZERO-SUM GAMES

    up, it becomes  likely that any specific individual volunteers.

         A. more

         B. less
6. True or False?

           True or False: In trying to get the best outcome for yourself in this
      experiment, it is useful to consider how likely it is that other people vol-
      unteer.

4.6 Volunteer's Dilemma

In Section 4.5, p. 94 we played a game called Volunteer's Dilemma.

Example 4.6.1 A Volunteer's Dilemma. One example of a Volunteer's
Dilemma is the game where everyone chooses "1 point" or "5 points." If at least
one person writes down 1 point, then everyone gets the number of points they
wrote down. If no one chooses 1 point, then everyone gets 0 points. Choosing
"1 point" is considered volunteering or cooperating. Choosing to not volunteer
and take "5 points" is defecting.

     You should note that it is difficult to put this game into a matrix form since
payoffs depend on whether there is at least one volunteer or cooperator. 

     In this section we will compare Class-wide Prisoner's Dilemma with Volun-
teer's Dilemma. In particular, we want to think about the effect cooperating
and defecting have on the group of players. How does one player's choice affect
everyone else? What happens to the group if there is a single cooperator or
a single defector? What happens if everyone cooperates or everyone defects?
We will use the payoffs for Prisoner's Dilemma from Section 4.3, p. 86 and
Table 4.4.1, p. 90, given again in the following table.

Table 4.6.2 Class-wide Prisoner's Dilemma (again).

                               Player 2

                               Cooperate Defect

    Driver 1        Cooperate  (3, 3)  (0, 5)
                    Defect
                               (5, 0)  (1, 1)

Activity 4.6.1 Effect of a single defector in Class-wide Prisoner's
Dilemma. In Class-wide Prisoner's Dilemma, Table 4.6.2, p. 98, what effect
does one defector have on the group? In other words, if a single player defects,
how many points does he cost each of the other players?

Activity 4.6.2 Effect of everyone's defection in Class-wide Prisoner's
Dilemma. In Class-wide Prisoner's Dilemma, Table 4.6.2, p. 98, what effect
does everyone's defection have on the group? In other words, what is the most
points lost by the group if everyone defects?

Activity 4.6.3 Effect of your defection in Class-wide Prisoner's
Dilemma. In Class-wide Prisoner's Dilemma, Table 4.6.2, p. 98, what ef-
fect could your own defection have on the group? In other words, how many
points does the group lose if you defect instead of cooperate? You may need
to consider different cases depending on how many cooperators there are. For
example what if there are no cooperators? What if there are no defectors?
What if there are some of each?

Activity 4.6.4 Effect of a single defector in Volunteer's Dilemma.
In Volunteer's Dilemma, with the payoffs given in Example 4.6.1, p. 98, what
4.6. VOLUNTEER'S DILEMMA  99

effect does one defector have on the group? In other words, if there is a single
defector, how many points do each of the other players lose?

Activity 4.6.5 Effect of everyone's defection in Volunteer's Dilemma.
In Volunteer's Dilemma, with the payoffs given in Example 4.6.1, p. 98, what
effect does everyone's defection have on the group? In other words, if everyone
defects, how many points does the group lose?

Activity 4.6.6 Effect of your defection in Volunteer's Dilemma. In
Volunteer's Dilemma, with the payoffs given in Example 4.6.1, p. 98, what
effect could your own defection have on the group? In other words, how many
points does the group lose if you defect instead of cooperate? You may need
to consider different cases depending on how many cooperators there are. For
example what if there are no cooperators? What if there are no defectors?
What if there are some of each?

     Now that we've considered how an individual decision can affect the group,
we can think about what the most rational strategy is in a multiplayer Pris-
oner's Dilemma or a Volunteer's Dilemma.

Activity 4.6.7 Rationality in Class-wide Prisoner's Dilemma. Con-
sidering your answers above and to previous work with Prisoner's Dilemma, in
Class-wide Prisoner's Dilemma, which is more rational, to be a cooperator or
a defector? Why?

Activity 4.6.8 Everyone is rational in Class-wide Prisoner's Dilemma.
Whichever strategy you chose in Activity 4.6.7, p. 99, explain what would hap-
pen if everyone was the most rational. Is it now more rational to do the
opposite?

Activity 4.6.9 Rationality in Volunteer's Dilemma. Considering your
answers above, in Volunteer's Dilemma, which is more rational, to be a coop-
erator (volunteer) or a defector? Why?

Activity 4.6.10 Everyone is rational in Volunteer's Dilemma.
Whichever strategy you chose in Activity 4.6.9, p. 99, explain what would hap-
pen if everyone was the most rational. Is it now more rational to do the
opposite?

Activity 4.6.11 Class-wide Chicken. Volunteer's Dilemma can also be
called Class-wide Chicken. Try to describe this class-wide game in terms of
"swerving" and "going straight." How do the payoffs for Volunteer's Dilemma
relate to the payoffs for Chicken?

     Even though the Class-wide Prisoner's Dilemma and the Volunteer's Dilemma
games were played with multiple players, each game was only played once. In
the next section we look at what might happen if we repeatedly play Prisoner's
Dilemma with the same opponent.

Check Your Understanding

1. Consider the Volunteer's Dilemma in which each player can choose 1 point
      or 0 points. If no one chooses 0, everyone loses 10 points. If at least one
      person chooses 0, every player gets the points they chose. A player who
      chooses 0 is a

         A. cooperator.

         B. defector.
100                        CHAPTER 4. NON-ZERO-SUM GAMES

2. Consider the Volunteer's Dilemma in which each player can choose 1 point
      or 0 points. If no one chooses 0, everyone loses 10 points. If at least one
      person chooses 0, every player gets the points they chose. A player who
      chooses 1 is a

     A. cooperator.

         B. defector.

3. Consider the Volunteer's Dilemma in which each player can choose 1 point
      or 0 points. If no one chooses 0, everyone loses 10 points. If at least one
      person chooses 0, every player gets the points they chose. Suppose you
      are playing this game in a class of 20 people. If everyone chooses 0, how
      many points does each person get?

4. Consider the Volunteer's Dilemma in which each player can choose 1 point
      or 0 points. If no one chooses 0, everyone loses 10 points. If at least one
      person chooses 0, every player gets the points they chose. Suppose you
      are playing this game in a class of 20 people. If no one chooses 0, how
      many points does each person get?

5. Consider the Volunteer's Dilemma in which each player can choose 1 point
      or 0 points. If no one chooses 0, everyone loses 10 points. If at least one
      person chooses 0, every player gets the points they chose. Suppose you
      are playing this game in a class of 20 people. If one person chooses 0 and
      19 choose 1, how many points does a defector get?

6. Consider the Volunteer's Dilemma in which each player can choose 1 point
      or 0 points. If no one chooses 0, everyone loses 10 points. If at least one
      person chooses 0, every player gets the points they chose. Suppose you
      are playing this game in a class of 20 people. If one person chooses 1 and
      19 choose 0, how many points does a defector get?

7. True or False?
           True or False: In the Volunteer's Dilemma in which players choose 1

      point or 0 points and if no one chooses 0, everyone loses 10, a cooperator
      will get 0 points no matter what anyone else does.

8. True or False?
           True or False: In the Volunteer's Dilemma in which players choose 1

      point or 0 points and if no one chooses 0, everyone loses 10, a defector
      will get 1 point no matter what anyone else does.

9. Consider the class-wide or multiplayer Prisoner's Dilemma with the fol-

     lowing payoff matrix  [                  ]
                             (1, 1)  (-5, 5) ,
                            (5, -5)   (0, 0)

     where every player is playing the game against every other player. A
     player who chooses Row or Column 1 is a

     A. cooperator.

     B. defector.

10. Consider the class-wide or multiplayer Prisoner's Dilemma with the fol-

     lowing payoff matrix  [                  ]
                             (1, 1)  (-5, 5) ,
                            (5, -5)   (0, 0)

     where every player is playing the game against every other player. A
     player who chooses Row or Column 2 is a
4.7. REPEATED PRISONER'S DILEMMA            101

A. cooperator.

B. defector.

11. Consider the class-wide or multiplayer Prisoner's Dilemma with the fol-

lowing payoff matrix  [                  ]
                        (1, 1)  (-5, 5) ,
                       (5, -5)   (0, 0)

where every player is playing the game against every other player. Suppose
you are playing this game in a class of 20 people. If everyone chooses Row/
Column 1, how many points does each person get?

12. Consider the class-wide or multiplayer Prisoner's Dilemma with the fol-

lowing payoff matrix  [                  ]
                        (1, 1)  (-5, 5) ,
                       (5, -5)   (0, 0)

where every player is playing the game against every other player. Suppose
you are playing this game in a class of 20 people. If no one chooses Row/
Column 1, how many points does each person get?

13. Consider the class-wide or multiplayer Prisoner's Dilemma with the fol-

lowing payoff matrix  [                  ]
                        (1, 1)  (-5, 5) ,
                       (5, -5)   (0, 0)

where every player is playing the game against every other player. Suppose
you are playing this game in a class of 20 people. If one player chooses
Row/Column 1 and 19 choose Row/Column 2, how many points does a
defector get?

14. Consider the class-wide or multiplayer Prisoner's Dilemma with the fol-

lowing payoff matrix  [                  ]
                        (1, 1)  (-5, 5) ,
                       (5, -5)   (0, 0)

where every player is playing the game against every other player. Suppose
you are playing this game in a class of 20 people. If 19 players chooses
Row/Column 1 and one chooses Row/Column 2, how many points does
a defector get?

15. True or False?

True or False: In the multiplayer Prisoner's Dilemma with payoff ma-

trix                  [                  ]

                         (1, 1) (-5, 5) ,
                         (5, -5) (0, 0)

a defector always does better than a cooperator no matter how many
cooperators there are.

4.7 Repeated Prisoner's Dilemma

In this section we look at two players playing Prisoner's Dilemma repeatedly.
We call this game an iterated Prisoner's Dilemma. Recall the general Pris-
oner's Dilemma matrix from previous sections, given again in Table 4.7.1,
p. 101.
102            CHAPTER 4. NON-ZERO-SUM GAMES

Table 4.7.1 A Prisoner's Dilemma matrix.

                          Player 2

                          Cooperate Defect

     Player 1  Cooperate  (3, 3)          (0, 5)
               Defect
                          (5, 0)          (1, 1)

    Before playing the iterated version, think about how you would play the
above game if you only play it once with an opponent. We'll give the game
some context in the following activity.

Activity 4.7.1 A single internet purchase. Suppose the above matrix in
Table 4.7.1, p. 101 represents the situation of purchasing an item (say, a used
textbook) on the internet where both parties are untraceable. You agree to
send the money at the same time that the seller agrees to send the book. Then
we can think of cooperating as each of you sending money/ book, and defecting
as not sending money/ book. Why might a player cooperate? Why might a
player defect?

Activity 4.7.2 Repeated internet purchases. Now suppose you wish to
continue to do business with the other party. For example, instead of buying a
used textbook, maybe you are buying music downloads. Why might a player
cooperate? Why might a player defect? Do these reasons differ from your
reasons in Activity 4.7.1, p. 102?

    It is possible that your answers to the above questions depended on the
context, so let's go back to just thinking about the game as a simple matrix
game. In Class-wide Prisoner's Dilemma, you played the game against multiple
players, but you played only once with each player. Think about your strategy
for the Class-wide Prisoner's Dilemma, but now think about repeating the
game several times with the same player. Do you think your strategy would
change? Remember, if we repeat the game we are not restricted to playing a
pure strategy.

Activity 4.7.3 Strategy for repeated Prisoner's Dilemma. Suggest a
strategy for playing the Prisoner's Dilemma in Table 4.7.1, p. 101 repeatedly.
DON'T SHARE YOUR STRATEGY WITH ANYONE YET!

    Now let's see how your strategy works by actually playing the game several
times.

Activity 4.7.4 Play Prisoner's Dilemma repeatedly. Play 10 rounds of
Prisoner's Dilemma with someone in class. Use your suggested strategy. Keep
track of the payoffs. Did your strategy seem effective? What should it mean
to have an "effective" strategy?

    We are now going to play a Prisoner's Dilemma Tournament! Several strate-
gies are suggested below. Choose one of the strategies or keep playing with
your own strategy. You are to play your strategy against everyone else in the
class. Keep a running total of your score. Don't tell your opponents your
strategy.

    Some possible strategies:

· Strategy: Defection. Your strategy is to always choose DEFECT (D).

· Strategy: Cooperation. Your strategy is to always choose COOPER-
   ATE (C).

· Strategy: Tit for Tat. Your strategy is to play whatever your opponent
   just played. Your first move is to COOPERATE (C), but then you need
   to repeat your opponent's last move.
4.7. REPEATED PRISONER'S DILEMMA  103

   · Strategy: Tit for Two Tats. Your strategy is to COOPERATE (C)
       unless your opponent DEFECTS twice in a row. After two D's you
       respond with D.

   · Strategy: Random (1/2, 1/2). Your strategy is to COOPERATE (C)
       randomly 50% of the time and DEFECT (D) 50% of the time. [Note:
       it will be hard to be truly random, but try to play each option approxi-
       mately the same amount.]

   · Strategy: Random (3/4, 1/4). Your strategy is to COOPERATE (C)
       randomly 75% of the time and DEFECT (D) 25% of the time. [Note: it
       will be hard to be truly random, but try to play C more often than D.]

   · Strategy: Random (1/4, 3/4). Your strategy is to COOPERATE (C)
       randomly 25% of the time and DEFECT (D) 75% of the time. [Note: it
       will be hard to be truly random, but try to play D more often than C.]

   · Strategy: Tit for Tat with Occasional Surprise D. Your strategy
       is to play whatever your opponent just played. Your first move is to
       COOPERATE (C), but then you need to repeat your opponent's last
       move. Occasionally, you will deviate from this strategy by playing D.

Activity 4.7.5 A Prisoner's Dilemma tournament. WITHOUT SHAR-
ING YOUR STRATEGY, play Prisoner's Dilemma 10 times with each of the
other members of the class. Keep track of the payoffs for each game and your
total score.
After playing Repeated Prisoner's Dilemma as a class, can you determine who
used which strategy? At this point you may share your strategy with others.
Was your strategy more effective with some strategies than with others? If
some of the above strategies were not used, can you guess how your strategy
would have done against them?

Activity 4.7.6 Effectiveness of your strategy. Describe which opponents'
strategies seemed to get you more points, which seemed to get you fewer?

Activity 4.7.7 Winning strategies. Describe the strategy or strategies
that had the highest scores in the tournament. Does this seem surprising?
Why or why not? How do the winning strategies compare to the strategy you
suggested in Activity 4.7.3, p. 102?

    What strategies seem the most rational? Are pure strategies the most
rational? Does it depend on what sort of strategy your opponent is playing?

Activity 4.7.8 Rationality in repeated Prisoner's Dilemma. How does
Repeated Prisoner's Dilemma differ from the "one-time" Prisoner's Dilemma?
Try to think in terms of rational strategies.

    As Activity 4.7.2, p. 102 suggests we can think of real-life interactions that
can be modeled as a Prisoner's Dilemma.

Activity 4.7.9 Example of Repeated Prisoner's Dilemma in real
life. Describe a situation from real life that resembles a Repeated Prisoner's
Dilemma.

    Repeated or Iterated Prisoner's Dilemma has applications to biology and
sociology. If you think of higher point totals as "success as a species" in biology
or "success of a society" in sociology, we can try to determine which strategies
seem the most effective or successful. Individuals do not need the highest point
total to be successful, but low point totals will not succeed. Just like grades
in a course, you don't need the highest score to pass a class, but very bad
scores will fail. In order to model the situation of a society, think about what
104                            CHAPTER 4. NON-ZERO-SUM GAMES

happens to defectors in a society of cooperators or cooperators in a society of
defectors. Who will be able to succeed?

Activity 4.7.10 Only a few defectors. How do a few defectors fare in a
society of mostly cooperators? How do the cooperators fare? In other words,
who will be more successful? Keep in mind that everyone is playing with
lots of cooperators and only a few defectors. Who will have the most points,
cooperators or defectors?

Activity 4.7.11 Only a few cooperators. How do a few cooperators fare
in a society of mostly defectors? How do the defectors fare? (In other words,
who will be more successful?) Keep in mind that everyone is playing with
lots of defectors and only a few cooperators. Who will have the most points,
cooperators or defectors?

    After thinking about individuals in a society playing pure strategies, what
happens to individiuals who are playing some of the mixed strategies listed
above?

Activity 4.7.12 A society of TIT-FOR-TATers. Now consider a society
of mostly TIT-FOR-TATers. How do a few defectors fare in a society of mostly
TIT-FOR-TATers? How do the TIT-FOR-TATers fare? How would a few
cooperators fare with the TIT-FOR-TATers? Would the evolution of such a
society favor cooperation or defection?

    The TIT-FOR-TAT strategy is particularly interesting in an iterated Pris-
oner's Dilemma. It has a few special characteristics that lead to success. First
it is responsive in that it responds to the strategy of the other player. If the
other player is cooperating, the TIT-FOR-TAT strategy will be able to gain
the 3 points on each round. If the other player is defecting, it will defect so as
to not keep getting the sucker's payoff of 0. The random strategies and pure
strategies, for example, are not responsive. They do not respond to how the
other player is playing. Chances are when you played in the tournament, you
wanted to be able to adapt your strategy to respond to how your opponent
was playing.

    The TIT-FOR-TAT strategy is also nice in that it starts by cooperating.
If it meets another cooperator it will continue to cooperate. If the opponent at
some point begins cooperating, it will, too. However, it is also unexploitable.
This means that a defector cannot take advantage of the "niceness." It "pun-
ishes" any defection with an in-kind defection.

    The TIT-FOR-TAT behavior has been observed in some animal popula-
tions, but you also might be able to think of situations in your own life where
you or your friends have employed such a strategy with each other! Has it been
effective for you?

Check Your Understanding

1. In a Prisoner's Dilemma, the best outcome for a player is if they  ,

     while their opponent      .

     A. cooperate; cooperates

     B. cooperate; defects

     C. defect; defects

     D. defect; cooperates
4.8. POPULAR CULTURE: PRISONER'S DILEMMA AND CHICKEN 105

2. In a standard game of Chicken, the best outcome for a player is if they

, while their opponent             .

A. cooperate; cooperates

B. cooperate; defects

C. defect; defects

D. defect; cooperates

3. In a repeated (or iterated) Prisoner's Dilemma, a player really wants their

opponent to              .

A. cooperate.

B. defect.

4. Now think about what should happen if we iterated (repeated) a game

of Chicken. In an iterated game of Chicken, a player really wants their

opponent to              .

A. cooperate.

B. defect.

5. In a repeated (or iterated) Prisoner's Dilemma, if a player always defects,

the the other player should     .

A. cooperate.

B. defect.

6. In a repeated (or iterated) game of Chicken, if a player always defects, the

the other player should      .

         A. cooperate.

         B. defect.
7. True or False?

           True or False: In an iterated Prisoner's Dilemma, it can be beneficial
      to cooperate in order to encourage your opponent to cooperate.

8. True or False?
           Recall in repeated zero-sum games, if there was a pure strategy equi-

      librium, then players never benefit from playing a mixed strategy. True or
      False: In a repeated non-zero-sum game with a pure strategy equilibrium,
      players never benefit from playing a mixed strategy.

9. True or False?
           Recall in repeated zero-sum games players never benefit from playing a

      strategy with a predictable pattern. True or False: In a repeated non-zero-
      sum game a player may benefit from playing a strategy with a predictable
      pattern.

4.8 Popular Culture: Prisoner's Dilemma and
     Chicken

In this section, we will look at applications of Prisoner's Dilemma and Chicken
in popular culture.
106                              CHAPTER 4. NON-ZERO-SUM GAMES

    The movie Return to Paradise (1998) explores a Prisoner's Dilemma through-
out the film. The two main characters, Tony and Sheriff, must decide if they
will cooperate by returning to Malaysia to serve time in prison, or defect by not
returning to Malaysia. If both defect, their friend will die in prison. If both
cooperate, their friend will be released and they will each serve short sentences.

Question 4.8.1 Give a payoff matrix to model the Prisoner's Dilemma in the

film. By the end of the film have the payoffs changed? Is it still a Prisoner's

Dilemma? Explain.                                          

Question 4.8.2 In the classic Prisoner's Dilemma, communication is not al-

lowed between the players. In the film, Tony and Sheriff can communicate

all they want. How does this communication impact the Prisoner's Dilemma.

Does it help or hinder their choice of strategy? Explain.  

     The movie Rebel Without a Cause (1955) contains an iconic Chicken scene,

in which the two characters race towards a cliff. The last one to jump out of

his car is declared the winner.

Question 4.8.3 Does Jim win or lose the game of Chicken? Explain your

answer.                                                    

Question 4.8.4 The movie Footloose (1984) also has a Chicken scene (this

time with tractors). Compare the Chicken scenes in Rebel and Footloose. Is

the Chicken game used similarly in each? In both scenes, one player has no

choice of strategy. Why might the writer have made this choice in each of these

films?                                                     

     In the film Crazy Rich Asians (2018), after getting engaged to Nick, Rachel

is in a battle of wills with her future Mother-in-Law, Eleanor. In one scene,

Rachel explicitly describes the battle as a game of Chicken. Both Rachel and

Eleanor want the other to "swerve" and back out of Nick's life (or at least stop

controlling it so much). They are determined to show their strength by not

backing down (going "straight"). If neither back down it is clear that they will

both lose Nick.

Question 4.8.5 How does the film ultimately resolve the conflict? Who "wins"

and what is the director trying to say about the characters in this resolution?

                                                           

Question 4.8.6 It is interesting to note that many classic Chicken scenes

have male protagonists, and the game is intended to demonstrate dominance.

In contrast, the protagonists in Crazy Rich Asians are women. Compare any

gender differences in the Chicken scenarios in, say, Footloose, and in Crazy

Rich Asians.                                               

Question 4.8.7 Given the classic presentation of Chicken (players choosing

to rick their lives driving towards each other), it can be tempting to say that

the only rational approach to Chicken is just to refuse to play. In Crazy Rich

Asians, do the characters have such a choice? Explain how the situation forces

the characters to engage in the game of Chicken. You might consider what it

means for a character to refuse to play.                   

     Dilemmas such as Prisoner's Dilemma and Volunteer's Dilemma are used

in some game shows and television competitions. For example, In Friend or

Foe (2002-2003) after working together to win a pot of money, the contestants

must decide if they are a "Friend" or a "Foe". If they both pick Friend, they

split the money. If one picks Foe, while the other picks Friend, Foe gets all the

money. If they both pick Foe, they both get nothing.

Question 4.8.8 Is the game in Friend or Foe really a Prisoner's Dilemma?

Explain why you think it is or isn't.                      
4.8. POPULAR CULTURE: PRISONER'S DILEMMA AND CHICKEN 107

Question 4.8.9 The players in Friend or Foe are allowed to communicate and

negotiate. What are some strategies you would use to convince your opponent

to say "Friend"?                                                  

Question 4.8.10 As we studied Prisoner's Dilemma, we saw that it was more

rational to defect (choose Foe). It turns out, over the course of the game show,

more contestants said Friend. Explain why, in this context, you think people

often chose Friend.                                               

An example of a Volunteer's Dilemma can be seen starting in Season 41

of Survivor (2021). Three contestants must decide to "Protect" their vote

or "Risk" their vote. Their vote is very valuable in the game. If all three

contestants choose Protect, they all keep their votes. If at least one contestant

chooses to Protect her vote, then all three keep their votes and any contestants

who chose Risk get an extra vote. If all three choose Risk, they all lose their

vote.

Question 4.8.11 Explain why this game in Survivor is a Volunteer's Dilemma.

If you were a contestant on Survivor, what would you choose to do and why?

Are there certain conditions that would make you more likely to choose Risk?

If you are familiar with the show, you might want to think about whether you

are more or less likely to Risk your vote if you feel you are in danger of being

voted off the island.                                             

Another example of a more complicated Volunteer's Dilemma occurs in

Season 2 of The Traitors, New Zealand, Episode 10 (2023). The five remaining

contestants are taken to separate locations and have no way of communicating.

Each is presented with a very unpleasant task.

· Anna: Get "The Traitor" logo tattooed on any part of her body.

· Brooke: Lying in a bathtub and getting covered by maggots and cock-
   roaches for 3 minutes.

· Colin: Eat a platter of delicacies consisting of a heart, a tongue and an
   eyeball of an animal.

· Julia: Submerging herself in a cryotherapy chamber for at least 3 minutes
   at a temperature of -140C minimum.

· Sam S: Get a monk's haircut, which is shaving the top and underneath
   of his hair while leaving hair around the back and sides.

If exactly four of them complete the task, they win money for the prize pot at
the end of the game. Otherwise they don't add any money to the prixe pot.

Question 4.8.12 Explain why this version of the game is more complicated
than a standard Volunteer's Dilemma. How would you decide whether or not
to complete your task if you were playing this game? Would it matter which
task you were given? Even if you couldn't communicate, how would knowing
who your fellow contestants are help you decide whether to complete your task?

                                                                                                    
    Now try to apply the models of cooperate-defect games to your own popular
culture, political, or social examples.

Question 4.8.13 Suppose players are allowed to communicate in a Prisoner's
Dilemma. Explain the relationship between trust and communication in a Pris-
oner's Dilemma. Give an example from a film demonstrating the relationship.

                                                                                                    
Question 4.8.14 Why might a writer include a Chicken scene in a film? What
key attributes might the director be trying to display about the winner of
108                              CHAPTER 4. NON-ZERO-SUM GAMES

Chicken and the loser? Use an example from popular culture to demonstrate

your answer.                                                          

Question 4.8.15 One of the interesting comparisons between Prisoner's

Dilemma and Chicken is with their equilibrium points. Players in a Prisoner's

Dilemma can reach an equilibrium point if they play the same way. Players

in a Chicken game can reach an equilibrium if they choose different strategies.

Find examples of how these games are used in popular culture to emphasize

differences between characters.                                       

Question 4.8.16 Give an example of a political or social situation that can be

modeled by a Prisoner's Dilemma or Chicken, what does it mean to cooperate

or defect in this situation?                                          

Question 4.8.17 Find a news article that describes a political or economic

situation as being either a Prisoner's Dilemma or a game of Chicken. Do you

agree that the situation is appropriately described as that game? Does the

article seem to favor cooperating or defecting? Explain your answer.  
References

[1] Roy Gardner, Games for Business and Economics, Wiley, 2003.
[2] Douglas Hofstadter, Metamagical Themas: Questing for the Essence of

       Mind and Pattern, Basic Books, 1985.
[3] Jennifer Nordstrom, "Battles of Wits and Matters of Trust: Game The-

       ory in Popular Culture", Mathematics and Popular Culture: Essays on
       Appearances in Film, Fiction, Games, Television and Other Media, eds.
       E. Sklar and J. Sklar, McFarland, 2012, pp. 86-98.
[4] William Poundstone, Prisoner's Dilemma: John von Neumann, Game
       Theory, and the Puzzle of the Bomb, Anchor Books, 1993.

                                                 109
Index

Crazy Rich Asians, 106                 expected value, 27, 59
Dr. Strangelove, 36                    expected value solution, 59
Footloose, 106
Friend or Foe, 106                     finite game, 3
Rebel Without a Cause, 106
Return to Paradise, 106                game
Sage, 53                                     Cake Cutting, 10
Survivor, 107                                Competitive Advantage, 14
The Princess Bride, 37                       generalized One-Card Stud
The Traitors, New Zealand, 107                     Poker, 31
                                             Liar's Poker, 64
augmented matrix, 67, 68                     Matching Pennies, 5, 60
                                             One-Card Stud Poker, 29
Cake Cutting game, 10                        Rock-Paper-Scissors, 14
Cake Division, 1                             Volunteer's Dilemma, 94
Chicken, 82
                                       game matrix, 5
      in popular culture, 105          generalized One-Card Stud Poker,
Class-Wide Prisoner's Dilemma,
                                                   31
            86                         graphical solution, 43
Competitive Advantage, 14
constant-sum game, see also            infinite game, 3
                                       iterated Prisoner's Dilemma, 101
            zero-sum game, 9
cooperate, 86                          Liar's Poker, 64

      strategy, 91                     Matching Pennies, 5, 60
cooperation, 91                        matrix, 5
cooperative game, 83
                                             augmented, 68
defect, 86                             maximin mixed strategy, 48, 55
      strategy, 91                     maximin strategy, 20

defection, 91                                expected value solution, 59
dominated by, 17                             graphical solution, 43
dominated strategy, 17                       repeated games, 47, 55
dominates, 17                          minimax, 20
                                       mixed strategy, 40
equally likely events, 25                    expected value solution, 59
equilibrium, 12, 13, 32                      graphical solution, 43
                                       mixed strategy equilibrium, 49
      mixed strategy, 49
equilibrium pair, 12, 32               net gain, 74
equilibrium point, 13, 32              non-cooperative game, 79, 83
expected payoff                        non-zero-sum game, 77

      mixed strategy, 46        111
112                                                                    INDEX

One-Card Stud Poker, 29            self-interest, 2, 5
                                   solution, 3
payoff, 2, 5
payoff vector, 5                         expected value, 59
perfect information, 3                   graphical, 43
                                         using Sage, 53
      in popular culture, 36       Solution Theorem for Zero-Sum
perfectly logical, 6
player, 1                                      Games, 33
popular culture                    strategy

      Chicken, 105                       cooperate, 91
      perfect information, 36            defect, 91
      Prisoner's Dilemma, 105            dominated, 17
      rationality, 36                    maximin, 20
Prisoner's Dilemma, 82                   maximin mixed, 48, 55
      conditions, 90                     minimax, 20
      in popular culture, 105            mixed, 40
      multiplayer, 86                    pure, 40
      repeated, 101                      repeated game, 40
probability, 25                          Tit for Tat, 102
proof by contradiction, 33         strategy pair, 10
pure strategy, 40                  symmetric game, 74
                                   system of equations, 67
rational, 2
rationality                        Tic Tac Toe, 3
                                   Tit for Tat strategy, 102
      in popular culture, 36
repeated game, 39                  Volunteer's Dilemma, 94, 98
Rock-Paper-Scissors, 14, 40
                                   zero-sum game, 9
      expected value solution, 62
row reduction, 68
          Colophon

This text was authored in PreTeXt.
