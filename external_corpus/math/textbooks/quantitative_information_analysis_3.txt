1. Sampling and Data
     1. Sampling and Data
     2. Statistics
     3. Probability
     4. Key Terms
     5. Data
     6. Sampling
     7. Variation
     8. Answers and Rounding Off
     9. Frequency
   10. Summary

2. Descriptive Statistics
     1. Descriptive Statistics
     2. Displaying Data
     3. Stem and Leaf Graphs (Stemplots)
     4. Histograms
     5. Box Plots
     6. Measures of the Location of the Data
     7. Measures of the Center of the Data
     8. Skewness and the Mean, Median, and Mode
     9. Measures of the Spread of the Data
   10. Summary of Formulas

3. Probability Topics
     1. Probability Topics
     2. Terminology
     3. Independent and Mutually Exclusive Events
     4. Two Basic Rules of Probability
     5. Contingency Tables
     6. Summary of Formulas

4. Discrete Random Variables
     1. Discrete Random Variables
     2. Probability Distribution Function (PDF) for a Discrete
        Random Variable

     3. Mean or Expected Value and Standard Deviation
     4. Common Discrete Probability Distribution Functions
     5. Binomial
     6. Poisson
     7. Summary of Functions
5. Continuous Random Variables
     1. Continuous Random Variables
     2. Continuous Probability Functions
     3. The Uniform Distribution
     4. The Exponential Distribution
     5. Summary of the Uniform and Exponential Probability

        Distributions
6. The Normal Distribution

     1. The Normal Distribution
     2. The Standard Normal Distribution
     3. Z-scores
     4. Normal Distribution: Areas to the Left and Right of x
     5. Calculations of Probabilities
     6. Summary of Formulas
7. The Central Limit Theorem
     1. The Central Limit Theorem
     2. The Central Limit Theorem for Sample Means (Averages)
     3. The Central Limit Theorem for Sums
     4. Using the Central Limit Theorem
     5. Summary of Formulas
8. Hypothesis Testing: Single Mean and Single Proportion
     1. Hypothesis Testing: Single Mean and Single Proportion
     2. Null and Alternate Hypotheses
     3. Outcomes and the Type I and Type II Errors
     4. Distribution Needed for Hypothesis Testing
      5. Assumption
      6. Rare Events
      7. Using the Sample to Support One of the Hypotheses
      8. Decision and Conclusion
      9. Additional Information
     10. Summary of the Hypothesis Test
     11. Lab: Hypothesis Testing of a Single Mean and Single

         Proportion
 9. Hypothesis Testing: Two Means, Paired Data, Two Proportions

      1. Hypothesis Testing: Two Population Means and Two
         Population Proportions

      2. Comparing Two Independent Population Means with
         Unknown Population Standard Deviations

      3. Comparing Two Independent Population Means with
         Known Population Standard Deviations

      4. Comparing Two Independent Population Proportions
      5. Matched or Paired Samples
      6. Summary of Types of Hypothesis Tests
10. Confidence Intervals
      1. Confidence Intervals
      2. Confidence Interval, Single Population Mean, Population

         Standard Deviation Known, Normal
      3. Confidence Interval, Single Population Mean, Standard

         Deviation Unknown, Student-T
      4. Confidence Interval for a Population Proportion
      5. Summary of Formulas
11. F Distribution and ANOVA
      1. F Distribution and ANOVA
      2. ANOVA
      3. The F Distribution and the F Ratio
      4. Facts About the F Distribution
      5. Test of Two Variances
      6. Summary
12. The Chi-Square Distribution

      1. The Chi-Square Distribution
      2. Notation
      3. Facts About the Chi-Square Distribution
      4. Goodness-of-Fit Test
      5. Test of Independence
      6. Test of a Single Variance (Optional)
      7. Summary of Formulas
13. Linear Regression and Correlation
      1. Linear Regression and Correlation
      2. Linear Regression and Correlation: Linear Equations
      3. Linear Regression and Correlation: Slope and Y-Intercept

         of a Linear Equation
      4. Scatter Plots
      5. The Regression Equation
      6. The Correlation Coefficient
      7. Facts About the Correlation Coefficient for Linear

         Regression
      8. Prediction
      9. Outliers
     10. 95% Critical Values of the Sample Correlation Coefficient

         Table
     11. Linear Regression and Correlation: Summary
Sampling and Data
This module provides a brief introduction to the field of statistics, including
examples of how these topics shows up in a variety of real-life examples.

Student Learning Outcomes

By the end of this chapter, the student should be able to:

      Recognize and differentiate between key terms.
      Apply various types of sampling methods to data collection.
      Create and interpret frequency tables.

Introduction

You are probably asking yourself the question, "When and where will I use
statistics?". If you read any newspaper or watch television, or use the
Internet, you will see statistical information. There are statistics about
crime, sports, education, politics, and real estate. Typically, when you read a
newspaper article or watch a news program on television, you are given
sample information. With this information, you may make a decision about
the correctness of a statement, claim, or "fact." Statistical methods can help
you make the "best educated guess."

Since you will undoubtedly be given statistical information at some point in
your life, you need to know some techniques to analyze the information
thoughtfully. Think about buying a house or managing a budget. Think
about your chosen profession. The fields of economics, business,
psychology, education, biology, law, computer science, police science, and
early childhood development require at least one course in statistics.

Included in this chapter are the basic ideas and words of probability and
statistics. You will soon understand that statistics and probability work
together. You will also learn how data are gathered and what "good" data
are.
Statistics
This module introduces the concept of statistics, specifically the ability to
use statistics to describe data (descriptive statistics) as well as draw
conclusions (inferential statistics). An optional classroom exercise is
included.
The science of statistics deals with the collection, analysis, interpretation,
and presentation of data. We see and use data in our everyday lives.

Optional Collaborative Classroom Exercise

In your classroom, try this exercise. Have class members write down the
average time (in hours, to the nearest half-hour) they sleep per night. Your
instructor will record the data. Then create a simple graph (called a dot
plot) of the data. A dot plot consists of a number line and dots (or points)
positioned above the number line. For example, consider the following
data:
5 5.5 6 6 6 6.5 6.5 6.5 6.5 7 7 8 8 9
The dot plot for this data would be as follows:
Frequency of Average Time (in Hours) Spent Sleeping per Night

Does your dot plot look the same as or different from the example? Why? If
you did the same example in an English class with the same number of
students, do you think the results would be the same? Why or why not?
Where do your data appear to cluster? How could you interpret the
clustering?

The questions above ask you to analyze and interpret your data. With this
example, you have begun your study of statistics.

In this course, you will learn how to organize and summarize data.
Organizing and summarizing data is called descriptive statistics. Two ways
to summarize data are by graphing and by numbers (for example, finding an
average). After you have studied probability and probability distributions,
you will use formal methods for drawing conclusions from "good" data.
The formal methods are called inferential statistics. Statistical inference
uses probability to determine how confident we can be that the conclusions
are correct.

Effective interpretation of data (inference) is based on good procedures for
producing data and thoughtful examination of the data. You will encounter
what will seem to be too many mathematical formulas for interpreting data.
The goal of statistics is not to perform numerous calculations using the
formulas, but to gain an understanding of your data. The calculations can be
done using a calculator or a computer. The understanding must come from
you. If you can thoroughly grasp the basics of statistics, you can be more
confident in the decisions you make in life.

Levels of Measurement and Statistical Operations

The way a set of data is measured is called its level of measurement.
Correct statistical procedures depend on a researcher being familiar with
levels of measurement. Not every statistical operation can be used with
every set of data. Data can be classified into four levels of measurement.
They are (from lowest to highest level):

      Nominal scale level
      Ordinal scale level
      Interval scale level
      Ratio scale level
Data that is measured using a nominal scale is qualitative. Categories,
colors, names, labels and favorite foods along with yes or no responses are
examples of nominal level data. Nominal scale data are not ordered. For
example, trying to classify people according to their favorite food does not
make any sense. Putting pizza first and sushi second is not meaningful.

Smartphone companies are another example of nominal scale data. Some
examples are Sony, Motorola, Nokia, Samsung and Apple. This is just a list
and there is no agreed upon order. Some people may favor Apple but that is
a matter of opinion. Nominal scale data cannot be used in calculations.

Data that is measured using an ordinal scale is similar to nominal scale
data but there is a big difference. The ordinal scale data can be ordered. An
example of ordinal scale data is a list of the top five national parks in the
United States. The top five national parks in the United States can be
ranked from one to five but we cannot measure differences between the
data.

Another example using the ordinal scale is a cruise survey where the
responses to questions about the cruise are "excellent," "good,"
"satisfactory" and "unsatisfactory." These responses are ordered from the
most desired response by the cruise lines to the least desired. But the
differences between two pieces of data cannot be measured. Like the
nominal scale data, ordinal scale data cannot be used in calculations.

Data that is measured using the interval scale is similar to ordinal level
data because it has a definite ordering but there is a difference between data.
The differences between interval scale data can be measured though the
data does not have a starting point.

Temperature scales like Celsius (C) and Fahrenheit (F) are measured by
using the interval scale. In both temperature measurements, 40 degrees is
equal to 100 degrees minus 60 degrees. Differences make sense. But 0
degrees does not because, in both scales, 0 is not the absolute lowest
temperature. Temperatures like -10 F and -15 C exist and are colder than
0.
Interval level data can be used in calculations but one type of comparison
cannot be done. Eighty degrees C is not 4 times as hot as 20 C (nor is 80
F 4 times as hot as 20 F). There is no meaning to the ratio of 80 to 20 (or 4
to 1).

Data that is measured using the ratio scale takes care of the ratio problem
and gives you the most information. Ratio scale data is like interval scale
data but, in addition, it has a 0 point and ratios can be calculated. For
example, four multiple choice statistics final exam scores are 80, 68, 20 and
92 (out of a possible 100 points). The exams were machine-graded.

The data can be put in order from lowest to highest: 20, 68, 80, 92.

The differences between the data have meaning. The score 92 is more than
the score 68 by 24 points.

Ratios can be calculated. The smallest score for ratio data is 0. So 80 is 4
times 20. The score of 80 is 4 times better than the score of 20.

Exercises

What type of measure scale is being used? Nominal, Ordinal, Interval or
Ratio.

   1. High school men soccer players classified by their athletic ability:
      Superior, Average, Above average.

   2. Baking temperatures for various main dishes: 350, 400, 325, 250, 300
   3. The colors of crayons in a 24-crayon box.
   4. Social security numbers.
   5. Incomes measured in dollars
   6. A satisfaction survey of a social website by number: 1 = very satisfied,

      2 = somewhat satisfied, 3 = not satisfied.
   7. Political outlook: extreme left, left-of-center, right-of-center, extreme

      right.
   8. Time of day on an analog watch.
   9. The distance in miles to the closest grocery store.
 10. The dates 1066, 1492, 1644, 1947, 1944.
 11. The heights of 21 - 65 year-old women.
 12. Common letter grades A, B, C, D, F.

Answers 1. ordinal, 2. interval, 3. nominal, 4. nominal, 5. ratio, 6. ordinal,
7. nominal, 8. interval, 9. ratio, 10. interval, 11. ratio, 12. ordinal

Glossary

Data
      A set of observations (a set of possible outcomes). Most data can be
      put into two groups: qualitative (hair color, ethnic groups and other
      attributes of the population) and quantitative (distance traveled to
      college, number of children in a family, etc.). Quantitative data can be
      separated into two subgroups: discrete and continuous. Data is
      discrete if it is the result of counting (the number of students of a given
      ethnic group in a class, the number of books on a shelf, etc.). Data is
      continuous if it is the result of measuring (distance traveled, weight of
      luggage, etc.)

Statistic
      A numerical characteristic of the sample. A statistic estimates the
      corresponding population parameter. For example, the average number
      of full-time students in a 7:30 a.m. class for this term (statistic) is an
      estimate for the average number of full-time students in any class this
      term (parameter).
Probability
This module introduces the concept of probability as a mathematical
measure of randomness, including a number of real-world applications.

Probability is a mathematical tool used to study randomness. It deals with

the chance (the likelihood) of an event occurring. For example, if you toss a

fair coin 4 times, the outcomes may not be 2 heads and 2 tails. However, if

you toss the same coin 4,000 times, the outcomes will be close to half heads

and half tails. The expected theoretical probability of heads in any one toss

is  1  or 0.5. Even though the outcomes of a few repetitions are uncertain,
    2

there is a regular pattern of outcomes when there are many repetitions.

After reading about the English statistician Karl Pearson who tossed a coin

24,000 times with a result of 12,012 heads, one of the authors tossed a coin

2,000 times. The results were 996 heads. The fraction   996  is equal to 0.498
                                                       2000

which is very close to 0.5, the expected probability.

The theory of probability began with the study of games of chance such as
poker. Predictions take the form of probabilities. To predict the likelihood
of an earthquake, of rain, or whether you will get an A in this course, we
use probabilities. Doctors use probability to determine the chance of a
vaccination causing the disease the vaccination is supposed to prevent. A
stockbroker uses probability to determine the rate of return on a client's
investments. You might use probability to decide to buy a lottery ticket or
not. In your study of statistics, you will use the power of mathematics
through probability calculations to analyze and interpret your data.

Glossary

Probability
      A number between 0 and 1, inclusive, that gives the likelihood that a
      specific event will occur. The foundation of statistics is given by the
      following 3 axioms (by A. N. Kolmogorov, 1930's): Let S denote the
      sample space and A and B are two events in S . Then:

            0  P (A)  1;.
            If A and B are any two mutually exclusive events, then
            P (A or B) = P (A) + P (B).
P (S) = 1.
Key Terms
This module introduces a number of key terms related to statistical
sampling and data.

In statistics, we generally want to study a population. You can think of a
population as an entire collection of persons, things, or objects under study.
To study the larger population, we select a sample. The idea of sampling is
to select a portion (or subset) of the larger population and study that portion
(the sample) to gain information about the population. Data are the result of
sampling from a population.

Because it takes a lot of time and money to examine an entire population,
sampling is a very practical technique. If you wished to compute the overall
grade point average at your school, it would make sense to select a sample
of students who attend the school. The data collected from the sample
would be the students' grade point averages. In presidential elections,
opinion poll samples of 1,000 to 2,000 people are taken. The opinion poll is
supposed to represent the views of the people in the entire country.
Manufacturers of canned carbonated drinks take samples to determine if a
16 ounce can contains 16 ounces of carbonated drink.

From the sample data, we can calculate a statistic. A statistic is a number
that is a property of the sample. For example, if we consider one math class
to be a sample of the population of all math classes, then the average
number of points earned by students in that one math class at the end of the
term is an example of a statistic. The statistic is an estimate of a population
parameter. A parameter is a number that is a property of the population.
Since we considered all math classes to be the population, then the average
number of points earned per student over all the math classes is an example
of a parameter.

One of the main concerns in the field of statistics is how accurately a
statistic estimates a parameter. The accuracy really depends on how well the
sample represents the population. The sample must contain the
characteristics of the population in order to be a representative sample. We
are interested in both the sample statistic and the population parameter in
inferential statistics. In a later chapter, we will use the sample statistic to
test the validity of the established population parameter.
A variable, notated by capital letters like X and Y , is a characteristic of
interest for each person or thing in a population. Variables may be
numerical or categorical. Numerical variables take on values with equal
units such as weight in pounds and time in hours. Categorical variables
place the person or thing into a category. If we let X equal the number of
points earned by one math student at the end of a term, then X is a
numerical variable. If we let Y be a person's party affiliation, then examples
of Y include Republican, Democrat, and Independent. Y is a categorical
variable. We could do some math with values of X (calculate the average
number of points earned, for example), but it makes no sense to do math
with values of Y (calculating an average party affiliation makes no sense).

Data are the actual values of the variable. They may be numbers or they
may be words. Datum is a single value.

Two words that come up often in statistics are mean and proportion. If you

were to take three exams in your math classes and obtained scores of 86,

75, and 92, you calculate your mean score by adding the three exam scores

and dividing by three (your mean score would be 84.3 to one decimal

place). If, in your math class, there are 40 students and 22 are men and 18

are women, then the proportion of men students is     22  and the proportion of
                                                      40

women students is  18  .  Mean  and  proportion  are  discussed  in  more  detail  in
                   40

later chapters.

Note:
Mean and Average
The words "mean" and "average" are often used interchangeably. The
substitution of one word for the other is common practice. The technical
term is "arithmetic mean" and "average" is technically a center location.
However, in practice among non-statisticians, "average" is commonly
accepted for "arithmetic mean."

Example:
Exercise:
   Problem:

   Define the key terms from the following study: We want to know the
   average (mean) amount of money first year college students spend at
   ABC College on school supplies that do not include books. We
   randomly survey 100 first year students at the college. Three of those
   students spent $150, $200, and $225, respectively.

   Solution:

   The population is all first year students attending ABC College this
   term.

   The sample could be all students enrolled in one section of a
   beginning statistics course at ABC College (although this sample may
   not represent the entire population).

   The parameter is the average (mean) amount of money spent
   (excluding books) by first year college students at ABC College this
   term.

   The statistic is the average (mean) amount of money spent (excluding
   books) by first year college students in the sample.

   The variable could be the amount of money spent (excluding books)
   by one first year student. Let X = the amount of money spent
   (excluding books) by one first year student attending ABC College.

   The data are the dollar amounts spent by the first year students.
   Examples of the data are $150, $200, and $225.

Optional Collaborative Classroom Exercise
Do the following exercise collaboratively with up to four people per group.
Find a population, a sample, the parameter, the statistic, a variable, and data
for the following study: You want to determine the average (mean) number
of glasses of milk college students drink per day. Suppose yesterday, in your
English class, you asked five students how many glasses of milk they drank
the day before. The answers were 1, 0, 1, 3, and 4 glasses of milk.

Glossary

Average
      A number that describes the central tendency of the data. There are a
      number of specialized averages, including the arithmetic mean,
      weighted mean, median, mode, and geometric mean.

Data
      A set of observations (a set of possible outcomes). Most data can be
      put into two groups: qualitative (hair color, ethnic groups and other
      attributes of the population) and quantitative (distance traveled to
      college, number of children in a family, etc.). Quantitative data can be
      separated into two subgroups: discrete and continuous. Data is
      discrete if it is the result of counting (the number of students of a given
      ethnic group in a class, the number of books on a shelf, etc.). Data is
      continuous if it is the result of measuring (distance traveled, weight of
      luggage, etc.)

Proportion

As a number: A proportion is the number of successes divided by

the total number in the sample.

As a probability distribution: Given a binomial random variable
(RV), X B(n, p), consider the ratio of the number X of

successes in n Bernouli trials to the number n of trials. P =  X.

                                                               n

This new RV is called a proportion, and if the number of trials, n,
is large enough, P' N (p, ) pq .

                                                                                              n
Data
This module introduces the concepts of qualitative data, quantitative
continuous data, and quantitative discrete data as used in statistics. Sample
problems are included.

Data may come from a population or from a sample. Small letters like x or
y generally are used to represent data values. Most data can be put into the
following categories:

Qualitative
Quantitative

Qualitative data are the result of categorizing or describing attributes of a
population. Hair color, blood type, ethnic group, the car a person drives, and
the street a person lives on are examples of qualitative data. Qualitative data
are generally described by words or letters. For instance, hair color might
be black, dark brown, light brown, blonde, gray, or red. Blood type might
be AB+, O-, or B+. Researchers often prefer to use quantitative data over
qualitative data because it lends itself more easily to mathematical analysis.
For example, it does not make sense to find an average hair color or blood
type.

Quantitative data are always numbers. Quantitative data are the result of
counting or measuring attributes of a population. Amount of money, pulse
rate, weight, number of people living in your town, and the number of
students who take statistics are examples of quantitative data. Quantitative
data may be either discrete or continuous.

All data that are the result of counting are called quantitative discrete
data. These data take on only certain numerical values. If you count the
number of phone calls you receive for each day of the week, you might get
0, 1, 2, 3, etc.

All data that are the result of measuring are quantitative continuous data

assuming that we can measure accurately. Measuring angles in radians

might result in the numbers  ,     ,      ,  ,  3   , etc. If you and your friends
                                3      2
                             6                   4

carry backpacks with books in them to school, the numbers of books in the
backpacks are discrete data and the weights of the backpacks are continuous
data.

Note:In this course, the data used is mainly quantitative. It is easy to
calculate statistics (like the mean or proportion) from numbers. In the
chapter Descriptive Statistics, you will be introduced to stem plots,
histograms and box plots all of which display quantitative data. Qualitative
data is discussed at the end of this section through graphs.

Example:
Data Sample of Quantitative Discrete Data
The data are the number of books students carry in their backpacks. You
sample five students. Two students carry 3 books, one student carries 4
books, one student carries 2 books, and one student carries 1 book. The
numbers of books (3, 4, 2, and 1) are the quantitative discrete data.

Example:
Data Sample of Quantitative Continuous Data
The data are the weights of the backpacks with the books in it. You sample
the same five students. The weights (in pounds) of their backpacks are 6.2,
7, 6.8, 9.1, 4.3. Notice that backpacks carrying three books can have
different weights. Weights are quantitative continuous data because
weights are measured.

Example:
Data Sample of Qualitative Data
The data are the colors of backpacks. Again, you sample the same five
students. One student has a red backpack, two students have black
backpacks, one student has a green backpack, and one student has a gray
backpack. The colors red, black, black, green, and gray are qualitative data.
Note:You may collect data as numbers and report it categorically. For
example, the quiz scores for each student are recorded throughout the term.
At the end of the term, the quiz scores are reported as A, B, C, D, or F.

Example:
Exercise:

   Problem:

   Work collaboratively to determine the correct data type (quantitative
   or qualitative). Indicate whether quantitative data are continuous or
   discrete. Hint: Data that are discrete often start with the words "the
   number of."

      1. The number of pairs of shoes you own.
      2. The type of car you drive.
      3. Where you go on vacation.
      4. The distance it is from your home to the nearest grocery store.
      5. The number of classes you take per school year.
      6. The tuition for your classes
      7. The type of calculator you use.
      8. Movie ratings.
      9. Political party preferences.
    10. Weight of sumo wrestlers.
    11. Amount of money won playing poker.
    12. Number of correct answers on a quiz.
    13. Peoples' attitudes toward the government.
    14. IQ scores. (This may cause some discussion.)

   Solution:

   Items 1, 5, 11, and 12 are quantitative discrete; items 4, 6, 10, and 14
   are quantitative continuous; and items 2, 3, 7, 8, 9, and 13 are
   qualitative.
Qualitative Data Discussion
Below are tables of part-time vs full-time students at De Anza College in
Cupertino, CA and Foothill College in Los Altos, CA for the Spring 2010
quarter. The tables display counts (frequencies) and percentages or
proportions (relative frequencies). The percent columns make comparing
the same categories in the colleges easier. Displaying percentages along
with the numbers is often helpful, but it is particularly important when
comparing sets of data that do not have the same totals, such as the total
enrollments for both colleges in this example. Notice how much larger the
percentage for part-time students at Foothill College is compared to De
Anza College.

   Full-time     Number  Percent
   Part-time     9,200   40.9%
   Total         13,296  59.1%
De Anza College  22,496  100%

Full-time        Number  Percent
Part-time        4,059   28.6%
                 10,124  71.4%
Total             14,183  100%

Foothill College

Tables are a good way of organizing and displaying data. But graphs can be
even more helpful in understanding the data. There are no strict rules
concerning what graphs to use. Below are pie charts and bar graphs, two
graphs that are used to display qualitative data.

In a pie chart, categories of data are represented by wedges in the circle
and are proportional in size to the percent of individuals in each category.

In a bar graph, the length of the bar for each category is proportional to the
number or percent of individuals in each category. Bars may be vertical or
horizontal.

A Pareto chart consists of bars that are sorted into order by category size
(largest to smallest).

Look at the graphs and determine which graph (pie or bar) you think
displays the comparisons better. This is a matter of preference.

It is a good idea to look at a variety of graphs to see which is the most
helpful in displaying the data. We might make different choices of what we
think is the "best" graph depending on the data and the context. Our choice
also depends on what we are using the data for.
Percentages That Add to More (or Less) Than 100%
Sometimes percentages add up to be more than 100% (or less than 100%).
In the graph, the percentages add to more than 100% because students can
be in more than one category. A bar graph is appropriate to compare the
relative size of the categories. A pie chart cannot be used. It also could not
be used if the percentages added to less than 100%.
   Characteristic/Category                                  Percent
   Full-time Students                                       40.9%
   Students who intend to transfer to a 4-year educational  48.6%
   institution                                              61.0%
   Students under age 25                                    150.5%
   TOTAL
De Anza College Spring 2010

Omitting Categories/Missing Data
The table displays Ethnicity of Students but is missing the
"Other/Unknown" category. This category contains people who did not feel
they fit into any of the ethnicity categories or declined to respond. Notice
that the frequencies do not add up to the total number of students. Create a
bar graph and not a pie chart.
Asian             Frequency  Percent
Black             8,794      36.1%
Filipino          1,412      5.8%
Hispanic          1,298      5.3%
Native American   4,180      17.1%
Pacific Islander  146        0.6%
White             236        1.0%
                  5,978      24.5%

TOTAL             22,044 out of 24,382 90.4% out of 100%

Missing Data: Ethnicity of Students De Anza College Fall Term 2007
(Census Day)
Bar graph Without Other/Unknown Category
The following graph is the same as the previous graph but the
"Other/Unknown" percent (9.6%) has been added back in. The
"Other/Unknown" category is large compared to some of the other
categories (Native American, 0.6%, Pacific Islander 1.0% particularly).
This is important to know when we think about what the data are telling us.
This particular bar graph can be hard to understand visually. The graph
below it is a Pareto chart. The Pareto chart has the bars sorted from largest
to smallest and is easier to read and interpret.

Bar Graph With Other/Unknown Category
Pareto Chart With Bars Sorted By Size
Pie Charts: No Missing Data
The following pie charts have the "Other/Unknown" category added back in
(since the percentages must add to 100%). The chart on the right is
organized having the wedges by size and makes for a more visually
informative graph than the unsorted, alphabetical graph on the left.

Glossary
Continuous Random Variable
      A random variable (RV) whose outcomes are measured.

Example:
The height of trees in the forest is a continuous RV.

Data
      A set of observations (a set of possible outcomes). Most data can be
      put into two groups: qualitative (hair color, ethnic groups and other
      attributes of the population) and quantitative (distance traveled to
      college, number of children in a family, etc.). Quantitative data can be
      separated into two subgroups: discrete and continuous. Data is
      discrete if it is the result of counting (the number of students of a given
      ethnic group in a class, the number of books on a shelf, etc.). Data is
      continuous if it is the result of measuring (distance traveled, weight of
      luggage, etc.)

Discrete Random Variable
      A random variable (RV) whose outcomes are counted.

Qualitative Data
      See Data.

Quantitative Data
      See Data.
Sampling
This module introduces the concept of statistical sampling. Students are
taught the difference between a simple random sample, stratified sample,
cluster sample, systematic sample, and convenience sample. Example
problems are provided, including an optional classroom activity.

Gathering information about an entire population often costs too much or is
virtually impossible. Instead, we use a sample of the population. A sample
should have the same characteristics as the population it is
representing. Most statisticians use various methods of random sampling
in an attempt to achieve this goal. This section will describe a few of the
most common methods.

There are several different methods of random sampling. In each form of
random sampling, each member of a population initially has an equal
chance of being selected for the sample. Each method has pros and cons.
The easiest method to describe is called a simple random sample. Any
group of n individuals is equally likely to be chosen by any other group of n
individuals if the simple random sampling technique is used. In other
words, each sample of the same size has an equal chance of being selected.
For example, suppose Lisa wants to form a four-person study group (herself
and three other people) from her pre-calculus class, which has 31 members
not including Lisa. To choose a simple random sample of size 3 from the
other members of her class, Lisa could put all 31 names in a hat, shake the
hat, close her eyes, and pick out 3 names. A more technological way is for
Lisa to first list the last names of the members of her class together with a
two-digit number as shown below.

ID  Name

00  Anselmo
ID  Name

01  Bautista

02  Bayani

03  Cheng

04  Cuarismo

05  Cuningham

06  Fontecha

07  Hong

08  Hoobler

09  Jiao

10  Khan

11  King

12  Legeny

13  Lundquist

14  Macierz

15  Motogawa

16  Okimoto

17  Patel
ID            Name

18            Price

19            Quizon

20            Reyes

21            Roquero

22            Roth

23            Rowell

24            Salangsang

25            Slade

26            Stracher

27            Tallai

28            Tran

29            Wai

30            Wood

Class Roster

Lisa can either use a table of random numbers (found in many statistics
books as well as mathematical handbooks) or a calculator or computer to
generate random numbers. For this example, suppose Lisa chooses to
generate random numbers from a calculator. The numbers generated are:

.94360 .99832 .14669 .51470 .40581 .73381 .04399
Lisa reads two-digit groups until she has chosen three class members (that
is, she reads .94360 as the groups 94, 43, 36, 60). Each random number
may only contribute one class member. If she needed to, Lisa could have
generated more random numbers.

The random numbers .94360 and .99832 do not contain appropriate two
digit numbers. However the third random number, .14669, contains 14 (the
fourth random number also contains 14), the fifth random number contains
05, and the seventh random number contains 04. The two-digit number 14
corresponds to Macierz, 05 corresponds to Cunningham, and 04
corresponds to Cuarismo. Besides herself, Lisa's group will consist of
Marcierz, and Cunningham, and Cuarismo.

Besides simple random sampling, there are other forms of sampling that
involve a chance process for getting the sample. Other well-known
random sampling methods are the stratified sample, the cluster sample,
and the systematic sample.

To choose a stratified sample, divide the population into groups called
strata and then take a proportionate number from each stratum. For
example, you could stratify (group) your college population by department
and then choose a proportionate simple random sample from each stratum
(each department) to get a stratified random sample. To choose a simple
random sample from each department, number each member of the first
department, number each member of the second department and do the
same for the remaining departments. Then use simple random sampling to
choose proportionate numbers from the first department and do the same for
each of the remaining departments. Those numbers picked from the first
department, picked from the second department and so on represent the
members who make up the stratified sample.

To choose a cluster sample, divide the population into clusters (groups)
and then randomly select some of the clusters. All the members from these
clusters are in the cluster sample. For example, if you randomly sample four
departments from your college population, the four departments make up
the cluster sample. For example, divide your college faculty by department.
The departments are the clusters. Number each department and then choose
four different numbers using simple random sampling. All members of the
four departments with those numbers are the cluster sample.

To choose a systematic sample, randomly select a starting point and take
every nth piece of data from a listing of the population. For example,
suppose you have to do a phone survey. Your phone book contains 20,000
residence listings. You must choose 400 names for the sample. Number the
population 1 - 20,000 and then use a simple random sample to pick a
number that represents the first name of the sample. Then choose every
50th name thereafter until you have a total of 400 names (you might have to
go back to the of your phone list). Systematic sampling is frequently chosen
because it is a simple method.

A type of sampling that is nonrandom is convenience sampling.
Convenience sampling involves using results that are readily available. For
example, a computer software store conducts a marketing study by
interviewing potential customers who happen to be in the store browsing
through the available software. The results of convenience sampling may be
very good in some cases and highly biased (favors certain outcomes) in
others.

Sampling data should be done very carefully. Collecting data carelessly can
have devastating results. Surveys mailed to households and then returned
may be very biased (for example, they may favor a certain group). It is
better for the person conducting the survey to select the sample
respondents.

True random sampling is done with replacement. That is, once a member
is picked that member goes back into the population and thus may be
chosen more than once. However for practical reasons, in most populations,
simple random sampling is done without replacement. Surveys are
typically done without replacement. That is, a member of the population
may be chosen only once. Most samples are taken from large populations
and the sample tends to be small in comparison to the population. Since this
is the case, sampling without replacement is approximately the same as
sampling with replacement because the chance of picking the same
individual more than once using with replacement is very low.
For example, in a college population of 10,000 people, suppose you want to
randomly pick a sample of 1000 for a survey. For any particular sample
of 1000, if you are sampling with replacement,

      the chance of picking the first person is 1000 out of 10,000 (0.1000);
      the chance of picking a different second person for this sample is 999
      out of 10,000 (0.0999);
      the chance of picking the same person again is 1 out of 10,000 (very
      low).

If you are sampling without replacement,

      the chance of picking the first person for any particular sample is 1000
      out of 10,000 (0.1000);
      the chance of picking a different second person is 999 out of 9,999
      (0.0999);
      you do not replace the first person before picking the next person.

Compare the fractions 999/10,000 and 999/9,999. For accuracy, carry the
decimal answers to 4 place decimals. To 4 decimal places, these numbers
are equivalent (0.0999).

Sampling without replacement instead of sampling with replacement only
becomes a mathematics issue when the population is small which is not that
common. For example, if the population is 25 people, the sample is 10 and
you are sampling with replacement for any particular sample,

      the chance of picking the first person is 10 out of 25 and a different
      second person is 9 out of 25 (you replace the first person).

If you sample without replacement,

      the chance of picking the first person is 10 out of 25 and then the
      second person (which is different) is 9 out of 24 (you do not replace
      the first person).

Compare the fractions 9/25 and 9/24. To 4 decimal places, 9/25 = 0.3600
and 9/24 = 0.3750. To 4 decimal places, these numbers are not equivalent.
When you analyze data, it is important to be aware of sampling errors and
nonsampling errors. The actual process of sampling causes sampling errors.
For example, the sample may not be large enough. Factors not related to the
sampling process cause nonsampling errors. A defective counting device
can cause a nonsampling error.

In reality, a sample will never be exactly representative of the population so
there will always be some sampling error. As a rule, the larger the sample,
the smaller the sampling error.

In statistics, a sampling bias is created when a sample is collected from a
population and some members of the population are not as likely to be
chosen as others (remember, each member of the population should have an
equally likely chance of being chosen). When a sampling bias happens,
there can be incorrect conclusions drawn about the population that is being
studied.

Example:
Exercise:

   Problem:

   Determine the type of sampling used (simple random, stratified,
   systematic, cluster, or convenience).

      1. A soccer coach selects 6 players from a group of boys aged 8 to
         10, 7 players from a group of boys aged 11 to 12, and 3 players
         from a group of boys aged 13 to 14 to form a recreational soccer
         team.

      2. A pollster interviews all human resource personnel in five
         different high tech companies.

      3. A high school educational researcher interviews 50 high school
         female teachers and 50 high school male teachers.

      4. A medical researcher interviews every third cancer patient from
         a list of cancer patients at a local hospital.
      5. A high school counselor uses a computer to generate 50 random
         numbers and then picks students whose names correspond to the
         numbers.

      6. A student interviews classmates in his algebra class to determine
         how many pairs of jeans a student owns, on the average.

   Solution:

      1. stratified
      2. cluster
      3. stratified
      4. systematic
      5. simple random
      6. convenience

If we were to examine two samples representing the same population, even
if we used random sampling methods for the samples, they would not be
exactly the same. Just as there is variation in data, there is variation in
samples. As you become accustomed to sampling, the variability will seem
natural.

Example:
Suppose ABC College has 10,000 part-time students (the population). We
are interested in the average amount of money a part-time student spends
on books in the fall term. Asking all 10,000 students is an almost
impossible task.
Suppose we take two different samples.
First, we use convenience sampling and survey 10 students from a first
term organic chemistry class. Many of these students are taking first term
calculus in addition to the organic chemistry class . The amount of money
they spend is as follows:
$128 $87 $173 $116 $130 $204 $147 $189 $93 $153
The second sample is taken by using a list from the P.E. department of
senior citizens who take P.E. classes and taking every 5th senior citizen on
the list, for a total of 10 senior citizens. They spend:
$50 $40 $36 $15 $50 $100 $40 $53 $22 $22
Exercise:

   Problem:

   Do you think that either of these samples is representative of (or is
   characteristic of) the entire 10,000 part-time student population?

   Solution:

   No. The first sample probably consists of science-oriented students.
   Besides the chemistry course, some of them are taking first-term
   calculus. Books for these classes tend to be expensive. Most of these
   students are, more than likely, paying more than the average part-time
   student for their books. The second sample is a group of senior
   citizens who are, more than likely, taking courses for health and
   interest. The amount of money they spend on books is probably much
   less than the average part-time student. Both samples are biased. Also,
   in both cases, not all students have a chance to be in either sample.

Exercise:

   Problem:

   Since these samples are not representative of the entire population, is
   it wise to use the results to describe the entire population?

   Solution:

   No. For these samples, each member of the population did not have an
   equally likely chance of being chosen.

Now, suppose we take a third sample. We choose ten different part-time
students from the disciplines of chemistry, math, English, psychology,
sociology, history, nursing, physical education, art, and early childhood
development. (We assume that these are the only disciplines in which part-
time students at ABC College are enrolled and that an equal number of
part-time students are enrolled in each of the disciplines.) Each student is
chosen using simple random sampling. Using a calculator, random
numbers are generated and a student from a particular discipline is selected
if he/she has a corresponding number. The students spend:
$180 $50 $150 $85 $260 $75 $180 $200 $200 $150
Exercise:

   Problem: Is the sample biased?

   Solution:

   The sample is unbiased, but a larger sample would be recommended
   to increase the likelihood that the sample will be close to
   representative of the population. However, for a biased sampling
   technique, even a large sample runs the risk of not being
   representative of the population.
Students often ask if it is "good enough" to take a sample, instead of
surveying the entire population. If the survey is done well, the answer is
yes.

Optional Collaborative Classroom Exercise

Exercise:
   Problem:

   As a class, determine whether or not the following samples are
   representative. If they are not, discuss the reasons.

      1. To find the average GPA of all students in a university, use all
         honor students at the university as the sample.

      2. To find out the most popular cereal among young people under
         the age of 10, stand outside a large supermarket for three hours
         and speak to every 20th child under age 10 who enters the
         supermarket.
3. To find the average annual income of all adults in the United
  States, sample U.S. congressmen. Create a cluster sample by
  considering each state as a stratum (group). By using simple
  random sampling, select states to be part of the cluster. Then
  survey every U.S. congressman in the cluster.

4. To determine the proportion of people taking public transportation
  to work, survey 20 people in New York City. Conduct the survey
  by sitting in Central Park on a bench and interviewing every
  person who sits next to you.

5. To determine the average cost of a two day stay in a hospital in
  Massachusetts, survey 100 hospitals across the state using simple
  random sampling.
Variation
This module discusses statistical variability within data and samples.
Students will be given the opportunity to see this variability in action
through participation in an optional classroom exercise. This module also
has a section that discusses Critical Evaluation.

Variation in Data

Variation is present in any set of data. For example, 16-ounce cans of
beverage may contain more or less than 16 ounces of liquid. In one study,
eight 16 ounce cans were measured and produced the following amount (in
ounces) of beverage:

15.8 16.1 15.2 14.8 15.8 15.9 16.0 15.5

Measurements of the amount of beverage in a 16-ounce can may vary
because different people make the measurements or because the exact
amount, 16 ounces of liquid, was not put into the cans. Manufacturers
regularly run tests to determine if the amount of beverage in a 16-ounce can
falls within the desired range.

Be aware that as you take data, your data may vary somewhat from the data
someone else is taking for the same purpose. This is completely natural.
However, if two or more of you are taking the same data and get very
different results, it is time for you and the others to reevaluate your data-
taking methods and your accuracy.

Variation in Samples

It was mentioned previously that two or more samples from the same
population, taken randomly, and having close to the same characteristics of
the population are different from each other. Suppose Doreen and Jung both
decide to study the average amount of time students at their college sleep
each night. Doreen and Jung each take samples of 500 students. Doreen
uses systematic sampling and Jung uses cluster sampling. Doreen's sample
will be different from Jung's sample. Even if Doreen and Jung used the
same sampling method, in all likelihood their samples would be different.
Neither would be wrong, however.

Think about what contributes to making Doreen's and Jung's samples
different.

If Doreen and Jung took larger samples (i.e. the number of data values is
increased), their sample results (the average amount of time a student
sleeps) might be closer to the actual population average. But still, their
samples would be, in all likelihood, different from each other. This
variability in samples cannot be stressed enough.

Size of a Sample

The size of a sample (often called the number of observations) is important.
The examples you have seen in this book so far have been small. Samples
of only a few hundred observations, or even smaller, are sufficient for many
purposes. In polling, samples that are from 1200 to 1500 observations are
considered large enough and good enough if the survey is random and is
well done. You will learn why when you study confidence intervals.

Be aware that many large samples are biased. For example, call-in surveys
are invariable biased because people choose to respond or not.

Optional Collaborative Classroom Exercise

Exercise:
   Problem:

   Divide into groups of two, three, or four. Your instructor will give each
   group one 6-sided die. Try this experiment twice. Roll one fair die (6-
   sided) 20 times. Record the number of ones, twos, threes, fours, fives,
   and sixes you get below ("frequency" is the number of times a
   particular face of the die occurs):
   Face on Die                Frequency
   1
   2
   3
   4
   5
   6
First Experiment (20 rolls)

   Face on Die                Frequency
   1
   2
   3
   4
   5
   6
Second Experiment (20 rolls)
   Did the two experiments have the same results? Probably not. If you
   did the experiment a third time, do you expect the results to be
   identical to the first or second experiment? (Answer yes or no.) Why
   or why not?

   Which experiment had the correct results? They both did. The job of
   the statistician is to see through the variability and draw appropriate
   conclusions.

Critical Evaluation

We need to critically evaluate the statistical studies we read about and
analyze before accepting the results of the study. Common problems to be
aware of include

      Problems with Samples: A sample should be representative of the
      population. A sample that is not representative of the population is
      biased. Biased samples that are not representative of the population
      give results that are inaccurate and not valid.
      Self-Selected Samples: Responses only by people who choose to
      respond, such as call-in surveys are often unreliable.
      Sample Size Issues: Samples that are too small may be unreliable.
      Larger samples are better if possible. In some situations, small samples
      are unavoidable and can still be used to draw conclusions, even though
      larger samples are better. Examples: Crash testing cars, medical testing
      for rare conditions.
      Undue influence: Collecting data or asking questions in a way that
      influences the response.
      Non-response or refusal of subject to participate: The collected
      responses may no longer be representative of the population. Often,
      people with strong positive or negative opinions may answer surveys,
      which can affect the results.
      Causality: A relationship between two variables does not mean that
      one causes the other to occur. They may both be related (correlated)
      because of their relationship through a different variable.
      Self-Funded or Self-Interest Studies: A study performed by a person or
      organization in order to support their claim. Is the study impartial?
      Read the study carefully to evaluate the work. Do not automatically
      assume that the study is good but do not automatically assume the
      study is bad either. Evaluate it on its merits and the work done.
      Misleading Use of Data: Improperly displayed graphs, incomplete
      data, lack of context.
      Confounding: When the effects of multiple factors on a response
      cannot be separated. Confounding makes it difficult or impossible to
      draw valid conclusions about the effect of each factor.

Glossary

Population
      The collection, or set, of all individuals, objects, or measurements
      whose properties are being studied.

Sample
      A portion of the population understudy. A sample is representative if it
      characterizes the population being studied.
Answers and Rounding Off
This module briefly explains the correct way to round off answers when
working with statistical data.

A simple way to round off answers is to carry your final answer one more
decimal place than was present in the original data. Round only the final
answer. Do not round any intermediate results, if possible. If it becomes
necessary to round intermediate results, carry them to at least twice as many
decimal places as the final answer. For example, the average of the three
quiz scores 4, 6, 9 is 6.3, rounded to the nearest tenth, because the data are
whole numbers. Most answers will be rounded in this manner.

It is not necessary to reduce most fractions in this course. Especially in
Probability Topics, the chapter on probability, it is more helpful to leave an
answer as an unreduced fraction.
Frequency
This module introduces the concepts of frequency, relative frequency, and
cumulative relative frequency, and the relationship between these measures.
Students will have the opportunity to interpret data through the sample problems
provided.

Twenty students were asked how many hours they worked per day. Their
responses, in hours, are listed below:

5 6 3 3 2 4 7 5 2 3 5 6 5 4 4 3 5 2 5 3

Below is a frequency table listing the different data values in ascending order and
their frequencies.

DATA VALUE                             FREQUENCY

2                                      3

3                                      5

4                                      3

5                                      6

6                                      2

7                                      1

Frequency Table of Student Work Hours

A frequency is the number of times a given datum occurs in a data set.
According to the table above, there are three students who work 2 hours, five
students who work 3 hours, etc. The total of the frequency column, 20, represents
the total number of students included in the sample.
A relative frequency is the fraction or proportion of times an answer occurs. To
find the relative frequencies, divide each frequency by the total number of
students in the sample - in this case, 20. Relative frequencies can be written as
fractions, percents, or decimals.

DATA VALUE  FREQUENCY  RELATIVE FREQUENCY

2           3          20 3 or 0.15

3           5          20 5 or 0.25

4           3          20 3 or 0.15

5           6          20 6 or 0.30

6           2          20 2 or 0.10

7           1          20 1 or 0.05

Frequency Table of Student Work Hours w/ Relative Frequency

The sum of the relative frequency column is 20 20 , or 1.

Cumulative relative frequency is the accumulation of the previous relative
frequencies. To find the cumulative relative frequencies, add all the previous
relative frequencies to the relative frequency for the current row.
DATA   FREQUENCY  RELATIVE      CUMULATIVE
VALUE             FREQUENCY     RELATIVE
                                FREQUENCY

2      3          20 3 or 0.15  0.15

3      5          20 5 or 0.25  0.15 + 0.25 =
                                0.40

4      3          20 3 or 0.15  0.40 + 0.15 =
                                0.55

5      6          20 6 or 0.30  0.55 + 0.30 =
                                0.85

6      2          20 2 or 0.10  0.85 + 0.10 =
                                0.95

7      1          20 1 or 0.05  0.95 + 0.05 =
                                1.00

Frequency Table of Student Work Hours w/ Relative and Cumulative Relative
Frequency

The last entry of the cumulative relative frequency column is one, indicating that
one hundred percent of the data has been accumulated.

Note:Because of rounding, the relative frequency column may not always sum
to one and the last entry in the cumulative relative frequency column may not be
one. However, they each should be close to one.

The following table represents the heights, in inches, of a sample of 100 male
semiprofessional soccer players.
HEIGHTS   FREQUENCY    RELATIVE      CUMULATIVE
(INCHES)               FREQUENCY     RELATIVE
                                     FREQUENCY

59.95 - 5              100 5 = 0.05  0.05
61.95

61.95 - 3              100 3 = 0.03  0.05 + 0.03 =
63.95                                0.08

63.95 - 15             15 = 0.15     0.08 + 0.15 =
65.95                                0.23
                       100

65.95 - 40             40 = 0.40     0.23 + 0.40 =
67.95                                0.63
                       100

67.95 - 17             17 = 0.17     0.63 + 0.17 =
69.95                                0.80
                       100

69.95 - 12             12 = 0.12     0.80 + 0.12 =
71.95                                0.92
                       100

71.95 - 7               7 = 0.07     0.92 + 0.07 =
73.95                                0.99
                       100

73.95 - 1              100 1 = 0.01  0.99 + 0.01 =
75.95                                1.00

          Total = 100  Total = 1.00

Frequency Table of Soccer Player Height

The data in this table has been grouped into the following intervals:

      59.95 - 61.95 inches
      61.95 - 63.95 inches
      63.95 - 65.95 inches
      65.95 - 67.95 inches
      67.95 - 69.95 inches
69.95 - 71.95 inches
71.95 - 73.95 inches
73.95 - 75.95 inches

Note:This example is used again in the Descriptive Statistics chapter, where the
method used to compute the intervals will be explained.

In this sample, there are 5 players whose heights are between 59.95 - 61.95
inches, 3 players whose heights fall within the interval 61.95 - 63.95 inches, 15
players whose heights fall within the interval 63.95 - 65.95 inches, 40 players
whose heights fall within the interval 65.95 - 67.95 inches, 17 players whose
heights fall within the interval 67.95 - 69.95 inches, 12 players whose heights fall
within the interval 69.95 - 71.95, 7 players whose height falls within the interval
71.95 - 73.95, and 1 player whose height falls within the interval 73.95 - 75.95.
All heights fall between the endpoints of an interval and not at the endpoints.

Example:
Exercise:

   Problem:

From the table, find the percentage of heights that are less than 65.95
inches.

Solution:

If you look at the first, second, and third rows, the heights are all less than

65.95 inches. There are 5 + 3 + 15 = 23 males whose heights are less than

65.95 inches. The percentage of heights less than 65.95 inches is then    23
                                                                         100

or 23%. This percentage is the cumulative relative frequency entry in the

third row.

Example:
Exercise:
   Problem:

   From the table, find the percentage of heights that fall between 61.95 and
   65.95 inches.

   Solution:

   Add the relative frequencies in the second and third rows: 0.03 + 0.15 =
   0.18 or 18%.

Example:
Exercise:

   Problem:

   Use the table of heights of the 100 male semiprofessional soccer players.
   Fill in the blanks and check your answers.

      1. The percentage of heights that are from 67.95 to 71.95 inches is:
      2. The percentage of heights that are from 67.95 to 73.95 inches is:
      3. The percentage of heights that are more than 65.95 inches is:
      4. The number of players in the sample who are between 61.95 and 71.95

         inches tall is:
      5. What kind of data are the heights?
      6. Describe how you could gather this data (the heights) so that the data

         are characteristic of all male semiprofessional soccer players.

   Remember, you count frequencies. To find the relative frequency, divide
   the frequency by the total number of data values. To find the cumulative
   relative frequency, add all of the previous relative frequencies to the
   relative frequency for the current row.

   Solution:

      1. 29%
      2. 36%
      3. 77%
      4. 87
      5. quantitative continuous
      6. get rosters from each team and choose a simple random sample from

         each

Optional Collaborative Classroom Exercise

Exercise:
   Problem:

   In your class, have someone conduct a survey of the number of siblings
   (brothers and sisters) each student has. Create a frequency table. Add to it a
   relative frequency column and a cumulative relative frequency column.
   Answer the following questions:

      1. What percentage of the students in your class has 0 siblings?
      2. What percentage of the students has from 1 to 3 siblings?
      3. What percentage of the students has fewer than 3 siblings?

Example:
Nineteen people were asked how many miles, to the nearest mile they commute
to work each day. The data are as follows:
2 5 7 3 2 10 18 15 20 7 10 18 5 12 13 12 4 5 10
The following table was produced:

DATA  FREQUENCY  RELATIVE   CUMULATIVE
                 FREQUENCY  RELATIVE
                            FREQUENCY
DATA  FREQUENCY  RELATIVE   CUMULATIVE
                 FREQUENCY  RELATIVE
                            FREQUENCY

3     3          19 3 0.1579

4     1          19 1 0.2105

5     3          19 3 0.1579

7     2          19 2 0.2632

10    3          19 4 0.4737

12    2          19 2 0.7895

13    1          19 1 0.8421

15    1          19 1 0.8948

18    1          19 1 0.9474

20    1          19 1 1.0000

Frequency of Commuting Distances

Exercise:

   Problem:

      1. Is the table correct? If it is not correct, what is wrong?
      2. True or False: Three percent of the people surveyed commute 3 miles.

         If the statement is not correct, what should it be? If the table is
         incorrect, make the corrections.
      3. What fraction of the people surveyed commute 5 or 7 miles?
      4. What fraction of the people surveyed commute 12 miles or more?
         Less than 12 miles? Between 5 and 13 miles (does not include 5 and
         13 miles)?
Solution:

1. No. Frequency column sums to 18, not 19. Not all cumulative relative

frequencies are correct.

2. False. Frequency for 3 miles should be 1; for 2 miles (left out), 2.

Cumulative relative frequency column should read: 0.1052, 0.1579,

0.2105, 0.3684, 0.4737, 0.6316, 0.7368, 0.7895, 0.8421, 0.9474, 1.

3. 5
          19

4. 7 , 12 , 7
19            19  19

Glossary

Frequency
      The number of times a value of the data occurs.

Relative Frequency
      The ratio of the number of times a value of the data occurs in the set of all
      outcomes to the number of all outcomes.

Cumulative Relative Frequency
      The term applies to an ordered set of observations from smallest to largest.
      The Cumulative Relative Frequency is the sum of the relative frequencies
      for all values that are less than or equal to the given value.
Summary
This module provides an outline/review of key concepts related to statistical
sampling and data.
Statistics

      Deals with the collection, analysis, interpretation, and presentation of
      data

Probability

      Mathematical tool used to study randomness

Key Terms

      Population
      Parameter
      Sample
      Statistic
      Variable
      Data

Types of Data

      Quantitative Data (a number)

            Discrete (You count it.)
            Continuous (You measure it.)

      Qualitative Data (a category, words)

Sampling

      With Replacement: A member of the population may be chosen more
      than once
      Without Replacement: A member of the population may be chosen
      only once

Random Sampling
      Each member of the population has an equal chance of being selected

Sampling Methods

      Random

            Simple random sample
            Stratified sample
            Cluster sample
            Systematic sample

      Not Random

            Convenience sample

Frequency (freq. or f)

      The number of times an answer occurs

Relative Frequency (rel. freq. or RF)

      The proportion of times an answer occurs
      Can be interpreted as a fraction, decimal, or percent

Cumulative Relative Frequencies (cum. rel. freq. or cum RF)

      An accumulation of the previous relative frequencies
Descriptive Statistics

Student Learning Outcomes

By the end of this chapter, the student should be able to:

      Display data graphically and interpret graphs: stemplots, histograms
      and boxplots.
      Recognize, describe, and calculate the measures of location of data:
      quartiles and percentiles.
      Recognize, describe, and calculate the measures of the center of data:
      mean, median, and mode.
      Recognize, describe, and calculate the measures of the spread of data:
      variance, standard deviation, and range.

Introduction

Once you have collected data, what will you do with it? Data can be
described and presented in many different formats. For example, suppose
you are interested in buying a house in a particular area. You may have no
clue about the house prices, so you might ask your real estate agent to give
you a sample data set of prices. Looking at all the prices in the sample often
is overwhelming. A better way might be to look at the median price and the
variation of prices. The median and variation are just two ways that you
will learn to describe data. Your agent might also provide you with a graph
of the data.

In this chapter, you will study numerical and graphical ways to describe and
display your data. This area of statistics is called "Descriptive Statistics".
You will learn to calculate, and even more importantly, to interpret these
measurements and graphs.
Displaying Data
This module provides a brief introduction into the ways graphs and charts
can be used to provide visual representations of data.

A statistical graph is a tool that helps you learn about the shape or
distribution of a sample. The graph can be a more effective way of
presenting data than a mass of numbers because we can see where data
clusters and where there are only a few data values. Newspapers and the
Internet use graphs to show trends and to enable readers to compare facts
and figures quickly.

Statisticians often graph data first to get a picture of the data. Then, more
formal tools may be applied.

Some of the types of graphs that are used to summarize and organize data
are the dot plot, the bar chart, the histogram, the stem-and-leaf plot, the
frequency polygon (a type of broken line graph), pie charts, and the
boxplot. In this chapter, we will briefly look at stem-and-leaf plots, line
graphs and bar graphs. Our emphasis will be on histograms and boxplots.
Stem and Leaf Graphs (Stemplots)
This module introduces the use of stem-and-leaf graphs (stemplots), line
graphs and bar graphs for describing a set of data visually.

One simple graph, the stem-and-leaf graph or stem plot, comes from the
field of exploratory data analysis.It is a good choice when the data sets are
small. To create the plot, divide each observation of data into a stem and a
leaf. The leaf consists of a final significant digit. For example, 23 has stem
2 and leaf 3. Four hundred thirty-two (432) has stem 43 and leaf 2. Five
thousand four hundred thirty-two (5,432) has stem 543 and leaf 2. The
decimal 9.3 has stem 9 and leaf 3. Write the stems in a vertical line from
smallest the largest. Draw a vertical line to the right of the stems. Then
write the leaves in increasing order next to their corresponding stem.

Example:
For Susan Dean's spring pre-calculus class, scores for the first exam were
as follows (smallest to largest):
334249495355556163676868696972737478808388888890929494949496
100

Stem  Leaf
3     3
4     299
5     355
6     1378899
Stem                   Leaf

7                      2348

8                      03888

9                      0244446

10                     0

Stem-and-Leaf Diagram

The stem plot shows that most scores fell in the 60s, 70s, 80s, and 90s.
Eight out of the 31 scores or approximately 26% of the scores were in the
90's or 100, a fairly high number of As.

The stem plot is a quick way to graph and gives an exact picture of the data.
You want to look for an overall pattern and any outliers. An outlier is an
observation of data that does not fit the rest of the data. It is sometimes
called an extreme value. When you graph an outlier, it will appear not to fit
the pattern of the graph. Some outliers are due to mistakes (for example,
writing down 50 instead of 500) while others may indicate that something
unusual is happening. It takes some background information to explain
outliers. In the example above, there were no outliers.

Example:
Create a stem plot using the data:
1.11.52.32.52.73.23.33.33.53.84.0 4.24.54.54.74.85.55.66.56.712.3
The data are the distance (in kilometers) from a home to the nearest
supermarket.
Exercise:

   Problem:
   1. Are there any values that might possibly be outliers?
   2. Do the data seem to have any concentration of values?

Note:The leaves are to the right of the decimal.

Solution:
The value 12.3 may be an outlier. Values appear to concentrate at 3
and 4 kilometers.

Stem  Leaf
1     1 5
2     3 5 7
3     2 3 3 5 8
4     0 2 5 5 7 8
5     5 6
6     5 7
7
8
Stem  Leaf

9

10

11

12    3

Another type of graph that is useful for specific data values is a line graph.
In the particular line graph shown in the example, the x-axis consists of
data values and the y-axis consists of frequency points. The frequency
points are connected.

Example:
In a survey, 40 mothers were asked how many times per week a teenager
must be reminded to do his/her chores. The results are shown in the table
and the line graph.

Number of times teenager is reminded  Frequency
0                                     2
1                                     5
Number of times teenager is reminded  Frequency
2                                     8
3                                     14
4                                     7
5                                     4

Bar graphs consist of bars that are separated from each other. The bars can
be rectangles or they can be rectangular boxes and they can be vertical or
horizontal.

The bar graph shown in Example 4 has age groups represented on the x-
axis and proportions on the y-axis.
Example:
By the end of 2011, in the United States, Facebook had over 146 million
users. The table shows three age groups, the number of users in each age
group and the proportion (%) of users in each age group. Source:
http://www.kenburbary.com/2011/03/facebook-demographics-revisited-
2011-statistics-2/

Age      Number of       Proportion (%) of
groups   Facebook users  Facebook users

13 - 25  65,082,280      45%

26 - 44  53,300,200      36%

45 - 64  27,885,100      19%
Example:
The columns in the table below contain the race/ethnicity of U.S. Public
Schools: High School Class of 2011, percentages for the Advanced
Placement Examinee Population for that class and percentages for the
Overall Student Population. The 3-dimensional graph shows the
Race/Ethnicity of U.S. Public Schools (qualitative data) on the x-axis and
Advanced Placement Examinee Population percentages on the y-axis.
(Source: http://www.collegeboard.com and Source:
http://apreport.collegeboard.org/goals-and-findings/promoting-equity)

Race/Ethnicity          AP Examinee  Overall
                        Population   Student
1 = Asian, Asian                     Population
American or Pacific
Islander                10.3%        5.7%

2 = Black or African    9.0%         14.7%
American                17.0%        17.6%
                        0.6%         1.1%
3 = Hispanic or Latino  57.1%        59.2%
                        6.0%         1.7%
4 = American Indian or
Alaska Native

5 = White

6 = Not reported/other
Go to Outcomes of Education Figure 22 for an example of a bar graph that
shows unemployment rates of persons 25 years and older for 2009.

Note:This book contains instructions for constructing a histogram and a
box plot for the TI-83+ and TI-84 calculators. You can find additional
instructions for using these calculators on the Texas Instruments (TI)
website.

Glossary

Outlier
      An observation that does not fit the rest of the data.
Histograms
This module provides an overview of Descriptive Statistics: Histogram as a
part of Collaborative Statistics collection (col10522) by Barbara Illowsky
and Susan Dean.

For most of the work you do in this book, you will use a histogram to
display the data. One advantage of a histogram is that it can readily display
large data sets. A rule of thumb is to use a histogram when the data set
consists of 100 values or more.

A histogram consists of contiguous boxes. It has both a horizontal axis and
a vertical axis. The horizontal axis is labeled with what the data represents
(for instance, distance from your home to school). The vertical axis is
labeled either Frequency or relative frequency. The graph will have the
same shape with either label. The histogram (like the stemplot) can give
you the shape of the data, the center, and the spread of the data. (The next
section tells you how to calculate the center and the spread.)

The relative frequency is equal to the frequency for an observed value of
the data divided by the total number of data values in the sample. (In the
chapter on Sampling and Data, we defined frequency as the number of
times an answer occurs.) If:

      f = frequency
      n = total number of data values (or the sum of the individual
      frequencies), and
      RF = relative frequency,

then:
Equation:

                                                                                               f
                                                                             RF =

                                                                                               n

For example, if 3 students in Mr. Ahab's English class of 40 students
received from 90% to 100%, then,
f = 3 , n = 40 , and RF = = = 0.075 f 3
n  40

Seven and a half percent of the students received 90% to 100%. Ninety
percent to 100 % are quantitative measures.

To construct a histogram, first decide how many bars or intervals, also
called classes, represent the data. Many histograms consist of from 5 to 15
bars or classes for clarity. Choose a starting point for the first interval to be
less than the smallest data value. A convenient starting point is a lower
value carried out to one more decimal place than the value with the most
decimal places. For example, if the value with the most decimal places is
6.1 and this is the smallest value, a convenient starting point is 6.05 (6.1 -
0.05 = 6.05). We say that 6.05 has more precision. If the value with the
most decimal places is 2.23 and the lowest value is 1.5, a convenient
starting point is 1.495 (1.5 - 0.005 = 1.495). If the value with the most
decimal places is 3.234 and the lowest value is 1.0, a convenient starting
point is 0.9995 (1.0 - .0005 = 0.9995). If all the data happen to be integers
and the smallest value is 2, then a convenient starting point is 1.5 (2 - 0.5 =
1.5). Also, when the starting point and other boundaries are carried to one
additional decimal place, no data value will fall on a boundary.

Example:
The following data are the heights (in inches to the nearest half inch) of
100 male semiprofessional soccer players. The heights are continuous data
since height is measured.
60 60.5 61 61 61.5
63.5 63.5 63.5
64 64 64 64 64 64 64 64.5 64.5 64.5 64.5 64.5 64.5 64.5 64.5
66 66 66 66 66 66 66 66 66 66 66.5 66.5 66.5 66.5 66.5 66.5 66.5 66.5
66.5 66.5 66.5 67 67 67 67 67 67 67 67 67 67 67 67 67.5 67.5 67.5 67.5
67.5 67.5 67.5
68 68 69 69 69 69 69 69 69 69 69 69 69.5 69.5 69.5 69.5 69.5
70 70 70 70 70 70 70.5 70.5 70.5 71 71 71
72 72 72 72.5 72.5 73 73.5
74
The smallest data value is 60. Since the data with the most decimal places
has one decimal (for instance, 61.5), we want our starting point to have two
decimal places. Since the numbers 0.5, 0.05, 0.005, etc. are convenient
numbers, use 0.05 and subtract it from 60, the smallest value, for the
convenient starting point.
60 - 0.05 = 59.95 which is more precise than, say, 61.5 by one decimal
place. The starting point is, then, 59.95.
The largest value is 74. 74+ 0.05 = 74.05 is the ending value.
Next, calculate the width of each bar or class interval. To calculate this
width, subtract the starting point from the ending value and divide by the
number of bars (you must choose the number of bars you desire). Suppose
you choose 8 bars.
Equation:

74.05 - 59.95     = 1.76
               8

Note:We will round up to 2 and make each bar or class interval 2 units
wide. Rounding up to 2 is one way to prevent a value from falling on a
boundary. Rounding to the next number is necessary even if it goes
against the standard rules of rounding. For this example, using 1.76 as the
width would also work.

The boundaries are:

      59.95
      59.95 + 2 = 61.95
      61.95 + 2 = 63.95
      63.95 + 2 = 65.95
      65.95 + 2 = 67.95
      67.95 + 2 = 69.95
      69.95 + 2 = 71.95
      71.95 + 2 = 73.95
      73.95 + 2 = 75.95
The heights 60 through 61.5 inches are in the interval 59.95 - 61.95. The
heights that are 63.5 are in the interval 61.95 - 63.95. The heights that are
64 through 64.5 are in the interval 63.95 - 65.95. The heights 66 through
67.5 are in the interval 65.95 - 67.95. The heights 68 through 69.5 are in
the interval 67.95 - 69.95. The heights 70 through 71 are in the interval
69.95 - 71.95. The heights 72 through 73.5 are in the interval 71.95 -
73.95. The height 74 is in the interval 73.95 - 75.95.
The following histogram displays the heights on the x-axis and relative
frequency on the y-axis.

Example:
The following data are the number of books bought by 50 part-time college
students at ABC College. The number of books is discrete data since books
are counted.
1 1 1 1 1 1 1 1 1 1 1
2 2 2 2 2 2 2 2 2 2
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
4 4 4 4 4 4
5 5 5 5 5
6 6
Eleven students buy 1 book. Ten students buy 2 books. Sixteen students
buy 3 books. Six students buy 4 books. Five students buy 5 books. Two
students buy 6 books.
Because the data are integers, subtract 0.5 from 1, the smallest data value
and add 0.5 to 6, the largest data value. Then the starting point is 0.5 and
the ending value is 6.5.
Exercise:

   Problem:

   Next, calculate the width of each bar or class interval. If the data are
   discrete and there are not too many different values, a width that
   places the data values in the middle of the bar or class interval is the
   most convenient. Since the data consist of the numbers 1, 2, 3, 4, 5, 6
   and the starting point is 0.5, a width of one places the 1 in the middle
   of the interval from 0.5 to 1.5, the 2 in the middle of the interval from
   1.5 to 2.5, the 3 in the middle of the interval from 2.5 to 3.5, the 4 in
   the middle of the interval from _______ to _______, the 5 in the
   middle of the interval from _______ to _______, and the _______ in
   the middle of the interval from _______ to _______ .

   Solution:

         3.5 to 4.5
         4.5 to 5.5
         6
         5.5 to 6.5

Calculate the number of bars as follows:
Equation:
6.5 - 0.5  =1
     bars

where 1 is the width of a bar. Therefore, bars = 6.
The following histogram displays the number of books on the x-axis and
the frequency on the y-axis.

Using the TI-83, 83+, 84, 84+ Calculator Instructions
Go to the Appendix (14:Appendix) in the menu on the left. There are
calculator instructions for entering data and for creating a customized
histogram. Create the histogram for Example 2.

      Press Y=. Press CLEAR to clear out any equations.
      Press STAT 1:EDIT. If L1 has data in it, arrow up into the name L1,
      press CLEAR and arrow down. If necessary, do the same for L2.
      Into L1, enter 1, 2, 3, 4, 5, 6
      Into L2, enter 11, 10, 16, 6, 5, 2
      Press WINDOW. Make Xmin = .5, Xmax = 6.5, Xscl = (6.5 - .5)/6,
      Ymin = -1, Ymax = 20, Yscl = 1, Xres = 1
      Press 2nd Y=. Start by pressing 4:Plotsoff ENTER.
      Press 2nd Y=. Press 1:Plot1. Press ENTER. Arrow down to TYPE.
      Arrow to the 3rd picture (histogram). Press ENTER.
      Arrow down to Xlist: Enter L1 (2nd 1). Arrow down to Freq. Enter L2
      (2nd 2).
      Press GRAPH
      Use the TRACE key and the arrow keys to examine the histogram.

Optional Collaborative Exercise

Count the money (bills and change) in your pocket or purse. Your instructor
will record the amounts. As a class, construct a histogram displaying the
data. Discuss how many intervals you think is appropriate. You may want to
experiment with the number of intervals. Discuss, also, the shape of the
histogram.

Record the data, in dollars (for example, 1.25 dollars).

Construct a histogram.

Glossary

Frequency
      The number of times a value of the data occurs.

Relative Frequency
      The ratio of the number of times a value of the data occurs in the set of
      all outcomes to the number of all outcomes.
Box Plots

Box plots or box-whisker plots give a good graphical image of the
concentration of the data. They also show how far from most of the data the
extreme values are. The box plot is constructed from five values: the
smallest value, the first quartile, the median, the third quartile, and the
largest value. The median, the first quartile, and the third quartile will be
discussed here, and then again in the section on measuring data in this
chapter. We use these values to compare how close other data values are to
them.

The median, a number, is a way of measuring the "center" of the data. You
can think of the median as the "middle value," although it does not actually
have to be one of the observed values. It is a number that separates ordered
data into halves. Half the values are the same number or smaller than the
median and half the values are the same number or larger. For example,
consider the following data:

1 11.5 6 7.2 4 8 9 10 6.8 8.3 2 2 10 1

Ordered from smallest to largest:

1 1 2 2 4 6 6.8 7.2 8 8.3 9 10 10 11.5

The median is between the 7th value, 6.8, and the 8th value 7.2. To find the
median, add the two values together and divide by 2.
Equation:

           6.8 + 7.2                    =7
                    2

The median is 7. Half of the values are smaller than 7 and half of the values
are larger than 7.

Quartiles are numbers that separate the data into quarters. Quartiles may or
may not be part of the data. To find the quartiles, first find the median or
second quartile. The first quartile is the middle value of the lower half of
the data and the third quartile is the middle value of the upper half of the
data. To get the idea, consider the same data set shown above:

1 1 2 2 4 6 6.8 7.2 8 8.3 9 10 10 11.5

The median or second quartile is 7. The lower half of the data is 1, 1, 2, 2,
4, 6, 6.8. The middle value of the lower half is 2.

1 1 2 2 4 6 6.8

The number 2, which is part of the data, is the first quartile. One-fourth of
the values are the same or less than 2 and three-fourths of the values are
more than 2.

The upper half of the data is 7.2, 8, 8.3, 9, 10, 10, 11.5. The middle value of
the upper half is 9.

7.2 8 8.3 9 10 10 11.5

The number 9, which is part of the data, is the third quartile. Three-fourths
of the values are less than 9 and one-fourth of the values are more than 9.

To construct a box plot, use a horizontal number line and a rectangular box.
The smallest and largest data values label the endpoints of the axis. The first
quartile marks one end of the box and the third quartile marks the other end
of the box. The middle fifty percent of the data fall inside the box. The
"whiskers" extend from the ends of the box to the smallest and largest data
values. The box plot gives a good quick picture of the data.

Note:You may encounter box and whisker plots that have dots marking
outlier values. In those cases, the whiskers are not extending to the
minimum and maximum values.

Consider the following data:
1 1 2 2 4 6 6.8 7.2 8 8.3 9 10 10 11.5
The first quartile is 2, the median is 7, and the third quartile is 9. The
smallest value is 1 and the largest value is 11.5. The box plot is constructed
as follows (see calculator instructions in the back of this book or on the TI
web site):

The two whiskers extend from the first quartile to the smallest value and
from the third quartile to the largest value. The median is shown with a
dashed line.

Example:
The following data are the heights of 40 students in a statistics class.
59 60 61 62 62 63 63 64 64 64 65 65 65 65 65 65 65 65 65 66 66 67 67 68
68 69 70 70 70 70 70 71 71 72 72 73 74 74 75 77
Construct a box plot:
Using the TI-83, 83+, 84, 84+ Calculator

      Enter data into the list editor (Press STAT 1:EDIT). If you need to
      clear the list, arrow up to the name L1, press CLEAR, arrow down.
      Put the data values in list L1.
      Press STAT and arrow to CALC. Press 1:1-VarStats. Enter L1.
      Press ENTER
      Use the down and up arrow keys to scroll.
      Smallest value = 59
      Largest value = 77
      Q1: First quartile = 64.5
      Q2: Second quartile or median= 66
      Q3: Third quartile = 70

Using the TI-83, 83+, 84, 84+ to Construct the Box Plot
Go to 14:Appendix for Notes for the TI-83, 83+, 84, 84+ Calculator. To
create the box plot:

      Press Y=. If there are any equations, press CLEAR to clear them.
      Press 2nd Y=.
      Press 4:Plotsoff. Press ENTER
      Press 2nd Y=
      Press 1:Plot1. Press ENTER.
      Arrow down and then use the right arrow key to go to the 5th picture
      which is the box plot. Press ENTER.
      Arrow down to Xlist: Press 2nd 1 for L1
      Arrow down to Freq: Press ALPHA. Press 1.
      Press ZOOM. Press 9:ZoomStat.
      Press TRACE and use the arrow keys to examine the box plot.

      aEach quarter has 25% of the data.
      bThe spreads of the four quarters are 64.5 - 59 = 5.5 (first quarter), 66
      - 64.5 = 1.5 (second quarter), 70 - 66 = 4 (3rd quarter), and 77 - 70 =
      7 (fourth quarter). So, the second quarter has the smallest spread and
      the fourth quarter has the largest spread.
      cInterquartile Range: IQR = Q3 - Q1 = 70 - 64.5 = 5.5.
      dThe interval 59 through 65 has more than 25% of the data so it has
      more data in it than the interval 66 through 70 which has 25% of the
      data.
      eThe middle 50% (middle half) of the data has a range of 5.5 inches.
For some sets of data, some of the largest value, smallest value, first
quartile, median, and third quartile may be the same. For instance, you
might have a data set in which the median and the third quartile are the
same. In this case, the diagram would not have a dotted line inside the box
displaying the median. The right side of the box would display both the
third quartile and the median. For example, if the smallest value and the
first quartile were both 1, the median and the third quartile were both 5,
and the largest value was 7, the box plot would look as follows:

Example:
Test scores for a college statistics class held during the day are:
99 56 78 55.5 32 90 80 81 56 59 45 77 84.5 84 70 72 68 32 79 90
Test scores for a college statistics class held during the evening are:
98 78 68 83 81 89 88 76 65 45 98 90 80 84.5 85 79 78 98 90 79 81 25.5
Exercise:

   Problem:

         What are the smallest and largest data values for each data set?
         What is the median, the first quartile, and the third quartile for
         each data set?
         Create a boxplot for each set of data.
         Which boxplot has the widest spread for the middle 50% of the
         data (the data between the first and third quartiles)? What does
         this mean for that set of data in comparison to the other set of
         data?
      For each data set, what percent of the data is between the
      smallest value and the first quartile? (Answer: 25%) the first
      quartile and the median? (Answer: 25%) the median and the third
      quartile? the third quartile and the largest value? What percent of
      the data is between the first quartile and the largest value?
      (Answer: 75%)

Solution:
First Data Set

           Xmin = 32
           Q1 = 56

                   = 74.5
           Q3 = 82.5
           Xmax = 99

Second Data Set

           Xmin = 25.5
           Q1 = 78

                   = 81
           Q3 = 89
           Xmax = 98
The first data set (the top box plot) has the widest spread for the middle
50% of the data. IQR = Q3 - Q1 is 82.5 - 56 = 26.5 for the first data
set and 89 - 78 = 11 for the second data set. So, the first set of data has
its middle 50% of scores more spread out.
25% of the data is between and Q3 and 25% is between Q3 and Xmax.

Glossary

Median
      A number that separates ordered data into halves. Half the values are
      the same number or smaller than the median and half the values are the
      same number or larger than the median. The median may or may not
      be part of the data.

Quartiles
      The numbers that separate the data into quarters. Quartiles may or may
      not be part of the data. The second quartile is the median of the data.
Measures of the Location of the Data
Descriptive Statistics: Measuring the Location of Data explains percentiles and
quartiles and is part of the collection col10555 written by Barbara Illowsky and
Susan Dean. Roberta Bloom contributed the section "Interpreting Percentiles,
Quartile and the Median."

The common measures of location are quartiles and percentiles (%iles). Quartiles
are special percentiles. The first quartile, Q1 is the same as the 25th percentile
(25th %ile) and the third quartile, Q3, is the same as the 75th percentile (75th
%ile). The median, M, is called both the second quartile and the 50th percentile
(50th %ile).

Note:Quartiles are given special attention in the Box Plots module in this chapter.

To calculate quartiles and percentiles, the data must be ordered from smallest to
largest. Recall that quartiles divide ordered data into quarters. Percentiles divide
ordered data into hundredths. To score in the 90th percentile of an exam does not
mean, necessarily, that you received 90% on a test. It means that 90% of test
scores are the same or less than your score and 10% of the test scores are the same
or greater than your test score.

Percentiles are useful for comparing values. For this reason, universities and
colleges use percentiles extensively.

Percentiles are mostly used with very large populations. Therefore, if you were to
say that 90% of the test scores are less (and not the same or less) than your score,
it would be acceptable because removing one particular data value is not
significant.

The interquartile range is a number that indicates the spread of the middle half
or the middle 50% of the data. It is the difference between the third quartile (Q3)
and the first quartile (Q1).
Equation:

                                                                           IQR = Q3 - Q1
The IQR can help to determine potential outliers. A value is suspected to be a
potential outlier if it is less than (1.5)(IQR) below the first quartile or more
than (1.5)(IQR) above the third quartile. Potential outliers always need further
investigation.

Example:
Exercise:

   Problem:

   For the following 13 real estate prices, calculate the IQR and determine if
   any prices are outliers. Prices are in dollars. (Source: San Jose Mercury
   News)

   389,950 230,500 158,000 479,000 639,000 114,950 5,500,000 387,000
   659,000 529,000 575,000 488,800 1,095,000

   Solution:

   Order the data from smallest to largest.

   114,950 158,000 230,500 387,000 389,950 479,000 488,800 529,000
   575,000 639,000 659,000 1,095,000 5,500,000

M = 488,800

Q1 =  230500+387000        = 308750
                        2

Q3 =  639000+659000        = 649000
                        2

IQR = 649000 - 308750 = 340250

(1.5)(IQR) = (1.5)(340250) = 510375

Q1 - (1.5)(IQR) = 308750 - 510375 = -201625

Q3 + (1.5)(IQR) = 649000 + 510375 = 1159375

No house price is less than -201625. However, 5,500,000 is more than
1,159,375. Therefore, 5,500,000 is a potential outlier.
Example:
Exercise:

   Problem:

   For the two data sets in the test scores example, find the following:

         aThe interquartile range. Compare the two interquartile ranges.
         bAny outliers in either set.
         cThe 30th percentile and the 80th percentile for each set. How much
         data falls below the 30th percentile? Above the 80th percentile?

Solution:

For the IQRs, see the answer to the test scores example. The first data set has
the larger IQR, so the scores between Q3 and Q1 (middle 50%) for the first
data set are more spread out and not clustered about the median.

First Data Set

           3                   3
         ( )  (IQR) = ( )  (26.5) = 39.75
           2                   2

         Xmax - Q3 = 99 - 82.5 = 16.5

         Q1 - Xmin = 56 - 32 = 24

( 2 )  (IQR) = 39.75 3 is larger than 16.5 and larger than 24, so the first set
has no outliers.

Second Data Set

           3               3
         ( )  (IQR) = ( )  (11) = 16.5
           2               2

         Xmax - Q3 = 98 - 89 = 9

         Q1 - Xmin = 78 - 25.5 = 52.5

(  3  )    (IQR)  =  16.5  is  larger  than  9  but  smaller  than  52.5,  so  for  the
   2

second set 45 and 25.5 are outliers.

To find the percentiles, create a frequency, relative frequency, and
cumulative relative frequency chart (see "Frequency" from the Sampling and
Data Chapter). Get the percentiles from that chart.
First Data Set

30th %ile (between the 6th and 7th values) =         (56 + 59)    = 57.5
                                                               2

80th %ile (between the 16th and 17th values) =       (84 + 84.5)    = 84.25
                                                                 2

Second Data Set

           30th %ile (7th value) = 78
           80th %ile (18th value) = 90

30% of the data falls below the 30th %ile, and 20% falls above the 80th
%ile.

Example:
Finding Quartiles and Percentiles Using a Table
Fifty statistics students were asked how much sleep they get per school night
(rounded to the nearest hour). The results were (student data):

AMOUNT   FREQUENCY  RELATIVE                         CUMULATIVE
OF       2          FREQUENCY                        RELATIVE
SLEEP    5                                           FREQUENCY
PER                 0.04
SCHOOL                                               0.04
NIGHT               0.10
(HOURS)                                              0.14

4

5
AMOUNT    FREQUENCY  RELATIVE   CUMULATIVE
OF        7          FREQUENCY  RELATIVE
SLEEP     12         0.14       FREQUENCY
PER       14         0.24
SCHOOL    7          0.28       0.28
NIGHT     3          0.14
(HOURS)              0.06       0.52

6                               0.80

7                               0.94

8                               1.00

9

10

Find the 28th percentile: Notice the 0.28 in the "cumulative relative frequency"
column. 28% of 50 data values = 14. There are 14 values less than the 28th %ile.
They include the two 4s, the five 5s, and the seven 6s. The 28th %ile is between
the last 6 and the first 7. The 28th %ile is 6.5.
Find the median: Look again at the "cumulative relative frequency " column and
find 0.52. The median is the 50th %ile or the second quartile. 50% of 50 = 25.
There are 25 values less than the median. They include the two 4s, the five 5s, the
seven 6s, and eleven of the 7s. The median or 50th %ile is between the 25th (7)
and 26th (7) values. The median is 7.
Find the third quartile: The third quartile is the same as the 75th percentile. You
can "eyeball" this answer. If you look at the "cumulative relative frequency"
column, you find 0.52 and 0.80. When you have all the 4s, 5s, 6s and 7s, you
have 52% of the data. When you include all the 8s, you have 80% of the data.
The 75th %ile, then, must be an 8 . Another way to look at the problem is to
find 75% of 50 (= 37.5) and round up to 38. The third quartile, Q3, is the 38th
value which is an 8. You can check this answer by counting the values. (There are
37 values below the third quartile and 12 values above.)

Example:
Exercise:

   Problem: Using the table:

      1. Find the 80th percentile.
      2. Find the 90th percentile.
      3. Find the first quartile.
      4. What is another name for the first quartile?

Solution:

1. (8+9)           = 8.5
                2

Look where cum. rel. freq. = 0.80. 80% of the data is 8 or less. 80th

%ile is between the last 8 and first 9.

2. 9

3. 6

4. First Quartile = 25th %ile

Collaborative Classroom Exercise: Your instructor or a member of the class will
ask everyone in class how many sweaters they own. Answer the following
questions.

   1. How many students were surveyed?
   2. What kind of sampling did you do?
   3. Construct a table of the data.
   4. Construct 2 different histograms. For each, starting value = _____ ending

      value = ____.
   5. Use the table to find the median, first quartile, and third quartile.
   6. Construct a box plot.
   7. Use the table to find the following:

            The 10th percentile
            The 70th percentile
            The percent of students who own less than 4 sweaters

Interpreting Percentiles, Quartiles, and Median
A percentile indicates the relative standing of a data value when data are sorted
into numerical order, from smallest to largest. p% of data values are less than or
equal to the pth percentile. For example, 15% of data values are less than or equal
to the 15th percentile.

      Low percentiles always correspond to lower data values.
      High percentiles always correspond to higher data values.

A percentile may or may not correspond to a value judgment about whether it is
"good" or "bad". The interpretation of whether a certain percentile is good or bad
depends on the context of the situation to which the data applies. In some
situations, a low percentile would be considered "good'; in other contexts a high
percentile might be considered "good". In many situations, there is no value
judgment that applies.

Understanding how to properly interpret percentiles is important not only when
describing data, but is also important in later chapters of this textbook when
calculating probabilities.

Guideline:

When writing the interpretation of a percentile in the context of the given data, the
sentence should contain the following information:

      information about the context of the situation being considered,
      the data value (value of the variable) that represents the percentile,
      the percent of individuals or items with data values below the percentile.
      Additionally, you may also choose to state the percent of individuals or items
      with data values above the percentile.

Example:
On a timed math test, the first quartile for times for finishing the exam was 35
minutes. Interpret the first quartile in the context of this situation.

      25% of students finished the exam in 35 minutes or less.
      75% of students finished the exam in 35 minutes or more.
      A low percentile could be considered good, as finishing more quickly on a
      timed exam is desirable. (If you take too long, you might not be able to
      finish.)
Example:
On a 20 question math test, the 70th percentile for number of correct answers was
16. Interpret the 70th percentile in the context of this situation.

      70% of students answered 16 or fewer questions correctly.
      30% of students answered 16 or more questions correctly.
      Note: A high percentile could be considered good, as answering more
      questions correctly is desirable.

Example:
At a certain community college, it was found that the 30th percentile of credit
units that students are enrolled for is 7 units. Interpret the 30th percentile in the
context of this situation.

      30% of students are enrolled in 7 or fewer credit units
      70% of students are enrolled in 7 or more credit units
      In this example, there is no "good" or "bad" value judgment associated with
      a higher or lower percentile. Students attend community college for varied
      reasons and needs, and their course load varies according to their needs.

Do the following Practice Problems for Interpreting Percentiles
Exercise:

   Problem:

         a For runners in a race, a low time means a faster run. The winners in a
         race have the shortest running times. Is it more desirable to have a finish
         time with a high or a low percentile when running a race?
         b The 20th percentile of run times in a particular race is 5.2 minutes.
         Write a sentence interpreting the 20th percentile in the context of the
         situation.
         c A bicyclist in the 90th percentile of a bicycle race between two towns
         completed the race in 1 hour and 12 minutes. Is he among the fastest or
         slowest cyclists in the race? Write a sentence interpreting the 90th
         percentile in the context of the situation.

   Solution:

         a For runners in a race it is more desirable to have a low percentile for
         finish time. A low percentile means a short time, which is faster.
         bINTERPRETATION: 20% of runners finished the race in 5.2 minutes
         or less. 80% of runners finished the race in 5.2 minutes or longer.
         cHe is among the slowest cyclists (90% of cyclists were faster than
         him.) INTERPRETATION: 90% of cyclists had a finish time of 1 hour,
         12 minutes or less.Only 10% of cyclists had a finish time of 1 hour, 12
         minutes or longer

Exercise:
   Problem:

         a For runners in a race, a higher speed means a faster run. Is it more
         desirable to have a speed with a high or a low percentile when running a
         race?
         bThe 40th percentile of speeds in a particular race is 7.5 miles per hour.
         Write a sentence interpreting the 40th percentile in the context of the
         situation.

   Solution:

         aFor runners in a race it is more desirable to have a high percentile for
         speed. A high percentile means a higher speed, which is faster.
         bINTERPRETATION: 40% of runners ran at speeds of 7.5 miles per
         hour or less (slower). 60% of runners ran at speeds of 7.5 miles per hour
         or more (faster).

Exercise:
   Problem:

   On an exam, would it be more desirable to earn a grade with a high or low
   percentile? Explain.

   Solution:

   On an exam you would prefer a high percentile; higher percentiles
   correspond to higher grades on the exam.
Exercise:
   Problem:

   Mina is waiting in line at the Department of Motor Vehicles (DMV). Her wait
   time of 32 minutes is the 85th percentile of wait times. Is that good or bad?
   Write a sentence interpreting the 85th percentile in the context of this
   situation.

   Solution:

   When waiting in line at the DMV, the 85th percentile would be a long wait
   time compared to the other people waiting. 85% of people had shorter wait
   times than you did. In this context, you would prefer a wait time
   corresponding to a lower percentile. INTERPRETATION: 85% of people at
   the DMV waited 32 minutes or less. 15% of people at the DMV waited 32
   minutes or longer.
Exercise:
   Problem:

   In a survey collecting data about the salaries earned by recent college
   graduates, Li found that her salary was in the 78th percentile. Should Li be
   pleased or upset by this result? Explain.

   Solution:

   Li should be pleased. Her salary is relatively high compared to other recent
   college grads. 78% of recent college graduates earn less than Li does. 22% of
   recent college graduates earn more than Li does.
Exercise:
   Problem:

   In a study collecting data about the repair costs of damage to automobiles in a
   certain type of crash tests, a certain model of car had $1700 in damage and
   was in the 90th percentile. Should the manufacturer and/or a consumer be
   pleased or upset by this result? Explain. Write a sentence that interprets the
   90th percentile in the context of this problem.

   Solution:

   The manufacturer and the consumer would be upset. This is a large repair
   cost for the damages, compared to the other cars in the sample.
   INTERPRETATION: 90% of the crash tested cars had damage repair costs of
   $1700 or less; only 10% had damage repair costs of $1700 or more.

Exercise:

   Problem:

         The University of California has two criteria used to set admission
         standards for freshman to be admitted to a college in the UC system:
         a. Students' GPAs and scores on standardized tests (SATs and ACTs) are
         entered into a formula that calculates an "admissions index" score. The
         admissions index score is used to set eligibility standards intended to
         meet the goal of admitting the top 12% of high school students in the
         state. In this context, what percentile does the top 12% represent?
         b. Students whose GPAs are at or above the 96th percentile of all
         students at their high school are eligible (called eligible in the local
         context), even if they are not in the top 12% of all students in the state.
         What percent of students from each high school are "eligible in the local
         context"?

   Solution:

         aThe top 12% of students are those who are at or above the 88th
         percentile of admissions index scores.
         b The top 4% of students' GPAs are at or above the 96th percentile,
         making the top 4% of students "eligible in the local context".

Exercise:
   Problem:

   Suppose that you are buying a house. You and your realtor have determined
   that the most expensive house you can afford is the 34th percentile. The 34th
   percentile of housing prices is $240,000 in the town you want to move to. In
   this town, can you afford 34% of the houses or 66% of the houses?

   Solution:

   You can afford 34% of houses. 66% of the houses are too expensive for your
   budget. INTERPRETATION: 34% of houses cost $240,000 or less. 66% of
   houses cost $240,000 or more.

**With contributions from Roberta Bloom

Glossary

Interquartile Range (IRQ)
      The distance between the third quartile (Q3) and the first quartile (Q1). IQR
      = Q3 - Q1.

Outlier
      An observation that does not fit the rest of the data.

Percentile
      A number that divides ordered data into hundredths.

Example:

Let a data set contain 200 ordered observations starting with

                            . Then the first percentile is  (2.7+2.8)                                                                                                                                    = 2.75,

{2.3,2.7,2.8,2.9,2.9,3.0...}

                                                                                                                                                                                                      2

because 1% of the data is to the left of this point on the number line and 99% of

                                                                                                                                                               (2.9+2.9)

the data is on its right. The second percentile is 2 = 2.9. Percentiles may
or may not be part of the data. In this example, the first percentile is not in the

data, but the second percentile is. The median of the data is the second quartile

and the 50th percentile. The first and third quartiles are the 25th and the 75th

percentiles, respectively.
Quartiles
      The numbers that separate the data into quarters. Quartiles may or may not be
      part of the data. The second quartile is the median of the data.
Measures of the Center of the Data
This chapter discusses measuring descriptive statistical information using the
center of the data

The "center" of a data set is also a way of describing location. The two most
widely used measures of the "center" of the data are the mean (average) and the
median. To calculate the mean weight of 50 people, add the 50 weights
together and divide by 50. To find the median weight of the 50 people, order
the data and find the number that splits the data into two equal parts (previously
discussed under box plots in this chapter). The median is generally a better
measure of the center when there are extreme values or outliers because it is not
affected by the precise numerical values of the outliers. The mean is the most
common measure of the center.

Note:The words "mean" and "average" are often used interchangeably. The
substitution of one word for the other is common practice. The technical term
is "arithmetic mean" and "average" is technically a center location. However,
in practice among non-statisticians, "average" is commonly accepted for
"arithmetic mean."

The mean can also be calculated by multiplying each distinct value by its
frequency and then dividing the sum by the total number of data values. The
letter used to represent the sample mean is an x with a bar over it (pronounced
"x bar"): x.

The Greek letter  (pronounced "mew") represents the population mean. One
of the requirements for the sample mean to be a good estimate of the population
mean is for the sample taken to be truly random.

To see that both ways of calculating the mean are the same, consider the
sample:

11122344444
Equation:
x=         1+1+1+2+2+3+4+4+4+4+4                                 = 2.7
                                                             11

Equation:

           x=  3  1 + 2  2+1  3 + 5  4          = 2.7
                                                11

In the second calculation for the sample mean, the frequencies are 3, 2, 1, and
5.

You can quickly find the location of the median by using the expression  n+1 .
                                                                             2

The letter n is the total number of data values in the sample. If n is an odd
number, the median is the middle value of the ordered data (ordered smallest to
largest). If n is an even number, the median is equal to the two middle values
added together and divided by 2 after the data has been ordered. For example, if
the total number of data values is 97, then 2 n+1 = 2 97+1 = 49. The median is the
49th value in the ordered data. If the total number of data values is 100, then
2 n+1 = 2 100+1 = 50.5. The median occurs midway between the 50th and 51st
values. The location of the median and the value of the median are not the
same. The upper case letter M is often used to represent the median. The next
example illustrates the location of the median and the value of the median.

Example:
Exercise:

   Problem:

   AIDS data indicating the number of months an AIDS patient lives after
   taking a new antibody drug are as follows (smallest to largest):

   34881011121314151516161717182122222424252626272729293132333
   33434353740444447

   Calculate the mean and the median.

   Solution:
The calculation for the mean is:

x=   [3+4+(8)(2)+10+11+12+13+14+(15)(2)+(16)(2)+...+35+37+40+(44)(2)+47]                                       = 23.6
                                                                                                           40

To find the median, M, first use the formula for the location. The location
is:

n+1  =  40+1  = 20.5

2          2

Starting at the smallest value, the median is located between the 20th and
21st values (the two 24s):

34881011121314151516161717182122222424
25262627272929313233333434353740444447

M=   24+24    = 24

        2

   The median is 24.

Using the TI-83,83+,84, 84+ Calculators
Calculator Instructions are located in the menu item 14:Appendix (Notes for
the TI-83, 83+, 84, 84+ Calculators).

Enter data into the list editor. Press STAT 1:EDIT
Put the data values in list L1.
Press STAT and arrow to CALC. Press 1:1-VarStats. Press 2nd 1 for L1
and ENTER.
Press the down and up arrow keys to scroll.

x = 23.6, M = 24

Example:
Exercise:

   Problem:

   Suppose that, in a small town of 50 people, one person earns $5,000,000
   per year and the other 49 each earn $30,000. Which is the better measure
   of the "center," the mean or the median?
Solution:

x=  5000000+4930000          = 129400
                          50

M = 30000

(There are 49 people who earn $30,000 and one person who earns
$5,000,000.)

The median is a better measure of the "center" than the mean because 49
of the values are 30,000 and one is 5,000,000. The 5,000,000 is an outlier.
The 30,000 gives us a better sense of the middle of the data.

Another measure of the center is the mode. The mode is the most frequent
value. If a data set has two values that occur the same number of times, then the
set is bimodal.

Example:
Statistics exam scores for 20 students are as follows
Statistics exam scores for 20 students are as follows:
50 53 59 59 63 63 72 72 72 72 72 76 78 81 83 84 84 84 90 93
Exercise:

   Problem:Find the mode.

   Solution:

   The most frequent score is 72, which occurs five times. Mode = 72.

Example:
Five real estate exam scores are 430, 430, 480, 480, 495. The data set is
bimodal because the scores 430 and 480 each occur twice.
When is the mode the best measure of the "center"? Consider a weight loss
program that advertises a mean weight loss of six pounds the first week of the
program. The mode might indicate that most people lose two pounds the first
week, making the program less appealing.

Note:The mode can be calculated for qualitative data as well as for
quantitative data.

Statistical software will easily calculate the mean, the median, and the mode.
Some graphing calculators can also make these calculations. In the real world,
people make these calculations using software.

The Law of Large Numbers and the Mean

The Law of Large Numbers says that if you take samples of larger and larger
size from any population, then the mean x of the sample is very likely to get
closer and closer to . This is discussed in more detail in The Central Limit
Theorem.

Note:The formula for the mean is located in the Summary of Formulas section
course.

Sampling Distributions and Statistic of a Sampling Distribution

You can think of a sampling distribution as a relative frequency distribution
with a great many samples. (See Sampling and Data for a review of relative
frequency). Suppose thirty randomly selected students were asked the number
of movies they watched the previous week. The results are in the relative
frequency table shown below.
# of movies  Relative Frequency
0            5/30
1            15/30
2            6/30
3            4/30
4            1/30

If you let the number of samples get very large (say, 300 million or more),
the relative frequency table becomes a relative frequency distribution.

A statistic is a number calculated from a sample. Statistic examples include the
mean, the median and the mode as well as others. The sample mean x is an
example of a statistic which estimates the population mean .

Glossary

Mean

A number that measures the central tendency. A common name for mean

is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By

definition, the mean for a sample (denoted by x) is

x = Sum of all values in the sample , and the mean for a population (denoted by
                  Number of values in the sample

) is  =      . Sum of all values in the population

             Number of values in the population

Median
      A number that separates ordered data into halves. Half the values are the
      same number or smaller than the median and half the values are the same
      number or larger than the median. The median may or may not be part of
      the data.

Mode
      The value that appears most frequently in a set of data.
Skewness and the Mean, Median, and Mode
Consider the following data set:
4 5 6 6 6 7 7 7 7 7 7 8 8 8 9 10
This data set produces the histogram shown below. Each interval has width
one and each value is located in the middle of an interval.

The histogram displays a symmetrical distribution of data. A distribution is
symmetrical if a vertical line can be drawn at some point in the histogram
such that the shape to the left and the right of the vertical line are mirror
images of each other. The mean, the median, and the mode are each 7 for
these data. In a perfectly symmetrical distribution, the mean and the
median are the same. This example has one mode (unimodal) and the
mode is the same as the mean and median. In a symmetrical distribution
that has two modes (bimodal), the two modes would be different from the
mean and median.
The histogram for the data:
4 5 6 6 6 7 7 7 7 8
is not symmetrical. The right-hand side seems "chopped off" compared to
the left side. The shape distribution is called skewed to the left because it is
pulled out to the left.
The mean is 6.3, the median is 6.5, and the mode is 7. Notice that the
mean is less than the median and they are both less than the mode. The
mean and the median both reflect the skewing but the mean more so.
The histogram for the data:
6 7 7 7 7 8 8 8 9 10
is also not symmetrical. It is skewed to the right.

The mean is 7.7, the median is 7.5, and the mode is 7. Of the three statistics,
the mean is the largest, while the mode is the smallest. Again, the mean
reflects the skewing the most.
To summarize, generally if the distribution of data is skewed to the left, the
mean is less than the median, which is often less than the mode. If the
distribution of data is skewed to the right, the mode is often less than the
median, which is less than the mean.
Skewness and symmetry become important when we discuss probability
distributions in later chapters.
Measures of the Spread of the Data
Descriptive Statistics: Measuring the Spread of Data explains standard deviation as a measure of variation in data
and is part of the collection col10555 written by Barbara Illowsky and Susan Dean. Roberta Bloom made
contributions that helped to clarify the standard deviation and the variance.

An important characteristic of any set of data is the variation in the data. In some data sets, the data values are
concentrated closely near the mean; in other data sets, the data values are more widely spread out from the mean.
The most common measure of variation, or spread, is the standard deviation.

The standard deviation is a number that measures how far data values are from their mean.

The standard deviation

      provides a numerical measure of the overall amount of variation in a data set
      can be used to determine whether a particular data value is close to or far from the mean

The standard deviation provides a measure of the overall variation in a data set
The standard deviation is always positive or 0. The standard deviation is small when the data are all concentrated
close to the mean, exhibiting little variation or spread. The standard deviation is larger when the data values are
more spread out from the mean, exhibiting more variation.

Suppose that we are studying waiting times at the checkout line for customers at supermarket A and supermarket
B; the average wait time at both markets is 5 minutes. At market A, the standard deviation for the waiting time is 2
minutes; at market B the standard deviation for the waiting time is 4 minutes.

Because market B has a higher standard deviation, we know that there is more variation in the waiting times at
market B. Overall, wait times at market B are more spread out from the average; wait times at market A are more
concentrated near the average.

The standard deviation can be used to determine whether a data value is close to or far from the mean.
Suppose that Rosa and Binh both shop at Market A. Rosa waits for 7 minutes and Binh waits for 1 minute at the
checkout counter. At market A, the mean wait time is 5 minutes and the standard deviation is 2 minutes. The
standard deviation can be used to determine whether a data value is close to or far from the mean.

Rosa waits for 7 minutes:

      7 is 2 minutes longer than the average of 5; 2 minutes is equal to one standard deviation.
      Rosa's wait time of 7 minutes is 2 minutes longer than the average of 5 minutes.
      Rosa's wait time of 7 minutes is one standard deviation above the average of 5 minutes.

Binh waits for 1 minute.

      1 is 4 minutes less than the average of 5; 4 minutes is equal to two standard deviations.
      Binh's wait time of 1 minute is 4 minutes less than the average of 5 minutes.
      Binh's wait time of 1 minute is two standard deviations below the average of 5 minutes.
      A data value that is two standard deviations from the average is just on the borderline for what many
      statisticians would consider to be far from the average. Considering data to be far from the mean if it is more
      than 2 standard deviations away is more of an approximate "rule of thumb" than a rigid rule. In general, the
      shape of the distribution of the data affects how much of the data is further away than 2 standard deviations.
      (We will learn more about this in later chapters.)

The number line may help you understand standard deviation. If we were to put 5 and 7 on a number line, 7 is to
the right of 5. We say, then, that 7 is one standard deviation to the right of 5 because
5 + (1)(2) = 7.

If 1 were also part of the data set, then 1 is two standard deviations to the left of 5 because
5 + (-2)(2) = 1.
      In general, a value = mean + (#ofSTDEV)(standard deviation)
      where #ofSTDEVs = the number of standard deviations
      7 is one standard deviation more than the mean of 5 because: 7=5+(1)(2)
      1 is two standard deviations less than the mean of 5 because: 1=5+(-2)(2)

The equation value = mean + (#ofSTDEVs)(standard deviation) can be expressed for a sample and for a
population:

      sample: x = x + (#of STDEV)(s)
      Population: x =  + (#ofSTDEV)()

The lower case letter s represents the sample standard deviation and the Greek letter  (sigma, lower case)
represents the population standard deviation.

The symbol x is the sample mean and the Greek symbol  is the population mean.

Calculating the Standard Deviation
If x is a number, then the difference "x - mean" is called its deviation. In a data set, there are as many deviations
as there are items in the data set. The deviations are used to calculate the standard deviation. If the numbers belong
to a population, in symbols a deviation is x -  . For sample data, in symbols a deviation is x- x .

The procedure to calculate the standard deviation depends on whether the numbers are the entire population or are
data from a sample. The calculations are similar, but not identical. Therefore the symbol used to represent the
standard deviation depends on whether it is calculated from a population or a sample. The lower case letter s
represents the sample standard deviation and the Greek letter  (sigma, lower case) represents the population
standard deviation. If the sample has the same characteristics as the population, then s should be a good estimate
of .

To calculate the standard deviation, we need to calculate the variance first. The variance is an average of the

squares  of  the  deviations                                           (the  x-  x  values                                                                        for  a  sample,  or  the  x  -    values  for  a  population).  The  symbol       2

                                                                                                                                                                                                                                               

represents the population variance; the population standard deviation  is the square root of the population

variance. The symbol s2 represents the sample variance; the sample standard deviation s is the square root of the

sample variance. You can think of the standard deviation as a special average of the deviations.

If the numbers come from a census of the entire population and not a sample, when we calculate the average of
the squared deviations to find the variance, we divide by N, the number of items in the population. If the data are
from a sample rather than a population, when we calculate the average of the squared deviations, we divide by n-
1, one less than the number of items in the sample. You can see that in the formulas below.

Formulas for the Sample Standard Deviation

                                                                  2                                                                                          2

                         (x-x)                                         or f(x-x)

s =                                                                          s =

                               n-1                                                                                n-1

For the sample standard deviation, the denominator is n-1, that is the sample size MINUS 1.

Formulas for the Population Standard Deviation

                                                                    2                                                                                          2

                          (x-)                                         or f(x-)

 =                                                                            =

                                   N                                                                                  N

For the population standard deviation, the denominator is N, the number of items in the population.
In these formulas, f represents the frequency with which a value appears. For example, if a value appears once, f
is 1. If a value appears three times in the data set or population, f is 3.

Sampling Variability of a Statistic

The statistic of a sampling distribution was discussed in Descriptive Statistics: Measuring the Center of the

Data. How much the statistic varies from one sample to another is known as the sampling variability of a

statistic. You typically measure the sampling variability of a statistic by its standard error. The standard error of

the mean is an example of a standard error. It is a special standard deviation and is known as the standard

deviation of the sampling distribution of the mean. You will cover the standard error of the mean in The Central

Limit Theorem (not now). The notation for the standard error of the mean is        where  is the standard
                                                                             n

deviation of the population and n is the size of the sample.

Note: In practice, USE A CALCULATOR OR COMPUTER SOFTWARE TO CALCULATE THE
STANDARD DEVIATION. If you are using a TI-83,83+,84+ calculator, you need to select the appropriate
standard deviation x or sx from the summary statistics. We will concentrate on using and interpreting the
information that the standard deviation gives us. However you should study the following step-by-step example to
help you understand how the standard deviation measures variation from the mean.

Example:
In a fifth grade class, the teacher was interested in the average age and the sample standard deviation of the ages
of her students. The following data are the ages for a SAMPLE of n = 20 fifth grade students. The ages are
rounded to the nearest half year:
9 9.5 9.5 10 10 10 10 10.5 10.5 10.5 10.5 11 11 11 11 11 11 11.5 11.5 11.5
Equation:

             x=  9 + 9.5  2 + 10  4 + 10.5  4 + 11  6 + 11.5  3                = 10.525
                                                                                20

The average age is 10.53 years, rounded to 2 places.
The variance may be calculated by using a table. Then the standard deviation is calculated by taking the square
root of the variance. We will explain the parts of the table after calculating s.

Data  Freq.      Deviations                                                     2   (Freq.)(Deviations 2 )

x     f          (x - x)                 Deviations                                                                       2
9     1          9 - 10.525 = -1.525
9.5   2          9.5 - 10.525 = -1.025                              2               (f )(x - x)
10    4          10 - 10.525 = -0.525                                               1  2.325625 = 2.325625
10.5  4          10.5 - 10.525 = -0.025  (x - x)                                    2  1.050625 = 2.101250
11    6          11 - 10.525 = 0.475                                                4  .275625 = 1.1025
                                                                          2         4  .000625 = .0025
                                                                                    6  .225625 = 1.35375
                                         (-1.525) = 2.325625

                                                                          2

                                         (-1.025) = 1.050625

                                                                          2

                                         (-0.525) = 0.275625

                                                                          2

                                         (-0.025) = 0.000625

                                                                   2

                                         (0.475) = 0.225625
   Data     Freq.     Deviations                                                    2  (Freq.)(Deviations 2 )

   11.5     3         11.5 - 10.525 = 0.975  Deviations                                3  .950625 = 2.851875

                                                                       2

                                             (0.975) = 0.950625

The sample variance, s2, is equal to the sum of the last column (9.7375) divided by the total number of data

values minus one (20 - 1):

2   9.7375  = 0.5125
s=
    20-1

The sample standard deviation s is equal to the square root of the sample variance:

s = 0.5125 =. 0715891 Rounded to two decimal places, s = 0.72

Typically, you do the calculation for the standard deviation on your calculator or computer. The

intermediate results are not rounded. This is done for accuracy.

Exercise:

   Problem: Verify the mean and standard deviation calculated above on your calculator or computer.

   Solution:
   Using the TI-83,83+,84+ Calculators

         Enter data into the list editor. Press STAT 1:EDIT. If necessary, clear the lists by arrowing up into the
         name. Press CLEAR and arrow down.
         Put the data values (9, 9.5, 10, 10.5, 11, 11.5) into list L1 and the frequencies (1, 2, 4, 4, 6, 3) into list
         L2. Use the arrow keys to move around.
         Press STAT and arrow to CALC. Press 1:1-VarStats and enter L1 (2nd 1), L2 (2nd 2). Do not forget the
         comma. Press ENTER.
         x=10.525
         Use Sx because this is sample data (not a population): Sx=0.715891

      For the following problems, recall that value = mean + (#ofSTDEVs)(standard deviation)
      For a sample: x = x + (#ofSTDEVs)(s)
      For a population: x =  + (#ofSTDEVs)( )
      For this example, use x = x + (#ofSTDEVs)(s) because the data is from a sample
Exercise:

   Problem: Find the value that is 1 standard deviation above the mean. Find (x + 1s).
   Solution:

     (x + 1s) = 10.53 + (1)(0.72) = 11.25

Exercise:

   Problem: Find the value that is two standard deviations below the mean. Find (x - 2s).
   Solution:

     (x - 2s) = 10.53 - (2)(0.72) = 9.09

Exercise:

   Problem: Find the values that are 1.5 standard deviations from (below and above) the mean.
   Solution:
                  (x - 1.5s) = 10.53 - (1.5)(0.72) = 9.45
                  (x + 1.5s) = 10.53 + (1.5)(0.72) = 11.61

Explanation of the standard deviation calculation shown in the table
The deviations show how spread out the data are about the mean. The data value 11.5 is farther from the mean than
is the data value 11. The deviations 0.97 and 0.47 indicate that. A positive deviation occurs when the data value is
greater than the mean. A negative deviation occurs when the data value is less than the mean; the deviation is
-1.525 for the data value 9. If you add the deviations, the sum is always zero. (For this example, there are n=20
deviations.) So you cannot simply add the deviations to get the spread of the data. By squaring the deviations, you
make them positive numbers, and the sum will also be positive. The variance, then, is the average squared
deviation.

The variance is a squared measure and does not have the same units as the data. Taking the square root solves the
problem. The standard deviation measures the spread in the same units as the data.

Notice that instead of dividing by n=20, the calculation divided by n-1=20-1=19 because the data is a sample. For
the sample variance, we divide by the sample size minus one (n-1). Why not divide by n? The answer has to do
with the population variance. The sample variance is an estimate of the population variance. Based on the
theoretical mathematics that lies behind these calculations, dividing by (n-1) gives a better estimate of the
population variance.

Note:Your concentration should be on what the standard deviation tells us about the data. The standard deviation
is a number which measures how far the data are spread from the mean. Let a calculator or computer do the
arithmetic.

The standard deviation, s or , is either zero or larger than zero. When the standard deviation is 0, there is no
spread; that is, the all the data values are equal to each other. The standard deviation is small when the data are all
concentrated close to the mean, and is larger when the data values show more variation from the mean. When the
standard deviation is a lot larger than zero, the data values are very spread out about the mean; outliers can make s
or  very large.

The standard deviation, when first presented, can seem unclear. By graphing your data, you can get a better "feel"
for the deviations and the standard deviation. You will find that in symmetrical distributions, the standard deviation
can be very helpful but in skewed distributions, the standard deviation may not be much help. The reason is that
the two sides of a skewed distribution have different spreads. In a skewed distribution, it is better to look at the
first quartile, the median, the third quartile, the smallest value, and the largest value. Because numbers can be
confusing, always graph your data.

Note:The formula for the standard deviation is at the end of the chapter.

Example:
Exercise:

   Problem:Use the following data (first exam scores) from Susan Dean's spring pre-calculus class:

   3342494953555561 6367686869697273 7478808388888890 929494949496100
      aCreate a chart containing the data, frequencies, relative frequencies, and cumulative relative
      frequencies to three decimal places.
      bCalculate the following to one decimal place using a TI-83+ or TI-84 calculator:

            iThe sample mean
            iiThe sample standard deviation
            iiiThe median
            ivThe first quartile
            vThe third quartile
            viIQR

      cConstruct a box plot and a histogram on the same set of axes. Make comments about the box plot, the
      histogram, and the chart.

Solution:

      a

Data  Frequency  Relative Frequency  Cumulative Relative Frequency
33    1          0.032               0.032
42    1          0.032               0.064
49    2          0.065               0.129
53    1          0.032               0.161
55    2          0.065               0.226
61    1          0.032               0.258
63    1          0.032               0.29
67    1          0.032               0.322
68    2          0.065               0.387
69    2          0.065               0.452
72    1          0.032               0.484
73    1          0.032               0.516
74    1          0.032               0.548
78    1          0.032               0.580
80    1          0.032               0.612
Data  Frequency  Relative Frequency  Cumulative Relative Frequency
83    1          0.032               0.644
88    3          0.097               0.741
90    1          0.032               0.773
92    1          0.032               0.805
94    4          0.129               0.934
96    1          0.032               0.966
100   1          0.032               0.998 (Why isn't this value 1?)

b

      iThe sample mean = 73.5
      iiThe sample standard deviation = 17.9
      iiiThe median = 73
      ivThe first quartile = 61
      vThe third quartile = 90
      viIQR = 90 - 61 = 29

cThe x-axis goes from 32.5 to 100.5; y-axis goes from -2.4 to 15 for the histogram; number of intervals
is 5 for the histogram so the width of an interval is (100.5 - 32.5) divided by 5 which is equal to 13.6.
Endpoints of the intervals: starting point is 32.5, 32.5+13.6 = 46.1, 46.1+13.6 = 59.7, 59.7+13.6 = 73.3,
73.3+13.6 = 86.9, 86.9+13.6 = 100.5 = the ending value; No data values fall on an interval boundary.

The long left whisker in the box plot is reflected in the left side of the histogram. The spread of the exam scores in
the lower 50% is greater (73 - 33 = 40) than the spread in the upper 50% (100 - 73 = 27). The histogram, box plot,
and chart all reflect this. There are a substantial number of A and B grades (80s, 90s, and 100). The histogram
clearly shows this. The box plot shows us that the middle 50% of the exam scores (IQR = 29) are Ds, Cs, and Bs.
The box plot also shows us that the lower 25% of the exam scores are Ds and Fs.

Comparing Values from Different Data Sets
The standard deviation is useful when comparing data values that come from different data sets. If the data sets
have different means and standard deviations, it can be misleading to compare the data values directly.
For each data value, calculate how many standard deviations the value is away from its mean.

Use the formula: value = mean + (#ofSTDEVs)(standard deviation); solve for #ofSTDEVs.

#of STDEVs =          value-mean
              standard deviation

Compare the results of this calculation.

#ofSTDEVs is often called a "z-score"; we can use the symbol z. In symbols, the formulas become:

Sample                            x = x + z s                                                                             z=  x-x
Population                        x =  + z                                                                                        s

                                                                                                                          z=  x-
                                                                                                                                  

Example:
Exercise:

   Problem:

   Two students, John and Ali, from different high schools, wanted to find out who had the highest G.P.A. when
   compared to his school. Which student had the highest G.P.A. when compared to his school?

Student       GPA                 School Mean GPA                                                                         School Standard Deviation
John          2.85                3.0                                                                                     0.7
Ali           77                  80                                                                                      10

Solution:

For each student, determine how many standard deviations (#ofSTDEVs) his GPA is away from the average,
for his school. Pay careful attention to signs when comparing and interpreting the answer.

#of STDEVs =          value-mean  ;z=  x-
              standard deviation           

For John, z = #of STDEVs = 2.85-3.0 = -0.21
                                                                                                                     0.7

For Ali, z = #of STDEVs = 77-80 = -0.3
                                                                                                             10

John has the better G.P.A. when compared to his school because his G.P.A. is 0.21 standard deviations below
his school's mean while Ali's G.P.A. is 0.3 standard deviations below his school's mean.

John's z-score of -0.21 is higher than Ali's z-score of -0.3 . For GPA, higher values are better, so we
conclude that John has the better GPA when compared to his school.
The following lists give a few facts that provide a little more insight into what the standard deviation tells us about
the distribution of the data.
For ANY data set, no matter what the distribution of the data is:

      At least 75% of the data is within 2 standard deviations of the mean.
      At least 89% of the data is within 3 standard deviations of the mean.
      At least 95% of the data is within 4 1/2 standard deviations of the mean.
      This is known as Chebyshev's Rule.

For data having a distribution that is MOUND-SHAPED and SYMMETRIC:

      Approximately 68% of the data is within 1 standard deviation of the mean.
      Approximately 95% of the data is within 2 standard deviations of the mean.
      More than 99% of the data is within 3 standard deviations of the mean.
      This is known as the Empirical Rule.
      It is important to note that this rule only applies when the shape of the distribution of the data is mound-
      shaped and symmetric. We will learn more about this when studying the "Normal" or "Gaussian" probability
      distribution in later chapters.

**With contributions from Roberta Bloom

Glossary

Standard Deviation
      A number that is equal to the square root of the variance and measures how far data values are from their
      mean. Notation: s for sample standard deviation and  for population standard deviation.

Variance
      Mean of the squared deviations from the mean. Square of the standard deviation. For a set of data, a deviation
      can be represented as x - x where x is a value of the data and x is the sample mean. The sample variance is
      equal to the sum of the squares of the deviations divided by the difference of the sample size and 1.
Summary of Formulas
A summary of useful formulas used in examining descriptive statistics
Commonly Used Symbols

      The symbol  means to add or to find the sum.
      n = the number of data values in a sample
      N = the number of people, things, etc. in the population
      x = the sample mean
      s = the sample standard deviation
       = the population mean
       = the population standard deviation
      f = frequency
      x = numerical value

Commonly Used Expressions

      x*f = A value multiplied by its respective frequency
       x = The sum of the values
       x*f = The sum of values multiplied by their respective frequencies
      (x - x) or (x - ) = Deviations from the mean (how far a value is
      from the mean)
      (x - x)2 or (x - )2 = Deviations squared
      f(x - x)2 or f(x - )2 = The deviations squared and multiplied by
      their frequencies

Mean Formulas:

               x                               f x

x=                    or x =
                                                    n
                   n                         f x

                x     or =
                                                  N
=

                  N

Standard Deviation Formulas:

                                                                  2                                                                                          2

                         (x-x)                                         or f(x-x)

s =                                                                          s =

                               n-1                                                                                n-1

                                                                    2                                                                                          2

                          (x-)                                         or f(x-)

 =                                                                            =

                                   N                                                                                  N
Formulas Relating a Value, the Mean, and the Standard Deviation:

      value = mean + (#ofSTDEVs)(standard deviation), where #ofSTDEVs
      = the number of standard deviations
      x = x+ (#ofSTDEVs)(s)
      x =  + (#ofSTDEVs)()
Probability Topics
This module introduces the concept of Probability, the chance of an event
occurring.

Student Learning Outcomes

By the end of this chapter, the student should be able to:

      Understand and use the terminology of probability.
      Determine whether two events are mutually exclusive and whether two
      events are independent.
      Calculate probabilities using the Addition Rules and Multiplication
      Rules.
      Construct and interpret Contingency Tables.
      Construct and interpret Venn Diagrams (optional).
      Construct and interpret Tree Diagrams (optional).

Introduction

It is often necessary to "guess" about the outcome of an event in order to
make a decision. Politicians study polls to guess their likelihood of winning
an election. Teachers choose a particular course of study based on what they
think students can comprehend. Doctors choose the treatments needed for
various diseases based on their assessment of likely results. You may have
visited a casino where people play games chosen because of the belief that
the likelihood of winning is good. You may have chosen your course of
study based on the probable availability of jobs.

You have, more than likely, used probability. In fact, you probably have an
intuitive sense of probability. Probability deals with the chance of an event
occurring. Whenever you weigh the odds of whether or not to do your
homework or to study for an exam, you are using probability. In this
chapter, you will learn to solve probability problems using a systematic
approach.

Optional Collaborative Classroom Exercise
Your instructor will survey your class. Count the number of students in the
class today.

      Raise your hand if you have any change in your pocket or purse.
      Record the number of raised hands.
      Raise your hand if you rode a bus within the past month. Record the
      number of raised hands.
      Raise your hand if you answered "yes" to BOTH of the first two
      questions. Record the number of raised hands.

Use the class data as estimates of the following probabilities. P(change)
means the probability that a randomly chosen person in your class has
change in his/her pocket or purse. P(bus) means the probability that a
randomly chosen person in your class rode a bus within the last month and
so on. Discuss your answers.

      Find P(change).
      Find P(bus).
      Find P(change and bus) Find the probability that a randomly chosen
      student in your class has change in his/her pocket or purse and rode a
      bus within the last month.
      Find P(change| bus) Find the probability that a randomly chosen
      student has change given that he/she rode a bus within the last month.
      Count all the students that rode a bus. From the group of students who
      rode a bus, count those who have change. The probability is equal to
      those who have change and rode a bus divided by those who rode a
      bus.
Terminology
Probability: Terminology is part of the collection col10555 written by
Barbara Illowsky and Susan Dean defines key terms related to Probability
and has contributions from Roberta Bloom.

Probability is a measure that is associated with how certain we are of
outcomes of a particular experiment or activity. An experiment is a
planned operation carried out under controlled conditions. If the result is
not predetermined, then the experiment is said to be a chance experiment.
Flipping one fair coin twice is an example of an experiment.

The result of an experiment is called an outcome. A sample space is a set
of all possible outcomes. Three ways to represent a sample space are to list
the possible outcomes, to create a tree diagram, or to create a Venn diagram.
The uppercase letter S is used to denote the sample space. For example, if
you flip one fair coin, S = {H, T} where H = heads and T = tails are the
outcomes.

An event is any combination of outcomes. Upper case letters like A and B
represent events. For example, if the experiment is to flip one fair coin,
event A might be getting at most one head. The probability of an event A is
written P(A).

The probability of any outcome is the long-term relative frequency of
that outcome. Probabilities are between 0 and 1, inclusive (includes 0 and
1 and all numbers between these values). P(A) = 0 means the event A can
never happen. P(A) = 1 means the event A always happens. P(A) = 0.5
means the event A is equally likely to occur or not to occur. For example, if
you flip one fair coin repeatedly (from 20 to 2,000 to 20,000 times) the
relative fequency of heads approaches 0.5 (the probability of heads).

Equally likely means that each outcome of an experiment occurs with
equal probability. For example, if you toss a fair, six-sided die, each face
(1, 2, 3, 4, 5, or 6) is as likely to occur as any other face. If you toss a fair
coin, a Head(H) and a Tail(T) are equally likely to occur. If you randomly
guess the answer to a true/false question on an exam, you are equally likely
to select a correct answer or an incorrect answer.
To calculate the probability of an event A when all outcomes in the
sample space are equally likely, count the number of outcomes for event
A and divide by the total number of outcomes in the sample space. For
example, if you toss a fair dime and a fair nickel, the sample space is
{HH, TH, HT, TT} where T = tails and H = heads. The sample space
has four outcomes. A = getting one head. There are two outcomes
{HT, TH}. P(A) = 2 .

                                                                        4

Suppose you roll one fair six-sided die, with the numbers {1,2,3,4,5,6} on

its faces. Let event E = rolling a number that is at least 5. There are two

outcomes  {5,  6}.  P(E)  =  2  .  If  you  were  to  roll  the  die  only  a  few  times,
                             6

you would not be surprised if your observed results did not match the

probability. If you were to roll the die a very large number of times, you

would expect that, overall, 2/6 of the rolls would result in an outcome of "at

least 5". You would not expect exactly 2/6. The long-term relative

frequency of obtaining this result would approach the theoretical probability

of 2/6 as the number of repetitions grows larger and larger.

This important characteristic of probability experiments is the known as the
Law of Large Numbers: as the number of repetitions of an experiment is
increased, the relative frequency obtained in the experiment tends to
become closer and closer to the theoretical probability. Even though the
outcomes don't happen according to any set pattern or order, overall, the
long-term observed relative frequency will approach the theoretical
probability. (The word empirical is often used instead of the word
observed.) The Law of Large Numbers will be discussed again in Chapter 7.

It is important to realize that in many situations, the outcomes are not
equally likely. A coin or die may be unfair, or biased . Two math
professors in Europe had their statistics students test the Belgian 1 Euro
coin and discovered that in 250 trials, a head was obtained 56% of the time
and a tail was obtained 44% of the time. The data seem to show that the
coin is not a fair coin; more repetitions would be helpful to draw a more
accurate conclusion about such bias. Some dice may be biased. Look at the
dice in a game you have at home; the spots on each face are usually small
holes carved out and then painted to make the spots visible. Your dice may
or may not be biased; it is possible that the outcomes may be affected by the
slight weight differences due to the different numbers of holes in the faces.
Gambling casinos have a lot of money depending on outcomes from rolling
dice, so casino dice are made differently to eliminate bias. Casino dice have
flat faces; the holes are completely filled with paint having the same density
as the material that the dice are made out of so that each face is equally
likely to occur. Later in this chapter we will learn techniques to use to work
with probabilities for events that are not equally likely.

"OR" Event:
An outcome is in the event A OR B if the outcome is in A or is in B or is
in both A and B. For example, let A = {1, 2, 3, 4, 5} and
B = {4, 5, 6, 7, 8}. A OR B = {1, 2, 3, 4, 5, 6, 7, 8}. Notice that 4
and 5 are NOT listed twice.

"AND" Event:
An outcome is in the event A AND B if the outcome is in both A and B at
the same time. For example, let A and B be {1, 2, 3, 4, 5} and
{4, 5, 6, 7, 8}, respectively. Then A AND B = {4, 5}.

The complement of event A is denoted A' (read "A prime"). A' consists of

all outcomes that are NOT in A. Notice that P(A) + P(A') = 1. For

example, let S = {1, 2, 3, 4, 5, 6} and let A = {1, 2, 3, 4}. Then,

                         4     2  4  2
A' = {5, 6}. P(A) = , P(A') = , and P(A) + P(A') = + = 1

                         6     6  6  6

The conditional probability of A given B is written P(A|B). P(A|B) is
the probability that event A will occur given that the event B has already
occurred. A conditional reduces the sample space. We calculate the
probability of A from the reduced sample space B. The formula to calculate
P(A|B) is

P(A|B)=  P(A AND B)
                   P(B)

where P(B) is greater than 0.

For example, suppose we toss one fair, six-sided die. The sample space
S = {1, 2, 3, 4, 5, 6}. Let A = face is 2 or 3 and B = face is even (2, 4, 6).
To calculate P(A|B), we count the number of outcomes 2 or 3 in the
sample space B = {2, 4, 6}. Then we divide that by the number of
outcomes in B (and not S).

We get the same result by using the formula. Remember that S has 6
outcomes.

P(A|B) =

P(A and B)     (the number of outcomes that are 2 or 3 and even in S) / 6     1/6     1

            =                                                              =       =

P(B)           (the number of outcomes that are even in S) / 6                3/6     3

Understanding Terminology and Symbols
It is important to read each problem carefully to think about and understand
what the events are. Understanding the wording is the first very important
step in solving probability problems. Reread the problem several times if
necessary. Clearly identify the event of interest. Determine whether there is
a condition stated in the wording that would indicate that the probability is
conditional; carefully identify the condition, if any.
Exercise:

   Problem:

   In a particular college class, there are male and female students. Some
   students have long hair and some students have short hair. Write the
   symbols for the probabilities of the events for parts (a) through (j)
   below. (Note that you can't find numerical answers here. You were not
   given enough information to find any probability values yet;
   concentrate on understanding the symbols.)

         Let F be the event that a student is female.
         Let M be the event that a student is male.
         Let S be the event that a student has short hair.
         Let L be the event that a student has long hair.

         a The probability that a student does not have long hair.
         b The probability that a student is male or has short hair.
         c The probability that a student is a female and has long hair.
         d The probability that a student is male, given that the student has
         long hair.
         e The probability that a student has long hair, given that the
         student is male.
         f Of all the female students, the probability that a student has
         short hair.
         g Of all students with long hair, the probability that a student is
         female.
         h The probability that a student is female or has long hair.
         i The probability that a randomly selected student is a male
         student with short hair.
         j The probability that a student is female.

   Solution:

         a P(L')=P(S)
         b P(M or S)
         c P(F and L)
         d P(M|L)
         e P(L|M)
         f P(S|F)
         g P(F|L)
         h P(F or L)
         i P(M and S)
         j P(F)

**With contributions from Roberta Bloom

Glossary

Conditional Probability
      The likelihood that an event will occur given that another event has
      already occurred.

Equally Likely
      Each outcome of an experiment has the same probability.
Experiment
      A planned activity carried out under controlled conditions.

Event
      A subset in the set of all outcomes of an experiment. The set of all
      outcomes of an experiment is called a sample space and denoted
      usually by S. An event is any arbitrary subset in S. It can contain one
      outcome, two outcomes, no outcomes (empty subset), the entire
      sample space, etc. Standard notations for events are capital letters such
      as A, B, C, etc.

Outcome (observation)
      A particular result of an experiment.

Probability
      A number between 0 and 1, inclusive, that gives the likelihood that a
      specific event will occur. The foundation of statistics is given by the
      following 3 axioms (by A. N. Kolmogorov, 1930's): Let S denote the
      sample space and A and B are two events in S . Then:

            0  P (A)  1;.
            If A and B are any two mutually exclusive events, then
            P (A or B) = P (A) + P (B).
            P (S) = 1.

Sample Space
      The set of all possible outcomes of an experiment.
Independent and Mutually Exclusive Events
Probability: Independent and Mutually Exclusive Events is part of the
collection col10555 written by Barbara Illowsky and Susan Dean and
explains the concept of independent events, where the probability of event
A does not have any effect on the probability of event B, and mutually
exclusive events, where events A and B cannot occur at the same time. The
module has contributions from Roberta Bloom.

Independent and mutually exclusive do not mean the same thing.

Independent Events

Two events are independent if the following are true:

           P(A|B) = P(A)
           P(B|A) = P(B)
           P(A AND B) = P(A)  P(B)

Two events A and B are independent if the knowledge that one occurred
does not affect the chance the other occurs. For example, the outcomes of
two roles of a fair die are independent events. The outcome of the first roll
does not change the probability for the outcome of the second roll. To show
two events are independent, you must show only one of the above
conditions. If two events are NOT independent, then we say that they are
dependent.

Sampling may be done with replacement or without replacement.

      With replacement: If each member of a population is replaced after it
      is picked, then that member has the possibility of being chosen more
      than once. When sampling is done with replacement, then events are
      considered to be independent, meaning the result of the first pick will
      not change the probabilities for the second pick.
      Without replacement:: When sampling is done without replacement,
      then each member of a population may be chosen only once. In this
      case, the probabilities for the second pick are affected by the result of
      the first pick. The events are considered to be dependent or not
      independent.

If it is not known whether A and B are independent or dependent, assume
they are dependent until you can show otherwise.

Mutually Exclusive Events

A and B are mutually exclusive events if they cannot occur at the same
time. This means that A and B do not share any outcomes and
P(A AND B) = 0.

For example, suppose the sample space S = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}.
Let A = {1, 2, 3, 4, 5}, B = {4, 5, 6, 7, 8}, and C = {7, 9}.
A AND B = {4, 5}. P(A AND B) = 10 2 and is not equal to zero.
Therefore, A and B are not mutually exclusive. A and C do not have any
numbers in common so P(A AND C) = 0. Therefore, A and C are
mutually exclusive.

If it is not known whether A and B are mutually exclusive, assume they
are not until you can show otherwise.

The following examples illustrate these definitions and terms.

Example:
Flip two fair coins. (This is an experiment.)
The sample space is {HH, HT, TH, TT} where T = tails and H = heads.
The outcomes are HH, HT, TH, and TT. The outcomes HT and TH are
different. The HT means that the first coin showed heads and the second
coin showed tails. The TH means that the first coin showed tails and the
second coin showed heads.

      Let A = the event of getting at most one tail. (At most one tail means
      0 or 1 tail.) Then A can be written as {HH, HT, TH}. The outcome
      HH shows 0 tails. HT and TH each show 1 tail.
      Let B = the event of getting all tails. B can be written as {TT}. B is
      the complement of A. So, B = A'. Also,
      P(A) + P(B) = P(A) + P(A') = 1.
      The probabilities for A and for B are P(A) = 43 and P(B) = 41 .
      Let C = the event of getting all heads. C = {HH}. Since B = {TT},
      P(B AND C) = 0. B and C are mutually exclusive. (B and C have
      no members in common because you cannot have all tails and all
      heads at the same time.)
      Let D = event of getting more than one tail. D = {TT}. P(D) = 41
      .
      Let E = event of getting a head on the first roll. (This implies you can
      get either a head or tail on the second roll.) E = {HT, HH}.
      P(E) = 2 .

                                                4

      Find the probability of getting at least one (1 or 2) tail in two flips.
      Let F = event of getting at least one tail in two flips.
      F = {HT, TH, TT}. P(F) = 3

                                                                                                                           4

Example:
Roll one fair 6-sided die. The sample space is {1, 2, 3, 4, 5, 6}. Let event
A = a face is odd. Then A = {1, 3, 5}. Let event B = a face is even. Then
B = {2, 4, 6}.

      Find the complement of A, A'. The complement of A, A', is B
      because A and B together make up the sample space.
      P(A) + P(B) = P(A) + P(A') = 1. Also, P(A) = 3 and

                                                                                                                                                                                                      6
                                                3

           P(B) =

                                                6

      Let event C = odd faces larger than 2. Then C = {3, 5}. Let event D
      = all even faces smaller than 5. Then D = {2, 4}. P(C and D) = 0
      because you cannot have an odd and even face at the same time.
      Therefore, C and D are mutually exclusive events.
      Let event E = all faces less than 5. E = {1, 2, 3, 4}.
      Exercise:
         Problem:

         Are C and E mutually exclusive events? (Answer yes or no.)
         Why or why not?

         Solution:

         No. C = {3, 5} and E = {1, 2, 3, 4}. P(C AND E) = 1 . To be
                                                                                                                                                                                                                    6

         mutually exclusive, P(C AND E) must be 0.
      Find P(C|A). This is a conditional. Recall that the event C is {3, 5}
      and event A is {1, 3, 5}. To find P(C|A), find the probability of C
      using the sample space A. You have reduced the sample space from
      the original sample space {1, 2, 3, 4, 5, 6} to {1, 3, 5}. So,

                                                         2

           P(C|A) =

                                                         3

Example:
Let event G = taking a math class. Let event H = taking a science class.
Then, G AND H = taking a math class and a science class. Suppose
P(G) = 0.6, P(H) = 0.5, and P(G AND H) = 0.3. Are G and H
independent?
If G and H are independent, then you must show ONE of the following:

           P(G|H) = P(G)
           P(H|G) = P(H)
           P(G AND H) = P(G)  P(H)

Note:The choice you make depends on the information you have. You
could choose any of the methods here because you have the necessary
information.
Exercise:

Problem: Show that P(G|H) = P(G).

Solution:

           P(G AND H)     0.3

P(G|H) =               =  0.5  = 0.6 = P(G)

           P(H)

Exercise:

   Problem: Show P(G AND H) = P(G)  P(H).

   Solution:

     P(G)  P(H) = 0.6  0.5 = 0.3 = P(G AND H)

Since G and H are independent, then, knowing that a person is taking a
science class does not change the chance that he/she is taking math. If the
two events had not been independent (that is, they are dependent) then
knowing that a person is taking a science class would change the chance
he/she is taking math. For practice, show that P(H|G) = P(H) to show
that G and H are independent events.

Example:
In a box there are 3 red cards and 5 blue cards. The red cards are marked
with the numbers 1, 2, and 3, and the blue cards are marked with the
numbers 1, 2, 3, 4, and 5. The cards are well-shuffled. You reach into the
box (you cannot see into it) and draw one card.
Let R = red card is drawn, B = blue card is drawn, E = even-numbered
card is drawn.
The sample space S = R1, R2, R3, B1, B2, B3, B4, B5. S has 8
outcomes.

      P(R) = 8 3 . P(B) = 8 5 . P(R AND B) = 0. (You cannot draw one
      card that is both red and blue.)
P(E) =  3  .  (There   are  3  even-numbered      cards,    R2,   B2,  and  B4.)
        8

P(E|B) =      2  .  (There  are  5  blue  cards:  B1,  B2,  B3,   B4,  and  B5.  Out
              5

of the blue cards, there are 2 even cards: B2 and B4.)

P(B|E) =      2  .  (There  are  3  even-numbered      cards:  R2,  B2,    and  B4.
              3

Out of the even-numbered cards, 2 are blue: B2 and B4.)

The events R and B are mutually exclusive because

P(R AND B) = 0.

Let G = card with a number greater than 3. G = {B4, B5}.

P(G) =  2  .  Let   H  =  blue   card  numbered   between      1  and  4,  inclusive.
        8

H = {B1, B2, B3, B4}. P(G|H) = 41 . (The only card in H that has

a number greater than 3 is B4.) Since     2       =    1 , P(G) = P(G|H)
                                          8
                                                       4

which means that G and H are independent.

Example:
In a particular college class, 60% of the students are female. 50 % of all
students in the class have long hair. 45% of the students are female and
have long hair. Of the female students, 75% have long hair. Let F be the
event that the student is female. Let L be the event that the student has long
hair. One student is picked randomly. Are the events of being female and
having long hair independent?

      The following probabilities are given in this example:
      P(F ) = 0.60 ; P(L ) = 0.50

           P(F AND L) = 0.45
           P(L|F) = 0.75

Note:The choice you make depends on the information you have. You
could use the first or last condition on the list for this example. You do not
know P(F|L) yet, so you can not use the second condition.
Solution 1
Check whether P(F and L) = P(F)P(L): We are given that P(F and L) = 0.45
; but P(F)P(L) = (0.60)(0.50)= 0.30 The events of being female and having
long hair are not independent because P(F and L) does not equal P(F)P(L).
Solution 2
check whether P(L|F) equals P(L): We are given that P(L|F) = 0.75 but
P(L) = 0.50; they are not equal. The events of being female and having
long hair are not independent.
Interpretation of Results
The events of being female and having long hair are not independent;
knowing that a student is female changes the probability that a student has
long hair.

**Example 5 contributed by Roberta Bloom

Glossary

Independent Events
      The occurrence of one event has no effect on the probability of the
      occurrence of any other event. Events A and B are independent if one
      of the following is true: (1). P (A|B) = P (A); (2) P (B|A) = P (B);
      (3) P (A and B) = P (A)P (B).

Mutually Exclusive
      An observation cannot fall into more than one class (category). Being
      in more than one category prevents being in a mutually exclusive
      category.
Two Basic Rules of Probability
This module introduces the multiplication and addition rules used when calculating
probabilities.

The Multiplication Rule

If A and B are two events defined on a sample space, then:
P(A AND B) = P(B)  P(A|B).

                                                                                                                                                     P(A AND B)

This rule may also be written as : P(A|B)=
                                                                                                                                                                P(B)

(The probability of A given B equals the probability of A and B divided by the
probability of B.)

If A and B are independent, then P(A|B) = P(A). Then
P(A AND B) = P(A|B) P(B) becomes P(A AND B) = P(A) P(B).

The Addition Rule

If A and B are defined on a sample space, then:
P(A OR B) = P(A) + P(B) - P(A AND B).

If A and B are mutually exclusive, then P(A AND B) = 0. Then
P(A OR B) = P(A) + P(B) - P(A AND B) becomes
P(A OR B) = P(A) + P(B).

Example:
Klaus is trying to choose where to go on vacation. His two choices are: A = New
Zealand and B = Alaska

      Klaus can only afford one vacation. The probability that he chooses A is
      P(A) = 0.6 and the probability that he chooses B is P(B) = 0.35.
      P(A and B) = 0 because Klaus can only afford to take one vacation
      Therefore, the probability that he chooses either New Zealand or Alaska is
      P(A OR B) = P(A) + P(B) = 0.6 + 0.35 = 0.95. Note that the probability
      that he does not choose to go anywhere on vacation must be 0.05.

Example:
Carlos plays college soccer. He makes a goal 65% of the time he shoots. Carlos is going
to attempt two goals in a row in the next game.
A = the event Carlos is successful on his first attempt. P(A) = 0.65. B = the event
Carlos is successful on his second attempt. P(B) = 0.65. Carlos tends to shoot in
streaks. The probability that he makes the second goal GIVEN that he made the first
goal is 0.90.
Exercise:

   Problem: What is the probability that he makes both goals?

   Solution:

   The problem is asking you to find P(A AND B) = P(B AND A). Since
   P(B|A) = 0.90:
   Equation:

                                   P(B AND A) = P(B|A) P(A) = 0.90*0.65 = 0.585

   Carlos makes the first and second goals with probability 0.585.
Exercise:

   Problem:

   What is the probability that Carlos makes either the first goal or the second goal?

   Solution:

   The problem is asking you to find P(A OR B).
   Equation:

     P(A OR B) = P(A) + P(B) - P(A AND B) = 0.65 + 0.65 - 0.585 = 0.715

   Carlos makes either the first goal or the second goal with probability 0.715.
Exercise:

   Problem: Are A and B independent?

   Solution:

   No, they are not, because P(B AND A) = 0.585.
   Equation:
Equation:  P(B)  P(A) = (0.65)  (0.65) = 0.423
                       0.423  0.585 = P(B AND A)

   So, P(B AND A) is not equal to P(B)  P(A).
Exercise:

   Problem: Are A and B mutually exclusive?
   Solution:
   No, they are not because P(A and B) = 0.585.
   To be mutually exclusive, P(A AND B) must equal 0.

Example:
A community swim team has 150 members. Seventy-five of the members are advanced
swimmers. Forty-seven of the members are intermediate swimmers. The remainder are
novice swimmers. Forty of the advanced swimmers practice 4 times a week. Thirty of
the intermediate swimmers practice 4 times a week. Ten of the novice swimmers
practice 4 times a week. Suppose one member of the swim team is randomly chosen.
Answer the questions (Verify the answers):
Exercise:

   Problem: What is the probability that the member is a novice swimmer?

   Solution:

           28
          150

Exercise:

   Problem: What is the probability that the member practices 4 times a week?

   Solution:

           80
          150
Exercise:
   Problem:

   What is the probability that the member is an advanced swimmer and practices 4
   times a week?

   Solution:

           40
          150

Exercise:
   Problem:

   What is the probability that a member is an advanced swimmer and an
   intermediate swimmer? Are being an advanced swimmer and an intermediate
   swimmer mutually exclusive? Why or why not?

   Solution:

   P(advanced AND intermediate) = 0, so these are mutually exclusive events.
   A swimmer cannot be an advanced swimmer and an intermediate swimmer at the
   same time.
Exercise:
   Problem:

   Are being a novice swimmer and practicing 4 times a week independent events?
   Why or why not?

   Solution:

   No, these are not independent events.
   Equation:

                                   P(novice AND practices 4 times per week) = 0.0667

   Equation:

                                     P(novice)  P(practices 4 times per week) = 0.0996

   Equation:

                                                                                 0.0667  0.0996
Example:
Studies show that, if she lives to be 90, about 1 woman in 7 (approximately 14.3%) will
develop breast cancer. Suppose that of those women who develop breast cancer, a test is
negative 2% of the time. Also suppose that in the general population of women, the test
for breast cancer is negative about 85% of the time. Let B = woman develops breast
cancer and let N = tests negative. Suppose one woman is selected at random.
Exercise:

   Problem:

   What is the probability that the woman develops breast cancer? What is the
   probability that woman tests negative?

   Solution:

   P(B) = 0.143 ; P(N) = 0.85
Exercise:

   Problem:

   Given that the woman has breast cancer, what is the probability that she tests
   negative?

   Solution:

     P(N|B) = 0.02

Exercise:
   Problem:

   What is the probability that the woman has breast cancer AND tests negative?

   Solution:

     P(B AND N) = P(B)  P(N|B) = (0.143)  (0.02) = 0.0029

Exercise:
   Problem:

   What is the probability that the woman has breast cancer or tests negative?

   Solution:

     P(B OR N) = P(B) + P(N) - P(B AND N) = 0.143 + 0.85 - 0.0029 = 0.9901
Exercise:

   Problem: Are having breast cancer and testing negative independent events?

   Solution:
   No. P(N) = 0.85; P(N|B) = 0.02. So, P(N|B) does not equal P(N)
Exercise:

   Problem: Are having breast cancer and testing negative mutually exclusive?

   Solution:
   No. P(B AND N) = 0.0029. For B and N to be mutually exclusive,
   P(B AND N) must be 0.

Glossary

Independent Events
      The occurrence of one event has no effect on the probability of the occurrence of
      any other event. Events A and B are independent if one of the following is true: (1).
      P (A|B) = P (A); (2) P (B|A) = P (B); (3) P (A and B) = P (A)P (B).

Mutually Exclusive
      An observation cannot fall into more than one class (category). Being in more than
      one category prevents being in a mutually exclusive category.

Sample Space
      The set of all possible outcomes of an experiment.
Contingency Tables
This module introduces the contingency table as a way of determining conditional
probabilities.

A contingency table provides a way of portraying data that can facilitate calculating
probabilities. The table helps in determining conditional probabilities quite easily. The
table displays sample values in relation to two different variables that may be dependent
or contingent on one another. Later on, we will use contingency tables again, but in
another manner. Contingincy tables provide a way of portraying data that can facilitate
calculating probabilities.

Example:
Suppose a study of speeding violations and drivers who use car phones produced the
following fictional data:

Car phone   Speeding violation in         No speeding violation in  Total
user        the last year                 the last year             305

Not a car   25                            280
phone user
            45                            405                       450
Total
            70                            685                       755

The total number of people in the sample is 755. The row totals are 305 and 450. The
column totals are 70 and 685. Notice that 305 + 450 = 755 and 70 + 685 = 755.
Calculate the following probabilities using the table
Exercise:

Problem: P(person is a car phone user) =

Solution:

number of car phone users  305

total number in study      =

                                   755
Exercise:

Problem: P(person had no violation in the last year) =

Solution:

number that had no violation     685

     total number in study       =

                                         755

Exercise:

Problem:

P(person had no violation in the last year AND was a car phone user) =

   Solution:

          280
          755

Exercise:
   Problem:

P(person is a car phone user OR person had no violation in the last year) =

Solution:

   305  +  685  )-  280  =  710

(  755     755      755     755

Exercise:

Problem:

P(person is a car phone user GIVEN person had a violation in the last year) =

Solution:

25   (The sample space is reduced to the number of persons who had a violation.)
70

Exercise:

Problem:

P(person had no violation last year GIVEN person was not a car phone user) =

Solution:

405     (The sample space is reduced to the number of persons who were not car phone
450

users.)
Example:
The following table shows a random sample of 100 hikers and the areas of hiking
preferred:

           The          Near Lakes and        On Mountain
                        Streams               Peaks
Sex        Coastline                                       Total
                        16                    ___          45
Female 18                                                  55
                        ___                   14           ___
Male       ___
                        41                    ___
Total      ___

Hiking Area Preference

Exercise:

Problem: Complete the table.
Solution:

           The                Near Lakes and  On Mountain
                              Streams         Peaks
Sex        Coastline                                       Total
                              16              11           45
Female 18                                                  55
                              25              14           100
Male       16
                              41              25
Total      34

Hiking Area Preference
Exercise:
   Problem:

Are the events "being female" and "preferring the coastline" independent events?

Let F = being female and let C = preferring the coastline.

aP(F AND C) =
bP(F)  P(C) =

Are these two numbers the same? If they are, then F and C are independent. If they
are not, then F and C are not independent.

Solution:

a P(F AND C) = = 0.18 18
                                                                   100

b 45                  34

P(F)  P(C) =   100    100  = 0.45  0.34 = 0.153

   P(F AND C)  P(F)  P(C), so the events F and C are not independent.
Exercise:

   Problem:

Find the probability that a person is male given that the person prefers hiking near
lakes and streams. Let M = being male and let L = prefers hiking near lakes and
streams.

aWhat word tells you this is a conditional?
bFill in the blanks and calculate the probability: P(___|___) = ___.
cIs the sample space for this problem all 100 hikers? If not, what is it?

   Solution:

         aThe word 'given' tells you that this is a conditional.
         bP(M|L) = 25

                                                                      41

         cNo, the sample space for this problem is 41.

Exercise:
    Problem:

    Find the probability that a person is female or prefers hiking on mountain peaks.
    Let F = being female and let P = prefers mountain peaks.

          aP(F) =
          bP(P) =
          cP(F AND P) =
          dTherefore, P(F OR P) =

    Solution:

              a 45

                P(F) =

                                                 100

              b 25

                 P(P) =

                                                  100

              cP(F AND P) = 11
                                                                              100

              d 45                                                                 25     -     11  =  59
              P(F OR P) =                                       +
                                                           100                     100       100       100

Example:

Muddy Mouse lives in a cage with 3 doors. If Muddy goes out the first door, the

probability that he gets caught by Alissa the cat is                                                        1  and the probability he is not caught
                                                                                                            5

is  4  .  If  he  goes  out  the                       second                      door,   the  probability    he  gets  caught  by  Alissa  is  1  and
    5                                                                                                                                            4

the probability he is not caught is                                                3    .  The  probability    that  Alissa  catches  Muddy      coming
                                                                                   4

out of the third door is                               1   and the probability she does not catch Muddy is                            21 . It is
                                                       2

equally likely that Muddy will choose any of the three doors so the probability of

choosing each door is                                  1.

                                                       3

    Caught or Not                                          Door One                                 Door Two             Door Three              Total
    Caught                                                                                                                                       ____
    Not Caught                                                1                                        1                   1                     ____
                                                            15                                       12                    6

                                                              4                                        3                   1
                                                            15                                       12                    6
Caught or Not           Door One  Door Two  Door Three                 Total

Total                   ____      ____      ____                       1

Door Choice

The first entry 1 = ( )( ) 1 1 is P(Door One AND Caught).
                 15     5      3

The entry 4 = ( )( ) 4 1 is P(Door One AND Not Caught).
             15      5  3

Verify the remaining entries.
Exercise:

   Problem:

Complete the probability contingency table. Calculate the entries for the totals.
Verify that the lower-right corner entry is 1.

Solution:

   Caught or Not        Door One  Door Two  Door Three                 Total
   Caught
   Not Caught              1         1        1                         19
   Total                 15        12         6                         60
Door Choice
                           4         3        1                         41
                         15        12         6                         60

                           5         4        2                        1
                         15        12         6

Exercise:

   Problem: What is the probability that Alissa does not catch Muddy?

   Solution:

          41
          60

Exercise:
   Problem:
   What is the probability that Muddy chooses Door One OR Door Two given that
   Muddy is caught by Alissa?
   Solution:

            9
           19

Note:You could also do this problem by using a probability tree. See the Tree Diagrams
(Optional) section of this chapter for examples.

Glossary

Contingency Table
      The method of displaying a frequency distribution as a table with rows and columns
      to show how two variables may be dependent (contingent) upon each other. The
      table provides an easy way to calculate conditional probabilities.
Summary of Formulas
This module provides a review of the probability formulas, including the
definitions of independent, complementary, and mutually exclusive events
as well as the addition and multiplication rules.
Formula
Complement

If A and A' are complements then P(A) + P(A' ) = 1
Formula
Addition Rule

P(A OR B) = P(A) + P(B) - P(A AND B)

Formula
Mutually Exclusive

If A and B are mutually exclusive then P(A AND B) = 0 ; so
P(A OR B) = P(A) + P(B).
Formula
Multiplication Rule

           P(A AND B) = P(B)P(A|B)
           P(A AND B) = P(A)P(B|A)

Formula
Independence

If A and B are independent then:

           P(A|B) = P(A)
           P(B|A) = P(B)
           P(A AND B) = P(A)P(B)
Discrete Random Variables
This module serves as the introduction to Discrete Random Variables in the
Elementary Statistics textbook/collection.

Student Learning Outcomes

By the end of this chapter, the student should be able to:

      Recognize and understand discrete probability distribution functions,
      in general.
      Calculate and interpret expected values.
      Recognize the binomial probability distribution and apply it
      appropriately.
      Recognize the Poisson probability distribution and apply it
      appropriately (optional).
      Recognize the geometric probability distribution and apply it
      appropriately (optional).
      Recognize the hypergeometric probability distribution and apply it
      appropriately (optional).
      Classify discrete word problems by their distributions.

Introduction

A student takes a 10 question true-false quiz. Because the student had such
a busy schedule, he or she could not study and randomly guesses at each
answer. What is the probability of the student passing the test with at least a
70%?

Small companies might be interested in the number of long distance phone
calls their employees make during the peak time of the day. Suppose the
average is 20 calls. What is the probability that the employees make more
than 20 long distance phone calls during the peak time?

These two examples illustrate two different types of probability problems
involving discrete random variables. Recall that discrete data are data that
you can count. A random variable describes the outcomes of a statistical
experiment in words. The values of a random variable can vary with each
repetition of an experiment.

In this chapter, you will study probability problems involving discrete
random distributions. You will also study long-term averages associated
with them.

Random Variable Notation

Upper case letters like X or Y denote a random variable. Lower case letters
like x or y denote the value of a random variable. If X is a random
variable, then X is written in words. and x is given as a number.

For example, let X = the number of heads you get when you toss three fair
coins. The sample space for the toss of three fair coins is TTT THH HTH
HHT HTT THT TTH HHH . Then, x = 0, 1, 2, 3. X is in words and x is
a number. Notice that for this example, the x values are countable
outcomes. Because you can count the possible values that X can take on
and the outcomes are random (the x values 0, 1, 2, 3), X is a discrete
random variable.

Optional Collaborative Classroom Activity

Toss a coin 10 times and record the number of heads. After all members of
the class have completed the experiment (tossed a coin 10 times and
counted the number of heads), fill in the chart using a heading like the one
below. Let X = the number of heads in 10 tosses of the coin.

x  Frequency of x  Relative Frequency of x
x  Frequency of x  Relative Frequency of x

      Which value(s) of x occurred most frequently?
      If you tossed the coin 1,000 times, what values could x take on?
      Which value(s) of x do you think would occur most frequently?
      What does the relative frequency column sum to?

Glossary

Random Variable (RV)
      see Variable

Variable (Random Variable)
      A characteristic of interest in a population being studied. Common
      notation for variables are upper case Latin letters X, Y , Z,...; common
      notation for a specific value from the domain (set of all possible values
      of a variable) are lower case Latin letters x, y, z,.... For example, if X
      is the number of children in a family, then x represents a specific
      integer 0, 1, 2, 3, .... Variables in statistics differ from variables in
      intermediate algebra in two following ways.

            The domain of the random variable (RV) is not necessarily a
            numerical set; the domain may be expressed in words; for
            example, if X = hair color then the domain is {black, blond, gray,
            green, orange}.
            We can tell what specific value x of the Random Variable X takes
            only after performing the experiment.
Probability Distribution Function (PDF) for a Discrete Random Variable
This module introduces the Probability Distribution Function (PDF) and its
characteristics.

A discrete probability distribution function has two characteristics:

      Each probability is between 0 and 1, inclusive.
      The sum of the probabilities is 1.

Example:
A child psychologist is interested in the number of times a newborn baby's
crying wakes its mother after midnight. For a random sample of 50
mothers, the following information was obtained. Let X = the number of
times a newborn wakes its mother after midnight. For this example, x = 0,
1, 2, 3, 4, 5.
P(x) = probability that X takes on a value x.

x  P(x)

0 P(x=0) = 2
                                                                                                       50

1 P(x=1) = 11
                                                                                                       50

2 P(x=2) = 23
                                                                                                       50

3 P(x=3) = 9
                                                                                                       50

4 P(x=4) = 4
                                                                                                       50

5
                                                         1

               P(x=5) =

                                                        50

X takes on the values 0, 1, 2, 3, 4, 5. This is a discrete PDF because

1. Each P(x) is between 0 and 1, inclusive.
2. The sum of the probabilities is 1, that is,

Equation:

           2      11     23                                 9      4      1

               +      +      +                                  +      +      =1

           50     50     50                                 50     50     50

Example:
Suppose Nancy has classes 3 days a week. She attends classes 3 days a
week 80% of the time, 2 days 15% of the time, 1 day 4% of the time, and
no days 1% of the time. Suppose one week is randomly selected.
Exercise:

   Problem:

   Let X = the number of days Nancy ____________________ .

   Solution:

   Let X = the number of days Nancy attends class per week.
Exercise:

   Problem: X takes on what values?

   Solution:

   0, 1, 2, and 3
Exercise:
Problem:

Suppose one week is randomly chosen. Construct a probability
distribution table (called a PDF table) like the one in the previous
example. The table should have two columns labeled x and P(x).
What does the P(x) column sum to?

Solution:

x  P(x)

0  0.01

1  0.04

2  0.15

3  0.80

Glossary

Probability Distribution Function (PDF)
      A mathematical description of a discrete random variable (RV), given
      either in the form of an equation (formula) , or in the form of a table
      listing all the possible outcomes of an experiment and the probability
      associated with each outcome.
Example:
A biased coin with probability 0.7 for a head (in one toss of the coin) is
tossed 5 times. We are interested in the number of heads (the RV X = the
number of heads). X is Binomial, so X  B(5, 0. 7) and P (X = x) =

  . 7 . 3 5 x 5-xor in the form of the table:

    x

x  P (X = x)

0  0.0024

1  0.0284

2  0.1323

3  0.3087

4  0.3602

5  0.1681
Mean or Expected Value and Standard Deviation
This module explores the Law of Large Numbers, the phenomenon where
an experiment performed many times will yield cumulative results closer
and closer to the theoretical mean over time.

The expected value is often referred to as the "long-term"average or
mean . This means that over the long term of doing an experiment over and
over, you would expect this average.

The mean of a random variable X is . If we do an experiment many times
(for instance, flip a fair coin, as Karl Pearson did, 24,000 times and let X =
the number of heads) and record the value of X each time, the average is
likely to get closer and closer to  as we keep repeating the experiment.
This is known as the Law of Large Numbers.

Note:To find the expected value or long term average, , simply multiply
each value of the random variable by its probability and add the products.

A Step-by-Step Example
A men's soccer team plays soccer 0, 1, or 2 days a week. The probability
that they play 0 days is 0.2, the probability that they play 1 day is 0.5, and
the probability that they play 2 days is 0.3. Find the long-term average, ,
or expected value of the days per week the men's soccer team plays soccer.

To do the problem, first let the random variable X = the number of days the
men's soccer team plays soccer per week. X takes on the values 0, 1, 2.
Construct a PDF table, adding a column xP(x). In this column, you will
multiply each x value by its probability.
x  P(x)                                                                          xP(x)

0  0.2                                                                           (0)(0.2) = 0

1  0.5                                                                           (1)(0.5) = 0.5

2  0.3                                                                           (2)(0.3) = 0.6

Expected Value TableThis table is called an expected value table. The table
helps you calculate the expected value or long-term average.

Add the last column to find the long term average or expected value:
(0)(0.2)+(1)(0.5)+(2)(0.3)= 0 + 0.5 + 0.6 = 1.1.

The expected value is 1.1. The men's soccer team would, on the average,
expect to play soccer 1.1 days per week. The number 1.1 is the long term
average or expected value if the men's soccer team plays soccer week after
week after week. We say =1.1

Example:
Find the expected value for the example about the number of times a
newborn baby's crying wakes its mother after midnight. The expected
value is the expected number of times a newborn wakes its mother after
midnight.

x  P(X)                                                                                 xP(X)

0 P(x=0) = 2                                                                            (0)( 50 ) 2 = 0
                                                                             50
x  P(X)                                                                          xP(X)

1 P(x=1) = 11                                                                    (1)( ) 11 = 11
                                                                             50  50     50

2 P(x=2) = 23                                                                    (2)( ) 23 = 46
                                                                             50  50     50

3 P(x=3) = 9                                                                     (3)( ) 9 = 27
                                                                             50  50     50

4 P(x=4) = 4                                                                     (4)( ) 4 = 16
                                                                             50  50     50

5 P(x=5) = 1                                                                     (5)( ) 1 = 5
                                                                             50  50     50

You expect a newborn to wake its mother after midnight 2.1 times, on the
average.

Add the last column to find the expected value.  = Expected Value =

 105

          = 2.1

   50

Exercise:

   Problem:

Go back and calculate the expected value for the number of days
Nancy attends classes a week. Construct the third column to do so.

Solution:
2.74 days a week.

Example:
Suppose you play a game of chance in which five numbers are chosen
from 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. A computer randomly selects five numbers
from 0 to 9 with replacement. You pay $2 to play and could profit
$100,000 if you match all 5 numbers in order (you get your $2 back plus
$100,000). Over the long term, what is your expected profit of playing the

game?

To do this problem, set up an expected value table for the amount of money

you can profit.

Let X = the amount of money you profit. The values of x are not 0, 1, 2, 3,

4, 5, 6, 7, 8, 9. Since you are interested in your profit (or loss), the values

of x are 100,000 dollars and -2 dollars.

To win, you must get all 5 numbers correct, in order. The probability of

choosing one correct number is          1  because there are 10 numbers. You may
                                       10

choose a number more than once. The probability of choosing all 5

numbers correctly and in order is:

Equation:

                 1      1     1     1      1           -5

                     *     *     *     *      *= 1*10      = 0.00001

           10 10 10 10 10

Therefore, the probability of winning is 0.00001 and the probability of
losing is
Equation:

                              1 - 0.00001 = 0.99999

The expected value table is as follows.

                 x                  P(x)      xP(x)

Loss             -2                 0.99999   (-2)(0.99999)=-1.99998

Profit           100,000            0.00001   (100000)(0.00001)=1

dd the last column. -1.99998 + 1 = -0.99998
Since -0.99998 is about -1, you would, on the average, expect to lose
approximately one dollar for each game you play. However, each time you
play, you either lose $2 or profit $100,000. The $1 is the average or
expected LOSS per game after playing this game over and over.

Example:
Suppose you play a game with a biased coin. You play each game by
tossing the coin once. P(heads) = 32 and P(tails) = 31 . If you toss a
head, you pay $6. If you toss a tail, you win $10. If you play this game
many times, will you come out ahead?
Exercise:

   Problem: Define a random variable X.

   Solution:

   X = amount of profit
Exercise:

   Problem: Complete the following expected value table.

WIN   x     ____  ____
LOSE
      10      1   ____
      ____    3
                   -12
            ____       3
Solution:

           x  P(x)  xP(x)

WIN        10 31     10
LOSE       -6 32       3

                     -12
                         3

Exercise:

   Problem: What is the expected value, ? Do you come out ahead?

   Solution:

   Add the last column of the table. The expected value  = 3 -2 . You
   lose, on average, about 67 cents each time you play the game so you
   do not come out ahead.

Like data, probability distributions have standard deviations. To calculate
the standard deviation () of a probability distribution, find each deviation
from its expected value, square it, multiply it by its probability, add the
products, and take the square root . To understand how to do the calculation,
look at the table for the number of days per week a men's soccer team plays
soccer. To find the standard deviation, add the entries in the column labeled

(x - )  P (x) 2 and take the square root.
x     P(x)    xP(x)           (x -) P(x) 2

0     0.2     (0)(0.2) = 0                                    2

1     0.5     (1)(0.5) = 0.5  (0 - 1.1) (.2) = 0.242

2     0.3     (2)(0.3) = 0.6                                  2

                              (1 - 1.1) (.5) = 0.005

                                                              2

                              (2 - 1.1) (.3) = 0.243

Add the last column in the table. 0.242 + 0.005 + 0.243 = 0.490. The
standard deviation is the square root of 0.49.  = 0.49 = 0.7

Generally for probability distributions, we use a calculator or a computer to
calculate  and  to reduce roundoff error. For some probability
distributions, there are short-cut formulas that calculate  and .

Glossary

Expected Value
      Expected arithmetic average when an experiment is repeated many
      times. (Also called the mean). Notations: E(x), . For a discrete
      random variable (RV) with probability distribution function P (x),the
      definition can also be written in the form E(x) =  =  xP(x).

Mean

   A number that measures the central tendency. A common name for

   mean is 'average.' The term 'mean' is a shortened form of 'arithmetic

   mean.' By definition, the mean for a sample (denoted by x) is

   x = Sum of all values in the sample , and the mean for a population
                     Number of values in the sample

   (denoted by ) is . Sum of all values in the population
              =

                 Number of values in the population
Common Discrete Probability Distribution Functions
This module serves as a lead-in for several types of common discrete
probability distribution functions, including binomial, geometric,
hypergeometric, and Poisson.

Some of the more common discrete probability functions are binomial,
geometric, hypergeometric, and Poisson. Most elementary courses do not
cover the geometric, hypergeometric, and Poisson. Your instructor will let
you know if he or she wishes to cover these distributions.

A probability distribution function is a pattern. You try to fit a probability
problem into a pattern or distribution in order to perform the necessary
calculations. These distributions are tools to make solving probability
problems easier. Each distribution has its own special characteristics.
Learning the characteristics enables you to distinguish among the different
distributions.
Binomial
This module describes the characteristics of a binomial experiment and the
binomial probability distribution function.

The characteristics of a binomial experiment are:

   1. There are a fixed number of trials. Think of trials as repetitions of an
      experiment. The letter n denotes the number of trials.

   2. There are only 2 possible outcomes, called "success" and, "failure" for
      each trial. The letter p denotes the probability of a success on one trial
      and q denotes the probability of a failure on one trial. p + q = 1.

   3. The n trials are independent and are repeated using identical
      conditions. Because the n trials are independent, the outcome of one
      trial does not help in predicting the outcome of another trial. Another
      way of saying this is that for each individual trial, the probability, p, of
      a success and probability, q, of a failure remain the same. For example,
      randomly guessing at a true - false statistics question has only two
      outcomes. If a success is guessing correctly, then a failure is guessing
      incorrectly. Suppose Joe always guesses correctly on any statistics true
      - false question with probability p = 0.6. Then, q = 0.4 .This means
      that for every true - false statistics question Joe answers, his
      probability of success (p = 0.6) and his probability of failure (q = 0.4
      ) remain the same.

The outcomes of a binomial experiment fit a binomial probability
distribution. The random variable X = the number of successes obtained
in the n independent trials.

The mean, , and variance, 2, for the binomial probability distribution is
 = np and 2 = npq. The standard deviation, , is then  = npq.

Any experiment that has characteristics 2 and 3 and where n = 1 is called a
Bernoulli Trial (named after Jacob Bernoulli who, in the late 1600s,
studied them extensively). A binomial experiment takes place when the
number of successes is counted in one or more Bernoulli Trials.
Example:
At ABC College, the withdrawal rate from an elementary physics course is
30% for any given term. This implies that, for any given term, 70% of the
students stay in the class for the entire term. A "success" could be defined
as an individual who withdrew. The random variable is X = the number of
students who withdraw from the randomly selected elementary physics
class.

Example:
Suppose you play a game that you can only either win or lose. The
probability that you win any game is 55% and the probability that you lose
is 45%. Each game you play is independent. If you play the game 20 times,
what is the probability that you win 15 of the 20 games? Here, if you
define X = the number of wins, then X takes on the values 0, 1, 2, 3, ...,
20. The probability of a success is p = 0.55. The probability of a failure is
q = 0.45. The number of trials is n = 20. The probability question can be
stated mathematically as P (x = 15).

Example:
A fair coin is flipped 15 times. Each flip is independent. What is the
probability of getting more than 10 heads? Let X = the number of heads in
15 flips of the fair coin. X takes on the values 0, 1, 2, 3, ..., 15. Since the
coin is fair, p = 0.5 and q = 0.5. The number of trials is n = 15. The
probability question can be stated mathematically as P (x > 10).

Example:
Approximately 70% of statistics students do their homework in time for it
to be collected and graded. Each student does homework independently. In
a statistics class of 50 students, what is the probability that at least 40 will
do their homework on time? Students are selected randomly.
Exercise:
   Problem:
   This is a binomial problem because there is only a success or a
   __________, there are a definite number of trials, and the probability
   of a success is 0.70 for each trial.

   Solution:
   failure
Exercise:
   Problem:
   If we are interested in the number of students who do their homework,
   then how do we define X?

   Solution:
   X = the number of statistics students who do their homework on time
Exercise:

   Problem: What values does x take on?

   Solution:
   0, 1, 2, ..., 50
Exercise:

   Problem: What is a "failure", in words?

   Solution:
   Failure is a student who does not do his or her homework on time.
The probability of a success is p = 0.70. The number of trial is n = 50.
Exercise:
   Problem: If p + q = 1, then what is q?

   Solution:
   q = 0.30
Exercise:
   Problem:
   The words "at least" translate as what kind of inequality for the
   probability question P (x____40).

   Solution:
   greater than or equal to ()
The probability question is P (x  40).

Notation for the Binomial: B = Binomial Probability
Distribution Function

X ~ B(n, p)

Read this as "X is a random variable with a binomial distribution." The
parameters are n and p. n = number of trials p = probability of a success on
each trial

Example:
It has been stated that about 41% of adult workers have a high school
diploma but do not pursue any further education. If 20 adult workers are
randomly selected, find the probability that at most 12 of them have a high
school diploma but do not pursue any further education. How many adult
workers do you expect to have a high school diploma but do not pursue
any further education?
Let X = the number of workers who have a high school diploma but do not
pursue any further education.
X takes on the values 0, 1, 2, ..., 20 where n = 20 and p = 0.41. q = 1 -
0.41 = 0.59. X ~ B(20, 0.41)
Find P (x  12). P (x  12) = 0.9738. (calculator or computer)
Using the TI-83+ or the TI-84 calculators, the calculations are as follows.
Go into 2nd DISTR. The syntax for the instructions are
To calculate (x = value): binompdf(n, p, number) If "number" is left out,
the result is the binomial probability table.
To calculate P (x  value): binomcdf(n, p, number) If "number" is left
out, the result is the cumulative binomial probability table.
For this problem: After you are in 2nd DISTR, arrow down to
binomcdf. Press ENTER. Enter 20,.41,12). The result is
P (x  12) = 0.9738.

Note:If you want to find P (x = 12), use the pdf (binompdf). If you want
to find P(x>12), use 1 - binomcdf(20,.41,12).

The probability at most 12 workers have a high school diploma but do not
pursue any further education is 0.9738
The graph of x ~ B(20, 0.41) is:
The y-axis contains the probability of x, where X = the number of workers

who have only a high school diploma.

The number of adult workers that you expect to have a high school

diploma but not pursue any further education is the mean,

 = np = (20)(0.41) = 8.2.

The  formula  for  the  variance  is       2  =  npq.  The  standard  deviation   is

                                      

 = npq.  = (20)(0.41)(0.59) = 2.20.

Example:

The following example illustrates a problem that is not binomial. It

violates the condition of independence. ABC College has a student

advisory committee made up of 10 staff members and 6 students. The

committee wishes to choose a chairperson and a recorder. What is the

probability that the chairperson and recorder are both students? All names

of the committee are put into a box and two names are drawn without

replacement. The first name drawn determines the chairperson and the

second name the recorder. There are two trials. However, the trials are not

independent because the outcome of the first trial affects the outcome of

the second trial. The probability of a student on the first draw is 16 6 . The

probability of a student on the second draw is          5   ,  when   the  first  draw
                                                       15

produces a student. The probability is            6  when the first draw produces a
                                                 15

staff member. The probability of drawing a student's name changes for

each of the trials and, therefore, violates the condition of independence.

Glossary

Bernoulli Trials
      An experiment with the following characteristics:

            There are only 2 possible outcomes called "success" and "failure"
            for each trial.
            The probability p of a success is the same for any trial (so the
            probability q = 1 - p of a failure is the same for any trial).
Binomial Distribution

A discrete random variable (RV) which arises from Bernoulli trials.

There are a fixed number, n, of independent trials. "Independent"

means that the result of any trial (for example, trial 1) does not affect

the results of the following trials, and all trials are conducted under the

same conditions. Under these circumstances the binomial RV X is

defined as the number of successes in n trials. The notation is: X~

B(n, p). The mean is  = np and the standard deviation is  = npq

. The probability of exactly x successes in n trials is

. n
                       x n-x
P (X = x) = ( )p q
x
Poisson
This module describes the characteristics of a Poisson experiment and the
Poisson probability distribution. This module is included in the Elementary
Statistics textbook/collection as an optional lesson.

Characteristics of a Poisson experiment:

   1. The Poisson gives the probability of a number of events occurring in a
      fixed interval of time or space if these events happen with a known
      average rate and independently of the time since the last event. For
      example, a book editor might be interested in the number of words
      spelled incorrectly in a particular book. It might be that, on the
      average, there are 5 words spelled incorrectly in 100 pages. The
      interval is the 100 pages.

   2. The Poisson may be used to approximate the binomial if the
      probability of success is "small" (such as 0.01) and the number of trials
      is "large" (such as 1000). You will verify the relationship in the
      homework exercises. n is the number of trials and p is the probability
      of a "success."

Poisson probability distribution. The random variable X = the number of
occurrences in the interval of interest. The mean and variance are given in
the summary.

Example:
The average number of loaves of bread put on a shelf in a bakery in a half-
hour period is 12. Of interest is the number of loaves of bread put on the
shelf in 5 minutes. The time interval of interest is 5 minutes. What is the
probability that the number of loaves, selected randomly, put on the shelf
in 5 minutes is 3?
Let X = the number of loaves of bread put on the shelf in 5 minutes. If the
average number of loaves put on the shelf in 30 minutes (half-hour) is 12,
then the average number of loaves put on the shelf in 5 minutes is
( 30 ) 5  12 = 2 loaves of bread
The probability question asks you to find P(x = 3).
Example:
A certain bank expects to receive 6 bad checks per day, on average. What
is the probability of the bank getting fewer than 5 bad checks on any given
day? Of interest is the number of checks the bank receives in 1 day, so the
time interval of interest is 1 day. Let X = the number of bad checks the
bank receives in one day. If the bank expects to receive 6 bad checks per
day then the average is 6 checks per day. The probability question asks for
P (x < 5).

Example:
You notice that a news reporter says "uh", on average, 2 times per
broadcast. What is the probability that the news reporter says "uh" more
than 2 times per broadcast.
This is a Poisson problem because you are interested in knowing the
number of times the news reporter says "uh" during a broadcast.
Exercise:

   Problem: What is the interval of interest?

   Solution:

   One broadcast
Exercise:

   Problem:

   What is the average number of times the news reporter says "uh"
   during one broadcast?

   Solution:

   2
Exercise:
   Problem: Let X = ____________. What values does X take on?

   Solution:
   Let X = the number of times the news reporter says "uh" during
   one broadcast.
   x = 0, 1, 2, 3, ...
Exercise:

   Problem: The probability question is P(______).

   Solution:

     P(x > 2)

Notation for the Poisson: P = Poisson Probability Distribution
Function

X ~ P()

Read this as "X is a random variable with a Poisson distribution." The
parameter is  (or ).  (or ) = the mean for the interval of interest.

Example:

Leah's answering machine receives about 6 telephone calls between 8 a.m.

and 10 a.m. What is the probability that Leah receives more than 1 call in

the next 15 minutes?

Let X = the number of calls Leah receives in 15 minutes. (The interval of

interest is 15 minutes or  1  hour.)
                           4

x = 0, 1, 2, 3, ...
If Leah receives, on the average, 6 telephone calls in 2 hours, and there are
eight 15 minutes intervals in 2 hours, then Leah receives

   1

        6 = 0.75

   8

calls in 15 minutes, on the average. So,  = 0.75 for this problem.
X ~ P(0.75)
Find P (x > 1). P (x > 1) = 0.1734 (calculator or computer)
TI-83+ and TI-84: For a general discussion, see this example (Binomial).
The syntax is similar. The Poisson parameter list is ( for the interval of
interest, number). For this problem:
Press 1- and then press 2nd DISTR. Arrow down to C:poissoncdf.
Press ENTER. Enter .75,1). The result is P (x > 1) = 0.1734. NOTE:
The TI calculators use  (lambda) for the mean.
The probability that Leah receives more than 1 telephone call in the next
fifteen minutes is about 0.1734.
The graph of X ~ P(0.75) is:

The y-axis contains the probability of x where X = the number of calls in
15 minutes.

Glossary
Poisson Distribution
      A discrete random variable (RV) that counts the number of times a
      certain event will occur in a specific interval. Characteristics of the
      variable:

            The probability that the event occurs in a given interval is the
            same for all intervals.
            The events occur with a known mean and independently of the
            time since the last event.

      The distribution is defined by the mean  of the event in the interval.
      Notation: X~P (). The mean is  = np. The standard deviation is
       = . The probability of having exactly x successes in r trials is

                                                                                                                      x

                                                                    - 

      P (X = x) = e x . The Poisson distribution is often used to
      approximate the binomial distribution when n is "large" and p is
      "small" (a general rule is that n should be greater than or equal to 20
      and p should be less than or equal to .05).
Summary of Functions
This module provides a review of the binomial, geometric, hypergeometric,
and Poisson probability distribution functions and their properties.
Formula
Binomial

X~B(n, p)

X = the number of successes in n independent trials

n = the number of independent trials

X takes on the values x = 0,1, 2, 3, ...,n

p = the probability of a success for any trial

q = the probability of a failure for any trial

p+q = 1  q = 1-p

The mean is  = np. The standard deviation is  = npq.
Formula
Geometric

X~G(p)

X = the number of independent trials until the first success (count the
failures and the first success)

X takes on the values x= 1, 2, 3, ...

p = the probability of a success for any trial

q = the probability of a failure for any trial

p+q = 1

q = 1-p
The mean is  =  1
                p

he  standard  deviation  is    =    1  ((  1  )  -  1)
                                    p      p

Formula
Hypergeometric

X~H (r, b, n)

X = the number of items from the group of interest that are in the chosen
sample.

X may take on the values x= 0, 1, ..., up to the size of the group of interest.
(The minimum value for X may be larger than 0 in some instances.)

r = the size of the group of interest (first group)

b= the size of the second group

n= the size of the chosen sample.

n  r+b

The mean is:  = r+b nr

                                                                                                                       rbn(r+b-n)

The standard deviation is:  =  2

                                                                                                                  (r+b) (r+b-1)

Formula
Poisson

X ~ P()

X = the number of occurrences in the interval of interest

X takes on the values x = 0, 1, 2, 3, ...

The mean  is typically given. ( is often used as the mean instead of .)
When the Poisson is used to approximate the binomial, we use the binomial
mean  = np. n is the binomial number of trials. p = the probability of a

success for each trial. This formula is valid when n is "large" and p "small"

(a general rule is that n should be greater than or equal to 20 and p should

be less than or equal to 0.05). If n is large enough and p is small enough

then the Poisson approximates the binomial very well. The variance is

    2  =    and  the  standard  deviation  is    =  


Continuous Random Variables
Continuous Random Variables: Introduction is part of the collection
col10555 written by Barbara Illowsky and Susan Dean and serves as an
introduction to the uniform and exponential distributions with contributions
from Roberta Bloom.

Student Learning Outcomes

By the end of this chapter, the student should be able to:

      Recognize and understand continuous probability density functions in
      general.
      Recognize the uniform probability distribution and apply it
      appropriately.
      Recognize the exponential probability distribution and apply it
      appropriately.

Introduction

Continuous random variables have many applications. Baseball batting
averages, IQ scores, the length of time a long distance telephone call lasts,
the amount of money a person carries, the length of time a computer chip
lasts, and SAT scores are just a few. The field of reliability depends on a
variety of continuous random variables.

This chapter gives an introduction to continuous random variables and the
many continuous distributions. We will be studying these continuous
distributions for several chapters.

Note:The values of discrete and continuous random variables can be
ambiguous. For example, if X is equal to the number of miles (to the
nearest mile) you drive to work, then X is a discrete random variable. You
count the miles. If X is the distance you drive to work, then you measure
values of X and X is a continuous random variable. How the random
variable is defined is very important.
Properties of Continuous Probability Distributions

The graph of a continuous probability distribution is a curve. Probability is
represented by area under the curve.

The curve is called the probability density function (abbreviated: pdf).
We use the symbol f(x) to represent the curve. f(x) is the function that
corresponds to the graph; we use the density function f(x) to draw the
graph of the probability distribution.

Area under the curve is given by a different function called the
cumulative distribution function (abbreviated: cdf). The cumulative
distribution function is used to evaluate probability as area.

      The outcomes are measured, not counted.
      The entire area under the curve and above the x-axis is equal to 1.
      Probability is found for intervals of x values rather than for individual
      x values.
      P (c < x < d) is the probability that the random variable X is in the
      interval between the values c and d. P (c < x < d) is the area under
      the curve, above the x-axis, to the right of c and the left of d.
      P (x = c) = 0 The probability that x takes on any single individual
      value is 0. The area below the curve, above the x-axis, and between
      x=c and x=c has no width, and therefore no area (area = 0). Since the
      probability is equal to the area, the probability is also 0.

We will find the area that represents probability by using geometry,
formulas, technology, or probability tables. In general, calculus is needed to
find the area under the curve for many probability density functions. When
we use formulas to find the area in this textbook, the formulas were found
by using the techniques of integral calculus. However, because most
students taking this course have not studied calculus, we will not be using
calculus in this textbook.

There are many continuous probability distributions. When using a
continuous probability distribution to model probability, the distribution
used is selected to best model and fit the particular situation.
In this chapter and the next chapter, we will study the uniform distribution,
the exponential distribution, and the normal distribution. The following
graphs illustrate these distributions.

       The graph shows a Uniform
   Distribution with the area between
    x=3 and x=6 shaded to represent

    the probability that the value of
     the random variable X is in the

        interval between 3 and 6.

          The graph shows an
    Exponential Distribution with
    the area between x=2 and x=4
        shaded to represent the

   probability that the value of the
      random variable X is in the
       interval between 2 and 4.

    The graph shows the Standard Normal Distribution with
      the area between x=1 and x=2 shaded to represent the
     probability that the value of the random variable X is in
                     the interval between 1 and 2.

**With contributions from Roberta Bloom

Glossary

Uniform Distribution
      A continuous random variable (RV) that has equally likely outcomes
      over the domain, a < x < b. Often referred as the Rectangular
      distribution because the graph of the pdf has the form of a rectangle.
      Notation: X~U(a,b). The mean is  = 2 a+b and the standard deviation
is  =  (b-a)2 The probability density function is f(X) = 1 for
              12                                                                        b-a

a < x < b or a  x  b. The cumulative distribution is

                  . x-a

P (X  x) =

                                                  b-a

Exponential Distribution

A continuous random variable (RV) that appears when we are

interested in the intervals of time between some random events, for

example, the length of time between emergency arrivals at a hospital.

Notation: X~Exp(m). The mean is  =                               1        and the standard deviation
                                                                m

is  =   1  .  The  probability                         density  function  is  f (x)  =  me-mx ,  x    0
       m

and the cumulative distribution function is P (X  x) = 1 - e-mx.
Continuous Probability Functions
This module introduces the continuous probability function and explores
the relationship between the probability of X and the area under the curve
of f(X).

We begin by defining a continuous probability density function. We use the
function notation f(x). Intermediate algebra may have been your first
formal introduction to functions. In the study of probability, the functions
we study are special. We define the function f(x) so that the area between
it and the x-axis is equal to a probability. Since the maximum probability is
one, the maximum area is also one.

For continuous probability distributions, PROBABILITY = AREA.

Example:

Consider the function f(x) = 20 1 for 0  x  20. x = a real number. The

graph of f(x) =   1  is a horizontal line. However, since 0  x  20 ,
                 20

f(x) is restricted to the portion between x = 0 and x = 20, inclusive .
f(x) = 1 for 0 x 20.
                             20

The graph of f(x) =      1    is a horizontal line segment when 0  x  20.
                        20

The area between f(x) =           1  where 0  x  20 and the x-axis is the area
                                 20

of  a  rectangle  with  base  =  20  and  height  =   1  .
                                                     20

                  1

AREA = 20         20    =1

This particular function, where we have restricted x so that the area

between the function and the x-axis is 1, is an example of a continuous

probability density function. It is used as a tool to calculate probabilities.

Suppose we want to find the area between f(x) =              1  and the x-axis
                                                            20

where 0 < x < 2 .

AREA = (2 - 0)          1     = 0.1

                        20

(2 - 0) = 2 = base of a rectangle

20 1 = the height.
The area corresponds to a probability. The probability that x is between 0
and 2 is 0.1, which can be written mathematically as
P(0<x<2) = P(x<2) = 0.1.

Suppose we want to find the area between f(x) =              1  and the x-axis
                                                            20

where 4 < x < 15 .
AREA = (15 - 4)    1   = 0.55

                   20

(15 - 4) = 11 = the base of a rectangle

 1  = the height.
20

The area corresponds to the probability P (4 < x < 15) = 0.55.

Suppose we want to find P ( x=15). On an x-y graph, x=15 is a vertical

line. A vertical line has no width (or 0 width). Therefore,

P ( x=15) = (base)(height) = (0)( ) 1 = 0.
                                                                                                                                20

P (X  x) (can be written as P (X < x) for continuous distributions) is
called the cumulative distribution function or CDF. Notice the "less than
or equal to" symbol. We can use the CDF to calculate P (X > x) . The
CDF gives "area to the left" and P (X > x) gives "area to the right." We
calculate P (X > x) for continuous distributions as follows:
P (X > x) = 1 - P (X < x).
Label the graph with f(x) and x. Scale the x and y axes with the maximum
x and y values. f(x) = 1 , 0  x  20.

                                                                                  20

                                                                                                                                                                                                  1

P (2.3 < x < 12.7) = (base)(height) = (12.7 - 2.3)( ) = 0.52

                                                                                                                                                                                                 20
The Uniform Distribution
Continuous Random Variable: Uniform Distribution is part of the collection col10555 written by Barbara
Illowsky and Susan Dean. It describes the properties of the Uniform Distribution with contributions from
Roberta Bloom.

Example:
The previous problem is an example of the uniform probability distribution.
Illustrate the uniform distribution. The data that follows are 55 smiling times, in seconds, of an eight-
week old baby.

10.4 19.6 18.8 13.9 17.8 16.8 21.6 17.9 12.5 11.1 4.9

12.8 14.8 22.8 20.0 15.9 16.3 13.4 17.1 14.5 19.0 22.8

1.3         0.7      8.9                        11.9 10.9 7.3  5.9             3.7  17.9 19.2 9.8

5.8         6.9      2.6                        5.8  21.7 11.8 3.4             2.1  4.5  6.3       10.7

8.9         9.4      9.4                        7.6  10.0 3.3  6.7             7.8  11.6 13.8 18.6

sample mean = 11.49 and sample standard deviation = 6.23

We will assume that the smiling times, in seconds, follow a uniform distribution between 0 and 23

seconds, inclusive. This means that any smiling time from 0 to and including 23 seconds is equally likely.

The histogram that could be constructed from the sample is an empirical distribution that closely matches

the theoretical uniform distribution.

Let X = length, in seconds, of an eight-week old baby's smile.

The notation for the uniform distribution is

X ~ U(a,b) where a = the lowest value of x and b = the highest value of x.

The probability density function is f(x) =              1      for a  x  b.
                                                     b-a

For this example, x ~ U (0,23) and f(x) = 23-0 1 for 0 x 23.

Formulas for the theoretical mean and standard deviation are

and  =                                (b-a)2
   a+b
      2     =

                                            12

For this problem, the theoretical mean and standard deviation are

   0+23              seconds and  =                  (23-0 )2  = 6.64 seconds

=    2      = 11.50                                  12

Notice that the theoretical mean and standard deviation are close to the sample mean and standard

deviation.

Example:
Exercise:
Problem:

What is the probability that a randomly chosen eight-week old baby smiles between 2 and 18
seconds?

Solution:

Find P (2 < x < 18).

P (2 < x < 18) = (base)(height) = (18 - 2)  1 = 16 .
                       23  23

Exercise:

Problem: Find the 90th percentile for an eight week old baby's smiling time.
Solution:
Ninety percent of the smiling times fall below the 90th percentile, k, so P (x < k) = 0.90

P (x < k) = 0.90

(base)(height) = 0.90

           1

(k - 0)    23  = 0.90

k = 23  0.90 = 20.7

Exercise:
Problem:

Find the probability that a random eight week old baby smiles more than 12 seconds KNOWING
that the baby smiles MORE THAN 8 SECONDS.

Solution:

Find P (x > 12|x > 8) There are two ways to do the problem. For the first way, use the fact that
this is a conditional and changes the sample space. The graph illustrates the new sample space. You
already know the baby smiled more than 8 seconds.

Write a new f(x): f(x) = 1 = 1
                        23-8       15

for 8 < x < 23

P (x > 12|x > 8) = (23 - 12)   1   =   11

                               15      15

For the second way, use the conditional formula from Probability Topics with the original
distribution X ~ U (0, 23):

           P (A AND B)  For this problem, A is (x > 12) and B is (x > 8).

P (A B) =

                P (B)

                                                     11

So, (x>12 AND x>8)                         P (x>12)  23

P (x > 12|x > 8) =                     =             = 15 = 0.733

                        P (x>8)            P (x>8)

                                                     23

Example:
Uniform: The amount of time, in minutes, that a person must wait for a bus is uniformly distributed
between 0 and 15 minutes, inclusive.
Exercise:
Problem: What is the probability that a person waits fewer than 12.5 minutes?

Solution:

Let X = the number of minutes a person must wait for a bus. a = 0 and b = 15. x~U(0, 15). Write

the probability density function. f(x) = 1 = 1 for 0 x 15.
                                         15-0      15

Find P (x < 12.5). Draw a graph.

P (x < k) = (base)(height) = (12.5 - 0)        1   = 0.8333

                                               15

The probability a person waits less than 12.5 minutes is 0.8333.

Exercise:

Problem: On the average, how long must a person wait?
Find the mean, , and the standard deviation, .

Solution:

 = a+b = 15+0 = 7.5. On the average, a person must wait 7.5 minutes.
2                  2

=          (b-a)2  =  (15-0 )2  = 4.3. The Standard deviation is 4.3 minutes.

           12         12

Exercise:

Problem: Ninety percent of the time, the time a person must wait falls below what value?

Note:This asks for the 90th percentile.

Solution:

Find the 90th percentile. Draw a graph. Let k = the 90th percentile.

                                                                                                                                                      1

P (x < k) = (base)(height) = (k - 0)  ( )

                                                                                                                                                    15
                                        1

0.90 = k 

                                       15

k = (0.90)(15) = 13.5

k is sometimes called a critical value.
The 90th percentile is 13.5 minutes. Ninety percent of the time, a person must wait at most 13.5
minutes.

Example:
Uniform: Suppose the time it takes a nine-year old to eat a donut is between 0.5 and 4 minutes, inclusive.
Let X = the time, in minutes, it takes a nine-year old child to eat a donut. Then X ~ U(0.5, 4).
Exercise:

   Problem:

The probability that a randomly selected nine-year old child eats a donut in at least two minutes is
_______.

Solution:

   0.5714
Exercise:

   Problem:

Find the probability that a different nine-year old child eats a donut in more than 2 minutes given that
the child has already been eating the donut for more than 1.5 minutes.

The second probability question has a conditional (refer to "Probability Topics"). You are asked to
find the probability that a nine-year old child eats a donut in more than 2 minutes given that the child
has already been eating the donut for more than 1.5 minutes. Solve the problem two different ways
(see the first example). You must reduce the sample space. First way: Since you already know the
child has already been eating the donut for more than 1.5 minutes, you are no longer starting at
a = 0.5 minutes. Your starting point is 1.5 minutes.

Write a new f(x):

f (x) =      1  =  2  for 1.5 x 4.

         4-1.5     5

Find P (x > 2|x > 1.5). Draw a graph.
P (x > 2|x > 1.5) = (base)(new height) = (4 - 2)(2/5) =?

Solution:

4
5

The probability that a nine-year old child eats a donut in more than 2 minutes given that the child has

already been eating the donut for more than 1.5 minutes is  4.

                                                            5

Second way: Draw the original graph for x ~ U(0.5, 4). Use the conditional formula

                                                   2

                     P (x>2 AND x>1.5) P (x>2) 3.5 4
P (x > 2|x > 1.5) =                  =             = 2.5 = 0.8 =

                     P (x>1.5)          P (x>1.5)                 5

                                                   3.5

Note:See "Summary of the Uniform and Exponential Probability Distributions" for a full summary.

Example:
Uniform: Ace Heating and Air Conditioning Service finds that the amount of time a repairman needs to
fix a furnace is uniformly distributed between 1.5 and 4 hours. Let x = the time needed to fix a furnace.
Then x ~ U (1.5, 4).

   1. Find the problem that a randomly selected furnace repair requires more than 2 hours.
   2. Find the probability that a randomly selected furnace repair requires less than 3 hours.
   3. Find the 30th percentile of furnace repair times.
   4. The longest 25% of repair furnace repairs take at least how long? (In other words: Find the

      minimum time for the longest 25% of repair times.) What percentile does this represent?
   5. Find the mean and standard deviation

Exercise:

Problem: Find the probability that a randomly selected furnace repair requires longer than 2 hours.

Solution:

To find f(x): f(x) = 1 = 1 so f(x) =0.4
                     4-1.5      2.5

P(x>2) = (base)(height) = (4 - 2)(0.4) = 0.8
   Example 4 Figure 1

          Uniform Distribution
         between 1.5 and 4 with
      shaded area between 2 and 4
      representing the probability
         that the repair time x is

               greater than 2

Exercise:
   Problem:
   Find the probability that a randomly selected furnace repair requires less than 3 hours. Describe how
   the graph differs from the graph in the first part of this example.
   Solution:
   P (x < 3) = (base)(height) = (3 - 1.5)(0.4) = 0.6
   The graph of the rectangle showing the entire distribution would remain the same. However the
   graph should be shaded between x=1.5 and x=3. Note that the shaded area starts at x=1.5 rather than
   at x=0; since X~U(1.5,4), x can not be less than 1.5.
   Example 4 Figure 2

           Uniform Distribution
         between 1.5 and 4 with
      shaded area between 1.5 and
      3 representing the probability
       that the repair time x is less

                    than 3

Exercise:
   Problem: Find the 30th percentile of furnace repair times.
   Solution:
   Example 4 Figure 3

       Uniform Distribution between
       1.5 and 4 with an area of 0.30
       shaded to the left, representing
      the shortest 30% of repair times.

     P (x < k) = 0.30
     P (x < k) = (base)(height) = (k - 1.5)  (0.4)

         0.3 = (k - 1.5) (0.4) ; Solve to find k:
         0.75 = k - 1.5 , obtained by dividing both sides by 0.4
         k = 2.25 , obtained by adding 1.5 to both sides
   The 30th percentile of repair times is 2.25 hours. 30% of repair times are 2.5 hours or less.
Exercise:
   Problem:
   The longest 25% of furnace repair times take at least how long? (Find the minimum time for the
   longest 25% of repairs.)
   Solution:
   Example 4 Figure 4

       Uniform Distribution between
       1.5 and 4 with an area of 0.25
      shaded to the right representing
      the longest 25% of repair times.

     P (x > k) = 0.25
     P (x > k) = (base)(height) = (4 - k)  (0.4)

         0.25 = (4 - k)(0.4) ; Solve for k:
         0.625 = 4 - k , obtained by dividing both sides by 0.4
         -3.375 = -k , obtained by subtracting 4 from both sides
         k=3.375

   The longest 25% of furnace repairs take at least 3.375 hours (3.375 hours or longer).

   Note: Since 25% of repair times are 3.375 hours or longer, that means that 75% of repair times are
   3.375 hours or less. 3.375 hours is the 75th percentile of furnace repair times.
Exercise:

Problem: Find the mean and standard deviation
Solution:

and  =                                 (b-a)2
   a+b
      2      =

                                             12

   1.5+4             hours and  =                                                                      (4-1.5)2  = 0.7217 hours

=         2  = 2.75                                                                                    12

Note:See "Summary of the Uniform and Exponential Probability Distributions" for a full summary.

**Example 5 contributed by Roberta Bloom

Glossary

Conditional Probability
      The likelihood that an event will occur given that another event has already occurred.

Uniform Distribution
      A continuous random variable (RV) that has equally likely outcomes over the domain, a < x < b.
      Often referred as the Rectangular distribution because the graph of the pdf has the form of a

rectangle. Notation: X~U(a,b). The mean is  = 2 and the standard deviation is  =                                                           (b-a)2
                                                                                                                       a+b
                                                                                                                                 

                                                                                                                                                                 12

The probability density function is f(x) =                                                                          1  for a < x < b or a  x  b. The cumulative
                                                                                                                 b-a

distribution is P (X  x) = x-a .
                                                                                                  b-a
The Exponential Distribution
This module introduces the properties of the exponential distribution, the behavior of probabilities that reflect a
large number of small values and a small number of high values.

The exponential distribution is often concerned with the amount of time until some specific event occurs. For
example, the amount of time (beginning now) until an earthquake occurs has an exponential distribution. Other
examples include the length, in minutes, of long distance business telephone calls, and the amount of time, in
months, a car battery lasts. It can be shown, too, that the value of the change that you have in your pocket or
purse approximately follows an exponential distribution.

Values for an exponential random variable occur in the following way. There are fewer large values and more
small values. For example, the amount of money customers spend in one trip to the supermarket follows an
exponential distribution. There are more people that spend less money and fewer people that spend large
amounts of money.

The exponential distribution is widely used in the field of reliability. Reliability deals with the amount of time a
product lasts.

Example:
Illustrates the exponential distribution: Let X = amount of time (in minutes) a postal clerk spends with
his/her customer. The time is known to have an exponential distribution with the average amount of time equal
to 4 minutes.
X is a continuous random variable since time is measured. It is given that  = 4 minutes. To do any
calculations, you must know m, the decay parameter.
m =  1 . Therefore, m = 4 = 0.25 1
The standard deviation, , is the same as the mean.  = 
The distribution notation is X~Exp(m). Therefore, X~Exp(0.25).
The probability density function is f(x) = m  e-mx The number e = 2.71828182846... It is a number that is
used often in mathematics. Scientific calculators have the key "ex." If you enter 1 for x, the calculator will
display the value e.
The curve is:
f(x) = 0.25  e- 0.25x where x is at least 0 and m = 0.25.
For example, f(5) = 0.25  e- 0.255 = 0.072
The graph is as follows:

Notice the graph is a declining curve. When x = 0,

f (x) = 0.25  e  - 0.250  = 0.25  1 = 0.25 = m
Example:
Exercise:

   Problem: Find the probability that a clerk spends four to five minutes with a randomly selected customer.
   Solution:
   Find P (4 < x < 5).
   The cumulative distribution function (CDF) gives the area to the left.

     P (x < x) = 1 - e-mx

   P (x < 5) = 1 - e-0.255 = 0.7135 and P (x < 4) = 1 - e-0.254 = 0.6321

   Note:You can do these calculations easily on a calculator.

   The probability that a postal clerk spends four to five minutes with a randomly selected customer is

     P (4 < x < 5) = P (x < 5) - P (x < 4) = 0.7135 - 0.6321 = 0.0814

   Note:TI-83+ and TI-84: On the home screen, enter (1-e^(-.25*5))-(1-e^(-.25*4)) or enter e^(-.25*4)-
   e^(-.25*5).

Exercise:
   Problem: Half of all customers are finished within how long? (Find the 50th percentile)
   Solution:
   Find the 50th percentile.
P (x < k) = 0.50, k = 2.8 minutes (calculator or computer)
Half of all customers are finished within 2.8 minutes.
You can also do the calculation as follows:
P (x < k) = 0.50 and P (x < k) = 1 - e-0.25k
Therefore, 0.50 = 1 - e-0.25k and e-0.25k = 1 - 0.50 = 0.5
Take natural logs: ln(e ) -0.25k = ln(0.50). So, -0.25k = ln(0.50)

Solve for k: k =  ln(.50)  = 2.8 minutes

                  -0.25

Note:A formula for the percentile k is k =  LN(1-AreaToTheLef t)  where LN is the natural log.

                                            -m

Note:TI-83+ and TI-84: On the home screen, enter LN(1-.50)/-.25. Press the (-) for the negative.

Exercise:

   Problem: Which is larger, the mean or the median?
   Solution:
   Is the mean or median larger?
   From part b, the median or 50th percentile is 2.8 minutes. The theoretical mean is 4 minutes. The mean is
   larger.

Optional Collaborative Classroom Activity

Have each class member count the change he/she has in his/her pocket or purse. Your instructor will record the
amounts in dollars and cents. Construct a histogram of the data taken by the class. Use 5 intervals. Draw a
smooth curve through the bars. The graph should look approximately exponential. Then calculate the mean.
Let X = the amount of money a student in your class has in his/her pocket or purse.

The distribution for X is approximately exponential with mean,  = _______ and m = _______. The standard
deviation,  = ________.

Draw the appropriate exponential graph. You should label the x and y axes, the decay rate, and the mean. Shade
the area that represents the probability that one student has less than $.40 in his/her pocket or purse. (Shade
P (x < 0.40)).

Example:
On the average, a certain computer part lasts 10 years. The length of time the computer part lasts is
exponentially distributed.
Exercise:

Problem: What is the probability that a computer part lasts more than 7 years?

Solution:

Let x = the amount of time (in years) a computer part lasts.

 = 10 so m = = = 0.1 1 1
                              10

Find P (x > 7). Draw a graph.

P (x > 7) = 1 - P (x < 7).

Since P (X < x) = 1 - e-mx then P (X > x) = 1 - (1 - e-mx) = e-mx

P (x  >  7)  =      -0.17  =  0.4966.  The  probability  that  a  computer  part  lasts  more  than  7  years  is  0.4966.

                e

Note:TI-83+ and TI-84: On the home screen, enter e^(-.1*7).

Exercise:
   Problem: On the average, how long would 5 computer parts last if they are used one after another?
   Solution:
   On the average, 1 computer part lasts 10 years. Therefore, 5 computer parts, if they are used one right after
   the other would last, on the average,
   (5)(10) = 50 years.
Exercise:

   Problem: Eighty percent of computer parts last at most how long?
   Solution:
   Find the 80th percentile. Draw a graph. Let k = the 80th percentile.

Solve for k: k =  ln(1-.80)  = 16.1 years

                  -0.1

Eighty percent of the computer parts last at most 16.1 years.

Note:TI-83+ and TI-84: On the home screen, enter LN(1 - .80)/-.1

Exercise:
   Problem: What is the probability that a computer part lasts between 9 and 11 years?
   Solution:
   Find P (9 < x < 11). Draw a graph.
    P (9 < x < 11) = P (x < 11) - P (x < 9) = (1 - e                 -0.111  ) - (1 - e       -0.19  ) = 0.6671 - 0.5934 = 0.0737

    . (calculator or computer)

    The probability that a computer part lasts between 9 and 11 years is 0.0737.

    Note:TI-83+ and TI-84: On the home screen, enter e^(-.1*9) - e^(-.1*11).

Example:

Suppose that the length of a phone call, in minutes, is an exponential random variable with decay parameter =

 1  .  If  another  person  arrives  at  a  public  telephone  just  before  you,  find  the  probability  that  you  will  have  to
12

wait more than 5 minutes. Let X = the length of a phone call, in minutes.

Exercise:

    Problem: What is m, , and ? The probability that you must wait more than 5 minutes is _______ .

    Solution:

          m= 1
                                      12

           = 12
           = 12

    P (x > 5) = 0.6592

Note:A summary for exponential distribution is available in "Summary of The Uniform and Exponential
Probability Distributions".

Glossary

Exponential Distribution

       A continuous random variable (RV) that appears when we are interested in the intervals of time between

       some random events, for example, the length of time between emergency arrivals at a hospital. Notation:

       X~Exp(m). The mean is  =              1  and the standard deviation is  =          1   .  The  probability  density  function  is
                                            m                                            m

       f(x) = me-mx, x  0 and the cumulative distribution function is P (X  x) = 1 - e-mx.
Summary of the Uniform and Exponential Probability Distributions
This module provides a summary of formulas and definitions related to Continuous Random
Variables.
Formula
Uniform

X = a real number between a and b (in some instances, X can take on the values a and b). a =
smallest X ; b = largest X

X ~ U (a,b)

The mean is  = 2 a+b

                                                                                                                (b-a)2

                                                                       

The standard deviation is  = 12

Probability density function: f(X) =                                                                                       1  for a  X  b
                                                                                                                        b-a

Area to the Left of x: P (X < x) = (base)(height)

Area to the Right of x: P (X > x) = (base)(height)

Area Between c and d: P (c < X < d) = (base)(height) = (d - c)(height).
Formula
Exponential

X ~ Exp(m)

X = a real number, 0 or larger. m = the parameter that controls the rate of decay or decline

The mean and standard deviation are the same.

 =  = 1 and m = = 1 1
m                      

The probability density function: f(X) = m  , e-mX X 0

Area to the Left of x: P (X < x) = 1 - e-mx

Area to the Right of x: P (X > x) = e-mx

Area Between c and d:

P (c < X < d) = P (X < d) - P (X < c) = (1 - e                                                                                - md) - (1 - e- mc)=e- mc  -e- md

                                                                  LN(1-AreaToTheLef t)

Percentile, k: k =
                                                                                            -m
The Normal Distribution

Student Learning Outcomes

By the end of this chapter, the student should be able to:

      Recognize the normal probability distribution and apply it
      appropriately.
      Recognize the standard normal probability distribution and apply it
      appropriately.
      Compare normal probabilities by converting to the standard normal
      distribution.

Introduction

The normal, a continuous distribution, is the most important of all the
distributions. It is widely used and even more widely abused. Its graph is
bell-shaped. You see the bell curve in almost all disciplines. Some of these
include psychology, business, economics, the sciences, nursing, and, of
course, mathematics. Some of your instructors may use the normal
distribution to help determine your grade. Most IQ scores are normally
distributed. Often real estate prices fit a normal distribution. The normal
distribution is extremely important but it cannot be applied to everything in
the real world.

In this chapter, you will study the normal distribution, the standard normal,
and applications associated with them.

Optional Collaborative Classroom Activity

Your instructor will record the heights of both men and women in your
class, separately. Draw histograms of your data. Then draw a smooth curve
through each histogram. Is each curve somewhat bell-shaped? Do you think
that if you had recorded 200 data values for men and 200 for women that
the curves would look bell-shaped? Calculate the mean for each data set.
Write the means on the x-axis of the appropriate graph below the peak.
Shade the approximate area that represents the probability that one
randomly chosen male is taller than 72 inches. Shade the approximate area
that represents the probability that one randomly chosen female is shorter
than 60 inches. If the total area under each curve is one, does either
probability appear to be more than 0.5?

The normal distribution has two parameters (two numerical descriptive
measures), the mean () and the standard deviation (). If X is a quantity to
be measured that has a normal distribution with mean () and the standard
deviation (), we designate this by writing

NORMAL:X~N(, )

The probability density function is a rather complicated function. Do not
memorize it. It is not necessary.

                   1  x- 2

f (x) =         1   e- 2 (  )
         2

The cumulative distribution function is P (X < x) . It is calculated either
by a calculator or a computer or it is looked up in a table. Technology has
made the tables basically obsolete. For that reason, as well as the fact that
there are various table formats, we are not including table instructions in
this chapter. See the NOTE in this chapter in Calculation of Probabilities.

The curve is symmetrical about a vertical line drawn through the mean, .
In theory, the mean is the same as the median since the graph is symmetric
about . As the notation indicates, the normal distribution depends only on
the mean and the standard deviation. Since the area under the curve must
equal one, a change in the standard deviation, , causes a change in the
shape of the curve; the curve becomes fatter or skinnier depending on . A
change in  causes the graph to shift to the left or right. This means there
are an infinite number of normal probability distributions. One of special
interest is called the standard normal distribution.

Glossary

Normal Distribution
      A continuous random variable (RV) with pdf
      f(x) = 1 e-(x-)2/22 , where  is the mean of the distribution and

                      2

       is the standard deviation. Notation: X ~ N(, ). If  = 0 and
       = 1, the RV is called the standard normal distribution.
The Standard Normal Distribution

The standard normal distribution is a normal distribution of
standardized values called z-scores. A z-score is measured in units of
the standard deviation. For example, if the mean of a normal distribution
is 5 and the standard deviation is 2, the value 11 is 3 standard deviations
above (or to the right of) the mean. The calculation is:
Equation:

                                       x =  + (z) = 5 + (3)(2) = 11

The z-score is 3.

The mean for the standard normal distribution is 0 and the standard
deviation is 1. The transformation

x-                     produces the distribution Z~ N(0, 1) . The value x comes

z=

                     

from a normal distribution with mean  and standard deviation .

Glossary

Standard Normal Distribution
      A continuous random variable (RV) X~N(0,1 ).. When X follows the
      standard normal distribution, it is often noted as Z~N(0,1).

z-score

                                                                                                                                                               x-

      The linear transformation of the form z =  . If this transformation
      is applied to any normal distribution X~N(, ) , the result is the
      standard normal distribution Z~N(0,1). If this transformation is
      applied to any specific value x of the RV with mean  and standard
      deviation  , the result is called the z-score of x. Z-scores allow us to
      compare data that are normally distributed but scaled differently.
Z-scores

If X is a normally distributed random variable and X~N(, ), then the z-
score is:
Equation:

                           z=  x-
                                    

The z-score tells you how many standard deviations that the value x is
above (to the right of) or below (to the left of) the mean, . Values of x
that are larger than the mean have positive z-scores and values of x that are
smaller than the mean have negative z-scores. If x equals the mean, then x
has a z-score of 0.

Example:
Suppose X ~ N(5, 6). This says that X is a normally distributed random
variable with mean  = 5 and standard deviation  = 6. Suppose x = 17.
Then:
Equation:

                           x-     17 - 5

                    z=         =          =2

                                  6

This means that x = 17 is 2 standard deviations (2) above or to the
right of the mean  = 5. The standard deviation is  = 6.
Notice that:
Equation:

            5 + 2  6 = 17  (The pattern is  + z = x. )

Now suppose x=1. Then:
Equation:

    x-         1-5

z=          =       = -0.67       (rounded to two decimal places)

               6
This means that x = 1 is 0.67 standard deviations (- 0.67) below or to

the left of the mean  = 5. Notice that:

5 + (-0.67)(6) is approximately equal to 1     (This has the pattern

 + (-0.67) = 1 )

Summarizing, when z is positive, x is above or to the right of  and when

z is negative, x is to the left of or below .

Example:
Some doctors believe that a person can lose 5 pounds, on the average, in a
month by reducing his/her fat intake and by exercising consistently.
Suppose weight loss has a normal distribution. Let X = the amount of
weight lost (in pounds) by a person in a month. Use a standard deviation of
2 pounds. X~N(5, 2). Fill in the blanks.
Exercise:

   Problem:

   Suppose a person lost 10 pounds in a month. The z-score when
   x = 10 pounds is z = 2.5 (verify). This z-score tells you that x = 10
   is ________ standard deviations to the ________ (right or left) of the
   mean _____ (What is the mean?).

   Solution:

   This z-score tells you that x = 10 is 2.5 standard deviations to the
   right of the mean 5.

Exercise:

   Problem:

   Suppose a person gained 3 pounds (a negative weight loss). Then z =
   __________. This z-score tells you that x = -3 is ________ standard
   deviations to the __________ (right or left) of the mean.

   Solution:
   z = -4. This z-score tells you that x = -3 is 4 standard deviations to
   the left of the mean.

Suppose the random variables X and Y have the following normal
distributions: X ~N(5, 6) and Y ~ N(2, 1). If x = 17, then z = 2. (This
was previously shown.) If y = 4, what is z?
Equation:

    y-     4-2      where =2 and =1.

z=      =       =2

           1

The z-score for y = 4 is z = 2. This means that 4 is z = 2 standard
deviations to the right of the mean. Therefore, x = 17 and y = 4 are both 2
(of their) standard deviations to the right of their respective means.
The z-score allows us to compare data that are scaled differently. To
understand the concept, suppose X ~N(5, 6) represents weight gains for
one group of people who are trying to gain weight in a 6 week period and
Y ~N(2, 1) measures the same weight gain for a second group of people.
A negative weight gain would be a weight loss. Since x = 17 and y = 4
are each 2 standard deviations to the right of their means, they represent
the same weight gain relative to their means.

The Empirical Rule
If X is a random variable and has a normal distribution with mean  and
standard deviation  then the Empirical Rule says (See the figure below)

      About 68.27% of the x values lie between -1 and +1 of the mean 
      (within 1 standard deviation of the mean).
      About 95.45% of the x values lie between -2 and +2 of the mean 
      (within 2 standard deviations of the mean).
      About 99.73% of the x values lie between -3 and +3 of the mean 
      (within 3 standard deviations of the mean). Notice that almost all the x
      values lie within 3 standard deviations of the mean.
      The z-scores for +1 and -1 are +1 and -1, respectively.
      The z-scores for +2 and -2 are +2 and -2, respectively.
      The z-scores for +3 and -3 are +3 and -3 respectively.
The Empirical Rule is also known as the 68-95-99.7 Rule.

Example:
Suppose X has a normal distribution with mean 50 and standard deviation
6.

      About 68.27% of the x values lie between -1 = (-1)(6) = -6 and 1 =
      (1)(6) = 6 of the mean 50. The values 50 - 6 = 44 and 50 + 6 = 56 are
      within 1 standard deviation of the mean 50. The z-scores are -1 and
      +1 for 44 and 56, respectively.
      About 95.45% of the x values lie between -2 = (-2)(6) = -12 and 2
      = (2)(6) = 12 of the mean 50. The values 50 - 12 = 38 and 50 + 12 =
      62 are within 2 standard deviations of the mean 50. The z-scores are
      -2 and 2 for 38 and 62, respectively.
      About 99.73% of the x values lie between -3 = (-3)(6) = -18 and 3
      = (3)(6) = 18 of the mean 50. The values 50 - 18 = 32 and 50 + 18 =
      68 are within 3 standard deviations of the mean 50. The z-scores are
      -3 and +3 for 32 and 68, respectively.
Normal Distribution: Areas to the Left and Right of x
The arrow in the graph below points to the area to the left of x. This area is
represented by the probability P (X < x). Normal tables, computers, and
calculators provide or calculate the probability P (X < x).

The area to the right is then P (X > x) = 1 - P (X < x).
Remember, P (X < x) = Area to the left of the vertical line through x.
P (X > x) = 1 - P (X < x) =. Area to the right of the vertical line
through x
P (X < x) is the same as P (X  x) and P (X > x) is the same as
P (X  x) for continuous distributions.
Calculations of Probabilities
Probabilities are calculated by using technology. There are instructions in
the chapter for the TI-83+ and TI-84 calculators.

Note:In the Table of Contents for Collaborative Statistics, entry 15.
Tables has a link to a table of normal probabilities. Use the probability
tables if so desired, instead of a calculator. The tables include instructions
for how to use then.

Example:
If the area to the left is 0.0228, then the area to the right is
1 - 0.0228 = 0.9772.

Example:
The final exam scores in a statistics class were normally distributed with a
mean of 63 and a standard deviation of 5.
Exercise:

   Problem:
   Find the probability that a randomly selected student scored more than
   65 on the exam.

   Solution:
   Let X = a score on the final exam. X~N (63, 5), where  = 63 and

      =5

   Draw a graph.
   Then, find P (x > 65).
P (x > 65) = 0.3446 (calculator or computer)

The probability that one student scores more than 65 is 0.3446.

Using the TI-83+ or the TI-84 calculators, the calculation is as
follows. Go into 2nd DISTR.

After pressing 2nd DISTR, press 2:normalcdf.

The syntax for the instructions are shown below.

normalcdf(lower value, upper value, mean, standard deviation) For

this problem: normalcdf(65,1E99,63,5) = 0.3446. You get 1E99 ( =

1099) by pressing 1, the EE key (a 2nd key) and then 99. Or, you can

enter  10^99  instead.  The  number                       99  is  way  out   in    the  right  tail  of

                                                  10

the normal curve. We are calculating the area between 65 and 1099. In

some instances, the lower number of the area might be -1E99 ( =

-1099).  The  number                 99  is  way  out         in  the  left  tail  of  the  normal

                      -10

curve.

Note:The TI probability program calculates a z-score and then the
probability from the z-score. Before technology, the z-score was
looked up in a standard normal probability table (because the math
involved is too cumbersome) to find the probability. In this example,
a standard normal table with area to the left of the z-score was used.
You calculate the z-score and look up the area to the left. The
probability is the area to the right.

z=  65-63  = 0.4  . Area to the left is 0.6554.

    5

P (x > 65) = P (z > 0.4) = 1 - 0.6554 = 0.3446

Exercise:

Problem:

Find the probability that a randomly selected student scored less than
85.

Solution:

Draw a graph.

Then find P (x < 85). Shade the graph. P (x < 85) = 1 (calculator
or computer)

The probability that one student scores less than 85 is approximately 1
(or 100%).

The TI-instructions and answer are as follows:

   normalcdf(0,85,63,5) = 1 (rounds to 1)
Exercise:

   Problem:

Find the 90th percentile (that is, find the score k that has 90 % of the
scores below k and 10% of the scores above k).

Solution:
   Find the 90th percentile. For each problem or part of a problem, draw
   a new graph. Draw the x-axis. Shade the area that corresponds to the
   90th percentile.
   Let k = the 90th percentile. k is located on the x-axis. P (x < k) is
   the area to the left of k. The 90th percentile k separates the exam
   scores into those that are the same or lower than k and those that are
   the same or higher. Ninety percent of the test scores are the same or
   lower than k and 10% are the same or higher. k is often called a
   critical value.
   k = 69.4 (calculator or computer)

   The 90th percentile is 69.4. This means that 90% of the test scores fall
   at or below 69.4 and 10% fall at or above. For the TI-83+ or TI-84
   calculators, use invNorm in 2nd DISTR. invNorm(area to the left,
   mean, standard deviation) For this problem, invNorm(0.90,63,5) =
   69.4
Exercise:
   Problem:
   Find the 70th percentile (that is, find the score k such that 70% of
   scores are below k and 30% of the scores are above k).
   Solution:
Find the 70th percentile.
Draw a new graph and label it appropriately. k = 65.6
The 70th percentile is 65.6. This means that 70% of the test scores fall
at or below 65.5 and 30% fall at or above.
invNorm(0.70,63,5) = 65.6

Example:
A computer is used for office work at home, research, communication,
personal finances, education, entertainment, social networking and a
myriad of other things. Suppose that the average number of hours a
household personal computer is used for entertainment is 2 hours per day.
Assume the times for entertainment are normally distributed and the
standard deviation for the times is half an hour.
Exercise:

   Problem:

Find the probability that a household personal computer is used
between 1.8 and 2.75 hours per day.

Solution:

Let X = the amount of time (in hours) a household personal computer
is used for entertainment. x~N (2, 0.5) where  = 2 and  = 0.5.

Find P (1.8 < x < 2.75).

The probability for which you are looking is the area between

x = 1.8 and x = 2.75.     P (1.8 < x < 2.75) = 0.5886
   normalcdf(1.8,2.75,2,0.5) = 0.5886
   The probability that a household personal computer is used between
   1.8 and 2.75 hours per day for entertainment is 0.5886.
Exercise:
   Problem:
   Find the maximum number of hours per day that the bottom quartile
   of households use a personal computer for entertainment.
   Solution:
   To find the maximum number of hours per day that the bottom
   quartile of households uses a personal computer for entertainment,
   find the 25th percentile, k, where P (x < k) = 0.25.

   invNorm(0.25,2,.5) = 1.66
The maximum number of hours per day that the bottom quartile of
households uses a personal computer for entertainment is 1.66 hours.
Summary of Formulas
Formula
Normal Probability Distribution

X~N (, )

 = the mean  = the standard deviation
Formula
Standard Normal Probability Distribution

Z~N (0, 1)

z = a standardized value (z-score)

mean = 0    standard deviation = 1

Formula

Finding the kth Percentile

To find the kth percentile when the z-score is known: k =  + (z)
Formula
z-score

z=  x-
        

Formula

Finding the area to the left

The area to the left: P (X < x)
Formula
Finding the area to the right

The area to the right: P (X > x) = 1 - P (X < x)
The Central Limit Theorem
This module provides a brief introduction to the Central Limit Theorem.

Student Learning Outcomes

By the end of this chapter, the student should be able to:

      Recognize the Central Limit Theorem problems.
      Classify continuous word problems by their distributions.
      Apply and interpret the Central Limit Theorem for Means.
      Apply and interpret the Central Limit Theorem for Sums.

Introduction

Why are we so concerned with means? Two reasons are that they give us a
middle ground for comparison and they are easy to calculate. In this
chapter, you will study means and the Central Limit Theorem.

The Central Limit Theorem (CLT for short) is one of the most powerful
and useful ideas in all of statistics. Both alternatives are concerned with
drawing finite samples of size n from a population with a known mean, ,
and a known standard deviation, . The first alternative says that if we
collect samples of size n and n is "large enough," calculate each sample's
mean, and create a histogram of those means, then the resulting histogram
will tend to have an approximate normal bell shape. The second alternative
says that if we again collect samples of size n that are "large enough,"
calculate the sum of each sample and create a histogram, then the resulting
histogram will again tend to have a normal bell-shape.

In either case, it does not matter what the distribution of the original
population is, or whether you even need to know it. The important fact
is that the sample means and the sums tend to follow the normal
distribution. And, the rest you will learn in this chapter.

The size of the sample, n, that is required in order to be to be 'large enough'
depends on the original population from which the samples are drawn. If
the original population is far from normal then more observations are
needed for the sample means or the sample sums to be normal. Sampling is
done with replacement.

Optional Collaborative Classroom Activity

Do the following example in class: Suppose 8 of you roll 1 fair die 10
times, 7 of you roll 2 fair dice 10 times, 9 of you roll 5 fair dice 10 times,
and 11 of you roll 10 fair dice 10 times.

Each time a person rolls more than one die, he/she calculates the sample
mean of the faces showing. For example, one person might roll 5 fair dice
and get a 2, 2, 3, 4, 6 on one roll.

The mean is  . 2+2+3+4+6                       The 3.4 is one mean when 5 fair dice

                                        = 3.4
             5

are rolled. This same person would roll the 5 dice 9 more times and

calculate 9 more means for a total of 10 means.

Your instructor will pass out the dice to several people as described above.
Roll your dice 10 times. For each roll, record the faces and find the mean.
Round to the nearest 0.5.

Your instructor (and possibly you) will produce one graph (it might be a
histogram) for 1 die, one graph for 2 dice, one graph for 5 dice, and one
graph for 10 dice. Since the "mean" when you roll one die, is just the face
on the die, what distribution do these means appear to be representing?

Draw the graph for the means using 2 dice. Do the sample means show
any kind of pattern?

Draw the graph for the means using 5 dice. Do you see any pattern
emerging?

Finally, draw the graph for the means using 10 dice. Do you see any
pattern to the graph? What can you conclude as you increase the number of
dice?

As the number of dice rolled increases from 1 to 2 to 5 to 10, the following
is happening:
   1. The mean of the sample means remains approximately the same.
   2. The spread of the sample means (the standard deviation of the sample

      means) gets smaller.
   3. The graph appears steeper and thinner.

You have just demonstrated the Central Limit Theorem (CLT).

The Central Limit Theorem tells you that as you increase the number of
dice, the sample means tend toward a normal distribution (the
sampling distribution).

Glossary

Average
      A number that describes the central tendency of the data. There are a
      number of specialized averages, including the arithmetic mean,
      weighted mean, median, mode, and geometric mean.

Central Limit Theorem

Given a random variable (RV) with known mean  and known

standard deviation . We are sampling with size n and we are

interested in two new RVs - the sample mean, X , and the sample sum,
X. If the size n of the sample is sufficiently large, then X 

N (,              and X  N(n, n). If the size n of the sample is

               )

          n

sufficiently large, then the distribution of the sample means and the

distribution of the sample sums will approximate a normal distribution

regardless of the shape of the population. The mean of the sample

means will equal the population mean and the mean of the sample

sums will equal n times the population mean. The standard deviation

of the distribution of the sample means,   , is called the standard

                                          n

error of the mean.
The Central Limit Theorem for Sample Means (Averages)

Suppose X is a random variable with a distribution that may be known or
unknown (it can be any distribution). Using a subscript that matches the
random variable, suppose:

      aX = the mean of X
      bX = the standard deviation of X

If you draw random samples of size n, then as n increases, the random
variable X which consists of sample means, tends to be normally
distributed and

~ X
X N (X ,     )

          n

The Central Limit Theorem for Sample Means says that if you keep
drawing larger and larger samples (like rolling 1, 2, 5, and, finally, 10 dice)
and calculating their means the sample means form their own normal
distribution (the sampling distribution). The normal distribution has the
same mean as the original distribution and a variance that equals the
original variance divided by n, the sample size. n is the number of values
that are averaged together not the number of times the experiment is done.

To put it more formally, if you draw random samples of size n,the

distribution of the random variable X, which consists of sample means, is
called the sampling distribution of the mean. The sampling distribution of
the mean approaches a normal distribution as n, the sample size, increases.

The random variable X has a different z-score associated with it than the
random variable X. x is the value of X in one sample.
Equation:

                    x - X

                z=

                       X

                    (     )

                       n
X is both the average of X and of X.

=       X  = standard deviation of X and is called the standard error of

     X  n

the mean.

Example:
An unknown distribution has a mean of 90 and a standard deviation of 15.
Samples of size n = 25 are drawn randomly from the population.
Exercise:

   Problem:

   Find the probability that the sample mean is between 85 and 92.

   Solution:

   Let X = one value from the original unknown population. The
   probability question asks you to find a probability for the sample
   mean.

   Let X = the mean of a sample of size 25. Since X = 90, X = 15,
   and n = 25;

then X ~ N (90, ) 15                                           Draw a graph.
                                                           25

Find P (85 < x < 92)

P (85 < x < 92) = 0.6997

The probability that the sample mean is between 85 and 92 is 0.6997.
TI-83 or 84: normalcdf(lower value, upper value, mean, standard
error of the mean)

The parameter list is abbreviated (lower value, upper value, ,                                                  )
                                                                                                                  n
                                                                                                                

   normalcdf(85,92,90, 15 ) = 0.6997
                                                                                           25

Exercise:
   Problem:

   Find the value that is 2 standard deviations above the expected value
   (it is 90) of the sample mean.

Solution:

To find the value that is 2 standard deviations above the expected
value 90, use the formula

value = X + (#of STDEVs)( ) X
                                                                                                             n

value = 90 + 2  15 = 96

                                                          25
So, the value that is 2 standard deviations above the expected value is
96.

Example:
The length of time, in hours, it takes an "over 40" group of people to play
one soccer match is normally distributed with a mean of 2 hours and a
standard deviation of 0.5 hours. A sample of size n = 50 is drawn
randomly from the population.
Exercise:

   Problem:

   Find the probability that the sample mean is between 1.8 hours and
   2.3 hours.

   Solution:

   Let X = the time, in hours, it takes to play one soccer match.

   The probability question asks you to find a probability for the sample
   mean time, in hours, it takes to play one soccer match.

   Let X = the mean time, in hours, it takes to play one soccer match.

   If X = _________, X = __________, and n = ___________, then
   X~N (______, ______) by the Central Limit Theorem for Means.

X = 2, X = 0.5, n = 50, and X~N (2, ) 0.5

                                                                                                                                               50

Find P (1.8 < x < 2.3).  Draw a graph.

P (1.8 < x < 2.3) = 0.9977

normalcdf(1.8,2.3,2, .5 ) = 0.9977
                                                                                   50
The probability that the mean time is between 1.8 hours and 2.3 hours
is ______.

Glossary

Average
      A number that describes the central tendency of the data. There are a
      number of specialized averages, including the arithmetic mean,
      weighted mean, median, mode, and geometric mean.

Central Limit Theorem

Given a random variable (RV) with known mean  and known

standard deviation . We are sampling with size n and we are

interested in two new RVs - the sample mean, X , and the sample sum,
X. If the size n of the sample is sufficiently large, then X 

N (,              and X  N(n, n). If the size n of the sample is

               )

          n

sufficiently large, then the distribution of the sample means and the

distribution of the sample sums will approximate a normal distribution

regardless of the shape of the population. The mean of the sample

means will equal the population mean and the mean of the sample

sums will equal n times the population mean. The standard deviation

of the distribution of the sample means,   , is called the standard

                                          n

error of the mean.

Normal Distribution
      A continuous random variable (RV) with pdf
      f(x) = 1 e-(x-)2/22 , where  is the mean of the distribution and

                      2

       is the standard deviation. Notation: X ~ N(, ). If  = 0 and
       = 1, the RV is called the standard normal distribution.

Standard Error of the Mean

      The standard deviation of the distribution of the sample means,  .

                                                                                                                                                                                                                                     n
The Central Limit Theorem for Sums

Suppose X is a random variable with a distribution that may be known or
unknown (it can be any distribution) and suppose:

      a X = the mean of X
      b X = the standard deviation of X

If you draw random samples of size n, then as n increases, the random
variable X which consists of sums tends to be normally distributed and

X ~ N (n  X , n  X )

The Central Limit Theorem for Sums says that if you keep drawing
larger and larger samples and taking their sums, the sums form their own
normal distribution (the sampling distribution) which approaches a normal
distribution as the sample size increases. The normal distribution has a
mean equal to the original mean multiplied by the sample size and a
standard deviation equal to the original standard deviation multiplied
by the square root of the sample size.

The random variable X has the following z-score associated with it:

ax is one sum.

bz =  x-nX
         nX

an  X = the mean of X
b n  X = standard deviation of X

Example:
An unknown distribution has a mean of 90 and a standard deviation of 15.
A sample of size 80 is drawn randomly from the population.
Exercise:

   Problem:
      aFind the probability that the sum of the 80 values (or the total of
      the 80 values) is more than 7500.
      bFind the sum that is 1.5 standard deviations above the mean of
      the sums.

Solution:

Let X = one value from the original unknown population. The
probability question asks you to find a probability for the sum (or
total of) 80 values.

X = the sum or total of 80 values. Since X = 90, X = 15, and
n = 80, then

X ~ N (80  90, 80  15)

      mean of the sums = n  X = (80)(90) = 7200
      standard deviation of the sums = n  X = 80  15
      sum of 80 values = x = 7500

      aFind P (x > 7500)

P (x > 7500) = 0.0127
normalcdf(lower value, upper value, mean of sums, stdev of
sums)
The parameter list is abbreviated (lower, upper, n  X, n  X)
normalcdf(7500,1E99, 80  90, 80  15) = 0.0127

Reminder: 1E99 = 1099. Press the EE key for E.

   bFind x where z = 1.5:

x = n  X + z  n  X = (80)(90) + (1.5)(80) (15) = 7401.2

Glossary

Central Limit Theorem

Given a random variable (RV) with known mean  and known

standard deviation . We are sampling with size n and we are

interested in two new RVs - the sample mean, X , and the sample sum,
X. If the size n of the sample is sufficiently large, then X 

N (, )  and X  N (n, n). If the size n of the sample is
                       n

sufficiently large, then the distribution of the sample means and the

distribution of the sample sums will approximate a normal distribution

regardless of the shape of the population. The mean of the sample

means will equal the population mean and the mean of the sample

sums will equal n times the population mean. The standard deviation

of the distribution of the sample means,       ,  is  called  the  standard
                                            n
                                          

error of the mean.

Normal Distribution
A continuous random variable (RV) with pdf
f(x) = 1 e-(x-)2/22 , where  is the mean of the distribution and

              2

 is the standard deviation. Notation: X ~ N(, ). If  = 0 and
 = 1, the RV is called the standard normal distribution.
Using the Central Limit Theorem
Central Limit Theorem: Using the Central Limit Theorem is part of the
collection col10555 written by Barbara Illowsky and Susan Dean. It covers
how and when to use the Central Limit Theorem and has contributions from
Roberta Bloom.

It is important for you to understand when to use the CLT. If you are being
asked to find the probability of the mean, use the CLT for the mean. If you
are being asked to find the probability of a sum or total, use the CLT for
sums. This also applies to percentiles for means and sums.

Note:If you are being asked to find the probability of an individual value,
do not use the CLT. Use the distribution of its random variable.

Examples of the Central Limit Theorem

Law of Large Numbers

The Law of Large Numbers says that if you take samples of larger and

larger size from any population, then the mean x of the sample tends to get

closer and closer to . From the Central Limit Theorem, we know that as n

gets larger and larger, the sample means follow a normal distribution. The

larger n gets, the smaller the standard deviation gets. (Remember that the

standard deviation for X  is      .) This means that the sample mean x must
                              n

be close to the population mean . We can say that  is the value that the

sample means approach as n gets larger. The Central Limit Theorem

illustrates the Law of Large Numbers.

Central Limit Theorem for the Mean and Sum Examples

Example:
A study involving stress is done on a college campus among the students.
The stress scores follow a uniform distribution with the lowest stress
score equal to 1 and the highest equal to 5. Using a sample of 75 students,
find:

1. The probability that the mean stress score for the 75 students is less
  than 2.

2. The 90th percentile for the mean stress score for the 75 students.
3. The probability that the total of the 75 stress scores is less than 200.
4. The 90th percentile for the total stress score for the 75 students.

Let X = one stress score.

Problems 1. and 2. ask you to find a probability or a percentile for a mean.

Problems 3 and 4 ask you to find a probability or a percentile for a total or

sum. The sample size, n, is equal to 75.

Since the individual stress scores follow a uniform distribution, X ~

U(1, 5) where a = 1 and b = 5 (See Continuous Random Variables for the

uniform).

       a+b  1+5

X = 2 = 2 = 3

X  =             (b-a)2                       (5-1)2    = 1.15

                           =

                       12                           12

For problems 1. and 2., let X = the mean stress score for the 75 students.

Then,

X ~ N (3, ) 1.15                           where n = 75.

                                       75

Exercise:

Problem: Find P (x < 2).                                Draw the graph.

Solution:

P (x < 2) = 0

The probability that the mean stress score is less than 2 is about 0.
   normalcdf (1, 2, 3, ) 1.15 = 0
                                                                                      75

   Note:The smallest stress score is 1. Therefore, the smallest mean for
   75 stress scores is 1.

Exercise:
   Problem:
   Find the 90th percentile for the mean of 75 stress scores. Draw a
   graph.
   Solution:
   Let k = the 90th precentile.
   Find k where P (x < k) = 0.90.

     k = 3.2
   The 90th percentile for the mean of 75 scores is about 3.2. This tells
   us that 90% of all the means of 75 stress scores are at most 3.2 and
   10% are at least 3.2.

   invNorm (.90, 3, ) = 3.2 1.15
                                                                          75

For problems c and d, let X = the sum of the 75 stress scores. Then, X
~ N [(75)  (3), 75  1.15]
Exercise:

Problem: Find P (x < 200).  Draw the graph.

Solution:
The mean of the sum of 75 stress scores is 75  3 = 225
The standard deviation of the sum of 75 stress scores is

75  1.15 = 9.96

P (x < 200) = 0
   The probability that the total of 75 scores is less than 200 is about 0.
   normalcdf (75, 200, 75  3, 75  1.15) = 0.

   Note: The smallest total of 75 stress scores is 75 since the smallest
   single score is 1.

Exercise:
   Problem:
   Find the 90th percentile for the total of 75 stress scores. Draw a graph.
   Solution:
   Let k = the 90th percentile.
   Find k where P (x < k) = 0.90.

     k = 237.8
   The 90th percentile for the sum of 75 scores is about 237.8. This tells
   us that 90% of all the sums of 75 scores are no more than 237.8 and
   10% are no less than 237.8.

   invNorm (.90, 75  3, 75  1.15) = 237.8

Example:
Suppose that a market research analyst for a cell phone company conducts
a study of their customers who exceed the time allowance included on their
basic cell phone contract; the analyst finds that for those people who
exceed the time included in their basic contract, the excess time used
follows an exponential distribution with a mean of 22 minutes.
Consider a random sample of 80 customers who exceed the time allowance
included in their basic cell phone contract.
Let X = the excess time used by one INDIVIDUAL cell phone customer
who exceeds his contracted time allowance.
X ~ Exp( 22 ) 1 From Chapter 5, we know that  = 22 and  = 22.
Let X = the mean excess time used by a sample of n = 80 customers who
exceed their contracted time allowance.
X ~ N (22, 22 ) by the CLT for Sample Means

                                           80

Exercise:

   Problem:
   Using the CLT to find Probability:
aFind the probability that the mean excess time used by the 80

customers in the sample is longer than 20 minutes. This is asking

us to find P (x > 20)  Draw the graph.

b Suppose that one customer who exceeds the time limit for his

cell phone contract is randomly selected. Find the probability

that this individual customer's excess time is longer than 20

minutes. This is asking us to find P (x > 20)

c Explain why the probabilities in (a) and (b) are different.

Solution:

Part a.
Find: P (x > 20)

P (x > 20) = 0.7919 using normalcdf (20, 1E99, 22, ) 22
                                                                                                                                                                                                    80

The probability is 0.7919 that the mean excess time used is more than
20 minutes, for a sample of 80 customers who exceed their contracted
time allowance.

Note:1E99 = 1099and-1E99 = -1099. Press the
EE
key for E. Or just use 10^99 instead of 1E99.
   Part b.
   Find P(x>20) . Remember to use the exponential distribution for an
   individual: X~Exp(1/22).

   P(X>20) = e^(-(1/22)*20) or e^(-.04545*20) = 0.4029
   Part c. Explain why the probabilities in (a) and (b) are different.

         P (x > 20) = 0.4029 but P (x > 20) = 0.7919
         The probabilities are not equal because we use different
         distributions to calculate the probability for individuals and for
         means.
         When asked to find the probability of an individual value, use the
         stated distribution of its random variable; do not use the CLT.
         Use the CLT with the normal distribution when you are being
         asked to find the probability for an mean.

Exercise:
   Problem:

   Using the CLT to find Percentiles:
   Find the 95th percentile for the sample mean excess time for samples
   of 80 customers who exceed their basic contract time allowances.
   Draw a graph.

   Solution:

   Let k = the 95th percentile. Find k where P (x < k) = 0.95

   k = 26.0 using invNorm(.95, 22, ) 22 = 26.0
                                                                                                                                  80
   The 95th percentile for the sample mean excess time used is about
   26.0 minutes for random samples of 80 customers who exceed their
   contractual allowed time.

   95% of such samples would have means under 26 minutes; only 5%
   of such samples would have means above 26 minutes.

Note:(HISTORICAL): Normal Approximation to the Binomial

Historically, being able to compute binomial probabilities was one of the
most important applications of the Central Limit Theorem. Binomial
probabilities were displayed in a table in a book with a small value for n
(say, 20). To calculate the probabilities with large values of n, you had to
use the binomial formula which could be very complicated. Using the
Normal Approximation to the Binomial simplified the process. To
compute the Normal Approximation to the Binomial, take a simple random
sample from a population. You must meet the conditions for a binomial
distribution:

      there are a certain number n of independent trials
      the outcomes of any trial are success or failure
      each trial has the same probability of a success p

Recall that if X is the binomial random variable, then X~B(n, p). The
shape of the binomial distribution needs to be similar to the shape of the
normal distribution. To ensure this, the quantities np and nq must both be
greater than five (np > 5 and nq > 5; the approximation is better if they
are both greater than or equal to 10). Then the binomial can be
approximated by the normal distribution with mean  = np and standard
deviation  = npq. Remember that q = 1 - p. In order to get the best
approximation, add 0.5 to x or subtract 0.5 from x ( use x + 0.5 or x - 0.5
). The number 0.5 is called the continuity correction factor.

Example:
Suppose in a local Kindergarten through 12th grade (K - 12) school
district, 53 percent of the population favor a charter school for grades K -
5. A simple random sample of 300 is surveyed.

   1. Find the probability that at least 150 favor a charter school.
   2. Find the probability that at most 160 favor a charter school.
   3. Find the probability that more than 155 favor a charter school.
   4. Find the probability that less than 147 favor a charter school.
   5. Find the probability that exactly 175 favor a charter school.

Let X= the number that favor a charter school for grades K - 5. X~
B(n, p) where n =300 and p = 0.53. Since np > 5 and nq > 5, use the
normal approximation to the binomial. The formulas for the mean and
standard deviation are  = np and  = npq. The mean is 159 and the
standard deviation is 8.6447. The random variable for the normal
distribution is Y . Y ~N (159, 8.6447). See The Normal Distribution for
help with calculator instructions.
For Problem 1., you include 150 so P (x  150) has normal
approximation P (Y  149.5)=0.8641.
normalcdf (149.5, 10^99, 159, 8.6447) = 0.8641.
For Problem 2., you include 160 so P (x  160) has normal
approximation P (Y  160.5)=0.5689.
normalcdf (0, 160.5, 159, 8.6447) = 0.5689
For Problem 3., you exclude 155 so P (x > 155) has normal
approximation P (y > 155.5)=0.6572.
normalcdf (155.5, 10^99, 159, 8.6447) = 0.6572
For Problem 4., you exclude 147 so P (x < 147) has normal
approximation P (Y < 146.5)=0.0741.
normalcdf (0, 146.5, 159, 8.6447) = 0.0741
For Problem 5., P (x=175) has normal approximation
P (174.5 < y < 175.5)=0.0083.
normalcdf (174.5, 175.5, 159, 8.6447) = 0.0083
Because of calculators and computer software that easily let you
calculate binomial probabilities for large values of n, it is not necessary to
use the the Normal Approximation to the Binomial provided you have
access to these technology tools. Most school labs have Microsoft Excel,
an example of computer software that calculates binomial probabilities.
Many students have access to the TI-83 or 84 series calculators and they
easily calculate probabilities for the binomial. In an Internet browser, if
you type in "binomial probability distribution calculation," you can find at
least one online calculator for the binomial.
For Example 3, the probabilities are calculated using the binomial (n=300
and p=0.53) below. Compare the binomial and normal distribution
answers. See Discrete Random Variables for help with calculator
instructions for the binomial.
P (x  150): 1 - binomialcdf (300, 0.53, 149)=0.8641
P (x  160): binomialcdf (300, 0.53, 160)=0.5684
P (x > 155): 1 - binomialcdf (300, 0.53, 155)=0.6576
P (x < 147): binomialcdf (300, 0.53, 146)=0.0742
P (x=175): (You use the binomial pdf.) binomialpdf

(175, 0.53, 146)=0.0083

**Contributions made to Example 2 by Roberta Bloom

Glossary
Average
      A number that describes the central tendency of the data. There are a
      number of specialized averages, including the arithmetic mean,
      weighted mean, median, mode, and geometric mean.

Central Limit Theorem

Given a random variable (RV) with known mean  and known

standard deviation . We are sampling with size n and we are

interested in two new RVs - the sample mean, X , and the sample sum,
X. If the size n of the sample is sufficiently large, then X 

N (,          and X  N(n, n). If the size n of the sample is

           )

      n

sufficiently large, then the distribution of the sample means and the

distribution of the sample sums will approximate a normal distribution

regardless of the shape of the population. The mean of the sample

means will equal the population mean and the mean of the sample

sums will equal n times the population mean. The standard deviation

of the distribution of the sample means,   , is called the standard

                                          n

error of the mean.

Exponential Distribution

A continuous random variable (RV) that appears when we are

interested in the intervals of time between some random events, for

example, the length of time between emergency arrivals at a hospital.

Notation: X~Exp(m). The mean is  =         1  and the standard deviation
                                          m

is  = 1 . The probability density function is f(x) = me-mx, x  0
                         m

and the cumulative distribution function is P (X  x) = 1 - e-mx.

Mean

A number that measures the central tendency. A common name for

mean is 'average.' The term 'mean' is a shortened form of 'arithmetic

mean.' By definition, the mean for a sample (denoted by x) is

x = Sum of all values in the sample , and the mean for a population
                  Number of values in the sample

(denoted by ) is . Sum of all values in the population
                      =   Number of values in the population

Uniform Distribution
A continuous random variable (RV) that has equally likely outcomes
over the domain, a < x < b. Often referred as the Rectangular
distribution because the graph of the pdf has the form of a rectangle.
Notation: X~U(a,b). The mean is  = 2 a+b and the standard deviation

                 (b-a)2 1

       
is  =  12 The probability density function is f(x) = b-a for

a < x < b or a  x  b. The cumulative distribution is

                  . x-a

P (X  x) =

                                                  b-a
Summary of Formulas
Formula
Central Limit Theorem for Sample Means

~ X                The Mean (X ): X
X N(X,          )

             n

Formula

Central Limit Theorem for Sample Means Z-Score and Standard Error of

the Mean

z=  x-X         Standard Error of the Mean (Standard Deviation

       X

    (     )

       n

(X )): X
                                    n

Formula
Central Limit Theorem for Sums

X ~ N [(n)  X, n  X] Mean for Sums (X): n  X
Formula
Central Limit Theorem for Sums Z-Score and Standard Deviation for Sums

z=  x-nX           Standard Deviation for Sums (X):  n  X
       nX
Hypothesis Testing: Single Mean and Single Proportion

Student Learning Outcomes

By the end of this chapter, the student should be able to:

      Differentiate between Type I and Type II Errors
      Describe hypothesis testing in general and in practice
      Conduct and interpret hypothesis tests for a single population mean,
      population standard deviation known.
      Conduct and interpret hypothesis tests for a single population mean,
      population standard deviation unknown.
      Conduct and interpret hypothesis tests for a single population
      proportion.

Introduction

One job of a statistician is to make statistical inferences about populations
based on samples taken from the population. Confidence intervals are one
way to estimate a population parameter. Another way to make a statistical
inference is to make a decision about a parameter. For instance, a car dealer
advertises that its new small truck gets 35 miles per gallon, on the average.
A tutoring service claims that its method of tutoring helps 90% of its
students get an A or a B. A company says that women managers in their
company earn an average of $60,000 per year.

A statistician will make a decision about these claims. This process is called
"hypothesis testing." A hypothesis test involves collecting data from a
sample and evaluating the data. Then, the statistician makes a decision as to
whether or not there is sufficient evidence based upon analyses of the data,
to reject the null hypothesis.

In this chapter, you will conduct hypothesis tests on single means and single
proportions. You will also learn about the errors associated with these tests.

Hypothesis testing consists of two contradictory hypotheses or statements, a
decision based on the data, and a conclusion. To perform a hypothesis test, a
statistician will:

   1. Set up two contradictory hypotheses.
   2. Collect sample data (in homework problems, the data or summary

      statistics will be given to you).
   3. Determine the correct distribution to perform the hypothesis test.
   4. Analyze sample data by performing the calculations that ultimately

      will allow you to reject or fail to reject the null hypothesis.
   5. Make a decision and write a meaningful conclusion.

Note:To do the hypothesis test homework problems for this chapter and
later chapters, make copies of the appropriate special solution sheets. See
the Table of Contents topic "Solution Sheets".

Glossary

Confidence Interval (CI)
      An interval estimate for an unknown population parameter. This
      depends on:

            The desired confidence level.
            Information that is known about the distribution (for example,
            known standard deviation).
            The sample and its size.

Hypothesis Testing
      Based on sample evidence, a procedure to determine whether the
      hypothesis stated is a reasonable statement and cannot be rejected, or
      is unreasonable and should be rejected.
Null and Alternate Hypotheses

The actual test begins by considering two hypotheses. They are called the
null hypothesis and the alternate hypothesis. These hypotheses contain
opposing viewpoints.

Ho: The null hypothesis: It is a statement about the population that will be
assumed to be true unless it can be shown to be incorrect beyond a
reasonable doubt.

Ha: The alternate hypothesis: It is a claim about the population that is
contradictory to Ho and what we conclude when we reject Ho.

Example:
Ho: No more than 30% of the registered voters in Santa Clara County
voted in the primary election.
Ha: More than 30% of the registered voters in Santa Clara County voted in
the primary election.

Example:

We want to test whether the mean grade point average in American

colleges is different from 2.0 (out of 4.0).

Ho:  = 2.0  Ha:   2.0

Example:

We want to test if college students take less than five years to graduate

from college, on the average.

Ho:   5     Ha:  < 5

Example:
In an issue of U. S. News and World Report, an article on school

standards stated that about half of all students in France, Germany, and

Israel take advanced placement exams and a third pass. The same article

stated that 6.6% of U. S. students take advanced placement exams and 4.4

% pass. Test if the percentage of U. S. students who take advanced

placement exams is more than 6.6%.

Ho: p= 0.066  Ha: p > 0.066

Since the null and alternate hypotheses are contradictory, you must examine
evidence to decide if you have enough evidence to reject the null hypothesis
or not. The evidence is in the form of sample data.

After you have determined which hypothesis the sample supports, you
make a decision. There are two options for a decision. They are "reject Ho"
if the sample information favors the alternate hypothesis or "do not reject
Ho" or "fail to reject Ho" if the sample information is insufficient to reject
the null hypothesis.

Mathematical Symbols Used in Ho and Ha:

Ho                       Ha

equal (=)                not equal () or greater than (>) or less
                         than (<)
greater than or equal
to ()                    less than (<)
less than or equal to (
)                        more than (>)
Note:Ho always has a symbol with an equal in it. Ha never has a symbol
with an equal in it. The choice of symbol depends on the wording of the
hypothesis test. However, be aware that many researchers (including one of
the co-authors in research work) use = in the Null Hypothesis, even with
> or < as the symbol in the Alternate Hypothesis. This practice is
acceptable because we only make the decision to reject or not reject the
Null Hypothesis.

Optional Collaborative Classroom Activity

Bring to class a newspaper, some news magazines, and some Internet
articles . In groups, find articles from which your group can write a null and
alternate hypotheses. Discuss your hypotheses with the rest of the class.

Glossary

Hypothesis
      A statement about the value of a population parameter. In case of two
      hypotheses, the statement assumed to be true is called the null
      hypothesis (notation H0) and the contradictory statement is called the
      alternate hypothesis (notation Ha).
Outcomes and the Type I and Type II Errors

When you perform a hypothesis test, there are four possible outcomes
depending on the actual truth (or falseness) of the null hypothesis Ho and
the decision to reject or not. The outcomes are summarized in the following
table:

ACTION            Ho IS ACTUALLY   ...
                  True             False
Do not reject Ho  Correct Outcome  Type II error
Reject Ho         Type I Error     Correct Outcome

The four possible outcomes in the table are:

      The decision is to not reject Ho when, in fact, Ho is true (correct
      decision).
      The decision is to reject Ho when, in fact, Ho is true (incorrect
      decision known as a Type I error).
      The decision is to not reject Ho when, in fact, Ho is false (incorrect
      decision known as a Type II error).
      The decision is to reject Ho when, in fact, Ho is false (correct
      decision whose probability is called the Power of the Test).

Each of the errors occurs with a particular probability. The Greek letters 
and  represent the probabilities.

 = probability of a Type I error = P(Type I error) = probability of
rejecting the null hypothesis when the null hypothesis is true.
 = probability of a Type II error = P(Type II error) = probability of not
rejecting the null hypothesis when the null hypothesis is false.

 and  should be as small as possible because they are probabilities of
errors. They are rarely 0.

The Power of the Test is 1 - . Ideally, we want a high power that is as
close to 1 as possible. Increasing the sample size can increase the Power of
the Test.

The following are examples of Type I and Type II errors.

Example:
Suppose the null hypothesis, Ho, is: Frank's rock climbing equipment is
safe.
Type I error: Frank thinks that his rock climbing equipment may not be
safe when, in fact, it really is safe. Type II error: Frank thinks that his
rock climbing equipment may be safe when, in fact, it is not safe.
 = probability that Frank thinks his rock climbing equipment may not be
safe when, in fact, it really is safe.  = probability that Frank thinks his
rock climbing equipment may be safe when, in fact, it is not safe.
Notice that, in this case, the error with the greater consequence is the Type
II error. (If Frank thinks his rock climbing equipment is safe, he will go
ahead and use it.)

Example:
Suppose the null hypothesis, Ho, is: The victim of an automobile accident
is alive when he arrives at the emergency room of a hospital.
Type I error: The emergency crew thinks that the victim is dead when, in
fact, the victim is alive. Type II error: The emergency crew does not
know if the victim is alive when, in fact, the victim is dead.
 = probability that the emergency crew thinks the victim is dead when,
in fact, he is really alive = P(Type I error).  = probability that the
emergency crew does not know if the victim is alive when, in fact, the
victim is dead = P(Type II error).
The error with the greater consequence is the Type I error. (If the
emergency crew thinks the victim is dead, they will not treat him.)

Glossary

Type 1 Error
      The decision is to reject the Null hypothesis when, in fact, the Null
      hypothesis is true.

Type 2 Error
      The decision is to not reject the Null hypothesis when, in fact, the Null
      hypothesis is false.
Distribution Needed for Hypothesis Testing

Earlier in the course, we discussed sampling distributions. Particular
distributions are associated with hypothesis testing. Perform tests of a
population mean using a normal distribution or a student's-t
distribution. (Remember, use a student's-t distribution when the population
standard deviation is unknown and the distribution of the sample mean is
approximately normal.) In this chapter we perform tests of a population
proportion using a normal distribution (usually n is large or the sample size
is large).

If you are testing a single population mean, the distribution for the test is
for means:

X ~ N (X , ) X or tdf
                                              n

The population parameter is . The estimated value (point estimate) for  is
x, the sample mean.

If you are testing a single population proportion, the distribution for the
test is for proportions or percentages:

P' ~ N (p,  ) pq
                                                  n

The population parameter is p. The estimated value (point estimate) for p is

p'. p' =  x  where x is the number of successes and n is the sample size.
          n

Glossary

Normal Distribution
      A continuous random variable (RV) with pdf
      1 f(x) = e-(x-)2/22 , where  is the mean of the distribution and

                      2

       is the standard deviation. Notation: X ~ N(, ). If  = 0 and
       = 1, the RV is called the standard normal distribution.
Standard Deviation
      A number that is equal to the square root of the variance and measures
      how far data values are from their mean. Notation: s for sample
      standard deviation and  for population standard deviation.

Student's-t Distribution
      Investigated and reported by William S. Gossett in 1908 and published
      under the pseudonym Student. The major characteristics of the random
      variable (RV) are:

            It is continuous and assumes any real values.
            The pdf is symmetrical about its mean of zero. However, it is
            more spread out and flatter at the apex than the normal
            distribution.
            It approaches the standard normal distribution as n gets larger.
            There is a "family" of t distributions: every representative of the
            family is completely defined by the number of degrees of
            freedom which is one less than the number of data.
Assumption

When you perform a hypothesis test of a single population mean  using
a Student's-t distribution (often called a t-test), there are fundamental
assumptions that need to be met in order for the test to work properly. Your
data should be a simple random sample that comes from a population that
is approximately normally distributed. You use the sample standard
deviation to approximate the population standard deviation. (Note that if
the sample size is sufficiently large, a t-test will work even if the population
is not approximately normally distributed).

When you perform a hypothesis test of a single population mean  using
a normal distribution (often called a z-test), you take a simple random
sample from the population. The population you are testing is normally
distributed or your sample size is sufficiently large. You know the value of
the population standard deviation.

When you perform a hypothesis test of a single population proportion p,
you take a simple random sample from the population. You must meet the
conditions for a binomial distribution which are there are a certain number
n of independent trials, the outcomes of any trial are success or failure, and
each trial has the same probability of a success p. The shape of the binomial
distribution needs to be similar to the shape of the normal distribution. To
ensure this, the quantities np and nq must both be greater than five (np > 5
and nq > 5). Then the binomial distribution of sample (estimated)
proportion can be approximated by the normal distribution with  = p and

                          pq

 =  n . Remember that q = 1 - p.

Glossary

Binomial Distribution
      A discrete random variable (RV) which arises from Bernoulli trials.
      There are a fixed number, n, of independent trials. "Independent"
      means that the result of any trial (for example, trial 1) does not affect
      the results of the following trials, and all trials are conducted under the
      same conditions. Under these circumstances the binomial RV X is
defined as the number of successes in n trials. The notation is: X~

B(n, p). The mean is  = np and the standard deviation is  = npq

. The probability of exactly x successes in n trials is

. n
   x n-x
P (X = x) = ( )p q
x

Normal Distribution
      A continuous random variable (RV) with pdf
      f(x) = 1 e-(x-)2/22 , where  is the mean of the distribution and

                      2

       is the standard deviation. Notation: X ~ N(, ). If  = 0 and
       = 1, the RV is called the standard normal distribution.

Standard Deviation
      A number that is equal to the square root of the variance and measures
      how far data values are from their mean. Notation: s for sample
      standard deviation and  for population standard deviation.

Student-t Distribution
      Investigated and reported by William S. Gossett in 1908 and published
      under the pseudonym Student. The major characteristics of the random
      variable (RV) are:

It is continuous and assumes any real values.
The pdf is symmetrical about its mean of zero. However, it is
more spread out and flatter at the apex than the normal
distribution.
It approaches the standard normal distribution as n gets larger.
There is a "family" of t distributions: every representative of the
family is completely defined by the number of degrees of
freedom which is one less than the number of data.
Rare Events

Suppose you make an assumption about a property of the population (this
assumption is the null hypothesis). Then you gather sample data randomly.
If the sample has properties that would be very unlikely to occur if the
assumption is true, then you would conclude that your assumption about the
population is probably incorrect. (Remember that your assumption is just an
assumption - it is not a fact and it may or may not be true. But your sample
data are real and the data are showing you a fact that seems to contradict
your assumption.)

For example, Didi and Ali are at a birthday party of a very wealthy friend.

They hurry to be first in line to grab a prize from a tall basket that they

cannot see inside because they will be blindfolded. There are 200 plastic

bubbles in the basket and Didi and Ali have been told that there is only one

with a $100 bill. Didi is the first person to reach into the basket and pull out

a bubble. Her bubble contains a $100 bill. The probability of this happening

is     1  = 0.005. Because this is so unlikely, Ali is hoping that what the two
    200

of them were told is wrong and there are more $100 bills in the basket. A

"rare event" has occurred (Didi getting the $100 bill) so Ali doubts the

assumption about only one $100 bill being in the basket.

Glossary

Hypothesis
      A statement about the value of a population parameter. In case of two
      hypotheses, the statement assumed to be true is called the null
      hypothesis (notation H0) and the contradictory statement is called the
      alternate hypothesis (notation Ha).
Using the Sample to Support One of the Hypotheses

Use the sample data to calculate the actual probability of getting the test
result, called the p-value. The p-value is the probability that, if the null
hypothesis is true, the results from another randomly selected sample
will be as extreme or more extreme as the results obtained from the
given sample.

A large p-value calculated from the data indicates that we should fail to
reject the null hypothesis. The smaller the p-value, the more unlikely the
outcome, and the stronger the evidence is against the null hypothesis. We
would reject the null hypothesis if the evidence is strongly against it.

Draw a graph that shows the p-value. The hypothesis test is easier to
perform if you use a graph because you see the problem more clearly.

Example:
(to illustrate the p-value)
Suppose a baker claims that his bread height is more than 15 cm, on the
average. Several of his customers do not believe him. To persuade his
customers that he is right, the baker decides to do a hypothesis test. He
bakes 10 loaves of bread. The mean height of the sample loaves is 17 cm.
The baker knows from baking hundreds of loaves of bread that the
standard deviation for the height is 0.5 cm. and the distribution of heights
is normal.
The null hypothesis could be Ho:   15 The alternate hypothesis is Ha:

 > 15

The words "is more than" translates as a ">" so " > 15" goes into the
alternate hypothesis. The null hypothesis must contradict the alternate
hypothesis.
Since  is known ( = 0.5 cm.), the distribution for the population is
known to be normal with mean = 15 and standard deviation 

                                                                                                                                                                                                                 n

= 0.5 = 0.16.

            10

Suppose the null hypothesis is true (the mean height of the loaves is no
more than 15 cm). Then is the mean height (17 cm) calculated from the
sample unexpectedly large? The hypothesis test works by asking the
question how unlikely the sample mean would be if the null hypothesis
were true. The graph shows how far out the sample mean is on the normal
curve. The p-value is the probability that, if we were to take other samples,
any other sample mean would fall at least as far out as 17 cm.
The p-value, then, is the probability that a sample mean is the same or
greater than 17 cm. when the population mean is, in fact, 15 cm. We
can calculate this probability using the normal distribution for means from
Chapter 7.

p-value = P (x > 17) which is approximately 0.
A p-value of approximately 0 tells us that it is highly unlikely that a loaf of
bread rises no more than 15 cm, on the average. That is, almost 0% of all
loaves of bread would be at least as high as 17 cm. purely by CHANCE
had the population mean height really been 15 cm. Because the outcome of
17 cm. is so unlikely (meaning it is happening NOT by chance alone),
we conclude that the evidence is strongly against the null hypothesis (the
mean height is at most 15 cm.). There is sufficient evidence that the true
mean height for the population of the baker's loaves of bread is greater than
15 cm.

Glossary

Hypothesis
      A statement about the value of a population parameter. In case of two
      hypotheses, the statement assumed to be true is called the null
      hypothesis (notation H0) and the contradictory statement is called the
      alternate hypothesis (notation Ha).
p-value
      The probability that an event will happen purely by chance assuming
      the null hypothesis is true. The smaller the p-value, the stronger the
      evidence is against the null hypothesis.

Standard Deviation
      A number that is equal to the square root of the variance and measures
      how far data values are from their mean. Notation: s for sample
      standard deviation and  for population standard deviation.
Decision and Conclusion

A systematic way to make a decision of whether to reject or not reject the
null hypothesis is to compare the p-value and a preset or preconceived 
(also called a "significance level"). A preset  is the probability of a Type
I error (rejecting the null hypothesis when the null hypothesis is true). It
may or may not be given to you at the beginning of the problem.

When you make a decision to reject or not reject Ho, do as follows:

      If  > p-value, reject Ho. The results of the sample data are
      significant. There is sufficient evidence to conclude that Ho is an
      incorrect belief and that the alternative hypothesis, Ha, may be
      correct.
      If   p-value, do not reject Ho. The results of the sample data are
      not significant. There is not sufficient evidence to conclude that the
      alternative hypothesis, Ha, may be correct.
      When you "do not reject Ho", it does not mean that you should believe
      that Ho is true. It simply means that the sample data have failed to
      provide sufficient evidence to cast serious doubt about the truthfulness
      of Ho.

Conclusion: After you make your decision, write a thoughtful conclusion
about the hypotheses in terms of the given problem.

Glossary

Hypothesis
      A statement about the value of a population parameter. In case of two
      hypotheses, the statement assumed to be true is called the null
      hypothesis (notation H0) and the contradictory statement is called the
      alternate hypothesis (notation Ha).

Level of Significance of the Test
      Probability of a Type I error (reject the null hypothesis when it is true).
      Notation: . In hypothesis testing, the Level of Significance is called
      the preconceived  or the preset .
p-value
      The probability that an event will happen purely by chance assuming
      the null hypothesis is true. The smaller the p-value, the stronger the
      evidence is against the null hypothesis.

Type 1 Error
      The decision is to reject the Null hypothesis when, in fact, the Null
      hypothesis is true.
Additional Information

      In a hypothesis test problem, you may see words such as "the level of
      significance is 1%." The "1%" is the preconceived or preset .
      The statistician setting up the hypothesis test selects the value of  to
      use before collecting the sample data.
      If no level of significance is given, the accepted standard is to use
       = 0.05.
      When you calculate the p-value and draw the picture, the p-value is
      the area in the left tail, the right tail, or split evenly between the two
      tails. For this reason, we call the hypothesis test left, right, or two
      tailed.
      The alternate hypothesis, Ha, tells you if the test is left, right, or two-
      tailed. It is the key to conducting the appropriate test.
      Ha never has a symbol that contains an equal sign.
      Thinking about the meaning of the p-value: A data analyst (and
      anyone else) should have more confidence that he made the correct
      decision to reject the null hypothesis with a smaller p-value (for
      example, 0.001 as opposed to 0.04) even if using the 0.05 level for
      alpha. Similarly, for a large p-value like 0.4, as opposed to a p-value of
      0.056 (alpha = 0.05 is less than either number), a data analyst should
      have more confidence that she made the correct decision in failing to
      reject the null hypothesis. This makes the data analyst use judgment
      rather than mindlessly applying rules.

The following examples illustrate a left, right, and two-tailed test.

Example:

Ho:  = 5  Ha:  < 5

Test of a single population mean. Ha tells you the test is left-tailed. The

picture of the p-value is as follows:
Example:

Ho: p  0.2  Ha: p > 0.2

This is a test of a single population proportion. Ha tells you the test is

right-tailed. The picture of the p-value is as follows:

Example:

Ho:  = 50   Ha:   50

This is a test of a single population mean. Ha tells you the test is two-

tailed. The picture of the p-value is as follows.
Glossary

Hypothesis Testing
      Based on sample evidence, a procedure to determine whether the
      hypothesis stated is a reasonable statement and cannot be rejected, or
      is unreasonable and should be rejected.

p-value
      The probability that an event will happen purely by chance assuming
      the null hypothesis is true. The smaller the p-value, the stronger the
      evidence is against the null hypothesis.
Summary of the Hypothesis Test

The hypothesis test itself has an established process. This can be
summarized as follows:

   1. Determine Ho and Ha. Remember, they are contradictory.
   2. Determine the random variable.
   3. Determine the distribution for the test.
   4. Draw a graph, calculate the test statistic, and use the test statistic to

      calculate the p-value. (A z-score and a t-score are examples of test
      statistics.)
   5. Compare the preconceived  with the p-value, make a decision (reject
      or do not reject Ho), and write a clear conclusion using English
      sentences.

Notice that in performing the hypothesis test, you use  and not .  is
needed to help determine the sample size of the data that is used in
calculating the p-value. Remember that the quantity 1 -  is called the
Power of the Test. A high power is desirable. If the power is too low,
statisticians typically increase the sample size while keeping  the same. If
the power is low, the null hypothesis might not be rejected when it should
be.

Glossary

Hypothesis Testing
      Based on sample evidence, a procedure to determine whether the
      hypothesis stated is a reasonable statement and cannot be rejected, or
      is unreasonable and should be rejected.

p-value
      The probability that an event will happen purely by chance assuming
      the null hypothesis is true. The smaller the p-value, the stronger the
      evidence is against the null hypothesis.
Lab: Hypothesis Testing of a Single Mean and Single Proportion

Class Time:

Names:

Student Learning Outcomes:

      The student will select the appropriate distributions to use in each case.
      The student will conduct hypothesis tests and interpret the results.

Television Survey

In a recent survey, it was stated that Americans watch television on average
four hours per day. Assume that  = 2. Using your class as the sample,
conduct a hypothesis test to determine if the average for students at your
school is lower.

   1. Ho:
   2. Ha:
   3. In words, define the random variable. __________ =
   4. The distribution to use for the test is:
   5. Determine the test statistic using your data.
   6. Draw a graph and label it appropriately.Shade the actual level of

      significance.

            aGraph:
            bDetermine the p-value:

   7. Do you or do you not reject the null hypothesis? Why?
   8. Write a clear conclusion using a complete sentence.

Language Survey

About 42.3% of Californians and 19.6% of all Americans over age 5 speak
a language other than English at home. Using your class as the sample,
conduct a hypothesis test to determine if the percent of the students at your
school that speak a language other than English at home is different from
42.3%. (Source: http://www.census.gov/hhes/socdemo/language/ )

   1. Ho:
   2. Ha:
   3. In words, define the random variable. __________ =
   4. The distribution to use for the test is:
   5. Determine the test statistic using your data.
   6. Draw a graph and label it appropriately. Shade the actual level of
      significance.
            a Graph:

            bDetermine the p-value:
   7. Do you or do you not reject the null hypothesis? Why?
   8. Write a clear conclusion using a complete sentence.

Jeans Survey

Suppose that young adults own an average of 3 pairs of jeans. Survey 8
people from your class to determine if the average is higher than 3.

   1. Ho:
   2. Ha:
   3. In words, define the random variable. __________ =
   4. The distribution to use for the test is:
5. Determine the test statistic using your data.
6. Draw a graph and label it appropriately. Shade the actual level of

  significance.
         a Graph:

         bDetermine the p-value:
7. Do you or do you not reject the null hypothesis? Why?
8. Write a clear conclusion using a complete sentence.
Hypothesis Testing: Two Population Means and Two Population
Proportions

Student Learning Outcomes

By the end of this chapter, the student should be able to:

      Classify hypothesis tests by type.
      Conduct and interpret hypothesis tests for two population means,
      population standard deviations known.
      Conduct and interpret hypothesis tests for two population means,
      population standard deviations unknown.
      Conduct and interpret hypothesis tests for two population proportions.
      Conduct and interpret hypothesis tests for matched or paired samples.

Introduction

Studies often compare two groups. For example, researchers are interested
in the effect aspirin has in preventing heart attacks. Over the last few years,
newspapers and magazines have reported about various aspirin studies
involving two groups. Typically, one group is given aspirin and the other
group is given a placebo. Then, the heart attack rate is studied over several
years.

There are other situations that deal with the comparison of two groups. For
example, studies compare various diet and exercise programs. Politicians
compare the proportion of individuals from different income brackets who
might vote for them. Students are interested in whether SAT or GRE
preparatory courses really help raise their scores.

In the previous chapter, you learned to conduct hypothesis tests on single
means and single proportions. You will expand upon that in this chapter.
You will compare two means or two proportions to each other. The general
procedure is still the same, just expanded.

To compare two means or two proportions, you work with two groups. The
groups are classified either as independent or matched pairs.
Independent groups mean that the two samples taken are independent, that
is, sample values selected from one population are not related in any way to
sample values selected from the other population. Matched pairs consist of
two samples that are dependent. The parameter tested using matched pairs
is the population mean. The parameters tested using independent groups are
either population means or population proportions.

Note:This chapter relies on either a calculator or a computer to calculate
the degrees of freedom, the test statistics, and p-values. TI-83+ and TI-84
instructions are included as well as the test statistic formulas. When using
the TI-83+/TI-84 calculators, we do not need to separate two population
means, independent groups, population variances unknown into large and
small sample sizes. However, most statistical computer software has the
ability to differentiate these tests.

This chapter deals with the following hypothesis tests:
Independent groups (samples are independent)

      Test of two population means.
      Test of two population proportions.

Matched or paired samples (samples are dependent)

      Becomes a test of one population mean.
Comparing Two Independent Population Means with Unknown Population
Standard Deviations
This module provides an overview of Comparing Two Independent
Population Means with Unknown Population Standard Deviations as a part
of Collaborative Statistics collection (col10522) by Barbara Illowsky and
Susan Dean.

   1. The two independent samples are simple random samples from two
      distinct populations.

   2. Both populations are normally distributed with the population means
      and standard deviations unknown unless the sample sizes are greater
      than 30. In that case, the populations need not be normally distributed.

Note:The test comparing two independent population means with
unknown and possibly unequal population standard deviations is called the
Aspin-Welch t-test. The degrees of freedom formula was developed by
Aspin-Welch.

The comparison of two population means is very common. A difference
between the two samples depends on both the means and the standard
deviations. Very different means can occur by chance if there is great
variation among the individual samples. In order to account for the
variation, we take the difference of the sample means, X1 - X2 , and divide
by the standard error (shown below) in order to standardize the difference.
The result is a t-score test statistic (shown below).

Because we do not know the population standard deviations, we estimate
them using the two sample standard deviations from our independent
samples. For the hypothesis test, we calculate the estimated standard
deviation, or standard error, of the difference in sample means, X1 - X2
.
Equation:

                               The standard error is:
                                                 2                                 2

                                  (S1 )                             (S2 )

                                                              +

                                    n1                              n2

The test statistic (t-score) is calculated as follows:
Equation:

                                         t-score

                         (x1 - x2 ) - (1 - 2 )

                                                   2             +                 2

                                    (S1 )                           (S2 )
                                       n1                              n2

where:

s1 and s2, the sample standard deviations, are estimates of 1 and 2,
respectively.
1 and 2 are the unknown population standard deviations.
x1 and x2 are the sample means. 1 and 2 are the population means.

The degrees of freedom (df) is a somewhat complicated calculation.
However, a computer or calculator calculates it easily. The dfs are not
always a whole number. The test statistic calculated above is approximated
by the student's-t distribution with dfs as follows:
Equation:

                                 Degrees of freedom

                                                           2     +                2      2

                                         (s1 )                      (s2 )            ]

                                    [                                  n2

                                             n1

                   df =

                                           2                  2                                    2     2

                              1     (s1 )                                1                  (s2 )
                         n1 -1                                      n2 -1
                                 [  n1        ]+                                      [     n2        ]

When both sample sizes n1 and n2 are five or larger, the student's-t

approximation  is  very  good.   Notice    that                  the  sample                variances               2  and          2

                                                                                                            s1              s2

are not pooled. (If the question comes up, do not pool the variances.)
Note: It is not necessary to compute this by hand. A calculator or computer
easily computes it.

Example:
Independent groups
The average amount of time boys and girls ages 7 through 11 spend
playing sports each day is believed to be the same. An experiment is done,
data is collected, resulting in the table below. Both populations have a
normal distribution.

Girls  Sample  Average Number of     Sample
Boys   Size    Hours Playing Sports  Standard
               Per Day               Deviation
       9
               2 hours               0.75
       16
               3.2 hours             1.00

Exercise:
   Problem:

   Is there a difference in the mean amount of time boys and girls ages 7
   through 11 play sports each day? Test at the 5% level of significance.

   Solution:

   The population standard deviations are not known. Let g be the
   subscript for girls and b be the subscript for boys. Then, g is the
population mean for girls and b is the population mean for boys.
This is a test of two independent groups, two population means.

Random variable: Xg - Xb = difference in the sample mean amount
of time girls and boys play sports each day.

Ho: g = b  g - b = 0

Ha: g  b   g - b  0

The words "the same" tell you Ho has an "=". Since there are no
other words to indicate Ha, then assume "is different." This is a two-
tailed test.

Distribution for the test: Use tdf where df is calculated using the df
formula for independent groups, two population means. Using a
calculator, df is approximately 18.8462. Do not pool the variances.

Calculate the p-value using a student's-t distribution: p-value =
0.0054

Graph:
sg = 0.75

sb = 1

So, xg - xb = 2 - 3.2 = -1.2
Half the p-value is below -1.2 and half is above 1.2.
Make a decision: Since  > p-value, reject Ho.
This means you reject g = b. The means are different.
Conclusion: At the 5% level of significance, the sample data show
there is sufficient evidence to conclude that the mean number of hours
that girls and boys aged 7 through 11 play sports per day is different
(mean number of hours boys aged 7 through 11 play sports per day is
greater than the mean number of hours played by girls OR the mean
number of hours girls aged 7 through 11 play sports per day is greater
than the mean number of hours played by boys).

Note:TI-83+ and TI-84: Press
STAT
. Arrow over to
TESTS
and press
4:2-SampTTest
. Arrow over to Stats and press
ENTER
. Arrow down and enter
2
for the first sample mean,

0.75

for Sx1,
9
for n1,
3.2
for the second sample mean,
1
for Sx2, and
16
for n2. Arrow down to 1: and arrow to
does not equal
2. Press
ENTER
. Arrow down to Pooled: and
No
. Press
ENTER
   . Arrow down to
   Calculate

   and press
   ENTER

   . The p-value is p = 0.0054, the dfs are approximately 18.8462, and
   the test statistic is -3.14. Do the procedure again but instead of
   Calculate do Draw.

Example:
A study is done by a community group in two neighboring colleges to
determine which one graduates students with more math classes. College A
samples 11 graduates. Their average is 4 math classes with a standard
deviation of 1.5 math classes. College B samples 9 graduates. Their
average is 3.5 math classes with a standard deviation of 1 math class. The
community group believes that a student who graduates from college A
has taken more math classes, on the average. Both populations have a
normal distribution. Test at a 1% significance level. Answer the following
questions.
Exercise:

   Problem:Is this a test of two means or two proportions?

   Solution:

   two means
Exercise:
   Problem:
   Are the populations standard deviations known or unknown?
   Solution:
   unknown
Exercise:

   Problem:Which distribution do you use to perform the test?
   Solution:
   student's-t
Exercise:

   Problem: What is the random variable?
   Solution:

     XA - XB

Exercise:

   Problem:What are the null and alternate hypothesis?
   Solution:

                 Ho : A  B
                 Ha : A > B

Exercise:

   Problem:Is this test right, left, or two tailed?
   Solution:

   right
Exercise:

   Problem:What is the p-value?

   Solution:

   0.1928
Exercise:

   Problem:Do you reject or not reject the null hypothesis?

   Solution:

   Do not reject.
Conclusion:
At the 1% level of significance, from the sample data, there is not
sufficient evidence to conclude that a student who graduates from college
A has taken more math classes, on the average, than a student who
graduates from college B.

Glossary

Degrees of Freedom (df)
      The number of objects in a sample that are free to vary.

Standard Deviation
      A number that is equal to the square root of the variance and measures
      how far data values are from their mean. Notation: s for sample
      standard deviation and  for population standard deviation.
Variable (Random Variable)
      A characteristic of interest in a population being studied. Common
      notation for variables are upper case Latin letters X, Y , Z,...; common
      notation for a specific value from the domain (set of all possible values
      of a variable) are lower case Latin letters x, y, z,.... For example, if X
      is the number of children in a family, then x represents a specific
      integer 0, 1, 2, 3, .... Variables in statistics differ from variables in
      intermediate algebra in two following ways.

            The domain of the random variable (RV) is not necessarily a
            numerical set; the domain may be expressed in words; for
            example, if X = hair color then the domain is {black, blond, gray,
            green, orange}.
            We can tell what specific value x of the Random Variable X takes
            only after performing the experiment.
Comparing Two Independent Population Means with Known Population
Standard Deviations
This module provides an overview of hypothesis testing in situations where
there are both two independent population means and known population
standard deviations in statistics.

Even though this situation is not likely (knowing the population standard
deviations is not likely), the following example illustrates hypothesis testing
for independent means, known population standard deviations. The
sampling distribution for the difference between the means is normal and
both populations must be normal. The random variable is X1 - X2. The
normal distribution has the following format:
Equation:

                                 Normal distribution

                                             2            2
                                                          (2) 
                                      (1)
           X1 - X2 ~N u1 - u2,  +

                                         n1               n2 

Equation:

           The standard deviation is:

                     2                       2

                      (1)         (2)
                           +

                 n1                      n2

Equation:

           The test statistic (z-score) is:

               (x1 - x2) - (1 - 2)

           z=

                                   2  +                2

                     (1)                 (2)

                        n1                  n2

Example:
independent groups, population standard deviations known: The mean
lasting time of 2 competing floor waxes is to be compared. Twenty floors
are randomly assigned to test each wax. Both populations have a normal
distribution. The following table is the result.

            Sample Mean Number of  Population
Wax Months Floor Wax Last          Standard
                                   Deviation
1  3
                                   0.33
2  2.9
                                   0.36

Exercise:
   Problem:

   Does the data indicate that wax 1 is more effective than wax 2? Test
   at a 5% level of significance.

   Solution:

   This is a test of two independent groups, two population means,
   population standard deviations known.

   Random Variable: X1 - X2 = difference in the mean number of
   months the competing floor waxes last.

     Ho : 1  2

     Ha : 1 > 2
The words "is more effective" says that wax 1 lasts longer than
wax 2, on the average. "Longer" is a > symbol and goes into Ha.
Therefore, this is a right-tailed test.

Distribution for the test: The population standard deviations are
known so the distribution is normal. Using the formula above, the
distribution is:

                                                                      0.332     0.362

X1 - X2 ~N (0,                                                               +  20     )
20

Since 1  2 then 1 - 2  0 and the mean for the normal
distribution is 0.

Calculate the p-value using the normal distribution: p-value =
0.1799

Graph:

x1 - x2 = 3 - 2.9 = 0.1

Compare  and the p-value:  = 0.05 and p-value = 0.1799.
Therefore,  < p-value.

Make a decision: Since  < p-value, do not reject Ho.
Conclusion: At the 5% level of significance, from the sample data,
there is not sufficient evidence to conclude that the mean time wax 1
lasts is longer (wax 1 is more effective) than the mean time wax 2
lasts.

Note:TI-83+ and TI-84: Press
STAT
. Arrow over to
TESTS
and press
3:2-SampZTest
. Arrow over to
Stats
and press
ENTER
. Arrow down and enter
.33
for sigma1,
.36
for sigma2,
3
for the first sample mean,
20
for n1,
2.9
for the second sample mean, and
20
for n2. Arrow down to 1: and arrow to > 2. Press
ENTER
. Arrow down to
Calculate
and press
ENTER
. The p-value is p = 0.1799 and the test statistic is 0.9157. Do the
procedure again but instead of
Calculate
do
Draw
.
Comparing Two Independent Population Proportions

1. The two independent samples are simple random samples that are
  independent.

2. The number of successes is at least five and the number of failures is at
  least five for each of the samples.

Comparing two proportions, like comparing two means, is common. If two

estimated proportions are different, it may be due to a difference in the

populations or it may be due to chance. A hypothesis test can help

determine  if  a  difference  in  the  estimated  proportions              -           reflects  a

                                                               (P             P)

                                                                        A           B

difference in the population proportions.

The difference of two proportions follows an approximate normal
distribution. Generally, the null hypothesis states that the two proportions
are the same. That is, Ho : pA = pB. To conduct the test, we use a pooled
proportion, pc.
Equation:

                The pooled proportion is calculated as follows:

                                  pc =  xA + xB
                                        nA + nB

Equation:

                  The distribution for the differences is:

                               1 1

           P A - P B ~N 0, pc  (1 - pc )  (                    +              )

                                                         nA       nB 

Equation:

                  The test statistic (z-score) is:

                              (pA - pB ) - (pA - pB )

                  z=

                              pc  (1 - pc )  (    1   +  1

                                                  nA     nB    )
Example:
Two population proportions
Two types of medication for hives are being tested to determine if there is a
difference in the proportions of adult patient reactions. Twenty out of a
random sample of 200 adults given medication A still had hives 30
minutes after taking the medication. Twelve out of another random
sample of 200 adults given medication B still had hives 30 minutes after
taking the medication. Test at a 1% level of significance.

        Determining the solution

         This is a test of 2 population proportions.
         Exercise:

Problem: How do you know?
Solution:
The problem asks for a difference in proportions.

Let A and B be the subscripts for medication A and
medication B. Then pA and pB are the desired population
proportions.

Random Variable:
P'A - P'B = difference in the proportions of adult patients
who did not react after 30 minutes to medication A and
medication B.

Ho : pA = pB  pA - pB = 0

Ha : pA  pB   pA - pB  0

The words "is a difference" tell you the test is two-tailed.

Distribution for the test: Since this is a test of two
binomial population proportions, the distribution is normal:
pc =  xA +xB    =     20+12  = 0.08  1 - pc = 0.92
      nA +nB       200+200

Therefore,

P'A - P'B ~N [0, (0.08)  (0.92)  (   1    +         1

                                     200            200  )]

P'A - P'B follows an approximate normal distribution.

Calculate the p-value using the normal distribution: p-
value = 0.1404.

Estimated proportion for group A:

            xA     20
p'A = nA = 200 = 0.1

Estimated proportion for group B:

            xB     12
p'B = nB = 200 = 0.06

Graph:

P'A - P'B = 0.1 - 0.06 = 0.04.
Half the p-value is below -0.04 and half is above 0.04.
Compare  and the p-value:  = 0.01 and the
p-value = 0.1404.  < p-value.
Make a decision: Since  < p-value, do not reject Ho.
Conclusion: At a 1% level of significance, from the sample
data, there is not sufficient evidence to conclude that there is
a difference in the proportions of adult patients who did not
react after 30 minutes to medication A and medication B.

Note:TI-83+ and TI-84: Press
STAT
. Arrow over to
TESTS
and press
6:2-PropZTest
. Arrow down and enter
20
for x1,
200
for n1,
12
for x2, and
200
for n2. Arrow down to
p1
: and arrow to
not equal p2
. Press
ENTER
. Arrow down to
Calculate
and press
ENTER
. The p-value is p = 0.1404 and the test statistic is 1.47.
Do the procedure again but instead of
Calculate
do
Draw
.
Matched or Paired Samples
This module provides an overview of Hypothesis Testing: Matched or Paired Samples as a part of
Collaborative Statistics collection (col10522) by Barbara Illowsky and Susan Dean.

   1. Simple random sampling is used.
   2. Sample sizes are often small.
   3. Two measurements (samples) are drawn from the same pair of individuals or objects.
   4. Differences are calculated from the matched or paired samples.
   5. The differences form the sample that is used for the hypothesis test.
   6. The matched pairs have differences that either come from a population that is normal or the number of

      differences is sufficiently large so the distribution of the sample mean of differences is approximately
      normal.

In a hypothesis test for matched or paired samples, subjects are matched in pairs and differences are calculated.
The differences are the data. The population mean for the differences, d, is then tested using a Student-t test
for a single population mean with n - 1 degrees of freedom where n is the number of differences.
Equation:

                                                 The test statistic (t-score) is:

                             xd - d

                         t=

                                sd

                             (      )

                                n

Example:
Matched or paired samples
A study was conducted to investigate the effectiveness of hypnotism in reducing pain. Results for randomly
selected subjects are shown in the table. The "before" value is matched to an "after" value and the differences
are calculated. The differences have a normal distribution.

Subject:  A    B    C        D         E     F    G    H
Before
After     6.6  6.5  9.0      10.3      11.3  8.1  6.3  11.6

          6.8  2.4  7.4      8.5       8.1   6.1  3.4  2.0

Exercise:
   Problem:
   Are the sensory measurements, on average, lower after hypnotism? Test at a 5% significance level.
   Solution:
   Corresponding "before" and "after" values form matched pairs. (Calculate "sfter" - "before").
After Data  Before Data                                                                                                 Difference
6.8         6.6                                                                                                         0.2
2.4         6.5                                                                                                         -4.1
7.4         9                                                                                                           -1.6
8.5         10.3                                                                                                        -1.8
8.1         11.3                                                                                                        -3.2
6.1         8.1                                                                                                         -2
3.4         6.3                                                                                                         -2.9
2           11.6                                                                                                        -9.6

The data for the test are the differences: {0.2, -4.1, -1.6, -1.8, -3.2, -2, -2.9, -9.6}

The sample mean and sample standard deviation of the differences are:                                                   xd = -3.13 and sd = 2.91
Verify these values.

Let d be the population mean for the differences. We use the subscript d to denote "differences."

Random Variable: Xd = the mean difference of the sensory measurements
Equation:

            Ho : d  0

There is no improvement. (d is the population mean of the differences.)
Equation:

                                                                                                            Ha : d < 0

There is improvement. The score should be lower after hypnotism so the difference ought to be negative
to indicate improvement.

Distribution for the test: The distribution is a student-t with df = n - 1 = 8 - 1 = 7. Use t7. (Notice
that the test is for a single population mean.)

Calculate the p-value using the Student-t distribution: p-value = 0.0095

Graph:
Xd is the random variable for the differences.
The sample mean and sample standard deviation of the differences are:

xd = -3.13
sd = 2.91

Compare  and the p-value:  = 0.05 and p-value = 0.0095.  > p-value.
Make a decision: Since  > p-value, reject Ho.
This means that d < 0 and there is improvement.
Conclusion: At a 5% level of significance, from the sample data, there is sufficient evidence to conclude
that the sensory measurements, on average, are lower after hypnotism. Hypnotism appears to be effective
in reducing pain.

Note:For the TI-83+ and TI-84 calculators, you can either calculate the differences ahead of time (after
- before) and put the differences into a list or you can put the after data into a first list and the before
data into a second list. Then go to a third list and arrow up to the name. Enter 1st list name - 2nd list
name. The calculator will do the subtraction and you will have the differences in the third list.

Note:TI-83+ and TI-84: Use your list of differences as the data. Press
STAT
and arrow over to
TESTS
. Press
2:T-Test
. Arrow over to
Data
and press
   ENTER
   . Arrow down and enter
   0
   for 0, the name of the list where you put the data, and
   1
   for Freq:. Arrow down to
   
   : and arrow over to
   <
   0. Press
   ENTER
   . Arrow down to
   Calculate
   and press
   ENTER
   . The p-value is 0.0094 and the test statistic is -3.04. Do these instructions again except arrow to
   Draw
   (instead of
   Calculate
   ). Press
   ENTER
   .

Example:
A college football coach was interested in whether the college's strength development class increased his
players' maximum lift (in pounds) on the bench press exercise. He asked 4 of his players to participate in a
study. The amount of weight they could each lift was recorded before they took the strength development
class. After completing the class, the amount of weight they could each lift was again measured. The data are
as follows:
Weight (in pounds)                               Player 1  Player 2  Player 3               Player 4
Amount of weighted lifted prior to the class     205       241       338                    368
Amount of weight lifted after the class          295       252       330                    360

The coach wants to know if the strength development class makes his players stronger, on average.
Exercise:

   Problem:

   Record the differences data. Calculate the differences by subtracting the amount of weight lifted prior to
   the class from the weight lifted after completing the class. The data for the differences are: {90, 11, -8,
   -8}. The differences have a normal distribution.

   Using the differences data, calculate the sample mean and the sample standard deviation.

xd = 21.3  sd = 46.7

Using the difference data, this becomes a test of a single __________ (fill in the blank).

Define the random variable: Xd = mean difference in the maximum lift per player.

The distribution for the hypothesis test is t3.

Ho : d  0  Ha : d > 0

Graph:

   Calculate the p-value: The p-value is 0.2150
   Decision: If the level of significance is 5%, the decision is to not reject the null hypothesis because
    < p-value.
   What is the conclusion?
   Solution:
   means; At a 5% level of significance, from the sample data, there is not sufficient evidence to conclude
   that the strength development class helped to make the players stronger, on average.

Example:
Seven eighth graders at Kennedy Middle School measured how far they could push the shot-put with their
dominant (writing) hand and their weaker (non-writing) hand. They thought that they could push equal
distances with either hand. The following data was collected.

Distance   Student  Student  Student                        Student  Student  Student  Student
(in feet)  1        2        3                              4        5        6        7
using      30       26       34                             17       19       26       20

Dominant   28       14       27                             18       17       26       16
Hand

Weaker
Hand

Exercise:
   Problem:

   Conduct a hypothesis test to determine whether the mean difference in distances between the children's
   dominant versus weaker hands is significant.

Note:use a t-test on the difference data. Assume the differences have a normal distribution. The random
variable is the mean difference.

Note:The test statistic is 2.18 and the p-value is 0.0716.

What is your conclusion?

Solution:

H0: d equals 0; Ha: d does not equal 0; Do not reject the null; At a 5% significance level, from the
sample data, there is not sufficient evidence to conclude that the mean difference in distances between the
children's dominant versus weaker hands is significant (there is not sufficient evidence to show that the
children could push the shot-put further with their dominant hand). Alpha and the p-value are close so the
test is not strong.
Summary of Types of Hypothesis Tests
Two Population Means

      Populations are independent and population standard deviations are
      unknown.
      Populations are independent and population standard deviations are
      known (not likely).

Matched or Paired Samples

      Two samples are drawn from the same set of objects.
      Samples are dependent.

Two Population Proportions

      Populations are independent.
Confidence Intervals

Student Learning Outcomes

By the end of this chapter, the student should be able to:

      Calculate and interpret confidence intervals for one population mean
      and one population proportion.
      Interpret the student-t probability distribution as the sample size
      changes.
      Discriminate between problems applying the normal and the student-t
      distributions.

Introduction

Suppose you are trying to determine the mean rent of a two-bedroom
apartment in your town. You might look in the classified section of the
newspaper, write down several rents listed, and average them together. You
would have obtained a point estimate of the true mean. If you are trying to
determine the percent of times you make a basket when shooting a
basketball, you might count the number of shots you make and divide that
by the number of shots you attempted. In this case, you would have
obtained a point estimate for the true proportion.

We use sample data to make generalizations about an unknown population.
This part of statistics is called inferential statistics. The sample data help
us to make an estimate of a population parameter. We realize that the
point estimate is most likely not the exact value of the population
parameter, but close to it. After calculating point estimates, we construct
confidence intervals in which we believe the parameter lies.

In this chapter, you will learn to construct and interpret confidence
intervals. You will also learn a new distribution, the Student's-t, and how it
is used with these intervals. Throughout the chapter, it is important to keep
in mind that the confidence interval is a random variable. It is the parameter
that is fixed.
If you worked in the marketing department of an entertainment company,
you might be interested in the mean number of compact discs (CD's) a
consumer buys per month. If so, you could conduct a survey and calculate
the sample mean, x, and the sample standard deviation, s. You would use x
to estimate the population mean and s to estimate the population standard
deviation. The sample mean, x, is the point estimate for the population
mean, . The sample standard deviation, s, is the point estimate for the
population standard deviation, .

Each of x and s is also called a statistic.

A confidence interval is another type of estimate but, instead of being just
one number, it is an interval of numbers. The interval of numbers is a range
of values calculated from a given set of sample data. The confidence
interval is likely to include an unknown population parameter.

Suppose for the CD example we do not know the population mean  but we
do know that the population standard deviation is  = 1 and our sample
size is 100. Then by the Central Limit Theorem, the standard deviation for
the sample mean is

 = 1 = 0.1.

n  100

The Empirical Rule, which applies to bell-shaped distributions, says that in
approximately 95% of the samples, the sample mean, x, will be within two
standard deviations of the population mean . For our CD example, two
standard deviations is (2)(0.1) = 0.2. The sample mean x is likely to be
within 0.2 units of .

Because x is within 0.2 units of , which is unknown, then  is likely to be
within 0.2 units of x in 95% of the samples. The population mean  is
contained in an interval whose lower number is calculated by taking the
sample mean and subtracting two standard deviations ((2)(0.1)) and whose
upper number is calculated by taking the sample mean and adding two
standard deviations. In other words,  is between x - 0.2 and x + 0.2 in
95% of all the samples.
For the CD example, suppose that a sample produced a sample mean x = 2
. Then the unknown population mean  is between

x - 0.2 = 2 - 0.2 = 1.8 and x + 0.2 = 2 + 0.2 = 2.2

We say that we are 95% confident that the unknown population mean
number of CDs is between 1.8 and 2.2. The 95% confidence interval is
(1.8, 2.2).

The 95% confidence interval implies two possibilities. Either the interval
(1.8, 2.2) contains the true mean  or our sample produced an x that is not
within 0.2 units of the true mean . The second possibility happens for only
5% of all the samples (100% - 95%).

Remember that a confidence interval is created for an unknown population
parameter like the population mean, . Confidence intervals for some
parameters have the form

(point estimate - margin of error, point estimate + margin of error)

The margin of error depends on the confidence level or percentage of
confidence.

When you read newspapers and journals, some reports will use the phrase
"margin of error." Other reports will not use that phrase, but include a
confidence interval as the point estimate + or - the margin of error. These
are two ways of expressing the same concept.

Note:Although the text only covers symmetric confidence intervals, there
are non-symmetric confidence intervals (for example, a confidence interval
for the standard deviation).

Optional Collaborative Classroom Activity
Have your instructor record the number of meals each student in your class
eats out in a week. Assume that the standard deviation is known to be 3
meals. Construct an approximate 95% confidence interval for the true mean
number of meals students eat out each week.

1. Calculate the sample mean.
2.  = 3 and n = the number of students surveyed.

3. Construct the interval  x-2                

                                     ,x + 2 

                                n             n

We say we are approximately 95% confident that the true average number
of meals that students eat out in a week is between __________ and
___________.

Glossary

Confidence Interval (CI)
      An interval estimate for an unknown population parameter. This
      depends on:

            The desired confidence level.
            Information that is known about the distribution (for example,
            known standard deviation).
            The sample and its size.

Inferential Statistics
      Also called statistical inference or inductive statistics. This facet of
      statistics deals with estimating a population parameter based on a
      sample statistic. For example, if 4 out of the 100 calculators sampled
      are defective we might infer that 4 percent of the production is
      defective.

Parameter
      A numerical characteristic of the population.

Point Estimate
      A single number computed from a sample and used to estimate a
      population parameter.
Confidence Interval, Single Population Mean, Population Standard
Deviation Known, Normal
Confidence Intervals: Confidence Interval, Single Population Mean,
Population Standard Deviation Known, Normal is part of the collection
col10555 written by Barbara Illowsky and Susan Dean with contributions
from Roberta Bloom.

Calculating the Confidence Interval

To construct a confidence interval for a single unknown population mean 
, where the population standard deviation is known, we need x as an
estimate for  and we need the margin of error. Here, the margin of error is
called the error bound for a population mean (abbreviated EBM). The
sample mean x is the point estimate of the unknown population mean 
The confidence interval estimate will have the form:

      (point estimate - error bound, point estimate + error bound) or, in
      symbols,(x - EBM, x + EBM)

The margin of error depends on the confidence level (abbreviated CL). The
confidence level is often considered the probability that the calculated
confidence interval estimate will contain the true population parameter.
However, it is more accurate to state that the confidence level is the percent
of confidence intervals that contain the true population parameter when
repeated samples are taken. Most often, it is the choice of the person
constructing the confidence interval to choose a confidence level of 90% or
higher because that person wants to be reasonably certain of his or her
conclusions.

There is another probability called alpha ().  is related to the confidence
level CL.  is the probability that the interval does not contain the unknown
population parameter.
Mathematically,  + CL = 1.

Example:
      Suppose we have collected data from a sample. We know the sample
      mean but we do not know the mean for the entire population.
      The sample mean is 7 and the error bound for the mean is 2.5.
x = 7 and EBM = 2.5.
The confidence interval is (7 - 2.5, 7 + 2.5); calculating the values gives
(4.5, 9.5).
If the confidence level (CL) is 95%, then we say that "We estimate with
95% confidence that the true value of the population mean is between 4.5
and 9.5."

A confidence interval for a population mean with a known standard
deviation is based on the fact that the sample means follow an
approximately normal distribution. Suppose that our sample has a mean of
x = 10 and we have constructed the 90% confidence interval (5, 15) where
EBM = 5.
To get a 90% confidence interval, we must include the central 90% of the
probability of the normal distribution. If we include the central 90%, we
leave out a total of  = 10% in both tails, or 5% in each tail, of the normal
distribution.

To capture the central 90%, we must go out 1.645 "standard deviations" on
either side of the calculated sample mean. 1.645 is the z-score from a
Standard Normal probability distribution that puts an area of 0.90 in the
center, an area of 0.05 in the far left tail, and an area of 0.05 in the far right
tail.

It is important that the "standard deviation" used must be appropriate for the

parameter we are estimating. So in this section, we need to use the standard

deviation that applies to sample means, which is  .     is commonly
                                                    n    n
                                                       

called the "standard error of the mean" in order to clearly distinguish the

standard deviation for a mean from the population standard deviation .

In summary, as a result of the Central Limit Theorem:

      X is normally distributed, that is, X ~ N(X, ). 
                                                                                                                                                                             n

      When the population standard deviation  is known, we use a
      Normal distribution to calculate the error bound.

Calculating the Confidence Interval:
To construct a confidence interval estimate for an unknown population
mean, we need data from a random sample. The steps to construct and
interpret the confidence interval are:

      Calculate the sample mean x from the sample data. Remember, in this
      section, we already know the population standard deviation .
      Find the Z-score that corresponds to the confidence level.
      Calculate the error bound EBM
      Construct the confidence interval
      Write a sentence that interprets the estimate in the context of the
      situation in the problem. (Explain what the confidence interval means,
      in the words of the problem.)

We will first examine each step in more detail, and then illustrate the
process with some examples.

Finding z for the stated Confidence Level
When we know the population standard deviation , we use a standard
normal distribution to calculate the error bound EBM and construct the
confidence interval. We need to find the value of z that puts an area equal to
the confidence level (in decimal form) in the middle of the standard normal
distribution Z~N(0,1).

The confidence level, CL, is the area in the middle of the standard normal

distribution. CL = 1 - . So  is the area that is split equally between the

two tails. Each of the tails contains an area equal to     .
                                                        2

The z-score that has an area to the right of            is denoted by z 

                                                     2                                                                          2

For example, when CL = 0.95 then  = 0.05 and 2 = 0.025  ; we write

z  = z.025
       2

The area to the right of z.025 is 0.025 and the area to the left of z.025 is 1-
0.025 = 0.975

z  = z0.025 = 1.96 , using a calculator, computer or a Standard Normal
       2

probability table.

Using the TI83, TI83+ or TI84+ calculator: invNorm(0.975, 0, 1) = 1.96

CALCULATOR NOTE: Remember to use area to the LEFT of z  ; in this

                                                                                                                                                                                                                                                                                                                2

chapter the last two inputs in the invNorm command are 0,1 because you

are using a Standard Normal Distribution Z~N(0,1)

EBM: Error Bound
The error bound formula for an unknown population mean  when the
population standard deviation  is known is

                                                   

EBM = z  

2  n

Constructing the Confidence Interval

The confidence interval estimate has the format
(x - EBM, x + EBM).

The graph gives a picture of the entire situation.
CL +  +  = CL +  = 1.
2  2

Writing the Interpretation
The interpretation should clearly state the confidence level (CL), explain
what population parameter is being estimated (here, a population mean),
and should state the confidence interval (both endpoints). "We estimate with
___% confidence that the true population mean (include context of the
problem) is between ___ and ___ (include appropriate units)."

Example:
Suppose scores on exams in statistics are normally distributed with an
unknown population mean and a population standard deviation of 3 points.
A random sample of 36 scores is taken and gives a sample mean (sample
mean score) of 68. Find a confidence interval estimate for the population
mean exam score (the mean score on all exams).
Exercise:

   Problem:

   Find a 90% confidence interval for the true (population) mean of
   statistics exam scores.

   Solution:
      You can use technology to directly calculate the confidence
      interval
      The first solution is shown step-by-step (Solution A).
      The second solution uses the TI-83, 83+ and 84+ calculators
      (Solution B).

Solution A
To find the confidence interval, you need the sample mean, x, and the
EBM.

x = 68

EBM = z   (        

                     )

             2  n

 = 3 ; n = 36 ; The confidence level is 90% (CL=0.90)

CL = 0.90 so  = 1 - CL = 1 - 0.90 = 0.10

             z  = z.05

     = 0.05         2

2

The area to the right of z.05 is 0.05 and the area to the left of z.05 is
1-0.05=0.95

z  = z.05 = 1.645

       2

using invNorm(0.95,0,1) on the TI-83,83+,84+ calculators. This can
also be found using appropriate commands on other calculators, using
a computer, or using a probability table for the Standard Normal
distribution.

EBM = 1.645  (  3    ) = 0.8225

                36

x - EBM = 68 - 0.8225 = 67.1775

     x + EBM = 68 + 0.8225 = 68.8225

   The 90% confidence interval is (67.1775, 68.8225).
Solution B
Using a function of the TI-83, TI-83+ or TI-84 calculators:

Press STAT and arrow over to TESTS.
Arrow down to 7:ZInterval.
Press ENTER.
Arrow to Stats and press ENTER.
Arrow down and enter 3 for , 68 for x , 36 for n, and .90 for C-level.
Arrow down to Calculate and press ENTER.
The confidence interval is (to 3 decimal places) (67.178, 68.822).
Interpretation
We estimate with 90% confidence that the true population mean exam
score for all statistics students is between 67.18 and 68.82.
Explanation of 90% Confidence Level
90% of all confidence intervals constructed in this way contain the true
mean statistics exam score. For example, if we constructed 100 of these
confidence intervals, we would expect 90 of them to contain the true
population mean exam score.

Changing the Confidence Level or Sample Size

Example:Changing the Confidence Level
Exercise:

   Problem:

   Suppose we change the original problem by using a 95% confidence
   level. Find a 95% confidence interval for the true (population) mean
   statistics exam score.

   Solution:

   To find the confidence interval, you need the sample mean, x, and the
   EBM.
x = 68

EBM = z   (          

                       )

              2     n

 = 3 ; n = 36 ; The confidence level is 95% (CL=0.95)

CL = 0.95 so  = 1 - CL = 1 - 0.95 = 0.05

                 z  = z.025

     = 0.025            2

2

The area to the right of z.025 is 0.025 and the area to the left of z.025 is
1-0.025=0.975

z  = z.025 = 1.96

       2

using invnorm(.975,0,1) on the TI-83,83+,84+ calculators. (This can
also be found using appropriate commands on other calculators, using
a computer, or using a probability table for the Standard Normal
distribution.)

EBM = 1.96  (    3   ) = 0.98

                 36

x - EBM = 68 - 0.98 = 67.02

     x + EBM = 68 + 0.98 = 68.98

Interpretation
We estimate with 95 % confidence that the true population mean for all
statistics exam scores is between 67.02 and 68.98.
Explanation of 95% Confidence Level
95% of all confidence intervals constructed in this way contain the true
value of the population mean statistics exam score.
Comparing the results
The 90% confidence interval is (67.18, 68.82). The 95% confidence
interval is (67.02, 68.98). The 95% confidence interval is wider. If you
look at the graphs, because the area 0.95 is larger than the area 0.90, it
makes sense that the 95% confidence interval is wider.
Summary: Effect of Changing the Confidence Level

      Increasing the confidence level increases the error bound, making the
      confidence interval wider.
      Decreasing the confidence level decreases the error bound, making
      the confidence interval narrower.

Example:Changing the Sample Size:
Suppose we change the original problem to see what happens to the error
bound if the sample size is changed.
Exercise:

   Problem:

   Leave everything the same except the sample size. Use the original
   90% confidence level. What happens to the error bound and the
   confidence interval if we increase the sample size and use n=100
   instead of n=36? What happens if we decrease the sample size to
   n=25 instead of n=36?

x = 68

EBM = z   (   

                   )

           2  n

 = 3 ; The confidence level is 90% (CL=0.90) ;

z  = z.05 = 1.645
       2

Solution:
If we increase the sample size n to 100, we decrease the error bound.

When n = 100 : EBM = z   ( )  = 1.645  ( ) 3 = 0.4935
      n                                      100
   2

Solution:
If we decrease the sample size n to 25, we increase the error bound.

When n = 25 : EBM = z   ( )  = 1.645  ( ) 3 = 0.987

2     n                                      25

Summary: Effect of Changing the Sample Size

Increasing the sample size causes the error bound to decrease, making
the confidence interval narrower.
Decreasing the sample size causes the error bound to increase, making
the confidence interval wider.

Working Backwards to Find the Error Bound or Sample Mean

Working Bacwards to find the Error Bound or the Sample Mean
When we calculate a confidence interval, we find the sample mean and
calculate the error bound and use them to calculate the confidence interval.
But sometimes when we read statistical studies, the study may state the
confidence interval only. If we know the confidence interval, we can work
backwards to find both the error bound and the sample mean.
Finding the Error Bound

      From the upper value for the interval, subtract the sample mean
      OR, From the upper value for the interval, subtract the lower value.
      Then divide the difference by 2.

Finding the Sample Mean
      Subtract the error bound from the upper value of the confidence
      interval
      OR, Average the upper and lower endpoints of the confidence interval

Notice that there are two methods to perform each calculation. You can
choose the method that is easier to use with the information you know.

Example:
Suppose we know that a confidence interval is (67.18, 68.82) and we want
to find the error bound. We may know that the sample mean is 68. Or
perhaps our source only gave the confidence interval and did not tell us the
value of the the sample mean.
Calculate the Error Bound:

If we know that the sample mean is 68: EBM = 68.82 - 68 = 0.82

If we don't know the sample mean: EBM =   (68.82-67.18)

                                               2         = 0.82

Calculate the Sample Mean:

If we know the error bound: x = 68.82 - 0.82 = 68

If we don't know the error bound: x =  (67.18+68.82)

                                                           = 68

                                          2

Calculating the Sample Size n

If researchers desire a specific margin of error, then they can use the error
bound formula to calculate the required sample size.

The error bound formula for a population mean when the population

standard deviation is known is EBM = z   (  )

                               2       n

The formula for sample size is n = 2 z22 , found by solving the error
                                                                                                                         EBM

bound formula for n
In this formula, z is z  , corresponding to the desired confidence level. A

                                                                                                      2

researcher planning a study who wants a specified confidence level and

error bound can use this formula to calculate the size of the sample needed

for the study.

Example:
The population standard deviation for the age of Foothill College students
is 15 years. If we want to be 95% confident that the sample mean age is
within 2 years of the true population mean age of Foothill College students
, how many randomly selected Foothill College students must be
surveyed?

From the problem, we know that  = 15 and EBM=2
z = z.025 = 1.96, because the confidence level is 95%.

n = 2 z22 = 2 1.962152 =216.09 using the sample size equation.
EBM  2

Use n = 217: Always round the answer UP to the next higher integer

to ensure that the sample size is large enough.

Therefore, 217 Foothill College students should be surveyed in order to be
95% confident that we are within 2 years of the true population mean age
of Foothill College students.

**With contributions from Roberta Bloom

Glossary

Confidence Interval (CI)
      An interval estimate for an unknown population parameter. This
      depends on:

            The desired confidence level.
            Information that is known about the distribution (for example,
            known standard deviation).
            The sample and its size.

Confidence Level (CL)
      The percent expression for the probability that the confidence interval
      contains the true population parameter. For example, if the CL = 90%
      , then in 90 out of 100 samples the interval estimate will enclose the
      true population parameter.

Error Bound for a Population Mean (EBM)
      The margin of error. Depends on the confidence level, sample size, and
      known or estimated population standard deviation.
Confidence Interval, Single Population Mean, Standard Deviation
Unknown, Student-T
Confidence Interval, Single Population Mean, Population Standard
Deviation Unknown, Student-t is part of the collection col10555 written by
Barbara Illowsky and Susan Dean with contributions from Roberta Bloom.

In practice, we rarely know the population standard deviation. In the past,
when the sample size was large, this did not present a problem to
statisticians. They used the sample standard deviation s as an estimate for 
and proceeded as before to calculate a confidence interval with close
enough results. However, statisticians ran into problems when the sample
size was small. A small sample size caused inaccuracies in the confidence
interval.

William S. Gossett (1876-1937) of the Guinness brewery in Dublin, Ireland
ran into this problem. His experiments with hops and barley produced very
few samples. Just replacing  with s did not produce accurate results when
he tried to calculate a confidence interval. He realized that he could not use
a normal distribution for the calculation; he found that the actual
distribution depends on the sample size. This problem led him to "discover"
what is called the Student's-t distribution. The name comes from the fact
that Gosset wrote under the pen name "Student."

Up until the mid 1970s, some statisticians used the normal distribution
approximation for large sample sizes and only used the Student's-t
distribution for sample sizes of at most 30. With the common use of
graphing calculators and computers, the practice is to use the Student's-t
distribution whenever s is used as an estimate for .

If you draw a simple random sample of size n from a population that has

approximately a normal distribution with mean  and unknown population

standard deviation  and calculate the t-score t = x- , then the t-scores

                  s

               (     )

                  n

follow a Student's-t distribution with n - 1 degrees of freedom. The t-

score has the same interpretation as the z-score. It measures how far x is

from its mean . For each sample size n, there is a different Student's-t

distribution.
The degrees of freedom, n - 1, come from the calculation of the sample
standard deviation s. In Chapter 2, we used n deviations (x - x values) to
calculate s. Because the sum of the deviations is 0, we can find the last
deviation once we know the other n - 1 deviations. The other n - 1
deviations can change or vary freely. We call the number n - 1 the
degrees of freedom (df).
Properties of the Student's-t Distribution

      The graph for the Student's-t distribution is similar to the Standard
      Normal curve.
      The mean for the Student's-t distribution is 0 and the distribution is
      symmetric about 0.
      The Student's-t distribution has more probability in its tails than the
      Standard Normal distribution because the spread of the t distribution is
      greater than the spread of the Standard Normal. So the graph of the
      Student's-t distribution will be thicker in the tails and shorter in the
      center than the graph of the Standard Normal distribution.
      The exact shape of the Student's-t distribution depends on the "degrees
      of freedom". As the degrees of freedom increases, the graph Student's-t
      distribution becomes more like the graph of the Standard Normal
      distribution.
      The underlying population of individual observations is assumed to be
      normally distributed with unknown population mean  and unknown
      population standard deviation . The size of the underlying population
      is generally not relevant unless it is very small. If it is bell shaped
      (normal) then the assumption is met and doesn't need discussion.
      Random sampling is assumed but it is a completely separate
      assumption from normality.

Calculators and computers can easily calculate any Student's-t probabilities.
The TI-83,83+,84+ have a tcdf function to find the probability for given
values of t. The grammar for the tcdf command is tcdf(lower bound, upper
bound, degrees of freedom). However for confidence intervals, we need to
use inverse probability to find the value of t when we know the probability.

For the TI-84+ you can use the invT command on the DISTRibution menu.
The invT command works similarly to the invnorm. The invT command
requires two inputs: invT(area to the left, degrees of freedom) The output
is the t-score that corresponds to the area we specified.

The TI-83 and 83+ do not have the invT command. (The TI-89 has an
inverse T command.)

A probability table for the Student's-t distribution can also be used. The
table gives t-scores that correspond to the confidence level (column) and
degrees of freedom (row). (The TI-86 does not have an invT program or
command, so if you are using that calculator, you need to use a probability
table for the Student's-t distribution.) When using t-table, note that some
tables are formatted to show the confidence level in the column headings,
while the column headings in some tables may show only corresponding
area in one or both tails.

A Student's-t table (See the Table of Contents 15. Tables) gives t-scores
given the degrees of freedom and the right-tailed probability. The table is
very limited. Calculators and computers can easily calculate any
Student's-t probabilities.
The notation for the Student's-t distribution is (using T as the random
variable) is

      T ~ tdf where df = n - 1.
      For example, if we have a sample of size n=20 items, then we calculate
      the degrees of freedom as df=n-1=20-1=19 and we write the
      distribution as T ~ t19

If the population standard deviation is not known, the error bound for
a population mean is:

EBM = t   (                s

                              )

                  2        n

t        is  the  t-score  with  area  to  the  right  equal  to  
                                                                  2
      2

use df = n - 1 degrees of freedom

s = sample standard deviation

The format for the confidence interval is:
(x - EBM, x + EBM).

The TI-83, 83+ and 84 calculators have a function that calculates the
confidence interval directly. To get to it,
Press STAT
Arrow over to TESTS.
Arrow down to 8:TInterval and press ENTER (or just press 8).

Example:
Exercise:

   Problem:

   Suppose you do a study of acupuncture to determine how effective it
   is in relieving pain. You measure sensory rates for 15 subjects with
   the results given below. Use the sample data to construct a 95%
   confidence interval for the mean sensory rate for the population
   (assumed normal) from which you took the data.

The solution is shown step-by-step and by using the TI-83, 83+ and
84+ calculators.
8.6 9.4 7.9 6.8 8.3 7.3 9.2 9.6 8.7 11.4 10.3 5.4 8.1 5.5 6.9

Solution:

      You can use technology to directly calculate the confidence
      interval.
      The first solution is step-by-step (Solution A).
      The second solution uses the Ti-83+ and Ti-84 calculators
      (Solution B).

Solution A
To find the confidence interval, you need the sample mean, x, and the
EBM.

x = 8.2267  s = 1.6722  n = 15
df = 15 - 1 = 14

CL = 0.95 so  = 1 - CL = 1 - 0.95 = 0.05

                     t  = t.025
                           2
     = 0.025

2

The area to the right of t.025 is 0.025 and the area to the left of t.025 is
1-0.025=0.975

t        = t.025  = 2.14 using invT(.975,14) on the TI-84+ calculator.

      2

                     s

EBM = t   (             )

                  2  n

EBM = 2.14  (           1.6722  ) = 0.924

                        15

x - EBM = 8.2267 - 0.9240 = 7.3

     x + EBM = 8.2267 + 0.9240 = 9.15

   The 95% confidence interval is (7.30, 9.15).

   We estimate with 95% confidence that the true population mean
   sensory rate is between 7.30 and 9.15.

Solution B
Using a function of the TI-83, TI-83+ or TI-84 calculators:

Press STAT and arrow over to TESTS.
Arrow down to 8:TInterval and press ENTER (or you can just press
8). Arrow to Data and press ENTER.
Arrow down to List and enter the list name where you put the data.
Arrow down to Freq and enter 1.
Arrow down to C-level and enter .95
Arrow down to Calculate and press ENTER.
The 95% confidence interval is (7.3006, 9.1527)
Note:When calculating the error bound, a probability table for the
Student's-t distribution can also be used to find the value of t. The table
gives t-scores that correspond to the confidence level (column) and
degrees of freedom (row); the t-score is found where the row and column
intersect in the table.

**With contributions from Roberta Bloom

Glossary

Confidence Interval (CI)
      An interval estimate for an unknown population parameter. This
      depends on:

            The desired confidence level.
            Information that is known about the distribution (for example,
            known standard deviation).
            The sample and its size.

Confidence Level (CL)
      The percent expression for the probability that the confidence interval
      contains the true population parameter. For example, if the CL = 90%
      , then in 90 out of 100 samples the interval estimate will enclose the
      true population parameter.

Degrees of Freedom (df)
      The number of objects in a sample that are free to vary.

Error Bound for a Population Mean (EBM)
      The margin of error. Depends on the confidence level, sample size, and
      known or estimated population standard deviation.

Normal Distribution
      A continuous random variable (RV) with pdf
      f(x) = 1 e-(x-)2/22 , where  is the mean of the distribution and

                      2

       is the standard deviation. Notation: X ~ N(, ). If  = 0 and
       = 1, the RV is called the standard normal distribution.

Standard Deviation
      A number that is equal to the square root of the variance and measures
      how far data values are from their mean. Notation: s for sample
      standard deviation and  for population standard deviation.

Student's-t Distribution
      Investigated and reported by William S. Gossett in 1908 and published
      under the pseudonym Student. The major characteristics of the random
      variable (RV) are:

            It is continuous and assumes any real values.
            The pdf is symmetrical about its mean of zero. However, it is
            more spread out and flatter at the apex than the normal
            distribution.
            It approaches the standard normal distribution as n gets larger.
            There is a "family" of t distributions: every representative of the
            family is completely defined by the number of degrees of
            freedom which is one less than the number of data.
Confidence Interval for a Population Proportion
Confidence Interval for a Population Proportion is part of the collection
col10555 written by Barbara Illowsky and Susan Dean with contributions
from Roberta Bloom.

During an election year, we see articles in the newspaper that state
confidence intervals in terms of proportions or percentages. For example, a
poll for a particular candidate running for president might show that the
candidate has 40% of the vote within 3 percentage points. Often, election
polls are calculated with 95% confidence. So, the pollsters would be 95%
confident that the true proportion of voters who favored the candidate
would be between 0.37 and 0.43 : (0.40 - 0.03, 0.40 + 0.03).

Investors in the stock market are interested in the true proportion of stocks
that go up and down each week. Businesses that sell personal computers are
interested in the proportion of households in the United States that own
personal computers. Confidence intervals can be calculated for the true
proportion of stocks that go up or down each week and for the true
proportion of households in the United States that own personal computers.

The procedure to find the confidence interval, the sample size, the error
bound, and the confidence level for a proportion is similar to that for the
population mean. The formulas are different.

How do you know you are dealing with a proportion problem? First, the
underlying distribution is binomial. (There is no mention of a mean or
average.) If X is a binomial random variable, then X~B(n, p) where n =
the number of trials and p = the probability of a success. To form a
proportion, take X, the random variable for the number of successes and
divide it by n, the number of trials (or the sample size). The random
variable P  (read "P prime") is that proportion,

                   X

P =

                    n

(Sometimes the random variable is denoted as P^, read "P hat".)
When n is large and p is not close to 0 or 1, we can use the normal
distribution to approximate the binomial.

X ~ N (n  p, n  p  q)

If we divide the random variable by n, the mean by n, and the standard
deviation by n, we get a normal distribution of proportions with P , called
the estimated proportion, as the random variable. (Recall that a proportion =
the number of successes divided by n.)

~ X            np     npq

      = P  N(  n   ,                )

n                            n

Using algebra to simplify :  npq          pq

                                       n  =

                                                               n

                                                                                                                                                                                                                              pq

P  follows a normal distribution for proportions: P  ~ N(p,  n )

The confidence interval has the form (p-EBP, p+EBP).

                 x

p=

                 n

p = the estimated proportion of successes (p is a point estimate for p,
the true proportion)
x = the number of successes.
n = the size of the sample
The error bound for a proportion is

               pq

EBP = z           n    where q= 1 - p

2

This formula is similar to the error bound formula for a mean, except that
the "appropriate standard deviation" is different. For a mean, when the
population standard deviation is known, the appropriate standard deviation
that we use is          .  For  a  proportion,  the  appropriate  standard  deviation    is
                     n
                   

   . pq



            n

However, in the error bound formula, we use n  pq as the standard

                                                                               pq

deviation, instead of  n

However,       in  the  error  bound  formula,  the  standard  deviation  is    pq    .
                                                                                   n

In the error bound formula, the sample proportions p and q are
estimates of the unknown population proportions p and q. The estimated
proportions p and q are used because p and q are not known. p and q are
calculated from the data. p is the estimated proportion of successes. q is
the estimated proportion of failures.

The confidence interval can only be used if the number of successes np
and the number of failures nq are both larger than 5.

Note:For the normal distribution of proportions, the z-score formula is as
follows.

                        pq                                        p-p
If P  ~ N (p,  n ) then the z-score formula is z =
                                                                    pq

                                                                  

                                                                    n

Example:
Exercise:
Problem:

Suppose that a market research firm is hired to estimate the percent of
adults living in a large city who have cell phones. 500 randomly
selected adult residents in this city are surveyed to determine whether
they have cell phones. Of the 500 people surveyed, 421 responded yes
- they own cell phones. Using a 95% confidence level, compute a
confidence interval estimate for the true proportion of adults residents
of this city who have cell phones.
Solution

      You can use technology to directly calculate the confidence
      interval.
      The first solution is step-by-step (Solution A).
      The second solution uses a function of the TI-83, 83+ or 84
      calculators (Solution B).

Solution:

Let X = the number of people in the sample who have cell phones. X
is binomial. X ~ B(500, ) 421 .

                                                                                      500

To calculate the confidence interval, you must find p, q, and EBP.

n = 500 x = the number of successes = 421

p=  x  =   421  = 0.842

    n      500

p= 0.842 is the sample proportion; this is the point estimate of the
population proportion.

q= 1 - p= 1 - 0.842 = 0.158   = 0.025.

Since CL = 0.95, then        2

 = 1 - CL = 1 - 0.95 = 0.05
Then z  = z.025 = 1.96
                                   2

Use the TI-83, 83+ or 84+ calculator command invNorm(0.975,0,1) to
find . z.025 Remember that the area to the right of z.025 is 0.025 and the
area to the left of z0.025 is 0.975. This can also be found using
appropriate commands on other calculators, using a computer, or
using a Standard Normal probability table.

EBP = z                                                           pq                                              (0.842)(0.158)     = 0.032

                                                 2                       = 1.96  

                                                                      n                                                         500

p-EBP = 0.842 - 0.032 = 0.81

p+EBP = 0.842 + 0.032 = 0.874

The confidence interval for the true binomial population proportion is
(p-EBP, p+EBP) =(0.810, 0.874).

Interpretation
We estimate with 95% confidence that between 81% and 87.4% of all
adult residents of this city have cell phones.

Explanation of 95% Confidence Level
95% of the confidence intervals constructed in this way would contain
the true value for the population proportion of all adult residents of
this city who have cell phones.

Solution:

Using a function of the TI-83, 83+ or 84 calculators:

Press STAT and arrow over to TESTS.
Arrow down to A:1-PropZint. Press ENTER.
Arrow down to x and enter 421.
Arrow down to n and enter 500.
Arrow down to C-Level and enter .95.
Arrow down to Calculate and press ENTER.
The confidence interval is (0.81003, 0.87397).
Example:
Exercise:

   Problem:

   For a class project, a political science student at a large university
   wants to estimate the percent of students that are registered voters. He
   surveys 500 students and finds that 300 are registered voters.
   Compute a 90% confidence interval for the true percent of students
   that are registered voters and interpret the confidence interval.

Solution:

      You can use technology to directly calculate the confidence
      interval.
      The first solution is step-by-step (Solution A).
      The second solution uses a function of the TI-83, 83+ or 84
      calculators (Solution B).

Solution A
x = 300 and n = 500.

p=  x  =  300  = 0.600

    n     500

q= 1 - p= 1 - 0.600 = 0.400

Since CL = 0.90, then         = 0.05.

 = 1 - CL = 1 - 0.90 = 0.10  2

z  = z.05 = 1.645
        2

Use the TI-83, 83+ or 84+ calculator command invNorm(0.95,0,1) to
find z.05. Remember that the area to the right of z.05 is 0.05 and the
area to the left of z.05 is 0.95. This can also be found using
appropriate commands on other calculators, using a computer, or
using a Standard Normal probability table.

EBP = z                                                           pq                                                  (0.60)(0.40)     = 0.036

                                                 2                       = 1.645  

                                                                      n                                                           500

p-EBP = 0.60 - 0.036 = 0.564

     p+EBP = 0.60 + 0.036 = 0.636

   The confidence interval for the true binomial population proportion is
   (p-EBP, p+EBP) =(0.564, 0.636).
   Interpretation:

         We estimate with 90% confidence that the true percent of all
         students that are registered voters is between 56.4% and 63.6%.
         Alternate Wording: We estimate with 90% confidence that
         between 56.4% and 63.6% of ALL students are registered voters.

   Explanation of 90% Confidence Level
   90% of all confidence intervals constructed in this way contain the
   true value for the population percent of students that are registered
   voters.

Solution B
Using a function of the TI-83, 83+ or 84 calculators:

Press STAT and arrow over to TESTS.
Arrow down to A:1-PropZint. Press ENTER.
Arrow down to x and enter 300.
Arrow down to n and enter 500.
Arrow down to C-Level and enter .90.
Arrow down to Calculate and press ENTER.
The confidence interval is (0.564, 0.636).

Calculating the Sample Size n
If researchers desire a specific margin of error, then they can use the error
bound formula to calculate the required sample size.

The error bound formula for a population proportion is

           EBP = z                                                           p'q'

                                                            2  

                                                                                 n

           Solving for n gives you an equation for the sample size.

                              2

                   z  p'q'

           n=       2
                                     2

                   EBP

Example:
Suppose a mobile phone company wants to determine the current
percentage of customers aged 50+ that use text messaging on their cell
phone. How many customers aged 50+ should the company survey in order
to be 90% confident that the estimated (sample) proportion is within 3
percentage points of the true population proportion of customers aged 50+
that use text messaging on their cell phone.

Solution
From the problem, we know that EBP=0.03 (3%=0.03) and

z          = z.05  = 1.645 because the confidence level is 90%

        2

However, in order to find n , we need to know the estimated (sample)

proportion p'. Remember that q'=1-p'. But, we do not know p' yet. Since we

multiply p' and q' together, we make them both equal to 0.5 because p'q'=

(.5)(.5)=.25 results in the largest possible product. (Try other products: (.6)

(.4)=.24; (.3)(.7)=.21; (.2)(.8)=.16 and so on). The largest possible product

gives us the largest n. This gives us a large enough sample so that we can

be 90% confident that we are within 3 percentage points of the true

population proportion. To calculate the sample size n, use the formula and

make the substitutions.

           2                                                                        2
n = 2 z p'q' gives n = 2 1.645 (.5)(.5) =751.7
           EBP                                                                      .03

Round the answer to the next higher value. The sample size should be 752

cell phone customers aged 50+ in order to be 90% confident that the
estimated (sample) proportion is within 3 percentage points of the true
population proportion of all customers aged 50+ that use text messaging on
their cell phone.
**With contributions from Roberta Bloom.

Glossary

Binomial Distribution

A discrete random variable (RV) which arises from Bernoulli trials.

There are a fixed number, n, of independent trials. "Independent"

means that the result of any trial (for example, trial 1) does not affect

the results of the following trials, and all trials are conducted under the

same conditions. Under these circumstances the binomial RV X is

defined as the number of successes in n trials. The notation is: X~

B(n, p). The mean is  = np and the standard deviation is  = npq

. The probability of exactly x successes in n trials is

          . n
                       x n-x
P (X = x) = ( )p q
          x

Confidence Interval (CI)
      An interval estimate for an unknown population parameter. This
      depends on:

The desired confidence level.
Information that is known about the distribution (for example,
known standard deviation).
The sample and its size.

Confidence Level (CL)
      The percent expression for the probability that the confidence interval
      contains the true population parameter. For example, if the CL = 90%
      , then in 90 out of 100 samples the interval estimate will enclose the
      true population parameter.

Error Bound for a Population Proportion(EBP)
      The margin of error. Depends on the confidence level, sample size, and
      the estimated (from the sample) proportion of successes.
Normal Distribution
      A continuous random variable (RV) with pdf
      f(x) = 1 e-(x-)2/22 , where  is the mean of the distribution and

                      2

       is the standard deviation. Notation: X ~ N(, ). If  = 0 and
       = 1, the RV is called the standard normal distribution.
Summary of Formulas
Formula General form of a confidence interval

(lower value, upper value) = (point estimate - error bound, point estimate + error bound)

FormulaTo find the error bound when you know the confidence interval

error bound = upper value - point estimate       OR

error bound =   upper value-lower value
                                              2

FormulaSingle Population Mean, Known Standard Deviation, Normal Distribution

Use the Normal Distribution for Means                                                               

                                                 EBM = z  

                                                 2   n

The confidence interval has the format (x - EBM, x + EBM).

FormulaSingle Population Mean, Unknown Standard Deviation, Student's-t Distribution

Use the Student's-t Distribution with degrees of freedom df = n - 1. EBM = t   s

                                                                                                         2  n

FormulaSingle Population Proportion, Normal Distribution

Use the Normal Distribution for a single population proportion p=                                     x
                                                                                                      n

            pq

EBP = z     n               p+q= 1

2

The confidence interval has the format (p-EBP, p+EBP).

FormulaPoint Estimates

x is a point estimate for 

p is a point estimate for 

s is a point estimate for 
F Distribution and ANOVA
This module provides a brief introduction on handling hypothesis tests with
two means by the one-way Analysis of Variance (One-Way ANOVA), F
Distribution, and the Test of Two Variances statistical analysis.

Student Learning Outcomes

By the end of this chapter, the student should be able to:

      Interpret the F probability distribution as the number of groups and the
      sample size change.
      Discuss two uses for the F distribution: One-Way ANOVA and the test
      of two variances.
      Conduct and interpret One-Way ANOVA.
      Conduct and interpret hypothesis tests of two variances.

Introduction

Many statistical applications in psychology, social science, business
administration, and the natural sciences involve several groups. For
example, an environmentalist is interested in knowing if the average
amount of pollution varies in several bodies of water. A sociologist is
interested in knowing if the amount of income a person earns varies
according to his or her upbringing. A consumer looking for a new car might
compare the average gas mileage of several models.

For hypothesis tests involving more than two averages, statisticians have
developed a method called Analysis of Variance" (abbreviated ANOVA). In
this chapter, you will study the simplest form of ANOVA called single
factor or One-Way ANOVA. You will also study the F distribution, used for
One-Way ANOVA, and the test of two variances. This is just a very brief
overview of One-Way ANOVA. You will study this topic in much greater
detail in future statistics courses.

      One-Way ANOVA, as it is presented here, relies heavily on a
      calculator or computer.
For further information about One-Way ANOVA, use the online link
ANOVA. Use the back button to return here. (The url is
http://en.wikipedia.org/wiki/Analysis_of_variance.)
ANOVA
This module describes the assumptions needed for implementing an One-
Way ANOVA and how to set up the hypothesis test for the ANOVA.

F Distribution and One-Way ANOVA: Purpose and Basic
Assumptions of One-Way ANOVA

The purpose of a One-Way ANOVA test is to determine the existence of a
statistically significant difference among several group means. The test
actually uses variances to help determine if the means are equal or not.

In order to perform a One-Way ANOVA test, there are five basic
assumptions to be fulfilled:

      Each population from which a sample is taken is assumed to be
      normal.
      Each sample is randomly selected and independent.
      The populations are assumed to have equal standard deviations (or
      variances).
      The factor is the categorical variable.
      The response is the numerical variable.

The Null and Alternate Hypotheses

The null hypothesis is simply that all the group population means are the
same. The alternate hypothesis is that at least one pair of means is different.
For example, if there are k groups:

Ho : 1 = 2 = 3 = ... = k

Ha : At least two of the group means 1, 2, 3, ..., k are not equal.

The graphs help in the understanding of the hypothesis test. In the first
graph (red box plots), Ho : 1 = 2 = 3 and the three populations have
the same distribution if the null hypothesis is true. The variance of the
combined data is approximately the same as the variance of each of the
populations.
If the null hypothesis is false, then the variance of the combined data is
larger which is caused by the different means as shown in the second graph
(green box plots).

Glossary
Analysis of Variance
      Also referred to as ANOVA. A method of testing whether or not the
      means of three or more populations are equal. The method is
      applicable if:

            All populations of interest are normally distributed.
            The populations have equal standard deviations.
            Samples (not necessarily of the same size) are randomly and
            independently selected from each population.

      The test statistic for analysis of variance is the F-ratio.

Variance
      Mean of the squared deviations from the mean. Square of the standard
      deviation. For a set of data, a deviation can be represented as x - x
      where x is a value of the data and x is the sample mean. The sample
      variance is equal to the sum of the squares of the deviations divided by
      the difference of the sample size and 1.
The F Distribution and the F Ratio
This module describes how to calculate the F Ratio and F Distribution based on the hypothesis
test for the One-Way ANOVA.

The distribution used for the hypothesis test is a new one. It is called the F distribution, named
after Sir Ronald Fisher, an English statistician. The F statistic is a ratio (a fraction). There are
two sets of degrees of freedom; one for the numerator and one for the denominator.

For example, if F follows an F distribution and the degrees of freedom for the numerator are 4
and the degrees of freedom for the denominator are 10, then F ~ . F4,10

Note:The F distribution is derived from the Student's-t distribution. One-Way ANOVA expands
the t-test for comparing more than two groups. The scope of that derivation is beyond the level
of this course.

To calculate the F ratio, two estimates of the variance are made.

1. Variance between samples: An estimate of 2 that is the variance of the sample means

    multiplied by n (when there is equal n). If the samples are different sizes, the variance

    between samples is weighted to account for the different sample sizes. The variance is also

    called variation due to treatment or explained variation.

2.  Variance  within  samples:  An  estimate  of       2  that  is  the  average  of  the  sample  variances

                                                  

    (also known as a pooled variance). When the sample sizes are different, the variance within

    samples is weighted. The variance is also called the variation due to error or unexplained

    variation.

    SSbetween = the sum of squares that represents the variation among the different samples.
    SSwithin = the sum of squares that represents the variation within samples that is due to
    chance.

To find a "sum of squares" means to add together squared quantities which, in some cases, may
be weighted. We used sum of squares to calculate the sample variance and the sample standard
deviation in Descriptive Statistics.

MS means "mean square." MSbetween is the variance between groups and MSwithin is the
variance within groups.
Calculation of Sum of Squares and Mean Square

    k = the number of different groups
    nj = the size of the jth group
    sj= the sum of the values in the jth group
    n = total number of all the values combined. (total sample size:  nj)
    x = one value:  x =  sj
    Sum of squares of all values from every group combined:  x2
                                                                                                                                                                                                                                                  2

Between group variability: SStotal =  x2 - n ( x)
Total sum of squares:  x2 ( x)2 -

                                                                                                               n

Explained variation- sum of squares representing variation among the different samples

                                                        (sj)2                          2

SSbetween = [ nj ] -                                           ( sj )
                                                                       n

Unexplained variation- sum of squares representing variation within samples due to chance:

SSwithin = SStotal - SSbetween                                                                                    SS between
                                                                                                                  df between
df's for different groups (df's for the numerator): df between = k - 1                                             SS within
Equation for errors within samples (df's for the denominator): df within = n - k                                   df within
Mean square (variance estimate) explained by the different groups: MSbetween =

Mean square (variance estimate) that is due to chance (unexplained): MSwithin =

MSbetween and MSwithin can be written as follows:

MSbetween =  SS between   =                                    SS between
             df between                                             k-1

MSwithin =  SS within  =  SS within
            df within        n-k

The One-Way ANOVA test depends on the fact that MSbetween can be influenced by population
differences among means of the several groups. Since MSwithin compares values of each group
to its own group mean, the fact that group means might be different does not affect . MSwithin

The null hypothesis says that all groups are samples from populations having the same normal
distribution. The alternate hypothesis says that at least two of the sample groups come from
populations with different normal distributions. If the null hypothesis is true, MSbetween and
MSwithin should both estimate the same value.

Note:The null hypothesis says that all the group population means are equal. The hypothesis of
equal means implies that the populations have the same normal distribution because it is
assumed that the populations are normal and that they have equal variances.

Equation:

                                                                                          F-Ratio or F Statistic

                                                                                          F=  MS between
                                                                                               MS within

If MSbetween and MSwithin estimate the same value (following the belief that Ho is true), then the
F-ratio should be approximately equal to 1. Mostly just sampling errors would contribute to
variations away from 1. As it turns out, MSbetween consists of the population variance plus a
variance produced from the differences between the samples. MSwithin is an estimate of the
population variance. Since variances are always positive, if the null hypothesis is false,
MSbetween will generally be larger than . MSwithin Then the F-ratio will be larger than 1.
However, if the population effect size is small it is not unlikely that MSwithin will be larger in a
give sample.

The above calculations were done with groups of different sizes. If the groups are the same size,
the calculations simplify somewhat and the F ratio can be written as:
Equation:

                         F-Ratio Formula when the groups are the same size

                                               F=                        2

                                                     n  sx

                                                         2

                                                     s pooled

where ...

n =the sample size

df numerator = k - 1

df denominator = n - k

    2         =    the  mean  of  the  sample  variances  (pooled           variance)

s pooled

        2  =  the  variance  of  the  sample  means

sx

The data is typically put into a table for easy viewing. One-Way ANOVA results are often
displayed in this manner by computer software.

Source of          Sum of              Degrees            Mean Square                  F
Variation          Squares             of                 (MS)
                   (SS)                Freedom                                         F =
Factor                                 (df)               MS(Factor) =                 MS(Factor)/MS(Error)
(Between)          SS(Factor)                             SS(Factor)/(k-
                                       k - 1              1)

Error              SS(Error)           n - k              MS(Error) =
(Within)                                                  SS(Error)/(n-
                                                          k)
Total
                   SS(Total)           n - 1

Example:
Three different diet plans are to be tested for mean weight loss. The entries in the table are the
weight losses for the different plans. The One-Way ANOVA table is shown below.
Plan 1                  Plan 2                      Plan 3
5                       3.5                         8
4.5                     7                           4
4                                                   3.5
3                       4.5

One-Way ANOVA Table: The formulas for SS(Total), SS(Factor) = SS(Between) and SS(Error)
= SS(Within) are shown above. This same information is provided by the TI calculator
hypothesis test function ANOVA in STAT TESTS (syntax is ANOVA(L1, L2, L3) where L1, L2,
L3 have the data from Plan 1, Plan 2, Plan 3 respectively).

Source of  Sum of       Degrees     Mean Square     F
Variation  Squares      of          (MS)
           (SS)         Freedom                     F =
Factor                  (df)        MS(Factor)      MS(Factor)/MS(Error)
(Between)  SS(Factor)               =               = 1.1229/2.9792
           =            k - 1       SS(Factor)/(k-  = 0.3769
Error      SS(Between)  = 3         1)
(Within)   =2.2458      groups -    = 2.2458/2
                        1           = 1.1229
Total      SS(Error)    = 2
           =                        MS(Error)
           SS(Within)   n - k       =
           = 20.8542    = 10 total  SS(Error)/(n-
                        data - 3    k)
           SS(Total)    groups      = 20.8542/7
           = 2.9792 +   = 7         = 2.9792
           20.8542
           =23.1        n - 1
                        = 10 total
                        data - 1
                        = 9
The One-Way ANOVA hypothesis test is always right-tailed because larger F-values are way
out in the right tail of the F-distribution curve and tend to make us reject Ho.

Notation

The notation for the F distribution is F ~ Fdf(num),df(denom)
where df (num) = dfbetween and df (denom) = dfwithin
The mean for the F distribution is  = df(num)

                                                                                                                                   df (denom)-1
Facts About the F Distribution
This module states the factors associated with F Distributions and provides
students with some examples to help further understand the concept.
Students will be given the opportunity to see F Distributions in action
through participation in an optional classroom exercise.

   1. The curve is not symmetrical but skewed to the right.
   2. There is a different curve for each set of dfs.
   3. The F statistic is greater than or equal to zero.
   4. As the degrees of freedom for the numerator and for the denominator

      get larger, the curve approximates the normal.
   5. Other uses for the F distribution include comparing two variances and

      Two-Way Analysis of Variance. Comparing two variances is discussed
      at the end of the chapter. Two-Way Analysis is mentioned for your
      information only.

Example:
One-Way ANOVA: Four sororities took a random sample of sisters
regarding their grade means for the past term. The results are shown below:

   MEAN GRADES FOR FOUR SORORITIES
SMoEroArNityG1RADESSFoOroRriFtyO2UR SORSOoRroITriItEy S3  Sorority 4

Sorority 1  Sorority 2  Sorority 3                        Sorority 4
2.17        2.63        2.63                              3.79
1.85        1.77        3.78                              3.45
2.83        3.25        4.00                              3.08
1.69        1.86        2.55                              2.26
3.33        2.21        2.45                              3.18

Exercise:
   Problem:

   Using a significance level of 1%, is there a difference in mean grades
   among the sororities?

   Solution:

   Let 1, 2, 3, 4 be the population means of the sororities.
   Remember that the null hypothesis claims that the sorority groups are
   from the same normal distribution. The alternate hypothesis says that
   at least two of the sorority groups come from populations with
   different normal distributions. Notice that the four sample sizes are
   each size 5.

Note:This is an example of a balanced design, since each factor (i.e.
Sorority) has the same number of observations.
Ho : 1 = 2 = 3 = 4

Ha: Not all of the means 1, 2, 3, 4 are equal.
Distribution for the test: F3,16
where k = 4 groups and n = 20 samples in total

df (num) = k - 1 = 4 - 1 = 3
df (denom) = n - k = 20 - 4 = 16

Calculate the test statistic: F = 2.23
Graph:

Probability statement: p-value = P (F > 2.23) = 0.1241

Compare  and the p-value:

 = 0.01  p-value = 0.1241   < p-value

Make a decision: Since  < p-value, you cannot reject Ho.

Conclusion: There is not sufficient evidence to conclude that there is a
difference among the mean grades for the sororities.

TI-83+ or TI 84: Put the data into lists L1, L2, L3, and L4. Press
STAT and arrow over to TESTS. Arrow down to F:ANOVA. Press
ENTER and Enter (L1,L2,L3,L4). The F statistic is 2.2303 and the
   p-value is 0.1241. df(numerator) = 3 (under "Factor") and
   df(denominator) = 16 (under Error).

Example:
A fourth grade class is studying the environment. One of the assignments is
to grow bean plants in different soils. Tommy chose to grow his bean plants
in soil found outside his classroom mixed with dryer lint. Tara chose to
grow her bean plants in potting soil bought at the local nursery. Nick chose
to grow his bean plants in soil from his mother's garden. No chemicals were
used on the plants, only water. They were grown inside the classroom next
to a large window. Each child grew 5 plants. At the end of the growing
period, each plant was measured, producing the following data (in inches):

   Tommy's Plants  Tara's Plants  Nick's Plants
   24              25             23
   21              31             27
   23              23             22
   30              20             30
   23              28             20

Exercise:
Problem:

Does it appear that the three media in which the bean plants were
grown produce the same mean height? Test at a 3% level of
significance.

Solution:

This time, we will perform the calculations that lead to the F' statistic.
Notice that each group has the same number of plants so we will use

                                                                                                          2

                                                               nsx

the formula F' = 2 .
                                                             s pooled

First, calculate the sample mean and sample variance of each group.

Sample               Tommy's  Tara's  Nick's
Mean                 Plants   Plants  Plants
                     24.2     25.4    24.4
Sample
Variance             11.7     18.3    16.3

Next, calculate the variance of the three group means (Calculate the

variance of 24.2, 25.4, and 24.4). Variance of the group means =

0.413  =          2

          sx

Then MSbetween = nsx 2 = (5)(0.413) where n = 5 is the sample
size (number of plants each child grew).

Calculate the mean of the three sample variances (Calculate the mean
of 11.7, 18.3, and 16.3). Mean of the sample variances = 15.433
             2

= s pooled

Then MSwithin = s pooled 2 = 15.433.

The F statistic (or F ratio) is

F=  MS between  =                     2  =  (5)(0.413)   = 0.134
     MS within                                   15.433
                     nsx
                   s2 pooled

The dfs for the numerator = the number of groups - 1 = 3 - 1 = 2

The dfs for the denominator =

the total number of samples - the number of groups = 15 - 3 = 12

The distribution for the test is F2,12 and the F statistic is F = 0.134

The p-value is P (F > 0.134) = 0.8759.

Decision: Since  = 0.03 and the p-value = 0.8759, do not reject
Ho. (Why?)

Conclusion: With a 3% the level of significance, from the sample
data, the evidence is not sufficient to conclude that the mean heights of
the bean plants are different.

   (This experiment was actually done by three classmates of the son of
   one of the authors.)

Another fourth grader also grew bean plants but this time in a jelly-like
mass. The heights were (in inches) 24, 28, 25, 30, and 32.
Exercise:

   Problem:

Do a One-Way ANOVA test on the 4 groups. You may use your
calculator or computer to perform the test. Are the heights of the bean
plants different? Use a solution sheet.

Solution:

    F = 0.9496
         p-value = 0.4402

   From the sample data, the evidence is not sufficient to conclude that
   the mean heights of the bean plants are different.

Optional Classroom Activity

From the class, create four groups of the same size as follows: men under
22, men at least 22, women under 22, women at least 22. Have each member
of each group record the number of states in the United States he or she has
visited. Run an ANOVA test to determine if the average number of states
visited in the four groups are the same. Test at a 1% level of significance.
Use one of the solution sheets at the end of the chapter (after the
homework).
Test of Two Variances
This module provides the assumptions to be considered in order to calculate
a Test of Two Variances and how to execute the Test of Two Variances. An
example is provided to help clarify the concept.

Another of the uses of the F distribution is testing two variances. It is often
desirable to compare two variances rather than two averages. For instance,
college administrators would like two college professors grading exams to
have the same variation in their grading. In order for a lid to fit a container,
the variation in the lid and the container should be the same. A supermarket
might be interested in the variability of check-out times for two checkers.

In order to perform a F test of two variances, it is important that the
following are true:

    1. The populations from which the two samples are drawn are normally
      distributed.

    2. The two populations are independent of each other.

Suppose we sample randomly from two independent normal populations.

Let  2       and       2       be  the  population           variances          and  s2     and  s2     be  the  sample

          1                 2                                                            1           2

variances. Let the sample sizes be n1 and n2. Since we are interested in

comparing the two sample variances, we use the F ratio

                           2
               (s 1 )

         [ 2]

               ( 1 )

F=           (s )2
                  2

         [          2  ]

             ( )
             2

F has the distribution F ~ F (n1 - 1, n2 - 1)

where n1 - 1 are the degrees of freedom for the numerator and n2 - 1 are
the degrees of freedom for the denominator.

If  the  null       hypothesis          is        2       =  2,      then  the  F-Ratio     becomes
                                                                  2
                                                       1

             (s )2
             1
         [             ]
                    2               .2

F=           ( 1 )            =  (s1 )

               (s )2                           2
                     2
                                 (s2 )
         [ 2]

               ( 2 )
                                                                                                                                                                      2

                                                                                                           (s2 )

Note:The F ratio could also be 2 . It depends on Ha and on which

                                                                                                           (s1 )

sample variance is larger.

If     the  two  populations   have   equal     variances,    then  s2     and  s2     are  close      in

                                                                        1           2

                                                                                          2

                                                     (s1 )

value and F = 2 is close to 1. But if the two population variances are

                                                     (s2 )

very   different,  s2     and  s2     tend  to  be  very  different,  too.  Choosing            s2     as                                                                the

                       1           2                                                                1

                                                    (s1 )  2

larger sample variance causes the ratio                       to  be  greater   than        1.  If     2                                                                 and
                                                                                                       s
                                                           2
                                                                                                           1
                                                    (s2 )

                                      (s1 )  2

2      are  far  apart,  then                2 is a large number.
s                              F  =

    2                                 (s2 )

Therefore, if F is close to 1, the evidence favors the null hypothesis (the
two population variances are equal). But if F is much larger than 1, then the
evidence is against the null hypothesis.

A test of two variances may be left, right, or two-tailed.

Example:
Two college instructors are interested in whether or not there is any
variation in the way they grade math exams. They each grade the same set
of 30 exams. The first instructor's grades have a variance of 52.3. The
second instructor's grades have a variance of 89.9.
Exercise:

   Problem:

   Test the claim that the first instructor's variance is smaller. (In most
   colleges, it is desirable for the variances of exam grades to be nearly
   the same among instructors.) The level of significance is 10%.

   Solution:
Let 1 and 2 be the subscripts that indicate the first and second
instructor, respectively.

n1 = n2 = 30.

Ho: 2 = 2 and Ha: 2<2
    1         2                                 1        2

Calculate     the        test  statistic:          By       the  null  hypothesis           2  =   ) 2 ,  the  F
                                                                                                       2
                                                                                   (

                                                                                            1

statistic is

F=                    2  =                2  =     52.3     = 0.5818
          (s 1 )                                   89.9
                            (s1 )
    [ 2]
                                          2
          ( 1 )
                            (s2 )
          (s )2
                2

    [ 2]

          ( 2 )

Distribution for the test: F29,29                                where n1 - 1 = 29 and
n2 - 1 = 29.

Graph: This test is left tailed.

Draw the graph labeling and shading appropriately.

Probability statement: p-value = P (F < 0.5818) = 0.0753

Compare  and the p-value:  = 0.10                                       > p-value.

Make a decision: Since  > p-value, reject Ho.
Conclusion: With a 10% level of significance, from the data, there is
sufficient evidence to conclude that the variance in grades for the first
instructor is smaller.

TI-83+ and TI-84: Press STAT and arrow over to TESTS. Arrow
down to D:2-SampFTest. Press ENTER. Arrow to Stats and

press ENTER. For Sx1, n1, Sx2, and n2, enter (52.3), 30,

(89.9), and 30. Press ENTER after each. Arrow to 1: and <2.
Press ENTER. Arrow down to Calculate and press ENTER.
F = 0.5818 and p-value = 0.0753. Do the procedure again and try
Draw instead of Calculate.
Summary
This module provides a summary of F Distribution and One-Way ANOVA
as a part of Collaborative Statistics collection (col10522) by Barbara
Illowsky and Susan Dean.

      A One-Way ANOVA hypothesis test determines if several population
      means are equal. The distribution for the test is the F distribution with
      2 different degrees of freedom.
      Assumptions:

         1. Each population from which a sample is taken is assumed to be
            normal.

         2. Each sample is randomly selected and independent.
         3. The populations are assumed to have equal standard deviations

            (or variances)

      A Test of Two Variances hypothesis test determines if two variances
      are the same. The distribution for the hypothesis test is the F
      distribution with 2 different degrees of freedom.
      Assumptions:

         1. The populations from which the two samples are drawn are
            normally distributed.

         2. The two populations are independent of each other.
The Chi-Square Distribution
This module provides an introduction to Chi-Square Distribution as a part
of Collaborative Statistics collection (col10522) by Barbara Illowsky and
Susan Dean.

Student Learning Outcomes

By the end of this chapter, the student should be able to:

      Interpret the chi-square probability distribution as the sample size
      changes.
      Conduct and interpret chi-square goodness-of-fit hypothesis tests.
      Conduct and interpret chi-square test of independence hypothesis tests.
      Conduct and interpret chi-square homogeneity hypothesis tests.
      Conduct and interpret chi-square single variance hypothesis tests.

Introduction

Have you ever wondered if lottery numbers were evenly distributed or if
some numbers occurred with a greater frequency? How about if the types of
movies people preferred were different across different age groups? What
about if a coffee machine was dispensing approximately the same amount
of coffee each time? You could answer these questions by conducting a
hypothesis test.

You will now study a new distribution, one that is used to determine the
answers to the above examples. This distribution is called the Chi-square
distribution.

In this chapter, you will learn the three major applications of the Chi-square
distribution:

      The goodness-of-fit test, which determines if data fit a particular
      distribution, such as with the lottery example
      The test of independence, which determines if events are independent,
      such as with the movie example
      The test of a single variance, which tests variability, such as with the
      coffee example

Note:Though the Chi-square calculations depend on calculators or
computers for most of the calculations, there is a table available (see the
Table of Contents 15. Tables). TI-83+ and TI-84 calculator instructions are
included in the text.

Optional Collaborative Classroom Activity

Look in the sports section of a newspaper or on the Internet for some sports
data (baseball averages, basketball scores, golf tournament scores, football
odds, swimming times, etc.). Plot a histogram and a boxplot using your
data. See if you can determine a probability distribution that your data fits.
Have a discussion with the class about your choice.
Notation
This module provides an overview of Chi-Square Distribution Notation as a
part of Collaborative Statistics collection (col10522) by Barbara Illowsky
and Susan Dean.

The notation for the chi-square distribution is:

2 ~ 2
                       df

where df = degrees of freedom depend on how chi-square is being used. (If
you want to practice calculating chi-square probabilities then use
df = n - 1. The degrees of freedom for the three major uses are each
calculated differently.)

For the 2 distribution, the population mean is  = df and the population
standard deviation is  = 2  df.

The  random                   variable  is  shown  as       2  but  may  be  any  upper  case  letter.

                                                       

The random variable for a chi-square distribution with k degrees of freedom
is the sum of k independent, squared standard normal variables.

     2  Z1                 2  +               2                 2

=                                Z2 + ... +        Zk
Facts About the Chi-Square Distribution

   1. The curve is nonsymmetrical and skewed to the right.
   2. There is a different chi-square curve for each df.

3. The test statistic for any test is always greater than or equal to zero.

4. When df > 90, the chi-square curve approximates the normal. For X

~  2          the  mean,    =  df  =  1000  and  the  standard  deviation,

        1000

 = 2  1000 = 44.7. Therefore, X ~ N (1000, 44.7),

approximately.

5. The mean, , is located just to the right of the peak.

In the next sections, you will learn about four different applications of the
Chi-Square Distribution. These hypothesis tests are almost always right-
tailed tests. In order to understand why the tests are mostly right-tailed, you
will need to look carefully at the actual definition of the test statistic. Think
about the following while you study the next four sections. If the expected
and observed values are "far" apart, then the test statistic will be "large" and
we will reject in the right tail. The only way to obtain a test statistic very
close to zero, would be if the observed and expected values are very, very
close to each other. A left-tailed test could be used to determine if the fit
were "too good." A "too good" fit might occur if data had been manipulated
or invented. Think about the implications of right-tailed versus left-tailed
hypothesis tests as you learn the applications of the Chi-Square
Distribution.
Goodness-of-Fit Test
This module describes how the chi-square distribution is used to conduct goodness-of-fit
test.

In this type of hypothesis test, you determine whether the data "fit" a particular
distribution or not. For example, you may suspect your unknown data fit a binomial
distribution. You use a chi-square test (meaning the distribution for the hypothesis test is
chi-square) to determine if there is a fit or not. The null and the alternate hypotheses
for this test may be written in sentences or may be stated as equations or
inequalities.

The test statistic for a goodness-of-fit test is:
Equation:

   (O - E)2



k                                                  E

where:

      O = observed values (data)
      E = expected values (from theory)
      k = the number of different data cells or categories

The observed values are the data values and the expected values are the values you
would expect to get if the null hypothesis were true. There are n terms of the form
. (O-E)2

          E

The degrees of freedom are df = (number of categories - 1).

The goodness-of-fit test is almost always right tailed. If the observed values and the
corresponding expected values are not close to each other, then the test statistic can get
very large and will be way out in the right tail of the chi-square curve.

Note:The expected value for each cell needs to be at least 5 in order to use this test.

Example:
Absenteeism of college students from math classes is a major concern to math
instructors because missing class appears to increase the drop rate. Suppose that a study
was done to determine if the actual student absenteeism follows faculty perception. The
faculty expected that a group of 100 students would miss class according to the
following chart.

Number absences per term  Expected number of students
0 - 2                     50
3 - 5                     30
6 - 8                     12
9 - 11                    6
12+                       2

A random survey across all mathematics courses was then done to determine the actual
number (observed) of absences in a course. The next chart displays the result of that
survey.

Number absences per term  Actual number of students
0 - 2                     35
3 - 5                     40
6 - 8                     20
9 - 11                    1
12+                       4

Determine the null and alternate hypotheses needed to conduct a goodness-of-fit test.
Ho: Student absenteeism fits faculty perception.
The alternate hypothesis is the opposite of the null hypothesis.
Ha: Student absenteeism does not fit faculty perception.
Exercise:

   Problem:

   Can you use the information as it appears in the charts to conduct the goodness-of-
   fit test?

   Solution:

   No. Notice that the expected number of absences for the "12+" entry is less than 5
   (it is 2). Combine that group with the "9 - 11" group to create new tables where the
   number of students for each entry are at least 5. The new tables are below.

Number absences per term  Expected number of students
0 - 2                     50
3 - 5                     30
6 - 8                     12
9+                        8

Number absences per term  Actual number of students
0 - 2                     35
3 - 5                     40
6 - 8                     20
9+                        5
Exercise:

   Problem: What are the degrees of freedom (df)?
   Solution:
   There are 4 "cells" or categories in each of the new tables.

     df = number of cells - 1 = 4 - 1 = 3

Example:
Employers particularly want to know which days of the week employees are absent in a
five day work week. Most employers would like to believe that employees are absent
equally during the week. Suppose a random sample of 60 managers were asked on
which day of the week did they have the highest number of employee absences. The
results were distributed as follows:

             Monday Tuesday Wednesday Thursday Friday

Number

of           15  12                     9   9  15

Absences

Day of the Week Employees were most Absent

Exercise:
   Problem:

For the population of employees, do the days for the highest number of absences
occur with equal frequencies during a five day work week? Test at a 5%
significance level.

Solution:

The null and alternate hypotheses are:
    Ho: The absent days occur with equal frequencies, that is, they fit a uniform
    distribution.
    Ha: The absent days occur with unequal frequencies, that is, they do not fit a
    uniform distribution.

If the absent days occur with equal frequencies, then, out of 60 absent days (the
total in the sample: 15 + 12 + 9 + 9 + 15 = 60), there would be 12 absences on
Monday, 12 on Tuesday, 12 on Wednesday, 12 on Thursday, and 12 on Friday.
These numbers are the expected (E) values. The values in the table are the
observed (O) values or data.

This time, calculate the 2 test statistic by hand. Make a chart with the following
headings and fill in the columns:

      Expected (E) values (12, 12, 12, 12, 12)
      Observed (O) values (15, 12, 9, 9, 15)

           (O - E)

                                               2

           (O - E)

                                                    2

                  (O-E)

                          E

                                                                                                               2

                                                           (O-E)

The last column ( E ) should have 0.75, 0, 0.75, 0.75, 0.75.
Now add (sum) the last column. Verify that the sum is 3. This is the 2 test
statistic.

To  find  the  p-value,  calculate                 2  >  3).  This  test  is  right-tailed.

                                    P (

(Use a computer or calculator to find the p-value. You should get

p-value = 0.5578.)

The df s are the number of cells - 1 = 5 - 1 = 4.

TI-83+ and TI-84: Press 2nd DISTR. Arrow down to 2cdf. Press ENTER.
Enter (3,10^99,4). Rounded to 4 decimal places, you should see 0.5578 which
is the p-value.

Next, complete a graph like the one below with the proper labeling and shading.
(You should shade the right tail.)
The decision is to not reject the null hypothesis.
Conclusion: At a 5% level of significance, from the sample data, there is not
sufficient evidence to conclude that the absent days do not occur with equal
frequencies.

Note:TI-83+ and some TI-84 calculators do not have a special program for the test
statistic for the goodness-of-fit test. The next example (Example 11-3) has the
calculator instructions. The newer TI-84 calculators have in
STAT TESTS
the test
Chi2 GOF
. To run the test, put the observed values (the data) into a first list and the expected
values (the values you expect if the null hypothesis is true) into a second list. Press
STAT
TESTS
and
Chi2 GOF
. Enter the list names for the Observed list and the Expected list. Enter the degrees
of freedom and press
calculate
or
draw
. Make sure you clear any lists before you start. See below.

Note:To Clear Lists in the calculators: Go into
STAT EDIT
and arrow up to the list name area of the particular list. Press
CLEAR
and then arrow down. The list will be cleared. Or, you can press
STAT
and press 4 (for
ClrList
). Enter the list name and press
ENTER
.

Example:
One study indicates that the number of televisions that American families have is
distributed (this is the given distribution for the American population) as follows:

Number of Televisions  Percent
0                      10
1                      16
2                      55
3                      11
over 3                 8
The table contains expected (E) percents.
A random sample of 600 families in the far western United States resulted in the
following data:

Number of Televisions  Frequency
0                      66
1                      119
2                      340
3                      60
over 3                 15
                       Total = 600

The table contains observed (O) frequency values.
Exercise:

   Problem:

   At the 1% significance level, does it appear that the distribution "number of
   televisions" of far western United States families is different from the distribution
   for the American population as a whole?

   Solution:

   This problem asks you to test whether the far western United States families
   distribution fits the distribution of the American families. This test is always right-
   tailed.

   The first table contains expected percentages. To get expected (E) frequencies,
   multiply the percentage by 600. The expected frequencies are:
Number of Televisions                             Percent  Expected Frequency
0                                                 10
1                                                 16       (0.10)  (600) = 60
2                                                 55       (0.16)  (600) = 96
3                                                 11       (0.55)  (600) = 330
over 3                                            8        (0.11)  (600) = 66
                                                           (0.08)  (600) = 48

Therefore, the expected frequencies are 60, 96, 330, 66, and 48. In the TI
calculators, you can let the calculator do the math. For example, instead of 60, enter
.10*600.

Ho: The "number of televisions" distribution of far western United States families
is the same as the "number of televisions" distribution of the American population.

Ha: The "number of televisions" distribution of far western United States families
is different from the "number of televisions" distribution of the American
population.

Distribution  for  the  test:  2       where  df  =  (the  number  of  cells)  -  1  =  5  -  1  =  4.

                                    4

Note:df  600 - 1

Calculate the test statistic: 2 = 29.65
Graph:
Probability statement: p-value = P (2 > 29.65) = 0.000006.
Compare  and the p-value:

            = 0.01
           p-value = 0.000006

So,  > p-value.
Make a decision: Since  > p-value, reject Ho.
This means you reject the belief that the distribution for the far western states is the
same as that of the American population as a whole.
Conclusion: At the 1% significance level, from the data, there is sufficient
evidence to conclude that the "number of televisions" distribution for the far
western United States is different from the "number of televisions" distribution for
the American population as a whole.

Note:TI-83+ and some TI-84 calculators: Press
STAT
and
ENTER
. Make sure to clear lists
L1
,
L2
, and
L3
if they have data in them (see the note at the end of Example 11-2). Into
L1
, put the observed frequencies
66
,
119
,
349
,
60
,
15
. Into
L2
, put the expected frequencies
.10*600, .16*600
,
.55*600
,
.11*600
,
.08*600
. Arrow over to list
L3
and up to the name area
"L3"
. Enter
(L1-L2)^2/L2
and
ENTER
. Press
2nd QUIT
. Press
2nd LIST
and arrow over to
MATH
. Press
5
. You should see
"sum" (Enter L3)
. Rounded to 2 decimal places, you should see
29.65
. Press
2nd DISTR
. Press
7
or Arrow down to
7:2cdf
and press
ENTER
. Enter
(29.65,1E99,4)
. Rounded to 4 places, you should see
5.77E-6 = .000006
(rounded to 6 decimal places) which is the p-value.
The newer TI-84 calculators have in
STAT TESTS
the test
Chi2 GOF
. To run the test, put the observed values (the data) into a first list and the expected
values (the values you expect if the null hypothesis is true) into a second list. Press
STAT
TESTS
and
Chi2 GOF
. Enter the list names for the Observed list and the Expected list. Enter the degrees
of freedom and press
calculate
or
draw
. Make sure you clear any lists before you start.

Example:
Exercise:

   Problem:

Suppose you flip two coins 100 times. The results are 20 HH, 27 HT, 30 TH, and
23 TT. Are the coins fair? Test at a 5% significance level.

Solution:

This problem can be set up as a goodness-of-fit problem. The sample space for
flipping two fair coins is {HH, HT, TH, TT}. Out of 100 flips, you would expect 25
HH, 25 HT, 25 TH, and 25 TT. This is the expected distribution. The question, "Are
the coins fair?" is the same as saying, "Does the distribution of the coins (20 HH,
27 HT, 30 TH, 23 TT) fit the expected distribution?"

Random Variable: Let X = the number of heads in one flip of the two coins. X
takes on the value 0, 1, 2. (There are 0, 1, or 2 heads in the flip of 2 coins.)
Therefore, the number of cells is 3. Since X = the number of heads, the observed
frequencies are 20 (for 2 heads), 57 (for 1 head), and 23 (for 0 heads or both tails).
The expected frequencies are 25 (for 2 heads), 50 (for 1 head), and 25 (for 0 heads
or both tails). This test is right-tailed.

Ho: The coins are fair.

Ha: The coins are not fair.

Distribution  for  the  test:  2       where   df    =  3  -  1  =  2.

                                    2

Calculate    the  test  statistic:       2  =  2.14

                                    

Graph:
Probability statement: p-value = P (2 > 2.14) = 0.3430
Compare  and the p-value:

            = 0.05
           p-value = 0.3430

So,  < p-value.
Make a decision: Since  < p-value, do not reject Ho.
Conclusion: There is insufficient evidence to conclude that the coins are not fair.

Note:TI-83+ and some TI- 84 calculators: Press
STAT
and
ENTER
. Make sure you clear lists
L1
,
L2
, and
L3
if they have data in them. Into
L1
, put the observed frequencies
20
,
57
,
23
. Into
L2
, put the expected frequencies
25
,
50
,
25
. Arrow over to list
L3
and up to the name area
"L3"
. Enter
(L1-L2)^2/L2
and
ENTER
. Press
2nd QUIT
. Press
2nd LIST
and arrow over to
MATH
. Press
5
. You should see
"sum"
.
Enter L3
. Rounded to 2 decimal places, you should see
2.14
. Press
2nd DISTR
. Arrow down to
7:2cdf
(or press
7
). Press
ENTER
. Enter
2.14,1E99,2)
. Rounded to 4 places, you should see
.3430
which is the p-value.

The newer TI-84 calculators have in
STAT TESTS
the test
Chi2 GOF
. To run the test, put the observed values (the data) into a first list and the expected
values (the values you expect if the null hypothesis is true) into a second list. Press
STAT
TESTS
and
Chi2 GOF
. Enter the list names for the Observed list and the Expected list. Enter the degrees
of freedom and press
calculate
or
draw
. Make sure you clear any lists before you start.
Test of Independence
This module describes how the chi-square distribution can be used to test for independence.

Tests of independence involve using a contingency table of observed (data) values. You first
saw a contingency table when you studied probability in the Probability Topics chapter.

The test statistic for a test of independence is similar to that of a goodness-of-fit test:
Equation:

                                                                                    (O - E)2

                                                                              

                                                                              (ij)  E

where:

     O = observed values
     E = expected values
     i = the number of rows in the table
     j = the number of columns in the table

                                                                      (O-E)2
There are i  j terms of the form                                           .

                                                                      E

A test of independence determines whether two factors are independent or not. You first
encountered the term independence in Chapter 3. As a review, consider the following
example.

Note:The expected value for each cell needs to be at least 5 in order to use this test.

Example:

Suppose A = a speeding violation in the last year and B = a cell phone user while driving. If

A and B are independent then P (A AND B) = P (A)P (B). A AND B is the event that a

driver received a speeding violation last year and is also a cell phone user while driving.

Suppose, in a study of drivers who received speeding violations in the last year and who uses

cell phones while driving, that 755 people were surveyed. Out of the 755, 70 had a speeding

violation and 685 did not; 305 were cell phone users while driving and 450 were not.

Let y = expected number of drivers that use a cell phone while driving and received speeding

violations.

If A and B are independent, then P (A AND B) = P (A)P (B). By substitution,

y       70     305

755  =  755    755

Solve for y : y = 70305 = 28.3
                                                                 755

About 28 people from the sample are expected to be cell phone users while driving and to

receive speeding violations.
In a test of independence, we state the null and alternate hypotheses in words. Since the
contingency table consists of two factors, the null hypothesis states that the factors are
independent and the alternate hypothesis states that they are not independent (dependent).
If we do a test of independence using the example above, then the null hypothesis is:
Ho: Being a cell phone user while driving and receiving a speeding violation are independent
events.
If the null hypothesis were true, we would expect about 28 people to be cell phone users
while driving and to receive a speeding violation.
The test of independence is always right-tailed because of the calculation of the test
statistic. If the expected and observed values are not close together, then the test statistic is
very large and way out in the right tail of the chi-square curve, like goodness-of-fit.
The degrees of freedom for the test of independence are:

df = (number of columns - 1)(number of rows - 1)

The following formula calculates the expected number (E):

E=  (row total)(column total)
       total number surveyed

Example:
In a volunteer group, adults 21 and older volunteer from one to nine hours each week to
spend time with a disabled senior citizen. The program recruits among community college
students, four-year college students, and nonstudents. The following table is a sample of the
adult volunteers and the number of hours they volunteer per week.

Type of Volunteer              1-3    4-6                  7-9    Row
                               Hours  Hours                Hours  Total

Community College 111 96 48 255
Students

Four-Year College              96     133                  61     290
Students

Nonstudents                    91     150                  53     294

Column Total                   298    379                  162    839

Number of Hours Worked Per Week by Volunteer Type (Observed)The table contains
observed (O) values (data).

Exercise:
Problem: Are the number of hours volunteered independent of the type of volunteer?

Solution:

The observed table and the question at the end of the problem, "Are the number of
hours volunteered independent of the type of volunteer?" tell you this is a test of
independence. The two factors are number of hours volunteered and type of
volunteer. This test is always right-tailed.

Ho: The number of hours volunteered is independent of the type of volunteer.

Ha: The number of hours volunteered is dependent on the type of volunteer.

The expected table is:

Type of Volunteer                                1-3 Hours  4-6 Hours               7-9 Hours

Community College Students                       90.57      115.19                  49.24

Four-Year College Students                       103.00     131.00                  56.00

Nonstudents                                      104.42     132.81                  56.77

Number of Hours Worked Per Week by Volunteer Type (Expected)The table contains
expected (E) values (data).

For example, the calculation for the expected frequency for the top left cell is

E=  (row total)(column total)  =       255298    = 90.57
       total number surveyed                839

Calculate  the  test  statistic:       2  =  12.99        (calculator or computer)

                                  

Distribution  for  the  test:       2

                               

                                    4

df = (3 columns - 1)(3 rows - 1) = (2)(2) = 4

Graph:
   Probability statement: p-value = P (2 > 12.99) = 0.0113

   Compare  and the p-value: Since no  is given, assume  = 0.05.
   p-value = 0.0113.  > p-value.

   Make a decision: Since  > p-value, reject Ho. This means that the factors are not
   independent.

   Conclusion: At a 5% level of significance, from the data, there is sufficient evidence to
   conclude that the number of hours volunteered and the type of volunteer are dependent
   on one another.

   For the above example, if there had been another type of volunteer, teenagers, what
   would the degrees of freedom be?

   Note:Calculator instructions follow.

   TI-83+ and TI-84 calculator: Press the MATRX key and arrow over to EDIT. Press 1:
   [A]. Press 3 ENTER 3 ENTER. Enter the table values by row from Example 11-6.
   Press ENTER after each. Press 2nd QUIT. Press STAT and arrow over to TESTS.
   Arrow down to C:2-TEST. Press ENTER. You should see Observed:[A] and
   Expected:[B]. Arrow down to Calculate. Press ENTER. The test statistic is
   12.9909 and the p-value = 0.0113. Do the procedure a second time but arrow down to
   Draw instead of calculate.

Example:
De Anza College is interested in the relationship between anxiety level and the need to
succeed in school. A random sample of 400 students took a test that measured anxiety level
and need to succeed in school. The table shows the results. De Anza College wants to know
if anxiety level and need to succeed in school are independent events.
Need to      High                 Med-       Medium   Med-     Low                   Row
Succeed      Anxiety              high       Anxiety  low      Anxiety               Total
in                                Anxiety             Anxiety
School

High 35 42 53                                         15       10                    155
Need

Medium 18 48 63                                       33       31                    193
Need

Low 4 5 11 15 17 52
Need

Column 57 95 127 63 58 400
Total

Need to Succeed in School vs. Anxiety Level

Exercise:
   Problem:

How many high anxiety level students are expected to have a high need to succeed in
school?

Solution:

The column total for a high anxiety level is 57. The row total for high need to succeed
in school is 155. The sample size or total surveyed is 400.

E=  (row total)(column total)     =  15557   = 22.09
                  total surveyed        400

   The expected number of students who have a high anxiety level and a high need to
   succeed in school is about 22.

Exercise:

   Problem:

If the two variables are independent, how many students do you expect to have a low
need to succeed in school and a med-low level of anxiety?

Solution:

The column total for a med-low anxiety level is 63. The row total for a low need to
succeed in school is 52. The sample size or total surveyed is 400.
Exercise:
   Problem:

             (row total)(column total)
                           total surveyed
a = E =

b The expected number of students who have a med-low anxiety level and a

low need to succeed in school is about:

Solution:

aE =         (row total)(column total)     = 8.19
b 8                        total surveyed

Glossary

Contingency Table
      The method of displaying a frequency distribution as a table with rows and columns to
      show how two variables may be dependent (contingent) upon each other. The table
      provides an easy way to calculate conditional probabilities.
Test of a Single Variance (Optional)
This module provides an overview on Chi-Square Distribution Tests of
Variance as a part of Collaborative Statistics collection (col10522) by
Barbara Illowsky and Susan Dean.

A test of a single variance assumes that the underlying distribution is
normal. The null and alternate hypotheses are stated in terms of the
population variance (or population standard deviation). The test statistic
is:
Equation:

                                                                          (n - 1)  s2

                                                                                     2

where:

n = the total number of data

s2 = sample variance

     2  =  population  variance



You may think of s as the random variable in this test. The degrees of
freedom are df = n - 1.

A test of a single variance may be right-tailed, left-tailed, or two-tailed.

The following example will show you how to set up the null and alternate
hypotheses. The null and alternate hypotheses contain statements about the
population variance.

Example:
Exercise:
   Problem:

   Math instructors are not only interested in how their students do on
   exams, on average, but how the exam scores vary. To many
   instructors, the variance (or standard deviation) may be more
   important than the average.

   Suppose a math instructor believes that the standard deviation for his
   final exam is 5 points. One of his best students thinks otherwise. The
   student claims that the standard deviation is more than 5 points. If the
   student were to conduct a hypothesis test, what would the null and
   alternate hypotheses be?

   Solution:

   Even though we are given the population standard deviation, we can
   set the test up using the population variance as follows.

         Ho: 2 = 52
         Ha: 2 > 52

Example:
Exercise:

   Problem:

   With individual lines at its various windows, a post office finds that
   the standard deviation for normally distributed waiting times for
   customers on Friday afternoon is 7.2 minutes. The post office
   experiments with a single main waiting line and finds that for a
   random sample of 25 customers, the waiting times for customers have
   a standard deviation of 3.5 minutes.

   With a significance level of 5%, test the claim that a single line
   causes lower variation among waiting times (shorter waiting
times) for customers.

Solution:

Since the claim is that a single line causes lower variation, this is a
test of a single variance. The parameter is the population variance, 2,
or the population standard deviation, .

Random Variable: The sample standard deviation, s, is the random
variable. Let s = standard deviation for the waiting times.

Ho: 2 = 7.22
Ha: 2<7.22

The word "lower" tells you this is a left-tailed test.

Distribution  for                        the  test:  2 ,                            where:
                                                          24

n = the number of customers sampled

df = n - 1 = 25 - 1 = 24

Calculate the test statistic:

2 =                                2  =                                          2  = 5.67

     (n-1)s                              (25-1)3.5
             2
                                                                   2

                                                   7.2

where n = 25, s = 3.5, and  = 7.2.

Graph:

Probability statement: p-value = P (2 < 5.67) = 0.000042
Compare  and the p-value:

 = 0.05  p-value = 0.000042   > p-value

Make a decision: Since  > p-value, reject Ho.

This means that you reject 2 = 7.22. In other words, you do not
think the variation in waiting times is 7.2 minutes, but lower.

Conclusion: At a 5% level of significance, from the data, there is
sufficient evidence to conclude that a single line causes a lower
variation among the waiting times or with a single line, the customer
waiting times vary less than 7.2 minutes.

TI-83+ and TI-84 calculators: In 2nd DISTR, use 7:2cdf. The
syntax is (lower, upper, df) for the parameter list. For
Example 11-9, 2cdf(-1E99,5.67,24). The
p-value = 0.000042.
Summary of Formulas
This module provides a summary on formulas used in Chi-Square
Distribution as a part of Collaborative Statistics collection (col10522) by
Barbara Illowsky and Susan Dean.

The Chi-Square Probability Distribution

 = df and  = 2  df
Goodness-of-Fit Hypothesis Test

Use goodness-of-fit to test whether a data set fits a particular
probability distribution.
The degrees of freedom are number of cells or categories - 1.

                                                                                                                               2

                                                                       (O-E)

The test statistic is  E , where O = observed values (data), E =
                                                                k

expected values (from theory), and k = the number of different data
cells or categories.
The test is right-tailed.

Test of Independence

Use the test of independence to test whether two factors are
independent or not.
The degrees of freedom are equal to
(number of columns - 1)(number of rows - 1).

                                                                                                                                      2

                                                                            (O-E)

The test statistic is  E where O = observed values, E =

                                                               (ij)

expected values, i = the number of rows in the table, and j = the
number of columns in the table.
The test is right-tailed.
If the null hypothesis is true, the expected number

E=  . (row total)(column total)
                  total surveyed

Test of Homogeneity

Use the test for homogeneity to decide if two populations with
unknown distributions have the same distribution as each other.
The degrees of freedom are equal to number of columns - 1.
                                                                            (O-E)2

The test statistic is  E where O = observed values, E =

                                                               (ij)

expected values, i = the number of rows in the table, and j = the
number of columns in the table.
The test is right-tailed.
If the null hypothesis is true, the expected number

E=  . (row total)(column total)
                  total surveyed

Note:The expected value for each cell needs to be at least 5 in order to use
the Goodness-of-Fit, Independence and Homogeneity tests.

Test of a Single Variance

Use the test to determine variation.

The degrees of freedom are the number of samples - 1.

                                                                   n-1 s2
                                                                                                                                                                                                                           2

The test statistic is 2 , where n = the total number of data, s =

sample  variance,  and         2  =  population  variance.

                           

The test may be left, right, or two-tailed.
Linear Regression and Correlation
This module provides an introduction of Linear Regression and Correlation
as a part of Collaborative Statistics collection (col10522) by Barbara
Illowsky and Susan Dean.

Student Learning Outcomes

By the end of this chapter, the student should be able to:

      Discuss basic ideas of linear regression and correlation.
      Create and interpret a line of best fit.
      Calculate and interpret the correlation coefficient.
      Calculate and interpret outliers.

Introduction

Professionals often want to know how two or more numeric variables are
related. For example, is there a relationship between the grade on the
second math exam a student takes and the grade on the final exam? If there
is a relationship, what is it and how strong is the relationship?

In another example, your income may be determined by your education,
your profession, your years of experience, and your ability. The amount you
pay a repair person for labor is often determined by an initial amount plus
an hourly fee. These are all examples in which regression can be used.

The type of data described in the examples is bivariate data - "bi" for two
variables. In reality, statisticians use multivariate data, meaning many
variables.

In this chapter, you will be studying the simplest form of regression, "linear
regression" with one independent variable ( ). This involves data that fits a
line in two dimensions. You will also study correlation which measures how
strong the relationship is.
Linear Regression and Correlation: Linear Equations
Linear regression for two variables is based on a linear equation with one
independent variable. It has the form:
Equation:

                                                                          y = a + bx

where a and b are constant numbers.
x is the independent variable, and y is the dependent variable.
Typically, you choose a value to substitute for the independent variable and
then solve for the dependent variable.

Example:
The following examples are linear equations.
Equation:

                                                                           y = 3 + 2x

Equation:

                                                                  y = -0.01 + 1.2x

The graph of a linear equation of the form y = a + bx is a straight line.
Any line that is not vertical can be described by this equation.

Example:
         Graph of the equation y = -1 + 2x.

Linear equations of this form occur in applications of life sciences, social
sciences, psychology, business, economics, physical sciences, mathematics,
and other areas.

Example:
Aaron's Word Processing Service (AWPS) does word processing. Its rate is
$32 per hour plus a $31.50 one-time charge. The total cost to a customer
depends on the number of hours it takes to do the word processing job.
Exercise:

   Problem:
   Find the equation that expresses the total cost in terms of the number
   of hours required to finish the word processing job.
   Solution:
Let x = the number of hours it takes to get the job done.
Let y = the total cost to the customer.
The $31.50 is a fixed cost. If it takes x hours to complete the job, then
(32)(x) is the cost of the word processing only. The total cost is:

y = 31.50 + 32x
Linear Regression and Correlation: Slope and Y-Intercept of a Linear
Equation

For the linear equation y = a + bx, b = slope and a = y-intercept.

From algebra recall that the slope is a number that describes the steepness
of a line and the y-intercept is the y coordinate of the point (0, a) where the
line crosses the y-axis.

  If b > 0, the line  If b = 0, the  If b < 0, the line slopes
slopes upward to the     line is     downward to the right.

         right.        horizontal.

                      Three possible graphs of y = a + bx.

Example:
Svetlana tutors to make extra money for college. For each tutoring session,
she charges a one time fee of $25 plus $15 per hour of tutoring. A linear
equation that expresses the total amount of money Svetlana earns for each
session she tutors is y = 25 + 15x.
Exercise:

   Problem:
   What are the independent and dependent variables? What is the y-
   intercept and what is the slope? Interpret them using complete
   sentences.

   Solution:
The independent variable (x) is the number of hours Svetlana tutors
each session. The dependent variable (y) is the amount, in dollars,
Svetlana earns for each session.

The y-intercept is 25 (a = 25). At the start of the tutoring session,
Svetlana charges a one-time fee of $25 (this is when x = 0). The slope
is 15 (b = 15). For each session, Svetlana earns $15 for each hour she
tutors.
Scatter Plots
This module provides an overview of Linear Regression and Correlation:
Scatter Plots as a part of Collaborative Statistics collection (col10522) by
Barbara Illowsky and Susan Dean.

Before we take up the discussion of linear regression and correlation, we
need to examine a way to display the relation between two variables x and
y. The most common and easiest way is a scatter plot. The following
example illustrates a scatter plot.

Example:
From an article in the Wall Street Journal: In Europe and Asia, m-
commerce is popular. M-commerce users have special mobile phones that
work like electronic wallets as well as provide phone and Internet services.
Users can do everything from paying for parking to buying a TV set or
soda from a machine to banking to checking sports scores on the Internet.
For the years 2000 through 2004, was there a relationship between the year
and the number of m-commerce users? Construct a scatter plot. Let x = the
year and let y = the number of m-commerce users, in millions.

Table showing the number of  Scatter plot showing the number
    m-commerce users (in         of m-commerce users (in
       millions) by year.             millions) by year.

x (year)  y (# of users)
  2000           0.5
  2002          20.0
x (year)  y (# of users)
  2003          33.0
  2004          47.0

A scatter plot shows the direction and strength of a relationship between
the variables. A clear direction happens when there is either:

      High values of one variable occurring with high values of the other
      variable or low values of one variable occurring with low values of the
      other variable.
      High values of one variable occurring with low values of the other
      variable.

You can determine the strength of the relationship by looking at the scatter
plot and seeing how close the points are to a line, a power function, an
exponential function, or to some other type of function.

When you look at a scatterplot, you want to notice the overall pattern and
any deviations from the pattern. The following scatterplot examples
illustrate these concepts.
Positive Linear Pattern (Strong)

Linear Pattern w/ One Deviation
Negative Linear Pattern (Strong)

Negative Linear Pattern (Weak)

Exponential Growth Pattern

           No Pattern

In this chapter, we are interested in scatter plots that show a linear pattern.
Linear patterns are quite common. The linear relationship is strong if the
points are close to a straight line. If we think that the points show a linear
relationship, we would like to draw a line on the scatter plot. This line can
be calculated through a process called linear regression. However, we only
calculate a regression line if one of the variables helps to explain or predict
the other variable. If x is the independent variable and y the dependent
variable, then we can use a regression line to predict y for a given value of
x.
The Regression Equation
Linear Regression and Correlation: The Regression Equation is a part of
Collaborative Statistics collection (col10522) by Barbara Illowsky and
Susan Dean. Contributions from Roberta Bloom include instructions for
finding and graphing the regression equation and scatterplot using the
LinRegTTest on the TI-83,83+,84+ calculators.

Data rarely fit a straight line exactly. Usually, you must be satisfied with
rough predictions. Typically, you have a set of data whose scatter plot
appears to "fit" a straight line. This is called a Line of Best Fit or Least
Squares Line.

Optional Collaborative Classroom Activity

If you know a person's pinky (smallest) finger length, do you think you
could predict that person's height? Collect data from your class (pinky
finger length, in inches). The independent variable, x, is pinky finger length
and the dependent variable, y, is height.

For each set of data, plot the points on graph paper. Make your graph big
enough and use a ruler. Then "by eye" draw a line that appears to "fit" the
data. For your line, pick two convenient points and use them to find the
slope of the line. Find the y-intercept of the line by extending your lines so
they cross the y-axis. Using the slopes and the y-intercepts, write your
equation of "best fit". Do you think everyone will have the same equation?
Why or why not?

Using your equation, what is the predicted height for a pinky length of 2.5
inches?

Example:
A random sample of 11 statistics students produced the following data
where x is the third exam score, out of 80, and y is the final exam score,
out of 200. Can you predict the final exam score of a random student if you
know the third exam score?
 Table showing the scores on     Scatter plot showing the scores
the final exam based on scores  on the final exam based on scores

      from the third exam.             from the third exam.

x (third     y (final
exam score)  exam
             score)
      65
      67          175
      71          133
      71          185
      66          163
      75          126
      67          198
      70          153
      71          163
      69          159
      69          151
                  159
The third exam score, x, is the independent variable and the final exam
score, y, is the dependent variable. We will plot a regression line that best
"fits" the data. If each of you were to fit a line "by eye", you would draw
different lines. We can use what is called a least-squares regression line to
obtain the best fit line.
Consider the following diagram. Each point of data is of the the form (x, y)
and each point of the line of best fit using least-squares linear regression has
the form (x, y^).
The y^ is read "y hat" and is the estimated value of y. It is the value of y
obtained using the regression line. It is not generally equal to y from data.

The term y0 - y^0 = 0 is called the "error" or residual. It is not an error
in the sense of a mistake. The absolute value of a residual measures the
vertical distance between the actual value of y and the estimated value of y.
In other words, it measures the vertical distance between the actual data
point and the predicted point on the line.
If the observed data point lies above the line, the residual is positive, and
the line underestimates the actual data value for y. If the observed data
point lies below the line, the residual is negative, and the line overestimates
that actual data value for y.
In the diagram above, y0 - y^0 = 0 is the residual for the point shown. Here
the point lies above the line and the residual is positive.

 = the Greek letter epsilon

For each data point, you can calculate the residuals or errors, yi - y^i = i
for i = 1, 2, 3, ..., 11.

Each || is a vertical distance.

For the example about the third exam scores and the final exam scores for
the 11 statistics students, there are 11 data points. Therefore, there are 11 
values. If you square each  and add, you get

                                                  11

        2             2                  2                               2
(1) + (2) + ... + (11) =  

                                                  i=1

This is called the Sum of Squared Errors (SSE).

Using calculus, you can determine the values of a and b that make the SSE
a minimum. When you make the SSE a minimum, you have determined the
points that are on the line of best fit. It turns out that the line of best fit has
the equation:
Equation:

                                         y^ = a + bx

                                                                     
                                         (x-x)(y-y)
where                       and                                   2.
        a  =       -  b            b  =
                y          x

                                                                   

                                             (x-x)

  and    are  the   sample  means      of  the  x  values                 and    the    y      values,  respectively.

x       y

The  best  fit  line  always  passes     through                      the   point        y ).

                                                                                   (x,

                                                                                                                                  sy

The slope b can be written as b = r  ( s ) where sy = the standard
                                                                                                                                                                                            x

deviation of the y values and sx = the standard deviation of the x values. r
is the correlation coefficient which is discussed in the next section.
Least Squares Criteria for Best Fit
The process of fitting the best fit line is called linear regression. The idea
behind finding the best fit line is based on the assumption that the data are
scattered about a straight line. The criteria for the best fit line is that the
sum of the squared errors (SSE) is minimized, that is made as small as
possible. Any other line you might choose would have a higher SSE than
the best fit line. This best fit line is called the least squares regression line
.

Note:Computer spreadsheets, statistical software, and many calculators
can quickly calculate the best fit line and create the graphs. The
calculations tend to be tedious if done by hand. Instructions to use the TI-
83, TI-83+, and TI-84+ calculators to find the best fit line and create a
scatterplot are shown at the end of this section.

THIRD EXAM vs FINAL EXAM EXAMPLE:
The graph of the line of best fit for the third exam/final exam example is
shown below:
The least squares regression line (best fit line) for the third exam/final exam
example has the equation:
Equation:

                                                       y^ = -173.51 + 4.83x

Note:

      Remember, it is always important to plot a scatter diagram first. If the
      scatter plot indicates that there is a linear relationship between the
      variables, then it is reasonable to use a best fit line to make
      predictions for y given x within the domain of x-values in the sample
      data, but not necessarily for x-values outside that domain.
      You could use the line to predict the final exam score for a student
      who earned a grade of 73 on the third exam.
      You should NOT use the line to predict the final exam score for a
      student who earned a grade of 50 on the third exam, because 50 is not
      within the domain of the x-values in the sample data, which are
      between 65 and 75.

UNDERSTANDING SLOPE
The slope of the line, b, describes how changes in the variables are related.
It is important to interpret the slope of the line in the context of the situation
represented by the data. You should be able to write a sentence interpreting
the slope in plain English.

INTERPRETATION OF THE SLOPE: The slope of the best fit line tells
us how the dependent variable (y) changes for every one unit increase in the
independent (x) variable, on average.
THIRD EXAM vs FINAL EXAM EXAMPLE

      Slope: The slope of the line is b = 4.83.
      Interpretation: For a one point increase in the score on the third exam,
      the final exam score increases by 4.83 points, on average.

Using the TI-83+ and TI-84+ Calculators

Using the Linear Regression T Test: LinRegTTest
In the STAT list editor, enter the X data in list L1 and the Y data in list L2,
paired so that the corresponding (x,y) values are next to each other in the
lists. (If a particular pair of values is repeated, enter it as many times as it
appears in the data.)
On the STAT TESTS menu, scroll down with the cursor to select the
LinRegTTest. (Be careful to select LinRegTTest as some calculators may
also have a different item called LinRegTInt.)
On the LinRegTTest input screen enter: Xlist: L1 ; Ylist: L2 ; Freq: 1
On the next line, at the prompt  or , highlight " 0" and press ENTER
Leave the line for "RegEq:" blank
Highlight Calculate and press ENTER.

The output screen contains a lot of information. For now we will focus on a
few items from the output, and will return later to the other items.
The second line says y=a+bx. Scroll down to find the values
a=-173.513, and b=4.8273 ; the equation of the best fit line is

y^ = -173.51 + 4.83x

The  two   items  at  the  bottom  are     2  =  .43969  and  r=.663.  For  now,  just

                                        r

note where to find these values; we will discuss them in the next two

sections.

Graphing the Scatterplot and Regression Line

We are assuming your X data is already entered in list L1 and your Y data is
in list L2
Press 2nd STATPLOT ENTER to use Plot 1
On the input screen for PLOT 1, highlightOnand press ENTER
For TYPE: highlight the very first icon which is the scatterplot and press
ENTER
Indicate Xlist: L1 and Ylist: L2
For Mark: it does not matter which symbol you highlight.
Press the ZOOM key and then the number 9 (for menu item "ZoomStat") ;
the calculator will fit the window to the data
To graph the best fit line, press the "Y=" key and type the equation
-173.5+4.83X into equation Y1. (The X key is immediately left of the STAT
key). Press ZOOM 9 again to graph it.
Optional: If you want to change the viewing window, press the WINDOW
key. Enter your desired window using Xmin, Xmax, Ymin, Ymax

**With contributions from Roberta Bloom
The Correlation Coefficient
Linear Regression and Correlation: The Correlation Coefficient and
Coefficient of Determination is a part of Collaborative Statistics collection
(col10522) by Barbara Illowsky and Susan Dean with contributions from
Roberta Bloom. The name has been changed from Correlation Coefficient.

The Correlation Coefficient r

Besides looking at the scatter plot and seeing that a line seems reasonable,
how can you tell if the line is a good predictor? Use the correlation
coefficient as another indicator (besides the scatterplot) of the strength of
the relationship between x and y.

The correlation coefficient, r, developed by Karl Pearson in the early
1900s, is a numerical measure of the strength of association between the
independent variable x and the dependent variable y.

The correlation coefficient is calculated as
Equation:

r=                     n  x  y - (x)  (y)
    [n  x2 - (x)2 ]  [n  y2 - (y)2 ]

where n = the number of data points.

If you suspect a linear relationship between x and y, then r can measure
how strong the linear relationship is.
What the VALUE of r tells us:

      The value of r is always between -1 and +1: -1  r  1.
      The size of the correlation r indicates the strength of the linear
      relationship between x and y. Values of r close to -1 or to +1 indicate a
      stronger linear relationship between x and y.
      If r=0 there is absolutely no linear relationship between x and y (no
      linear correlation).
      If r = 1, there is perfect positive correlation. If r = -1, there is
      perfect negative correlation. In both these cases, all of the original data
      points lie on a straight line. Of course, in the real world, this will not
      generally happen.
What the SIGN of r tells us
      A positive value of r means that when x increases, y tends to increase
      and when x decreases, y tends to decrease (positive correlation).
      A negative value of r means that when x increases, y tends to decrease
      and when x decreases, y tends to increase (negative correlation).
      The sign of r is the same as the sign of the slope, b, of the best fit line.

Note:Strong correlation does not suggest that x causes y or y causes x. We
say "correlation does not imply causation." For example, every person
who learned math in the 17th century is dead. However, learning math does
not necessarily cause death!

Positive Correlation

   A scatter plot
   showing data

        with a
       positive
    correlation.

          0<r<1

Negative Correlation
   A scatter plot
   showing data

        with a
      negative
    correlation.

        -1 < r < 0

  Zero Correlation

   A scatter plot
   showing data

      with zero
   correlation. r

          =0

The formula for r looks formidable. However, computer spreadsheets,
statistical software, and many calculators can quickly calculate r. The
correlation coefficient r is the bottom item in the output screens for the
LinRegTTest on the TI-83, TI-83+, or TI-84+ calculator (see previous
section for instructions).

The Coefficient of Determination
r2 is called the coefficient of determination. r2 is the square of the

correlation coefficient , but is usually stated as a percent, rather than in

decimal  form.      2  has  an  interpretation  in   the   context  of                the  data:

                r

r2, when expressed as a percent, represents the percent of variation in
the dependent variable y that can be explained by variation in the
independent variable x using the regression (best fit) line.
1-r2, when expressed as a percent, represents the percent of variation
in y that is NOT explained by variation in x using the regression line.
This can be seen as the scattering of the observed data points about the
regression line.

Consider the third exam/final exam example introduced in the previous
section

The line of best fit is: y^ = -173.51 + 4.83x

The correlation coefficient is r = 0.6631

The      coefficient   of   determination       is  r2  =                          2  =  0.4397

                                                           0.6631

Interpretation         of       2  in  the  context  of   this  example:

                            r

Approximately 44% of the variation (0.4397 is approximately 0.44) in

the final exam grades can be explained by the variation in the grades

on the third exam, using the best fit regression line.

Therefore approximately 56% of the variation (1 - 0.44 = 0.56) in the

final exam grades can NOT be explained by the variation in the grades

on the third exam, using the best fit regression line. (This is seen as the

scattering of the points about the line.)

**With contributions from Roberta Bloom.

Glossary

Coefficient of Correlation
      A measure developed by Karl Pearson (early 1900s) that gives the
      strength of association between the independent variable and the
      dependent variable. The formula is:
      Equation:
r=                       n  xy - ( x)( y)
                                                                                                        ,

    [n  x2 - ( x)2 ][n  y2 - ( y)2 ]

where n is the number of data points. The coefficient cannot be more
then 1 and less then -1. The closer the coefficient is to 1, the stronger
the evidence of a significant linear relationship between x and y.
Facts About the Correlation Coefficient for Linear Regression
Linear Regression and Correlation: Testing the Significance of the
Correlation Coefficient is a part of Collaborative Statistics collection
(col10522) by Barbara Illowsky and Susan Dean. The title has been
changed from Facts About the Correlation Coefficient for Linear
Regression. Roberta Bloom has made major contributions to this module.

Testing the Significance of the Correlation Coefficient

The correlation coefficient, r, tells us about the strength of the linear
relationship between x and y. However, the reliability of the linear model
also depends on how many observed data points are in the sample. We need
to look at both the value of the correlation coefficient r and the sample size
n, together.

We perform a hypothesis test of the "significance of the correlation
coefficient" to decide whether the linear relationship in the sample data is
strong enough to use to model the relationship in the population.

The sample data is used to compute r, the correlation coefficient for the
sample. If we had data for the entire population, we could find the
population correlation coefficient. But because we only have sample data,
we can not calculate the population correlation coefficient. The sample
correlation coefficient, r, is our estimate of the unknown population
correlation coefficient.

      The symbol for the population correlation coefficient is , the Greek
      letter "rho".
       = population correlation coefficient (unknown)
      r = sample correlation coefficient (known; calculated from sample
      data)

The hypothesis test lets us decide whether the value of the population
correlation coefficient  is "close to 0" or "significantly different from 0".
We decide this based on the sample correlation coefficient r and the sample
size n.
If the test concludes that the correlation coefficient is significantly
different from 0, we say that the correlation coefficient is "significant".

      Conclusion: "There is sufficient evidence to conclude that there is a
      significant linear relationship between x and y because the correlation
      coefficient is significantly different from 0."
      What the conclusion means: There is a significant linear relationship
      between x and y. We can use the regression line to model the linear
      relationship between x and y in the population.

If the test concludes that the correlation coefficient is not significantly
different from 0 (it is close to 0), we say that correlation coefficient is
"not significant".

      Conclusion: "There is insufficient evidence to conclude that there is a
      significant linear relationship between x and y because the correlation
      coefficient is not significantly different from 0."
      What the conclusion means: There is not a significant linear
      relationship between x and y. Therefore we can NOT use the
      regression line to model a linear relationship between x and y in the
      population.

Note:

      If r is significant and the scatter plot shows a linear trend, the line can
      be used to predict the value of y for values of x that are within the
      domain of observed x values.
      If r is not significant OR if the scatter plot does not show a linear
      trend, the line should not be used for prediction.
      If r is significant and if the scatter plot shows a linear trend, the line
      may NOT be appropriate or reliable for prediction OUTSIDE the
      domain of observed x values in the data.
PERFORMING THE HYPOTHESIS TEST
SETTING UP THE HYPOTHESES:

      Null Hypothesis: Ho:  = 0
      Alternate Hypothesis: Ha:   0

What the hypotheses mean in words:

      Null Hypothesis Ho: The population correlation coefficient IS NOT
      significantly different from 0. There IS NOT a significant linear
      relationship(correlation) between x and y in the population.
      Alternate Hypothesis Ha: The population correlation coefficient IS
      significantly DIFFERENT FROM 0. There IS A SIGNIFICANT
      LINEAR RELATIONSHIP (correlation) between x and y in the
      population.

DRAWING A CONCLUSION:

      There are two methods to make the decision. Both methods are
      equivalent and give the same result.
      Method 1: Using the p-value
      Method 2: Using a table of critical values
      In this chapter of this textbook, we will always use a significance level
      of 5%,  = 0.05
      Note: Using the p-value method, you could choose any appropriate
      significance level you want; you are not limited to using  = 0.05. But
      the table of critical values provided in this textbook assumes that we
      are using a significance level of 5%,  = 0.05. (If we wanted to use a
      different significance level than 5% with the critical value method, we
      would need different tables of critical values that are not provided in
      this textbook.)

METHOD 1: Using a p-value to make a decision

      The linear regression t-test LinRegTTEST on the TI-83+ or TI-84+
      calculators calculates the p-value.
      On the LinRegTTEST input screen, on the line prompt for  or ,
      highlight " 0"
The output screen shows the p-value on the line that reads "p =".
(Most computer statistical software can calculate the p-value.)

If the p-value is less than the significance level ( = 0.05):

Decision: REJECT the null hypothesis.
Conclusion: "There is sufficient evidence to conclude that there is a
significant linear relationship between x and y because the correlation
coefficient is significantly different from 0."

If the p-value is NOT less than the significance level ( = 0.05)

Decision: DO NOT REJECT the null hypothesis.
Conclusion: "There is insufficient evidence to conclude that there is a
significant linear relationship between x and y because the correlation
coefficient is NOT significantly different from 0."

Calculation Notes:

You will use technology to calculate the p-value. The following

describe the calculations to compute the test statistics and the p-value:

The p-value is calculated using a t-distribution with n-2 degrees of

freedom.

The formula for the test statistic is t =  rn-2
                                              2 . The value of the test
                                           1-r

statistic, t, is shown in the computer or calculator output along with

the p-value. The test statistic t has the same sign as the correlation

coefficient r.

The p-value is the combined area in both tails.

An alternative way to calculate the p-value (p) given by LinRegTTest

is the command 2*tcdf(abs(t),10^99, n-2) in 2nd DISTR.

THIRD EXAM vs FINAL EXAM EXAMPLE: p value method

Consider the third exam/final exam example.
The line of best fit is: y^ = -173.51 + 4.83x with r = 0.6631 and
there are n = 11 data points.
      Can the regression line be used for prediction? Given a third exam
      score (x value), can we use the line to predict the final exam score
      (predicted y value)?

      Ho:  = 0
      Ha:   0
       = 0.05
      The p-value is 0.026 (from LinRegTTest on your calculator or from
      computer software)
      The p-value, 0.026, is less than the significance level of  = 0.05
      Decision: Reject the Null Hypothesis Ho
      Conclusion: There is sufficient evidence to conclude that there is a
      significant linear relationship between x and y because the correlation
      coefficient is significantly different from 0.
      Because r is significant and the scatter plot shows a linear trend,
      the regression line can be used to predict final exam scores.

METHOD 2: Using a table of Critical Values to make a decision
The 95% Critical Values of the Sample Correlation Coefficient Table at
the end of this chapter (before the Summary) may be used to give you a
good idea of whether the computed value of r is significant or not.
Compare r to the appropriate critical value in the table. If r is not between
the positive and negative critical values, then the correlation coefficient is
significant. If r is significant, then you may want to use the line for
prediction.

Example:
Suppose you computed r = 0.801 using n = 10 data points.
df = n - 2 = 10 - 2 = 8. The critical values associated with df = 8 are
-0.632 and + 0.632. If r< negative critical value or
r > positive critical value, then r is significant. Since r = 0.801 and
0.801 > 0.632, r is significant and the line may be used for prediction. If
you view this example on a number line, it will help you.
       r is not significant between -0.632 and +0.632.
     r = 0.801 > +0.632. Therefore, r is significant.

Example:
Suppose you computed r = -0.624 with 14 data points.
df = 14 - 2 = 12. The critical values are -0.532 and 0.532. Since -0.624
<-0.532, r is significant and the line may be used for prediction

     r = -0.624<-0.532. Therefore, r is significant.

Example:
Suppose you computed r = 0.776 and n = 6. df = 6 - 2 = 4. The
critical values are -0.811 and 0.811. Since -0.811< 0.776 < 0.811, r is
not significant and the line should not be used for prediction.

      -0.811<r = 0.776<0.811. Therefore, r is not
                            significant.
THIRD EXAM vs FINAL EXAM EXAMPLE: critical value method

      Consider the third exam/final exam example.
      The line of best fit is: y^ = -173.51 + 4.83x with r = 0.6631 and
      there are n = 11 data points.
      Can the regression line be used for prediction? Given a third exam
      score (x value), can we use the line to predict the final exam score
      (predicted y value)?

      Ho:  = 0
      Ha:   0
       = 0.05
      Use the "95% Critical Value" table for r with

           df = n - 2 = 11 - 2 = 9

      The critical values are -0.602 and +0.602
      Since 0.6631 > 0.602, r is significant.
      Decision: Reject Ho:
      Conclusion:There is sufficient evidence to conclude that there is a
      significant linear relationship between x and y because the correlation
      coefficient is significantly different from 0.
      Because r is significant and the scatter plot shows a linear trend,
      the regression line can be used to predict final exam scores.

Example:
Additional Practice Examples using Critical Values
Suppose you computed the following correlation coefficients. Using the
table at the end of the chapter, determine if r is significant and the line of
best fit associated with each r can be used to predict a y value. If it helps,
draw a number line.

   1. r = -0.567 and the sample size, n, is 19. The df = n - 2 = 17. The
      critical value is -0.456. -0.567<-0.456 so r is significant.

   2. r = 0.708 and the sample size, n, is 9. The df = n - 2 = 7. The
      critical value is 0.666. 0.708 > 0.666 so r is significant.

   3. r = 0.134 and the sample size, n, is 14. The df = 14 - 2 = 12. The
      critical value is 0.532. 0.134 is between -0.532 and 0.532 so r is not
      significant.
   4. r = 0 and the sample size, n, is 5. No matter what the dfs are, r = 0

      is between the two critical values so r is not significant.

Assumptions in Testing the Significance of the Correlation
Coefficient

Testing the significance of the correlation coefficient requires that certain
assumptions about the data are satisfied. The premise of this test is that the
data are a sample of observed points taken from a larger population. We
have not examined the entire population because it is not possible or
feasible to do so. We are examining the sample to draw a conclusion about
whether the linear relationship that we see between x and y in the sample
data provides strong enough evidence so that we can conclude that there is a
linear relationship between x and y in the population.

The regression line equation that we calculate from the sample data gives
the best fit line for our particular sample. We want to use this best fit line
for the sample as an estimate of the best fit line for the population.
Examining the scatterplot and testing the significance of the correlation
coefficient helps us determine if it is appropriate to do this.
The assumptions underlying the test of significance are:

      There is a linear relationship in the population that models the average
      value of y for varying values of x. In other words, the expected value
      of y for each particular value lies on a straight line in the population.
      (We do not know the equation for the line for the population. Our
      regression line from the sample is our best estimate of this line in the
      population.)
      The y values for any particular x value are normally distributed about
      the line. This implies that there are more y values scattered closer to
      the line than are scattered farther away. Assumption (1) above implies
      that these normal distributions are centered on the line: the means of
      these normal distributions of y values lie on the line.
      The standard deviations of the population y values about the line are
      equal for each value of x. In other words, each of these normal
      distributions of y values has the same shape and spread about the line.
      The residual errors are mutually independent (no pattern).

    The y values for each x value are normally distributed about the line
   with the same standard deviation. For each x value, the mean of the y
   values lies on the regression line. More y values lie near the line than

                     are scattered further away from the line.

**With contributions from Roberta Bloom
Prediction
Linear Regression and Correlation: Prediction is a part of Collaborative
Statistics collection (col10522) by Barbara Illowsky and Susan Dean with
contributions from Roberta Bloom.

Recall the third exam/final exam example.

We examined the scatterplot and showed that the correlation coefficient is
significant. We found the equation of the best fit line for the final exam
grade as a function of the grade on the third exam. We can now use the least
squares regression line for prediction.

Suppose you want to estimate, or predict, the final exam score of statistics

students who received 73 on the third exam. The exam scores ( -values)

range from 65 to 75. Since 73 is between the -values 65 and 75,

substitute  into the equation. Then:

Equation:

We predict that statistic students who earn a grade of 73 on the third exam
will earn a grade of 179.08 on the final exam, on average.

Example:
Recall the third exam/final exam example.
Exercise:

   Problem:
   What would you predict the final exam score to be for a student who
   scored a 66 on the third exam?

   Solution:
   145.27
Exercise:
   Problem:
   What would you predict the final exam score to be for a student who
   scored a 90 on the third exam?
   Solution:
   The x values in the data are between 65 and 75. 90 is outside of the
   domain of the observed x values in the data (independent variable), so
   you cannot reliably predict the final exam score for this student. (Even
   though it is possible to enter x into the equation and calculate a y
   value, you should not do so!)
   To really understand how unreliable the prediction can be outside of
   the observed x values in the data, make the substitution x = 90 into the
   equation.

   The final exam score is predicted to be 261.19. The largest the final
   exam score can be is 200.

   Note:The process of predicting inside of the observed x values in the
   data is called interpolation. The process of predicting outside of the
   observed x values in the data is called extrapolation.

**With contributions from Roberta Bloom
Outliers
Linear Regression and Correlation: Outliers is a part of Collaborative
Statistics collection (col10522) by Barbara Illowsky and Susan Dean. The
module has been modified to include a graphical method for identifying
outliers contributed by Roberta Bloom.

In some data sets, there are values (observed data points) called outliers.
Outliers are observed data points that are far from the least squares
line. They have large "errors", where the "error" or residual is the vertical
distance from the line to the point.

Outliers need to be examined closely. Sometimes, for some reason or
another, they should not be included in the analysis of the data. It is possible
that an outlier is a result of erroneous data. Other times, an outlier may hold
valuable information about the population under study and should remain
included in the data. The key is to carefully examine what causes a data
point to be an outlier.

Besides outliers, a sample may contain one or a few points that are called
influential points. Influential points are observed data points that are far
from the other observed data points in the horizontal direction. These points
may have a big effect on the slope of the regression line. To begin to
identify an influential point, you can remove it from the data set and see if
the slope of the regression line is changed significantly.

Computers and many calculators can be used to identify outliers from the
data. Computer output for regression analysis will often identify both
outliers and influential points so that you can examine them.

Identifying Outliers
We could guess at outliers by looking at a graph of the scatterplot and best
fit line. However we would like some guideline as to how far away a point
needs to be in order to be considered an outlier. As a rough rule of thumb,
we can flag any point that is located further than two standard
deviations above or below the best fit line as an outlier. The standard
deviation used is the standard deviation of the residuals or errors.
We can do this visually in the scatterplot by drawing an extra pair of lines
that are two standard deviations above and below the best fit line. Any data
points that are outside this extra pair of lines are flagged as potential
outliers. Or we can do this numerically by calculating each residual and
comparing it to twice the standard deviation. On the TI-83, 83+, or 84+, the
graphical approach is easier. The graphical procedure is shown first,
followed by the numerical calculations. You would generally only need to
use one of these methods.

Example:
Exercise:

   Problem:

   In the third exam/final exam example, you can determine if there is an
   outlier or not. If there is an outlier, as an exercise, delete it and fit the
   remaining data to a new line. For this example, the new line ought to
   fit the remaining data better. This means the SSE should be smaller
   and the correlation coefficient ought to be closer to 1 or -1.

   Solution:

   Graphical Identification of Outliers
   With the TI-83,83+,84+ graphing calculators, it is easy to identify the
   outlier graphically and visually. If we were to measure the vertical
   distance from any data point to the corresponding point on the line of
   best fit and that distance was equal to 2s or farther, then we would
   consider the data point to be "too far" from the line of best fit. We
   need to find and graph the lines that are two standard deviations
   below and above the regression line. Any points that are outside these
   two lines are outliers. We will call these lines Y2 and Y3:

   As we did with the equation of the regression line and the correlation
   coefficient, we will use technology to calculate this standard deviation
   for us. Using the LinRegTTest with this data, scroll down through the
   output screens to find s=16.412
Line Y2=-173.5+4.83x-2(16.4) and line Y3=-173.5+4.83x+2(16.4)

where y^=-173.5+4.83x is the line of best fit. Y2 and Y3 have the same
slope as the line of best fit.

Graph the scatterplot with the best fit line in equation Y1, then enter
the two extra lines as Y2 and Y3 in the "Y="equation editor and press
ZOOM 9. You will find that the only data point that is not between
lines Y2 and Y3 is the point x=65, y=175. On the calculator screen it
is just barely outside these lines. The outlier is the student who had a
grade of 65 on the third exam and 175 on the final exam; this point is
further than 2 standard deviations away from the best fit line.

Sometimes a point is so close to the lines used to flag outliers on the
graph that it is difficult to tell if the point is between or outside the
lines. On a computer, enlarging the graph may help; on a small
calculator screen, zooming in may make the graph clearer. Note that
when the graph does not give a clear enough picture, you can use the
numerical comparisons to identify outliers.
[missing_resource: linrgoutlier.gif]

Numerical Identification of Outliers
In the table below, the first two columns are the third exam and final
exam data. The third column shows the predicted y^ values calculated
from the line of best fit: y^=-173.5+4.83x. The residuals, or errors,
have been calculated in the fourth column of the table:
observed y value - predicted y value = y - y^.

s is the standard deviation of all the y - y^ =  values where n = the
total number of data points. If each residual is calculated and squared,
and the results are added, we get the SSE. The standard deviation of
the residuals is calculated from the SSE as:

                          SSE

s=

                          n-2

Rather than calculate the value of s ourselves, we can find s using the
computer or calculator. For this example, the calculator function
LinRegTTest found s = 16.4 as the standard deviation of the residuals
35 -17 16 -6 -19 9 3 -1 -10 -9 -1 .

x   y    y^   y - y^
              175 - 140 = 35
65  175  140  133 - 150 = -17
         150  185 - 169 = 16
67  133  169  163 - 169 = -6
         169  126 - 145 = -19
71  185  145  198 - 189 = 9
         189  153 - 150 = 3
71  163  150  163 - 164 = -1
         164  159 - 169 = -10
66  126  169  151 - 160 = -9
         160  159 - 160 = -1
75  198  160

67  153

70  163

71  159

69  151

69  159

We are looking for all data points for which the residual is greater
than 2s=2(16.4)=32.8 or less than -32.8. Compare these values to the
residuals in column 4 of the table. The only such data point is the
student who had a grade of 65 on the third exam and 175 on the final
exam; the residual for this student is 35.
   How does the outlier affect the best fit line?
   Numerically and graphically, we have identified the point (65,175) as
   an outlier. We should re-examine the data for this point to see if there
   are any problems with the data. If there is an error we should fix the
   error if possible, or delete the data. If the data is correct, we would
   leave it in the data set. For this problem, we will suppose that we
   examined the data and found that this outlier data was an error.
   Therefore we will continue on and delete the outlier, so that we
   can explore how it affects the results, as a learning experience.

   Compute a new best-fit line and correlation coefficient using the
   10 remaining points:
   On the TI-83, TI-83+, TI-84+ calculators, delete the outlier from L1
   and L2. Using the LinRegTTest, the new line of best fit and the
   correlation coefficient are:

   y^ = -355.19 + 7.39x and r = 0.9121

   The new line with r = 0.9121 is a stronger correlation than the
   original (r=0.6631) because r = 0.9121 is closer to 1. This means
   that the new line is a better fit to the 10 remaining data values. The
   line can better predict the final exam score given the third exam score.

Numerical Identification of Outliers: Calculating s and Finding
Outliers Manually

If you do not have the function LinRegTTest, then you can calculate the
outlier in the first example by doing the following.

First, square each y - y^ (See the TABLE above):

The squares are 352 17 16 6 19 9 3 1 10 9 1 2 2 2 2 2 2 2 2 2 2

Then, add (sum) all the y - y^ squared terms using the formula
11                     11

                 2              2                                                             (Recall that yi - y^i = i.)
 ( yi - y^i ) =  i

i=1                    i=1

     2      2       2        2                                                             2  2         2  2        2  2     2
= 35 + 17 + 16 + 6 + 19 + 9 + 3 + 1 + 10 + 9 + 1

= 2440 = SSE. The result, SSE is the Sum of Squared Errors.

Next, calculate s, the standard deviation of all the y - y^ =  values
where n = the total number of data points.

The calculation is s =  SSE
                                                                                      n-2

For  the  third  exam/final  exam                                                          problem,  s  =     2440  = 16.47
                                                                                                              11-2

Next, multiply s by 1.9:

(1.9)  (16.47) = 31.29

31.29 is almost 2 standard deviations away from the mean of the y - y^
values.

If we were to measure the vertical distance from any data point to the
corresponding point on the line of best fit and that distance is at least 1.9s,
then we would consider the data point to be "too far" from the line of best
fit. We call that point a potential outlier.

For the example, if any of the y - y^ values are at least 31.29, the
corresponding (x, y) data point is a potential outlier.

For the third exam/final exam problem, all the y - y^ 's are less than 31.29
except for the first one which is 35.

35 > 31.29          That is, y - y^  (1.9)  (s)

The point which corresponds to y - y^ = 35 is (65, 175). Therefore, the
data point (65, 175) is a potential outlier. For this example, we will delete
it. (Remember, we do not always delete an outlier.)
The next step is to compute a new best-fit line using the 10 remaining
points. The new line of best fit and the correlation coefficient are:

y^ = -355.19 + 7.39x and r = 0.9121

Example:
Exercise:

   Problem:

   Using this new line of best fit (based on the remaining 10 data points),
   what would a student who receives a 73 on the third exam expect to
   receive on the final exam? Is this the same as the prediction made
   using the original line?

   Solution:

   Using the new line of best fit, y^ = -355.19 + 7.39(73) = 184.28. A
   student who scored 73 points on the third exam would expect to earn
   184 points on the final exam.

   The original line predicted y^ = -173.51 + 4.83(73) = 179.08 so
   the prediction using the new line with the outlier eliminated differs
   from the original prediction.

Example:
(From The Consumer Price Indexes Web site) The Consumer Price Index
(CPI) measures the average change over time in the prices paid by urban
consumers for consumer goods and services. The CPI affects nearly all
Americans because of the many ways it is used. One of its biggest uses is
as a measure of inflation. By providing information about price changes in
the Nation's economy to government, business, and labor, the CPI helps
them to make economic decisions. The President, Congress, and the
Federal Reserve Board use the CPI's trends to formulate monetary and
fiscal policies. In the following table, x is the year and y is the CPI.

x     y

1915  10.1
1926  17.7
1935  13.7
1940  14.7
1947  24.1
1952  26.5
1964  31.0
1969  36.7
1975  49.3
1979  72.6
1980  82.4
1986  109.6
1991  130.7
1999  166.6
Data:

Exercise:

   Problem:

         Make a scatterplot of the data.
         Calculate the least squares line. Write the equation in the form
         y^ = a + bx.
         Draw the line on the scatterplot.
         Find the correlation coefficient. Is it significant?
         What is the average CPI for the year 1990?

   Solution:

         Scatter plot and line of best fit.
         y^ = -3204 + 1.662x is the equation of the line of best fit.

                 r = 0.8694

         The number of data points is n = 14. Use the 95% Critical
         Values of the Sample Correlation Coefficient table at the end of
         Chapter 12. n - 2 = 12. The corresponding critical value is
         0.532. Since 0.8694 > 0.532, r is significant.
         y^ = -3204 + 1.662(1990) = 103.4 CPI
         Using the calculator LinRegTTest, we find that s = 25.4 ;
         graphing the lines Y2=-3204+1.662X-2(25.4) and
         Y3=-3204+1.662X+2(25.4) shows that no data values are outside
         those lines, identifying no outliers. (Note that the year 1999 was
         very close to the upper line, but still inside it.)
Note:In the example, notice the pattern of the points compared to the line.
Although the correlation coefficient is significant, the pattern in the
scatterplot indicates that a curve would be a more appropriate model to
use than a line. In this example, a statistician should prefer to use other
methods to fit a curve to this data, rather than model the data with the line
we found. In addition to doing the calculations, it is always important to
look at the scatterplot when deciding whether a linear model is
appropriate.

If you are interested in seeing more years of data, visit the Bureau of Labor
Statistics CPI website ftp://ftp.bls.gov/pub/special.requests/cpi/cpiai.txt ;
our data is taken from the column entitled "Annual Avg." (third column
from the right). For example you could add more current years of data. Try
adding the more recent years 2004 : CPI=188.9, 2008 : CPI=215.3 and
2011: CPI=224.9. See how it affects the model. (Check:
y^ = -4436 + 2.295x. r = 0.9018. Is r significant? Is the fit better with
the addition of the new points?)

**With contributions from Roberta Bloom
Glossary

Outlier
      An observation that does not fit the rest of the data.
95% Critical Values of the Sample Correlation Coefficient Table
This module provides an overview of Linear Regression and Correlation:
95% Critical Values of the Sample Correlation Coefficient Table as a part of
Collaborative Statistics collection (col10522) by Barbara Illowsky and
Susan Dean.

Degrees of Freedom: n  Critical Values: ( and )
1                      0.997
2                      0.950
3                      0.878
4                      0.811
5                      0.754
6                      0.707
7                      0.666
8                      0.632
9                      0.602
10                     0.576
11                     0.555
12                     0.532
Degrees of Freedom: n  Critical Values: ( and )
13                     0.514
14                     0.497
15                     0.482
16                     0.468
17                     0.456
18                     0.444
19                     0.433
20                     0.423
21                     0.413
22                     0.404
23                     0.396
24                     0.388
25                     0.381
26                     0.374
27                     0.367
28                     0.361
29                     0.355
Degrees of Freedom: n  Critical Values: ( and )
30                     0.349
40                     0.304
50                     0.273
60                     0.250
70                     0.232
80                     0.217
90                     0.205
100                    0.195
Linear Regression and Correlation: Summary

Bivariate Data: Each data point has two values. The form is (x, y).

Line of Best Fit or Least Squares Line (LSL): y^ = a + bx

x = independent variable; y = dependent variable

Residual: Actual y value - predicted y value = y - y^
Correlation Coefficient r:

   1. Used to determine whether a line of best fit is good for prediction.
   2. Between -1 and 1 inclusive. The closer r is to 1 or -1, the closer the

      original points are to a straight line.
   3. If r is negative, the slope is negative. If r is positive, the slope is

      positive.
   4. If r = 0, then the line is horizontal.

Sum of Squared Errors (SSE): The smaller the SSE, the better the
original set of points fits the line of best fit.

Outlier: A point that does not seem to fit the rest of the data.
