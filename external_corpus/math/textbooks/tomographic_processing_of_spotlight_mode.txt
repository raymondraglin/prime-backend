1. Introduction
2. Background
3. Projection-Slice Theorem
4. Tomographic Processing
5. Data and Processing
6. Conclusions and Future Work
7. Appendix and References
8. THE TEAM!!
Introduction

Introduction

Our project covers an investigation of Synthetic Aperture Radar (SAR) and
the Matlab processing of SAR data we received from Ohio State University.
The data was generated by a simulation of spotlight-mode SAR, a specific
type of SAR which takes advantage of a moving sensor tracking a single
ground target. To process this data, we utilize digital signal processing
techniques such as interpolation and windowing along with a knowledge of
how SAR works.
Background

Synthetic Aperture Radar: Background

What is Synthetic Aperture Radar?

Synthetic Aperture Radar (SAR) is a microwave imaging system that is
used to obtain high resolution pictures of large areas of terrain. The radar
can be either airborne or spaceborne. As the platform moves, closely spaced
pulses are transmitted and the reflected signals are received and processed
using Fourier methods. The processed data resembles data taken with a
system that has a very large antenna, thus allowing extremely high
resolution.

Synthetic Aperture Radar was first developed in the early 1950's. The
earliest type of SAR is called strip-mapping mode SAR. It is primarily used
for imaging large areas of terrain, such as the surface of a nearby planet.
This mode emits the radar pulses at a constant "look" angle to the surface
while traveling along a flight path or orbit. This process creates a strip of
mapped ground, and can be repeated along a polar orbit to map the entire
surface of a planet.

Spotlight mode SAR is a newer form of SAR and was developed in the
early 1980's. It is more widely used today than strip-mapping mode and it is
what our project deals with. In spotlight mode, the radar is steered
continually as the carrier of the radar flies over a patch of ground. In
another word, the "look" angle is constantly adjusted so that a single patch
of ground is always illuminated. This method allows for higher resolution
in the azimuth "travel" direction of the platform but is not able to image as
large of an area as strip-mapping mode.

How Does Imaging Radar Work?

As mentioned earlier, we use the Synthetic Aperture Radar processing
technique because of its advantages when it comes to imaging large areas at
high resolutions. However, why do we even use radar to image things in the
first place?

Radar is used in imaging because of the minimal constraints that is has on
time-of-day and atmospheric conditions. The area of imaging does not have
to be illuminated by sunlight in order to obtain a picture. This allows for
continuous mapping regardless of the position of the sun, which saves time
and therefore, money.

Radar also has the ability to penetrate cloud cover because one can choose a
wavelength that is not absorbed by water. This fact is what allowed
scientists at NASA to provide stunning images of the surface of Venus,
which is completely shrouded in cloud-cover.

Imaging radar works by emitting a signal and then recording the strength of
the reflected signal (scattering coefficient) for that area. The pulses are
emitted at an angle to the surface such that if they strike a smooth, flat
surface, very little of the signal will be reflected back towards the antenna
which corresponds to a darker spot on our scattering coefficient image.

When the radar pulse strikes uneven surfaces such as urban areas or
vegetated areas, the signal gets reflected numerous times and there is an
increased likelihood that the radar antenna will eventually receive a large
portion of the signal back, corresponding to a whiter spot on your image.
Scientists use this fact to determine the extent of flooding in urban areas or
to discern how much an oil spill in the ocean has grown.

Synthetic Aperture Radar and Microwave Imaging System

The resolution of an image taken from an imaging system is usually
determined by the size of the Aperture (lens for optical systems and antenna
for radar). Conventional radar systems use passive methods deployed with
optical or short-wave infrared sector that rely on sunlight reflection. On the
other hand, synthetic Aperture Radar uses a microwave imaging system.
Two important advantages resulting from using microwave pulses are that
cloud cover can be penetrated and the imaging process can be performed at
night.

However, antenna size limits one from applying microwave imaging
systems. A very large size of antenna is required to obtain satisfactory
resolution. Therefore, the size of the antenna makes it impractical for the
radar carrier.

Synthetic Aperture Radar solves the problem by "simulating" a large
Aperture. The radar sends and receives signals from a relatively small
antenna while the platform traveling along a flight path. One can then use
the digital signal processing techniques to combine the data into a coherent
image. The result is the same as if one has used a very large antenna.
Projection-Slice Theorem

Brief Review of Computer-Aided Tomography

Computer-Aided Tomography, or CAT (as in CAT scan) is a technique for
remote 2-D and 3-D imaging. By moving a sensor around a target, one can
collect sufficient 1-dimensional data to reconstruct the original
multidimensional image. This process utilizes an amazing relationship
called the Projection-Slice Theorem, which states that each piece of
projection data at some angle is the same as the Fourier transform of the
multidimensional object at that angle. Using a range of data from a range of
angles, one can, given sufficient computation resources, reconstruct the
actual image by taking the inverse transform. The Projection-Slice Theorem
has found a range of applications in remote sensing, the most famous of
which is the 3-D imaging of humans, popularly known as the CAT scan.
The focus of this project, Spotlight-Mode Synthetic Aperture Radar, uses
the Projection Slice Theorem in a way quite similar to CAT scan
technology, except the way radar projections are generated by the image is
slightly different from the way CAT scans use X-rays.

Projection-Slice Theorem

Let g(x,y) represent the radar reflection of our image. The two-dimensional
Fourier transform of g is defined as

And
We can model the reflection behavior of the incident radar by considering
the following overhead diagram

The smooth line outlines our image g(x,y), and the horizontal and vertical
axes x,y are overlaid. The radar is incident upon the target along the axis of
the path u at an angle theta. For a target which is far away, the radar wave
front is approximately flat, and so this means that a reflected beam which
has traveled a certain unique distance to and from the sensor comes from a
straight path across the image, perpendicular to u. This path is in the
direction of v and can be represented by a line integral in the direction of v
at position u0. The formula for this is given by

The 1-D Fourier transform of p(u) is given by
And then, through applying the equation for p(u) and simplifying, we are
left with

This is the Projection Slice Theorem! What this states is that the Fourier
transform of a projection taken at an angle theta is equal to the 2-D Fourier
transform of the image at that same angle theta. To reconstruct the original
image, one must merely take the inverse Fourier transform in two
dimensions of a set of data P(U). This is not as easy as it sounds for reasons
discussed later. Notice how the Fourier transform of the image G does not
have the usual form, G(X,Y). It is instead expressed in polar form, and the
variable theta lets us know that we have only a slice of the transform for
each P(U).
Tomographic Processing

Data Processing

In the words of the highly esteemed Rich Baraniuk, the signals received by
the radar sensor must be "munjed" upon in order that the user can learn
anything useful at all. We flesh-out the basic spotlight-mode SAR
derivation from start to finish, noting the places in which we make
approximations, all the while aiming at interpreting our bit stream into the
meaningful pieces of the Projection-Slice Theorem. Something to note is
that this theoretical approach does not include any Doppler shift analysis.
Other approaches to synthetic aperture radar heavily rely on phase data
collected during a physical flyby of the target, where instrument velocity
plays an important role. The mathematics in this section follows as in David
Munson's 1983 paper on "A Tomographic Formulation of Spotlight-Mode
Synthetic Aperture Radar."

The Setup

The way spotlight-mode SAR collects data samples is by gathering image
projections from a range of angles. In our case, this range is broken down
into a set of equally spaced angles so that essentially we have snapshots at
various views around a target. A depiction of what it would look like is
given below.
This drawing shows how the altitude of the sensor platform might play a
role in the angular view of the target. For our derivation, we will ignore this
parameter and assume that the radar is somehow incident at ground level,
that as the sensor moves closer to the target distances remain undistorted by
this variation in 3-dimensions. This ground plane geometry is as shown
below.
Note that the angle theta is the same as that in the description of the
Projection-Slice Theorem. The distance from the center of the target image
is given by the variable R, and the radius of a circular target is given by L.
The radar signal travels along and parallel to path u.

Generating the Reflection Signal

At this point we are ready to start generating our signals! Our radar device
works in a microwave frequency range designed to penetrate clouds and
other obstructions with ease. It emits a linear FM chirp pulse waveform
Re{s(t)} where
In this signal, w0 is the RF carrier frequency and 2a is the FM rate. The
frequency rises linearly with time so that the minimum frequency is w0-aT
and the maximum is w0+aT. The point reflection off of a reflection
coefficient at (x0,y0) given by g(x0,y0) can be written

Where R0 is the distance of g(x0,y0) from the radar, A accounts for
propagation attenuation, c is the speed of light, and 2R0/c accounts for the
two-way travel time from radar to target.

Interpreting the Reflection Signal
Points on the target ground patch equidistant from the radar lie on an arc,
but typically R>>L, so this arc is nearly, and may be approximated as, a
straight line. Combining this approximation with the polar formulation of a
differential line of scatterers (radar reflectors), we can write down a new
relation involving a polar representation of the reflection.

If R>>L, we may take A as a constant over u, and this enables us to write
the reflection from the whole ground patch as the integral of r1 over u.

This integral has the form of a convolution! This provides us a good hint
that Fourier methods might be the right way to analyze this signal. The
signal stated here is really the raw data that we receive from the radar. The
return chirp is the projection slice convolved with the initial pulse.
Mixing the Reflection Signal
It turns out that the correct way to process this raw data is to mix it with the
starting signal, s(t). Written out, r(t) has the form

Mixing this signal with the real and imaginary parts of the signal s(t), low-
pass filtering the two, and then adding them together gives us a complex
signal.

The quadratic term in the exponential can be approximated as 0, and as that
term disappears, we get a very profound result

Which is the Fourier transform of p(t).
Interpreting Our Result
From our formulation of r(t) above, we know the restriction on t. If we
consider the argument of P( ) to be X, the radial spatial frequency, we know
P(X) is only determined for X between X1 and X2 where

The term 4aL/c will be negligible for typical SAR, so we can see that X1
and X2 are proportional to the lowest and highest frequencies in the
transmitted chirp pulse. X1 and X2 correspond to the inner and outer radii
for which P(X) is defined.

C(t) is the final form of the processed data! What this tells us is that after
mixing the reflection with the real and imaginary parts of the original
chirped pulse, low-pass filtering, and linearly combining the two, we are
left with the Fourier transform of the projection p(t). From here we need to
take the inverse transform to finally reconstruct g(x,y). Unfortunately, we
have the polar form of a Fourier transform, whose known values would be
located somewhere on this Locus
There exists a 2-D polar inverse Fourier transform, and this is the preferred
method of transform for the optimal quality reconstruction. This method,
called Convolution Back-Projection, requires an enormous number of
computations to execute, however, and so in practice one has to either have
a quite powerful system or be ready to wait for results. The practical
method attempts to remedy this issue by utilizing the Fast Fourier
Transform, or FFT. Although there is no known 2-dimensional FFT or
inverse FFT for polar coordinates, one may interpolate the polar data to
rectify the coordinate system and then apply the 2-D inverse FFT in the
regular fashion. The rectification process requires windowing the data, and
interpolation is by its nature inexact, so this method ends up trading a great
deal of resolution for extra speed.
Data and Processing

Introduction and Preparation of SAR Data

In order to simulate the processing of SAR data, we received SAR data
from the ECE department at Ohio State University. The data they gave us
was acquired through a computer simulated fly-by past a CAD model of a
backhoe.

The data we received from OSU was in digital format, meaning the analog
mixing and low pass filtering was already completed and we received
digitized versions of C(t). This function was shown to be equivalent to
P(U), the Fourier transform of our projection slices p(u). The matlab file
that contained this information was a 512x1541 matrix iq_lin, a vector of
various P signals for different values of , the viewing angle. There were
1541 different viewing angles, listed in az_lin, that stepped by 1/14° for
each element and varied from -10° to 100°, a median viewing angle of 45°.
We also received a vector of length 512 called f that contained the
microwave frequencies (7-13 GHz) that were transmitted and received. By
using the wideband approximation, we made the transformation from time
frequency to spatial frequency via

  
where R is the radial spatial frequency and f is the microwave frequency
content. By the projection slice theorem, we have that the various P are
arranged radially in a polar grid along the various angles . We then get that
our data lies on a domain

  

Processing of SAR Data

Knowing that our data is the Fourier transform of our image, after the
proper preparation we want to take the inverse Fourier transform. To do this
simply and efficiently (we don't want Matlab running for hours!) we
linearly interpolate the data to a Cartesian grid. This is done in our Matlab
function sar_lin (code found in appendix). The idea is to find an inscribed
rectangular grid inside our polar data. We chose to use the square centered
at 45° inscribed in our ribbon. To interpolate we made a Cartesian grid at
this location and computed the polar representation of each point in order to
find its 4 nearest polar neighbors. Once those neighbors were found, the
Cartesian point's value was determined by linearly interpolating in the R-
direction for the two  values and then linearly interpolating in the -
direction. The end result of our program's running of this is shown below.

After linearly interpolating each point in the Cartesian grid we have formed,
we now have our data in a form that allows us to take the 2-d inverse DFT
by the fast Fourier transform method. This is what saved us computation
time (program ran in about 15 seconds) and is the reason we interpolated to
Cartesian coordinates to begin with. Below is the image after taking the
inverse Fourier transform.
Conclusions and Future Work

Conclusions

Our project shows that an image can be extracted from scattering
coefficients obtained from SAR techniques. One need only apply some
digital signal processing techniques, such as the polar to Cartesian
interpolation of our data. SAR has many benefits and real world
applications. For example, the microwave radiation used in SAR penetrates
cloud cover. This fact has been used to image Venus' surface, providing
stunning visuals otherwise unavailable. Another benefit is that SAR does
not require the construction of a large antenna as the motion of the detector
creates an artificial aperture.

Future Work

One negative aspect of our data is that the range of frequencies represented
is very narrow. That is, the interpolated grid we chose focuses on a small
range of frequencies relative to the amount of data that we received to work
with. One potential fix for this is to do multiple interpolations of multiple
Cartesian grids, ensuring no overlap, and superimpose the images that
result. As long as the relative location of the grids is taken into account,
then by linearity, we should be able to acquire a more detailed image by
superimposing the images. One might imagine, for example, that we could
superimpose the grids shown below.
Another possibility is to forego the interpolation, which restricts the amount
of data that we can use, and instead we can work in polar coordinates. This
would allow us to use all of our data, cutting out nothing. The downside to
this is that there is no fast Fourier transform method for polar coordinates,
so the computational complexity increases the run time to be on the order of
hours.
Appendix and References

Appendix

MATLAB Function for Processing SAR Data
function img = sar_lin(f,az_lin,iq_lin)
% INITIALIZATION
R=4*pi*f/3e8;% Transformation of Time Freqeuncy to
Spatial Frequency
A=pi/180*az_lin;% Transformation of Angle in
degree to radians
for j=1:147
A(j)=A(j)-2*pi;% Adjustment so that all angular
values are between 0 and pi
end
% Initialization of Cartesian Grid
X=zeros(1,175);
Y=zeros(175,1);
for j=1:175
X(j)=208+(j-1);
Y(j)=208+(j-1);
end
val=zeros(175);% Initialize the matrix of values
in the cartesian grid.
% INTERPOLATOR
for j=1:175
j % Update on how far we are.
for k=1:175
r=sqrt(X(j)^2+Y(k)^2);
a=atan(Y(k)/X(k));
if (r>R(1) & r<R(512))
% Data index of cartesian point
J=ceil((r-R(1))*511/(R(512)-R(1)));
K=ceil((a-A(1))*1540/(A(1541)-A(1)));
% Linearly interpolate the cartesian point with
its 4 nearest neighbor polar data points.
% Interpolate in R
v0 = 1/(R(J+1)-R(J)) * ( iq_lin(J,K)*(R(J+1)-r) +
iq_lin(J+1,K)*(r-R(J)) );
v1 = 1/(R(J+1)-R(J)) * ( iq_lin(J,K+1)*(R(J+1)-r)
+ iq_lin(J+1,K+1)*(r-R(J)) );
% Interpolate in THETA
val(j,k) = 1/(A(K+1)-A(K)) * ( v0*(A(K+1)-a) + v1*
(a-A(K)) );
end

end

end

% Plot the interpolated values

figure(1)

imagesc(abs(val));

% Take the 2d inverse DFT to get the image

img = ifft2(val);

% Plot the image

figure(2)

imagesc(abs(img));

References

D. C. Munson Jr., J. D. O'Brien, W. K. Jenkins, "A Tomographic
Formulation of Spotlight-Mode Synthetic Aperture Radar," Proc. IEEE, vol.
71, pp 917-925, August 1983.

D. C. Munson Jr., R. L. Visentin, "A Signal Processing View of Strip-
Mapping Synthetic Aperture Radar," IEEE Transactions on Acoustics,
Speech, and Signal Processing, vol. 37, no. 12, pp 2131-2147, December
1989.

G. D. Martin, A. W. Doerry, "SAR Polar Format Implementation with
MATLAB," Sandia National Laboratories, SAND2005-7413, November
2005.
P. Buxa, L. Gorham, Lt. M. Lukacs, "Mapping of a 2D SAR Backprojection
Algorithm to an SRC Reconfigurable Computing MAP Processor," Air
Force Research Laboratory, Sensors Directorate.
THE TEAM!!
Our Elec 301 group project team: THE LATE NIGHT ELECS
Aaron Hallquist: ahallquist@rice.edu
Tianlai Lu: tian@rice.edu
Max Magee: max.r.magee@rice.edu
Jason Ryan: jdr@rice.edu
Our pictures can be found on the right!
