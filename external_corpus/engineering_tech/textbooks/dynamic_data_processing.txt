Dynamic data processing: Recursive least-squares

Peter J.G. Teunissen
Dynamic data processing

     recursive least-squares
    Dynamic data processing

          recursive least-squares

                   P.J.G. Teunissen

                Delft University of Technology
Department of Mathematical Geodesy and Positioning
Series on Mathematical Geodesy and Positioning
© VSSD, first edition 2001, reprinted 2007
© TU Delft OPEN Publishing, second edition 2024
ISBN: 978-94-6366-917-7 (Ebook)
ISBN: 978-94-6366-916-0 (Paperback/softback)
DOI: https://10.59490/tb.98

This work is licensed under a Creative Commons Attribution 4.0 International
license

Keywords: Recursive Least-squares, State-space modelling, Kalman filtering,
Prediction and Smoothing
Preface 2nd Edition

To promote open access, this new edition of Dynamic Data Processing, is
published by TU Delft Open Publishing instead of Delft Academic Press. The
book develops least-squares estimation theory for the case of time-varying
parameters with an emphasis on their recursive determination. As such the book is
a natural follow-on of Adjustment Theory, An Introduction, TU Delft Open
Publishing, second edition 2024

August, 2024

Peter J.G. Teunissen
Foreword

This book is based on the lecture notes of the course Dynamic data processing as it has been
given by the Department of Mathematical Geodesy and Positioning (MGP) of the Delft
University of Technology since 1990. The prerequisites are a solid knowledge of adjustment
theory and geodetic positioning, together with linear algebra, statistics and calculus. The theory
and application of least-squares adjustment are treated in Adjustment theory (Delft University
Press, 2000). The material of the present course extends the theory to the recursive estimation
of time-varying or dynamic parameters. The time-varying parameters could for instance be
geometric parameters such as position, attitude and shape, physical parameters such as
temperature and humidity, or instrumental parameters such as clock drifts and biases. The
time-varying parameters are said to be determined recursively when the method of determination
enables sequential, rather than batch processing of the measurement data. The main goal is
therefore to convey the knowledge necessary to be able to process sequentially collected
measurement data in an optimal and efficient manner for the purpose of estimating time-varying
parameters.

Following the Introduction, the basic theory of least-squares estimation is reviewed in Chapter
1. This is done for the model of observation equations and for the model of condition equations.
In Chapter 2 the principle of recursive least-squares estimation is introduced. The recursive
principle allows one to update the least-squares solution for new observations without the need
to store all past observations. Two different forms of the measurement-update equations are
given. The results of Chapter 2, which hold true for time-invariant parameters, are generalized
in Chapter 3 to the case of time-varying parameters. The time-varying nature of the parameters
is assumed captured by means of polynomial equations of motion. The recursive solution now
consists of two types of update equations, the measurement-update equations and the time-update
equations. Since there still exist many dynamic systems for which the rather simple polynomial
model of Chapter 3 does not apply, a larger class of dynamic models is introduced in Chapter
4. These models are formulated using the state-space description of dynamic systems. In order
to include randomness in the state-space description of dynamic systems, some of the elementary
concepts of the theory of random functions are discussed in Chapter 5. This chapter also includes
a description of the propagation laws for linear, time-varying systems. The results of Chapter 5
are used in Chapter 6 to model possible uncertainties associated with the dynamic model. As a
result the update equations are obtained for the recursive least-squares filtering and prediction
of time-varying parameters.

Many colleagues of the Department of Mathematical Geodesy and Positioning whose assistance
made the completion of this book possible are gratefully acknowledged. The typing of the book
was done by Mrs. M.P.M. Scholtes, while C.D. de Jong took care of the editing. Various
lecturers have taught the book's material over the past years. In particular the feedback and
valuable recommendations of the lecturers H.M. de Heus, C.D. de Jong and C.C.J.M. Tiberius
are acknowledged.

P.J.G. Teunissen
July, 2001
Contents

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1

1 Least-squares: a review . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5

   1.1  The linear A-model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5

        1.1.1 Consistency and inconsistency . . . . . . . . . . . . . . . . . . . . . . . . . . . 5

        1.1.2 Least-squares estimates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

        1.1.3 A stochastic model for the observations . . . . . . . . . . . . . . . . . . . 18

        1.1.4 Least-squares estimators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

        1.1.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23

   1.2  The nonlinear A-model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24

        1.2.1 Nonlinear observation equations . . . . . . . . . . . . . . . . . . . . . . . . . 24

        1.2.2 The linearized A-model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27

        1.2.3 Least-squares iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33

   1.3  The B-model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35

        1.3.1 The linear B-model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35

        1.3.2 The nonlinear B-model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38

2  Recursive least-squares: the static case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43

   2.1  Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43

   2.2  Recursive least-squares: the A-form . . . . . . . . . . . . . . . . . . . . . . . . . . 46

   2.3  Recursive least-squares: the B-form . . . . . . . . . . . . . . . . . . . . . . . . . . 54

   2.4  Linearization, iteration and recursion . . . . . . . . . . . . . . . . . . . . . . . . . 63

3  Recursive least-squares: the time-varying case . . . . . . . . . . . . . . . . . . . . . . . . . . 73

   3.1  Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73

   3.2  Equations of motion: a polynomial model . . . . . . . . . . . . . . . . . . . . . . 74

   3.3  Prediction, filtering and smoothing . . . . . . . . . . . . . . . . . . . . . . . . . . . 80

   3.4  Recursive prediction and filtering: the A-form . . . . . . . . . . . . . . . . . . . 87

   3.5  Recursive prediction and filtering: the B-form . . . . . . . . . . . . . . . . . . . 90

4  State-space models for dynamic systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103

   4.1  Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103

   4.2  Equations of motion: kinematics . . . . . . . . . . . . . . . . . . . . . . . . . . . 103

   4.3  Equations of motion: dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111

   4.4  State vector description of dynamic systems . . . . . . . . . . . . . . . . . . . 118

   4.5  Linearization of a nonlinear state equation . . . . . . . . . . . . . . . . . . . . . 126

   4.6  Linear time-varying state equations . . . . . . . . . . . . . . . . . . . . . . . . . 132

   4.7  Linear time-invariant state equations . . . . . . . . . . . . . . . . . . . . . . . . . 136

   4.8  Evaluation of the matrix exponential . . . . . . . . . . . . . . . . . . . . . . . . . 138

        4.8.1 The Taylor-series method . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138

        4.8.2 The Jordan canonical form method . . . . . . . . . . . . . . . . . . . . . . 142
   4.9  Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150

5 Random functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153

   5.1  Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153

   5.2  The mean and covariance of random functions . . . . . . . . . . . . . . . . . 153

   5.3  Propagation laws for linear systems: the general case . . . . . . . . . . . . . 162

        5.3.1 The mean of the output x(t) . . . . . . . . . . . . . . . . . . . . . . . . . . 163

        5.3.2 The cross-covariance between the output x(t) and input

        z(t) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164

        5.3.3 The auto-covariance of the output x(t) . . . . . . . . . . . . . . . . . . . 170

   5.4  White noise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183

   5.5  The auto-covariance of the output of a linear system:

        the white noise case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190

   5.6  Random polynomial equations of motion . . . . . . . . . . . . . . . . . . . . . 201

        5.6.1 Random constants as input . . . . . . . . . . . . . . . . . . . . . . . . . . . 201

        5.6.2 White noise as input . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203

        5.6.3 Exponentially correlated noise as input . . . . . . . . . . . . . . . . . . . 204

   5.7. Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208

6  Recursive least-squares: the dynamic case . . . . . . . . . . . . . . . . . . . . . . . . . . . 209

   6.1  Introduction: filter divergence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209

   6.2  The dynamic model of observation equations . . . . . . . . . . . . . . . . . . . 213

   6.3  Recursive prediction and filtering . . . . . . . . . . . . . . . . . . . . . . . . . . . 214

   6.4  State vector augmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232

        6.4.1 Exponentially correlated zero-mean velocity . . . . . . . . . . . . . . . 233

        6.4.2 Exponentially correlated zero-mean acceleration . . . . . . . . . . . . . 235

   6.5  Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239

Literature . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241
Introduction

As in other physical sciences, empirical data are used in geodesy to make inferences so as to
describe physical reality. Many such problems involve the determination of unknown parameters
from a set of redundant measurements. Measurements are said to be redundant when they exceed
the minimum necessary for a unique determination of the parameters. There are two main reasons
for collecting redundant measurements. First the requirement to be able to check for mistakes
or errors. Second the wish to increase the accuracy of the results computed. As a consequence
of measurement uncertainty (exact measurements do not exist), the redundant data are usually
inconsistent in the sense that each sufficient subset yields results which will differ from the
results obtained from another subset. To obtain a unique solution, consistency needs to be
restored by applying corrections to the data. This computational process of making the
measurement data consistent with the model such that the unknown parameters can be
determined uniquely, is referred to as adjustment. Adjustment theory therefore deals with the
optimal combination of redundant measurements together with the estimation of unknown
parameters. An introductory course on adjustment was presented in Adjustment theory (Delft
University Press, 2000). This theory is extended in this book to the case of time-varying or
dynamic parameters with an emphasis on their recursive estimation.

Time-varying parameters occur in many geodetic models. They could be geometric parameters
such as position, attitude and shape, physical parameters such as temperature and humidity, or
instrumental parameters such as clock drifts and biases. When a body (e.g. satellite, aircraft, car,
or ship) is in motion, its position changes as function of time. Being able to track the position
of such a moving object is of importance, for instance for navigation and guidance. A moving
body may also change its attitude as function of time. Attitude determination is sometimes
needed as an aid to navigation and guidance, but it also applies, in case of earth rotation, to the
Earth as a whole. Objects that are subject to deformation change their shape as a function of
time. On a global scale, for instance, the earth deforms due to various geophysical processes. But
the earth's surface may also change its shape on more local or regional scales. Subsidence due
to gas extraction is one such example. Apart from time-varying geometric parameters, also
physical and instrumental parameters may change as function of time. Atmospheric parameters
such as those of the ionosphere and troposphere, change on an hourly, daily and even seasonal
basis. Also the performance of instruments often displays a dependence on time. This is the
reason why calibrations are carried out, so as to keep the time-varying instrumental parameters
in control.

A parameter solution is said to be recursive when the method of determination enables
sequential, rather than batch processing of the measurement data. The need for a recursive
solution is usually driven by the efficiency with which such solutions can be computed. This
holds true in particular for applications in which the time-varying parameters need to be
determined instantly or in real-time. We speak of a (near) real-time determination when the time
of determination (almost) coincides with the time the parameter takes on the value to be
determined. Such applications can typically be found in the area of navigation and guidance. In
the case of navigation, for instance, it does not make sense to determine one's position with a
too long time delay. In these applications there is therefore a real need to have a computational
cycle time of the position determination that is as short as possible. This is feasible when
2 Dynamic data processing

recursive methods are used. But even in case real-time solutions are not an important issue, the
use of recursive methods can still be attractive due to their computational efficiency.

When determining time-varying parameters from sequentially collected measurement data, one
can discriminate between three types of estimation problems (see Figure 0.1). When the time at
which a parameter estimate is required coincides with the time the last measurements are
collected, the problem is referred to as filtering. When the time of interest falls within the time
span of available measurement data, the problem is referred to as smoothing, and when the time
of interest occurs after the time the last measurements are collected, the problem is called
prediction. Thus filtering aims at the determination of current parameter values, while smoothing
and prediction aim respectively at the determination of past and future parameter values. The
emphasis in this book will be on recursive filtering.

                             Figure 0.1: Prediction, filtering and smoothing.

The essence of a recursive method is that it enables one to update the parameter estimates for
new measurements without the need to store all past measurements. Assume, for example, that
one has collected at epoch t-1 a redundant set of measurements yt-1 which bears a linear
relationship with an unknown parameter vector x. The measurements yt-1 can then be used to
obtain a linear least-squares estimate x^t 1 of the unknown parameter vector x. Now assume that
at the next epoch t a new set of measurements yt becomes available which also bears a linear
relationship to the same unknown parameter vector x. Since these additional measurements also
contain information about the unknown parameter vector x, they can be used to improve the
estimate x^t 1 of x. One approach would be to use both yt 1 and yt and to repeat the least-squares
adjustment. As a result one obtains the improved least-squares estimate x^t of x. Although this
approach is valid, it requires that one saves the past measurements yt-1. In some cases this may
be a too heavy computational burden, in particular if there are many past measurements or many
epochs that precede the current epoch. Fortunately there is an alternative approach available, the
recursive solution. It can be shown (under some mild restrictions) that the same improved
least-squares estimate x^t of x, can also be computed from x^t 1 and yt instead of from yt 1 and yt.
The solution will then have the recursive structure:
                                                                                                                       Introduction 3

in which Kt and At are matrices. This recursive equation, which holds true for any epoch t, is
referred to as the measurement-update equation: the new measurements yt are used to update the
previous parameter estimate x^t 1 so as to obtain the current parameter estimate x^t .

Some elements of recursive estimation were already briefly introduced in Adjustment theory
(Chapter 6, Section 3). However, just as in the above example, this brief introduction only dealt
with models in which the parameter vector remained constant in time. In this book we will
extend the theory to the case of time-varying parameters. This implies that some additional
modeling needs to be done, namely one that describes the time-dependence of the parameter
vector. Depending on the application at hand, these equations of motion can be of a kinematic
or of a dynamic nature. Kinematics is used to relate position, velocity, acceleration and time
without reference to the cause of motion, whereas dynamics also includes an explicit description
of the forces responsible for the motion. As a consequence of having incorporated the
time-varying nature of the parameter vector into the model, the recursion will now consist of two
different update equations, the time-update (TU) and the measurement update (MU):

with t,t 1 the transition matrix. The time-update uses the filtered estimate x^t 1 t 1 of epoch t-1
to predict the parameter vector of the next epoch, xt, as x^t t 1 . This predicted estimate together
with the new measurements yt are then combined in the measurement update to obtain the filtered
estimate of xt as x^t t .
1 Least-squares: a review

1.1 The linear A-model

1.1.1 Consistency and inconsistency

Assume that we want to determine n parameters x ,  1,...,n . An m-number of
measurements yi , i 1,...,m , are carried out to determine these parameters. If the
measurements bear a known linear relationship with the unknown parameters, we may write the
model of observation equations as:
(1)

In this equation the known scalars ai model the assumed linear relationships between the
measurements yi and the parameters x . By introducing the matrix and vectors:

equation (1) can be written in matrix-vector form as:
(2)

This is a system of an m-number of linear equations in an n-number of unknown parameters. It
is now of interest to know under what conditions a solution to the linear system (2) exists and
if a solution exists, whether it is unique or not. It will be clear that a solution to (2) exists if and
only if the vector y can be written as a linear combination of the column vectors of matrix A.
If this is the case the vector y is an element of the column space or range space of matrix A.
This space is denoted as R(A) . Thus a solution to (2) exists if and only if:
(3)
Systems for which this holds are called consistent systems. A system is said to be inconsistent
if and only if:
(4)
In this case the vector y cannot be written as a linear combination of the column vectors of
matrix A and hence no vector x exists such that (2) holds. The difference between consistency
and inconsistency is depicted geometrically in Figure 1.1.
6 Dynamic data processing

                           (a) consistency : yR(A) m
     Figure 1.1:                                      m.
                           (b) inconsistency : yR(A)

Since y m , it follows from (3) that consistency is guaranteed if R(A) m . But R(A) m only
holds if the dimension of R(A) equals the dimension of m . Hence, if dim R(A) m . It follows
therefore, since dim R(A) equals the rank of matrix A (= number of linear independent columns
or rows of A), that consistency is guaranteed if and only if:
(5)

In all other cases, rank A < m, the linear system may or may not be consistent. Assuming
consistency, the next question one can ask is whether the solution to (2) is unique or not. That
is, whether the information content of the measurements collected in the vector y is sufficient
for determining the parameter vector x uniquely. The solution is unique only if all the columns
of matrix A are linearly independent. Hence, the solution is unique if the rank of matrix A equals
the number of unknown parameters:
(6)

To clarify this, assume x and x  x to be two different solutions of (2). Then
Ax Ax or A (x x ) 0 must hold. But this can only be the case if some of the columns of
matrix A are linearly dependent, which contradicts the assumption of full column rank (6). In all
other cases, rank A < n, there will be more than one solution to a consistent system. In this book
we will always assume that (6) holds. The case that rank A < n is treated elsewhere [Teunissen,
1985a]. With rank A = n and the fact that the rank of matrix A is always equal to or less than
the number of rows or columns of A, it follows that two cases can be distinguished:
(7)

In the first case, both (5) and (6) are satisfied, implying that the linear system (2) is consistent
and that a unique solution exists. The unique solution, denoted by x^ , is found through an
inversion of the matrix A:

(8)

In the second case, only (6) is satisfied, implying that a unique solution to (2) exists provided
that the system is consistent. Consistency in this case is however not guaranteed. But if we
assume the system to be consistent, that is yR(A) , one way to obtain the unique solution is to
invert n out of the m > n linear equations:
                                                                                                       Least-squares: a review 7

(9)

Since the columns of matrix A are linearly independent, it is possible to find a matrix A1 for
which the columns are linearly independent as well, implying that the inverse of the square
matrix A1 exists. Note that y2 is not used in computing x^ . This is allowed in the present
situation since y2 is consistent with y1 and hence does not contain any additional information.

Example 1
Consider the linear system:

(10)

In this case we have: m = 2, n = 2 and rank A = 2. Thus, the system is consistent since rank A
= m = 2, and the system has a unique solution since rank A = n = 2. The unique solution of (10)
reads: x^ (5/7 , 3/7) .
Example 2
A particle is moving with constant velocity along a straight line. If we denote the position of the
particle as function of time as u(t) , we have:

with u(t0) and u(t0) being the initial position and initial velocity respectively of the particle at
time t0 . It is assumed that the initial position and initial velocity of the particle are unknown.
The unknown parameters u(t0) and u(t0) can then be determined from two measurements of
position at times t1 and t2t1 . This results in the following linear system (see Figure 1.2):

(11)
8 Dynamic data processing

                                 Figure 1.2: Position as function of time.
In this case we have: m = 2, n = 2 and rank A = 2. Thus, the system is consistent since rank A
= m = 2, and the system has a unique solution since rank A = n = 2. With

the unique solution follows as:

or as:
(12)

Note that rank A = 1 if t2 t1 . In this case no unique solution exists.
Example 3
Consider the linear system:
(13)
In this case we have: m = 3, n = 2 and rank A = 2. Since m = 3 > rank A = 2, consistency of
the system is not automatically guaranteed. A closer look at the measurement vector y of (13)
shows however that:
                                                                                                       Least-squares: a review 9

This shows that y can be written as a linear combination of the column vectors of A. Therefore
yR(A) , showing that the system is consistent. And since n = rank A = 2, its solution is also
unique. If we partition (13) as:

the unique solution follows as:
(14)
The system (13) may of course also be partitioned as:

The unique solution follows then as:
(15)

Example 4
Consider again the situation of a particle moving along a straight line with constant velocity. But
now assume that three measurements of position are carried out at the three different times
t1 , t2 and t3 . The linear system reads then:
(16)

With the times t0 0 , t1 1 , t2 2 and t3 3 , and the position measurements u(t1 1) 3,
u(t2 2) 4, u(t3 3) 5 system (16) becomes:
10 Dynamic data processing

(17)

In this case we have: m = 3, n = 2 and rank A = 2. Since m = 3 > rank A = 2, consistency of
the system is not automatically guaranteed. But a closer look at the measurement vector of (17)
shows that:

Thus the measurement vector y can be written as a linear combination of the column vectors of
matrix A. Therefore yR(A) , showing that (17) is consistent. And since n = rank A = 2 its
solution is also unique. If we partition (17) as:

the unique solution follows as:
(18)

In this case the solution for u(t0) , u(t0) is found from fitting the line u(t) u(t0) u(t0)(t t0)
through the two points (t1 1 , u(t1) 3) and ( t2 2, u(t2) 4 ). See Figure 1.3a. We may of
course partition (17) also as:

the unique solution follows then as:
(19)

In this case the solution for u(t0) , u(t0) is found from fitting the line u(t) u(t0) u(t0)(t t0)
through the two points (t2 2 , u(t2) 4) and (t3 3 , u(t3) 5) . See Figure 1.3b. Since the
linear system (17) is consistent, which means that all three points (t1 , u(t1)),
(t2 , u(t2)) and (t3 , u(t3)) lie on the same line (see Figure 1.3c), the two solutions (18) and (19)
are of course identical.
                                                                                                     Least-squares: a review 11

                 Figure 1.3: Fitting a straight line through consistent measurements.
Example 5
Consider the situation of Example 4. But now assume that the position measurements read:
The linear system (16) then becomes:
(20)
In this case the measurement vector y cannot be written as a linear combination of the column
vectors of matrix A. Hence yR(A) , showing that the system is inconsistent. This inconsistency
can clearly be seen from Figure 1.4a. Figure 1.4a shows clearly that no straight line
12 Dynamic data processing

u(t) u(t0) u(t0) (t t0) exists that passes through all three measurement points. In order to find
a solution one could disregard measurement u(t3 3) 6 and solve the system:

The solution of this system reads (see Figure 1.4b):
(21)

But instead of disregarding u(t3 3)  6 one could also opt for disregarding measurement
u(t1 1) 3 or measurement u(t2 2)     5 . In case of disregarding measurement u(t1 1) 3 ,
one has to solve the system:

The solution of this system reads (see Figure 1.4b):

(22)

This solution differs however from solution (21) (see also Figure 1.4b). So, which solution
should we accept? The problem with the above approach is the arbitrariness in disregarding
measurements. Why should we disregard measurement u(t3 3) 6 and completely rely on the
measurements u(t1 1) 3 and u(t2 2) 5 ? It seems more appropriate to have a solution
method which somehow takes all measurements into account. In case of the present example one
could for instance think of computing the line u(t) u(t0) u(t0)(t t0) such that it fits all three
measurement points as closely as possible (see Figure 1.4c). A method that accomplishes this
task in a predefined way, is the method of least-squares. This method will be introduced in the
next section.
                                                                                                     Least-squares: a review 13

                Figure 1.4: Fitting a straight line through inconsistent measurements.
1.1.2 Least-squares estimates
An inconsistent system, that is, a system for which y  R(A) holds, can be made consistent by
introducing an m×1 error vector e as (see Figure 1.5):
(23)
14 Dynamic data processing

      Figure 1.5: The geometry of y Ax e .

In (23), y and A are given, whereas x and e are unknown. From the geometry of Figure 1.5 it
seems intuitively appealing to estimate x as x^ such that A x^ is as close as possible to the given
measurement- or observation vector y. In other words, the idea is to find that value of x that
minimizes the length of the vector e y Ax . This idea leads to the following minimization
problem:

(24)                           .

From calculus we know that x^ is a solution of (24) if x^ statisfies:
(25)

where E(x) is given as:
(26)
Taking the first-order and second-order partial derivatives of E(x) gives:

(27)

Equating the first equation of (27) to zero shows that x^ satisfies the normal equations:
(28)

Since rank A A rank A n , the system is consistent and has a unique solution. Through an
inversion of the normal matrix A A the unique solution of (28) is found as:

(29)                        .

That this solution x^ is the minimizer of (26) follows from the fact that the matrix 2E/x 2 of
(27) is indeed positive-definite. The vector x^ is known as the least-squares estimate of x, since
it produces the smallest possible value of the sum-of-squares function E(x) . From the normal
equations (28) it follows that A (y Ax^) 0 . This shows that the vector e^ y Ax^ , which is
the least-squares estimate of e, is orthogonal to the range space of matrix A (see Figure 1.6):

(30)                           .
                                                                    Least-squares: a review 15

                        Figure 1.6: The geometry of least-squares: y Ax^ e^ .

Example 6
Consider again the situation of a particle moving with constant velocity along a straight line. We
assume that three observations of position are carried out at three different times
t1, t2 and t3 : u(t1), u(t2) and u(t3) . We also assume that the time instances are equidistant:
t1 t0 t2 t1 t3 t2 T . The linear system reads then:

If the system is inconsistent, it can be made consistent by introducing an error vector e as:
(31)

The least-squares solution of (31) follows now from minimizing e e    3
parameters u(t0) and u(t0) . With
                                                                        ei2 as function of the

                                                                    i1

and
16 Dynamic data processing       (u(t0), u(t0)) follows as:

the least-squares estimate of x

This may be rearranged to give:
(32)

This result shows that the slope of the straight line, u(t0) (= velocity of particle), is determined
from the two outer points (t1, u(t1)) and (t3, u(t3)) , and that the intercept of the straight line,
u(t0) (= initial position of particle), equals the average of u(ti) u^.(t0)iT, i 1, 2, 3 .

So far we have discussed the unweighted least-squares principle. The least-squares principle can
be generalized, however, by introducing a positive-definite m×m weight matrix W. This is done
by replacing (24) by the following minimization problem:

(33)                                                            .

The solution of (33) can be derived along lines which are similar to the ones used for solving
(24). The solution of (33) reads:

(34)                                                         .

This is the weighted least-squares estimate of x. In case of weighted least-squares the normal
equations read: A WAx^ A Wy . This shows that the vector e^ y Ax^ , which is the weighted
least-squares estimate of e, satisfies:

(35)                                                            .

If the inner product of the observation space m is defined as (a,b) a Wb, a,b m , (35) can
also be written as (Ax,e^) 0, x n . This shows that also in the case of weighted least-squares,
the vector e^ can be considered to be orthogonal to the range space of A. A summary of the least-

squares algorithm is given in Table 1.1.
                                           Least-squares: a review 17

             Inconsistent linear system
    y Ax e, y, e m, x n, m > n rank A

         Weighted least-squares principle

    minimize (y Ax) W(y Ax), W positive definite

             x

              Weighted least-squares estimates

    parameter vector : x^    (A WA) 1A Wy
                             Ax^
    observation vector : y^  y y^

    error vector  : e^

    Table 1.1: Weighted least-squares.

Example 7

The elements of the weight matrix W can be chosen to emphasize (or de-emphasize) the
influence of specific observations upon the estimate x^ . In this way different levels of importance
may be attached to the different observations. This is of importance if one believes that some
observations are more trustworthy than other observations. For instance, some observations may
be more trustworthy than others if they are obtained from more accurate measurement
instruments. In order to illustrate the influence of the weight matrix, we consider a stationary
particle with unkown position u(t0) . We assume that two observations of position are carried out
at times t1 and t2 . The linear system reads then:

(36)

A diagonal matrix is taken as weight matrix:

(37)

Then

or
18 Dynamic data processing

(38)

This shows that u^(t0) equals the average of u(ti), i 1, 2, if w11 w22 (see Figure 1.7a). In this
case both observations have the same influence on u^(t0) . However, if w22 < w11 then less weight
is attached to the second observation and u^(t0) is closer to u(t1) , see Figure 1.7b.

                          Figure 1.7: Weighted least-squares estimate of u(t0)
                                        (a) w11 w22 ; (b) w11 > w22 .

1.1.3 A stochastic model for the observations
In the previous section the principle of least-squares was introduced. The least-squares principle
enables us, in case of inconsistent systems, to obtain an intuitively appealing estimate x^ of the
parameter vector x. But although the least-squares estimate x^ is intuitively appealing, no quality
measures as yet can be attached to the estimate. That is, we know how to compute the estimate
x^ , but we are not able yet to say how good the estimate really is. Of course, the numerical value
of the sum of squares, e^ We^ , does indicate something about the quality of x^ . If e^ We^ is small
one is inclined to have more confidence in the estimate x^ , than if e^ We^ is large. But how small
is small? Besides, e^ We^ is identically zero if the linear system is consistent. Would this then
automatically imply that the estimate x^ has good quality? Not really, since the observations may
still be subject to measurement errors. In order to obtain quality measures for the results of least-
squares estimation, we start by introducing a qualitative description of the input, that is of the
observations. This description will be of a probabilistic nature. The introduction of a probabilistic
description is motivated by the experimental fact that the variability in the outcome of
                                                                                                     Least-squares: a review 19

measurements, when repeated under similar circumstances, can be described to a sufficient
degree by stochastic or random variables. We will therefore assume that the observation vector
y, which contains the numerical values of the measurements, constitutes a sample of the random
vector of observables y (note: the underscore indicates that we are dealing with a random
variable). It is furthermore assumed that the vector of observables y can be written as the sum
of a deterministic functional part Ax and a random residual part e :

(39)                            .

Although a random vector is completely described by its probability density function, we will
restrict ourselves for the time being to the first two moments of random variables. That is, we
will restrict ourselves to the mean and to the variance matrix. If we assume that e models the
probabilistic nature of the variability in the measurements, it seems acceptable to assume that this
variability is zero on the average and therefore that the mean of e is zero:
(40)

where E . stands for the mathematical expectation operator. The measurement variability itself
is modelled through the dispersion or variance matrix of e . We will assume that this matrix is
known and denote it by Qy :
(41)

where D . stands for the dispersion operator. It is defined in terms of E . as D .
E (. E . )(. E . ) . With (40) and (41) we are now in the position to determine the mean and
variance matrix of the vector of observables y . Application of the law of propagation of means
and the law of propagation of variances to (39) gives with (40) and (41):

(42)                               .

This will be our model of observation equations for the vector of observables y . As the results
of the next section show, model (42) enables us to describe the quality of the results of least-
squares estimation in terms of the mean and the variance matrix.

1.1.4 Least-squares estimators

Functions of random variables are again random variables. It follows therefore, that if the vector
of observables is assumed to be a random vector y and substituted for y in the formulae of Table
1.1 in Section 1.1.2 the results are again random variables:

(43)

These random vectors will be called least-squares estimators. And if y is replaced by its sample
or measurement value y, we speak of least-squares estimates. The quality of the above estimators
can now be deduced from the first two moments of y .
20 Dynamic data processing

The first moment: the mean
Together with E y Ax , application of the propagation law of means to (43) gives:
(44)

This important result shows that under the assumption that (42) holds, the least-squares
estimators are unbiased estimators. Note that this property of unbiasedness is independent of the
choice for the weight matrix W.

The second moment: the variance matrix and covariance matrix

Together with D y  Qy , application of the propagation law of variances and covariances to (43)
gives:

(45)

and
(46)

The above variance matrices enable us now to give a complete precision description of any
arbitrary linear function of the estimators. Consider for instance the linear function ^ a x^ .
Application of the propagation law of variances gives then for the precision of ^: ^2 a Qx^a .
The above results enable us to describe the quality of the results of least-squares estimation in
terms of the mean and the variance matrix. The introduction of a stochastic model for the vector
of observables y enables us however also to judge the merits of the least-squares principle itself.
Recall that the least-squares principle was introduced on the basis of intuition and not on the
basis of probabilistic reasoning. With the mathematical model (42) one could now however try
to develop an estimation procedure that produces estimators with certain well-defined
probabilistic optimality properties. One such procedure is based on the principle of Best Linear
Unbiased Estimation (BLUE), [Teunissen, 2000]. Assume that we are interested in estimating a
parameter  which is a linear function of x:

(47)

The estimator of  will be denoted as ^ . Then according to the BLUE's criteria, the estimator
^ of  has to be a linear function of y :
                                                                                                     Least-squares: a review 21

(48)

such that it is unbiased:
(49)
and such that it is best in the sense of minimum variance:
(50)
The objective is thus to find a vector l m such that with (48), the conditions (49) and (50) are
satisfied. From Adjustment theory, [Teunissen, 2000] we know that the solution to the above
problem is given by:

If we substitute this into (48) we get:
(51)
This is the best linear unbiased estimator of . The important result (51) shows that the best
linear unbiased estimator of x is given by:
(52)
A comparison between (43) and (52) shows that the BLUE of x is identical to the weighted least-
squares estimator of x if the weight matrix W is taken to be equal to the inverse of the variance
matrix of y :
(53)
This is an important result, because it shows that the weighted least-squares estimators are best
in the probabilistic sense of having minimal variance if (53) holds. The variances and covariances
of these estimators follow if the weight matrix W is replaced in (45) and (46) by Qy 1 . From now
on we will always assume, unless stated otherwise, that the weight matrix W is chosen to be
equal to Qy 1 . Consequently no distinction will be made anymore in this book between weighted
least-squares estimators and Best Linear Unbiased Estimators. Instead we will simply speak of
least-squares estimators.

Example 8

Consider again the situation of a stationary particle. Assume that it is required to determine its
position with a variance of 2/10 . The position measurements are uncorrelated and all have a
variance equal to 2 . How many position measurements are then needed in order to estimate the
particle's position with sufficient precision?

In order to answer this question we first introduce our linear A-model:
22 Dynamic data processing

The variance of the least-squares estimators u^(t0) of u(t0) reads then:
This result shows that m = 10 position measurements are needed to satisfy the requirements.
Example 9
Consider the situation of Example 2. The position observables are assumed to be uncorrelated
and to have the same variance 2 . An interesting question is now how the times of measurement
t1 and t2 should be chosen, in order to minimize the variances of the least-squares estimators
of initial position u(t0) and initial velocity u(t0) . In order to answer this question we first
introduce our linear A-model:

Note that this model consists of two equations in two unknowns. Hence the redundancy m-n
equals zero, and matrix A is square and invertible (provided that t2  t1 ). In this case the least-
squares estimator and its variance matrix simply reduce to:

With

this gives for the variance matrix:
                                Least-squares: a review 23

(54)

Let us now first consider the variance of the velocity estimator u^.(t0) . It reads:

This result shows that the variance of u^.(t0) gets smaller, i.e. its precision gets better, if the time
interval t2 t1 gets larger. Thus one can improve the precision of the velocity estimator by
increasing the time interval between the two position measurements. This is also quite

understandable if one looks at Figure 1.2 in Section 1.1.1. A straight line can be fitted better

through two points that are far apart than through two points that are close together. And in fact

it becomes impossible to fit the line uniquely if the two points coincide, just like it is impossible

to estimate the velocity if t2  t1 . Let us now consider the variance of the position estimator
u^(t0) . It reads (see (54)):

Also this result shows that the variance of the initial position estimator gets smaller if the time
interval t2 t1 gets larger. Also note that in case t1  t0 , the variance of u^(t0) is always larger
than the variance of 2 of the position observables. The smallest value of u^(t0) 2 is obtained for
t1 t0 . This shows that the precision of the initial position estimator is best if the first position
measurement is taken at the initial time t0 .

1.1.5 Summary

In Table 1.2 an overview is given of the main characteristics of least-squares estimation.
24 Dynamic data processing

                            The linear A-model

                            Least-squares estimators

                            Mean

                            Variances and covariances

                                    Table 1.2: Least-squares estimation.

1.2 The nonlinear A-model

1.2.1 Nonlinear observation equations

Up to this point the development of our estimation theory was based on the assumption that the
m-vector E y is linearly related to the n-vector of unknown parameters x. In geodetic
applications there are however only a few cases where this assumption truly holds. A typical
example is levelling. In the majority of applications, however, the m-vector E y is nonlinearly
related to the n-vector of unknown parameters x. This implies that instead of the linear A-model
(42), we are generally dealing with a nonlinear model of observation equations:
                                                                                                     Least-squares: a review 25

(55)

where A(.) is a nonlinear vector function from n into m . The following two simple examples
will make this clear.

Example 10

Consider the configuration of Figure 1.8a. The x, y coordinates of the three points 1, 2 and 3 are

known and the coordinates x4 and y4 of point 4 are unknown. The observables consist of the

three azimuth variates a , a and a . Since azimuth and coordinates are related as (see Figure
            14 24  34

1.8b):

the model of observation equations for the configuration of Figure 1.8a reads:

This model consists of three nonlinear observation equations in the two unknown parameters
x4 and y4 .

                                       Figure 1.8: Azimuth resection.

Example 11

Consider the situation of Figure 1.9. It shows two cartesian coordinate systems: the x,y-system
and the u,v-system. The two systems only differ in their orientation. This means that if the
coordinates of a point i are given in the u,v-system, (ui , vi) , a rotation by an angle  is needed
to obtain the coordinates of the same point i in the x,y-system, (xi , yi) :
26 Dynamic data processing

(56)

          Figure 1.9: A coordinate transformation.

Let us now assume that we have at our disposal the coordinate observables of two points in both

coordinate systems: (x , y ) and (u , v ), i  1, 2 . Using (56), our model reads then:
      ii                    ii

(57)

This model is however still not in the form of observation equations. If we consider the
orientation angle  and the coordinates of the two points in the u,v-system as the unknown
parameters, (57) can be written in terms of observation equations as:

(58)

This model consists of eight observations in five unknown parameters. Note that the first four
observation equations are nonlinear.
                              Least-squares: a review 27

1.2.2 The linearized A-model

We know how to compute least-squares estimators in case of a linear A-model. But how are we
now going to compute least-squares estimators if the model of observation equations is non-
linear? For the majority of nonlinear problems the solution is to approximate the originally
nonlinear A-model with a linear one. In order to show how this can be done, we first recall the
theorem of Taylor.

Taylor's Theorem

Let f(x) be a function from n into . Let x0 n be an approximation to x n and define
x x x 0, and  x 0 t(x x 0) with t . Then a scalar t(0,1) exists such that:

(59)

with the remainder:
(60)

In (59) and (60), 1..q q f(x) denotes the qth-order partial derivative of f(x) evaluated at x. For the
case q = 2, it follows from (59) and (60) that:
(61)

If we introduce the gradient vector and Hessian matrix of f(x) respectively as:

then equation (61) may be written in the more compact matrix-vector form as:

(62)                          .

This important result shows that a nonlinear function f(x) can be written as a sum of three terms.

The first term in this sum is the zero-order term f(x 0) . The zero-order term depends on x 0 but

is independent of x. The second term in the sum is the first-order term xf(x 0) x . It depends on x 0
and is linearly dependent on x. Finally, the third term in the sum is the second-order remainder

R2(,x) . An important consequence of Taylor's theorem is that the remainder R2(,x) can be
made arbitrarily small by choosing the approximation x 0 close enough to x. Now assume that
28 Dynamic data processing

the approximation x 0 is chosen such that the second-order remainder can indeed be neglected.
Then, instead of (62) we may write to a sufficient degree of approximation:

(63)                                          .

Hence, if x 0 is sufficiently close to x, the nonlinear function f(x) can be approximated to a
sufficient degree by the function f(x 0) x f(x 0) x which is linear in x. This function is the
linearized version of f(x). A geometric interpretation of this linearization is given in Figure 1.10

for the case n = 1.

   Figure 1.10: The nonlinear curve y = f(x) and its linear tangent y f(x 0) d f(x 0)(x x 0).

                                                                                                                                                                 dx

Let us now apply the above linearization to our nonlinear observation equations:

(64)

Each nonlinear observation equation ai(x), i  1, ,m , can now be linearized according to (63).
This gives:

(65)

If we denote the m×n matrix of (65) as xA(x 0) , and substitute (65) into (64) we get:

If we bring the constant m-vector A(x 0) to the left-hand side of the equation and define
y y A(x 0) , we finally obtain our linearized model of observation equations:

(66)                                             .

This is the linearized A-model. Compare (66) with (55) and (42). Note when comparing (66)
with (42) that in the linearized A-model y takes the place of y, xA(x 0) takes the place of A
                                                                                                     Least-squares: a review 29

and x takes the place of x. Since the linearized A-model is linear in x x x 0 our standard
formulae of least-squares can be applied again. This gives for the least-squares estimator
x^ x 0 x^ of x :
(67)
Application of the propagation law of variances to (67) gives:
(68)
It will be clear that the above results, (67) and (68), are approximate in the sense that the second-
order remainder is neglected. But these approximations are good enough if the second-order
remainder can be neglected to a sufficient degree. In this case also the optimality conditions of
least-squares (unbiasedness, minimal variance) hold to a sufficient degree. A summary of the
linearized least-squares estimators is given in Table 1.3.

                                           The nonlinear A-model

                                           The linearized A-model

                                          Least-squares estimators

                                                    Variances

                              Table 1.3: Linearized least-squares estimation.
30 Dynamic data processing

Example 12

Consider the configuration of Figure 1.11a. The x, y coordinates of the three points 1, 2 and 3

are known and the two coordinates x4 and y4 of point 4 are unknown. The observables consist

of  the  three  distance  variates  l,   l    and  l.   Since  distance  and  coordinates  are  related  as  (see

                                     14   24        34

Figure 1.11b):

the model of observation equations for the configuration of Figure 1.11a reads:
(69)

This model consists of three nonlinear observation equations in the two unknown parameters
x4 and y4 .

                                       Figure 1.11: Distance resection.
In order to linearize (69) we need approximate values for the unknown coordinates x4 and y4 .
These approximate values will be denoted as x40 and y40 . With these approximate values a
linearization of (69) gives:

(70)

where:
                                                                                                     Least-squares: a review 31

Model (70) is the linearized version of the nonlinear A-model (69).
Example 13
Consider the nonlinear A-model (58) of Example 11. The unknown parameters are  and
ui, vi for i 1,2 . The approximate values of these parameters will be denoted as
0 and ui0, vi0 for i 1,2 . Linearization of (58) gives then:

(71)

where:

Example 14
Consider the situation of Figure 1.12. A satellite orbiting the earth is assumed to have a circular
orbit with unknown radius R. Distance measurements from two known points 1 and 2 on the
32 Dynamic data processing

earth surface are carried out to the two satellite positions 3 and 4. It is assumed that the earth
is a non-rotating body.

                 Figure 1.12: Distance measurement to a satellite orbiting the earth.
The distance lij between two points i and j can be parameterized in terms of cartesian coordinates
as:
(72)
The circular satellite orbit itself can be parameterized in terms of polar coordinates as:
(73)
With (72) and (73) the nonlinear model of observation equations becomes:

(74)

The unknowns in these observation equations are besides the orbital radius R also the coordinates
3 and 4 . The approximate values of these parameters are denoted as R 0, 30 and 40 .
Linearization of (74) gives then:
                                                                                                     Least-squares: a review 33

(75)
1.2.3 Least-squares iteration
Up to this point it was assumed that the second-order remainder was sufficiently small and that
x0 was a good enough approximation for x. If this is not the case, then x^ as computed by (67)
is not the least-squares estimate and hence an unacceptable error is made. In order to repair this
situation, we need to improve upon the approximation x 0 . It seems reasonable to expect that the
estimate:

is a better approximation than x 0 . That is, it seems reasonable to expect that x 1 is closer to the
true least-squares estimate than x 0 . In fact one can show that this is indeed the case for most
practical applications. But if x 1 is a better approximation than x 0 , a further improvement can
be expected if we replace x 0 by x 1 in the linearization of the nonlinear model. The recomputed
linearized least-squares estimate reads then:
34 Dynamic data processing

                                     Table 1.4: Least-squares iteration.
By repeating this process a number of times, one can expect that finally the solution converges
to the actual least-squares estimate x^ . This is called the least-squares iteration process. The
iteration is usually terminated if the difference between successive solutions is negligible. A flow
diagram of the least-squares iteration process is shown in Table 1.4. For more details on the
numerical properties of the iteration process and on the probabilistic properties of nonlinear least-
squares estimators the reader is referred to the theory as developed in [Teunissen, 1985b].
                             Least-squares: a review 35

1.3 The B-model

1.3.1 The linear B-model

In the previous sections we considered the model of observation equations. In this section and
the next we briefly review the model of condition equations. For more details the reader is again
referred to Adjustment theory, [Teunissen, 2000]. As our starting point we take the linear A-
model:

(76)

This linear model is uniquely solvable if m = n, i.e. if the number of observables equals the

number of unknown parameters. In this case A is a square matrix which is invertible because of

rank A = n. If m = n, the redundancy equals zero, and no conditions can be imposed on the

observables. If m > n = rank A, then more observables are available than strictly needed for the

determination of the n unknown parameters. In this case an ( m n )-number of redundant

observables exist. Each separate redundant observable gives rise to the possibility of formulating

a condition equation. Thus the total number of independent condition equations that can be

formulated equals:

(77)                      .

We will now show how one can construct the condition equations, given the linear A-model (76).
Each of the column vectors of matrix A is an element of the observation space m . Together the
n-number of linearly independent column vectors of A span the range space of A. This range
space has dimension n and it is a linear subspace of m: R(A)  m . Since dim R(A) = n and dim m
= m, exactly ( m n )-number of linearly independent vectors can be found that are orthogonal to
R(A). Let us denote these vectors as: bi m, i 1,...,(m n) . Then:

From this it follows, if the ( m n )-number of linearly independent vectors bi are collected in an
m×(m n) matrix B as:

that

(78)                         .

This result may now be used to obtain the model of condition equations from (76).
Premultiplication of the linear system of observation equations in (76) by B gives together with
(78) the following linear model of condition equations:

(79)                            .
36 Dynamic data processing

Example 15
Consider the following linear A-model:
(80)
Since m = 3, n = 1 and rank A = 1 = n, the redundancy equals m-n = 2. Hence two linearly
independent condition equations can be formulated. The two vectors:

are linearly independent and are both orthogonal to the single column vector of matrix A in (80).
Hence the with (80) corresponding linear model of condition equations reads:

(81)

Example 16
Consider the linear A-model of Example 6 in Section 1.1.2:

(82)

Since m = 3, n = 2 and rank A = 2 = n, the redundancy equals m-n = 1. Hence, only one
condition equations can be formulated. The with (82) corresponding linear B-model reads:
                          Least-squares: a review 37

(83)

Verify that B A 0 holds.

Now that we have the linear B-model (79) at our disposal, how are we going to compute the
corresponding least-squares estimators? We know how to compute the least-squares estimators
for the linear A-model. The corresponding formulae are however all expressed in terms of the
A-matrix. What is needed therefore is to transform these formulae such that they are expressed
in terms of the B-matrix. This is possible with the following important matrix identity:

(84)                      .

The proof of this matrix identity is as follows. We define two matrices C and C as:
(85)

Since both matrices C and C are of dimension m×m and since both can be shown to be of full

rank, it follows that they are invertible. From (85) it follows with the help of (78) that CC Im .
Hence C C 1 and therefore CC Im . Substitution of (85) into this last expression proves
(84). With (84) and the least-squares results of Table 1.2 of Section 1.1.5 we are now in the

position to derive the expressions for the least-squares estimators in terms of the matrix B. The

results are summarized in Table 1.5.
38 Dynamic data processing

                             The linear B-model

                              Least-squares estimators
                             Variances and covariances

                            Table 1.5: Least-squares estimation.

1.3.2 The nonlinear B-model

Just as in the case of the A-model, there are very few geodetic applications for which the model
of condition equations is linear. In most cases the model of condition equations is nonlinear. The
nonlinear B-model reads:

(86)                                                    .

Where B (.) is a nonlinear vector function from m into m n . The relationship between the non-
linear B-model and the nonlinear A-model is given by:

(87)                                             .

This is the nonlinear generalization of (78). If we take the partial derivative with respect to x of
(87) and apply the chain rule, we get:

(88)                                                              .

This is the linearized version of (87). Compare (88) with (78). With (88) we are now in the
position to construct the linearized B-model from the linearized A-model (66). Premultiplication
of (66) with the matrix [yB(y 0)] gives together with (88) the result:
                                                            Least-squares: a review 39

(89)                                                        .

This is the linearized B-model. With (89) we are now in the position again to apply our standard
least-squares estimation formulae.

Example 17

The cartesian coordinates of three points 1, 2 and 3 are measured. The observables are therefore:

x , y , x , y , x and y . The three points are assumed to lie on a circle with unknown radius R,
11223       3

see Figure 1.13. Since the circle can be parameterized as:

the nonlinear A-model reads:

(90)

This model consists of six nonlinear observation equations in the four unknown parameters
R, 1, 2 and 3 . The approximate values of these parameters are denoted as R 0, 10, 20 and 30 .
Linearization of (90) gives:
40 Dynamic data processing

(91)

                                     Figure 1.13: Circle with radius R.
Instead of parameterizing the circle, one can alternatively describe the circle implicitly as:
This description leads to the following nonlinear model of condition equations:
(92)
The number of independent condition equations equals the redundancy, which is equal to
6 4 2 . If the approximate values are chosen such that:
                                                                   Least-squares: a review 41

linearization of (92) gives:
(93)

Verify yourself that [yB(y 0)] [xA(x 0)] 0 holds for y 0 A(x 0) .
2 Recursive least-squares: the static case

2.1 Introduction

In the previous chapter we reviewed the standard theory of least-squares estimation. In this
chapter we will make a modest start with the development of the theory of recursive least-
squares estimation. Recursive least-squares is a least-squares estimation procedure that enables
us to update least-squares estimators for new observables without the need of having to save all
past observables. As such the method is of great practical importance. The following example
should make the practical relevance of such a recursive procedure clear.

Example 18

Figure 2.1a shows a levelling loop of four points. The heights of these points are denoted as
x0, x1, x2 and x3 . The height of point 0 is known and it is equal to zero: x0 0 .

                               Figure 2.1: Two levelling networks.

The  four  height  difference  observables  are  denoted  as  y,   y,   y    and  y.   They  are  uncorrelated

                                                                1    2    3         4
and they have all the same variance 2 . The linear A-model reads therefore:

(1)

Its least-squares solution reads (verify this yourself):
(2)
44 Dynamic data processing

with corresponding variance matrix:
(3)

Now  assume    that    an  additional  height    difference  observable   y,     which  has  a   variance  of  2    and

                                                                            5
                           y,         1,...,4 , is included in the levelling network (see Figure 2.1b). What
is  uncorrelated    with        i
                             1
would then be an efficient way to compute the least-squares estimator of x (x1, x2, x3) ? One

could of course formulate again the A-model in terms of the original height difference

observables:

(4)

Its least-squares solution reads (verify this yourself):
(5)

with corresponding variance matrix:
(6)

Note that this approach requires that all original height difference observables are available. Also

no use is made in this approach of the previous solution (2) and (3). The advantage of the

recursive least-squares procedure is now that the same solution (5) and (6) can be obtained

without the explicit need of having to store all original observables. Instead of using all original

observables    y,   i      1,...,4 ,  plus  the  new  observables  y,   the  recursive      least-squares  procedure

                 1                                                   5

is  based  on  an  optimal  combination     of   the  previous  solution  x^     with  the  new  observable    y.   The

                                                                            (1)                                  5

appropriate model for this combination reads:
                                                                        Recursive least-squares: the static case 45

(7)

As will be shown below, the solution of this model is identical to the solution (5) and (6).

Consider the partitioned model:

(8)

Note  that  it  is  assumed  that  y    and  y    are  uncorrelated.    The  least-squares  solution  of  (8)  will  be

                                     1         2

denoted as x^ . It reads:

                          (2)

(9)

Let us now consider the partial model:
(10)
Its solution will be denoted as x^ . It reads:

                                                                   (1)

(11)

From this it follows that:

Substitution of this result into (9) shows that:
(12)
But this is exactly the solution of the model:
(13)
46 Dynamic data processing

Hence, we have proven that the solution of the partitioned model (8) can be found in two steps.

First one solves for the partial model (10). This gives x^(1) (1) and Qx^ . Then in a second step one
uses x^(1) (1) and Qx^ together with y2 and Q2 to find, via model (13), the final solution
x^(2) (2) and Qx^ . This result shows that there is no need to store past observables y1 for the purpose

of  computing  present    estimators       x^ .   This  is  the    essence  of  recursive  estimation.

                                             (2)

2.2 Recursive least-squares: the A-form

The two-step procedure of the previous section can be generalized to more than two steps.
Consider the partitioned model:

(14)

Note  again    that  the  y,   i     0,...,k , are assumed to be mutually uncorrelated. The least-squares

                            i

solution  of   model  (14)     will  be  denoted  as    x^ .   It  reads:

                                                          (k)

(15)

Let   us  now  consider   model      (14)  with   the  exception   of      y:

                                                                             k

(16)

The least-squares solution of this model reads:
(17)
From this it follows that:
                                                                     Recursive least-squares: the static case 47

Using these equations, we may rewrite (15) as :
(18)
But this is exactly the solution of the model:
(19)

The above derivation shows that there is no need to store the previous observables

y, i  1,...,(k   1) ,  for        the  purpose       of  computing   the    present     least-squares  estimator  x^ .   That

  i                                                                                                                 (k)

is , the estimator x^ can be computed directly from the previous estimator x^ and the present
                      (k)                                                                              (k 1)

observable  y.   This,       again,       is   the   essence   of    recursive   estimation.    The  recursive   estimation

              k

procedure   is  initialized       with    the  computation       of  the    initial  least-squares  estimator  x^ :

                                                                                                                 (0)

Once x^ is known, x^ can be computed from x^ and y for k 1,2, using (18). Note that
      (0)                    (k)                                     (k 1)           k

by rearranging the right-hand side of the first equation of (18), the recursive estimator can

alternatively be expressed as (verify this yourself):

(20)                                                                                         .

The first equation is called the measurement update equation. It clearly shows how to update the

previous   estimator   x^    1)   in      order  to  take  care  of  the    new  observable  y.     The  second  equation  is

                         (k                                                                    k

called the variance update equation. A flow diagram of the above recursive least-squares

procedure is shown in Table 2.1. Note the great resemblance in structure between the recursive

least-squares process and the least-squares iteration process of Table 1.4 of Section 1.2.3. The

resemblance is a consequence of the fact that both processes are based on the repeated

application of the least-squares principle. Despite this resemblance, however, both processes solve

two fundamentally different problems. In order to get a somewhat better understanding of the

above recursive least-squares procedure, consider the correction term in the first equation of (20).

In this term the vector Akx^(k 1) occurs. This vector depends on all previous observables
y, i  1,...,(k   1) ,
                       but        it  is  independent      of  the   present  observable  y.
  i
                                                                                            k
48 Dynamic data processing

                           Table 2.1: Recursive least-squares estimation.

Since x^(k 1) is unbiased, that is E x^(k 1) x holds, we have that E Ak x^(k 1) Ak E x^(k 1)

    Akx    also holds, showing that       Akx^(k 1)  is an unbiased estimator of       Ey        Akx . In fact, if

                                                                                              k

one recalls the principle of Best Linear Unbiased Estimation, it will be clear that Ak x^(k 1) is

the Best Linear Unbiased Estimator of         Ey         when the estimation is based on the model (16).

                                                     k

This model contains only the past observables                y, i       0,...,(k 1) . Hence, Akx^(k 1) can be

                                                               i

interpreted as the prediction of the present observable            y    .  The  difference  y^   Ak x^(k 1)  in (20)

                                                                     k                        k

is therefore the residual value between the present observable and its prediction. It will be called

the predicted residual and denoted as:

(21)

In  (20),  the  predicted  residual  v    is  premultiplied  by  the    matrix:

                                       k

(22)

and the product is then added to the previous estimator x^ to obtain the current estimation x^ .
                                                                    (k 1)                                        (k)

Hence    the  gain  in  estimation  experienced      by  including  the    observable  y    is   determined  by  the

                                                                                         k
                                                              Recursive least-squares: the static case 49

product  Kk v k .  It  depends  both   on  the  predicted  residual  v    and  on   the  matrix  Kk ,  which   will  be

                                                                       k

called the gain matrix. Expression (20) shows that the correction to the estimate x^(k 1) is small

if the predicted residual vk is small. This is also what one would expect. Because if the predicted

observation Akx^(k 1) is close to the actual observation yk there is no need really to change the

estimate x^(k 1) by a large amount. Expression (20) also shows that the correction to the estimate

x^(k 1) is small if the gain matrix Kk is small. Equation (22) shows that the gain matrix Kk

depends on Qx^ , Ak and Qk respectively. Hence, it depends on:
                                                   (k 1)

                        The precision of the previous estimator x^ : Qx^
                                                                                  (k 1)  (k 1)

(23)  The type of observable y k that is added : Ak
                       
                        The precision of the added observable y : Qk .
                                                                               k

Equation (22) shows that the gain matrix is small if the variance matrix Qx^ is small. This is
                                                                                                                                                                                                                                                                      (k 1)

(k 1) also what one would expect. If Qx^ is small, the confidence in the estimator x^(k 1) is high and

therefore the new estimator       x^   should not differ too much from the old estimator               x^     . Equation

                                    k                                                                    (k  1)

(22) shows on the other hand that the gain matrix is large if the variance matrix Qk is small. In

this  case  one  has   high  confidence    in  the  new  observable  y.   The     estimator     x^     should  therefore

                                                                       k                          (k)

gain  considerably     from  the  inclusion     of  the  new  observable       y.   To   conclude      this  section,  a

                                                                                 k

summary of the above discussed recursive least-squares procedure is given in Table 2.2.

Example 19

An unknown distance x is measured a k-number of times. The observables are denoted as

y, i     1,...,k . They are uncorrelated and all have the same variance 2 . The corresponding

  i

model of observation equations reads then:

(24)

Its batch solution reads:
(25)

In this simple case the estimator x^ equals the average of the k-number of distance observables
y i, i 1,...,k . A plot of the variance (k) x^(k) 2 as function of k is given in Figure 2.2. It shows that
the variance x^(k) 2 decreases for increasing values of k. This is of course as it should be. When
more distance observables are used for the estimation of the unknown distance x, more
50 Dynamic data processing

                            Partitioned model

                            Batch least-squares solution

                      Recursive least-squares solution
                                  Initialization

                        Measurement update equation

                          Variance update equation
Table 2.2: Batch and recursive least-squares estimation (the A-form).
                                                                                           Recursive least-squares: the static case 51

                                   Figure 2.2: The variance x^(k) 2 2/k .

information is used and therefore a more precise estimator can be computed. In the limit we
have:

This implies that the estimator x^(k) converges to a constant for k  . And since x^(k) is an

unbiased estimator of x, that is E x^                                        x holds, it follows that in the limit:

                                                                        (k)

Thus  the  larger  k  gets,  the  closer  x^                                 gets  to  x.  This                                is  shown  in  Figure  2.3  for  a  simulated

                                            (k)

example based on model (24). Figure 2.3a shows a plot of the simulated observations and Figure

2.3b shows a plot of the corresponding least-squares estimates as function of k. The true value

of x used in the simulation was x = 10.

16                                                                                                                             16
15                                                                                                                             15
14                                                                                                                             14
13                                                                                                                             13
12                                                                                                                             12
11                                                                                                                             11
10                                                                                                                             10

 9                                                                                                                              9
 8                                                                                                                              8
 7                                                                                                                              7
 6                                                                                                                              6
 5                                                                                                                              5
 4                                                                                                                              4
   0 10 20 30 40 50 60 70 80 90 100                                                                                               0 10 20 30 40 50 60 70 80 90 100

                                         epoch                                                                                                                          epoch

                       (a)                                                                                                                             (b)
observation
                                                                                                                  observation

                      Figure 2.3: (a) Observation plot; (b) Estimation plot.
52 Dynamic data processing

Let us now consider the recursive least-squares estimator. It is readily derived from (25). From
writing x^(k) and x^(k) 2 as:

and

it follows with x^                                 k1               2 / (k 1) directly that:

                                  (k 1)      1 k 1 y i and x^(k 1)

                                                  i1

(26)

This result shows that for the present case the gain matrix equals Kk 1/k . It decreases for

increasing  values  of                   k,  showing  that  the  gain  in  the  estimator  x^     gets  less  for  larger  values  of

                                                                                             (k)

k. This is in agreement with the characteristics of Figure 2.3b.

Example 20

Consider the following model:

(27)

Its batch solution reads:
(28)

Note that model (27) and its solution (28) reduce to that of (24) and (25) if

ai 1 for i 1,...,k . The above estimation problem can be viewed as the problem of estimating
the unknown slope x of a straight line y = a x that passes through the origin (see Figure 2.4a).
The result (28) shows that the variance of the slope estimator, x^(k) 2 , is large if all the
ai, i 1,...,k are close to zero. This is easy to understand if one looks at Figure 2.4b.
                                                                           Recursive least-squares: the static case 53

                                       Figure 2.4: Estimation of slope.
The determination of the slope of a straight line becomes more difficult if the observation points
are clustered together and close to the origin. The variance x^(k) 2 is small however if the values
of ai, i 1,...,k are large. See also Figure 2.4c. Let us now consider the recursive least-squares
estimator of the slope. From writing x^(k) and x^(k) 2 as:
and
54 Dynamic data processing

it follows directly that:
(29)

This is the recursive least-squares estimator of the slope x.

2.3 Recursive least-squares: the B-form

Expression  (20)  for  the  recursive  estimator  x^     shows  that  a  matrix  of    dimension   n  needs  to  be

                                                    (k)

inverted.  One  can  however  also  derive  an  expression  for  x^      in  which  a  matrix  of  dimension     mk

                                                                   (k)

needs to be inverted. This expression is found if we solve (19) via the model of condition

equations. Model (19) reads in terms of condition equations as:

(30)

The solution of this model is identical to the solution of (19) and therefore also identical to the
solution of the partitioned model (14). The solution of (30) follows by applying our standard
least-squares algorithm for the linear B-model. It reads:

(31)
From the second equation of (31) it follows that:
                                                                           Recursive least-squares: the static case 55

(32)

In  this  expression  we    recognize    the   predicted                   residual  v       y k Ak x^(k 1) and its variance matrix:

                                                                                       k

(33)

Since     the  least-squares   residual  is   defined                 as   e^   y      y^ ,  equation    (32)    shows  how  the  least-

                                                                             k    k      k

squares   residual   e^   and  the  predicted       residual               v    are  related:

                       k                                                     k

(34)

This  shows    that  the  two  residuals  e^   and      v             differ    and  that  they  should     not  be  confused    with  one

                                            k             k

another.  The  least-squares   residual        e^   is                the  difference     between   the  actual  observable      and   the

                                                 k

estimated      observable,  whereas      the   predicted                   residual  v     is  the  difference   between     the  actual

                                                                                       k

observable     and   the  predicted    observable.                    The       recursive    least-squares     estimator  x^     and   its

                                                                                                                            (k)

variance matrix Qx^ follow from (31) as:
                                                                 (k)

(35)                                                                                                     .

Compare this expression with (20) and note that the gain matrix Kk now takes the form:
(36)

Compare this with (22). Solution (35) is of course identical to (20). The principal difference
between the two expressions (20) and (35) lies however in the number and dimension of the
matrices that need to be inverted. In case of (20) three matrices of order n, mk and n respectively
need to be inverted, namely:

In case of (35) only one matrix of dimension mk needs to be inverted, namely the variance
matrix of the predicted residuals:

This indicates that for most practical applications expression (35) is to be preferred over (20).
This is especially the case if mk < n . Note that in case mk 1 , the matrix inversion in (35) even
reduces to a simple scalar division. To conclude this section, a summary of the above discussed
recursive least-squares procedure is given in Table 2.3.
56 Dynamic data processing

                            Partitioned model

                            Batch least-squares solution

                     Recursive least-squares solution
                                  Initialization

                       Measurement update equation

                          Variance update equation
Table 2.3: Batch and recursive least-squares estimation (the B-form).
                                                                           Recursive least-squares: the static case 57

Example 21
Consider again Example 18 of Section 2.1. The result of the least-squares estimation after the
first step was given as (see (2) and (3)):

(37)

with corresponding variance matrix:
(38)

In order to take care of the second estimation step, we are now in the position to make use of

the  results  of  Table  2.3.  The  partial  model  for  the  new  observable  y    reads:

                                                                                 5

With A2 ( 1 0 1), Q2 2 and (38) it follows that:
(39)
Hence, the updated estimator becomes:
58 Dynamic data processing

(40)

Substitution of (37) into (40) will show that (40) is identical to (5) of Section 2.1 (verify this
yourself). The variance matrix of (40) follows with A2 ( 1 0 1) , (38) and (39) as:

(41)

which is identical to (6) of Section 2.1. Note that in the present example the matrix inversion is
simply a division by a scalar.
Example 22
Consider the following model:
(42)

Note that this model reduces to that of (27) of Section 2.2 if x1 0 , and it reduces to that of
(24) of Section 2.2 if x2 0 . The with model (42) corresponding estimation problem can be
viewed as the problem of estimating the intercept x1 and slope x2 of a straight line y x1 ax2
(see Figure 2.5a).
                                                                           Recursive least-squares: the static case 59

                              Figure 2.5: Estimation of intercept and slope.
Batch estimator
We will first consider the batch solution of (42). The normal equations read:
(43)
For the ease of deriving the solution of (43) we define:
(44)
Then
60 Dynamic data processing

(45)
and the normal equations (43) may be written as:
(46)

If we subtract ac times the first equation from the second we get:

Hence, the least-squares estimator of the slope x2 reads:
(47)
Compare this estimator with the slope estimator of (28) of Section 2.2. With the slope estimator
(47) known, the intercept estimator follows from the first equation of (46) as:
(48)
Compare this estimator with the intercept estimator of (25) of Section 2.2. The variance matrix
of the estimator (x^ , x^ ) follows from inverting the normal matrix of (43) and scaling by 2 :

                                     1(k) 2(k)

With the use of (44) and (45), this expression can be simplified to:

(49)
                                                                 Recursive least-squares: the static case 61

Note that the variances of both the intercept estimator and the slope estimator are larger than the

variances of the corresponding estimators in (25) and (28), respectively. This is of course due

to the fact that in the present example the intercept x1 and slope x2 are estimated simultaneously,
whereas in (24) and in (27) of Section 2.2 the intercept and slope were estimated separately.

From the variankce matrix (49) it follows thk at the precision of the estimators improves if either
                        2                                     2
k increases or a i increases. The sum a i can be made large by having the measurements
                     i    1                               i1
carried  out                  the  ai,  i  1,...,k            large  interval.  The  clustering  of  observation  points
              such      that                        cover a

as shown in Figure 2.5b provides therefore a poor geometry for the estimation of the intercept

and the slope. If the measurements are evenly distributed such that ai               iT , with T = constant,
then (see Figure 2.5c):

(50)

For this case the elements of the variance matrix (49) can be worked out to give:
(51)

Note that the variances are infinite if k = 1. This is of course a consequence of the fact that it
is impossible to determine intercept and slope simultaneously from only one measurement.

Recursive estimator

We will now consider the recursive solution of (42). We will assume that the measurements are
evenly distributed such that ai iT , with T = constant, holds. The gain matrix Kk can then be
computed from (51) for k 1, Qk 2 and Ak (1 kT) as:

or as:
(52)

The recursive estimator for the intercept and slope becomes therefore:
62 Dynamic data processing

(53)

Note that the elements of the gain matrix decrease for increasing k.

Example 23

Consider the levelling network of Figure 2.6a (note that this is the network of Figure 2.1b of

Example  18,  extended   with  the  observation    y ).  The  heights  of  the  four  points  are  denoted  as

                                                     6
x,  0, 1, 2, 3 . The height of point 0 is known and equal to zero: x0 0 . The six height

difference  observables  are  denoted  as  y,   i  1,...,6 . They are uncorrelated and have the same

variance 2 .                                 i

                                       Figure 2.6: Levelling network.
The with the configuration of Figure 2.6a corresponding linear A-model reads:

(54)

Let us assume that it is required to determine the variance matrix Qx^ of the least-squares
                                                                                                                                                                                                                                                           (3)

estimator of x (x1, x2, x3) . Then clearly:
(55)
                                                        Recursive least-squares: the static case 63

In this case we need to invert a 3×3 matrix to find Qx^ . An easier way to determine Qx^ would
                                                        (3)                                            (3)

be to rely on the results of Example 18 of Section 2.1. In Example 18 it was shown that the

variance matrix of the least-squares estimator of x     (x1, x2, x3) based on the configuration of
Figure 2.6b, is given as:

(56)

Since  the  two  configurations  of  Figure  2.6  only  differ  in  the  observable  y,   it  follows  that  it  is

                                                                                       6

easier to compute Qx^ from (56) using the variance update equation of the B-form. With (56),
Q3 2 and A3 (0 1 0) it follows that: (3)

or that:
(57)

Note that only a scalar division was needed for the computation of (57). Verify yourself that (57)
is indeed identical to (55).

2.4 Linearization, iteration and recursion
Up to this point the partitioned model was assumed to consist of linear observation equations.
In this section we will consider the case that the partitioned model consists of nonlinear
observation equations. As our starting point we take the following nonlinear model:

(58)

Now assume that we have an approximation x 0 of x at our disposal, such that the second-order
remainders of Ai(x), i 0, ,k , can be neglected. From the theory of Section 1.2.2 it follows then
that we may replace the nonlinear model (58) by the linearized model:
64 Dynamic data processing

(59)

in which y i y i Ai(x 0), x x x 0 and xAi(x 0) is the matrix of partial derivatives of Ai(x) .
Since the partitioned model (59) is linear in x , our results of the previous two sections may be

applied again. An overview of the corresponding batch- and recursive estimators is given in

Tables 2.4, 2.5 and 2.6. The results given in these tables hold as long as x 0 is a good

approximation. Now assume that x 0 is not a good enough approximation. In that case we need

an iteration to improve upon the approximation x 0 (see Section 1.2.3). For the batch solution of

model (58) the iteration is straightforward. The corresponding flow diagram is given in Table

2.7. Compare this flow diagram with that of Table 1.4 of Section 1.2.3. The question is now how

to iterate in case we want to compute the least-squares estimate of x recursively. It will be clear

that the batch solution can be computed in recursive form in each iteration step. The

disadvantage of this approach is however that, although recursion is achieved within each

iteration step, the overall procedure, including the iteration, is not recursive. Each iteration cycle

requires  namely  the  availability  of  the  whole  batch  of  observables  y,   i  0, ,k . Thus the

                                                                               i

iteration procedure of Table 2.7 does not lend itself for a recursive approach. Therefore an

alternative approach needs to be developed. The idea is to have instead of a recursion step at

each iteration step, an iteration at each recursion step. The procedure is as follows. Starting with

the approximation x 0 one first solves the least-squares initialization in an iterative manner. This

should take care of the nonlinearity in A0(x) . The initialization provides the initial estimate x^(0) .
We are now in the position to commence with the first step of the recursion. For the first

approximation to x^(1) we may either take x 0 , which was also used as a first approximation for
the initialization, or x^(0) , the initial estimate. Since x^(0) is likely to be a better approximation, this
value will be used as our first approximation to x^(1) . Starting with x^(0) the first step of the
recursion can now be solved in an iterative manner. This should take care of nonlinearity in

A1(x) . As a result of the first step of the recursion we get x^(1) . This estimate may then be used
in the second step of the recursion as the first approximation to x^(2) , and the whole process is
repeated again. By continuing in this manner it is possible to take care of the nonlinearity in the

partitioned model and at the same time to obtain the estimates in recursive form. A flow diagram

of the whole procedure is shown in Table 2.8.
                                   Recursive least-squares: the static case 65

       Nonlinear partitioned model
      Linearized partitioned model
     Linearized batch least-squares

Table 2.4: Batch least-squares estimation.
66 Dynamic data processing

                            Linearized recursive least-squares: the A-form
                                                  Initialization

                                                    Recursion
                                             Measurement update

                                               Variance update
                      Table 2.5: Recursive least-squares estimation: the A-form.
                                               Recursive least-squares: the static case 67

    Linearized recursive least-squares: the B-form
                            Initialization

                             Recursion
                      Measurement update

                         Variance update
Table 2.6: Recursive least-squares estimation: the B-form.
68 Dynamic data processing

                                  Table 2.7: Batch least-squares iteration.
                                    Recursive least-squares: the static case 69

Table 2.8: Recursive least-squares iteration.
70 Dynamic data processing

                                           Table 2.8: continued.
                                                                           Recursive least-squares: the static case 71

Example 24
Consider the situation of Figure 2.7. It shows two cartesian coordinate systems: the x, y-system
and the u, v-system. The two systems only differ in their orientation. Hence:

It is assumed that the u, v-coordinates of a k-number of points are known. Of these same points

we  have  at  our  disposal  the  x,  y-coordinate  observables  x,   y,   i  1, ,k . These observables are

                                                                   i    i
uncorrelated and all have the same variance 2 . The corresponding nonlinear A-model reads

then:

(60)

This model consists of a 2k-number of nonlinear observation equations in one unknown
parameter . We will assume that the difference in orientation between the two systems is small.
The approximate value of  may therefore be taken to be equal to zero: 0 0 . The linearized
version of (60) reads then:

(61)

                                  Figure 2.7: Coordinate transformation.
72 Dynamic data processing

Let us assume that it is required to solve (61) in recursive form by taking one point at a time
into account. In order to derive the corresponding recursive estimator, we first need an expression
for the gain matrix Kk . The following two expressions for Kk are available to us:
(62)

For the present example we have mk 2 and n 1 . The derivation of the gain matrix is
therefore for the present example the easiest if we use expression (62a.) This gives, with

the following expression for the gain matrix:
(63)

Hence, the recursive least-squares estimator of  reads:

(64)

Note that the two elements of the gain matrix are small if point k is located close to the origin.
This is understandable if one thinks of the point configuration that is needed for a good
determination of a rotation. The rotation about a fixed origin is clearly better determined from
points far away from the origin than from points that are close to it.
3 Recursive least-squares: the time-varying case

3.1 Introduction
In the previous chapter we considered the partitioned model:

(1)

This model formed the basis of our development of a recursive least-squares procedure for the
estimation of the parameter vector x. In this chapter we will generalize the theory of the previous
chapter such that it becomes possible to estimate time-varying parameters in recursive form. This
generalization is of great practical importance, since many geodetic applications exist in which
time-varying parameters need to be determined. In navigation applications for instance, it is often
the position and/or velocity of a moving vehicle, such as a car, ship, aircraft or satellite, that
needs to be determined as function of time.

To start our development of the appropriate model, we will thus assume that the parameter vector

x varies as time proceeds. Hence, instead of assuming x to be constant and thus time-

independent, we assume in this chapter that the parameter vector x is a continuous function of

time t : x(t) . In order to reconstruct the function x(t) from measurements it is furthermore

assumed  that     observables   y    are   available  at  discrete  time  instances        ti, i  0, ,k . These

                                  i

observables are uncorrelated from one time instance to another. The expected values of the

observables  y    are  assumed  to   bear  a  linear  relationship  with  x(t)  at  times  t      ti . This gives:

               i

(2)

It will be clear that the assumptions underlying this discrete like model are not sufficient for
estimating the continuous function x(t). Model (2) enables us at the most the estimation of x(t)
at times ti. Hence, additional information is needed in order to be able to estimate x(t) for all t.
In this chapter we will assume that this information is available in the form of the linear
relationship:

(3)

The n×n matrix (t , t0) in (3) will be called the transition matrix; it describes the transition from
x(t0) to x(t) for all t. The elements of the transition matrix  (t , t0) are assumed to be known
functions of t and t0 . The transition matrix is also assumed to be invertible. This implies that
knowledge of x at any one particular time instant is sufficient for the determination of the
74 Dynamic data processing

complete function x(t). It is admitted that this assumption seems to be a bit unrealistic for most
practical applications. The assumption will therefore be relaxed somewhat in Chapter 5. For the
moment, however, it is assumed that relationship (3) holds true. Model (2) together with the
transition model (3) will constitute our basic model for the present chapter. Note that our
previous model (1) can be interpreted as being a special case of (2) and (3). Because if the
transition matrix is equal to the identity matrix,  (t , t0) I , then x(t) x(t0) for all t, and (2)
reduces to (1). We will start our development of the recursive least-squares estimation algorithms
in Section 3.3 and the sections following. First, however, we will introduce a class of models for
the transition (3) that can be used in a fair amount of applications.

3.2 Equations of motion: a polynomial model

In many geodetic applications it is the position, velocity or acceleration of a moving object that
needs to be determined as function of time. In many applications one also has some fair idea of
the type of movement the object is subject to. For instance, whether the object is stationary or
whether it moves with constant velocity, such as a ship or aircraft at cruising speed, or whether
it moves with constant acceleration, such as an object in free fall in a uniform gravity field. It
is this type of information that we will use in the following to derive an explicit expression for
the transition model (3). Figure 3.1 shows the trajectory of a moving object P. The position of
the object can be described with the coordinates u, v and w. Since the object moves as time
proceeds, the coordinates are functions of time: u(t), v(t) and w(t). The complete time history of
the object's motion is known, once these coordinate functions are known. In the following we
will develop the transition model for the single coordinate function u(t). The development of the
transition model for the other two coordinate functions v(t) and w(t) goes along similar lines. We
will consider the following three cases: stationarity, constant velocity and constant acceleration.

                                     Figure 3.1: Trajectory of object P.
              Recursive least-squares: the time-varying case 75

Stationarity

This case is trivial, but it is included since it illustrates in a straightforward manner the principal
ideas involved. Assuming that the coordinate function u(t) has a continuous time derivative, we
may write:

(4)           .

This expression shows that the coordinate function u(t) is completely described once the initial
position u(t0) and the velocity u(t) are known. Now assume that the object is stationary. Then
u(t) vanishes and (4) reduces simply to:
(5)

This is the transition model for the single coordinate function u(t) in case of stationarity. The
transition model for all three coordinate functions u(t), v(t) and w(t) reads therefore in case of
stationarity as:

(6)

In this case the transition matrix is simply the identity matrix.
Constant velocity
Assuming that the function u(t) has a continuous time derivative, we may write:
(7)

If this expression is substituted into (4) we get:

or
(8)

The double integral in this expression may be written as a single integral if we use integration
by parts. Since:
76 Dynamic data processing

it follows by substituting:
that

or that:
(9)
Substitution of (9) into (8) gives:
(10)
Expressions (7) and (10) combined read therefore in matrix vector form as:

(11)                         .

This expression shows that the coordinate function u(t) and its time derivative u(t) are
completely determined once the initial position u(t0) , the initial velocity u(t0) and acceleration
u¨(t) are known. Now assume that the object moves with constant velocity. Then u¨(t) vanishes
and (11) reduces to:

(12)

This is the transition model for the single coordinate function u(t) in case of constant velocity.
The corresponding transition matrix reads therefore:
                                                                      Recursive least-squares: the time-varying case 77

(13)
Note that this transition matrix is indeed invertible.
Constant acceleration
Assuming that the function u¨(t) has a continuous time derivative, we may write:
(14)
If this expression is substituted into (7) we get for velocity:

or
(15)
Using (9) with u¨() replaced by u() , the double integral of (15) can be replaced by a single
integral, so that:
(16)
If this expression is substituted into (4) we get for position:

or
(17)
The double integral of (17) can be transformed into a single integral as follows. We have:
(18)
Integration by parts gives:
78 Dynamic data processing

(19)
From (17), (18) and (19) it follows then that u(t) can be written as:
(20)
Expression (14), (16) and (20) combined read therefore in matrix vector form as:

(21)                                                        .

This expression shows that position, velocity and acceleration are completely determined once
their initial values and u(t) are known. Now assume that the object moves with constant
acceleration. Then u(t) vanishes and (21) reduces to:

(22)

This is the transition model for the single coordinate function u(t) in case of constant
acceleration. It will be clear by now that the above derivations of the transition model can be
continued along similar lines to include time derivatives of the order higher than the second as
well. From the above results (5), (12) and (22) there are three immediately obvious and very
basic properties of the transition matrix. They are (verify yourself):

(23)                                                     .

These properties will be used repeatedly in the sequel.

Example 25

Consider an object which is being dropped with zero initial velocity from a building of height
h(t0) (see Figure 3.2):
                                                                      Recursive least-squares: the time-varying case 79

                                              Figure 3.2: Free fall.
The gravity field is assumed to be uniform. The acceleration of the object is then constant and
equal to the gravitational acceleration g. Hence, the transition model reads:
(24)
Example 26
A ship is sailing with constant velocity in the u-direction and with constant acceleration in the
v-direction. Then u¨(t) 0 and v (t) 0 . The corresponding transition model reads therefore:

(25)
80 Dynamic data processing

3.3 Prediction, filtering and smoothing

In this section we will make a start with the estimation of time-varying parameters. But before
we proceed, first a few words about the notation used. In order to simplify our notation
somewhat, we will write instead of x(ti) from now on xi . Also the continuous time argument of
the vector function x(t) will be written as an index. Thus instead of x(t) we write xt . And for
the transition matrix we write, instead of (t, t0) , simply t,t . Using this notation we may write

                                                                                                                                                                                                               0

the partitioned model (2) and the transition model (3) of Section 3.1 as:

(26)

and
(27)

Now assume that we want to estimate xt for an arbitrary time t. Then the parameter vectors
xi, i 0, ,k of (26) need to be replaced by xt . This is achieved with the transition model (27).
Inversion of (27) gives: x0 t,01 xt . With the inversion property of the transition matrix (see
(23)), this may be written as: x0 0,t xt . Substitution of this expression into xi i,0 x0 gives
xi i,00,t xt . And with the transition property of the transition matrix, this may in turn be
written as: xi i,t xt . This relation may now be used to replace all the n-vectors xi of (26) such
that only one parameter vector, namely xt , remains:

(28)

This is our basic partitioned linear model for the estimation of time-varying parameters. Note the

striking resemblance in structure between model (28) and model (1) in Section 3.1. The least-

squares  solution    of   model  (28)  will     be  denoted  as  x^    .  The  first  index  refers  to  the  time  to  which

                                                                   t  k

the parameter vector corresponds and the second index indicates that the estimator is based on

all  observables     y,   i     0, ,k . The following three cases, depending on whether t > tk, t

                       i

tk or t < tk, may now be distinguished (see Figure 3.3).

Prediction (t > tk)

One speaks of prediction if t > tk . If tk denotes the present time, that is, the time the last

measurement has been carried out, t > tk implies that the parameter vector is being estimated

for  future  times.  In   this  case  x^    is  the  predicted   estimator     of     xt .

                                        tk
                                                                             Recursive least-squares: the time-varying case 81

                                        Figure 3.3: Prediction, filtering and smoothing.

Let   us   assume       that      we  have    the   estimator          x^    at  our   disposal.     Then,        since    xt     t,kxk , the Best

                                                                         kk

Linear     Unbiased           Estimator  of   xt ,  which     is  the        predicted  estimator          if  t  >  tk ,  reads  in  terms  of  x^

                                                                                                                                                   kk

as:

(29)                                                                                              .

Filtering (t tk)

One speaks of filtering if t tk . In this case the parameter vector xt is estimated for the present

time  tk ,     that     is,  the   time  the  last  measurement,             namely     y,        has  been       carried      out.  The  estimator

                                                                                          k

x^    is  called        the   filtered   estimator  of     xk .  The   filtered        estimator     of    xk  is  the     least-squares   solution

  kk

of model (28) for the case t tk . It reads:

(30)                                                                                                                    .

Smoothing (t < tk)

One speaks of smoothing if t < tk . In this case the parameter vector xt is estimated for past

times from measurements which have been carried out up to and including the present time tk .

In   this   case        x^    is   the   smoothed       estimator            of  xt .  Let    us     assume       that     we  have   the  filtered

                          tk                                                 t,kxk , the Best Linear Unbiased Estimator of xt ,

estimator      x^    k  at    our  disposal.  Then,     since     xt

                 k

which      is  the      smoothed      estimator     if  t  <     tk ,  reads     in    terms  of     x^    as:

                                                                                                       kk
82 Dynamic data processing

(31)                                   .

When comparing (29) and (31), we note that the expression for the predicted and smoothed
estimator, when written in terms of the filtered estimator, are identical in structure. In later
chapters when we generalize our theory so as to include more realistic transition models, we will
see that this will not be the case anymore.

Example 27

Consider a particle that moves with constant velocity along a straight line. Its transition model
reads then:
(32)

The position of the particle is measured at successive time instances t1 , , tk . The position

observables  are  denoted  as  u,   i  1 , , k . They are uncorrelated and all have the same variance

                                 i
2 . The model of observation equations parameterized in terms of position ui and velocity ui

reads then:

(33)

Now assume that we want to estimate ( ut , ut ) for an arbitrary time t. By combining (32) and
(33) we may write the model parameterized in terms of (ut , ut) as:
                                                                      Recursive least-squares: the time-varying case 83

(34)

or as:
(35)

This is the appropriate model in case position and velocity of the particle are unknown. For the
present example we will assume however that the initial position u0 of the particle is known to
be zero: u0 0 . From the transition model (32) it follows then that:
(36)
Substitution of (36) into (35) gives then:
(37)

Note that this model has the same structure as model (27) of Example 20 of Section 2.2. The
least-squares solution of model (37) reads:

(38)
84 Dynamic data processing

Compare this result with (28) in Section 2.2. The variance 2u^t k of u^t k is a continuous function
of time t, but a discrete function of the number of observables k. The result (38) shows that:

(39)

The first inequality tells us that for a fixed number of observables k, the precision of the position

estimator  u^   k   deteriorates     for  increasing          t.  This     is  understandable  if   one     thinks            of  the    geometry

             t

of the straight line (see Figure 2.4 in Section 2.2). Since the line is hinged at the origin, small

changes in its slope will result in changes in its position that are larger for points that are further

away from the hinging point. The second inequality of (39) tells us that for time t fixed, the

precision of the position estimator improves for increasing k. This is of course due to the

additional position information brought in by the increasing number of position observables. In

Figure 3.4 we have plotted the variance u^t k 2 as function of time, for different values of k. The
plot shows that the parabola u^t k 2 increases as function of time (the first inequality of (39)), but
that it gets more flattened if k increases (the second inequality of (39)).

                         Figure 3.4: The parabola u^2 for different values of k.
                                                                                                                          tk

Let us now consider the precision characteristics of the predicted, filtered and smoothed position

estimators. We will first consider prediction and filtering. It is assumed that the present and

future position estimates are computed every time that a new position measurement becomes

available. Let us start at time tk . At this time instant all the position observables ui , i 1 , , k

are  available      and  the  best   (in    the  sense        of      minimal      variance)  position      estimator               u^   k   can  be

                                                                                                                                      k
derived. It has a variance of u^k k 2 . At time tk also the best position estimators for future times
t > tk can be derived. The variance of these predicted estimators is given as u^t k 2 for t > tk . The
variances u^k k 2 and u^t k 2 for t > tk are plotted in Figure 3.5a. Now assume that the next position

measurement is scheduled to be carried out at time tk 1 . The best position estimator for this time

tk  1,  based   on  the  position    observables              u,      i    1 , , k is then given by the predicted position

                                                                i
                                                              u^2 . Once the new measurement at time
estimator  u^   1   k . Its variance is given by                     k 1k                                                         tk  1  has been

             k

carried  out,   it  can  be  used    to  improve         upon      the   predicted   estimate  u^   1   k.  The               position   estimator

                                                                                                 k

for  time  tk   1,  which    is  based    on     all     the  past       position  observables     u,   i                     1 , , k and the new

                                                                                                     i

position   observable    u       1,  reads  u^   1    k  1.   It  is  the  filtered  position  estimator    for               time  tk   1,  and  its

                           k                  k
                                                                              Recursive least-squares: the time-varying case 85

variance is of course smaller than the variance of the predicted position estimator for time tk 1 .
That is, u^2 < u^2 . This is shown in Figure 3.5b.
                 k 1k 1        k 1k

                      Figure 3.5: Variances of the predicted and filtered position estimator.

The whole process of predicting and filtering can now be repeated again. From time tk 1 one can
predict the positions up to the time the next measurement is scheduled to be carried out, say tk 2
(see Figure 3.5c). Once the measurement at time tk 2 is available, it can be used to improve upon
the predicted position. As a result one obtains the filtered position estimate for time tk 2 (see
Figure 3.5d).

Let us now consider smoothing. Again we start at time tk with the filtered position estimator

u^   k.  At  this     time     instant   all  the  position       observables          u,   i     1 , , k are available and based on

  k                                                                                      i

them the best position estimators for all times t < tk can be derived. These are the smoothed

position     estimators        with     variances      u^ ,       t  <  tk .  This  is  shown         in  Figure     3.6a.     At  the  next  time
                                                              tk

instant      tk  1    when     the   new      position  observable            u     1  becomes           available,  the       filtered  position

                                                                                k

estimator        u^   1  k  1  can   be  derived.      Since         additional    information           is  available     in  the  form      of   the

                   k

new      position     observable         u    1,  the  previous         smoothed        position         estimators  u^      ,  t   <   tk ,  can  be

                                           k                                                                           t    k

replaced     by     the     improved     smoothed      position         estimators      u^     k   ,  t  <   tk  1.  This  is  shown     in   Figure

                                                                                          t       1

3.6b. This whole process can be repeated again when at tk 2 the next position observable

becomes available (see Figure 3.6c).
86 Dynamic data processing

                       Figure 3.6: Variances of the smoothed position estimator.

So far in the whole discussion no restrictions were put on the intervals between the times that
the measurements are carried out. These intervals were allowed to vary from one time to another.
This has as a consequence that no statement can be made about the general behaviour of the
variance of the filtered position estimator, u^k k 2 , as function of k. This changes, however, if we
assume that the time instances ti are equidistant in time (= uniform sampling). Then
ti t0 i T , with T constant, and u^t k 2 (see (38)) reads for t t0 l T :

(40)

This  shows  that  in  case  of  uniform  sampling  the  variance  of  the  filtered  position  estimator,  u^ k 2  ,

                                                                                                                    k

decreases as k increases. This is shown in Figure 3.7a. The relationship between the variances

in case of prediction, filtering and smoothing is shown in Figure 3.7b.
                                                          Recursive least-squares: the time-varying case 87

                           Figure 3.7: Variances in case of uniform sampling.

3.4 Recursive prediction and filtering: the A-form

In the previous section the concepts of prediction, filtering and smoothing were introduced. In
this section we will develop the algorithm for recursive prediction and filtering. As was pointed
out in the previous chapter, the essence of recursive estimation is that there is no need to store
past measurements for the purpose of computing present least-squares estimates. Recursion
enables one to keep track of the time process xt by means of an efficient computation of the
corresponding best estimates. Recursive estimation is therefore in particular of great importance
for problems where it is required to estimate time-varying parameters in real-time. The central
idea in our development of the theory of recursive prediction and filtering is to rely on the
stepwise manner in which a partitioned model may be solved. As our starting point we take the
linear model (28) parameterized in terms of xk 1 :

(41)

This model may be solved in two steps. In the first step we consider model (41) with the

exception  of  yk .  Its  solution  is  then  given  by      the  filtered  estimator  x^   1k  1.  The  complete

                                                                                         k

solution of model (41) then follows from solving the following model in a second step:

(42)

The solution of this model would give us             x^   1  k  in terms of the filtered estimator       x^   1k   1.

                                                       k                                                   k

Instead  however,    we   would  like   to  obtain  an    expression  where  the  filtered      estimator  x^   k  is

                                                                                                             k
88 Dynamic data processing

expressed      in    terms  of    x^   1k  1.  We      therefore       first  parameterize      model    (42)  in  terms  of      xk .

                                    k

Replacing xk 1 in (42) by k 1,k xk gives:

(43)

This model may again be solved in two steps. In the first step we consider the partial model:

(44)

Its  solution       would   give   us   the    predicted       estimator      x^    1   in   terms   of  the   filtered  estimator

                                                                                kk

x^   1  k  1.  Note  that,  since  the  transition     matrix       k   1,k   is  square  and   invertible,   the  redundancy     of

  k

the partial model (44) equals zero. The solution of (44) follows therefore simply from inverting

the transition matrix:

(45)                                                                                         .

This result expresses the predicted estimator in terms of the filtered estimator. Both estimators

are  based     on   the  same     set  of  observables         y,   i   0 , , (k 1) . They refer however to different

                                                                 i

time instances, namely tk and tk 1 respectively. The equations of (45) will therefore be called the

time-update equations. Note that the result (45) is in agreement with (29) in Section 3.3. The

complete solution of model (43) follows now from solving in a second step the model:

(46)
Its solution reads:
(47)

Compare        (46)  and    (47)  with     (19)  and   (18).   Result   (47)      expresses     the  filtered  estimator  x^   k  in

                                                                                                                            k

terms      of  the  predicted   estimator      x^   k  1.  It  can  be  written     in  the  more    familiar  form:

                                                 k

(48)                                                                                            .

These are the measurement-update equations. Compare (48) with (20) in Section 2.2 and note
the striking resemblance. But also note that the measurement-update equations of (48) are not
in a recursive form. This in contrast to the measurement-update equations of (20) in Secion 2.2.
For the present time-varying case, it are the time-update equations (45) together with the
measurement-update equations (48) that form a set of recursive equations. A flow diagram of the
                                                                      Recursive least-squares: the time-varying case 89

above derived recursive prediction and filtering algorithm is shown in Table 3.1. Compare Table
3.1 with Table 2.1.

                       Table 3.1: Recursive prediction and filtering: the A-form.
90 Dynamic data processing

3.5 Recursive prediction and filtering: the B-form
The B-form of the recursive prediction and filtering algorithm follows if we write model (46)
in terms of condition-equations:
(49)

Solving this model in the standard way gives for the measurement-update equations:

(50)                                                                                 .

in  which  Qv         is  the  variance  matrix  of  the  predicted  residual  vk :
                   k

(51)

Compare (50) with (35) of Section 2.2. A flow diagram of the B-form of the recursive prediction
and filtering algorithm is shown in Table 3.2. It should be noted that the time-update equations
remain unchanged.

Example 28
We will start with Example 27 in Section 3.3 and consider model (35):

(52)

Batch estimator

We will first consider the batch solution of (52). Note that the structure of model (52) is identical

to that of model (42) of Section 2.2. Hence, the variance matrix of the estimator

x^ ( u^ u^ ) may be readily obtained from the result (49) in Section 2.2. With the
tk         tk tk

definition:

(53)

this gives:
                                          Recursive least-squares: the time-varying case 91

Table 3.2: Recursive prediction and filtering: the B form.
92 Dynamic data processing

This  shows  that  the  variance  of  the  position  estimator  u^   k  reads:

                                                                  t

(55)

Compare this result with (38) in Section 3.3. The following two inequalities hold:
(56)

The first inequality follows directly from (55), as this equation shows that the parabola u^t k 2

attains its minimum of 1 / k at t     tc     .  The  second  inequality  of                         (56)  is,  however,                                                   not   so   obvious
                                          k

when one considers expression (55). Still, it can be shown to hold true and the reason is of

course that the precision of the estimator should improve when more observables are involved.

In Figure 3.8 we have plotted the variance u^t k 2 as function of time, for different values of k. The
plot not only shows that u^2 attains its minimum of 1 / k at t
                                                                                                tk  tc ,   but  also                                                      that  the  parabola
                                                                                                        k

gets more flattened and that its minimum decreases in value, if more observables are involved,

that is, if k increases. Compare Figure 3.8 with Figure 3.4 in Section 3.3.

                        Figure 3.8: The parabola u^2 for different values of k.
                                                                                                                                                                      tk

Recursive prediction and filtering
The time-update of the estimator reads:
                                                                      Recursive least-squares: the time-varying case 93

(57)

For the measurement-update we may either use the A-form of (48) or the B-form of (50). From

a numerical point of view it is more advantageous for the present example to use the B-form.

However, since we already have the variance matrix (54) at our disposal, it is from an analytical

point of view faster to use the A-form. The corresponding gain matrix Kk  Qx^ Ak Qk 1 follows
then with (54) for t tk , Ak (1 0) and Qk 2 as:                                   kk

(58)

The measurement-update of the estimator reads therefore:
(59)

The general precision characteristics of the predicted and filtered position estimator are shown
in Figure 3.9. Compare Figure 3.9 with Figure 3.5.
94 Dynamic data processing

      Figure 3.9: Variances of the predicted and filtered position estimator.

Uniform sampling

Let us now consider the case of uniform sampling. Then ti  t0 i T with T  constant . Using
the identities:

(60)

it can be shown that in case of uniform sampling the variance matrix of (54) reduces to:

Note that as a consequence of uniform sampling the minimum ( 1 (k 1) T , 1 / k) of the parabola
u^t k 2 lies now in the centre of the measurement interval [ t1 T , 2tk kT ] .
The time-update equations read in case of uniform sampling as:
                                                                      Recursive least-squares: the time-varying case 95

(62)

And the corresponding measurement-update equations read:
(63)

Note that the elements of the gain matrix reduce in value if the number of observables k
increases. Also note that the variance of the filtered position estimator:
is a decreasing function of k. This implies that in case of uniform sampling the points
(tk k T , u^k k 2 ) , k 1,2 , lie on a descending graph. The general precision characteristics of the
predicted and filtered position estimator are in this case therefore as shown in Figure 3.10.

               Figure 3.10: Variances of the predicted and filtered position estimator
                                         in case of uniform sampling.
96 Dynamic data processing

Example 29

A satellite orbits the earth (see Figure 3.11). Position measurements are carried out for the

determination of the satellite's position. The position observables  x,   y ,i  1 , , k, are uncorrelated

                                                                       i    i
and all have the same variance 2 . The model of observation equations parameterized in terms

of the polar coordinates ri and i reads:

(64)

                                    Figure 3.11: Earth orbiting satellite.
These observation equations are nonlinear. Linearization of (64) gives:
                                                                      Recursive least-squares: the time-varying case 97

(65)

Note that the redundancy of model (64) equals zero. It is assumed that the satellite orbit is a
circle with unknown radius. It is furthermore assumed that the angular velocity of the satellite,  t
is constant. The transition model of the satellite reads then:
(66)

All three initial values r0 , 0 and  0 are assumed to be unknown. In order to be able to combine
(65) with (66) such that the combined model is parameterized in terms of the increments  rt ,
 t and   t , we first need to formulate the transition model with (  ri ,  i ,   i ) expressed
in terms of (  rt ,  t ,   t) . This relation follows from (66) as:
(67)

Substitution of (67) into (65) gives:

(68)

At this point it is important to make some remarks about the approximate values in (68). Model
(68) consists of only three unknown parameters, namely  rt rt rt0,  t t t0 and
98 Dynamic data processing

 t  t  t0. This implies that all approximate values in (68) are functionally related to the
approximate values of rt , t and  t . Their relation follows from the transition model (66) as:
(69)

Substitution of (69) into (68) gives:

(70)
Note that the redundancy of this model equals 2k-3.
Batch estimator
We will first consider the variance matrix of the batch estimator of (70). It reads:

(71)

The 2x2 sub-matrix in (71) is a familiar one; see for instance (43) in Section 2.3. The variance
matrix Qx^t k follows therefore readily as:
                                                                      Recursive least-squares: the time-varying case 99

(72)

Recursive prediction and filtering

It is now rather straightforward to formulate the time-update and measurements-update equations.

We therefore only give the gain matrix Kk . Since Kk  Qx^ Ak Qk 1 , it follows with (72) for
t tk and                                                      kk

that

(73)

Example 30

A ship sails along a straight line with constant velocity. Azimuth ai and distance measurements
li are carried out at successive time instances ti , i 1, ,k, from a known point with coordinates
u 0, v 0 , see Figure 3.12.
100 Dynamic data processing

                                  Figure 3.12: Positioning of a ship.

The   observables  a     and  l   are  uncorrelated  and  all  have  the  same  variance  2 .  The  model  of

                      i        i

observation equations parameterized in terms of the cartesian coordinates ui , vi reads then:

(74)

These observation equations are nonlinear. Linearization of (74) gives:

(75)

Note that the redundancy of this model equals zero. Let us now consider the transition model.
Since it is assumed that the ship sails with constant velocity in both the u- and v-direction, the
transition model reads:
                                                                    Recursive least-squares: the time-varying case 101

(76)
All four initial values u0 , v0 , u0 and v0 are assumed to be unknown. In order to be able to
combine (75) with (76) such that the combined model is parameterized in terms of the
increments  ut ,  vt ,  u t and  vt , we first need to formulate the transition model with
( ui ,  vi ,  u i ,  vi) expressed in terms of ( ut ,  vt ,  u t ,  vt) . This relation follows from (76)
as:
(77)

Substitution of (77) into (75) gives:

or
102 Dynamic data processing

(78)

This is the basic model on which the recursive prediction and filtering of the ship's position at
time t can be based. Note that the redundancy of model (78) equals 2k-4. It should also be noted
that the approximate values in (78) are functionally related to those of ut , vt , u t and vt as:
(79)
4 State-space models for dynamic systems

4.1 Introduction

In Chapter 3 a start was made with the development of the theory of recursive estimation of
time-varying parameters x(t) . The development was based on a polynomial description of x(t)
which led to the transition model x(t) (t,t0)x(t0) . Many dynamic systems exist, however, that
cannot be described with such a simple linear transition model. In this chapter we will therefore
have a closer look at a larger class of models that describe the time dependent behaviour of x(t) .
The generalization from the simple polynomial model treated in the previous chapter to the
dynamic models of the present chapter, becomes necessary if one wants to include a description
of the forces that cause the time dependency of x(t) . The inclusion of forces in our model
description implies that the reader needs to have some working knowledge of classical mechanics
[Goldstein, 1980]. However, in order for the present book to be sufficiently self contained, we
have included a separate section on the dynamics of motion. In that section the most elementary
concepts of particle mechanics are introduced. The section on the dynamics of motion is
preceded by Section 4.2 in which the kinematics of motion are discussed. Together with the
material of the two Sections 4.2 and 4.3, the dynamic model can be formulated for a sufficiently
large number of cases.

As it turns out these models consist in their most general form usually of nonlinear differential
equations. In Sections 4.3 and following we will present ways of solving these models and show
how their solution can be put into a form that is suitable for estimation purposes. In order to
illustrate the theory we have again included a number of examples that are important from a
geodetic point of view. Many of the examples are concerned with positioning and navigation.

4.2 Equations of motion: kinematics

The quantities required for the kinematic description of the motion of a particle are its position,
velocity and acceleration. The form which the description of these vector quantities takes,
depends on the coordinates in terms of which and the coordinate system with respect to which
it is chosen to describe the motion of the particle. It should be clear that the choice of the
coordinate system is quite arbitrary. In all the examples of the previous chapter the choice was
made to describe motion with respect to a fixed coordinate system. Frequently, however, it is
mathematically more convenient to employ the kinematic description of the motion of a particle
with respect to a moving coordinate system. This is in particular the case when one wants to take
care of the relation that exists between the motion of the particle, the mass of the particle and
the forces acting on the particle. The fundamental laws of mechanics (see Section 4.3) are
namely postulated with respect to an inertial coordinate system, which is a non-accelerating, non-
rotating coordinate system. Hence, if one wants to take these laws into account and at the same
time wants to describe the motion of a particle with respect to a coordinate system fixed for
instance to the rotating and orbiting earth, a proper description of motion requires knowledge of
the relationships that exist between coordinate systems which are in motion with respect to each
other. The objective of this section is therefore to derive the relationships that exist between
104 Dynamic data processing

position, velocity and acceleration of a particle, in coordinate systems which are in motion with
respect to each other.
Position
Consider Figure 4.1. It shows two coordinate systems; the i-system and the b-system. The two
systems or frames differ in their location and orientation. The cartesian coordinates of the origin
0b of the b-frame with respect to the i-frame are denoted as ti 1 and ti 2 . And the cartesian
coordinates of point P when expressed in the i-frame or the b-frame are denoted as
ri 1, ri 2 or rb 1, rb 2 respectively. From the geometry of Figure 4.1 it follows then that:
(1)

This expression shows how the coordinates of point P are related when expressed in the two
different frames i and b. In order to transform the coordinates from the b-frame into the i-frame,
one first needs to rotate the coordinates through an angle  and then add a translation vector to
take care of the difference in origin of the two frames.

                     Figure 4.1: A coordinate transformation in two dimensions.
Expression (1) holds for the two-dimensional case. A similar expression can be derived for the
three-dimensional case. It reads:
(2)

The three angles of rotation ,  and  of the three rotation matrices in (2) are defined in
Figure 4.2. Note that if   0 , then transformation (2) reduces to that of (1) for the first two
coordinates.
          State-space models for dynamic systems 105

                          Figure 4.2: The rotation angles , , and  defined.

Using a self-evident vector and matrix notation, expressions (1) and (2) can be written in the
compact matrix-vector form:

(3)                                                      .

In (3), ri and rb denote the vector of coordinates of point P when expressed in the i- and b-
frame respectively, Rib denotes the rotation matrix from the b-frame to the i-frame, and ti
denotes the translation vector expressed in the i-frame. Equation (3) thus relates the position of

point P as seen by two observers fixed to the i- and b-frame respectively.

Velocity

We will assume that all quantities in (3) may depend on time. Hence, we not only assume that
particle P may move with respect to the b-frame, but also that the b-frame itself may change its
location and orientation with respect to the i-frame as function of time. The relation between the
velocities of the particle as seen by the two observers fixed to the i- and b-frame respectively,
follows then from taking the time-derivative of (3):

(4)

The matrix R 1 ib Rib in (4) has a special significance in its own right. First of all it is easily
demonstrated that this matrix is skew-symmetric:

(5)

This is shown as follows. First recall that Rib is a rotation matrix and that the inverse of a
rotation matrix equals its transpose: Rib1 Rib . Now, if we write Rib1Rib I as RibRib I , and take
the time derivative we get R ibRib RibR ib 0 or (RibRib) RibRib . Replacing Rib by Rib1 in this
last expression proves (5). The matrix R 1 ib Rib will be denoted as bib :
(6)

With this definition, expression (4) may be written as:
106 Dynamic data processing

(7)                                                 .

If the origin of the b-frame is stationary, then ti 0 and vb in ri Ribvb is the velocity of particle

P referenced with respect to the i-frame, but expressed in the b-frame. It depends on rb , the
velocity as seen by the observer fixed to the b-frame, and bibrb , the rate of change in orientation
of the b-frame with respect to the i-frame. Because of the explicit form of the matrix bib , a
coordinate vector bib may be defined through:

(8)

where " × " stands for the vector cross product. The meaning of the indices in bib will now be
clear from (8). The lower index of bib indicates that the entries of matrix bib are expressed in
the b-frame. And the two upper indices of bib indicate that the matrix describes the change in

rotation from the b-frame to the i-frame. With (8), expression (7) may be written in the

alternative form:

(9)                                                    .

The significance of introducing the coordinate vector bib becomes clear if it is assumed that
particle P is fixed to the b -frame and the origins Oi and Ob of the two frames coincide. Then
rb 0 and ti 0 and (9) reduces to:
(10)

Through an application of the transformation rule:
(11)

equation (10) can be written as:
(12)

This result shows that the rate of change of a particle P fixed to a rotating b -frame with fixed

origin, is seen by an observer fixed to the i-frame as an instantaneous rotation about the vector
iib , see Figure 4.3.
              State-space models for dynamic systems 107

                                            Figure 4.3: ri iib × ri .
The vector iib will therefore be referred to as the angular-velocity vector of the b -frame with
respect to the i-frame expressed in the i-frame. The proof of the transformation rule (11) is based
on the definition of a determinant of a 3×3 matrix and its invariance under rotations. We have
for an arbitrary vector xi :

(13)

The second equality follows from the first by the definition of a determinant of a 3×3 matrix.
The third equality follows from the second by taking the rotation matrix Rib outside the brackets.
The fourth equality follows from the third through the invariance of the determinant against
rotations. Finally, the last equality is again a consequence of the definition of a determinant of
a 3×3 matrix. Since (13) holds for any arbitrary vector xi , transformation rule (11) must hold
true. Transformation rule (11) can also be written for the skew-symmetric matrix bib . It reads
(verify yourself):

(14)

Acceleration

The relation between the accelerations as seen by the two observers fixed to the i and b -frame,
respectively, follows from taking the time derivative of (7). Using (6) this gives:

(15)          .
108 Dynamic data processing

With (8), equation (15) can be expressed alternatively as:

(16)                                                        .

If the particle P is fixed to the b -frame (rb 0) and rotates about a fixed axis in space ( bib 0)
such that the origin of the b -frame remains stationary (ti 0) , then all terms, except the first, on
the right-hand side of (15) vanish. The acceleration of the particle P is then directed towards the

axis of rotation, see Figure 4.4.

                                    Figure 4.4: Centripetal acceleration.

The first term on the right-hand side of (15) is therefore called the centripetal acceleration,
meaning towards the centre. The second term on the right-hand side of (15) is sometimes called
the tangential acceleration, since it is tangential to the motion of particle P if the rotation is
about a fixed axis with time-varying angular velocity. The third term is called Coriolis
acceleration, after the French engineer C.G. Coriolis, who discovered it. It comes into play when
particle P is moving with respect to the b-frame. Finally, r¨b is the acceleration of P as
witnessed by an observer fixed to the b-frame and ¨ti is the acceleration of the origin of the b-
frame with respect to the i-frame. An overview of the existing relations between position,
velocity and acceleration is given in Table 4.1.
              State-space models for dynamic systems 109

Position
Velocity

Acceleration

Transformation rule
                            Table 4.1: Position, velocity and acceleration.

Example 31

An observer I fixed to an i-frame monitors the motion of a particle P . Observer I comes to the
conclusion that particle P moves with constant acceleration r¨i(t0) . The equation of motion of
particle P for observer I reads then:

(17)

A second observer E monitors the motion of the same particle P . Observer E is however fixed
to an e -frame which itself is in motion with respect to the i-frame. Our objective is now to
derive the equation of motion of particle P for observer E. The differential equation that governs
the motion of particle P as seen by observer E follows readily from (15) as:

(18)

The solution of this second-order differential equation provides re (t) , the motion of the particle
as seen by observer E. A block diagram of the computation steps involved in solving (18) is
shown in Figure 4.5. It is not altogether obvious from equation (18) alone how the solution re (t)
looks like. But for the present case we do know how the solution looks like in the i-frame. The
solution re(t) of (18) follows therefore if we transform equation (17) into the e -frame. This gives
with:
110 Dynamic data processing

                        Figure 4.5: Block diagram of differential equation (18).
substituted into (17) the result:
(19)
Verify yourself that (19) is indeed the solution to (18). Let us now, in order to be more specific,
consider a concrete example. We assume that the origins of the two frames coincide and that the
e-frame rotates with respect to the i-frame with a constant angular velocity  , see Figure 4.6.
Then ti 0 , and Rie and eie read:
(20)

                                         Figure 4.6: Rotating e -frame.
                                                                            State-space models for dynamic systems 111

Hence, the differential equations (18) take the form:
(21)

Their solution follows from (19) as:

(22)

This is the equation of motion of particle P as seen by observer E. If the e -frame is fixed to the
earth and lies in the equatorial plane with its origin at the earth's centre, then  is the earth's
rotation-rate. If we also assume that the gravitational field is uniform such that u¨(t0) 0 and
v¨(t0) g , then (22) is the equation of motion, for an earth-fixed observer, of an object that has
been dropped from a building at the equator.

4.3 Equations of motion: dynamics

Kinematics, which is the study of the geometry of motion, was discussed in the previous section.
Kinematics is used to relate position, velocity, acceleration and time, without reference to the
cause of motion. Dynamics, on the other hand, is the study of the relation that exists between
the forces acting on a body, the mass of the body, and the motion of the body. Dynamics is used
to predict the motion caused by given forces or to determine the forces required to produce a
given motion. In this section dynamics is discussed. In our presentation however, we will
introduce only a few of the most elementary concepts. In order to gain a thorough introduction
to the subject, the reader should consult [Goldstein, 1980].

Newton's formulation of classical mechanics given in the PRINCIPIA (1687)1 forms the basis
for the study of motion. Newton's three laws of motion can be stated in the following form:

Law I:  Every particle remains in a state of rest or continues to move in a
        straight line with constant velocity unless compelled by external
        forces to change that state.

1 "PHILOSOPHIAE NATURALIS PRINCIPIA MATHEMATICA", i.e. "Mathematical Principles of
     Natural Philosophy".
112 Dynamic data processing

Law II:   The acceleration of a particle is proportional to the resultant force
          acting on it and is in the direction of this force.

Law III:  To every action there is always an equal and contrary reaction; or
          the forces of action and reaction between any two particles are
          equal in magnitude, opposite in direction, and collinear.

The first law, also known as the law of inertia, associates the motion of force with that of
acceleration, and attaches significance to the state of zero acceleration. But before any statement
can be made about the acceleration of a particle, a coordinate system or reference frame is
required, since a particle may have zero acceleration relative to one set of axes, but not to
another (see Section 4.2). The assumption behind the first law is therefore the existence of
reference frames with respect to which every particle has a constant velocity vector when free
from external forces. Such a frame is called inertial. Reference frames that accelerate or rotate
with respect to such a frame are by this definition non-inertial. The axes of an inertial frame,
though not arbitrary are also not unique, for axes moving with constant velocity relative to an
inertial frame also constitute an inertial set. Although Newton's laws postulate the existence of
inertial frames, they do not identify inertial frames and therefore do not explain how to choose
such frames in practice. Here one must appeal to experience to decide what is reasonable. A
particular reference frame can be considered a sufficient approximation to an inertial frame if the
motion predicted by Newton's laws using this reference frame compares satisfactorily with
observational data. A good approximation of an inertial frame of reference, and one from which
Newton derived his concept, is an astronomic coordinate system with its origin in the bary-centre
of the solar system and its axes fixed with respect to the distant galaxies. Thus an earth-fixed
system of reference is by definition non-inertial in the Newtonian sense because the earth is
rotating with respect to the distant galaxies and also has very small but measurable accelerations
relative to an astronomic coordinate system.

Newton's second law, also known as the law of acceleration, is formulated for an inertial frame
of reference. It defines force as being proportional to acceleration. The proportionality constant
is the mass of the particle. Thus for a particle with mass m, subjected to a resultant force Fi the
law may be stated as:
(23)

where both the force Fi and acceleration r¨i are expressed in an inertial frame i. Note that
Newton's first law is a consequence of his second law, since there is no acceleration when the
force is zero, and the particle is either at rest or is moving with constant velocity. Newton's
second law yields three differential equations of second order, which when integrated, give the
trajectory of the particle. However, for the integration to be useful, the forces acting on the
particle need to be known. Therefore, before equation (23) can be used to make predictions, it
is necessary to have further laws or measurement of force available which describe how forces
vary when a particle is subject to the various mechanisms appearing in a given problem. There
exist various forces in nature with their corresponding laws, such as for example contact forces,
nuclear forces, electric and magnetic forces. Another law which is especially of importance for
geodetic work, is Newton's universal law of gravitation. This law says that any two particles are
                                                                            State-space models for dynamic systems 113

attracted to one another by a force that depends directly upon the product of their masses and
inversely on the square of the distance separating them. Thus:

(24)

where Fi is the force of attraction on mass m due to mass M, k is the universal gravitational
constant, ri is the vector separating M and m expressed in the i-frame and directed from m to
M, and ri is the length of ri . Newton arrived at his law of gravitation through a study of the
three laws of planetary motion which were postulated by Kepler on the basis of careful
astronomical observations of the Danish astronomer Tycho Brahe. Law (24), formulated for
particles, forms the basis in the development of a model of the earth's gravitational field.

Newton's third law applies to the interaction of two particles. Note that Newton's universal law
of gravitation (24) satisfies his third law. It should also be noted that Newton's first and second
law define the concept of force in terms of mass times acceleration while Newton's second and
third law define the ratio of masses of two interacting particles as the reciprocal ratio of their
accelerations.

As was pointed out in Section 4.2, quite often the need arises in applications to introduce frames
which are moving with respect to an inertial frame of reference. For instance, the description of
motion of a point with respect to a coordinate system fixed to the earth involves quite naturally
a coordinate system which is at the same time being translated and rotated in space. In order to
see what form Newton's second law takes in a frame, say a b-frame, which is rotating and
accelerating with respect to an inertial i-frame, we write equation (15) as:

Together with Newton's second law (23) this gives:

(25)

where:

Note that (25) has the same form as Newton's original second law (23). The sum  Fb in (25)
is called the sum of apparant forces or inertial forces, and it is a function of the motion of the
selected b-frame with respect to the i-frame. It consists among other forces of the centripetal,
tangential and Coriolis force. Equation (25) is the form of Newton's second law which is usually
needed in practical applications.
114 Dynamic data processing

Example 32
Consider a satellite orbiting planet earth. Both the earth and the satellite are assumed to be point
masses with mass M and m respectively. It is also assumed that the centre of the earth is non-
accelerating. It can therefore be taken as the origin of our inertial i-frame, see Figure 4.7.

                                      Figure 4.7: Earth orbiting satellite.
The satellite is assumed to be subject to two types of forces. The first force equals the
gravitational force and reads:
(26)
The second force is provided by the thrust of the satellite's rockets. It is denoted as Fi2 .
According to Newton's second law we have:

Substitution of (26) and dividing by m, the mass of the satellite, gives:
(27)
where fi Fi2 / m is the so-called specific force of the satellite's thrust. Equation (27) constitutes
a set of three second-order nonlinear differential equations for the satellite's inertial cartesian
coordinates. The nonlinearity is a consequence of the dependence of r on ri . A block diagram
of the computation steps involved in solving (27) is given in Figure 4.8. It shows how the inertial
position vector ri of the satellite, the output of the block diagram, can be computed from the
input fi .
The differential equations of (27) are expressed in inertial cartesian coordinates. We will now
express them in a rotating and therefore non-inertial b-frame. For the sake of simplicity we will
only consider the two-dimensional case. The b-frame is defined in Figure 4.9. In order to express
(27) in the rotating b-frame we need the following result from Section 4.2:
                                                                            State-space models for dynamic systems 115

(28)

                                     Figure 4.8 Block diagram of (27).

          Figure 4.9 Definition of the b-frame.

Since:
(29)

we have:
(30)

substitution of (29) and (30) into (28) gives together with fb Rbi fi , rb (r,0) , ¨ti (0,0) and (27)
the result:

(31)
116 Dynamic data processing

These two nonlinear second-order differential equations govern the motion of the satellite when
expressed in the polar coordinates r and  .
Example 33
A linear mass-spring accelerometer is an instrument designed to measure the inertial result of
translational motion. To analyze the performance of the instrument, consider Figure 4.10. This
is a single-degree-of-freedom accelerometer since it has only one axis along which it is sensitive.
Point C is the centre of mass of the sensitive element with mass m. Point O indicates the
equilibrium position of the centre of mass of the sensitive element when there is no external
force acting on the case along the sensitive axis.

                             Figure 4.10: Linear mass-spring accelerometer.
Point O is fixed to the case. The output indication of the instrument, supplied by displacement-
sensitive transducers, is made proportional to the displacement x of the sensitive element relative
to the case. The sensitive element is supported by a spring which is attached to the case. The
spring is assumed to be weightless and to develop a restoring force proportional to the deflection
of the sensitive element from its equilibrium position. Thus if the spring has a stiffness
coefficient of k > 0 , then by Hooke's law the restoring force is kx . The sensitive element is also
supported by a damper. Dampers are used to provide means of controlling the response of the
instrument to dynamic inputs. The damper develops a viscous friction force cx , where c > 0 is
the damping coefficient.
Before developing the differential equation that governs the dynamics of the linear mass-spring
accelerometer, we first consider what happens to the sensitive element under some different
circumstances. Consider an accelerometer positioned on a flat platform such that its sensitive axis
is parallel to the platform surface. If the platform is held horizontally and at rest, the system will
be in equilibrium with zero indication of the accelerometer (see Figure 4.11a). Now if the case
is tilted over an angle  while the accelerometer remains switched on, it will indicate the
                                                                            State-space models for dynamic systems 117

                                     Figure 4.11: Accelerometer output.
component of gravity gsin , see Figure 4.11b. If the accelerometer is allowed to slide, in the
absence of frictional contact forces, it will experience an acceleration of gsin along the tilted
platform, and indicate zero, see Figure 4.11c. This is due to the fact that the gravitational field
influences simultaneously both the case and the sensitive element of the accelerometer and so
by itself produces no deflection of the sensitive element. That is, the accelerometer does not
measure any component of the acceleration due to the force of gravity unless an equal and
opposite force is acting on its case. With friction the indication of the sliding accelerometer will
be proportional to the friction force only. Now, if the accelerometer is placed on the platform
so that its sensitive axis is vertical, mass attraction is acting along the sensitive axis of the
accelerometer and pulls the sensitive element toward the platform until it is balanced by spring
tension at which point the accelerometer indicates the value of gravity g, see Figure 4.11d. This
output signal is, however, indistinguishable from the output of the same accelerometer when it
is accelerated horizontally at a rate of g meters per seconds squared, see Figure 4.11e. The
important conclusion is thus reached that an accelerometer cannot distinguish between inertial
acceleration and gravitational acceleration. Hence, the effects of any component of gravity acting
118 Dynamic data processing

along the accelerometer sensitive axis must be allowed for, if it is required to deduce the
trajectory of the case.

To obtain the differential equation which governs the dynamic behaviour of the accelerometer,
we apply Newton's second law to the sensitive element by equating all the forces acting on the
element along the sensitive axis (spring force, friction force and gravity) to the product of its
mass m and its acceleration relative to inertial space along the sensitive axis. Assuming that the
x-axis is vertical and pointing upwards this gives:

Substitution of r x t , where t is the position of point O on the case relative to inertial space,
and dividing by m, gives:
(32)

This equation shows that by measuring the displacement x and solving for the differential
equation, the accelerometer determines the combination of the gravitational field intensity and
the acceleration of the case relative to inertial space along the sensitive axis: g ¨t . Thus once g
is known, ¨t is known and a double integration of ¨t enables us to compute the position t of the
moving case. It is this principle which is used in inertial navigation.

4.4 State vector description of dynamic systems

In Section 4.3 we have seen how the appropriate equations of motion could be derived from
Newton's laws of mechanics. Because of the nature of Newton's second law, these equations of
motion consist of a set of scalar second-order differential equations. For the purpose of
estimation it is, however, more convenient to transform these scalar second-order differential
equations into a first-order vector form. The following two examples show how this can be done.

Example 34

According to (32) the differential equation representing a linear mass-spring system reads:
(33)

To put this scalar second-order differential equation into a first-order vector form, we define two
variables x1 , and x2 as:

(34)

Then
                                            State-space models for dynamic systems 119

(35)
and substitution of (34) into (33) yields:
(36)

The two equations (35) and (36) can be arranged to give the first-order vector form:
(37)

Thus with (34) we have transformed the scalar second-order differential equation (33) into the
first-order vector form (37). The vector (x1, x2)* is called state vector.

Example 35

According to (27) the equations of motion of an earth orbiting satellite expressed in inertial
coordinates read:

(38)

To put these second-order differential equations into a first-order vector form, we define a 6-
vector x as:
(39)

With this definition, the three second-order differential equations of (38) can be put into the
following first-order vector form:

(40)
120 Dynamic data processing

The device used in the above examples of transforming scalar differential equations involving
second-order derivatives to first-order vector equations is an important one. This procedure is
easily generalized to allow one to express an nth-order scalar differential equation by n first-order
differential equations. Higher order scalar equations such as:
(41)

where u (n)(t) d nu (t)/ dt n can be put in a first-order vector form by letting xi(t) u (i 1)(t), i 1, ,n ,
to get:

(42)

Clearly, this idea can be extended to simultaneous higher-order equations as well. The general
form of a first-order vector differential equation is given by:
(43)
This equation will be referred to as the state equation. It is in a form which is general enough
to describe the characteristics of many dynamic systems. The time-varying n-vector x(t) will be
referred to as the state vector of the system and the time-varying l-vector z(t) indicates the input
to the system. A block diagram of the state equation (43) is given in Figure 4.12.

                                      Figure 4.12: State equation (43).
It is implicit from the above representation that given the value of the state vector x(t) at any
time t t0 , and given the time history of the input z() over an interval of time t0    t , the
solution of the state equation will yield x(t) . The state equations can be classified according to
whether the vector function f is nonlinear or not, and whether it explicity depends on time or not.
If the function f is nonlinear, one speaks of a nonlinear system. Equation (40) for example
constitutes a nonlinear system. If the function f is linear and one or more parameters of the
system vary with time, the system is called a linear, time-varying system. In this case the system
equation takes the form:
(44)
                                                                            State-space models for dynamic systems 121

where F(t) and G(t) are time-varying matrices of appropriate dimensions. A matrix block
diagram of a linear, time-varying system is given in Figure 4.13.

      Figure 4.13: Matrix block diagram of (44).

If the system matrices F and G of (44) are constant, i.e. independent of time, the system is
called a linear, time-invariant system:

(45)  .

Equation (37) for example constitutes a linear, time-invariant system.

For many systems the choice of the state vector follows naturally from the physical structure of
the dynamic system. Similarly, the state equation usually follows directly from the physical laws
that govern the system. For instance, in mechanical systems the state variables often correspond
to position and velocity, and the inputs represent the action of several external forces. The
precise nature of the differential equations is then deduced primarily through Newton's equations
of motion. The following examples serve to demonstrate how a system may be placed in a state
vector frame work. It should be pointed out, however, that the choice of the state variables is not
unique. One may always transform a state vector x(t) via a non-singular transformation into a
new state vector x /(t) . The system of equations will then transform accordingly. It is clear that
the transformed representation is completely equivalent to the original representation, since one
can always reconstruct the behaviour of the dynamic system in terms of the original state by
using the inverse transformation from x /(t) to x(t) . This shows that the choice of the state can
be adapted to suit various purposes.

Example 36

A mass m, considered a pointmass, is suspended from a massless rod of length l, as shown in
Figure 4.14. The rod is connected to a rigid support at Q by means of a frictionless pinned
arrangement. We shall assume the mass constrained so as to move in a plane. Consequently, only
a single coordinate  is required to describe completely the position of the point mass C at any
time. There are two forces acting: the force of gravity Fi1 pulling the point mass C toward the
centre of the earth and the rod tension Fi2 pulling the point mass toward the pin at Q. The force
122 Dynamic data processing

of gravity will be assumed to be constant in magnitude and direction. A component of gravity
serves as a restoring force, acting to return the point mass C to its lowest position at  0 .

                                Figure 4.14: The mathematical pendulum.
According to Newton's second law we have:
(46)
with ri the position of the point mass in the i-frame. Substitution of ri (lsin, lcos) ,
Fi1 (0, mg) and Fi2 ( F 2sin, F 2cos) into (46) gives, since l is constant:

By eliminating the rod tension F 2 , the equation of motion for the mathematical pendulum
follows as:
(47)
To put this equation into a state vector form, we define a two-dimensional state vector as
x ( , ) . The state vector form for (47) follows then as:
(48)
This is a zero-input nonlinear state equation.
            State-space models for dynamic systems 123

Example 37

Figure 4.15 shows the meridian plane of a spherical non-rotating earth with radius R. A vehicle
(car, ship, or airplane) is at time t located at position r , . A b-frame is attached to the vehicle.
The vehicle is equipped with two single-degree-of-freedom accelerometers and one gyroscope.
The sensitive axes of the two accelerometers are aligned with the b1 and b2 axis , respectively.
They sense the resultant of acceleration along these two axes. The gyroscope senses the angular
velocity of the b-frame with respect to the inertial i-frame.

               Figure 4.15: Spherical non-rotating earth with vehicle at position r ,  .

As we have seen in Example 33 of Section 4.3, accelerometers are not capable of separating
vehicle acceleration r¨i from gravitational acceleration gi . The sensed output of the
accelerometers, denoted by fi when expressed in the i-frame, is therefore equal to the difference
of r¨i and gi or:
(49)

A single integration of this equation gives the vehicle's velocity in the i-frame as:

(50)

And a second integration gives the vehicle's position in the i-frame as:

(51)

Thus positioning and navigation of the vehicle is possible once fi , gi , the initial position ri(t0)
and initial velocity ri(t0) are known. A model for the gravitational acceleration gi is available
if we assume that the earth can be considered to be a point mass with mass M. Then, according
to Newton's universal law of gravitation:
124 Dynamic data processing

(52)

In order to obtain fi , we need to transform the sensed output of the accelerometers, fb , to the
inertial frame:
(53)
with

This shows that the angle  is needed for the transformation. Here is where the need of a
gyroscope shows up. The gyroscope is capable of sensing the angular velocity of the b-frame
with respect to the i-frame. If the output sensed by the gyroscope is denoted as ib , then:
(54)
Integration of (54) gives  , which when substituted into (53) enables us to compute fi from the
accelerometer output fb . Summarizing, the appropriate set of differential equations for the
equations of motion of the vehicle in inertial coordinates reads:
(55)

The computations involved in solving (55) are shown in the block diagram of Figure 4.16. In
order to put (55) into a first-order state vector form, we define the state vector x as x =
(r1,r2,r1,r2,) . Then from (55) it follows that:

(56)

This is a nonlinear state-equation with input f1 , f2 and ib .
                                                                            State-space models for dynamic systems 125

                     Figure 4.16: Block diagram of an inertial navigation system.
Example 38
In Example 32 the equations of motion of a satellite were expressed in the polar coordinates
r and  (see (31) of Section 4.3). Assuming that the satellite orbit lies in the earth's equatorial
plane, we will now express the satellite's equations of motion in terms of the geographic
coordinates r (radius) and  (longitude). This implies that we have to introduce an earth-fixed
e-frame and take the constant angular velocity  of the earth into account. The earth-fixed e-
frame is defined in Figure 4.17a. Figure 4.17b shows the b-frame relative to the e-frame. The
rotation matrices that relate the three frames, i, e and b, are given as:

                                   Figure 4.17: The earth-fixed e-frame.
From this it follows that:
(57)
A comparison of (57) with (29) shows that obviously   t . Hence the equations of motion
of the satellite in terms of the geographic coordinates r and  , follow readily from (31) of
Section 4.3 as:
126 Dynamic data processing

(58)

In order to put these equations into a first-order state vector form, we define the state vector
x as x (r , ,r, ) . It follows then from (58) that:

(59)

This is a nonlinear state equation with input f1 and f2 .

4.5. Linearization of a nonlinear state equation
The main concern in the remaining sections of this chapter is to obtain solutions, analytical if
possible, to the state equations of dynamic systems. For a nonlinear system, unfortunately, one
cannot in general obtain an analytical closed-form formula which specifies x(t) explicitly in
terms of the initial state x(t0) and the input z(t) . This implies that the nonlinear state equation:
(60)

has to be integrated numerically. For an overview of existing numerical integration techniques
the reader is referred to e.g. [Stoer and Bulirsch, 1980].
If a solution of (60) is available (possibly after numerical integration) for an approximate initial
state x 0(t0) and an approximate input z 0(t) , the actual solution of (60), x(t) , corresponding with
the actual initial state x(t0) and actual input z(t) , can often be approximated to a sufficient degree
by solving the linearized version of (60). In order to see how the linearized version of (60) can
be derived, it is assumed that a solution x 0(t) of the nonlinear state equation (60) is known for
a given initial state x 0(t0) and input z 0(t) . Then:
(61)

The actual state x(t) and actual input z(t) can be written in terms of the approximate state x 0(t)
and approximate input z 0(t) as:

(62)

Substitution of (62) into (60) gives:
                                                                            State-space models for dynamic systems 127

If it is assumed that the vector function f is sufficiently smooth, a Taylor series expansion of
f about x 0(t) and z 0(t) gives:
(63)

Here x f(x 0(t) , z 0(t) , t) is the matrix of partial derivatives of f with respect to x evaluated at
x 0(t) and z 0(t) . Thus x f is a matrix the ( , ) th element of which is:

where f is the  th component of f and x is the  th component of x. The matrix z f is
similarly defined. From (61) and (63) it follows, after neglecting the higher order terms in (63),

that:

(64)  .

This is the linearized version of (60). Note that (64) represents a linear, time-varying system,

with the state vector x(t) , the input vector z(t) and the system matrices xf (x 0 (t) , z 0(t) , t) and
z f (x 0(t) , z 0(t) , t) . Whether one is allowed to neglect the higher order terms in (63) depends on
the smallness of x(t) and z(t) in relation to the nonlinearity of the vector function f. The

following examples serve to demonstrate the linearization process.

Example 39
We will again consider the mathematical pendulum of Example 36. According to (48) of Section
4.4, its nonlinear state equation reads:
(65)

It is assumed that the angular displacement (t) and angular velocity (t) of the pendulum
remain small. A reasonable approximation to (t) and (t) is then:
(66)

Linearization of (65) about the approximate state (66) gives:
128 Dynamic data processing

(67)
This is a linear, time-invariant state equation with zero input. It describes the small angle
behaviour of the mathematical pendulum.
Example 40
The nonlinear state equation for a satellite orbiting the earth in the equatorial plane reads in
geographic coordinates r and  (see (59) of Section 4.4):

(68)
Linearization of this nonlinear state equation gives:

(69)

This is a linear, time-varying state equation. Now assume that the satellite orbits the earth such
that to a first approximation:
(70)
Then
(71)
                                                                            State-space models for dynamic systems 129

The with (70) and (71) corresponding input f10 and f20 reads then according to (68) as:
(72)
Substitution of (70), (71) and (72) into (69) gives:
(73)

This is a linear, time-invariant state equation. Thus if it is assumed that to a first approximation
no radial displacement takes place and that the time rate of change of longitude is constant, the
time-varying state equation (69) reduces to the time-invariant state equation (73).
Example 41
Consider the nonlinear state equation (56) of Section 4.4. It is expressed in terms of the inertial
coordinates r1 and r2 . Since we assume the earth to be non-rotating in the present example, we
may use r1 rcos  and r2 rsin to transform the state equation (56) such that it is expressed
in the geographic coordinates r (radius) and  (latitude). This gives:

(74)

where we have used the abbreviations c  and s  for cos ( ) and sin ( ) , respectively.
Linearization of the nonlinear state equation (74) gives:
130 Dynamic data processing

(75)

This is a linear, time-varying system. Now assume that the motion of the vehicle is such that:
(76)
Then
(77)
If we also assume that the orientation of the b-frame is such that to a first approximation:
(78)
then
(79)
With (76), (77), (78) and (79), the linear, time-varying state equation (75) reduces to the
following linear, time-invariant state equation:
                                                                            State-space models for dynamic systems 131

(80)
As was pointed out earlier, the choice of the state variables is not unique. One may always
transform one state vector x(t) via a non-singular transformation into a new state vector x /(t) .
The state equations will then transform accordingly. In order to demonstrate this for the present
example, we define new state variables as:

(81)

In terms of these new state variables, the state equation (80) reads:

(82)

Note that   is the misalignment angle between the b1 -axis of the b-frame and the local
zenith (see Figure 4.15 of Section 4.4). By rearranging the order of the state variables such that
the vertical and horizontal coordinates are separated, the state equation (82) may also be written
as:
132 Dynamic data processing

(83)
This shows that the coupling between the vertical and horizontal coordinates is provided by the
term 2 0 . The vertical and horizontal coordinates are decoupled if one assumes that the vehicle
is approximately stationary, that is, if  0 0 . Now assume that the vehicle moves along the
spherical surface of the earth (this is of course a stronger assumption then only r 0(t) constant ).
Then r(t) R constant and the first two equations of (83) vanish. As a result we get the state
equation:

(84)

Integration of this state equation gives the horizontal position and velocity of the vehicle as
function of time. Note, since f1 is absent, that in this case only one single-degree-of-freedom
accelerometer is needed.

4.6 Linear time-varying state equations
In this section the solution and the properties of an n-dimensional linear, time-varying system
represented by the state equation:
(85)
will be examined. First, attention is turned to the homogeneous part of the state equation which
is obtained by setting the input z(t) to zero: z(t) 0 . The homogeneous equation is studied first
because its solution provides the solution for the general state equation (85). In other words, the
solution to the homogeneous state equation is the difficult problem. As a start two distinct
questions about the homogeneous equation x(t) F(t)x(t) require attention:
(i) Given an initial state vector x(t0) at a time t0 , does there exist a solution that passes

          through x(t0) at time t0 ?
(ii) If there exists a solution passing through x(t0) at time t0 , is it unique?
                                                                            State-space models for dynamic systems 133

The following theorem states the condition under which a unique solution to the homogeneous
equation can be shown to exist.

Theorem 1

If F(t) is a matrix the elements of which are continuous functions of time in the interval
t0  t  t1 then there exists a solution of x(t) F(t)x(t) which is defined in the interval t0  t  t1 and
takes on the value of x(t0) at t t0 . Moreover, this solution is unique.

For a proof of this theorem the reader is referred to [Decarlo, 1989]. With the above existence
and uniqueness theorem one can now show that the set of solutions of the homogeneous equation
constitutes a linear vector space of a dimension equal to that of the underlying state space.

Theorem 2

Let F(t) be an n×n matrix the elements of which are continuous functions of time t. Then the
set of solutions of the homogeneous state equation:

(86)

forms an n-dimensional linear vector space.

Proof

It is clear from Theorem 1 that the set of solutions of (86) is not empty. It is also clear by
linearity of the time derivative and by linearity of matrix F(t) , that the set of solutions is closed
under linear combinations. The set of solutions constitutes therefore a linear vector space. To
determine the dimension of this vector space, it will first be shown that if the columns of the
n×n matrix X(t) satisfying the matrix initial value problem:

(87)

are linearly independent at time t0 , they are linear independent for all times t. Suppose that some
linear combination of the columns of matrix X(t) is the zero function so that X(t)a 0 for all t .
Evaluation at t0 yields X(t0)a 0 . Hence, a 0 if the columns of matrix X(t0) are linearly
independent. But this implies, since X(t)a 0 for all t , that the columns of matrix X (t) are
linearly independent for all t . The conclusion reads thus that if an n×n matrix X(t) is
nonsingular for some time t0 and satisfies the homogeneous equation X(t) F(t)X(t) , it is
nonsingular for all t . Any n×n matrix X(t) which satisfies X(t) F(t)X(t) and also has linearly
independent columns at time t0 is called a fundamental matrix of (86). Thus the columns of a
fundamental matrix form a basis of n for all times t. To show that the columns of a
fundamental matrix span the set of solutions of (86), let x(t) be any solution of (86). Since
x(t0) n and the columns of X(t0) are linearly independent, a vector b n exists such that
x(t0) X(t0)b . Now consider x /(t) X(t)b . It is a linear combination of solutions of (86) and thus
itself a solution of (86). Its value at t0 is x(t0) . By uniqueness it follows then that x /(t) x(t) .
Hence, any solution of the homogeneous equation (86) can be written as a linear combination
134 Dynamic data processing

of the n linearly independent columns of a fundamental matrix. This proves that the dimension
of the linear vector space of solutions of (86) equals n.

                                                                                                     End of proof.

The concept of a fundamental matrix can be used to formulate the solution of the homogeneous
equation in terms of it. Let X(t) be any fundamental matrix of (86). Since X(t) satisfies (87) and
is nonsingular for any t0 , the matrix  (t , t0) defined by:
(88)
exists and satisfies:

(89)

and
(90)
for all t0 . This special fundamental matrix  (t,t0) is called the state transition matrix of (86).
Since the ith column of  (t,t0) is a solution of the initial value problem x(t) F(t)x(t),
x(t0) (0 0 1 0 0) with the "1" at the i-th position, the state transition matrix (t,t0) satisfies
the matrix differential equation (88) and reduces to the identity matrix at t t0 , one has the
following result:

Theorem 3

The unique solution of:
(91)
can be represented as:
(92)
where  (t,t0) is the unique matrix satisfying:
(93)

Proof

Differentiating x(t)  (t,t0)x0 yields:

And evaluation at t0 yields:

                              End of proof.
                                                                            State-space models for dynamic systems 135

Equation (92) reveals the reason that  (t,t0) is called the state transition matrix. It describes the
zero-input motion of the state vector x(t) of a linear, time-varying system and represents the
linear transformation which maps the initial state x(t0) at time t0 into the state at time t. The
following theorem summarizes two important properties of the state transition matrix.

Theorem 4

(i) transition property:

(ii) inversion property:  .

Proof

If X(t) is any fundamental matrix of x(t) F(t)x(t) then:

which is (i). Using (i) and letting t2 t0 :                              End of proof.
whence (ii) follows.

The transition and inversion properties are illustrated in Figure 4.18.

                  Figure 4.18: Two dimensional state space illustration of the
                                    transition and inversion property of  (t,t0) .

Having discussed the linear homogeneous equation in some detail, the machinery is now
available to represent the solution x(t) of the complete state equation (85) for some non-zero
input z(t) .

Theorem 5

If F(t) is continuous, and  (t,t0) is the state transition matrix for x(t) F(t)x(t) and G(t) and z(t)
are piecewise continuous for all t, then the unique solution of the state equation:
136 Dynamic data processing

(94)

is given by:

(95)                                          .

Proof
Let X(t) be a fundamental matrix of x(t) F(t)x(t) . From integrating:

follows:

Premultiplication with X(t) gives, with  (t,t0) X (t)X (t0) 1 , the desired result. Note that
uniqueness of (95) is not a problem. For if x1(t) and x2(t) are two solutions of equation (94)
satisfying the same initial condition, then x1(t) x2(t) F(t) (x1(t) x2(t)) with x1(t0) x2(t0) 0 , and
thus x1 (t) x2 (t) for all t by Theorem 1.

                                                                                                     End of proof.

Equation (95) expresses the state vector x (t) in terms of the state transition matrix  (t,t0) . In
general, it may be exceedingly difficult, or impossible, to find a closed form solution for the state
transition matrix. This implies that in most cases one must resort to numerical integration
techniques.

4.7 Linear time-invariant state equations

If the system matrices F and G in (85) of Section 4.6 are constant matrices, the linear system
is time-invariant and the state equation becomes:

(96)                                       .

The state transition matrix  (t,t0) of a linear, time-invariant system satisfies the matrix initial
value problem:
                                                                            State-space models for dynamic systems 137

(97)

In the previous section, matrix F was time dependent and no analytical expression for the
solution of (97) could be derived. Note, however, that if F is time-independent one can obtain
an explicit form of the state transition matrix. To see this, first consider the scalar version of
(97):

The solution of this scalar first order differential equation is clearly:

where the exponential function is defined as the infinite series:
(98)

This series expansion motivates to define the exponential of a square matrix by an infinite series
identical in form to (98). Thus the matrix exponential for any square matrix F shall be defined
as:

(99) .

It can be shown that the infinite series of (99) is absolutely and uniformly convergent for all
values of t. Consequently, the series can be differentiated and integrated term by term.
Differentiating (99) term by term gives:

But this shows that the unique solution of (97) is given by:

(100)  .

Hence, the following theorem has been proven:

Theorem 6

The unique solution of the linear, time-invariant state equation:
(101)
is given by:
138 Dynamic data processing

(102)                        .

Some important properties of the exponential of a square matrix are given in the next theorem.
Theorem 7
For any constant square matrix F, the matrix exponential e Ft satisfies:

The proof of the theorem is omitted since all above properties follow easily from the infinite
series definition (99) of the matrix exponential. Note that there is a strong analogy between the
matrix exponential and scalar exponential, although in some cases it breaks down slightly.

4.8 Evaluation of the matrix exponential

When the exponential of a matrix must be found, such as in the solution of a linear time-
invariant system, a number of numerical calculation methods for evaluating the matrix
exponential are available. In this section two methods will be discussed: the Taylor-series method
and the Jordan canonical form method.

4.8.1 The Taylor-series method

One straightforward way to evaluate the matrix exponential is to use the infinite series by which
the matrix exponential is defined. This method simply approximates e Ft by evaluating only the
first, say n, terms in the series expansion. In other words, one uses the approximation:
                                                                            State-space models for dynamic systems 139

(103)

The larger the n and the smaller the time interval t , the better the approximation. For larger
time intervals t , the transition property may be used:
(104)

The Taylor-series method may also be used for approximating the state transition matrix of a
linear time-varying system if the time interval t t0 is much less then the time required for
significant changes in the system matrix F(t) . Thus in effect one uses the constant F
approximation to replace the time-varying system  (t,t0) F(t)(t,t0) by the time-invariant
system  (t,t0) F (t0) (t,t0) . The Taylor-series method is quite useful for numerical work since
the repeated multiplication and addition are easily programmed and performed. The method also
makes for flexible programming since it does not require major changes when the dimension of
the state vector is changed. In general, the Taylor-series method is not preferred as an analytical
approach. Only for small dimensions or simple structures of the system matrix F, the method
may be used to write down the transition matrix explicity in terms of elementary functions. The
following three examples illustrate this analytical approach.

Example 42
                                                                                                  ...

Consider a particle that moves with constant acceleration in the u-direction. Then u 0 . The state
equation reads therefore:

(105)

This is a linear, time-invariant system with the system matrix:

(106)

From this it follows that:

(107)

Substitution of (106) and (107) into:
140 Dynamic data processing

gives for the transition matrix:
(108)

Compare this result with (22) of Section 3.2.
Example 43
From (67) of Section 4.5 it follows that the system matrix of the linearized state equation of the
mathematical pendulum reads:
(109)
The powers of F needed for the infinite series of the matrix exponential are:

Multipying by the appropriate powers of t and the factorials and summing the elements results
in:

Inspection of the terms in the above series reveals that:
(110)
The solution of the linear, time-invariant homogeneous state equation (67) of Section 4.5 reads
therefore:
(111)
                                      State-space models for dynamic systems 141

Example 44

The system matrix of the linearized state equation (84) of Section 4.5 reads:

(112)

The powers of the system matrix are:

Hence, the series expansion of the matrix exponential becomes:

Inspection of the terms in the above series reveals that:
(113)
The solution of the linear, time-invariant state equation (84) of Section 4.5 reads therefore:

(114)
Note that if we take the limit  0 , the first two equations of (114) reduce to:
142 Dynamic data processing

(115)

Compare this result with (11) of Section 3.2.

4.8.2 The Jordan canonical form method
This second method for computing the matrix exponential is based on the idea that the matrix
exponential of a diagonal matrix is very easy to compute. For a diagonal matrix  ,  = diag.
(1, ,n) , the following equality holds:
(116)

It also holds, see Theorem 7 of Section 4.7, that for any invertible constant matrix T:

Hence, if one could determine an invertible matrix T such that:
(117)
the matrix exponential of F could be computed as:
(118)

Unfortunately not all square nxn matrices F can be diagonalized. Square matrices can be
diagonalized, however, if they have n linearly independent eigenvectors ti, i 1, ,n . This can be
seen as follows. From the n relations:

where i are the eigenvalues of F, it follows that:
(119)
where

Then, since T is assumed to have n linearly independent columns, it has rank n and is thus
invertible. Premultiplication of both sides of (119) with the inverse T 1 yields the desired result
(117). Equation (118) is a valuable computational form for finding the matrix exponential e Ft .
It also clearly shows that the eigenvalues of F to a considerable extent determine the dynamic
behaviour of the linear, time-invariant system. A form of (118) which shows this even more
                                                                            State-space models for dynamic systems 143

clearly follows by expressing (118) explicitly in terms of the column vectors ti, i 1, ,n, of T
and row vectors ui , i 1, ,n, of T 1 . Using:

in (118), gives the dyadic sum:
(120)

This shows that the response of a system is a composition of motions along the eigenvectors of
the system matrix F. A particular eigenvalue is excited if the initial state or input vector lies
along the corresponding eigenvector. The following two examples illustrate the calculation of the
matrix exponential using (118) with (116).
Example 45
From the state equation (37) of Section 4.4 the system matrix of a linear mass-spring
accelerometer follows as:
(121)

The characteristic polynomial of F is given by:

This gives the two eigenvalues:
(122)
For the present example it will be assumed that 2 > 2 . Then, since  is positive, both
eigenvalues are negative. The eigenvectors are obtained by solving for i 1,2 :

Ordering the eigenvectors by columns, the matrix T is obtained as:
(123)
Its inverse reads:
144 Dynamic data processing

(124)
With (123) and (124), application of (118) with (116) gives:
(125)
The solution of the linear, time-invariant state equation (37) of Section 4.4 reads therefore:
(126)
where

Example 46
Consider again the system matrix F of (112) of Section 4.8.1:
(127)
The characteristic polynomical of F reads:

which results in the three eigenvalues:
(128)
The matrix of eigenvectors T and its inverse are given by:

(129)

With (128) and (129), application of (118) with (116) gives:
                                                                            State-space models for dynamic systems 145

or

(130)

where use was made of e it cost isint . Compare (130) with (113) of Section 4.8.1

It was already pointed out that not all square matrices can be diagonalized. For instance the
system matrix of Example 45 cannot be diagonalized if 2 2 . This more complicated case is
solved by transforming the systems matrix into an almost diagonal form so that the matrix
exponential of this form is still easy to compute. This almost diagonal form is called the Jordan
canonical form.
Theorem 8
Let F be any nxn matrix. Then it is always possible to find a nonsingular matrix T which can
be partitioned as:
such that:
where

The block matrix Ji has dimension mi×mi, i 1, ,k and the partitioning of T matches that of J.
The number k of blocks Ji equals the number of linearly independent eigenvectors of F. The
block matrices Ji can be subpartitioned as:

where each subblock Jij is of the form :
146 Dynamic data processing

The number li of subblocks Jij equals the number of linearly independent eigenvectors that
correspond with eigenvalue i . Matrix J is called the Jordan canonical form of F and matrix Jij
is called a Jordan block. For a proof of this theorem the reader is referred to [Noble, 1969]. The
columns of matrix T can be computed as follows. From F T T J and the form of J it follows
that:
(131)
where i is either 0 or 1 , depending on J, and where  is an eigenvalue of F. The number i
is zero whenever the corresponding column vector ti corresponds with the first column of a
Jordan block. In this case ti is an eigenvector of F. Once this column vector is found the
remaining column vectors of T corresponding with the remaining columns of the Jordan block
can be found from (131) with i 1 . These remaining column vectors ti are known as
generalized eigenvectors of F. After having computed the Jordan form J of F and the
transformation matrix T and its inverse T 1 , the matrix exponential of F can be computed as
shown in the next theorem.
Theorem 9
Let:

where J is the Jordan canonical form of F. Then:
(i)
(ii)
(iii)

(iv)

                where p is the dimension of Jij .
                                         State-space models for dynamic systems 147

Proof
Only (iv) will be proven. With:

of dimension p, it follows that:

where k 0 if k < p 1 .

               p1

This gives with           , the result:

from which (iv) follows.

                                         End of proof.
148 Dynamic data processing

It is seen from this theorem that if the matrix F cannot be diagonalized, the matrix exponential
of Ft contains besides the purely exponential terms of the form e it also terms of the form
te it, t 2e it and so on. The dyadic sum of the matrix exponential of Ft will in this case therefore
also contain the additional terms te it, etc. Let the matrices T and T 1 be partitioned so that their
blocks Tij and Uij respectively correspond with the Jordan blocks Jij . Then, according to the
above theorem one may write:

To show explicitly the dependence on the terms e it and powers of t, one can take the
exponential e it out of e Jijt and write:

(132)

where i is the sum of the dimensions of the li -number of matrices Jij and the matrices Pij
follow from the ordering per power of t. Expression (132) reduces to that of (120) of Section
4.8.2 if matrix F can be diagonalized. The following two examples illustrate the use of the
Jordan canonical form.

Example 47

Consider a particle that moves with constant velocity in the u-direction. Then u¨  0 . The state
equation reads therefore:

(133)

This is a linear, time-invariant system with the system matrix:
(134)

This matrix has two identical eigenvalues: 1,2 0 . The number of linearly independent
eigenvectors that correspond with this eigenvalue equals 1. This eigenvector reads:

Using (131) the corresponding generalized eigenvector t2 follows from:
as:
                                                                            State-space models for dynamic systems 149

Hence, the transformation matrix T and its inverse T 1 read as:

The Jordan canonical form of (134) reads therefore:

with  0 . The matrix exponential of F t follows with Theorem 9 then as:

Hence, the solution of the state equation (133) reads:

Compare this result with (12) of Section 3.2
Example 48
In Example 45 it was assumed that 2 > 2 . This is known as the overdamped case. Now we will
consider the critically damped case. This corresponds to the assumption that 2 2 . The
eigenvalues of the system matrix:

are then:
One eigenvector of F is easily found from ( F  I2)t1 0 as:

Since the rank of the 2 × 2 matrix (F  I2) is one, there is only one linearly independent
eigenvector which corresponds with the eigenvalue  . The vector t2 must therefore be a
generalized eigenvector of F. This vector is found from (F  I2)t2 t1 as:
150 Dynamic data processing

The matrix T and its inverse T 1 become therefore:

With the Jordan canonical form of F given as:

the matrix exponential of Ft follows as:
(135)

The solution of the linear, time-invariant state equation (37) of Section 4.4 reads therefore for
the critically damped case as:
(136)

where :

4.9 Summary
In this chapter we introduced a class of models that enable us to describe the dynamic behaviour
of a sufficient number of dynamic systems. In its most general form the dynamic model consists
of a nonlinear first-order vector differential equation. An analytical closed form solution of it is
generally not available. Linearization of the nonlinear system leads however to a linear, time-
varying system of which the structure of the solution is known. The actual solution of this linear
system is known once the state transition matrix is known. In most cases numerical integration
is needed in order to find the state transition matrix. However if the linear system can be shown
to be time-invariant, then an explicit formula for the state transition matrix is available. It is the
matrix exponential of the constant system matrix. The chapter was concluded with a discussion
of two methods for evaluating the matrix exponential. Table 4.2 gives an overview of the
different types of state equations.
                                                     State-space models for dynamic systems 151

                       Nonlinear state equation
           Solution found through numerical integration

                       Linearized state equation
            This is a linear, time-varying state equation

                 Linear time-varying state equation
                         Solution is of the form:

State transition matrix is found through numerical integration of

               Linear time-invariant state equation
                                 Solution is

            Table 4.2: Different types of state equations.
5 Random functions

5.1 Introduction

In the previous chapter we developed the concept of a state-space model for time-varying
parameters x(t) . The approach taken in the precious chapter was a purely deterministic one;
no considerations of randomness were given. In practice however, it often happens that it
does not suffice to base a study of the characteristics of a dynamic system solely on a
deterministic description of the system. Often the inputs of the system are influenced by
disturbances which are difficult or even impossible to describe deterministically. If a
deterministic description of the input fails, it is fortunately often still possible to consider, to
a sufficient degree of approximation, the disturbances as random. For instance, the
acceleration imported to a vehicle when it travels over a road can be considered to be
influenced by random disturbances, the statistical nature of which depends on the quality of
the road. Also the forces acting upon a ship may sometimes be considered as random. And of
course also the inherent uncertainty in measurements of for instance the system's input may
be considered as random. In order to be able to include randomness in the description of
dynamic systems, this chapter is concerned with some of the elementary concepts in the
theory of random functions. Random functions are sometimes also called random processes or
stochastic processes. As we will see, random functions are generalizations of random
variables, and therefore much of the probability theory of random variables can be applied to
random functions [Breiman, 1969, Papoulis, 1985, Peebles, 1987].

This chapter is organized as follows. In Section 5.2 we briefly discuss some of the statistical
characteristics of random functions. For the purposes of this book the most important
characteristics of random functions are their first two moments: the mean and variance. In
Section 5.3 we present the extremely important propagation laws for the mean and variance
of the output of dynamic systems. These laws generalize in a natural way the well-known
propagation laws of random vectors. Section 5.4 deals with a special type of random function,
namely the white noise random function. In Section 5.5 it is shown how the propagation laws
of Section 5.3 simplify if the random inputs of the dynamic system consist of white noise.
Finally, in the last section, Section 5.6, we introduce the random polynomial equations of
motion.

5.2 The mean and covariance of random functions

The consideration of random variables which are functions of time, leads us to the study of
random functions. A random function x(t) may be thought of as a family, or collection, of
functions of time t, x i(t), i 1,2, , any one of which might be observed on any trial of an
experiment1. The functions x i(t), i 1,2, , are called sample functions of the random
function x(t) . An interpretative picture of a random function x(t) in terms of its sample
functions x i(t), i 1,2,3 is illustrated in Figure 5.1.

     1 The parameter t will normally be interpreted as time, although this is not necessary.
154 Dynamic data processing

       Figure 5.1: Three sample functions x 1(t), x 2(t) , x 3(t) of the random function x(t) .
For time t fixed, say t t1, x(t1) takes on repeated trials of the experiment different sample
values at random. Thus x(t1) is a random variable, and the probability that x(t1) takes values
in a certain range is given by the probability distribution function. In this case the
dependence on time is shown explicitly in the notation of the probability distribution
function:
(1)
The corresponding probability density function is given as:
(2)
By letting time t1 vary in (1) and (2), we have in fact specified the first-order probability
distribution function and the first-order probability density function of the random function
x(t) . For another fixed time instant, say t2 , x(t2) , is again a random variable. The probability
of occurrence of a pair of sample values of x(t1) and x(t2) in certain ranges is then given by
the joint probability distribution function:
(3)
The corresponding joint probability density function is given as:
                                                                                                           Random functions 155

(4)

By letting t1 and t2 vary in (3) and (4) we have specified the second-order probability
distribution function and second-order probability density function of the random function
x (t) . Following this pattern, analogous definitions can be given for the higher-order
distribution and density functions of x(t) . As with random variables, we can define the mean
and variance of a random function x (t) . The mean of a random function x(t) is defined as:
(5)

Note that the mean of x(t) is, in general, a deterministic function of t. We shall say that a
random function is mean value stationary if the mean is not a function of time t. The auto-
covariance of a random function x(t) is defined as:

(6)

The auto-variance is, in general, a function of times t1 and t2 . We therefore speak of the
auto-covariance function of x(t) . The following short-hand notation will be used for the auto-
covariance function:
(7)

Thus for t1 and t2t1 fixed, xx(t1,t2) is the covariance between the two random variables
x(t1) and x(t2) . And for t2 t1 fixed, xx(t1,t1) is the variance of the random variable x(t1) .
We shall say that a random function x(t) is covariance stationary, if the auto-covariance
function xx(t1,t2) is only dependent on the time difference t2 t1 . Thus if x(t) is covariance
stationary, then xx(t,t ) only depends on  and not on t . If xx(t,t ) is independent of t,
we will write instead of xx(t,t ) simply xx() . Note that in this case, xx(0) is the variance
of the random variable x(t) for all t .

The cross-covariance between two random functions x(t) and y(t) is defined as:

(8)

Also the cross-covariance is, in general, a function of times t1 and t2 . We speak therefore of
the cross-covariance function between x(t) and y(t) . The following short-hand notation will
be used for the cross-covariance function:
156 Dynamic data processing

(9)

The above given definitions hold for scalar-valued random functions. The definitions can
however be generalized quite naturally to the case of vector-valued random functions. If x (t)
is a random vector function, the scalar auto-covariance of (7) generalizes to the auto-
covariance matrix:
(10)

Thus for t1 and t2 t1 fixed, Qxx(t1,t2) is the covariance matrix of the two random vectors
x(t1) and x(t2) . Note that the diagonal entries of the matrix Qxx(t1,t2) consist of auto-
covariance functions, whereas the off-diagonal entries of this matrix consist of cross-
covariance functions. Also note that:
(11)

Thus the matrix Qxx(t1,t2) is square, but not symmetric. The matrix is only symmetric if
t1 t2 . In this case, Qxx(t,t) is the variance matrix of x(t) . The random vector function x(t) is
said to be covariance stationary if Qxx(t1,t2) only depends on the time difference t2 t1 . If
x(t) is covariance stationary, we will write instead of Qxx(t,t ) simply Qxx() . The auto-
covariance of covariance stationary random functions has the following properties:

(12)

Proof

ad a)

         This implies that the auto-covariance function of a covariance stationary scalar
         random function is an even function of  :

ad b)

       Let x(t) be a scalar random function and define u(t) as u(t) x(t ) x(t) .

       Application of the propagation law of variances and covariances gives:

       0  uu(t,t) xx(t ,t ) xx(t ,t) xx(t,t ) xx(t,t). Since xx(t ,t ) xx(t,t)
       xx(0) and xx(t ,t) xx (t,t ) xx(), we get 0  uu (t,t) 2 (xx(0) xx ())

         or:
(13)

       Now define v (t) as v (t) x (t ) x(t) . Then we find in a similar way as
       above that 0  vv (t,t) 2 (xx(0) xx()) , or:
                                                                                                           Random functions 157

(14)

         From (13) and (14) the result (12b) follows.

Let x (t) and y (t) be two random vector functions. The scalar cross-covariance of (9)
generalizes then to the cross-covariance matrix:
(15)

The cross-covariance of two covariance stationary random functions has the following
properties:

(16)

Proof  Define the random vector function w(t) in terms of the scalar
ad a)  random functions x(t) and y(t) as w(t) (x(t),y(t )) . The
       variance matrix Qww(t,t) of w(t) follows then as:
ad b)

                  Because of the covariance stationarity of x(t) and y(t) , the
                  entries of the matrix Qww(t,t) are independent of t :
(17)

                  Matrix Qww(t,t) is a variance matrix, and therefore always
                  positive semi-definite. Its determinant is therefore always non-
                  negative. From the non-negativeness of the determinant of (17)
                  it follows then:

And this proves (16b). It should be noted that (16) reduces to (12) if y(t) x(t). To conclude
this section, some typical examples of auto-covariance functions are given in Table 5.1. Many
of these auto-covariance functions will be seen to reappear in the remaining part of this book.
158 Dynamic data processing

    2

        0                      The constant covariance function
                               The linear covariance function
    t2
                               The triangular covariance function
-t      0     

    qt

-t      0       

    1

-t      0  t    

                               The exponential covariance function

                             

                                                   The damped exponential covariance func-
                                                   tion

                        

                                          The band limited covariance function

                  Table 5.1: Auto-covariance functions.
                                                                                                           Random functions 159

Example 49
Let x(t) be an n×1 random vector function with auto-covariance matrix Qxx(t,) . And let the
m×1 random vector function y(t) be defined as:
(18)

where A is a constant m×n matrix and a is a constant m×1 vector. We are asked to derive
the auto-covariance matrix of y(t) and the cross-covariance matrix between y(t) and x(t) .
With (18), the auto-covariance matrix of y(t) follows as:

or as:
(19)

In a similar way the cross-covariance matrix between y(t) and x(t) follows as:

or as:
(20)

Example 50

Let   x (t)  and  x (t)  be  two  scalar  random  functions  with  auto-covariance  functions:

        1           2

(21)

Their cross-covariance function x x (t,) is assumed to be identically zero. Hence, the two
                                                                                                                           12

random functions are uncorrelated. A scalar random function y(t) is defined as the difference

of x1 (t) and x2(t) :
(22)

We are asked to derive the auto-covariance function yy() , and the cross-covariance

functions yx () and yx () . In order to do so, we first write (22) in matrix-vector form as:
             1               2
160 Dynamic data processing

With
(24)

application of (19) to (23) gives:
(25)
In a similar way it follows from applying (20) to (23), with (24), that:
(26)

Example 51
Let x(t) be a random function with auto-covariance function:
(27)
We are asked to derive the variances and covariances of the three random variables
x(ti), with ti t0 (i 1)/2 for i 1,2,3 . In order to obtain the required variances and
covariances, we first define a 3×1 random vector y as:
(28)
The variance matrix Qyy of y reads then:

(29)
                                                                                       Random functions 161

With ti t0 (i 1)/2 and (27) this gives:

The required variances and covariances of x (ti), i 1,2,3 are given by the entries of Qyy.
Example 52

Two    scalar  random     functions  x (t)  and   x (t)  are  defined  as:

                                       1            2

(31)

where a and b are random variables with the following variances and covariance:
(32)

We are asked to derive the auto-covariance functions and cross-covariance function of

x (t)  and  x2 (t) .  In  order  to  solve  this  problem,    we  first     define  a  random  vector  function

  1
x (t) as x (t)  (x (t), x (t))       and write (31) in matrix-vector form as:
                      1   2

(33)

Substitution of (33) into:

gives:

And with (32) this gives:
or
162 Dynamic data processing

(34)
Hence, the required covariance functions follow as:
(35)

Note  that  both  random  functions  x (t)  and  x (t)  are  covariance  stationary.

                                       1           2

5.3 Propagation laws for linear systems: the general case

In this section we will show how to compute the mean, the cross-covariance and the auto-
covariance of the output of a linear, time-varying system:
(36)

when the initial state is a random vector and the input is a random function. According to
Theorem 5 of Section 4.6 the solution of the state equation (36) reads:

(37)

It will be clear that when the initial state is a random vector, x(t0) , and the input is a random
function, z(t) , the output of the linear system becomes a random function:

(38)                                                                     .
                                                                                                           Random functions 163

5.3.1 The mean of the output x(t)

A formal derivation of the mean of x(t) will now be given.2 From taking the expectation of
(38) it follows that:

The propagation law for the mean of the output of a linear system reads therefore:

(39)  .

This shows that the mean of x(t) is a solution of the differential equation:

2 Derivatives and integrals of random functions are again random functions. As in the case of
     deterministic time functions, these derivative and integral operators are defined in terms of
     limits. However, since we wish to ensure convergence of the associated limits for the entire
     family of sample functions that contains the random function, the definitions of derivatives and
     integrals of random functions may differ from those of ordinary deterministic time functions.
     There is no difference if the associated limits exist for every sample function of the random
     function. But there is a difference if the ordinary limits of some of the sample functions fail to
     exist. This may for instance be due to the fact that some of the sample functions fail to be
     continuous. If the ordinary limits fail to exist for the entire family of sample functions, one can
     define the limits in an alternative, less stringent, way. These alternative definitions include
     convergence in probability, convergence with probability one and mean-square convergence,
     see e.g. [Stark and Woods, 1986]. If the ordinary limits do not exist for the entire family of
     sample functions, it is usually sufficient for most practical applications, to assume that the
     limits exist in the mean-square sense. And it can be shown that the same propagation laws, as
     derived in this section, follow if the derivatives and integrals are to be interpreted in the mean-
     square sense. For more details the reader is referred to e.g. [Melsa and Sage, 1973].
164 Dynamic data processing

5.3.2 The cross-covariance between the output x(t) and input z(t)
A formal derivation of the cross-covariance matrix Qxz (t1 , t2) of the output x (t) and the input
z (t) will now be given. With the definitions:
(40)

the difference of (38) and (39) may be written as:
(41)
Substitution of (41) into:

gives:

The propagation law for the cross-covariance between the output x(t) and the input z (t) reads
therefore:

(42)  .

Example 53
A random function x(t) is defined as the integral of the random function z(t) :
(43)
                                                   Random functions 165

The auto-covariance function of z(t) is given as:
(44)

We are asked to derive the cross-covariance function xz (t1, t2) . According to (42) the cross-
covariance function xz (t1, t2) between x(t) and z(t) of (43) satisfies:

(45)

Since z(t) is covariance stationary, we have:
(46)
Substitution of (46) into (45) gives:

(47)

If we apply the change of variable 1 t2  , the integral (47) becomes:

(48)

Substitution of (44) into (48) gives then after integration, for the required cross-covariance
funtion:
(49)

It is of interest to compare this result, with the result one would get in the discrete case. The
discrete counterpart of the integral (43) is given by the sum:
(50)

Note that (44) implies that both the variance of z(t) , as well as the covariance between
z(t) and z() equal the constant 2 for all t, . For the discrete case this would mean that:

(51)

Application of the propagation law of covariances to (50) gives therefore with (51) for l  k :
166 Dynamic data processing

(52)

The same result follows for l  k . Compare the discrete result (52) with its continuous
counterpart (49).
Example 54
Consider again equation (43). Now however, it is assumed that the auto-covariance function
of z(t) is of exponential form:
(53)
Substitution of (53) into (48) gives:
(54)

In order to solve this integral we need to distinguish between two cases:
The case t0  t1  t2
In this case (54) becomes:

Hence:
(55)
The case t0  t2  t1
In this case t2 t0  0 , but t2 t1  0 . We therefore write (54) as the sum of two integrals:

Integration gives:
                                                                                                           Random functions 167

or
(56)
From (55) and (56) the required cross-covariance function follows as:

(57)

Let us now investigate what happens when the limit 0 of (57) is taken. Since (53)
reduces to the constant 2 for 0 , we expect the limit 0 of (57) to be identical to (49)
of the previous example. In order to verify this, we make use of the expansion:
(58)
With (58), we may write (57) as:

(59)

By taking the limit 0 of (59) we get:
(60)
And this is indeed identical to (49).
Example 55
The random function x(t) is defined in terms of the random function z(t) as:
(61)
The auto-covariance function of z(t) is assumed to be a damped exponential:
168 Dynamic data processing

(62)
We are asked to derive the cross-covariance function between x(t) and z(t) . According to
(42) the cross-covariance function between x(t) and z(t) of (61) satisfies:
(63)
With the change of variable 1 t2  this integral may also be written as:
(64)
Substitution of (62) into (64) gives:
(65)

In order to solve this integral we need to distinguish between two cases:
The case t0  t1  t2
In this case (65) may be written as:
(66)
Using
(67)
and

(68)

we get for (66):
                                                                                                           Random functions 169

(69)
The case t0  t2  t1
In this case (65) may be written as:
(70)
Again using (67) and (68), we get for (70):

(71)

Thus the required cross-covariance function is given by (69) and (71).
Let us now investigate what happens to the cross-covariance function if we take the limit
0 , or the limit 0 , or both these limits. It follows from (69) and (71) that:
(72)

This is the cross-covariance function one would get when the auto-covariance function of the
input z(t) is of exponential form (verify this yourself). If we take the limit 0 , it follows
from (69) and (71) that:
(73)
170 Dynamic data processing

This is the cross-covariance function one would get when the auto-covariance of the input
z (t) is of cosine form (verify this yourself). Finally, if we take the limit 0 of (73), it
follows that:
(74)

This is the cross-covariance function one would get when the auto-covariance function of the
input z(t) equals a constant (verify this yourself).

5.3.3 The auto-covariance of the output x(t)
A formal derivation of the auto-covariance matrix Qxx (t1,t2) of the output x(t) will now be
given. Substitution of (41) into:

gives:
                                                                                                           Random functions 171

The propagation law for the auto-covariance of the output x(t) follows therefore as:

(75)        .

This result shows that the auto-covariance matrix of x(t) is composed of four terms. The first
term depends on the variance matrix Qxx (t0,t0) of the initial state vector x(t0) . The second and
third term are dependent on the cross-covariance matrix Qxz (t0,t) Qzx (t,t0) . These two terms
are absent if the input z(t) is uncorrelated with the initial state vector x(t0) . And the fourth
term is dependent on the auto-covariance matrix Qzz (t1,t2) of the input vector z(t) . It happens
that in many practical applications x(t0) is uncorrelated with z(t) . Then:

and (75) simplifies to:

(76)     .

Note that a double integration is needed for the computation of Qxx(t1,t2) . However, if the
cross-covariance matrix Qzx(t1,t2) is known, one can do with just a single integration. It
follows namely with (42) that (76) may be expressed in terms of Qzx(t1,t2) Qxz(t2,t1) as:

(77)  .
172 Dynamic data processing

Example 56
The random function x(t) is defined as the integral of z(t) :
(78)
The auto-covariance function of z(t) is assumed to be a constant:
(79)

We are asked to derive the auto-covariance function of x(t) . According to (76) the auto-
covariance function of x(t) satisfies:
(80)

Since z(t) is covariance stationary we have:
(81)

Substitution of (81) into (80) gives with the change of variable 1 2  :
(82)
Substitution of (79) into (82) gives then:

or
(83)

Note that the variance of x(t) , xx (t,t) 2 (t t0)2 , increases quadratically with time t,
whereas the covariance between x (t) and x (t ), xx (t,t ) 2 (t t0)2 2 (t t0) ,
increases linearly with  . A plot of the auto-covariance function (83) is shown in Figure 5.2
for 2 1 and t0 0 .
                                                                                                           Random functions 173

Figure 5.2: The auto-covariance function xx (t1,t2) 2 (t1 t0) (t2 t0), with 2 1 and t0 0.
Instead of using (76) for the derivation of (83), we could also have used (77). According to
(77), the auto-covariance function of x(t) satisfies:
(84)
Since the cross-covariance function xz (t1,t2) has already been derived in Example 53, we
may use also (49) in Section 5.4.3. Substitution of (49) into (84) gives then after integration
indeed (83).
Example 57
The random function x (t) is defined as the average of z(t) :
(85)
The auto-covariance function of z(t) is given as:
(86)
The auto-covariance function of the output x(t) follows then with (76) as:
(87)

Hence, the variance of x(t) is constant and independent of t:
(88)
At first sight it may seem strange that the variance of the average x(t) is constant. Would we
not expect that the variance of x(t) decreases for increasing t? This is at least what we
encountered so many times in the discrete case. See for instance equation (25) in Section 2.2.
In order to understand this difference, we consider the discrete counterpart of (85):
174 Dynamic data processing

(89)

Let   us  assume  that  the  variances  and  covariances  of  z   are  given  as:

                                                               i

(90)

where ij is the Kronecker symbol, which is defined as:

(91)

If we apply the propagation law for variances and covariances to (89) we get with (90) and
(91):

or
(92)

This  result  indeed    shows  that  the  variance  of  the  average   x    decreases  as  k  increases.  How

                                                                         k

does this result then compare with (88)? The answer lies in our assumptions about the

variances and covariances of zi . Equation (90) is namely not the discrete counterpart of (86).
With (90) we have z z 0 for ij , whereas with (86) we have zz (t1,t2) 2  0 for t1 t2 .

                                                                                 ij

The correct discrete counterpart of (86) is therefore:

(93)

If we now apply the propagation law of variances and covariances to (89) we get with (93):
                                                      Random functions 175

or
(94)

And this result indeed corresponds with (87). A random function z(t) having as auto-
covariance function the constant (86), is called a random constant. This terminology is best
explained if we look at the discrete case. We define a (k k0)×1 vector z as:
(95)
Its variance matrix reads according to (93) as:

(96)

Note that the rank of this matrix equals 1. Hence, there exist a (k k0 1) -number of linearly
independent functions of z that have a zero-variance. Since:

if

the vector w B z has a zero variance matrix and is therefore constant. This shows that the

successive  differences  of  the  z   are  constant:

                                   i
176 Dynamic data processing

Hence:

which  shows  that  the  random  characteristics  of  the  z    are  constant  for  all  i.

                                                             i

Example 58

Let x(t) be defined as:

(97)

The auto-covariance function of z(t) is assumed to be of exponential form:
(98)

According to (76), the auto-covariance function of x(t) satisfies:

(99)

This gives with the change of variable 2 1  :

(100)

Since xx (t1,t2) xx(t2,t1) we only need to consider the case t0  t1  t2 . For this case (100)
may be written as:

Performing the integration between brackets gives:
or
                                                                                                           Random functions 177

And a second integration gives:
or
(101)
The result that corresponds to the case that t0  t2  t1 follows from interchanging t1 and t2 in
(101). The auto-covariance function of x(t) reads therefore:

(102)

Let us now investigate what happens to the auto-covariance function if the limit 0 is
taken. Using:
we may expand (102) as:
(103)
This shows that:
(104)
Compare this result with (83).
Example 59
Let x(t) be defined as the average of z(t) :
(105)
The auto-covariance function of z(t) is assumed to be of the following exponential form:
178 Dynamic data processing

(106)

The auto-covariance function of the average x(t) follows then from multiplying (102) with
1  / ((t1 t0) (t2 t0)). This gives:

 2

(107)

If we take the limit  of (107) we get:

(108)

This result is the continuous counterpart of (92) in Section 5.3.3. It seems therefore natural to
believe that (106) is the continuous counterpart of (90) in Section 5.3.3 for the case that
 . Note however, that although the limit (108) exists, the corresponding limit of zz()
of (106) does not exist. It follows therefore that (108) should be seen as an approximation to
the auto-covariance function of the average x(t) , for the case the input z(t) has (106) as auto-
covariance function with large, but finite, value of . The auto-covariance function (106) is
plotted in Figure 5.3 for some different values of . This figure shows that the covariance
between z(t) and z (t ) decreases as x decreases. And for  large enough one may consider
the covariance between z(t) and z(t ) as practically absent. This shows that in practical
applications, one may use (106) with large, but finite,  as an approximation to the auto-
covariance function of a random function for which z(t) and z(t ), 0, are uncorrelated.
We will have more to say about uncorrelated random functions in the next section.
                                                                                                           Random functions 179

            Figure 5.3: The auto-covariance function zz() 1 2e  

                                                                                                                              2

                                   for increasing values of .
Example 60
Let x(t) be defined as the moving average of z(t) :
(109)
The auto-covariance function of z(t) is of exponential form:
(110)
Then

This gives with the change of variable 1 2  :
(111)
We now need to distinguish between the case t2 t1  T and the case t2 t1  T :
The case t2 t1  T
If t2  t1 , then 2 t1  0 for 2  [t2 T,t1], 2 t1  0 for 2  [t1,t2] and 2 t1 T  0 for
2  [t2 T,t2] . We therefore write (111) as the sum of two double integrals:
180 Dynamic data processing

This may be written as:

Solving for the inner integrals gives:

or

And a second integration gives:

or finally
(112)
The case t2 t1  T
If t2  t1 , then 2 t1  0 and 2 t1 T  0 for 2  [t2 T,t2] . We may therefore write (111)
as:
Solving for the inner integral gives:
                                 Random functions 181

And a second integration gives:
(113)

Both the equations (112) and (113) hold for t2  t1 . The corresponding result for t1  t2
follows, since xx (t1,t2) xx (t2,t1) , from interchanging t1 and t2 in the right-hand sides of
(112) and (113). The auto-covariance function of the moving average x(t) follows therefore,

with  t2 t1 as:

(114)
Let us now investigate what happens to the auto-covariance function (114) if the limit 0
is taken. Using the expansion:

it follows from (114) that:
(115)
This agrees with the auto-covariance function of the average, as derived in equation (87) in
Section 5.3.3. In a similar way it follows from (114) that:

(116)

This shows that if the auto-covariance function of the input z(t) is given by
zz () 1 2e   , the auto-covariance function of the moving average x(t) approaches, as

                 2

 goes to infinity, the triangular function (116), see Figure 5.4.

Figure 5.4: The triangular auto-covariance function (116).
182 Dynamic data processing

Example 61
Consider a particle that moves along a straight line. It is assumed that the acceleration of the
particle is measured continuously with an accelerometer. The initial position and initial
velocity of the particle are assumed known and zero. The position x(t) of the particle follows
then from the observed acceleration x¨(t) as (see e.g. equation (11) in Section 3.2):
(117)
The auto-covariance function of the observed acceleration is assumed to be given as:
(118)
We are asked to compute the variance xx(t,t) of the position x(t) . From (117) and (118) it
follows with (76) that:

This may be written, with the change of variable 1 2  , as:

or as:
(119)

Integration of the inner integrals between brackets gives:

(120)

Substitution of (120) into (119) gives:
                                                                                        Random functions 183

After integration, the variance function of position x(t) follows as:
(121)
If we substitute the expansion:

into (121) and rearrange terms we get:
(122)

This shows that:

(123)

This would be the variance of position, if the acceleration is treated as a random constant,
having as its auto-covariance function the constant x¨x¨ () 2 . It also follows from (121)
that:

(124)

This would for large, but finite,  approximate the variance of position, if the continuously
observed accelerations have the auto-covariance function x¨x¨ () 1  2 e   .

                                                                                                                                            2

5.4 White noise

Up to this point we have been dealing with random functions z(t) of which the auto-

covariance functions zz (t,t ) satisfy for any t zz (t,t )  0 if   0 . That is, we have so
far considered only random functions z(t) of which the random variables of any pair

z(t1), z(t2) are correlated for t1  t2 . The interesting question now arises as to how to define a
random function z (t) of which the random variables of any pair z(t1), z(t2) are uncorrelated
for t1  t2 . Such a random function will be called a white noise random function. By drawing

the parallel with the discrete case, one is tempted to define a white noise random function as

one for which the auto-covariance function satisfies zz (t,t ) 0 for   0 and zz (t,t )  0
otherwise. However, as it turns out, no such random function exists, except in a highly

degenerate sense. To gain some insight into this rather surprising result, let us start with a

brief  review   of  the  discrete  case.  A  random    variable   x    is  defined  in  terms  of  a    sequence  of

                      z,     1,2, , as:                             k

random     variables   i  i

(125)

The    ai  are  non-random   constants.      For  the  variances  and      covariances  of  the    z    we  assume

                                                                                                     i

that:
184 Dynamic data processing

(126)
The symbol ij denotes the Kronecker symbol. It is defined as:
(127)

Thus   it  is  assumed  that  the  sequence  z    consists  of  uncorrelated  random  variables.  If  we

                                               i

apply the propagation law of variances and covariances to (125) we get:

(128)

With (126) this gives:
(129)

and with property (127) of the Kronecker symbol, equation (129) reduces to:
(130)

with min. [k,l] defined as:
(131)

Note that the above derivation shows that it is the property of uncorrelatedness of z i , that
makes the double sum (128) transform into the single sum (130). Let us now consider the
continuous case. The continuous counterpart of the sum (125) is given by the integral:

(132)

The function a(t) is non-random. Equation (126) suggests to define the auto-covariance
function of an uncorrelated random function z(t) as:

(133)

Application of the propagation law (76) to (132) gives:
                                                                                   Random functions 185

(134)

This result is the continuous counterpart of the discrete result (128). We may therefore expect

to find the continuous counterpart of (130) when (133) is substituted into (134). However, if

we substitute (133) into (134), we find that the double integral equals zero! This is because

the function (133) vanishes everywhere except along the line  0 . Hence, the volume of

zz (1,2) is zero. Thus we find, that although (133) seems to be the continuous counterpart
of (126), the double integral (134), being zero for this case, does not correspond with the

non-zero sum (130). It therefore follows that (133) is not the way to define an uncorrelated

random function. Another approach needs therefore be taken. We have seen above in the

discrete case that it is the property of uncorrelatedness that enables us to write the double

sum (128) as a single sum (130). This shows that instead of defining uncorrelatedness in

terms of the zero covariances of the input z i , we may also define uncorrelatedness in terms

of  the  variances  and  covariances    of   the  output  xk.  That  is,  we  may  define   the  sequence     z    to

                                                                                                                i

be  uncorrelated    if  the  variances  and  covariances  of   the  output    x    satisfy  the  single  sum  (130).

                                                                                k

Let us now try to generalize this approach to the continuous case. A random function is then

said to be uncorrelated if the auto-covariance of the output of (132) satisfies:

(135)

This integral is the continuous counterpart of the sum (130). The question now arises what
type of auto-covariance function of the input z(t) will make the auto-covariance function of
the output look like (135). The answer is that the auto-covariance function of an uncorrelated
random function z(t) must be a scaled version of the so-called Dirac delta function or
impulse function. That is, the required auto-covariance function of an uncorrelated random
function z(t) is given by:

(136)                                                                     .

where (t) is the Dirac delta function or impulse function. The impulse function (t) is
defined by its property that it isolates or reproduces the function value f (t) of any function
f () , which is continuous at t, according to the following integral formula:

(137)                                                                .

Let us now verify that we indeed get (135) when (136) is substituted into (134). Substitution
of (136) into (134) gives with the change of variable 1 2  :
186 Dynamic data processing

(138)

if t1  t2 , then 2 t1  0 and 2 t0  0 for 2  [t0,t2] . The inner integral of (138) may then be
considered as a special case of (137). Indeed, defining:

(139)

we obtain with (137):

(140)

Substitution of (140) into (138) gives:

(141)

which is indeed identical to (135) for t2  t1 . The corresponding result for the case t1  t2
follows by replacing t2 in the right-hand side of (141) by t1 . Hence, we have shown that
(134) reduces to (135), if the auto-covariance function of z (t) satisfies (136). Thus, it seems
that a white noise random function z(t) may be defined as a random function having (136) as
its auto-covariance function. There is however one problem with this definition. The impulse
function (t) does not exist as an ordinary function. It will be clear that the essential feature
of the above derivation is given by the defining property (137) of the impulse function () .
Unfortunately, no ordinary function () exists, that has the reproducing property (137) for
any function f (t ) continuous at t. This can be seen as follows. Let us define a function
f (t ) in terms of f (t ) as:
(142)

It follows then with (137) that:

(143)

But this would imply with (137) that:
       Random functions 187

(144)

And clearly no ordinary function () exists such that (144) holds true for any function
f (t ) continuous at t. That is, no function () exists that is zero in any interval not

containing the origin and non-zero at the origin. Thus, strictly speaking (137), and therefore
also (136), make no sense. A way out of this dilemma is however to consider instead of () ,
a family of functions () , parametrized with the parameter  , such that (137) holds true
approximately. Consider for instance the following family of functions:

(145)

Then:
(146)

This is the average of f (t ) over the interval [ 1 , 1 ], see Figure 5.5 which is a good
approximation to f (t) for large values of  .  

                           Figure 5.5: The average of f (t ) for   [ 1 , 1 ].

                                                                                                                                            

In fact, this average reduces exactly to f (t) if the limit 0 of the integral (146) is taken.
Hence, it follows that although no ordinary function () exists such that (137) holds true,
there do exist functions () for which:

(147)
188 Dynamic data processing

For  large enough, the corresponding class of functions:
(148)

may therefore be considered to approximate to a sufficient degree the auto-covariance
function of practically uncorrelated random functions z(t) . Note namely that for increasing
values of  , the auto-covariance function (148) behaves more and more like an impulse, see
also Figure 5.6.

                         Figure 5.6: Graph of () for different values of  .

The limit of (148) as  does, however, not exist. This stipulates, that strictly speaking
white noise random functions do not exist. Hence, in order to model the auto-covariance
function of a practically uncorrelated random function z(t) , we should strictly speaking make
use of (148) with  large but finite. The finite value of  has however the disadvantage that
no use can be made of the integral property (147). As a consequence the simplification from
the double integral (134) to the single integral (135) is strictly speaking impossible if  is
finite. Practically however, the single integral may be considered a good enough
approximation to the double integral for  large enough. Thus for practically uncorrelated
random functions, the simplification from (134) to (135) can be done with a sufficient degree
of approximation. We will therefore agree from now on to define white noise random
functions as those inputs to (132) that result in an output x(t) having (135) as auto-covariance
function. The name white noise arises out of the fact that () contains in the limit as
 , just as white light, all frequencies in the same amounts. The notation used for the
auto-covariance function of a white noise random function will be that of (136), with the
impulse function () satisfying the integral equation (137). And the interpretation given to
the integral equation (137) will be that of the limit (147). As a final remark, we note (see
137) that since the impulse function () has the units of 1/time, the function 2(t) of (136)
cannot have the same units as zz(t1,t2) . The function 2(t) is therefore not a variance
function. It is called a spectral density function. And it has the units of the auto-covariance
function multiplied with the unit of time.

Example 62

In this example we will show that a random function z(t) with auto-covariance function:
                                                                                                           Random functions 189

(149)
can be considered as white noise when  . The auto-covariance function (149) is plotted
in Figure 5.7 for different values of  . Note the impulse-like behaviour of this auto-
covariance function as  increases. We consider the following integral:
(150)
with a(t) a non-random function.

        Figure 5.7: The auto-covariance function 1 2e   for increasing values of  .

                                                                                                      2

Application of propagation law (76) to (150) gives, with the change of variable 1 2  :
(151)
Let us first evaluate the inner integral of (151):
(152)
If t1  t2 , then 2 t1  0 and 2 t0  0 for 2  [t0,t2] . Hence, we may write (152) as:
(153)
Integration by parts gives for the first integral:
190 Dynamic data processing

(154)

and for the second integral:

(155)

Since 2 t1  0 and 2 t0  0 , it follows that the limits of (154) and (155) as    are both
equal to 1 a(2). Hence (152), which is the sum of (154) and (155), becomes after taking the

                    2

limit  , equal to a(2) :
(156)
We have therefore shown that for t1  t2 , the limit of (151) as  equals:
(157)
The corresponding result for the case t2  t1 follows by replacing t2 on the right-hand side of
(157) by t1 . As a general result we therefore have:
(158)
And this proves that the random function z(t) can indeed be considered to be white noise for
 .

5.5 The auto-covariance of the output of a linear system: the white
         noise case.

In this section we will show how to compute the auto-covariance of the output:
                                                                 Random functions 191

(159)

when the input z(t) is a white noise random function with auto-covariance matrix:

(160)  .

The matrix Szz(t) is called the spectral density matrix of the random function z(t) . It will be
assumed that the input z(t) is uncorrelated with the initial state vector x(t0) :

(161)

Then, according to (76), the following propagation law applies:

(162)

Substitution of (160) into (162) gives after the change of variable 1 2  :

(163)

If t1  t2 , then 2 t1  0 and 2 t0  0 for 2  [t0, t2] . In this case the inner integral of (163)
can be evaluated using property (137) of the impulse function. The result reads
 (t1,2) G(2) Szz (2) . We therefore have for t1  t2 :

(164)

The corresponding result for the case t2  t1 follows by replacing t2 in the integral of (164) by
t1 . Hence, the propagation law for the auto-covariance of the output of a linear system driven
by white noise, reads:

(165)                                                            .
192 Dynamic data processing

Example 63
Let x(t) be defined as:
(166)
with the auto-covariance function of the white noise input z(t) given as:
(167)
If we apply the propagation law (165) to (166) we get with (167) for the auto-covariance
function of the output x(t) :
(168)

Note that this result is identical to the result one would get if the limit  were taken of
1  times the auto-covariance function xx(t1,t2) of (102) in Section 5.3.3.

 2

Example 64
Let x(t) be defined as:
(169)
with the auto-covariance function of the white noise input z(t) given as:
(170)
Application of the propagation law (165) to (169) gives with (170):

(171)

Hence, the variance of x(t) reads:
                                                                                                           Random functions 193

(172)
Compare this result with (124) in Section 5.3.3.
Example 65
Let x(t) be defined through the differential equation:
(173)
The output x(t) reads then:
(174)
It is assumed that the input z(t) is uncorrelated with the initial state x(t0) . If we apply
propagation law (76) to (174), the auto-covariance function of the output x(t) follows as:

(175)

The double integral of (175) transforms into a single integral if z(t) is a white noise random
function. Let us assume that the input z(t) is a white noise random function with auto-
covariance function:
(176)
Then (175) simplifies, according to (165), to:

(177)

If t2  t1 , equation (177) may be written as:

Solving for the integral gives:
(178)
194 Dynamic data processing

This shows that if the variance of the initial state x(t0) equals:
(179)
the auto-covariance function of the output x(t) becomes:
(180)
The corresponding result for the case t1  t2 follows by interchanging t1 and t2 in the right-
hand side of (180). Hence, we have shown that if x(t) satifies (173) and (179), and if the
input z(t) is uncorrelated with the initial state and satisfies (176), then the auto-covariance
function of the output x(t) equals the exponential:
(181)
This is an important result. It shows that a random function x(t) having an exponential as its
auto-covariance function, can be thought of as being generated by the first-order differential
equation (173) with a white noise input z(t) .

The propagation law for the auto-covariance of the output of a linear system driven by white
noise is given by (165). This law is written as an integral equation. It is also possible,
however, to write this propagation law as a linear matrix differential equation. In order to
show this, we first consider the variance matrix of x(t) . The variance matrix of x(t) follows
by setting t1 and t2 in (165) equals to t:
(182)

We will now transform this integral equation into a linear matrix differential equation. Taking
the time-derivative of (182) gives:

(183)
Recall that the transition matrix satisfies (see equation (93) in Section 4.6):

Equation (183) may therefore be written as:
                                                    Random functions 195

(184)

And by substituting (182) into (184) we obtain:

(185)                                               .

This is a linear matrix differential equation for the variance matrix Qxx(t,t) of x(t) . Once
(185) has been solved for Qxx(t,t) , the auto-covariance matrix of x(t) can be computed from
Qxx(t,t) as:

(186)                                            .

Example 66
Let x(t) be defined through the differential equation:
(187)

The input z(t) is assumed to be white noise, which is uncorrelated with the initial state x(t0) .
The auto-covariance of z(t) is given as:
(188)
According to (185) the variance x2(t) of x(t) satisfies:

(189)

The solution of this differential equation reads:
196 Dynamic data processing

(190)

For the auto-covariance function xx(t1,t2) we have according to (186):
(191)

Substitution of (190) into (191) gives then:
(192)

This shows that if x2(t0)  2 , then:
(193)

Compare this result with (181) in Section 5.4.

Example 67

Let x(t) be defined through the second-order differential equation:
(194)
The input z(t) is assumed to be white noise, with auto-covariance function:
(195)

The initial conditions of (194) are assumed to be constant. Hence:
(196)

We are asked to derive the variance xx(t,t) of the output x(t) . First, we write the second-
order scalar differential equation (194) as a first-order vector differential equation. To put

(194) into a state vector form, we define the two-dimensional state vector as:
                                                 Random functions 197

(197)
The state vector form of (194) follows then as:
(198)

Two methods can now be used for deriving the auto-covariance of the output of (198). The
first method makes use of the integral form (165) of the propagation law for the auto-
covariance, the second is based on the linear matrix differential equation (185). We will
consider both methods.

First method

In order to make use of (165), we first need to find the matrix exponential of the system
matrix:

(199)

Since:

it follows that:
(200)

With the initial state vector of (198) being constant, the variance matrix of the output follows
according to (165) as:
198 Dynamic data processing

Integration gives:

or
(201)
Hence, the required variance-function of the output x(t) of (194) reads:
(202)
Second method
According to (185), the linear matrix differential equation for the variance matrix of the
output of the state equation (198) reads:

(203)
This matrix equation contains three independent scalar equations:

(204)

These equations may be put into state vector form as:
             Random functions 199

(205)

In order to solve this state equation, we first need to find the matrix exponential of the
system matrix:

(206)

We will use the Jordan canonical form (see Section 4.8.2) for the derivation of the matrix
exponential of F. The eigenvalues of the system matrix F follow from solving the
characteristic equation:

This gives:

or

Hence, the three distinct eigenvalues of the system matrix F are:
(207)
The corresponding eigenvectors t are obtained by solving (F I3) t 0,  1,2,3 . Ordering
the eigenvectors so obtained by columns, the matrix T of eigenvectors becomes:

(208)
200 Dynamic data processing

Its inverse reads:
(209)
Hence, the matrix exponential of F follows from (207), (208) and (209) as:
(210)
Since the initial state vector of (205) equals zero (see (196)), it follows with (210) that the
solution of the state equation (205) satisfies:

Integration gives:

or finally:
(211)
Compare this result with that of (201).
                                                            Random functions 201

5.6 Random polynomial equations of motion

In Section 3.2 polynomial equations of motion were derived for respectively: a stationary
object, an object that moves with constant velocity and an object that moves with constant
acceleration. As a result we were able to derive a one-to-one, linear relationship between the
state vector x(t) at an arbitrary time instant t and the state vector x(t0) at the initial epoch t0 .
The fact that this relationship is one-to-one implies that knowledge of x at any one particular
time-instant is sufficient for the exact determination of the complete time history of x(t) . But
one will agree that this is not very realistic for most practical applications. It is for instance
highly unlikely that a ship sailing at cruising speed, will indeed move with an exactly
constant velocity. It is more likely that the ship sails with a velocity that can be considered
constant on the average. But the velocity will nevertheless be subject to random changes from
time-instant to time-instant. For a ship sailing at cruising speed, it seems therefore more
realistic to model the ship's acceleration as a random function with zero mean. The expected
erratic behaviour of acceleration should then be reflected in the choice of the auto-covariance
function of acceleration.

In this section we will develop the random polynomial equations of motion that correspond
with, respectively, zero-mean velocity and zero-mean acceleration. As in Section 3.2 we will
develop the random polynomial equations of motion only for the single coordinate function
u(t) . The development for the other coordinate functions is similar.

5.6.1 Random constants as input

Zero-mean velocity

If we assume the initial position to be a random variable and velocity to be a random
function, the random position variable follows as (compare with equation (4) in Section 3.2):

(212)                                                    .

If we model velocity as a zero-mean random function:
(213)

the mean of the random position variable becomes:
(214)

Note that the deterministic relation (5) in Section 3.2 is now replaced by the expectation of
u(t) . We will assume that the velocity input of (212) is a random constant:

(215)                                                 .
202 Dynamic data processing

We will also assume that velocity is uncorrelated with the initial position u(t0) . Application
of propagation law (76) to (212) gives then, with (215), for the variance of u(t) :

or

(216)                                                     .

Zero-mean acceleration

If we assume the initial position and the initial velocity to be random variables, and
acceleration to be a random function, the random position and velocity variables follow as
(compare with equation (11) in Section 3.2):

(217)                                                        .

If we model acceleration as a zero-mean random function:
(218)
the mean of position and velocity becomes:

(219)

Compare this with equation (12) in Section 3.2.

We will assume that the acceleration input to (217) is a random constant:

(220)                                            .

We will also assume that acceleration is uncorrelated with u(t0) and u(t0) . Application of
propagation law (76) to (217) gives then, with (220), for the variance matrix of (u(t),u(t)) :
                                                               Random functions 203

or:

(221)                                                          .

Note that the last matrix of (221) is singular: it has rank 1. This is a direct consequence of
the random constant assumption (220).

5.6.2 White noise as input

Velocity as white noise

We will now assume that velocity is a white-noise random function with spectral density qu :

(222)                                                       .

We also assume that velocity is uncorrelated with the initial position u(t0). Application of
propagation law (165) to (212) gives then, with (222), for the variance of u(t):

or:

(223)                                                    .

Compare this result with (216) and note the difference.
204 Dynamic data processing

Acceleration as white noise

We assume that acceleration is a white noise random function with spectral density qu¨ :

(224)                        .

We also assume that acceleration is uncorrelated with u(t0) and u(t0) . Application of
propagation law (165) to (217) gives then, with (224), for the variance matrix of (u(t),u(t)) :

or:

(225)                           .

Compare this result with (221) and note the difference.

5.6.3 Exponentially correlated noise as input

In Section 5.6.2 the random functions were modelled as white noise. This is a realistic
assumption if for a particular application it is believed that velocity or acceleration behave in
a highly erratic manner. There are applications, however, for which the white noise
assumption is not realistic. For instance, an object navigating a straight-line constant velocity
course may be acted upon by zero-mean random forces that are correlated in time (e.g., surge
and sway, atmospheric turbulence). As a result the acceleration at time t will be correlated
with the acceleration at time t  for sufficiently small  . In this section we will therefore
consider velocity and acceleration as being correlated in time. We will assume that the
exponential can be used as a representative model for the correlations in time.

Exponentially correlated velocity

We assume that velocity is a random function with auto-covariance function:
(226)                                                    Random functions 205

                                        .

We also assume that velocity is uncorrelated with the initial position u(t0) . Application of
propagation law (76) to (212) gives then, with (226), for the variance of u(t) :

or

(227)                                      .

There are two limiting cases of interest. First, we consider long time intervals:
(228)
Then, since:

the variance function of u(t) becomes:

(229)                                   .

This shows, when we compare (229) with (223), that for time intervals (t t0) that are large
compared with the correlation length 1/ , the contribution of random velocity is essentially
that of white noise. This is also clear from Figure 5.8. This figure shows the exponential
auto-covariance function on three different time scales. In Figure 5.8b the time scale has been
stretched considerably with respect to that of Figure 5.8a. As a result the auto-covariance
function exhibits an impulse-like behaviour.
206 Dynamic data processing

                         Figure 5.8: The exponential auto-covariance function.
Figure 5.9 shows the relationship between (227) and (223) for some decreasing values of the
correlation length 1/ . It was assumed that t0 0, uu(t0,t0) 0 and 2 1 qu . Note that the

                                                                                                                                                           2

position variance in case of correlated velocity is always smaller than the position variance in
case of white noise velocity.

                  Figure 5.9: Graph of (223) and graphs of (227) for different values of  .
The second limiting case of interest concerns short time intervals:
(230)
Then, using the expansion:
it follows from (227) that:                      Random functions 207
(231)
                                          .

This shows that for time intervals (t t0) that are small compared to the correlation length
1/ , the contribution of random velocity is essentially that of a random constant. Compare
(231) with (216), and see also Figure 5.8c. Hence, this result reflects the fact that for

sufficiently short time intervals, the object moves essentially with a random, but constant,

velocity.

Exponentially correlated acceleration

We assume that acceleration is a random function with auto-covariance function:

(232)                                  .

We also assume that acceleration is uncorrelated with u(t0) and u(t0) . Application of
propagation law (76) to (217) gives then with (232) for the variance matrix of (u(t) , u(t)) :

or (verify this yourself):
208 Dynamic data processing

Again two limiting cases are of interest. First, for long time intervals (t t0) 1/, the
variance contribution of acceleration becomes:

(234)                               .

Compare this result with (225). Second, for short time intervals, (t t0) 1/ , the variance
contribution of acceleration becomes:

(235)                            .

Compare this result with (221).

5.7 Summary

In this chapter we introduced some elementary concepts of the theory of random functions. In
particular, attention was given to the extremely important propagation laws for the cross-
covariance and auto-covariance of the output of a linear, time-varying state-equation. These
propagation laws for random functions generalize in a natural way the well-known
propagation laws for random vectors. We have seen that in its most general form, the
propagation law for the auto-covariance consists of a double integral. This double integral,
however, simplifies to a single integral if the input can be considered to be a white noise
random function. It was shown that the white-noise random function can be seen as the
continuous counterpart of a discrete sequence of uncorrelated random variables. As a
preparation for the next chapter, we also introduced the random polynomial equations of
motion. As inputs we considered random constants, white noise random functions and
exponentially correlated random functons. It was shown how the model of exponentially
correlated random functions can be used to approximate white noise inputs and inputs that are
random constants. This is achieved through a suitable choice of the correlation length 1/ in
relation to the time interval considered. This is an important result, which shows the
flexibility of the model of exponentially correlated random functions.
6 Recursive least-squares: the dynamic case

6.1 Introduction: filter divergence
In Chapter 3 we considered the partitioned model:

(1)

together with the transition equation:
(2)
The combination of (1) and (2) led to the partitioned model (see (28) in Section 3.3):

(3)

It was on the basis of this model, that we developed in Chapter 3 two methods for recursively
predicting and filtering the time-varying state vector xt . The essence of recursive estimation is
that there is no need to store past measurements for the purpose of computing present least-
squares estimates. Hence, recursion enables us to keep track of the time process xt by means of
an efficient computation of the corresponding best estimates. As was pointed out in Chapter 3,
the transition equation (2) implies that knowledge of x at any particular time instant is sufficient
for the determination of the complete time history of x (t) . In other words, equation (2) implies
that the time-varying state vector x (t) can be parameterized in terms of one single vector x (t0) ,
for all times t. It will be clear that this is a rather stringent assumption, which will not be
realistic for most practical applications. In the present chapter this assumption will therefore be
relaxed considerably. It will be assumed that the dynamics of x (t) can be modelled through the
linear, time-varying state equation:
(4)
This implies that the transition equation (2) will be replaced by the solution of (4):
(5)

Note that the difference between (5) and our earlier transition equation (2) is given by:
210 Dynamic data processing

(6)

See also Figure 6.1.

                           Figure 6.1: Trajectory of x(t) =  (t,t0)x(t0) d(t,t0).
Now, if the transition equation (2) is replaced by (5), then the partitioned model (3) gets replaced
by 1):

(7)

It will be clear that the information content of the discrete set of observables y, i 0 , 1, , is not
enough for the simultaneous estimation of both xt and the di,t , i 0 , 1 , . What we need is
information about the difference vectors di,t . That is, we need to have some information available
about the input z(t) of (6), in order to be able to relate the state vectors of the various epochs
with one another. One way to tackle this problem is to assume the input z(t) to be identically
zero. Then also the difference vectors di,t are zero and (7) reduces to (3). But as was pointed out
earlier, the zero-input assumption is too stringent for most practical applications. In fact, an
unwarranted zero-input assumption will result in what is known as filter divergence. One speaks
of filter divergence, when the error in the estimated state vector grows without bound. In order
to explain the phenomenon of filter divergence, let us assume that the least-squares estimator of
xt is computed on the basis of model (3). The estimator reads then:
(8)

     1 We have used the notation di,t instead of d(ti,t).
                                                                         Recursive least-squares: the dynamic case 211

This estimator is unbiased if model (3) holds true. It is, however, a biased estimator if di,t  0
and model (7) holds true. If the expectation is taken of (8), we get with (7):

or
(9)

This shows that E     x^   k   xt   if  di,t  0 .    The  second    term  on    the  right-hand   side  of  (9)  describes

                        t

the  bias  of  the  estimator  x^    .  It  is  the  bias  in  the  filtered    estimator  if  t  tk . If the bias in the

                                 t  k

filtered  estimator  has  the  tendency         to  grow  as  k  gets  larger,  the  separation   between   E    x^   k  and

                                                                                                                   k

xk increases and the filtered estimator is said to diverge. The following example illustrates this

phenomenon of divergence.

Example 67

We are asked to estimate the one-dimensional position of a particle. Position measurements are

carried out at times ti , i    0,1,2,       ,k . The position observables            u    are uncorrelated and all have

                                                                                       i
the same variance 2 . The position of the particle at time tk is related to its position at time tk 1

and its velocity as:

(10)

Let us assume that the velocity ut of the particle is so small that we decide to ignore it in (10).
The corresponding model of our choice reads then:

(11)

Based on this model, we obtain the filtered position estimator as:
(12)

This estimator is unbiased if model (11) holds true. It is however a biased estimator if the
velocity u t of the particle cannot be ignored. Let us now investigate the effect of the neglected
velocity on the filtered position estimator (12). If the expectation is taken of (12), we get with:

that:
212 Dynamic data processing

(13)

Now assume that the velocity u t is indeed small, but constant. Then we have in case of uniform
sampling, ti t0 i T , that:

(14)

Substitution of (14) into (13) gives:
(15)

This result shows that the bias in the filtered position estimator increases as k gets larger. Hence,

the  mean  of  u^    diverges  from  the  actual  value  uk .  In  order  to  remedy  this  problem  of

                 kk

divergence, one might be inclined to include velocity as an unknown but constant parameter in

model (11). In this case, however, one may end up with the same problem of divergence due to

unmodelled constant accelerations.

We have seen that the zero-input assumption is too stringent for most practical applications, and
that an unwarranted zero-input assumption leads to the serious problem of filter divergence. So
what to do? It will be clear that the solution to the problem depends on the information we
believe to have available about the input z(t) . Let us therefore assume for the moment that the
continuous input z(t) is observable. If the continuous input z(t) is observable, we may also
consider the difference vector d (t , t0) of (6) observable, and construct with (5) and (6) for all t,
the observation equations:
(16)

These observation equations together with (1) will allow us then to estimate the state vector x (t)
for all times t. The supposition of this approach is of course that one has sensors at one's
disposal that observe the input z(t) on a continuous basis. In some applications this is indeed the
case. For instance, if the input z(t) equals velocity or acceleration, speedometers or
accelerometers could be available for observing z(t) on a continuous basis. Still, in a majority
of applications, no sensors are available for actually observing the input z(t) . Hence, it seems
that we are confronted with a dilemma. It seems that either we have to assume that the input z(t)
is identically zero and fall back on the transition equation (2). Or, that we have to assume that
the input z(t) is unknown and rely safely on the partitioned model (1). Both approaches have
their drawbacks. In the first approach filter divergence is likely to occur, especially over longer
time spans. And in the second approach, the drawback is that we have no means to estimate x (t)
other than at the discrete time instants ti , i 0 ,1, . In this chapter, our solution to the above
described dilemma will be the following. We will assume that, even in the absence of sensors
that actually observe z(t) , we can still treat the input z(t) as being observable. This approach is
motivated by the fact that in most applications the input z(t) can be modelled as a zero-mean
                                                                         Recursive least-squares: the dynamic case 213

random function. For a ship sailing at cruising speed for instance, one may model the ship's
acceleration as a random function with zero mean. For this case we will then consider the zero-
mean value of acceleration as the sample value of the input z(t) and use the auto-variance
function of acceleration for the modelling of the dispersion of the input. With this approach
equation (16) is interpreted as an observation equation and used together with (1) for the least-
squares estimation of the state vector x (t) for all times t.

6.2 The dynamic model of observation equations

In this section we will formulate the observation equations for the dynamic model. As a start we
will assume that the time-varying state vector xt can be modelled as:

(17)

We also assume that the input can be treated as being observable and that its auto-covariance
matrix is given as:
(18)

This implies that the difference vector:

(19)

is also observable, and that its variance matrix is given as 2:
(20)

It  should  be  noted  that  the  d,    i  1,2,  , are mutually uncorrelated:

                                     i

(21)

This can bee seen as follows. If we apply the propagation law for the auto-covariance to (19) we
get:

With the change of variable  2 1 , this may be written as:

    2 We have used the notation Qd instead of Qdd(ti,ti).
                                                                                                          i
214 Dynamic data processing

or after substitution of (18) as:

(22)

But if the two intervals [ ti 1 , ti ] and [ tj 1 , tj ] are disjunct, then 2 ti and 2 ti 1 are both
positive or both negative. This implies that the inner integral of (22) vanishes due to the impulse
function  () and that (21) indeed holds true. We are now in the position to formulate the
appropriate observation equations for the dynamic model. The observation equations themselves
follow from combining (17) and (19). And the corresponding dispersion follows from (20) and
(21). The dynamic model of observation equations reads therefore:

(23)                                                                                             .

6.3 Recursive prediction and filtering

In this section we will generalize the results of Sections 3.4 and 3.5. This will be done by taking
into account the dynamic model of observation equations (23). The complete partitioned model
of observation equations, on the basis of which the state vector will be estimated, reads therefore:

(24)

This model is based on (1) and (23). Our objective is now to derive an algorithm for the

recursive computation of the best estimate x^k k of xk . We therefore consider as a first step model

(24)  with  the  exception  of  d     and  y.   The  solution  of  this  model  is  then  given  by  the  vector  of

                                   k         k

estimates ( x^ , x^ , , x^ ) . The solution of the complete model (24) follows from solving
            0k 1 1k 1           k 1k 1

in a second step the model:
                                                                         Recursive least-squares: the dynamic case 215

(25)

The solution of this model is given by the vector of estimators ( x^ , x^ , , x^ , x^ ) . The
                                                                                             0k 1k           k 1k kk
structure of the design matrix of (25) reveals that the x^ , i 0 , 1 , k 2 , do not contribute to
                                                                             ik 1
                             and                                             and         of         and
the  solution  of  xk     1       xk .  That  is,  the  estimators  x^   1k        x^        xk  1       xk  only  depend  on

                                                                      k              kk

x^ , d and y . Hence, the estimators x^ and x^ can be derived from solving the model:
k 1k 1 k               k                                k 1k             kk

(26)

But the solution of this model can again be obtained in two steps. We first consider:
(27)
216 Dynamic data processing

Note that the design matrix of this model is square and of full rank. The redundancy equals
therefore zero, and (27) may be solved by simply inverting the design matrix. Since:

The solution of (27) follows as:
(28)

The   result  shows        how   the  predicted       estimator       x^    1  can  be  expressed      in  terms  of   the  filtered

                                                                        kk

estimator x^ and the vector d . The time-update equations read therefore:
              k 1k 1                            k

(29)                                                                                      .

Compare this result with the time-update equations of (45) in Section 3.4. Note that the above

result  reduces   to   that  of  (45)  in  Section    3.4,  if  d     is    identically   zero.  This  corresponds     to   the  case

                                                                   k

that  the  input  z    is  assumed    to  be    identically    zero.  The      time-update     equations   (29)   are  formulated

                    t

for   the  discrete    time  instant      tk .  This  is  the   time  instant       that  the  next  observable       y    becomes

                                                                                                                        k

available. But in fact one may formulate the time-update equations for the complete time interval

( tk 1 , tk ) . The continuous time-update equations read therefore:

(30)                                                                                                              .

See also Figure 6.2.
                                                                 Recursive least-squares: the dynamic case 217

                          Figure      6.2:  A   continuous  time-update     k,k  1 x^k  1k    .

                                                                                              1

The above time-update equations followed from solving model (27). The complete solution of
model (26) follows now from solving in a second step the model:

The   solution  of  this  model   is  given    by  the  vector   of  estimators  (x^     , x^ )   .  Again     we  note  that

                                                                                    k  1k kk

the  structure  of  the   design  matrix    of  (31)   is  such  that  the  estimator   x^    of     xk  will  only  depend

                                                                                          kk

on x^ and y . Hence the estimator x^ can be derived from solving the model:
      kk 1      k                                  kk

(32)

But this model is identical to model (46) in Section 3.4. Hence, the solution of (32) is identical
to (48) in Section 3.4 and reads:

(33)                                                                                    .

These are the measurement-update equations. If we write model (32) in terms of condition
equations and solve this model, we get as in (50) in Section 3.5 the alternative measurement-
update equations:
218 Dynamic data processing

in which Qv is the variance matrix of the predicted residuals. When we compare the recursive
                                          k

prediction and filtering results of this section with the results of Section 3.4 and 3.5, we note that
the only difference lies in the way the time-update computations are performed.

Example 68

We are asked to determine the one-dimensioned position of a particle. Position measurements

are carried out at the discrete time instants   ti,   i  0,1,2,... . The observables   x    are assumed to be

                                                                                         i
uncorrelated and all have the same variance x2 . We will start with the assumption that the

particle has a zero-velocity, i.e., that its position is constant. The corresponding model reads then:

(35)

From  this  the  filtered  position  estimator  x^    and  its  variance  follow  as:

                                                  kk

Note that the variance of the filtered position estimator gets smaller as k gets larger. And in the
limit we have:

(37)                                                            .

See also Figure 6.3.

                           Fig. 6.3.: The variance x^k k 2 x2/ (k 1) for x2 1 .

Also the gain Kk 1 / (k 1) gets smaller as k gets larger. And in the limit we have:
(38)
                                                              Recursive least-squares: the dynamic case 219

This  implies  that,  as  k   gets  larger  less  weight  is  given  to  the      new  position  observable  x.     That

                                                                                                               k

is,  the  contribution    of  the   new  position  observable     x      to  the   filtered   position  estimator   x^

                                                                    k                                                 kk

diminishes for increasing k. This is of course completely justified as long as the model (35) is

valid. Let us now assume that the velocity of the particle is not zero, but zero on the average.

The position of the particle is then constant on the average, although it may nevertheless change

from time instant to time instant. Would we now still base our filter computations on model (35),

we would end up for large k with a filtered position-estimator that is insensitive to the position

observable  x.   Hence,       the   filtered  position  estimate     x^k k   will  then  be   unable    to  follow  any

              k

position changes of the particle. As a consequence filter divergence is likely to occur. We

therefore  have  to   modify  model      (35)  in  order  to  make   the     filtered  position  estimator   x^    more

                                                                                                               kk

responsive to position changes of the particle. If we believe that the particle moves with a

velocity that is zero on the average, it seems realistic to model velocity as a zero-mean random

function. Let us therefore model velocity x k as a zero-mean random function, with the following
auto-covariance function:

(39)                                                                                       .

The spectral density q x should be chosen such that it reflects the expected erratic behaviour of
velocity. The variance contribution of velocity to position follows from applying with (39) the

propagation law to:

as:

(40)

Our   modified  model     follows   now     from   combining  the    observation       equations  E   d     xi xi 1 and

                                                                                                         i

(40) with (35). The result reads:

(41)

Unfortunately, no analytical solution of model (41) can be given. The computer was therefore

used for the computation of the variances of respectively x^ and x^ . They are given in Table
                                                                            kk 1       kk
6.1 for the case x2 1, qx 1/4 and ti ti 1 1 .
220 Dynamic data processing     x^k k 2  k x^k k 1 2 x^k k 2

                  k x^k k 1 2    1
                               0.556
0  -                           0.446     9   0.641 0.391
                               0.410
1  1.25                        0.398     8   0.641 0.390
                               0.393
2  0.806                       0.391     10  0.640  0.390
                               0.391
3  0.696                                 11  0.640  0.390

4  0.660                                 12  0.640  0.390

5  0.648                                 13  0.640  0.390

6  0.643                                 14  0.640  0.390

7  0.641                                 15  0.640  0.390

               Table 6.1: The variances  x^ 2 and x^k k 2 for x2 1, qx 1/4, ti ti 1 1 .
                                                                                                                                                kk 1

A plot of the results of Table 6.1 is given in Figure 6.4.

                     Figure 6.4: The variances x^k k 1 2 and x^k k 2 for x2 1, d2 1/4.

When we look at the results of Table 6.1 or at the plot of Fig. 6.4, we note that the variance of
the filtered position estimator x^k k does not seem to go to zero for increasing k. This in contrast
to (37). In fact it seems that for k both x^k k 1 2 and x^k k 2 converge to a non-zero constant value:
(42)

This would imply that in the limit the loss of precision due to prediction is exactly equal to the
gain in precision due to filtering:

(43)

We will now prove analytically that (42) and (43) indeed hold true. We will first consider the
variance of the filtered estimator. From:
                                         Recursive least-squares: the dynamic case 221

see (29) and (30) it follows that:
(44)
Now, if the variance matrix of the filtered estimator is constant in the limit, then:

and (44) may be written as:
(45)

For our present example this implies:
(46)

This equation can be rewritten as the quadratic equation:
(47)
This equation has two roots, a positive one and a negative one. Since x^k k 2  0 only the positive
root is valid. It reads:

(48)
                                                                                  .

The limiting value of the variance of the predicted estimator follows with (48) from
x^k k 1 2 1 x^k 1 k 1 2 1 d2 as:

(49)                                        .

And from (48) and (49) it follows that:

(50)                                     .

The numerical results (42) and (43) are now easily verified with (48), (49) and (50) (do this

yourself). Another two examples of (48), (49) and (50) are given in Figure 6.5. Note that as d2
gets larger, the limiting values of both xk k 2 and xk k 1 2 , and the difference (xk k 1 2 x^k k 1 2 ) get larger.
222 Dynamic data processing

     Figure 6.5: The variances  x^ 2 and x^k k 2 for (a) x2 1,d2 0.5; and (b) x2 1,d2 1.
                                                                                                                      kk 1

It is also of interest to find the limiting value of the gain. Since:

it follows with (48) that:

(51)                                                                               .

This shows that the limiting value of the gain is non-zero (compare with (38)) and that it is

uniquely determined by the ratio x2 / d2 . Note that the limiting value of the gain gets smaller if
the ratio x2 / d2 gets larger. This can be explained as follows. If x2 gets larger or d2 gets

smaller,   then  there  is  less  confidence  in    the  position    observable       x    but  more  confidence        in  the

                                                                                        k

dynamic model. In this case the filtered position estimator needs to be less responsive to the new

position observable and thus the gain will be smaller.

Model (41) has been formulated for the case that velocity is assumed to be zero on the average.

In  that  case   the  sample  values   of   the  d     are    taken  to  be   zero    and      the  spectral   density      qx  is

                                                    i

chosen so as to reflect the expected erratic behaviour of velocity. We will now consider two

different but related situations. First, we consider the situation where we really have a sensor

available that measures velocity on a continuous basis. Our observables are the discrete position

observables      x, i   0,1,...,  and  the  continuous   velocity        observable   x .  In   this  case    our  estimation

                   i                                                                    t

can again be based on model (41). The assumptions on the basis of which model (41) is

formulated are now, however, fundamentally different. First of all, no assumption needs to be

made about the mean value of velocity. Since velocity is measured on a continuous basis, model

(41) is now valid for every velocity profile of the particle. Also, the spectral density qx should
now describe the precision of the velocity sensor and not the expected erratic behaviour of

velocity.  And   finally,   the   sample    values  of   the  d     are  now  not   set    to  zero,  but  of  course       given

                                                                 i

as the integrated velocity measurements.
                                                            Recursive least-squares: the dynamic case 223

Let us now consider the situation where we have a sensor available that measures velocity on

a  discrete-time  basis.  Our  observables  are  then  the  discrete  position  observables  x,   i  0,1,... and

                                                                                               i

the  discrete  velocity   observables  x ,  i  1,2,... . It will be clear that these observables are not

                                         i

sufficient for the estimation of position for all times t. We therefore assume in addition that the

unknown velocity of the particle is constant. Then:

(52)
and

(53)

Substitution of (52) and (53) into (41) gives:

or
(54)
This shows that the constant, but unknown, velocity model can be obtained from (41).
224 Dynamic data processing

Example 69

Consider Figure 6.6. A ship follows an unknown trajectory. Our objective is to compute, on a
real-time basis, the best estimate of the ships's position ut, vt. For this purpose we assume that
the ship is equipped with two accelerometers that observe on a continuous basis the accelerations
u¨ t and v¨t . The autocovariance functions of acceleration are given as:
(55)

                                                                                           .

                                        Figure 6.6: Positioning of a ship.

Thus, we assume the measurement errors of the two accelerometers to behave as white noise and

u¨    to  be  uncorrelated  with  v¨ .  It  will  be  clear  that  acceleration  information  alone  is  not  sufficient

   t                                t

for the recovery of the ship's trajectory. We therefore also assume that at successive discrete

time instances ti, i 0,1,... azimuth ai and distance measurements li are carried out. These
measurements are carried out from a known point with coordinates u=0, v=0. The variances and

covariances of the azimuth and distance observables are given as:

(56)

In order to formulate the complete partitioned model of observation equations, we first start with
the discrete observation equations for azimuth and distance. These nonlinear observation
equations parameterized in terms of the cartesian coordinates ui, vi read:
                                 Recursive least-squares: the dynamic case 225

(57)

The corresponding linearized observation equations read:
(58)

This may also be written as:

(59)                                                      .

Let us now consider the observation equations for the observed accelerations. We will only
consider the accelerations along the u-axis. The development for the acceleration along the v-axis
goes along identical lines. The position ui and velocity u i follow from acceleration u¨ i as:

(60)

If we define the observable random vector d (d , d ) of integrated acceleration as:
                              i  u,i u,i

(61)

the corresponding linear observation equations follow with (55) from (60) and (61) as:

(62)                                                                                    .
226 Dynamic data processing

                             (63)
Recursive least-squares: the dynamic case 227

(64)
228 Dynamic data processing

With (59) and (62) we are now in the position to formulate the complete partitioned model of
linearized observation equations for all times ti. The complete model is given on the pages 226
and 227. It is on the basis of this model that the recursive estimation of position and velocity can
be carried out.

The recursive algorithm has to be initialized. Note that in the present example, initialization
cannot be based on only the azimuth and distance observable of time t0. Their information
content is namely not sufficient for the determination of both position and velocity at time t0. For
the present example, initialization has therefore to be based on the observables:

(65)

There are two ways for using these eight observables for the initialization. In the first approach
one solves for the eight state vector elements:

(66)

by using the first eight observation equations of model (63). Since these observation equations
are linearized, an iteration has to be performed to solve for the corresponding state vector
elements. After iteration we obtain as a result of the initialization the state vector estimates,
u^0 1, u^ 0 1, v^0 1, v^ 0 1, u^1 1, u^ 1 1, v^1 1, v^ 1 1 with their corresponding variance-covariance matrix.

The alternative approach to initialization is based on the fact that there exists a one-to-one
relationship between the first eight observables of (65) and the eight state vector elements of (66)
(note that the redundancy of the first eight observation equations of (63) equals zero). The
position estimators may therefore be computed directly from the azimuth and distance
observables as:

(67)

For the first velocity estimators we can make use of (60) and (61), This gives:

(68)

or after substitution of (67):
                                                                         Recursive least-squares: the dynamic case 229

(69)
In order to obtain the variances and covariances of the position and velocity estimators of (67)
and (69), we first have to linearize (67) and (69). this gives:

(70)

Note that the matrix of (70) is the inverse of the design matrix of the first eight observation

equations of (63). For the approximate values needed in (70) one may take the sample values

of  a,   l,  a    and  l   .  The  variances  and  covariances  of  the  position  and  velocity  estimators  follow

      0   0    1        1

now from applying with (56) the propagation law to (70). This concludes the initialization phase.

The first step after initialization is prediction. For the present example this implies that we have

to time-propagate the filtered state vector (u^ , u^ , v^ , v^ ) to the next time instant t2. This

                                                                                           11 11 11 11

is done with the linear time-update equations:
230 Dynamic data processing

(71)

The variance matrix of the predicted estimator follows from applying the propagation law to (71)

as:

(72)                                                             .

The   variance  matrix  of  the  filtered  estimator  x^    was  computed  in  the  initialization  phase  as:

                                                        11

(73)
                           Recursive least-squares: the dynamic case 231

and Qd is given as:
                        2

(74)

Note that if li2 (li0)2 ai 2 , then the variance matrix Qx^ of (73) simplifies to:
                                                                                                                                                                                             11

(75)

In that case the position and velocity estimators along the u-axis are and remain uncorrelated
with the correponding position and velocity estimators along the v-axis. The next step after
prediction is filtering. This implies for the present example that we have to solve the linearized
model:

(76)

The corresponding measurement-update equation gives then the solution for the filtered estimate
x^2 2 (u^2 2, u^ 2 2, v^2 2, v^ 2 2) with corresponding variance matrix Qx^ . Note that since (76) is a

                                                                                                                                                                                                                                       22
232 Dynamic data processing

linearized model one has to perform an iteration. As starting values for the approximate values
one may take (compare with our earlier discussion in Section 2.4):

(77)

After model (76) has been solved, the whole cycle of prediction and filtering is performed again.
To conclude this example one final remark is in order. Up to now it was assumed that the ship
was equipped with two accelerometers. In that case the trajectory of the ship is allowed to take
any form. Now assume that no accelerometers are available. In that case the same recursive
algorithm as described above can be applied, provided that some additional assumptions are
satisfied. First of all, one will have to assume that the ship moves with an acceleration that is
zero on the average. The sample values of the di are then taken to be zero. And secondly, the
spectral densities qu¨ and qv¨ will now have to correspond with the expected erratic behaviour of
the ship's acceleration and not with the measurement precision of the accelerometers.

6.4 State vector augmentation

In the previous section the general time-update and measurement-update equations were derived
for the recursive prediction and filtering of the time-varying state vector x(t). One of the starting
assumptions in the development of the resursive estimation algorithms was that the variance
matrix of the vector of observables has to be of a block-diagonal form, see the dispersion of
model (24) in Section 6.3. In particular was assumed that:

(78)

In  Section  6.2  it  was  shown  that  (78)  holds  true  if  the  input  z    is  modelled  as  a  white-noise

                                                                             t

random function, see (18) in Section 6.2. But as was pointed out in Section 5.6.3 there do exist

particular applications for which the white-noise assumption is not realistic. In some applications

it is more realistic to model the input as being correlated in time. Correlation in time, however,

will affect the structure of the variance matrix of the vector of observables. That is, it will then

not be in a block-diagonal form anymore. And this has as a consequence that the recursive

algorithms of the previous section will not be applicable anymore. It thus seems that recursive

estimation is impossible if correlations in time are present. Fortunately, there is one way out of

this dilemma, namely when the correlations in time are of exponential form. In this section we

will show that if the input is exponentially correlated in time, a modification of the dynamic

model through an augmentation of the state vector is possible, such that (78) still holds true but

now for an augmented dynamics vector d . The idea is based on the result of Example 65 in

Section 5.5. In this example it was shown that an exponentially correlated random function can

be thought of as being generated by a first-order differential equation driven by white-noise. We

will consider the two cases of exponentially correlated zero-mean velocity and exponentially

correlated zero-mean acceleration.
                                                                         Recursive least-squares: the dynamic case 233

6.4.1 Exponentially correlated zero-mean velocity
Consider a particle that moves with an exponentially correlated velocity u(t) that is zero on the
average. Velocity will then be modelled as a zero-mean random function with auto-covariance
function:
(79)
The corresponding dynamic model of observation equations reads then:
(80)

In this case, however, (78) will fail to hold true. Based on the result of Example 65 in Section
5.5, we therefore model the zero-mean random velocity u(t) as:
(81)
with

(82)

With (81) and (82) we are now in a position to formulate a dynamic model for which (78)
indeed holds true. In order to show this we first put (81) into a first-order state vector form:

(83)

This is a linear, time-invariant state equation. The matrix-exponential of the system matrix F
reads (verify this yourself):
(84)

The solution of the linear, time-invariant state equation (83) reads therefore:

(85)  .

It is this relation which replaces (212) in Section 5.6.1 when the zero-mean velocity is
exponentially corrrelated. Note that with E u(t0) 0 and E z(t) 0 (see (82)), the expectation
234 Dynamic data processing

of (85) indeed satisfies (213) and (214) in Section 5.6.1. The variance matrix of position and
velocity follows with (82) from (85) as:

or as:
                                                                                                                    .

(86)

Note that the variance function u2(t) of (86) is indeed identical to (227) in Section 5.6.3. Again
there are two limiting cases of interest. First, for long time-intervals (t t0) > > 1 , we have:

(87)                                                    .

This result agrees with (229) in Section 5.6.3. Secondly, for short time-intervals (t t0) < < 1 , we
have:

(88)                                                 .

And this result agrees with (231) in Section 5.6.3.
                                                                         Recursive least-squares: the dynamic case 235

6.4.2 Exponentially correlated zero-mean acceleration
Consider a particle that moves with an exponentially correlated acceleration u¨(t) that is zero on
the average. In order to obtain a dynamic model such that (78) holds true, we model the zero-
mean random acceleration u¨(t) as:
(89)
with
(90)

The first-order state vector form of (89) reads:

(91)

And the matrix exponential of the system matrix F reads (verify this yourself):
(92)

The solution of the linear, time-invariant state equation (91) reads therefore:

(93)  .
236 Dynamic data processing

It is this relation which replaces (217) in Section 5.6.1 when the zero-mean acceleration is
exponentially correlated. Note that with E u(t0) 0 and E z(t) 0 , see (90), the expectation of
(93) indeed satisfies (218) and (219) in Section 5.6.1. The variance matrix of position, velocity
and acceleration follows with (90) and (93) as (verify this yourself), formula (94).

(94)
with

Verify yourself that the variance matrix of position and velocity of (94) is identical to (233) in
Section 5.6.3.
                                                                         Recursive least-squares: the dynamic case 237

Example 70
Consider again the situation of Example 69. But now assume that the ship sails with an
exponentially correlated acceleration that is zero on the average, Then the dynamic model (62)
in Section 6.3 needs to be modified using the results of (93) and (94). The augmented dynamic
model reads then:

In this case the sample values of the d (d , d , d ) are taken to be zero. And at
initialization u¨(t0) is treated as an observable with a sample value of zero and variance i u,i u,i u¨,i 2 (see
(90)).
Example 71
In Example 69 the choice was made to parameterize the models in terms of cartesian coordinates
see (63). This resulted in nonlinear observation equations for the azimuth and distance
observables (see (57)), but in a linear dynamic model (see (62)). In the present example a
different parameterization will be used. Instead of using a fixed i-frame, we will now
parameterize with respect to a rotating b-frame such that the observation equations for the
azimuth and distance observables will become linear. This will have as a consequence that now
the dynamic model will take a nonlinear form.
238 Dynamic data processing

                                   Figure 6.7: The i-frame and b-frame.
Consider Figure 6.7. The position, velocity and acceleration of the ship in the rotating b-frame
read:
(96)
where
(97)
As state vector elements we will take: x, vx,  and vy . The observation equations for azimuth
and distance will then take the following linear form:
(98)
Let us now consider the corresponding state equation. We have according to Table 4.1 for
velocity and acceleration:

and

This shows that if the acceleration Rbir¨i is considered as input, the first-order state equation may
be written as:
                                         Recursive least-squares: the dynamic case 239

(99)
or in the components x, vx,  and vy as:

(100)

This is a nonlinear, time-invariant state equation.

6.5 Summary

In this chapter we developed the general least-squares prediction and filtering formulae for the
recursive estimation of a time-varying state vector x(t). It was shown that the measurement-
update equations are identical to the ones developed in Chapter 3. The time-update equations
differ, however, from those of Chapter 3. This difference is due to the way the dynamics of the
system are modelled. In the present chapter the input z(t) was included in the dynamic model.
It was shown that an unwarranted zero-input assumption may lead to filter divergence. It is
therefore expedient to model inputs that can be considered to be zero on the average, as zero-
mean random functions. This leads to a more flexible dynamic model, with the zero-input
assumption as special case. It was also shown how to augment the dynamic model in case the
input cannot be treated as white noise. Augmentation is possible if the input is exponentially
correlated in time.
240 Dynamic data processing

Literature

Breiman, L.; Probability and stochastic processes: with a view toward applications
Boston, Houghton Mifflin Company (1969)

Decarlo, R. and R.A. Decarlo.; Linear systems, a state variable approach with numerical
implementation
Englewood Cliffs, Prentice Hall (1990)

Gelb, A. (eds.); Applied optimal estimation
Cambridge, Mass, MIT Press (1974)

Goldstein, H.: Classical mechanics
Reading, Addison Wesley Publishing Company, 2nd ed. (1981-1980)

Melsa, J. and A. Sage; An introduction to probability and stochastic processes
Englewood Cliffs, Prentice Hall (1973)

Newton, I.; The principia: mathematical principles of natural philosophy, translated by B. Cohen
A. Whitman from the origin: Philosophiae naturalis principia mathematica
Berkeley University of California Press (1999)

Papoulis, A.; Probability, random variables and stochastic processes
New York, McGraw-Hill Book Company (1991)

Peebles, P.Z.; Probability, random variables and random signal principles
New York, McGraw-Hill Book Company, 4th ed. (2001)

Stark, H. and Woods, J.W.; Probability, random processess and estimation theory for engineers
Englewood Cliffs, Prentice Hall (1986)

Stoer, J. and Bulirsch, R.; Introduction to numerical analysis
New York, Springer Verlag, 2nd ed. (1994)

Teunissen, P.J.G.; Generalized inverses, adjustment, the datum problem and S-transformations
In: Optimization and design of geodetic networks, Ed. E. Grafarend and F. Sansò, Springer
Verlag, pp. 11-54 (1985a)

Teunissen, P.J.G.; The geometry of geodetic inverse linear mapping and nonlinear adjustment
Netherlands Geodetic commission, Publ. on Geodesy, New Series 8(1) (1985b)

Teunissen, P.J.G.; Adjustment theory, an introduction
Delft University Press, 1st ed. (2000)
Index                                                                               Index 241

a                                        m

A-model                                  matrix exponential 138
-linear 5                                - Jordan canonical form 142
-nonlinear 24                            - Taylor's series 138
augmentation; see state augmentation     mean; see expectation
                                         mean value stationary 155
b                                        measurement update 47, 55, 88, 90, 217

Best Linear Unbiased Estimation 20, 48   n
B-model
- linear 35                              Newton's laws 111
- nonlinear 38
                                         o
c
                                         observation equation 5, 19
condition equation 35                    - linearized 28
consistency 5
covariance 20                            p
covariance stationary 155, 156
                                         predicted residual 48, 55
d                                        prediction 80

Dirac delta function 185                 r
dispersion 19
                                         random constant 175, 220
e                                        random function 153
                                         - auto-variance 155, 156, 170
equations of motion 103, 111             - cross-covariance 155, 156, 163
expectation 19, 20                       - mean 155, 163
exponentially correlated noise 204, 232
                                         s
f
                                         smoothing 81
filter divergence 210                    spectral density 188, 191
filtering 81                             state augmentation 232
fundamental matrix 133                   state equation 120
                                         - linear(ized) 126, 132, 136
g                                        state transition matrix; see
                                         transition matrix
gain matrix 49, 55                       state vector 119
gradient vector 27
                                         t
h
                                         Taylor's theorem 27
Hessian matrix 27                        time update 88, 216
                                         time-invariant system 121
i                                        time-varying system 120
                                         transition matrix 73, 133
impulse function; see                    - properties 78, 135
Dirac delta function
inconsistency 5                          v
inertial navigation 118
iteration 33, 63                         variance 19, 20
                                         variance update 47, 55
k
                                         w
Kronecker symbol 174
                                         weight matrix 16, 21
l                                        weighted least squares; see
                                         least squares
least squares 13                         white noise 183, 186, 188, 203
- estimates 19
- estimators 19
- recursive, A-form 46, 87
- recursive, B-form 54, 90
- residual 14, 55
- weighted 16
linearization 27, 63
Dynamic data processing :
Recursive least-squares

Peter J.G. Teunissen

This book is a follow-up on Adjustment theory. It extends the theory to
the case of time-varying parameters with an emphasis on their recursive
determination. Least-squares estimation will be the leading principle used. A
least-squares solution is said to be recursive when the method of computation
enables sequential, rather than batch, processing of the measurement data.
The recursive equations enable the updating of parameter estimates for
new observations without the need to store all past observations. Methods
of recursive least-squares estimation are therefore particularly useful for
applications in which the time-varying parameters need to be instantly
determined. Important examples of such applications can be found in the fields
of real-time kinematic positioning, navigation and guidance, or multivariate
time series analysis. The goal of this book is therefore to convey the necessary
knowledge to be able to process sequentially collected measurements for the
purpose of estimating time-varying parameters.

When determining time-varying parameters from sequentially collected
measurement data, one can discriminate between three types of estimation
problems: filtering, prediction and smoothing. Filtering aims at the determination
of current parameter values, while smoothing and prediction aim at the
determination of respectively past and future parameter values. The emphasis in
this book will be on recursive least-squares filtering. The theory is worked out for
the important case of linear(ized) models. The measurement-update and time-
update equations of recursive least-squares are discussed in detail. Models with
sequentially collected data, but time-invariant parameters are treated first.

In this case only the measurement-update equations apply. State-space models
for dynamic systems are discussed so as to include time-varying parameters.
This includes their linearization and the construction of the state trans matrix.
Elements from the theory of random functions are used to describe the
propagation laws for linear dynamic systems. The theory is illustrated by means
of many worked out examples. They are drawn from applications such as
kinematic positioning, satellite orbit determination and inertial navigation

P.J.G. Teunissen                                                                      © 2024 TU Delft Open
                                                                                      ISBN 978-94-6366-917-7
Delft University of Technology                                                        DOI https://10.59490/tb.98
Faculty of Civil Engineering and Geosciences                                          textbooks.open.tudelft.nl

Dr (Peter) Teunissen is Professor of Geodesy at Delft                                 Cover image: A. Smits
University of Technology (DUT) and an elected member
of the Royal Netherlands Academy of Arts and Sciences.
He is research-active in various fields of Geodesy, with
current research focused on the development of theory,
models, and algorithms for high-accuracy applications
of satellite navigation and remote sensing systems.
His past DUT positions include Head of the Delft Earth
Observation Institute, Education Director of Geomatics
Engineering and Vice-Dean of Civil Engineering and
Geosciences. His books at TUDelft Open are Adjustment
Theory, Testing Theory, Dynamic Data Processing and
Network Quality Control.
